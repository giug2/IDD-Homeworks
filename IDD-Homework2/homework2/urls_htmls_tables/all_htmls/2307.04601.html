<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.04601] InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval</title><meta property="og:description" content="Recent work has explored Large Language Models (LLMs) to overcome the lack of training data for Information Retrieval (IR) tasks. The generalization abilities of these models have enabled the creation of synthetic in-dâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.04601">

<!--Generated on Wed Feb 28 18:56:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on February 2023.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hugo Abonizio
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">NeuralMind</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_institution">University of Campinas</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Luiz Bonifacio
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">NeuralMind</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_institution">University of Campinas</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vitor Jeronymo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">NeuralMind</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_institution">University of Campinas</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Roberto Lotufo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">NeuralMind</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_institution">University of Campinas</span><span id="id12.3.id3" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jakub Zavrel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">Zeta Alpha</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_country">Netherlands</span>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rodrigo Nogueira
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id15.1.id1" class="ltx_text ltx_affiliation_institution">Zeta Alpha</span><span id="id16.2.id2" class="ltx_text ltx_affiliation_institution">NeuralMind</span><span id="id17.3.id3" class="ltx_text ltx_affiliation_institution">University of Campinas</span><span id="id18.4.id4" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
</div>
<div class="ltx_dates">(Date: February 2023; 2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id19.id1" class="ltx_p">Recent work has explored Large Language Models (LLMs) to overcome the lack of training data for Information Retrieval (IR) tasks. The generalization abilities of these models have enabled the creation of synthetic in-domain data by providing instructions and a few examples on a prompt.
InParsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib1" title="" class="ltx_ref">10.1145/3477495.3531863, </a>)</cite> and PromptagatorÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib3" title="" class="ltx_ref">https://doi.org/10.48550/arxiv.2209.11755, </a>)</cite> have pioneered this approach and both methods have demonstrated the potential of using LLMs as synthetic data generators for IR tasks.
This makes them an attractive solution for IR tasks that suffer from a lack of annotated data.
However, the reproducibility of these methods was limited, because InParsâ€™ training scripts are based on TPUs â€“ which are not widely accessible â€“ and because the code for Promptagator was not released and its proprietary LLM is not publicly accessible.
To fully realize the potential of these methods and make their impact more widespread in the research community, the resources need to be accessible and easy to reproduce by researchers and practitioners.
Our main contribution is a unified toolkit for end-to-end reproducible synthetic data generation research, which includes generation, filtering, training and evaluation. Additionally, we provide an interface to IR libraries widely used by the community and support for GPU.
Our toolkit not only reproduces the InPars method and partially reproduces Promptagator, but also provides a plug-and-play functionality allowing the use of different LLMs, exploring filtering methods and finetuning various reranker models on the generated data. We also made available all the synthetic data generated in this work for the 18 different datasets in the BEIR benchmark which took more than 2,000 GPU hours to be generated as well as the reranker models finetuned on the synthetic data. Code and data are available at <a target="_blank" href="https://github.com/zetaalphavector/InPars" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zetaalphavector/InPars</a></p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>;  </span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>;</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">price: </span></span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Effective neural Information Retrieval (IR) models often require a large amount of labeled training data. However, obtaining human labeled data is costly and many publicly available benchmarks contain few or no training examplesÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib16" title="" class="ltx_ref">thakur2021beir, </a>)</cite>. In these cases, the common approach is to train a model on a large dataset, such as
MS MARCOÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib9" title="" class="ltx_ref">DBLP:journals/corr/NguyenRSGTMD16, </a>)</cite> and Natural QuestionsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib6" title="" class="ltx_ref">kwiatkowski-etal-2019-natural, </a>)</cite>, and use it in a zero-shot transfer learning scenarioÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib14" title="" class="ltx_ref">Rosa_2022, </a>)</cite>.
Nonetheless, models trained on these datasets face challenges to generalize to the variety of tasks and specific domains available in the real world.
Thus, the recently proposed InParsÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib1" title="" class="ltx_ref">10.1145/3477495.3531863, </a>)</cite> and PromptagatorÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib3" title="" class="ltx_ref">https://doi.org/10.48550/arxiv.2209.11755, </a>)</cite> methods, along with their extensions InPars-v2Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">https://doi.org/10.48550/arxiv.2301.01820, </a>)</cite> and InPars-LightÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib2" title="" class="ltx_ref">https://doi.org/10.48550/arxiv.2301.02998, </a>)</cite>, have explored Large Language Models (LLMs) to generate synthetic data and have demonstrated their effectiveness. These methods not only outperform models that are finetuned on extensively labeled datasets but have also shown to be more adaptable to different tasks.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">These methods propose the generation of synthetic in-domain training data by exploring the few-shot learning abilities of LLMs, prompting them with a brief description of the task and a small number of in-domain examples. InPars uses a static prompt that include examples collected from the MS MARCO dataset, whereas Promptagator uses dynamic prompts that include domain and task-specific examples sampled from the target dataset. Another key difference of these methods lies in the filtering of generated data. While InPars uses the sequence probability given by the LLM at generation time, Promptagator uses a consistency filtering with a model trained on the generated data. Similarly, InPars-v2 extends the pipeline by using a pre-trained reranker model to filter the examples. InPars-Light goes further in the efficiency direction by using lightweight models and showing that they are competitive with larger models.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">These methods have proven to be effective, representing the state of the art in the BEIR benchmarkÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib16" title="" class="ltx_ref">thakur2021beir, </a>)</cite>. However, reproducing such pipelines can still be a challenging task; researchers need to handle different codebases in addition to having access to a specific computational infrastructure. Most of the time, such components are not well integrated, making it difficult for researchers and practitioners to use them effectively. In this work, we bring all these components together, making it possible to experiment with InPars, Promptagator, and their variants, as well as to try new approaches using different LLMs, prompting approaches and datasets. We believe that making these resources available to allow reproducible work in the field of IR is crucial for several reasons. First, reproducibility is a key component of scientific research, as it allows other researchers to confirm and build upon the findings of a study. Second, the reproduction of LLM related studies is often costly, and making the models and generated data available provides a valuable resource for the community. We summarize our contributions as follows:
</p>
</div>
<div id="S1.p4" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We provide an extensive guideline for reproducing InPars and InPars-v2 for datasets on the BEIR benchmark on GPU. For Promptagator, we provide an implementation for reproducing the synthetic queries generation step with the dynamic prompt construction originally proposed by the authors.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We also provide support for using different data sources: Pyseriniâ€™sÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">Lin_etal_SIGIR2021_Pyserini, </a>)</cite> pre-built indexes for the BEIR datasets, and <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">ir_datasets</span>Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib8" title="" class="ltx_ref">macavaney:sigir2021-irds, </a>)</cite> library, which contains multiple IR datasets.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Lastly, we make available all the synthetic data generated in this reproduction study, along with the prompts and the finetuned reranker models.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Methods</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we describe the main methods reproduced in this paper and highlight the differences in their data generation pipelines.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>InPars</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.11" class="ltx_p">The InPars method, currently available in two different versions, explores the few-shot learning abilities of LLMs to generate synthetic training data for IR tasks, by using a prompt template that instructs the LLM on how to generate the synthetic data. The prompt <math id="S2.SS1.p1.1.m1.1" class="ltx_math_unparsed" alttext="t||d" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1b"><mi id="S2.SS1.p1.1.m1.1.1">t</mi><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS1.p1.1.m1.1.2">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS1.p1.1.m1.1.3">|</mo><mi id="S2.SS1.p1.1.m1.1.4">d</mi></mrow><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">t||d</annotation></semantics></math> is the concatenation of a prefix <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">t</annotation></semantics></math> and a document <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">d</annotation></semantics></math>, where the prefix <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">t</annotation></semantics></math> consists of <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">N</annotation></semantics></math> pairs of documents and their relevant queries, i.e., <math id="S2.SS1.p1.6.m6.3" class="ltx_Math" alttext="t=\{(q_{1}^{*},d_{1}^{*}),...,(q_{N}^{*},d_{N}^{*})\}" display="inline"><semantics id="S2.SS1.p1.6.m6.3a"><mrow id="S2.SS1.p1.6.m6.3.3" xref="S2.SS1.p1.6.m6.3.3.cmml"><mi id="S2.SS1.p1.6.m6.3.3.4" xref="S2.SS1.p1.6.m6.3.3.4.cmml">t</mi><mo id="S2.SS1.p1.6.m6.3.3.3" xref="S2.SS1.p1.6.m6.3.3.3.cmml">=</mo><mrow id="S2.SS1.p1.6.m6.3.3.2.2" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.6.m6.3.3.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">{</mo><mrow id="S2.SS1.p1.6.m6.2.2.1.1.1.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml"><mo stretchy="false" id="S2.SS1.p1.6.m6.2.2.1.1.1.2.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml">(</mo><msubsup id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.2.cmml">q</mi><mn id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.3.cmml">1</mn><mo id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.3.cmml">âˆ—</mo></msubsup><mo id="S2.SS1.p1.6.m6.2.2.1.1.1.2.4" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml">,</mo><msubsup id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.cmml"><mi id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.2.cmml">d</mi><mn id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.3.cmml">1</mn><mo id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S2.SS1.p1.6.m6.2.2.1.1.1.2.5" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml">)</mo></mrow><mo id="S2.SS1.p1.6.m6.3.3.2.2.4" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">â€¦</mi><mo id="S2.SS1.p1.6.m6.3.3.2.2.5" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">,</mo><mrow id="S2.SS1.p1.6.m6.3.3.2.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.6.m6.3.3.2.2.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml">(</mo><msubsup id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.cmml"><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.2.cmml">q</mi><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.3.cmml">N</mi><mo id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.3.cmml">âˆ—</mo></msubsup><mo id="S2.SS1.p1.6.m6.3.3.2.2.2.2.4" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml">,</mo><msubsup id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.cmml"><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.2.cmml">d</mi><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.3.cmml">N</mi><mo id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S2.SS1.p1.6.m6.3.3.2.2.2.2.5" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.SS1.p1.6.m6.3.3.2.2.6" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.3b"><apply id="S2.SS1.p1.6.m6.3.3.cmml" xref="S2.SS1.p1.6.m6.3.3"><eq id="S2.SS1.p1.6.m6.3.3.3.cmml" xref="S2.SS1.p1.6.m6.3.3.3"></eq><ci id="S2.SS1.p1.6.m6.3.3.4.cmml" xref="S2.SS1.p1.6.m6.3.3.4">ğ‘¡</ci><set id="S2.SS1.p1.6.m6.3.3.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2"><interval closure="open" id="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2"><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.2">ğ‘</ci><cn type="integer" id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.2.3">1</cn></apply><times id="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.1.1.3"></times></apply><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2">superscript</csymbol><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.2">ğ‘‘</ci><cn type="integer" id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.3.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.2.3">1</cn></apply><times id="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.3.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.2.3"></times></apply></interval><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">â€¦</ci><interval closure="open" id="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2"><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1">superscript</csymbol><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.2">ğ‘</ci><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.2.3">ğ‘</ci></apply><times id="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.1.1.3"></times></apply><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2">superscript</csymbol><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.2">ğ‘‘</ci><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.2.3">ğ‘</ci></apply><times id="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.2.3"></times></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.3c">t=\{(q_{1}^{*},d_{1}^{*}),...,(q_{N}^{*},d_{N}^{*})\}</annotation></semantics></math>. The prompt <math id="S2.SS1.p1.7.m7.1" class="ltx_math_unparsed" alttext="t||d" display="inline"><semantics id="S2.SS1.p1.7.m7.1a"><mrow id="S2.SS1.p1.7.m7.1b"><mi id="S2.SS1.p1.7.m7.1.1">t</mi><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS1.p1.7.m7.1.2">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S2.SS1.p1.7.m7.1.3">|</mo><mi id="S2.SS1.p1.7.m7.1.4">d</mi></mrow><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">t||d</annotation></semantics></math> is fed to a language model <math id="S2.SS1.p1.8.m8.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.SS1.p1.8.m8.1a"><mi id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><ci id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">G</annotation></semantics></math> that generates a question <math id="S2.SS1.p1.9.m9.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">q</annotation></semantics></math> that is likely to be relevant to <math id="S2.SS1.p1.10.m10.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS1.p1.10.m10.1a"><mi id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.1b"><ci id="S2.SS1.p1.10.m10.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.1c">d</annotation></semantics></math>. The resulting pair <math id="S2.SS1.p1.11.m11.2" class="ltx_Math" alttext="(q,d)" display="inline"><semantics id="S2.SS1.p1.11.m11.2a"><mrow id="S2.SS1.p1.11.m11.2.3.2" xref="S2.SS1.p1.11.m11.2.3.1.cmml"><mo stretchy="false" id="S2.SS1.p1.11.m11.2.3.2.1" xref="S2.SS1.p1.11.m11.2.3.1.cmml">(</mo><mi id="S2.SS1.p1.11.m11.1.1" xref="S2.SS1.p1.11.m11.1.1.cmml">q</mi><mo id="S2.SS1.p1.11.m11.2.3.2.2" xref="S2.SS1.p1.11.m11.2.3.1.cmml">,</mo><mi id="S2.SS1.p1.11.m11.2.2" xref="S2.SS1.p1.11.m11.2.2.cmml">d</mi><mo stretchy="false" id="S2.SS1.p1.11.m11.2.3.2.3" xref="S2.SS1.p1.11.m11.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m11.2b"><interval closure="open" id="S2.SS1.p1.11.m11.2.3.1.cmml" xref="S2.SS1.p1.11.m11.2.3.2"><ci id="S2.SS1.p1.11.m11.1.1.cmml" xref="S2.SS1.p1.11.m11.1.1">ğ‘</ci><ci id="S2.SS1.p1.11.m11.2.2.cmml" xref="S2.SS1.p1.11.m11.2.2">ğ‘‘</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m11.2c">(q,d)</annotation></semantics></math> forms a positive training example that is later used to finetune a retrieval model. The original InPars work uses a GPT-3 LLM as the synthetic data generator, while InPars-v2 replaced the LLM with GPT-JÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib18" title="" class="ltx_ref">gpt-j, </a>)</cite>. These models, trained on massive amounts of text data, have shown impressive abilities in generating human-like text, answering questions, translating languages, and even creating original content. GPT-J is an open-source 6B parameters transformer model trained using 402 billion tokens from the PileÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib4" title="" class="ltx_ref">DBLP:journals/corr/abs-2101-00027, </a>)</cite>, an 800 GB English dataset. When generating the synthetic queries, a greedy decoding strategy was used.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">InPars proposes two different prompts. The first one, named â€œVanillaâ€ prompt, uses three fixed pairs of examples of document and relevant query, that were randomly collected from the MS MARCO training dataset. The second prompt template, referred to as â€œGuided by Bad Questionsâ€ (GBQ) uses the same examples from the first prompt, but it labels the original questions from the MS MARCO dataset as â€œbadâ€ questions. The â€œgoodâ€ questions were manually created and are more elaborated. The intention is to encourage the LLM to produce more informative questions, where the full context of the document contributes to the answers.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.4" class="ltx_p">InPars generates 100K pairs of positive training examples using documents randomly sampled from a collection <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">D</annotation></semantics></math>. The prefix <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">t</annotation></semantics></math> is always the same regardless of the input document <math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><mi id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">d</annotation></semantics></math>. After generating the synthetic data, a filtering step is proposed, to select the top <math id="S2.SS1.p3.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p3.4.m4.1a"><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">K</annotation></semantics></math> pairs with respect to the following (log) probability:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="p_{q}=\frac{1}{|q|}\sum_{i=1}^{|q|}\log p(q_{i}|t,d,q_{&lt;i})," display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.3" xref="S2.E1.m1.5.5.1.1.3.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml">p</mi><mi id="S2.E1.m1.5.5.1.1.3.3" xref="S2.E1.m1.5.5.1.1.3.3.cmml">q</mi></msub><mo id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.5.5.1.1.1" xref="S2.E1.m1.5.5.1.1.1.cmml"><mfrac id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mn id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml">1</mn><mrow id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">q</mi><mo stretchy="false" id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.5.5.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.cmml"><munderover id="S2.E1.m1.5.5.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E1.m1.5.5.1.1.1.1.2.2.2" xref="S2.E1.m1.5.5.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.2.2.3" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.2.2.3.2" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S2.E1.m1.5.5.1.1.1.1.2.2.3.1" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.5.5.1.1.1.1.2.2.3.3" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.3.1" xref="S2.E1.m1.2.2.1.2.1.cmml">|</mo><mi id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml">q</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.2.2.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S2.E1.m1.5.5.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.1.3.1" xref="S2.E1.m1.5.5.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E1.m1.5.5.1.1.1.1.1.3a" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml">â¡</mo><mi id="S2.E1.m1.5.5.1.1.1.1.1.3.2" xref="S2.E1.m1.5.5.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.2.cmml">q</mi><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">t</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">d</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mrow id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><eq id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"></eq><apply id="S2.E1.m1.5.5.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2">ğ‘</ci><ci id="S2.E1.m1.5.5.1.1.3.3.cmml" xref="S2.E1.m1.5.5.1.1.3.3">ğ‘</ci></apply><apply id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1"><times id="S2.E1.m1.5.5.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.2"></times><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><divide id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1"></divide><cn type="integer" id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3">1</cn><apply id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.3"><abs id="S2.E1.m1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.3.1"></abs><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ğ‘</ci></apply></apply><apply id="S2.E1.m1.5.5.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1"><apply id="S2.E1.m1.5.5.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2">superscript</csymbol><apply id="S2.E1.m1.5.5.1.1.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.5.5.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2.2.2"></sum><apply id="S2.E1.m1.5.5.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3"><eq id="S2.E1.m1.5.5.1.1.1.1.2.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.1"></eq><ci id="S2.E1.m1.5.5.1.1.1.1.2.2.3.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S2.E1.m1.5.5.1.1.1.1.2.2.3.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.3"><abs id="S2.E1.m1.2.2.1.2.1.cmml" xref="S2.E1.m1.2.2.1.3.1"></abs><ci id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1.1">ğ‘</ci></apply></apply><apply id="S2.E1.m1.5.5.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1"><times id="S2.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2"></times><apply id="S2.E1.m1.5.5.1.1.1.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.3"><log id="S2.E1.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.3.1"></log><ci id="S2.E1.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.3.2">ğ‘</ci></apply><apply id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply><list id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1"><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ‘¡</ci><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ğ‘‘</ci><apply id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><apply id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3"><lt id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">p_{q}=\frac{1}{|q|}\sum_{i=1}^{|q|}\log p(q_{i}|t,d,q_{&lt;i}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p3.10" class="ltx_p">where <math id="S2.SS1.p3.5.m1.3" class="ltx_Math" alttext="p(q_{i}|t,d,q_{&lt;i})" display="inline"><semantics id="S2.SS1.p3.5.m1.3a"><mrow id="S2.SS1.p3.5.m1.3.3" xref="S2.SS1.p3.5.m1.3.3.cmml"><mi id="S2.SS1.p3.5.m1.3.3.3" xref="S2.SS1.p3.5.m1.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.5.m1.3.3.2" xref="S2.SS1.p3.5.m1.3.3.2.cmml">â€‹</mo><mrow id="S2.SS1.p3.5.m1.3.3.1.1" xref="S2.SS1.p3.5.m1.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.5.m1.3.3.1.1.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.5.m1.3.3.1.1.1" xref="S2.SS1.p3.5.m1.3.3.1.1.1.cmml"><msub id="S2.SS1.p3.5.m1.3.3.1.1.1.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3.cmml"><mi id="S2.SS1.p3.5.m1.3.3.1.1.1.3.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3.2.cmml">q</mi><mi id="S2.SS1.p3.5.m1.3.3.1.1.1.3.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="S2.SS1.p3.5.m1.3.3.1.1.1.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.2.cmml">|</mo><mrow id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.SS1.p3.5.m1.1.1" xref="S2.SS1.p3.5.m1.1.1.cmml">t</mi><mo id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.2.cmml">,</mo><mi id="S2.SS1.p3.5.m1.2.2" xref="S2.SS1.p3.5.m1.2.2.cmml">d</mi><mo id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.2.cmml">,</mo><msub id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.2.cmml">q</mi><mrow id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.2" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.1" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.SS1.p3.5.m1.3.3.1.1.3" xref="S2.SS1.p3.5.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m1.3b"><apply id="S2.SS1.p3.5.m1.3.3.cmml" xref="S2.SS1.p3.5.m1.3.3"><times id="S2.SS1.p3.5.m1.3.3.2.cmml" xref="S2.SS1.p3.5.m1.3.3.2"></times><ci id="S2.SS1.p3.5.m1.3.3.3.cmml" xref="S2.SS1.p3.5.m1.3.3.3">ğ‘</ci><apply id="S2.SS1.p3.5.m1.3.3.1.1.1.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1"><csymbol cd="latexml" id="S2.SS1.p3.5.m1.3.3.1.1.1.2.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.2">conditional</csymbol><apply id="S2.SS1.p3.5.m1.3.3.1.1.1.3.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m1.3.3.1.1.1.3.1.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p3.5.m1.3.3.1.1.1.3.2.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3.2">ğ‘</ci><ci id="S2.SS1.p3.5.m1.3.3.1.1.1.3.3.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.3.3">ğ‘–</ci></apply><list id="S2.SS1.p3.5.m1.3.3.1.1.1.1.2.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1"><ci id="S2.SS1.p3.5.m1.1.1.cmml" xref="S2.SS1.p3.5.m1.1.1">ğ‘¡</ci><ci id="S2.SS1.p3.5.m1.2.2.cmml" xref="S2.SS1.p3.5.m1.2.2">ğ‘‘</ci><apply id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.2">ğ‘</ci><apply id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3"><lt id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p3.5.m1.3.3.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m1.3c">p(q_{i}|t,d,q_{&lt;i})</annotation></semantics></math> is the probability assigned by <math id="S2.SS1.p3.6.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.SS1.p3.6.m2.1a"><mi id="S2.SS1.p3.6.m2.1.1" xref="S2.SS1.p3.6.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m2.1b"><ci id="S2.SS1.p3.6.m2.1.1.cmml" xref="S2.SS1.p3.6.m2.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m2.1c">G</annotation></semantics></math> when autoregressively generating the <math id="S2.SS1.p3.7.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p3.7.m3.1a"><mi id="S2.SS1.p3.7.m3.1.1" xref="S2.SS1.p3.7.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m3.1b"><ci id="S2.SS1.p3.7.m3.1.1.cmml" xref="S2.SS1.p3.7.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m3.1c">i</annotation></semantics></math>-th token of <math id="S2.SS1.p3.8.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS1.p3.8.m4.1a"><mi id="S2.SS1.p3.8.m4.1.1" xref="S2.SS1.p3.8.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m4.1b"><ci id="S2.SS1.p3.8.m4.1.1.cmml" xref="S2.SS1.p3.8.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m4.1c">q</annotation></semantics></math>, and <math id="S2.SS1.p3.9.m5.1" class="ltx_Math" alttext="q_{&lt;i}" display="inline"><semantics id="S2.SS1.p3.9.m5.1a"><msub id="S2.SS1.p3.9.m5.1.1" xref="S2.SS1.p3.9.m5.1.1.cmml"><mi id="S2.SS1.p3.9.m5.1.1.2" xref="S2.SS1.p3.9.m5.1.1.2.cmml">q</mi><mrow id="S2.SS1.p3.9.m5.1.1.3" xref="S2.SS1.p3.9.m5.1.1.3.cmml"><mi id="S2.SS1.p3.9.m5.1.1.3.2" xref="S2.SS1.p3.9.m5.1.1.3.2.cmml"></mi><mo id="S2.SS1.p3.9.m5.1.1.3.1" xref="S2.SS1.p3.9.m5.1.1.3.1.cmml">&lt;</mo><mi id="S2.SS1.p3.9.m5.1.1.3.3" xref="S2.SS1.p3.9.m5.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m5.1b"><apply id="S2.SS1.p3.9.m5.1.1.cmml" xref="S2.SS1.p3.9.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m5.1.1.1.cmml" xref="S2.SS1.p3.9.m5.1.1">subscript</csymbol><ci id="S2.SS1.p3.9.m5.1.1.2.cmml" xref="S2.SS1.p3.9.m5.1.1.2">ğ‘</ci><apply id="S2.SS1.p3.9.m5.1.1.3.cmml" xref="S2.SS1.p3.9.m5.1.1.3"><lt id="S2.SS1.p3.9.m5.1.1.3.1.cmml" xref="S2.SS1.p3.9.m5.1.1.3.1"></lt><csymbol cd="latexml" id="S2.SS1.p3.9.m5.1.1.3.2.cmml" xref="S2.SS1.p3.9.m5.1.1.3.2">absent</csymbol><ci id="S2.SS1.p3.9.m5.1.1.3.3.cmml" xref="S2.SS1.p3.9.m5.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m5.1c">q_{&lt;i}</annotation></semantics></math> are the tokens generated in the previous decoding steps.
This score is used to filter the top <math id="S2.SS1.p3.10.m6.2" class="ltx_Math" alttext="K=10,000" display="inline"><semantics id="S2.SS1.p3.10.m6.2a"><mrow id="S2.SS1.p3.10.m6.2.3" xref="S2.SS1.p3.10.m6.2.3.cmml"><mi id="S2.SS1.p3.10.m6.2.3.2" xref="S2.SS1.p3.10.m6.2.3.2.cmml">K</mi><mo id="S2.SS1.p3.10.m6.2.3.1" xref="S2.SS1.p3.10.m6.2.3.1.cmml">=</mo><mrow id="S2.SS1.p3.10.m6.2.3.3.2" xref="S2.SS1.p3.10.m6.2.3.3.1.cmml"><mn id="S2.SS1.p3.10.m6.1.1" xref="S2.SS1.p3.10.m6.1.1.cmml">10</mn><mo id="S2.SS1.p3.10.m6.2.3.3.2.1" xref="S2.SS1.p3.10.m6.2.3.3.1.cmml">,</mo><mn id="S2.SS1.p3.10.m6.2.2" xref="S2.SS1.p3.10.m6.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.10.m6.2b"><apply id="S2.SS1.p3.10.m6.2.3.cmml" xref="S2.SS1.p3.10.m6.2.3"><eq id="S2.SS1.p3.10.m6.2.3.1.cmml" xref="S2.SS1.p3.10.m6.2.3.1"></eq><ci id="S2.SS1.p3.10.m6.2.3.2.cmml" xref="S2.SS1.p3.10.m6.2.3.2">ğ¾</ci><list id="S2.SS1.p3.10.m6.2.3.3.1.cmml" xref="S2.SS1.p3.10.m6.2.3.3.2"><cn type="integer" id="S2.SS1.p3.10.m6.1.1.cmml" xref="S2.SS1.p3.10.m6.1.1">10</cn><cn type="integer" id="S2.SS1.p3.10.m6.2.2.cmml" xref="S2.SS1.p3.10.m6.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.10.m6.2c">K=10,000</annotation></semantics></math> pairs of document and synthetic queries to be used as finetuning data.
This filtering improves the quality of the training data. Without it, i.e., using the full set of 100K synthetic queries to finetune a reranker model resulted in a drop of 4 MMR@10 points on MS MARCO.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">The filtering approach was improved on InPars-v2, where a pretrained reranker model is used to filter the synthetic queries for the training step. A monoT5-3B reranker model finetuned for one epoch on the MS MARCO dataset is used to estimate a relevance score for each synthetic query generated by the LLM and the document that was used to generate it. After computing the score for each one of the 100,000 pairs of synthetic queries and documents, only the <math id="S2.SS1.p4.1.m1.2" class="ltx_Math" alttext="K=10,000" display="inline"><semantics id="S2.SS1.p4.1.m1.2a"><mrow id="S2.SS1.p4.1.m1.2.3" xref="S2.SS1.p4.1.m1.2.3.cmml"><mi id="S2.SS1.p4.1.m1.2.3.2" xref="S2.SS1.p4.1.m1.2.3.2.cmml">K</mi><mo id="S2.SS1.p4.1.m1.2.3.1" xref="S2.SS1.p4.1.m1.2.3.1.cmml">=</mo><mrow id="S2.SS1.p4.1.m1.2.3.3.2" xref="S2.SS1.p4.1.m1.2.3.3.1.cmml"><mn id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml">10</mn><mo id="S2.SS1.p4.1.m1.2.3.3.2.1" xref="S2.SS1.p4.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.SS1.p4.1.m1.2.2" xref="S2.SS1.p4.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.2b"><apply id="S2.SS1.p4.1.m1.2.3.cmml" xref="S2.SS1.p4.1.m1.2.3"><eq id="S2.SS1.p4.1.m1.2.3.1.cmml" xref="S2.SS1.p4.1.m1.2.3.1"></eq><ci id="S2.SS1.p4.1.m1.2.3.2.cmml" xref="S2.SS1.p4.1.m1.2.3.2">ğ¾</ci><list id="S2.SS1.p4.1.m1.2.3.3.1.cmml" xref="S2.SS1.p4.1.m1.2.3.3.2"><cn type="integer" id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">10</cn><cn type="integer" id="S2.SS1.p4.1.m1.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.2c">K=10,000</annotation></semantics></math> highest scores are kept as finetuning data.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">These filtered queries are used to train a monoT5Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">nogueira2020document, </a>)</cite> reranker, an adapted version of T5Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib13" title="" class="ltx_ref">DBLP:journals/corr/abs-1910-10683, </a>)</cite> model for text ranking tasks. The filtered queries are used as positive examples, while negative examples are mined from BM25 candidates. Two models with 220M and 3B parameters were trained for one epoch over the 20,000 query-document pairs. The trained model is subsequently used to rerank the initial BM25 retrievals. This approach employs a two-stage retrieval pipeline. Firstly, BM25 retrieves the top 1,000 documents per query. Secondly, the trained model reranks the list by assigning a relevance score for each pair of query and document.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Promptagator</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The Promptagator method also creates synthetic training data for IR tasks by exploiting the few-shot abilities of a 137B-parameter LLM. Differently from InPars, a specific prompt is created for each dataset using in-domain examples.
By creating a specific prompt template for each dataset, the prefixes used were selected according to the dataset description. Using the ArguAna dataset prompt as an example, the model is prompted with a prefix â€œ<span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">Argument:</span>â€ which indicates the document from the dataset, followed by a prefix â€œ<span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">Counter Argument:</span>â€, marking the question related to the document. This way, the prefixes resemble a better description of the datasets while instructing the LLM to generate a query for that specific task and document. Moreover, in the few-shot scenario, they use from 2 to 8 relevant query-document examples to create the prompt, sampled from the development set when it is available or, if not, from the test set.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Promptagator generates synthetic queries using a sampling decoding algorithm with a temperature of 0.7. For each dataset, they generate 8 synthetic queries for each document from a randomly sampled set of 1 million documents. FLANÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib19" title="" class="ltx_ref">wei2022finetuned, </a>)</cite> is used as the generator, which is a proprietary LLM that was pretrained on a multiple tasks using instructions.
To ensure that only high-quality synthetic questions are generated, the authors propose a filtering step based on consistency filtering. They train a retriever model using the same synthetic data that needs to be filtered to predict the most relevant passage for a given query. The retriever model keeps only queries that, when fed to the model, return the document that originated it among its top K results. The authors observed that setting K to 1 leads to better results when using the MS MARCO dataset as a validation set.
The authors suggest that this filtering strategy removes low-quality synthetic questions and improves performance on 8 out of the 11 datasets that were evaluated.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">In the final step, the Promptagator method finetunes two different models using the synthetic data. The first is a bi-encoder based on the GTRÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">DBLP:journals/corr/abs-2112-07899, </a>)</cite> architecture with 110M parameters. The second is a cross-encoder with the same number of parameters, which reranks the top 200 candidates retrieved by the bi-encoder model.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Experimental Setup</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the process of using the toolkit provided in this work. Firstly, we outline the steps for generating synthetic data. Next, we discuss the process of filtering the generated data to remove possibly irrelevant instances. Then, we describe how to build the training set using the filtered positive examples and mining the negatives. After that, we provide details on how to use the synthetic data to train a reranker. Finally, we describe the process of reranking and evaluating the trained model. By following the guidelines in this section, researchers and practitioners are able to leverage the provided resources effectively and reproduce the InPars method, as well as partially reproduce the Promptagator method and extend to new pipelines.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Commands</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To begin, the synthetic data generation step is done using the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">inpars.generate</span> command-line as follows:</p>
<div id="S3.SS1.p1.2" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMuZ2VuZXJhdGUgXAogICAgICAgIC0tcHJvbXB0PSJpbnBhcnMiIFwKICAgICAgICAtLWRhdGFzZXQ9InRyZWMtY292aWQiIFwKICAgICAgICAtLWRhdGFzZXRfc291cmNlPSJpcl9kYXRhc2V0cyIgXAogICAgICAgIC0tYmFzZV9tb2RlbD0iRWxldXRoZXJBSS9ncHQtai02QiIgXAogICAgICAgIC0tb3V0cHV0PSJ0cmVjLWNvdmlkLXF1ZXJpZXMuanNvbmwi" download="">â¬‡</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx1.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx1.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx1.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx1.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx1.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx1.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx1.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx1.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx1.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx1.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">generate</span><span id="lstnumberx1.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx1.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx2.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx2.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">prompt</span><span id="lstnumberx2.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx2.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"inpars"</span><span id="lstnumberx2.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx2.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx3.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset</span><span id="lstnumberx3.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx3.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid"</span><span id="lstnumberx3.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx3.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx4.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset_source</span><span id="lstnumberx4.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"ir_datasets"</span><span id="lstnumberx4.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx4.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx5.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">base_model</span><span id="lstnumberx5.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"EleutherAI/gpt-j-6B"</span><span id="lstnumberx5.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx5.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx6.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx6.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">output</span><span id="lstnumberx6.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx6.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-queries.jsonl"</span>
</div>
</div>
<p id="S3.SS1.p1.3" class="ltx_p">Diving into the required arguments, thwe first need to define the <span id="S3.SS1.p1.3.1" class="ltx_text ltx_font_typewriter">prompt</span>, which supports four different options for the prompt template to be selected: <span id="S3.SS1.p1.3.2" class="ltx_text ltx_font_typewriter">inpars</span>, <span id="S3.SS1.p1.3.3" class="ltx_text ltx_font_typewriter">inpars-gbq</span>, <span id="S3.SS1.p1.3.4" class="ltx_text ltx_font_typewriter">promptagator</span> and <span id="S3.SS1.p1.3.5" class="ltx_text ltx_font_typewriter">custom</span>. This argument will define which prompt template to be used during the generation step. We provide both â€œVanillaâ€ and â€œGBQâ€ prompts templates used by InPars, with â€œVanillaâ€ as a default.
The <span id="S3.SS1.p1.3.6" class="ltx_text ltx_font_typewriter">promptagator</span> prompt template uses a specific template for each dataset and dynamically selects random pairs of query and relevant document to be used as prompt examples. The <span id="S3.SS1.p1.3.7" class="ltx_text ltx_font_typewriter">n_fewshot_examples</span> argument specifies the number of examples that will be used in the prompt in this case â€“ with a default of 3 examples.
We randomly select labeled examples from the training set of each dataset when training data is available. If there is no training set, we use the development set as our source and, as a last resort, when there is no training or development set, we use the test set for creating the prompt examples. This approach is slight different from the one proposed by Promptagator, that collects examples only from the development or test set. Once the examples are collected, for each document that requires a synthetic question, the prompt is built dynamically. This means that the prompt examples are randomly ordered for each document. To ensure a fair evaluation, the queries and documents used as few-shot examples that were extracted from the development or test sets are discarded from the evaluation metrics.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The next arguments are the <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">dataset</span> and <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">dataset_source</span>, which specify dataset to generate synthetic queries for and the source from which to load it. In line with InPars and Promptagator, we support the datasets from the BEIRÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib16" title="" class="ltx_ref">thakur2021beir, </a>)</cite> benchmark. BEIR is a widely used evaluation framework in the IR domain. It aims to provide a comprehensive evaluation benchmark on a variety of IR tasks, with a particular emphasis on zero-shot evaluation.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">The <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">dataset_source</span> argument is designed to integrate with two widely used dataset interfaces in the IR community: PyseriniÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">Lin_etal_SIGIR2021_Pyserini, </a>)</cite>, a toolkit for conducting reproducible IR research with sparse and dense representations, and <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">ir_datasets</span>Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib8" title="" class="ltx_ref">macavaney:sigir2021-irds, </a>)</cite>, a commonplace for several IR <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">ad-hoc</span> ranking benchmarks. Furthermore, it is also possible to indicate a local file as the document and query collection. By default, we use the <span id="S3.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">ir_datasets</span> as the source, but both sources include all publicly available BEIR datasets.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">The <span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_typewriter">base_model</span> argument determines the LLM that will be used to generate the synthetic queries. By default, our toolkit uses the GPT-JÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib17" title="" class="ltx_ref">mesh-transformer-jax, </a>)</cite> model available in the Hugging Face HubÂ <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/EleutherAI/gpt-j-6B" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/EleutherAI/gpt-j-6B</a></span></span></span>, but it can support any generative model available from Hugging Face. Lastly, the <span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_typewriter">output</span> argument specifies the name of an output file to save the synthetic data. The output file will be a JSON format file, which will contain one query per line. This file will also include additional information related to the synthetic generation step, such as the log probabilities assigned to each token by the LLM during query generation, the prompt text fed to the LLM, and the document for which the query was generated.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Additional arguments related to the LLM, such as the maximum length of input and output or batch size, can also be set through the command-line arguments.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Once the synthetic data has been generated, we move on to the filtering stage. We provide two different filtering strategies, and the command to filter the synthetic queries is:</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<div id="S3.SS1.p7.1" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMuZmlsdGVyIFwKICAgICAgICAtLWlucHV0PSJ0cmVjLWNvdmlkLXF1ZXJpZXMuanNvbmwiIFwKICAgICAgICAtLWRhdGFzZXQ9InRyZWMtY292aWQiIFwKICAgICAgICAtLWZpbHRlcl9zdHJhdGVneT0ic2NvcmVzIiBcCiAgICAgICAgLS1rZWVwX3RvcF9rPSIxMF8wMDAiIFwKICAgICAgICAtLW91dHB1dD0idHJlYy1jb3ZpZC1xdWVyaWVzLWZpbHRlcmVkLmpzb25sIg==" download="">â¬‡</a></div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx7.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx7.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx7.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx7.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx7.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx7.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx7.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx7.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx7.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx7.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">filter</span><span id="lstnumberx7.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx7.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx8.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx8.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">input</span><span id="lstnumberx8.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx8.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-queries.jsonl"</span><span id="lstnumberx8.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx8.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx9.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx9.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset</span><span id="lstnumberx9.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx9.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid"</span><span id="lstnumberx9.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx9.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx10.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">filter_strategy</span><span id="lstnumberx10.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx10.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"scores"</span><span id="lstnumberx10.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx10.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx11.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">keep_top_k</span><span id="lstnumberx11.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx11.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"10_000"</span><span id="lstnumberx11.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx11.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx12.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">output</span><span id="lstnumberx12.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx12.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-queries-filtered.jsonl"</span>
</div>
</div>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.1" class="ltx_p">Initially, before applying the filtering strategy, we keep only synthetic queries that meet some conditions. These conditions require the token count to fall within a specified range of minimum and maximum amount, defined by the arguments <span id="S3.SS1.p8.1.1" class="ltx_text ltx_font_typewriter">min_tokens</span> and <span id="S3.SS1.p8.1.2" class="ltx_text ltx_font_typewriter">max_tokens</span>. This is done to remove possible noisy synthetic queries. The <span id="S3.SS1.p8.1.3" class="ltx_text ltx_font_typewriter">skip_questions_copied_from_context</span> optional argument removes synthetic queries in which a part of the document used for generation was copied to the query.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para">
<p id="S3.SS1.p9.1" class="ltx_p">The first argument required by the filtering command-line is the <span id="S3.SS1.p9.1.1" class="ltx_text ltx_font_typewriter">input</span>, which refers to the file containing the synthetic queries generated in the previous step to be filtered. The <span id="S3.SS1.p9.1.2" class="ltx_text ltx_font_typewriter">dataset</span> argument indicates which dataset the queries belong to. The <span id="S3.SS1.p9.1.3" class="ltx_text ltx_font_typewriter">filter_strategy</span> specifies the filtering strategy to be used. The default filtering strategy, introduced by InPars-v1, is called <span id="S3.SS1.p9.1.4" class="ltx_text ltx_font_typewriter">scores</span> and is based on a mean value computed from LLMâ€™s tokens probabilities. The synthetic queries list is then sorted in descending order, and only the top-K values are retained. The <span id="S3.SS1.p9.1.5" class="ltx_text ltx_font_typewriter">keep_top_k</span> argument defines the value of <math id="S3.SS1.p9.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p9.1.m1.1a"><mi id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><ci id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">k</annotation></semantics></math>, with a default value of 10,000.</p>
</div>
<div id="S3.SS1.p10" class="ltx_para">
<p id="S3.SS1.p10.1" class="ltx_p">The second filtering strategy, which was introduced by InPars-v2, is called reranker. This strategy employs a pretrained reranker model to filter the synthetic queries by computing a relevancy score for each synthetic query-document pair. The scores list is sorted in descending order and only the top-k pairs with the highest scores are kept as positives query-document pairs to be used during training. Finally, the output file must be specified in <span id="S3.SS1.p10.1.1" class="ltx_text ltx_font_typewriter">output</span> to indicate where the filtered synthetic queries will be saved.</p>
</div>
<div id="S3.SS1.p11" class="ltx_para">
<p id="S3.SS1.p11.1" class="ltx_p">The filtering strategy proposed by Promptagator is not currently supported because its more elaborated and seem to require more computational resources: A bi-encoder is initially finetuned on 1 million synthetic examples and then used in the filtering step by retaining only the examples that correctly retrieve the source document. This is a costly procedure that has been postponed for future work.</p>
</div>
<div id="S3.SS1.p12" class="ltx_para">
<p id="S3.SS1.p12.5" class="ltx_p">The third stage of the pipeline involves mining negative examples for model training. In this stage, negative examples are mined by using the filtered synthetic queries to search for candidate documents. We followed the approach outlined in InPars, using BM25 to retrieve 1,000 candidate documents from the target collection. From this set, a random document is selected as the negative example. If the candidate document is the same one used during the synthetic generation step, the example is discarded, and a new one is sampled. The following command-line is used to execute this step:</p>
<div id="S3.SS1.p12.6" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMuZ2VuZXJhdGVfdHJpcGxlcyBcCiAgICAgICAgLS1pbnB1dD0idHJlYy1jb3ZpZC1xdWVyaWVzLWZpbHRlcmVkLmpzb25sIiBcCiAgICAgICAgLS1kYXRhc2V0PSJ0cmVjLWNvdmlkIiBcCiAgICAgICAgLS1vdXRwdXQ9InRyZWMtY292aWQtdHJpcGxlcy50c3Yi" download="">â¬‡</a></div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx13.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx13.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx13.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx13.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx13.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx13.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx13.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx13.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">generate_triples</span><span id="lstnumberx13.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx13.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx14.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx14.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">input</span><span id="lstnumberx14.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx14.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-queries-filtered.jsonl"</span><span id="lstnumberx14.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx14.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx15.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx15.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset</span><span id="lstnumberx15.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx15.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid"</span><span id="lstnumberx15.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx15.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx16.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx16.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">output</span><span id="lstnumberx16.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx16.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-triples.tsv"</span>
</div>
</div>
<p id="S3.SS1.p12.4" class="ltx_p">The <span id="S3.SS1.p12.4.1" class="ltx_text ltx_font_typewriter">input</span> argument expects a file containing the previously filtered synthetic queries, as well as the <span id="S3.SS1.p12.4.2" class="ltx_text ltx_font_typewriter">dataset</span> identification. The result is a tuple <math id="S3.SS1.p12.1.m1.3" class="ltx_Math" alttext="(q,d^{+},d^{-})" display="inline"><semantics id="S3.SS1.p12.1.m1.3a"><mrow id="S3.SS1.p12.1.m1.3.3.2" xref="S3.SS1.p12.1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS1.p12.1.m1.3.3.2.3" xref="S3.SS1.p12.1.m1.3.3.3.cmml">(</mo><mi id="S3.SS1.p12.1.m1.1.1" xref="S3.SS1.p12.1.m1.1.1.cmml">q</mi><mo id="S3.SS1.p12.1.m1.3.3.2.4" xref="S3.SS1.p12.1.m1.3.3.3.cmml">,</mo><msup id="S3.SS1.p12.1.m1.2.2.1.1" xref="S3.SS1.p12.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p12.1.m1.2.2.1.1.2" xref="S3.SS1.p12.1.m1.2.2.1.1.2.cmml">d</mi><mo id="S3.SS1.p12.1.m1.2.2.1.1.3" xref="S3.SS1.p12.1.m1.2.2.1.1.3.cmml">+</mo></msup><mo id="S3.SS1.p12.1.m1.3.3.2.5" xref="S3.SS1.p12.1.m1.3.3.3.cmml">,</mo><msup id="S3.SS1.p12.1.m1.3.3.2.2" xref="S3.SS1.p12.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p12.1.m1.3.3.2.2.2" xref="S3.SS1.p12.1.m1.3.3.2.2.2.cmml">d</mi><mo id="S3.SS1.p12.1.m1.3.3.2.2.3" xref="S3.SS1.p12.1.m1.3.3.2.2.3.cmml">âˆ’</mo></msup><mo stretchy="false" id="S3.SS1.p12.1.m1.3.3.2.6" xref="S3.SS1.p12.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p12.1.m1.3b"><vector id="S3.SS1.p12.1.m1.3.3.3.cmml" xref="S3.SS1.p12.1.m1.3.3.2"><ci id="S3.SS1.p12.1.m1.1.1.cmml" xref="S3.SS1.p12.1.m1.1.1">ğ‘</ci><apply id="S3.SS1.p12.1.m1.2.2.1.1.cmml" xref="S3.SS1.p12.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p12.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p12.1.m1.2.2.1.1">superscript</csymbol><ci id="S3.SS1.p12.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p12.1.m1.2.2.1.1.2">ğ‘‘</ci><plus id="S3.SS1.p12.1.m1.2.2.1.1.3.cmml" xref="S3.SS1.p12.1.m1.2.2.1.1.3"></plus></apply><apply id="S3.SS1.p12.1.m1.3.3.2.2.cmml" xref="S3.SS1.p12.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p12.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p12.1.m1.3.3.2.2">superscript</csymbol><ci id="S3.SS1.p12.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p12.1.m1.3.3.2.2.2">ğ‘‘</ci><minus id="S3.SS1.p12.1.m1.3.3.2.2.3.cmml" xref="S3.SS1.p12.1.m1.3.3.2.2.3"></minus></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p12.1.m1.3c">(q,d^{+},d^{-})</annotation></semantics></math>, where <math id="S3.SS1.p12.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p12.2.m2.1a"><mi id="S3.SS1.p12.2.m2.1.1" xref="S3.SS1.p12.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p12.2.m2.1b"><ci id="S3.SS1.p12.2.m2.1.1.cmml" xref="S3.SS1.p12.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p12.2.m2.1c">q</annotation></semantics></math> and <math id="S3.SS1.p12.3.m3.1" class="ltx_Math" alttext="d^{+}" display="inline"><semantics id="S3.SS1.p12.3.m3.1a"><msup id="S3.SS1.p12.3.m3.1.1" xref="S3.SS1.p12.3.m3.1.1.cmml"><mi id="S3.SS1.p12.3.m3.1.1.2" xref="S3.SS1.p12.3.m3.1.1.2.cmml">d</mi><mo id="S3.SS1.p12.3.m3.1.1.3" xref="S3.SS1.p12.3.m3.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p12.3.m3.1b"><apply id="S3.SS1.p12.3.m3.1.1.cmml" xref="S3.SS1.p12.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p12.3.m3.1.1.1.cmml" xref="S3.SS1.p12.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p12.3.m3.1.1.2.cmml" xref="S3.SS1.p12.3.m3.1.1.2">ğ‘‘</ci><plus id="S3.SS1.p12.3.m3.1.1.3.cmml" xref="S3.SS1.p12.3.m3.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p12.3.m3.1c">d^{+}</annotation></semantics></math> are fixed (the synthetic query and the source document) and <math id="S3.SS1.p12.4.m4.1" class="ltx_Math" alttext="d^{-}" display="inline"><semantics id="S3.SS1.p12.4.m4.1a"><msup id="S3.SS1.p12.4.m4.1.1" xref="S3.SS1.p12.4.m4.1.1.cmml"><mi id="S3.SS1.p12.4.m4.1.1.2" xref="S3.SS1.p12.4.m4.1.1.2.cmml">d</mi><mo id="S3.SS1.p12.4.m4.1.1.3" xref="S3.SS1.p12.4.m4.1.1.3.cmml">âˆ’</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p12.4.m4.1b"><apply id="S3.SS1.p12.4.m4.1.1.cmml" xref="S3.SS1.p12.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p12.4.m4.1.1.1.cmml" xref="S3.SS1.p12.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p12.4.m4.1.1.2.cmml" xref="S3.SS1.p12.4.m4.1.1.2">ğ‘‘</ci><minus id="S3.SS1.p12.4.m4.1.1.3.cmml" xref="S3.SS1.p12.4.m4.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p12.4.m4.1c">d^{-}</annotation></semantics></math> represents the negative example sampled from BM25 candidates. The document collection is indexed using Pyserini, and all BEIR benchmark datasets are already available as pre-built indexes.</p>
</div>
<div id="S3.SS1.p13" class="ltx_para">
<p id="S3.SS1.p13.1" class="ltx_p">Once the synthetic training data is obtained, we proceed to the training step. We support the finetuning of a monoT5 reranker model, which is the same model used in InPars, as the final stage of the multi-stage retrieval pipeline. To finetune the reranker using the synthetic data, the command-line is:</p>
<div id="S3.SS1.p13.2" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMudHJhaW4gXAogICAgICAgIC0tdHJpcGxlcz0idHJlYy1jb3ZpZC10cmlwbGVzLnRzdiIgXAogICAgICAgIC0tYmFzZV9tb2RlbD0iY2FzdG9yaW5pL21vbm90NS0zYi1tc21hcmNvLTEwayIgXAogICAgICAgIC0tb3V0cHV0X2Rpcj0iLi9yZXJhbmtlci8iIFwKICAgICAgICAtLW1heF9zdGVwcz0iMTU2Ig==" download="">â¬‡</a></div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx17.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx17.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx17.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx17.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx17.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx17.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx17.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx17.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx17.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">train</span><span id="lstnumberx17.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx17.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx18.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">triples</span><span id="lstnumberx18.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx18.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-triples.tsv"</span><span id="lstnumberx18.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx18.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx19.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">base_model</span><span id="lstnumberx19.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx19.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"castorini/monot5-3b-msmarco-10k"</span><span id="lstnumberx19.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx19.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx20.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx20.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">output_dir</span><span id="lstnumberx20.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx20.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"./reranker/"</span><span id="lstnumberx20.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx20.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx21.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx21.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">max_steps</span><span id="lstnumberx21.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx21.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"156"</span>
</div>
</div>
<p id="S3.SS1.p13.3" class="ltx_p">The <span id="S3.SS1.p13.3.1" class="ltx_text ltx_font_typewriter">triples</span> argument specifies the file containing the training tuples obtained in the previous step, where every line consists of a triple comprising a query, a positive document, and a negative document. The <span id="S3.SS1.p13.3.2" class="ltx_text ltx_font_typewriter">base_model</span> argument indicates the model to be finetuned â€“ e.g., an original T5 model or a pre-trained monoT5. In all our experiments, we used the <span id="S3.SS1.p13.3.3" class="ltx_text ltx_font_typewriter">castorini/monot5-3b-msmarco-10k</span>Â <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/castorini/monot5-3b-msmarco-10k" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/castorini/monot5-3b-msmarco-10k</a></span></span></span> as our initial base model. The <span id="S3.SS1.p13.3.4" class="ltx_text ltx_font_typewriter">output</span> argument specifies the path where the finetuned model should be saved. Our reranker models were trained for 156 steps, equivalent to one epoch over the query-relevant document pairs. In contrast to the InPars script that relies on TPUs, our training script supports GPUs. We conducted all experiments using a NVIDIA A100 80 GB GPU, and training the model for 156 steps took approximately 30 minutes.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.2.3.1" class="ltx_tr">
<th id="S3.T1.2.3.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt"></th>
<th id="S3.T1.2.3.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt"></th>
<th id="S3.T1.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">covid</th>
<th id="S3.T1.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">nfc</th>
<th id="S3.T1.2.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">hotpot</th>
<th id="S3.T1.2.3.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">fiqa</th>
<th id="S3.T1.2.3.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">arg</th>
<th id="S3.T1.2.3.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">touchÃ©</th>
<th id="S3.T1.2.3.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">dbp</th>
<th id="S3.T1.2.3.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">scidocs</th>
<th id="S3.T1.2.3.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">fever</th>
<th id="S3.T1.2.3.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">climate</th>
<th id="S3.T1.2.3.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">scifact</th>
<th id="S3.T1.2.3.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AVG</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.4.1" class="ltx_tr">
<th id="S3.T1.2.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">(1a)</th>
<th id="S3.T1.2.4.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">BM25-flat</th>
<td id="S3.T1.2.4.1.3" class="ltx_td ltx_align_center ltx_border_tt">0.594</td>
<td id="S3.T1.2.4.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.321</td>
<td id="S3.T1.2.4.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.633</td>
<td id="S3.T1.2.4.1.6" class="ltx_td ltx_align_center ltx_border_tt">0.236</td>
<td id="S3.T1.2.4.1.7" class="ltx_td ltx_align_center ltx_border_tt">0.397</td>
<td id="S3.T1.2.4.1.8" class="ltx_td ltx_align_center ltx_border_tt">0.442</td>
<td id="S3.T1.2.4.1.9" class="ltx_td ltx_align_center ltx_border_tt">0.318</td>
<td id="S3.T1.2.4.1.10" class="ltx_td ltx_align_center ltx_border_tt">0.149</td>
<td id="S3.T1.2.4.1.11" class="ltx_td ltx_align_center ltx_border_tt">0.651</td>
<td id="S3.T1.2.4.1.12" class="ltx_td ltx_align_center ltx_border_tt">0.165</td>
<td id="S3.T1.2.4.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.678</td>
<td id="S3.T1.2.4.1.14" class="ltx_td ltx_align_center ltx_border_tt">0.416</td>
</tr>
<tr id="S3.T1.2.5.2" class="ltx_tr">
<th id="S3.T1.2.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">(1b)</th>
<th id="S3.T1.2.5.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">BM25-multi</th>
<td id="S3.T1.2.5.2.3" class="ltx_td ltx_align_center">0.656</td>
<td id="S3.T1.2.5.2.4" class="ltx_td ltx_align_center">0.325</td>
<td id="S3.T1.2.5.2.5" class="ltx_td ltx_align_center">0.603</td>
<td id="S3.T1.2.5.2.6" class="ltx_td ltx_align_center">0.236</td>
<td id="S3.T1.2.5.2.7" class="ltx_td ltx_align_center">0.414</td>
<td id="S3.T1.2.5.2.8" class="ltx_td ltx_align_center">0.367</td>
<td id="S3.T1.2.5.2.9" class="ltx_td ltx_align_center">0.313</td>
<td id="S3.T1.2.5.2.10" class="ltx_td ltx_align_center">0.158</td>
<td id="S3.T1.2.5.2.11" class="ltx_td ltx_align_center">0.753</td>
<td id="S3.T1.2.5.2.12" class="ltx_td ltx_align_center">0.213</td>
<td id="S3.T1.2.5.2.13" class="ltx_td ltx_align_center ltx_border_r">0.665</td>
<td id="S3.T1.2.5.2.14" class="ltx_td ltx_align_center">0.427</td>
</tr>
<tr id="S3.T1.2.6.3" class="ltx_tr">
<th id="S3.T1.2.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">(2)</th>
<th id="S3.T1.2.6.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">monoT5 (3B)Â <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">nogueira2020document, </a>)</cite>
</th>
<td id="S3.T1.2.6.3.3" class="ltx_td ltx_align_center ltx_border_t">0.795</td>
<td id="S3.T1.2.6.3.4" class="ltx_td ltx_align_center ltx_border_t">0.384</td>
<td id="S3.T1.2.6.3.5" class="ltx_td ltx_align_center ltx_border_t">0.759</td>
<td id="S3.T1.2.6.3.6" class="ltx_td ltx_align_center ltx_border_t">0.514</td>
<td id="S3.T1.2.6.3.7" class="ltx_td ltx_align_center ltx_border_t">0.288</td>
<td id="S3.T1.2.6.3.8" class="ltx_td ltx_align_center ltx_border_t">0.200</td>
<td id="S3.T1.2.6.3.9" class="ltx_td ltx_align_center ltx_border_t">0.478</td>
<td id="S3.T1.2.6.3.10" class="ltx_td ltx_align_center ltx_border_t">0.197</td>
<td id="S3.T1.2.6.3.11" class="ltx_td ltx_align_center ltx_border_t">0.850</td>
<td id="S3.T1.2.6.3.12" class="ltx_td ltx_align_center ltx_border_t">0.280</td>
<td id="S3.T1.2.6.3.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.777</td>
<td id="S3.T1.2.6.3.14" class="ltx_td ltx_align_center ltx_border_t">0.511</td>
</tr>
<tr id="S3.T1.2.7.4" class="ltx_tr">
<th id="S3.T1.2.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">(3a)</th>
<th id="S3.T1.2.7.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">InPars-v1</th>
<td id="S3.T1.2.7.4.3" class="ltx_td ltx_align_center ltx_border_t">0.846</td>
<td id="S3.T1.2.7.4.4" class="ltx_td ltx_align_center ltx_border_t">0.385</td>
<td id="S3.T1.2.7.4.5" class="ltx_td ltx_align_center ltx_border_t">0.790</td>
<td id="S3.T1.2.7.4.6" class="ltx_td ltx_align_center ltx_border_t">0.492</td>
<td id="S3.T1.2.7.4.7" class="ltx_td ltx_align_center ltx_border_t">0.371</td>
<td id="S3.T1.2.7.4.8" class="ltx_td ltx_align_center ltx_border_t">0.260</td>
<td id="S3.T1.2.7.4.9" class="ltx_td ltx_align_center ltx_border_t">0.494</td>
<td id="S3.T1.2.7.4.10" class="ltx_td ltx_align_center ltx_border_t">0.206</td>
<td id="S3.T1.2.7.4.11" class="ltx_td ltx_align_center ltx_border_t">0.852</td>
<td id="S3.T1.2.7.4.12" class="ltx_td ltx_align_center ltx_border_t">0.287</td>
<td id="S3.T1.2.7.4.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.774</td>
<td id="S3.T1.2.7.4.14" class="ltx_td ltx_align_center ltx_border_t">0.523</td>
</tr>
<tr id="S3.T1.2.8.5" class="ltx_tr">
<th id="S3.T1.2.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">(3b)</th>
<th id="S3.T1.2.8.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">InPars-v2</th>
<td id="S3.T1.2.8.5.3" class="ltx_td ltx_align_center">0.846</td>
<td id="S3.T1.2.8.5.4" class="ltx_td ltx_align_center">0.385</td>
<td id="S3.T1.2.8.5.5" class="ltx_td ltx_align_center">0.791</td>
<td id="S3.T1.2.8.5.6" class="ltx_td ltx_align_center">0.509</td>
<td id="S3.T1.2.8.5.7" class="ltx_td ltx_align_center">0.369</td>
<td id="S3.T1.2.8.5.8" class="ltx_td ltx_align_center">0.291</td>
<td id="S3.T1.2.8.5.9" class="ltx_td ltx_align_center">0.498</td>
<td id="S3.T1.2.8.5.10" class="ltx_td ltx_align_center">0.208</td>
<td id="S3.T1.2.8.5.11" class="ltx_td ltx_align_center">0.872</td>
<td id="S3.T1.2.8.5.12" class="ltx_td ltx_align_center">0.323</td>
<td id="S3.T1.2.8.5.13" class="ltx_td ltx_align_center ltx_border_r">0.774</td>
<td id="S3.T1.2.8.5.14" class="ltx_td ltx_align_center">0.533</td>
</tr>
<tr id="S3.T1.2.9.6" class="ltx_tr">
<th id="S3.T1.2.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">(4a)</th>
<th id="S3.T1.2.9.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PromptagatorÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib3" title="" class="ltx_ref">https://doi.org/10.48550/arxiv.2209.11755, </a>)</cite>
</th>
<td id="S3.T1.2.9.6.3" class="ltx_td ltx_align_center ltx_border_t">0.762</td>
<td id="S3.T1.2.9.6.4" class="ltx_td ltx_align_center ltx_border_t">0.370</td>
<td id="S3.T1.2.9.6.5" class="ltx_td ltx_align_center ltx_border_t">0.736</td>
<td id="S3.T1.2.9.6.6" class="ltx_td ltx_align_center ltx_border_t">0.494</td>
<td id="S3.T1.2.9.6.7" class="ltx_td ltx_align_center ltx_border_t">0.630</td>
<td id="S3.T1.2.9.6.8" class="ltx_td ltx_align_center ltx_border_t">0.381</td>
<td id="S3.T1.2.9.6.9" class="ltx_td ltx_align_center ltx_border_t">0.434</td>
<td id="S3.T1.2.9.6.10" class="ltx_td ltx_align_center ltx_border_t">0.201</td>
<td id="S3.T1.2.9.6.11" class="ltx_td ltx_align_center ltx_border_t">0.866</td>
<td id="S3.T1.2.9.6.12" class="ltx_td ltx_align_center ltx_border_t">0.203</td>
<td id="S3.T1.2.9.6.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.731</td>
<td id="S3.T1.2.9.6.14" class="ltx_td ltx_align_center ltx_border_t">0.528</td>
</tr>
<tr id="S3.T1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">(4b)</th>
<th id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">InPars-v1<sup id="S3.T1.1.1.1.1" class="ltx_sup">â€ </sup>
</th>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_center">0.762</td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_center">0.364</td>
<td id="S3.T1.1.1.5" class="ltx_td ltx_align_center">0.606</td>
<td id="S3.T1.1.1.6" class="ltx_td ltx_align_center">0.487</td>
<td id="S3.T1.1.1.7" class="ltx_td ltx_align_center">0.506</td>
<td id="S3.T1.1.1.8" class="ltx_td ltx_align_center">0.262</td>
<td id="S3.T1.1.1.9" class="ltx_td ltx_align_center">0.490</td>
<td id="S3.T1.1.1.10" class="ltx_td ltx_align_center">0.175</td>
<td id="S3.T1.1.1.11" class="ltx_td ltx_align_center">0.858</td>
<td id="S3.T1.1.1.12" class="ltx_td ltx_align_center">0.307</td>
<td id="S3.T1.1.1.13" class="ltx_td ltx_align_center ltx_border_r">0.790</td>
<td id="S3.T1.1.1.14" class="ltx_td ltx_align_center">0.519</td>
</tr>
<tr id="S3.T1.2.2" class="ltx_tr">
<th id="S3.T1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">(4c)</th>
<th id="S3.T1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">InPars-v2<sup id="S3.T1.2.2.1.1" class="ltx_sup">â€ </sup>
</th>
<td id="S3.T1.2.2.3" class="ltx_td ltx_align_center">0.832</td>
<td id="S3.T1.2.2.4" class="ltx_td ltx_align_center">0.357</td>
<td id="S3.T1.2.2.5" class="ltx_td ltx_align_center">0.790</td>
<td id="S3.T1.2.2.6" class="ltx_td ltx_align_center">0.487</td>
<td id="S3.T1.2.2.7" class="ltx_td ltx_align_center">0.529</td>
<td id="S3.T1.2.2.8" class="ltx_td ltx_align_center">0.327</td>
<td id="S3.T1.2.2.9" class="ltx_td ltx_align_center">0.394</td>
<td id="S3.T1.2.2.10" class="ltx_td ltx_align_center">0.192</td>
<td id="S3.T1.2.2.11" class="ltx_td ltx_align_center">0.857</td>
<td id="S3.T1.2.2.12" class="ltx_td ltx_align_center">0.139</td>
<td id="S3.T1.2.2.13" class="ltx_td ltx_align_center ltx_border_r">0.790</td>
<td id="S3.T1.2.2.14" class="ltx_td ltx_align_center">0.517</td>
</tr>
<tr id="S3.T1.2.10.7" class="ltx_tr">
<th id="S3.T1.2.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">(5)</th>
<th id="S3.T1.2.10.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">RankT5</th>
<td id="S3.T1.2.10.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.823</td>
<td id="S3.T1.2.10.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.399</td>
<td id="S3.T1.2.10.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.753</td>
<td id="S3.T1.2.10.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.493</td>
<td id="S3.T1.2.10.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.406</td>
<td id="S3.T1.2.10.7.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.486</td>
<td id="S3.T1.2.10.7.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.459</td>
<td id="S3.T1.2.10.7.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.191</td>
<td id="S3.T1.2.10.7.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.848</td>
<td id="S3.T1.2.10.7.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.275</td>
<td id="S3.T1.2.10.7.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.760</td>
<td id="S3.T1.2.10.7.14" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.535</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Results from monoT5 reranker finetuned using synthetic data generated from the InPars and the Promptagator prompts. <sup id="S3.T1.6.1" class="ltx_sup">â€ </sup> indicates that Promptagator prompt templates were used to generate the synthetic data.</figcaption>
</figure>
<div id="S3.SS1.p14" class="ltx_para">
<p id="S3.SS1.p14.1" class="ltx_p">Once the model has been trained, the next stage uses it to rerank a dataset. In this stage we support all BEIR datasets, as well as any custom local datasets. The command-line to rerank is:</p>
<div id="S3.SS1.p14.2" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMucmVyYW5rIFwKICAgICAgICAtLW1vZGVsPSIuL3JlcmFua2VyLyIgXAogICAgICAgIC0tZGF0YXNldD0idHJlYy1jb3ZpZCIgXAogICAgICAgIC0tb3V0cHV0X3J1bj0idHJlYy1jb3ZpZC1ydW4udHh0Ig==" download="">â¬‡</a></div>
<div id="lstnumberx22" class="ltx_listingline">
<span id="lstnumberx22.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx22.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx22.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx22.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx22.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx22.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx22.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx22.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx22.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx22.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx22.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">rerank</span><span id="lstnumberx22.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx22.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx23.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx23.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">model</span><span id="lstnumberx23.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx23.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"./reranker/"</span><span id="lstnumberx23.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx23.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span id="lstnumberx24.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx24.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx24.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset</span><span id="lstnumberx24.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx24.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid"</span><span id="lstnumberx24.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx24.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span id="lstnumberx25.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx25.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx25.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">output_run</span><span id="lstnumberx25.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx25.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-run.txt"</span>
</div>
</div>
<p id="S3.SS1.p14.3" class="ltx_p">The first argument is the <span id="S3.SS1.p14.3.1" class="ltx_text ltx_font_typewriter">model</span>, which specifies the trained model to be used for reranking. The <span id="S3.SS1.p14.3.2" class="ltx_text ltx_font_typewriter">dataset</span> argument indicates one of the BEIR datasets to load the documents and queries, as well as the initial run to be reranked. We are using the BEIR runs, created using BM25, as initial run for all the datasets. However, it is possible to provide an initial run from a local file in the TREC format using the <span id="S3.SS1.p14.3.3" class="ltx_text ltx_font_typewriter">initial_run</span> argument. The reranker model will compute a relevancy score for each query and the candidates documents from the initial run. The output will consist of a reranked run, which will be saved in the location indicated by the <span id="S3.SS1.p14.3.4" class="ltx_text ltx_font_typewriter">output_run</span> path.</p>
</div>
<div id="S3.SS1.p15" class="ltx_para">
<p id="S3.SS1.p15.1" class="ltx_p">Finally, to evaluate the reranked run, the following command-line is used:</p>
<div id="S3.SS1.p15.2" class="ltx_listing ltx_lst_language_bash ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAkIHB5dGhvbiAtbSBpbnBhcnMuZXZhbHVhdGUgXAogICAgICAgIC0tZGF0YXNldD0idHJlYy1jb3ZpZCIgXAogICAgICAgIC0tcnVuPSJ0cmVjLWNvdmlkLXJ1bi50eHQi" download="">â¬‡</a></div>
<div id="lstnumberx26" class="ltx_listingline">
<span id="lstnumberx26.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">  </span><span id="lstnumberx26.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">$</span><span id="lstnumberx26.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx26.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">python</span><span id="lstnumberx26.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx26.6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">-</span><span id="lstnumberx26.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">m</span><span id="lstnumberx26.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx26.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">inpars</span><span id="lstnumberx26.10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">.</span><span id="lstnumberx26.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">evaluate</span><span id="lstnumberx26.12" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx26.13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx27.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx27.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">dataset</span><span id="lstnumberx27.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx27.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid"</span><span id="lstnumberx27.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;"> </span><span id="lstnumberx27.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">\</span>
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span id="lstnumberx28.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:90%;">        </span><span id="lstnumberx28.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">--</span><span id="lstnumberx28.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:90%;">run</span><span id="lstnumberx28.4" class="ltx_text ltx_font_typewriter" style="font-size:90%;">=</span><span id="lstnumberx28.5" class="ltx_text ltx_lst_string ltx_font_typewriter" style="font-size:90%;">"trec-covid-run.txt"</span>
</div>
</div>
<p id="S3.SS1.p15.3" class="ltx_p">By providing the <span id="S3.SS1.p15.3.1" class="ltx_text ltx_font_typewriter">dataset</span> and <span id="S3.SS1.p15.3.2" class="ltx_text ltx_font_typewriter">run</span> to be evaluated, our script computes the metrics like recall and nDCG, in addition to other metrics computed by the TREC evaluation script.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents and discusses the results obtained by reproducing the methods using our toolkit. TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.1. Commands â€£ 3. Experimental Setup â€£ InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents a comparison between the baselines, the results reported by original methods and our reproductions. The first two rows (1a and 1b) represent the BM25 baselines. In BM25-flat, document titles and contents are concatenated and stored as a single field while BM25-multi stores them as separate fields. The top 1000 documents retrieved by BM25-flat are reranked by the models in rows (2), (3a), (3b), (4b), and (4c). Row (2) presents the result of monoT5-3B, which was finetuned on MS MARCO for one epoch, used in a zero-shot setup.
Rows (3a) and (3b) presents the reproductions of InPars-v1 and InPars-v2 pipelines, respectively. Row (4a) presents the reported result for Promptagator.
The results in rows (4b) and (4c) illustrate the impact of using the Promptagator prompt with InPars pipelines. Comparing these results to those of InPars v1 and v2 (rows (3a) and (3b)), the results produced by the Promptagator prompt are either equal or slightly lower than those obtained through the InPars prompt, except for the ArguAna, TouchÃ©-2020 and SciFact datasets. Notably, for the ArguAna dataset, finetuning the reranker on the synthetic data generated by the Promptagator prompt resulted in an almost 14 nDCG@10 improvement compared to InParsâ€™ best result. These findings suggest that the Promptagator prompts are particularly effective in generating synthetic queries for the ArguAna and TouchÃ©-2020 datasets. Such datasets concentrate on argument retrieval, which is slightly different from other datasets in the BEIR benchmark. As a result, they gain advantage from using dataset-specific prompts. Also, a factor that probably limited InPars prompt performance on the ArguAna dataset reported in rows (3a) and (3b) is related to the query length. When generating the synthetic queries, InPars sets a maximum number of 64 tokens. As shown in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4. Results â€£ InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the average number of words and tokens for queries across all datasets in the BEIR benchmark is below this value with the exception of the ArguAna dataset.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">When examining the filtering strategy, the results from the InPars prompt indicate an average difference of 1 nDCG@10 point between the results displayed in rows (3a) and (3b). The improvements observed in the reranker strategy results are primarily driven by TouchÃ©-2020, FEVER and Climate-FEVER datasets. When using the Promptagator prompt, the filtering strategy appears to make a difference for certain datasets, as shown in rows (4b) and (4c). The reranking strategy appears to perform better for TREC-COVID, TouchÃ©-2020, and HotpotQA datasets. In particular, the HotpotQA dataset showed an improvement of more than 18 nDCG@10 points when compared to the scores strategy. On the other hand, the scores filtering strategy resulted in an improvement for the DBPedia and Climate-FEVER datasets, with gains of 9.6 and 16.8 nDCG@10 points, respectively. Despite the individual differences, the average results are very similar.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">TPU</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">GPU</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Diff</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">TREC-COVID</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.846</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.851</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.005</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">BioASQ</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">0.595</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">0.629</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center">0.034</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NFCorpus</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">0.385</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">0.385</td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NQ</th>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0.638</td>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r">0.639</td>
<td id="S4.T2.1.5.4.4" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S4.T2.1.6.5" class="ltx_tr">
<th id="S4.T2.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HotpotQA</th>
<td id="S4.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">0.791</td>
<td id="S4.T2.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r">0.711</td>
<td id="S4.T2.1.6.5.4" class="ltx_td ltx_align_center">0.080</td>
</tr>
<tr id="S4.T2.1.7.6" class="ltx_tr">
<th id="S4.T2.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FiQA-2018</th>
<td id="S4.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">0.509</td>
<td id="S4.T2.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r">0.506</td>
<td id="S4.T2.1.7.6.4" class="ltx_td ltx_align_center">0.003</td>
</tr>
<tr id="S4.T2.1.8.7" class="ltx_tr">
<th id="S4.T2.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Signal-1M (RT)</th>
<td id="S4.T2.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">0.308</td>
<td id="S4.T2.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r">0.308</td>
<td id="S4.T2.1.8.7.4" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S4.T2.1.9.8" class="ltx_tr">
<th id="S4.T2.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TREC-NEWS</th>
<td id="S4.T2.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">0.490</td>
<td id="S4.T2.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r">0.490</td>
<td id="S4.T2.1.9.8.4" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S4.T2.1.10.9" class="ltx_tr">
<th id="S4.T2.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Robust04</th>
<td id="S4.T2.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r">0.632</td>
<td id="S4.T2.1.10.9.3" class="ltx_td ltx_align_center ltx_border_r">0.648</td>
<td id="S4.T2.1.10.9.4" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S4.T2.1.11.10" class="ltx_tr">
<th id="S4.T2.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ArguAna</th>
<td id="S4.T2.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r">0.369</td>
<td id="S4.T2.1.11.10.3" class="ltx_td ltx_align_center ltx_border_r">0.407</td>
<td id="S4.T2.1.11.10.4" class="ltx_td ltx_align_center">0.038</td>
</tr>
<tr id="S4.T2.1.12.11" class="ltx_tr">
<th id="S4.T2.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TouchÃ©-2020</th>
<td id="S4.T2.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r">0.291</td>
<td id="S4.T2.1.12.11.3" class="ltx_td ltx_align_center ltx_border_r">0.287</td>
<td id="S4.T2.1.12.11.4" class="ltx_td ltx_align_center">0.004</td>
</tr>
<tr id="S4.T2.1.13.12" class="ltx_tr">
<th id="S4.T2.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CQADupstack</th>
<td id="S4.T2.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r">0.448</td>
<td id="S4.T2.1.13.12.3" class="ltx_td ltx_align_center ltx_border_r">0.441</td>
<td id="S4.T2.1.13.12.4" class="ltx_td ltx_align_center">0.007</td>
</tr>
<tr id="S4.T2.1.14.13" class="ltx_tr">
<th id="S4.T2.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Quora</th>
<td id="S4.T2.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r">0.845</td>
<td id="S4.T2.1.14.13.3" class="ltx_td ltx_align_center ltx_border_r">0.844</td>
<td id="S4.T2.1.14.13.4" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S4.T2.1.15.14" class="ltx_tr">
<th id="S4.T2.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DBPedia</th>
<td id="S4.T2.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r">0.498</td>
<td id="S4.T2.1.15.14.3" class="ltx_td ltx_align_center ltx_border_r">0.498</td>
<td id="S4.T2.1.15.14.4" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S4.T2.1.16.15" class="ltx_tr">
<th id="S4.T2.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SCIDOCS</th>
<td id="S4.T2.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r">0.208</td>
<td id="S4.T2.1.16.15.3" class="ltx_td ltx_align_center ltx_border_r">0.212</td>
<td id="S4.T2.1.16.15.4" class="ltx_td ltx_align_center">0.004</td>
</tr>
<tr id="S4.T2.1.17.16" class="ltx_tr">
<th id="S4.T2.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FEVER</th>
<td id="S4.T2.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r">0.872</td>
<td id="S4.T2.1.17.16.3" class="ltx_td ltx_align_center ltx_border_r">0.869</td>
<td id="S4.T2.1.17.16.4" class="ltx_td ltx_align_center">0.003</td>
</tr>
<tr id="S4.T2.1.18.17" class="ltx_tr">
<th id="S4.T2.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Climate-FEVER</th>
<td id="S4.T2.1.18.17.2" class="ltx_td ltx_align_center ltx_border_r">0.323</td>
<td id="S4.T2.1.18.17.3" class="ltx_td ltx_align_center ltx_border_r">0.323</td>
<td id="S4.T2.1.18.17.4" class="ltx_td ltx_align_center">0.000</td>
</tr>
<tr id="S4.T2.1.19.18" class="ltx_tr">
<th id="S4.T2.1.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SciFact</th>
<td id="S4.T2.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r">0.774</td>
<td id="S4.T2.1.19.18.3" class="ltx_td ltx_align_center ltx_border_r">0.775</td>
<td id="S4.T2.1.19.18.4" class="ltx_td ltx_align_center">0.001</td>
</tr>
<tr id="S4.T2.1.20.19" class="ltx_tr">
<th id="S4.T2.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">AVG</th>
<td id="S4.T2.1.20.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.545</td>
<td id="S4.T2.1.20.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.545</td>
<td id="S4.T2.1.20.19.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.010</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Reproduction of InPars-v2 on TPU and GPU. Numbers are nDCG@10. The same synthetic data was used to train each model on different devices.</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">TableÂ <a href="#S4.T2" title="Table 2 â€£ 4. Results â€£ InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents results comparing the performance on GPU (PyTorchÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib12" title="" class="ltx_ref">Paszke_PyTorch_An_Imperative_2019, </a>)</cite> and TransformersÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib20" title="" class="ltx_ref">Wolf_Transformers_State-of-the-Art_Natural_2020, </a>)</cite>) versus TPU (Mesh-TensorFlowÂ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib15" title="" class="ltx_ref">shazeer2018mesh, </a>)</cite>). As part of our work, we added GPU support to reproduce InPars results. This support covers the synthetic data generation, filtering, training, reranking and evaluating. We conducted an experiment to verify that running it on a GPU setup would produce the same results as running it on the TPU setup. For this, we trained monoT5-3B models following the InPars-v2 approach. Our analysis revealed that while there were minor variations in datasets such as TREC-COVID, BioASQ, Robust04 and ArguAna, the results remained exactly the same for NFCorpus, NQ, and FiQA-2018, regardless of the device used. For the majority of datasets, the variance in results between running on TPU and GPU is minimal when considering individual performance, as demonstrated in the â€Diffâ€ column on TableÂ <a href="#S4.T2" title="Table 2 â€£ 4. Results â€£ InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Furthermore, the average nDCG@10 remains consistent in both evaluation scenarios.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">All experiments were conducted using an NVIDIA A100 80 GB GPU. Training monoT5-3B for 156 steps took about 30 minutes. Filtering 100K queries using a monoT5-3B model takes approximately 45 minutes. The duration of the evaluation step is determined by the number of queries that need to be reranked for each dataset, which can range from 50 queries for TREC-COVID to 13,145 queries for CQADupstack. The reranking of 1,000 candidate documents for a given query took a maximum of 30 seconds using the monoT5-3B reranker model.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">Additionally, TableÂ <a href="#S4.T3" title="Table 3 â€£ 4. Results â€£ InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows statistics regarding the token count for each set of documents and queries in all datasets on the BEIR benchmark.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Documents</th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Queries</th>
</tr>
<tr id="S4.T3.1.2.2" class="ltx_tr">
<th id="S4.T3.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S4.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Words</th>
<th id="S4.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Tokens</th>
<th id="S4.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Words</th>
<th id="S4.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Tokens</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.3.1" class="ltx_tr">
<th id="S4.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">ArguAna</th>
<td id="S4.T3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">170</td>
<td id="S4.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">210</td>
<td id="S4.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">197</td>
<td id="S4.T3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">246</td>
</tr>
<tr id="S4.T3.1.4.2" class="ltx_tr">
<th id="S4.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TREC-NEWS</th>
<td id="S4.T3.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">655</td>
<td id="S4.T3.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">918</td>
<td id="S4.T3.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">11</td>
<td id="S4.T3.1.4.2.5" class="ltx_td ltx_align_center">14</td>
</tr>
<tr id="S4.T3.1.5.3" class="ltx_tr">
<th id="S4.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Robust04</th>
<td id="S4.T3.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">469</td>
<td id="S4.T3.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r">617</td>
<td id="S4.T3.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r">15</td>
<td id="S4.T3.1.5.3.5" class="ltx_td ltx_align_center">18</td>
</tr>
<tr id="S4.T3.1.6.4" class="ltx_tr">
<th id="S4.T3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TouchÃ©-2020</th>
<td id="S4.T3.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r">293</td>
<td id="S4.T3.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r">370</td>
<td id="S4.T3.1.6.4.4" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="S4.T3.1.6.4.5" class="ltx_td ltx_align_center">7</td>
</tr>
<tr id="S4.T3.1.7.5" class="ltx_tr">
<th id="S4.T3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NFCorpus</th>
<td id="S4.T3.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r">220</td>
<td id="S4.T3.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">322</td>
<td id="S4.T3.1.7.5.4" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="S4.T3.1.7.5.5" class="ltx_td ltx_align_center">5</td>
</tr>
<tr id="S4.T3.1.8.6" class="ltx_tr">
<th id="S4.T3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">BioASQ</th>
<td id="S4.T3.1.8.6.2" class="ltx_td ltx_align_center ltx_border_r">203</td>
<td id="S4.T3.1.8.6.3" class="ltx_td ltx_align_center ltx_border_r">310</td>
<td id="S4.T3.1.8.6.4" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T3.1.8.6.5" class="ltx_td ltx_align_center">12</td>
</tr>
<tr id="S4.T3.1.9.7" class="ltx_tr">
<th id="S4.T3.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SciFact</th>
<td id="S4.T3.1.9.7.2" class="ltx_td ltx_align_center ltx_border_r">201</td>
<td id="S4.T3.1.9.7.3" class="ltx_td ltx_align_center ltx_border_r">303</td>
<td id="S4.T3.1.9.7.4" class="ltx_td ltx_align_center ltx_border_r">12</td>
<td id="S4.T3.1.9.7.5" class="ltx_td ltx_align_center">19</td>
</tr>
<tr id="S4.T3.1.10.8" class="ltx_tr">
<th id="S4.T3.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TREC-COVID</th>
<td id="S4.T3.1.10.8.2" class="ltx_td ltx_align_center ltx_border_r">197</td>
<td id="S4.T3.1.10.8.3" class="ltx_td ltx_align_center ltx_border_r">289</td>
<td id="S4.T3.1.10.8.4" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S4.T3.1.10.8.5" class="ltx_td ltx_align_center">15</td>
</tr>
<tr id="S4.T3.1.11.9" class="ltx_tr">
<th id="S4.T3.1.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SCIDOCS</th>
<td id="S4.T3.1.11.9.2" class="ltx_td ltx_align_center ltx_border_r">169</td>
<td id="S4.T3.1.11.9.3" class="ltx_td ltx_align_center ltx_border_r">220</td>
<td id="S4.T3.1.11.9.4" class="ltx_td ltx_align_center ltx_border_r">9</td>
<td id="S4.T3.1.11.9.5" class="ltx_td ltx_align_center">14</td>
</tr>
<tr id="S4.T3.1.12.10" class="ltx_tr">
<th id="S4.T3.1.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CQADupStack</th>
<td id="S4.T3.1.12.10.2" class="ltx_td ltx_align_center ltx_border_r">146</td>
<td id="S4.T3.1.12.10.3" class="ltx_td ltx_align_center ltx_border_r">274</td>
<td id="S4.T3.1.12.10.4" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T3.1.12.10.5" class="ltx_td ltx_align_center">11</td>
</tr>
<tr id="S4.T3.1.13.11" class="ltx_tr">
<th id="S4.T3.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FiQA-2018</th>
<td id="S4.T3.1.13.11.2" class="ltx_td ltx_align_center ltx_border_r">136</td>
<td id="S4.T3.1.13.11.3" class="ltx_td ltx_align_center ltx_border_r">172</td>
<td id="S4.T3.1.13.11.4" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="S4.T3.1.13.11.5" class="ltx_td ltx_align_center">13</td>
</tr>
<tr id="S4.T3.1.14.12" class="ltx_tr">
<th id="S4.T3.1.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Climate-FEVER</th>
<td id="S4.T3.1.14.12.2" class="ltx_td ltx_align_center ltx_border_r">99</td>
<td id="S4.T3.1.14.12.3" class="ltx_td ltx_align_center ltx_border_r">123</td>
<td id="S4.T3.1.14.12.4" class="ltx_td ltx_align_center ltx_border_r">20</td>
<td id="S4.T3.1.14.12.5" class="ltx_td ltx_align_center">25</td>
</tr>
<tr id="S4.T3.1.15.13" class="ltx_tr">
<th id="S4.T3.1.15.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FEVER</th>
<td id="S4.T3.1.15.13.2" class="ltx_td ltx_align_center ltx_border_r">97</td>
<td id="S4.T3.1.15.13.3" class="ltx_td ltx_align_center ltx_border_r">117</td>
<td id="S4.T3.1.15.13.4" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T3.1.15.13.5" class="ltx_td ltx_align_center">11</td>
</tr>
<tr id="S4.T3.1.16.14" class="ltx_tr">
<th id="S4.T3.1.16.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NQ</th>
<td id="S4.T3.1.16.14.2" class="ltx_td ltx_align_center ltx_border_r">79</td>
<td id="S4.T3.1.16.14.3" class="ltx_td ltx_align_center ltx_border_r">106</td>
<td id="S4.T3.1.16.14.4" class="ltx_td ltx_align_center ltx_border_r">9</td>
<td id="S4.T3.1.16.14.5" class="ltx_td ltx_align_center">10</td>
</tr>
<tr id="S4.T3.1.17.15" class="ltx_tr">
<th id="S4.T3.1.17.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DBPedia</th>
<td id="S4.T3.1.17.15.2" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T3.1.17.15.3" class="ltx_td ltx_align_center ltx_border_r">75</td>
<td id="S4.T3.1.17.15.4" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T3.1.17.15.5" class="ltx_td ltx_align_center">7</td>
</tr>
<tr id="S4.T3.1.18.16" class="ltx_tr">
<th id="S4.T3.1.18.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HotpotQA</th>
<td id="S4.T3.1.18.16.2" class="ltx_td ltx_align_center ltx_border_r">46</td>
<td id="S4.T3.1.18.16.3" class="ltx_td ltx_align_center ltx_border_r">69</td>
<td id="S4.T3.1.18.16.4" class="ltx_td ltx_align_center ltx_border_r">15</td>
<td id="S4.T3.1.18.16.5" class="ltx_td ltx_align_center">20</td>
</tr>
<tr id="S4.T3.1.19.17" class="ltx_tr">
<th id="S4.T3.1.19.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Signal-1M (RT)</th>
<td id="S4.T3.1.19.17.2" class="ltx_td ltx_align_center ltx_border_r">15</td>
<td id="S4.T3.1.19.17.3" class="ltx_td ltx_align_center ltx_border_r">23</td>
<td id="S4.T3.1.19.17.4" class="ltx_td ltx_align_center ltx_border_r">9</td>
<td id="S4.T3.1.19.17.5" class="ltx_td ltx_align_center">10</td>
</tr>
<tr id="S4.T3.1.20.18" class="ltx_tr">
<th id="S4.T3.1.20.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Quora</th>
<td id="S4.T3.1.20.18.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">12</td>
<td id="S4.T3.1.20.18.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">15</td>
<td id="S4.T3.1.20.18.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">9</td>
<td id="S4.T3.1.20.18.5" class="ltx_td ltx_align_center ltx_border_bb">11</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Average number of words and tokens for each dataset in the BEIR benchmark. We use Pythonâ€™s <span id="S4.T3.3.1" class="ltx_text ltx_font_typewriter">str.split()</span> for counting the number of words. For tokenizing the text, we use GPT-J tokenizer. </figcaption>
</figure>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">The ArguAna dataset is noteworthy for having significantly different query length compared to the other datasets. TREC-NEWS and Robust04 have the largest document lengths. This information is crucial to keep in mind when choosing documents to use as prompt examples. For instance, if we consider the GPT-J model, with a maximum sequence length of 2048 tokens, at most two average TREC-NEWS documents can fit into a prompt, without even accounting for the length of the queries.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We have introduced the InPars Toolkit, a codebase designed to generate synthetic data using LLMs in a reproducible manner for neural IR tasks. The toolkit comprises an end-to-end pipeline that encompasses data generation, training, reranking, and evaluating the trained models. Additionally, the codebase is integrated with two major libraries for commonly used datasets from the BEIR benchmark, and it supports both GPU and TPU training and inference. Our goal is to make research on these methods more accessible and to pave the way for this emerging research trend in the IR community.
Our experiments have demonstrated that training reranker models using synthetic data and evaluating them on GPU infrastructure yielded results comparable to those obtained when training on the TPU setup. Additionally, we have also made available all synthetic data generated for all BEIR datasets and the models finetuned on this data.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Future work will focus on integrating a wider range of open-source LLMs, including instruction finetuned LLMs, with the aim of enhancing the generation process. Another area of further exploration is to experiment with different prompting techniques, such as chain-of-thought prompting, and prompting for retrieval explanations. Moreover, there are plans to incorporate consistency filtering and expand the filtering methods to completely reproduce Promptagator and lay the foundations for new research approaches in the field of synthetic data generation for IR.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L.Â Bonifacio, H.Â Abonizio, M.Â Fadaee, and R.Â Nogueira.

</span>
<span class="ltx_bibblock">Inpars: Unsupervised dataset generation for information retrieval.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the 45th International ACM SIGIR Conference on
Research and Development in Information Retrieval</span>, SIGIR â€™22, page
2387â€“2392, New York, NY, USA, 2022. Association for Computing Machinery.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L.Â Boytsov, P.Â Patel, V.Â Sourabh, R.Â Nisar, S.Â Kundu, R.Â Ramanathan, and
E.Â Nyberg.

</span>
<span class="ltx_bibblock">Inpars-light: Cost-effective unsupervised training of efficient
rankers, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Z.Â Dai, V.Â Y. Zhao, J.Â Ma, Y.Â Luan, J.Â Ni, J.Â Lu, A.Â Bakalov, K.Â Guu, K.Â B.
Hall, and M.-W. Chang.

</span>
<span class="ltx_bibblock">Promptagator: Few-shot dense retrieval from 8 examples, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L.Â Gao, S.Â Biderman, S.Â Black, L.Â Golding, T.Â Hoppe, C.Â Foster, J.Â Phang,
H.Â He, A.Â Thite, N.Â Nabeshima, S.Â Presser, and C.Â Leahy.

</span>
<span class="ltx_bibblock">The pile: An 800gb dataset of diverse text for language modeling.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2101.00027, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
V.Â Jeronymo, L.Â Bonifacio, H.Â Abonizio, M.Â Fadaee, R.Â Lotufo, J.Â Zavrel, and
R.Â Nogueira.

</span>
<span class="ltx_bibblock">Inpars-v2: Large language models as efficient dataset generators for
information retrieval, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T.Â Kwiatkowski, J.Â Palomaki, O.Â Redfield, M.Â Collins, A.Â Parikh, C.Â Alberti,
D.Â Epstein, I.Â Polosukhin, J.Â Devlin, K.Â Lee, K.Â Toutanova, L.Â Jones,
M.Â Kelcey, M.-W. Chang, A.Â M. Dai, J.Â Uszkoreit, Q.Â Le, and S.Â Petrov.

</span>
<span class="ltx_bibblock">Natural questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Transactions of the Association for Computational Linguistics</span>,
7:452â€“466, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J.Â Lin, X.Â Ma, S.-C. Lin, J.-H. Yang, R.Â Pradeep, and R.Â Nogueira.

</span>
<span class="ltx_bibblock">Pyserini: A Python toolkit for reproducible information retrieval
research with sparse and dense representations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proceedings of the 44th Annual International ACM SIGIR
Conference on Research and Development in Information Retrieval (SIGIR
2021)</span>, pages 2356â€“2362, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S.Â MacAvaney, A.Â Yates, S.Â Feldman, D.Â Downey, A.Â Cohan, and N.Â Goharian.

</span>
<span class="ltx_bibblock">Simplified data wrangling with ir_datasets.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">SIGIR</span>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
T.Â Nguyen, M.Â Rosenberg, X.Â Song, J.Â Gao, S.Â Tiwary, R.Â Majumder, and L.Â Deng.

</span>
<span class="ltx_bibblock">MS MARCO: A human generated machine reading comprehension
dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1611.09268, 2016.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J.Â Ni, C.Â Qu, J.Â Lu, Z.Â Dai, G.Â H. Ãbrego, J.Â Ma, V.Â Y. Zhao, Y.Â Luan,
K.Â B. Hall, M.Â Chang, and Y.Â Yang.

</span>
<span class="ltx_bibblock">Large dual encoders are generalizable retrievers.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2112.07899, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R.Â Nogueira, Z.Â Jiang, R.Â Pradeep, and J.Â Lin.

</span>
<span class="ltx_bibblock">Document ranking with a pretrained sequence-to-sequence model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing: Findings</span>, pages 708â€“718, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A.Â Paszke, S.Â Gross, F.Â Massa, A.Â Lerer, J.Â Bradbury, G.Â Chanan, T.Â Killeen,
Z.Â Lin, N.Â Gimelshein, L.Â Antiga, A.Â Desmaison, A.Â Kopf, E.Â Yang, Z.Â DeVito,
M.Â Raison, A.Â Tejani, S.Â Chilamkurthy, B.Â Steiner, L.Â Fang, J.Â Bai, and
S.Â Chintala.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance Deep Learning
Library.

</span>
<span class="ltx_bibblock">In H.Â Wallach, H.Â Larochelle, A.Â Beygelzimer, F.Â dâ€™AlchÃ© Buc,
E.Â Fox, and R.Â Garnett, editors, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information
Processing Systems 32</span>, pages 8024â€“8035. Curran Associates, Inc., 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C.Â Raffel, N.Â Shazeer, A.Â Roberts, K.Â Lee, S.Â Narang, M.Â Matena, Y.Â Zhou,
W.Â Li, and P.Â J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1910.10683, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G.Â Rosa, L.Â Bonifacio, V.Â Jeronymo, H.Â Abonizio, M.Â Fadaee, R.Â Lotufo, and
R.Â Nogueira.

</span>
<span class="ltx_bibblock">No parameter left behind: How distillation and model size affect
zero-shot retrieval.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">https://arxiv.org/abs/2206.02873</span>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
N.Â Shazeer, Y.Â Cheng, N.Â Parmar, D.Â Tran, A.Â Vaswani, P.Â Koanantakool,
P.Â Hawkins, H.Â Lee, M.Â Hong, C.Â Young, R.Â Sepassi, and B.Â Hechtman.

</span>
<span class="ltx_bibblock">Mesh-TensorFlow: Deep learning for supercomputers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Neural Information Processing Systems</span>, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
N.Â Thakur, N.Â Reimers, A.Â RÃ¼cklÃ©, A.Â Srivastava, and I.Â Gurevych.

</span>
<span class="ltx_bibblock">BEIR: A heterogeneous benchmark for zero-shot evaluation of
information retrieval models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Thirty-fifth Conference on Neural Information Processing
Systems Datasets and Benchmarks Track (Round 2)</span>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
B.Â Wang.

</span>
<span class="ltx_bibblock">Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer
Language Model with JAX.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
B.Â Wang and A.Â Komatsuzaki.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J.Â Wei, M.Â Bosma, V.Â Zhao, K.Â Guu, A.Â W. Yu, B.Â Lester, N.Â Du, A.Â M. Dai, and
Q.Â V. Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T.Â Wolf, L.Â Debut, V.Â Sanh, J.Â Chaumond, C.Â Delangue, A.Â Moi, P.Â Cistac, C.Â Ma,
Y.Â Jernite, J.Â Plu, C.Â Xu, T.Â LeÂ Scao, S.Â Gugger, M.Â Drame, Q.Â Lhoest, and
A.Â M. Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-Art Natural Language Processing.

</span>
<span class="ltx_bibblock">pages 38â€“45. Association for Computational Linguistics, 10 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.04600" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.04601" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.04601">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.04601" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.04602" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 18:56:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
