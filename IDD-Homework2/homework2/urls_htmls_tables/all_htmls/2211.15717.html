<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.15717] Abstract</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Abstract">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Abstract">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.15717">

<!--Generated on Thu Mar 14 09:45:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div id="id1" class="ltx_logical-block">
<div id="id1.p1" class="ltx_para">
<p id="id1.p1.1" class="ltx_p ltx_align_left"><span id="id1.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Learning deep abdominal CT registration through adaptive loss weighting and synthetic data generation<span id="id1.p1.1.1.1" class="ltx_text ltx_font_medium">
</span></span>

<br class="ltx_break"></p>
<p id="id1.p1.2" class="ltx_p ltx_align_left">Javier PÃ©rez de Frutos<sup id="id1.p1.2.1" class="ltx_sup">1*</sup>,
AndrÃ© Pedersen<sup id="id1.p1.2.2" class="ltx_sup">1,2,3</sup>,
Egidijus Pelanis<sup id="id1.p1.2.3" class="ltx_sup">4</sup>,
David Bouget<sup id="id1.p1.2.4" class="ltx_sup">1</sup>,
Shanmugapriya Survarachakan<sup id="id1.p1.2.5" class="ltx_sup">5</sup>,
Thomas LangÃ¸<sup id="id1.p1.2.6" class="ltx_sup">1,6</sup>,
Ole-Jakob Elle<sup id="id1.p1.2.7" class="ltx_sup">4</sup>,
Frank Lindseth<sup id="id1.p1.2.8" class="ltx_sup">5</sup></p>
<br class="ltx_break ltx_align_left">
<p id="id1.p1.3" class="ltx_p ltx_align_left"><sup id="id1.p1.3.1" class="ltx_sup">1</sup> Department of Health Research, SINTEF, Trondheim, Norway</p>
<p id="id1.p1.4" class="ltx_p ltx_align_left"><sup id="id1.p1.4.1" class="ltx_sup">2</sup> Department of Clinical and Molecular Medicine, Norwegian University of Technology (NTNU), Trondheim, Norway</p>
<p id="id1.p1.5" class="ltx_p ltx_align_left"><sup id="id1.p1.5.1" class="ltx_sup">3</sup> Clinic of Surgery, St. Olavs hospital, Trondheim University Hospital, Trondheim, Norway</p>
<p id="id1.p1.6" class="ltx_p ltx_align_left"><sup id="id1.p1.6.1" class="ltx_sup">4</sup> The Intervention Centre, Oslo University Hospital, Oslo, Norway</p>
<p id="id1.p1.7" class="ltx_p ltx_align_left"><sup id="id1.p1.7.1" class="ltx_sup">5</sup> Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway</p>
<p id="id1.p1.8" class="ltx_p ltx_align_left"><sup id="id1.p1.8.1" class="ltx_sup">6</sup> Research Department, Future Operating Room, St. Olavs hospital, Trondheim University Hospital, Trondheim, Norway</p>
<br class="ltx_break ltx_align_left">
<p id="id1.p1.9" class="ltx_p ltx_align_left">* Corresponding author</p>
<p id="id1.p1.10" class="ltx_p ltx_align_left">E-mail: javier.perezdefrutos@sintef.no</p>
</div>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Abstract</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Purpose:</span> This study aims to explore training strategies to improve convolutional neural network-based image-to-image deformable registration for abdominal imaging.

<br class="ltx_break"><span id="Sx1.p1.1.2" class="ltx_text ltx_font_bold">Methods:</span> Different training strategies, loss functions, and transfer learning schemes were considered. Furthermore, an augmentation layer which generates artificial training image pairs on-the-fly was proposed, in addition to a loss layer that enables dynamic loss weighting.

<br class="ltx_break"><span id="Sx1.p1.1.3" class="ltx_text ltx_font_bold">Results:</span> Guiding registration using segmentations in the training step proved beneficial for deep-learning-based image registration. Finetuning the pretrained model from the brain MRI dataset to the abdominal CT dataset further improved performance on the latter application, removing the need for a large dataset to yield satisfactory performance. Dynamic loss weighting also marginally improved performance, all without impacting inference runtime.

<br class="ltx_break"><span id="Sx1.p1.1.4" class="ltx_text ltx_font_bold">Conclusion:</span> Using simple concepts, we improved the performance of a commonly used deep image registration architecture, VoxelMorph. In future work, our framework, DDMR, should be validated on different datasets to further assess its value.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Introduction</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">For liver surgery, minimally invasive techniques such as laparoscopy have become as relevant as open surgeryÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Among other benefits, laparoscopy has shown to yield higher quality of life, shorten recovery time, lessen patient trauma, and reduce blood loss with comparable long-term oncological outcomesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Overcoming challenges from limited field of view to manoeuvrability, and a small work space are the foundations of laparoscopy success. Image-guided navigation platforms aim to ease the burden off the surgeon, by bringing better visualisation techniques to the operating roomÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Image-to-patient and image-to-image registration techniques (hereafter image registration) are at the core of such platforms to provide clinically valuable visualisation tools. The concept of image registration refers to the alignment of at least two images, matching the location of corresponding features across images in order to express them into a common space. Both rigid and non-rigid registration are the two main strategies to define the alignment between the images. Rigid registration uses affine transformations, which are quicker to compute but less accurate as these are applied globally. Non-rigid registration, also known as deformable registration, defines a diffeomorphism, i.e., a point-to-point correspondence, between the images. However, non-rigid registration comes at the expense of higher computational needs and thus hardware constraints might hinder the development and deployment of such algorithms. In medicine, image registration is mandatory for fusing clinically relevant information across images; groundwork for enabling image-guided navigation during laparoscopic interventionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Additionally, laparoscopic preoperative surgical planning benefits from abdominal computed tomography (CT) to magnetic resonance imaging (MRI) registration to better identify risk areas in a patientâ€™s anatomyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">During laparoscopic liver surgeries, intraoperative imaging (e.g., video and ultrasound) is routinely used to assist the surgeon in navigating the liver while identifying the location of landmarks. In parenchyma-sparing liver resection (i.e., wedge resection) for colorectal liver metastasis, a minimal safety margin around the lesions is defined to ensure no recurrence and spare healthy tissueÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. When dealing with narrow margins and close proximity to critical structures, a high accuracy in the registration method employed is paramount to ensure the best patient outcome. Patient-specific cross-modality registration between images of different nature (e.g., CT to MRI) is practisedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, yet being a more complex process compared to mono-modal registration.</p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p">The alignment of images can be evaluated through different metrics based either on intensity information from the voxels, shape information from segmentation masks, or spatial information from landmarksâ€™ location or relative distances. The most common intensity-based similarity metrics are the normalised cross-correlation (NCC), structural similarity index measure (SSIM), or related variationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. For segmentation-based metrics, the most notorious are the Dice similarity coefficient (DSC) and Hausdorff distance (HD)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. However, target registration error (TRE) is the gold standard metric for practitioners, conferring a quantitative error measure based on the target lesion location across imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p">Research on the use of convolutional neural networks (CNNs) for image registration has gained momentum in recent years, motivated by the improvements in hardware and software.
One early application of deep learning-based image registration (hereafter deep image registration) was performed by Wu <span id="Sx2.p4.1.1" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. They proposed a network built with two convolutional layers, coupled with principal component analysis as a dimensionality reduction step, to align brain MR scans. Expanding upon the concept, Jaderberg <span id="Sx2.p4.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> introduced the spatial transformer network, including a sampling step for data interpolation, allowing for gradients to be backpropagated. Hence, further enabling neural network deformable image-to-image registration applications. Publications on CNNs for image-registration show a preference for encoder-decoder architectures like U-NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, followed by a spatial transformer network, as can be seen in QuicksilverÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, VoxelMorphÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, and other studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Mok <span id="Sx2.p4.1.3" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> proposed a Laplacian pyramid network for multi-resolution-based MRI registration, enforcing the non-rigid transformation to be diffeomorphic.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p id="Sx2.p5.1" class="ltx_p">The development of weakly-supervised training strategiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> enabled model training by combining intensity information with other data types (e.g., segmentation masks). Intensity-based unsupervised training for non-rigid registration was explored for abdominal and lung CTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Building cross-modality image registration models through reinforcement learning has also been exploredÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
However, semi-supervised training of convolutional encoder-decoder architectures has been favoured for training registration models and producing the displacement mapÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p id="Sx2.p6.1" class="ltx_p">In our study, the focus is brought towards improving the training scheme of deep neural networks for deformable image registration to cater more easily to use-cases with limited data. We narrowed the scope to mono-modal registration, and the investigation of transfer learning across image modalities and anatomies. Our proposed main contributions are:</p>
<ul id="Sx2.I1" class="ltx_itemize">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p">an augmentation layer for on-the-fly data augmentation (compatible with TensorFlow GPU computational graphs), which includes generation of ground truth samples for non-rigid image registration, based on thin plate splines (TPS), removing the need for pre-computation and storage of augmented copies on disk,</p>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p">an uncertainty weighting loss layer to enable adaptive multi-task learning in a weakly-supervised learning approach,</p>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p">and the validation of a cross-anatomy and cross-modality transfer learning approach for image registration with scarce data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Materials and methods</h2>

<section id="Sx3.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Dataset</h3>

<div id="Sx3.SSx1.p1" class="ltx_para">
<p id="Sx3.SSx1.p1.1" class="ltx_p">In this study, two datasets were selected for conducting the experiments: the Information eXtraction from Images (IXI) dataset and Laparoscopic Versus Open Resection for Colorectal Liver Metastases: The Oslo-CoMet Randomized Controlled Trial datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="Sx3.SSx1.p2" class="ltx_para">
<p id="Sx3.SSx1.p2.6" class="ltx_p">The IXI dataset contains <math id="Sx3.SSx1.p2.1.m1.1" class="ltx_Math" alttext="578" display="inline"><semantics id="Sx3.SSx1.p2.1.m1.1a"><mn id="Sx3.SSx1.p2.1.m1.1.1" xref="Sx3.SSx1.p2.1.m1.1.1.cmml">578</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.1.m1.1b"><cn type="integer" id="Sx3.SSx1.p2.1.m1.1.1.cmml" xref="Sx3.SSx1.p2.1.m1.1.1">578</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.1.m1.1c">578</annotation></semantics></math> T1-weighted head MR scans from healthy subjects collected from three different hospitals in London. This dataset is made available under the Creative Commons CC BY-SA
3.0 license. Only T1-weighted MRIs were used in this study, but other MRI sequences such as T2 and proton density are also available. Using the advanced normalization tools (ANTs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, the T1 images were registered to the symmetric Montreal Neurological Institute ICBM2009a atlas, to subsequently obtain the segmentation masks of <math id="Sx3.SSx1.p2.2.m2.1" class="ltx_Math" alttext="29" display="inline"><semantics id="Sx3.SSx1.p2.2.m2.1a"><mn id="Sx3.SSx1.p2.2.m2.1.1" xref="Sx3.SSx1.p2.2.m2.1.1.cmml">29</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.2.m2.1b"><cn type="integer" id="Sx3.SSx1.p2.2.m2.1.1.cmml" xref="Sx3.SSx1.p2.2.m2.1.1">29</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.2.m2.1c">29</annotation></semantics></math> different regions of the brain. Ultimately, left and right parcels were merged together resulting in a collection of <math id="Sx3.SSx1.p2.3.m3.1" class="ltx_Math" alttext="17" display="inline"><semantics id="Sx3.SSx1.p2.3.m3.1a"><mn id="Sx3.SSx1.p2.3.m3.1.1" xref="Sx3.SSx1.p2.3.m3.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.3.m3.1b"><cn type="integer" id="Sx3.SSx1.p2.3.m3.1.1.cmml" xref="Sx3.SSx1.p2.3.m3.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.3.m3.1c">17</annotation></semantics></math> labels (see the online resource Table A in S1 Appendix). The data was then stratified into three cohorts: training (n=<math id="Sx3.SSx1.p2.4.m4.1" class="ltx_Math" alttext="407" display="inline"><semantics id="Sx3.SSx1.p2.4.m4.1a"><mn id="Sx3.SSx1.p2.4.m4.1.1" xref="Sx3.SSx1.p2.4.m4.1.1.cmml">407</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.4.m4.1b"><cn type="integer" id="Sx3.SSx1.p2.4.m4.1.1.cmml" xref="Sx3.SSx1.p2.4.m4.1.1">407</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.4.m4.1c">407</annotation></semantics></math>), validation (n=<math id="Sx3.SSx1.p2.5.m5.1" class="ltx_Math" alttext="87" display="inline"><semantics id="Sx3.SSx1.p2.5.m5.1a"><mn id="Sx3.SSx1.p2.5.m5.1.1" xref="Sx3.SSx1.p2.5.m5.1.1.cmml">87</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.5.m5.1b"><cn type="integer" id="Sx3.SSx1.p2.5.m5.1.1.cmml" xref="Sx3.SSx1.p2.5.m5.1.1">87</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.5.m5.1c">87</annotation></semantics></math>), and test (n=<math id="Sx3.SSx1.p2.6.m6.1" class="ltx_Math" alttext="88" display="inline"><semantics id="Sx3.SSx1.p2.6.m6.1a"><mn id="Sx3.SSx1.p2.6.m6.1.1" xref="Sx3.SSx1.p2.6.m6.1.1.cmml">88</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p2.6.m6.1b"><cn type="integer" id="Sx3.SSx1.p2.6.m6.1.1.cmml" xref="Sx3.SSx1.p2.6.m6.1.1">88</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p2.6.m6.1c">88</annotation></semantics></math>) sets.</p>
</div>
<div id="Sx3.SSx1.p3" class="ltx_para">
<p id="Sx3.SSx1.p3.3" class="ltx_p">The Oslo-CoMet trial dataset, compiled by the Intervention Centre, Oslo University Hospital (Norway), contains 60 contrast-enhanced CTs. The trial protocol for this study was approved by the Regional Ethical Committee of South Eastern Norway (REK SÃ¸r-Ã˜st B
2011/1285) and the Data Protection Officer of Oslo University Hospital (Clinicaltrials.org identifier NCT01516710). Informed written consent was obtained from all participants included in the study. Manual delineations of the liver parenchyma, i.e., liver segmentation masks, were available as part of the Oslo-CoMet datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Additionally, an approximate segmentation of the vascular structures was obtained using the segmentation model available in the public livermask toolÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. The data was then stratified into three cohorts: training (n=<math id="Sx3.SSx1.p3.1.m1.1" class="ltx_Math" alttext="41" display="inline"><semantics id="Sx3.SSx1.p3.1.m1.1a"><mn id="Sx3.SSx1.p3.1.m1.1.1" xref="Sx3.SSx1.p3.1.m1.1.1.cmml">41</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p3.1.m1.1b"><cn type="integer" id="Sx3.SSx1.p3.1.m1.1.1.cmml" xref="Sx3.SSx1.p3.1.m1.1.1">41</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p3.1.m1.1c">41</annotation></semantics></math>), validation (n=<math id="Sx3.SSx1.p3.2.m2.1" class="ltx_Math" alttext="8" display="inline"><semantics id="Sx3.SSx1.p3.2.m2.1a"><mn id="Sx3.SSx1.p3.2.m2.1.1" xref="Sx3.SSx1.p3.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p3.2.m2.1b"><cn type="integer" id="Sx3.SSx1.p3.2.m2.1.1.cmml" xref="Sx3.SSx1.p3.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p3.2.m2.1c">8</annotation></semantics></math>), and test (n=<math id="Sx3.SSx1.p3.3.m3.1" class="ltx_Math" alttext="11" display="inline"><semantics id="Sx3.SSx1.p3.3.m3.1a"><mn id="Sx3.SSx1.p3.3.m3.1.1" xref="Sx3.SSx1.p3.3.m3.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p3.3.m3.1b"><cn type="integer" id="Sx3.SSx1.p3.3.m3.1.1.cmml" xref="Sx3.SSx1.p3.3.m3.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p3.3.m3.1c">11</annotation></semantics></math>) sets.</p>
</div>
</section>
<section id="Sx3.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Preprocessing</h3>

<div id="Sx3.SSx2.p1" class="ltx_para">
<p id="Sx3.SSx2.p1.3" class="ltx_p">Before the training phase, both CT and MR images, as well as the segmentation masks, were resampled to an isotropic resolution of <math id="Sx3.SSx2.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="Sx3.SSx2.p1.1.m1.1a"><mn id="Sx3.SSx2.p1.1.m1.1.1" xref="Sx3.SSx2.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p1.1.m1.1b"><cn type="integer" id="Sx3.SSx2.p1.1.m1.1.1.cmml" xref="Sx3.SSx2.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p1.1.m1.1c">1</annotation></semantics></math>â€‰mm<sup id="Sx3.SSx2.p1.3.1" class="ltx_sup">3</sup> and resized to <math id="Sx3.SSx2.p1.3.m3.1" class="ltx_Math" alttext="128\times 128\times 128" display="inline"><semantics id="Sx3.SSx2.p1.3.m3.1a"><mrow id="Sx3.SSx2.p1.3.m3.1.1" xref="Sx3.SSx2.p1.3.m3.1.1.cmml"><mn id="Sx3.SSx2.p1.3.m3.1.1.2" xref="Sx3.SSx2.p1.3.m3.1.1.2.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx2.p1.3.m3.1.1.1" xref="Sx3.SSx2.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx2.p1.3.m3.1.1.3" xref="Sx3.SSx2.p1.3.m3.1.1.3.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx2.p1.3.m3.1.1.1a" xref="Sx3.SSx2.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx2.p1.3.m3.1.1.4" xref="Sx3.SSx2.p1.3.m3.1.1.4.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p1.3.m3.1b"><apply id="Sx3.SSx2.p1.3.m3.1.1.cmml" xref="Sx3.SSx2.p1.3.m3.1.1"><times id="Sx3.SSx2.p1.3.m3.1.1.1.cmml" xref="Sx3.SSx2.p1.3.m3.1.1.1"></times><cn type="integer" id="Sx3.SSx2.p1.3.m3.1.1.2.cmml" xref="Sx3.SSx2.p1.3.m3.1.1.2">128</cn><cn type="integer" id="Sx3.SSx2.p1.3.m3.1.1.3.cmml" xref="Sx3.SSx2.p1.3.m3.1.1.3">128</cn><cn type="integer" id="Sx3.SSx2.p1.3.m3.1.1.4.cmml" xref="Sx3.SSx2.p1.3.m3.1.1.4">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p1.3.m3.1c">128\times 128\times 128</annotation></semantics></math>â€‰voxels. Additionally, the CT images were cropped around the liver mask before the resampling step. Cubic spline interpolation was used for resampling the intensity images, whereas segmentations were interpolated using nearest neighbour. The segmentation masks were stored as categorical 8-bit unsigned integer single-channel images, to enable rapid batch generation during training.</p>
</div>
<div id="Sx3.SSx2.p2" class="ltx_para">
<p id="Sx3.SSx2.p2.5" class="ltx_p">To overcome the scarcity of image registration datasets for algorithm development, we propose an augmentation layer, implemented in TensorFlowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, to generate artificial moving images during training.
The augmentation layer allows for data augmentation and preprocessing. The layer features gamma (0.5 to 2) and brightness augmentation (<math id="Sx3.SSx2.p2.1.m1.1" class="ltx_Math" alttext="\pm 20\%" display="inline"><semantics id="Sx3.SSx2.p2.1.m1.1a"><mrow id="Sx3.SSx2.p2.1.m1.1.1" xref="Sx3.SSx2.p2.1.m1.1.1.cmml"><mo id="Sx3.SSx2.p2.1.m1.1.1a" xref="Sx3.SSx2.p2.1.m1.1.1.cmml">Â±</mo><mrow id="Sx3.SSx2.p2.1.m1.1.1.2" xref="Sx3.SSx2.p2.1.m1.1.1.2.cmml"><mn id="Sx3.SSx2.p2.1.m1.1.1.2.2" xref="Sx3.SSx2.p2.1.m1.1.1.2.2.cmml">20</mn><mo id="Sx3.SSx2.p2.1.m1.1.1.2.1" xref="Sx3.SSx2.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p2.1.m1.1b"><apply id="Sx3.SSx2.p2.1.m1.1.1.cmml" xref="Sx3.SSx2.p2.1.m1.1.1"><csymbol cd="latexml" id="Sx3.SSx2.p2.1.m1.1.1.1.cmml" xref="Sx3.SSx2.p2.1.m1.1.1">plus-or-minus</csymbol><apply id="Sx3.SSx2.p2.1.m1.1.1.2.cmml" xref="Sx3.SSx2.p2.1.m1.1.1.2"><csymbol cd="latexml" id="Sx3.SSx2.p2.1.m1.1.1.2.1.cmml" xref="Sx3.SSx2.p2.1.m1.1.1.2.1">percent</csymbol><cn type="integer" id="Sx3.SSx2.p2.1.m1.1.1.2.2.cmml" xref="Sx3.SSx2.p2.1.m1.1.1.2.2">20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p2.1.m1.1c">\pm 20\%</annotation></semantics></math>), rotation, and rigid and non-rigid transformations, to generate the moving images. Data preprocessing includes resizing and intensity normalisation to the range <math id="Sx3.SSx2.p2.2.m2.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="Sx3.SSx2.p2.2.m2.2a"><mrow id="Sx3.SSx2.p2.2.m2.2.3.2" xref="Sx3.SSx2.p2.2.m2.2.3.1.cmml"><mo stretchy="false" id="Sx3.SSx2.p2.2.m2.2.3.2.1" xref="Sx3.SSx2.p2.2.m2.2.3.1.cmml">[</mo><mn id="Sx3.SSx2.p2.2.m2.1.1" xref="Sx3.SSx2.p2.2.m2.1.1.cmml">0</mn><mo id="Sx3.SSx2.p2.2.m2.2.3.2.2" xref="Sx3.SSx2.p2.2.m2.2.3.1.cmml">,</mo><mn id="Sx3.SSx2.p2.2.m2.2.2" xref="Sx3.SSx2.p2.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="Sx3.SSx2.p2.2.m2.2.3.2.3" xref="Sx3.SSx2.p2.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p2.2.m2.2b"><interval closure="closed" id="Sx3.SSx2.p2.2.m2.2.3.1.cmml" xref="Sx3.SSx2.p2.2.m2.2.3.2"><cn type="integer" id="Sx3.SSx2.p2.2.m2.1.1.cmml" xref="Sx3.SSx2.p2.2.m2.1.1">0</cn><cn type="integer" id="Sx3.SSx2.p2.2.m2.2.2.cmml" xref="Sx3.SSx2.p2.2.m2.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p2.2.m2.2c">[0,1]</annotation></semantics></math>. The maximum displacements, rigid and non-rigid, can be constrained to mimic real-case scenarios. In our case, <math id="Sx3.SSx2.p2.3.m3.1" class="ltx_Math" alttext="30" display="inline"><semantics id="Sx3.SSx2.p2.3.m3.1a"><mn id="Sx3.SSx2.p2.3.m3.1.1" xref="Sx3.SSx2.p2.3.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p2.3.m3.1b"><cn type="integer" id="Sx3.SSx2.p2.3.m3.1.1.cmml" xref="Sx3.SSx2.p2.3.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p2.3.m3.1c">30</annotation></semantics></math>â€‰mm and <math id="Sx3.SSx2.p2.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="Sx3.SSx2.p2.4.m4.1a"><mn id="Sx3.SSx2.p2.4.m4.1.1" xref="Sx3.SSx2.p2.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p2.4.m4.1b"><cn type="integer" id="Sx3.SSx2.p2.4.m4.1.1.cmml" xref="Sx3.SSx2.p2.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p2.4.m4.1c">6</annotation></semantics></math>â€‰mm respectively. Rotation was limited to <math id="Sx3.SSx2.p2.5.m5.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="Sx3.SSx2.p2.5.m5.1a"><msup id="Sx3.SSx2.p2.5.m5.1.1" xref="Sx3.SSx2.p2.5.m5.1.1.cmml"><mn id="Sx3.SSx2.p2.5.m5.1.1.2" xref="Sx3.SSx2.p2.5.m5.1.1.2.cmml">10</mn><mo id="Sx3.SSx2.p2.5.m5.1.1.3" xref="Sx3.SSx2.p2.5.m5.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p2.5.m5.1b"><apply id="Sx3.SSx2.p2.5.m5.1.1.cmml" xref="Sx3.SSx2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="Sx3.SSx2.p2.5.m5.1.1.1.cmml" xref="Sx3.SSx2.p2.5.m5.1.1">superscript</csymbol><cn type="integer" id="Sx3.SSx2.p2.5.m5.1.1.2.cmml" xref="Sx3.SSx2.p2.5.m5.1.1.2">10</cn><compose id="Sx3.SSx2.p2.5.m5.1.1.3.cmml" xref="Sx3.SSx2.p2.5.m5.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p2.5.m5.1c">10^{\circ}</annotation></semantics></math>, for any of the three coordinate axes.</p>
</div>
<div id="Sx3.SSx2.p3" class="ltx_para">
<p id="Sx3.SSx2.p3.1" class="ltx_p">The non-rigid deformation was achieved using TPS applied on an <math id="Sx3.SSx2.p3.1.m1.1" class="ltx_Math" alttext="8\times 8\times 8" display="inline"><semantics id="Sx3.SSx2.p3.1.m1.1a"><mrow id="Sx3.SSx2.p3.1.m1.1.1" xref="Sx3.SSx2.p3.1.m1.1.1.cmml"><mn id="Sx3.SSx2.p3.1.m1.1.1.2" xref="Sx3.SSx2.p3.1.m1.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx2.p3.1.m1.1.1.1" xref="Sx3.SSx2.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx2.p3.1.m1.1.1.3" xref="Sx3.SSx2.p3.1.m1.1.1.3.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx2.p3.1.m1.1.1.1a" xref="Sx3.SSx2.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx2.p3.1.m1.1.1.4" xref="Sx3.SSx2.p3.1.m1.1.1.4.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx2.p3.1.m1.1b"><apply id="Sx3.SSx2.p3.1.m1.1.1.cmml" xref="Sx3.SSx2.p3.1.m1.1.1"><times id="Sx3.SSx2.p3.1.m1.1.1.1.cmml" xref="Sx3.SSx2.p3.1.m1.1.1.1"></times><cn type="integer" id="Sx3.SSx2.p3.1.m1.1.1.2.cmml" xref="Sx3.SSx2.p3.1.m1.1.1.2">8</cn><cn type="integer" id="Sx3.SSx2.p3.1.m1.1.1.3.cmml" xref="Sx3.SSx2.p3.1.m1.1.1.3">8</cn><cn type="integer" id="Sx3.SSx2.p3.1.m1.1.1.4.cmml" xref="Sx3.SSx2.p3.1.m1.1.1.4">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx2.p3.1.m1.1c">8\times 8\times 8</annotation></semantics></math> grid, with a configurable maximum displacement. Rigid transformations include rotation and translation.</p>
</div>
</section>
<section id="Sx3.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Model architecture</h3>

<div id="Sx3.SSx3.p1" class="ltx_para">
<p id="Sx3.SSx3.p1.4" class="ltx_p">The baseline architecture consists of a modified VoxelMorph modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, based on a U-NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> variant. The model was used to predict the displacement map, as depicted in <a href="#Sx3.F1" title="In Model architecture â€£ Materials and methods" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. After the augmentation step, the fixedÂ (<math id="Sx3.SSx3.p1.1.m1.1" class="ltx_Math" alttext="I_{f}" display="inline"><semantics id="Sx3.SSx3.p1.1.m1.1a"><msub id="Sx3.SSx3.p1.1.m1.1.1" xref="Sx3.SSx3.p1.1.m1.1.1.cmml"><mi id="Sx3.SSx3.p1.1.m1.1.1.2" xref="Sx3.SSx3.p1.1.m1.1.1.2.cmml">I</mi><mi id="Sx3.SSx3.p1.1.m1.1.1.3" xref="Sx3.SSx3.p1.1.m1.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p1.1.m1.1b"><apply id="Sx3.SSx3.p1.1.m1.1.1.cmml" xref="Sx3.SSx3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx3.p1.1.m1.1.1.1.cmml" xref="Sx3.SSx3.p1.1.m1.1.1">subscript</csymbol><ci id="Sx3.SSx3.p1.1.m1.1.1.2.cmml" xref="Sx3.SSx3.p1.1.m1.1.1.2">ğ¼</ci><ci id="Sx3.SSx3.p1.1.m1.1.1.3.cmml" xref="Sx3.SSx3.p1.1.m1.1.1.3">ğ‘“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p1.1.m1.1c">I_{f}</annotation></semantics></math>) and the generated movingÂ (<math id="Sx3.SSx3.p1.2.m2.1" class="ltx_Math" alttext="I_{m}" display="inline"><semantics id="Sx3.SSx3.p1.2.m2.1a"><msub id="Sx3.SSx3.p1.2.m2.1.1" xref="Sx3.SSx3.p1.2.m2.1.1.cmml"><mi id="Sx3.SSx3.p1.2.m2.1.1.2" xref="Sx3.SSx3.p1.2.m2.1.1.2.cmml">I</mi><mi id="Sx3.SSx3.p1.2.m2.1.1.3" xref="Sx3.SSx3.p1.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p1.2.m2.1b"><apply id="Sx3.SSx3.p1.2.m2.1.1.cmml" xref="Sx3.SSx3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="Sx3.SSx3.p1.2.m2.1.1.1.cmml" xref="Sx3.SSx3.p1.2.m2.1.1">subscript</csymbol><ci id="Sx3.SSx3.p1.2.m2.1.1.2.cmml" xref="Sx3.SSx3.p1.2.m2.1.1.2">ğ¼</ci><ci id="Sx3.SSx3.p1.2.m2.1.1.3.cmml" xref="Sx3.SSx3.p1.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p1.2.m2.1c">I_{m}</annotation></semantics></math>) images were concatenated into a two-channel volumetric image and fed to the VoxelMorph model. The model returns the displacement map (<math id="Sx3.SSx3.p1.3.m3.1" class="ltx_Math" alttext="\Phi" display="inline"><semantics id="Sx3.SSx3.p1.3.m3.1a"><mi mathvariant="normal" id="Sx3.SSx3.p1.3.m3.1.1" xref="Sx3.SSx3.p1.3.m3.1.1.cmml">Î¦</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p1.3.m3.1b"><ci id="Sx3.SSx3.p1.3.m3.1.1.cmml" xref="Sx3.SSx3.p1.3.m3.1.1">Î¦</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p1.3.m3.1c">\Phi</annotation></semantics></math>) i.e., a volume image with three channels, which describes the relative displacement of each voxel along each of the three coordinate axes. Finally, the predicted fixed image (<math id="Sx3.SSx3.p1.4.m4.1" class="ltx_Math" alttext="I_{p}" display="inline"><semantics id="Sx3.SSx3.p1.4.m4.1a"><msub id="Sx3.SSx3.p1.4.m4.1.1" xref="Sx3.SSx3.p1.4.m4.1.1.cmml"><mi id="Sx3.SSx3.p1.4.m4.1.1.2" xref="Sx3.SSx3.p1.4.m4.1.1.2.cmml">I</mi><mi id="Sx3.SSx3.p1.4.m4.1.1.3" xref="Sx3.SSx3.p1.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p1.4.m4.1b"><apply id="Sx3.SSx3.p1.4.m4.1.1.cmml" xref="Sx3.SSx3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="Sx3.SSx3.p1.4.m4.1.1.1.cmml" xref="Sx3.SSx3.p1.4.m4.1.1">subscript</csymbol><ci id="Sx3.SSx3.p1.4.m4.1.1.2.cmml" xref="Sx3.SSx3.p1.4.m4.1.1.2">ğ¼</ci><ci id="Sx3.SSx3.p1.4.m4.1.1.3.cmml" xref="Sx3.SSx3.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p1.4.m4.1c">I_{p}</annotation></semantics></math>) is reconstructed by interpolating voxels on the moving image at the locations defined by the displacement map. This way, the model can be trained by comparing the predicted image with the original fixed image.</p>
</div>
<figure id="Sx3.F1" class="ltx_figure"><img src="/html/2211.15717/assets/x1.png" id="Sx3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Sx3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Fig 1</span>: </span><span id="Sx3.F1.3.2" class="ltx_text" style="font-size:90%;">
Proposed deep image registration pipeline. Generation of artificial moving images on-the-fly, prediction of the displacement map using a modified U-Net, and finding the optimal loss weighting automatically using uncertainty weighting. </span></figcaption>
</figure>
<div id="Sx3.SSx3.p2" class="ltx_para">
<p id="Sx3.SSx3.p2.2" class="ltx_p">When provided, the segmentations (<math id="Sx3.SSx3.p2.1.m1.1" class="ltx_Math" alttext="S_{m}" display="inline"><semantics id="Sx3.SSx3.p2.1.m1.1a"><msub id="Sx3.SSx3.p2.1.m1.1.1" xref="Sx3.SSx3.p2.1.m1.1.1.cmml"><mi id="Sx3.SSx3.p2.1.m1.1.1.2" xref="Sx3.SSx3.p2.1.m1.1.1.2.cmml">S</mi><mi id="Sx3.SSx3.p2.1.m1.1.1.3" xref="Sx3.SSx3.p2.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p2.1.m1.1b"><apply id="Sx3.SSx3.p2.1.m1.1.1.cmml" xref="Sx3.SSx3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx3.p2.1.m1.1.1.1.cmml" xref="Sx3.SSx3.p2.1.m1.1.1">subscript</csymbol><ci id="Sx3.SSx3.p2.1.m1.1.1.2.cmml" xref="Sx3.SSx3.p2.1.m1.1.1.2">ğ‘†</ci><ci id="Sx3.SSx3.p2.1.m1.1.1.3.cmml" xref="Sx3.SSx3.p2.1.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p2.1.m1.1c">S_{m}</annotation></semantics></math>) are likewise updated using the same displacement map. The symmetric U-Net architecture was designed with six contraction blocks featuring 32, 64, 128, 256, 512, and 1024 convolution filters respectively. Each contracting block consisted of a convolution with kernel size <math id="Sx3.SSx3.p2.2.m2.1" class="ltx_Math" alttext="3\times 3\times 3" display="inline"><semantics id="Sx3.SSx3.p2.2.m2.1a"><mrow id="Sx3.SSx3.p2.2.m2.1.1" xref="Sx3.SSx3.p2.2.m2.1.1.cmml"><mn id="Sx3.SSx3.p2.2.m2.1.1.2" xref="Sx3.SSx3.p2.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx3.p2.2.m2.1.1.1" xref="Sx3.SSx3.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx3.p2.2.m2.1.1.3" xref="Sx3.SSx3.p2.2.m2.1.1.3.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx3.p2.2.m2.1.1.1a" xref="Sx3.SSx3.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="Sx3.SSx3.p2.2.m2.1.1.4" xref="Sx3.SSx3.p2.2.m2.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx3.p2.2.m2.1b"><apply id="Sx3.SSx3.p2.2.m2.1.1.cmml" xref="Sx3.SSx3.p2.2.m2.1.1"><times id="Sx3.SSx3.p2.2.m2.1.1.1.cmml" xref="Sx3.SSx3.p2.2.m2.1.1.1"></times><cn type="integer" id="Sx3.SSx3.p2.2.m2.1.1.2.cmml" xref="Sx3.SSx3.p2.2.m2.1.1.2">3</cn><cn type="integer" id="Sx3.SSx3.p2.2.m2.1.1.3.cmml" xref="Sx3.SSx3.p2.2.m2.1.1.3">3</cn><cn type="integer" id="Sx3.SSx3.p2.2.m2.1.1.4.cmml" xref="Sx3.SSx3.p2.2.m2.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx3.p2.2.m2.1c">3\times 3\times 3</annotation></semantics></math> and a LeakyReLU activation function, followed by max pooling with stride 2. The decoder blocks consisted of a convolution and a LeakyReLU activation function, followed by a nearest neighbour interpolation upsampling layer. The output convolutional layer, named Head in <a href="#Sx3.F1" title="In Model architecture â€£ Materials and methods" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, was set to two consecutive convolutions of 16 filters with LeakyReLU activation function. A convolution layer with three filters was used as the output layer. This produces a displacement map with the same size as the input images and three channels, one for each displacement dimension.</p>
</div>
</section>
<section id="Sx3.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Model training</h3>

<div id="Sx3.SSx4.p1" class="ltx_para">
<p id="Sx3.SSx4.p1.1" class="ltx_p">The registration model was trained in a weakly-supervised manner, as proposed by Hu <span id="Sx3.SSx4.p1.1.1" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Instead of evaluating the displacement map directly as in traditional supervised training, only the final registration results were assessed during training.</p>
</div>
<div id="Sx3.SSx4.p2" class="ltx_para">
<p id="Sx3.SSx4.p2.5" class="ltx_p">Due to the complexity of the task at hand, a single loss function would provide limited insight of the registration result, therefore a combination of well-known loss functions was deemed necessary. Balancing the contribution of these operators can be challenging, time consuming, and prone to errors. We therefore used uncertainty weighting (UW)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, which combines losses as a weighted sum and enables the loss weights to be tuned dynamically during backpropagation. Our loss function <math id="Sx3.SSx4.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="Sx3.SSx4.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="Sx3.SSx4.p2.1.m1.1.1" xref="Sx3.SSx4.p2.1.m1.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p2.1.m1.1b"><ci id="Sx3.SSx4.p2.1.m1.1.1.cmml" xref="Sx3.SSx4.p2.1.m1.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p2.1.m1.1c">\mathcal{L}</annotation></semantics></math> was implemented as a custom layer, and consists of a weighted sum of <math id="Sx3.SSx4.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="Sx3.SSx4.p2.2.m2.1a"><mi id="Sx3.SSx4.p2.2.m2.1.1" xref="Sx3.SSx4.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p2.2.m2.1b"><ci id="Sx3.SSx4.p2.2.m2.1.1.cmml" xref="Sx3.SSx4.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p2.2.m2.1c">N</annotation></semantics></math> loss functions <math id="Sx3.SSx4.p2.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="Sx3.SSx4.p2.3.m3.1a"><mi id="Sx3.SSx4.p2.3.m3.1.1" xref="Sx3.SSx4.p2.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p2.3.m3.1b"><ci id="Sx3.SSx4.p2.3.m3.1.1.cmml" xref="Sx3.SSx4.p2.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p2.3.m3.1c">L</annotation></semantics></math> and <math id="Sx3.SSx4.p2.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="Sx3.SSx4.p2.4.m4.1a"><mi id="Sx3.SSx4.p2.4.m4.1.1" xref="Sx3.SSx4.p2.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p2.4.m4.1b"><ci id="Sx3.SSx4.p2.4.m4.1.1.cmml" xref="Sx3.SSx4.p2.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p2.4.m4.1c">M</annotation></semantics></math> regularisers <math id="Sx3.SSx4.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="Sx3.SSx4.p2.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="Sx3.SSx4.p2.5.m5.1.1" xref="Sx3.SSx4.p2.5.m5.1.1.cmml">â„›</mi><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p2.5.m5.1b"><ci id="Sx3.SSx4.p2.5.m5.1.1.cmml" xref="Sx3.SSx4.p2.5.m5.1.1">â„›</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p2.5.m5.1c">\mathcal{R}</annotation></semantics></math>:</p>
<table id="Sx3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx3.E1.m1.4" class="ltx_Math" alttext="\mathcal{L}\left(\textbf{y}_{t},\textbf{y}_{p}\right)=\sum_{i=1}^{N}\omega_{i}L_{i}\left(\textbf{y}_{t},\textbf{y}_{p}\right)+\sum_{j=1}^{M}\lambda_{j}\mathcal{R}_{j}" display="block"><semantics id="Sx3.E1.m1.4a"><mrow id="Sx3.E1.m1.4.4" xref="Sx3.E1.m1.4.4.cmml"><mrow id="Sx3.E1.m1.2.2.2" xref="Sx3.E1.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx3.E1.m1.2.2.2.4" xref="Sx3.E1.m1.2.2.2.4.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="Sx3.E1.m1.2.2.2.3" xref="Sx3.E1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="Sx3.E1.m1.2.2.2.2.2" xref="Sx3.E1.m1.2.2.2.2.3.cmml"><mo id="Sx3.E1.m1.2.2.2.2.2.3" xref="Sx3.E1.m1.2.2.2.2.3.cmml">(</mo><msub id="Sx3.E1.m1.1.1.1.1.1.1" xref="Sx3.E1.m1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.1.1.1.1.1.1.2" xref="Sx3.E1.m1.1.1.1.1.1.1.2a.cmml">y</mtext><mi id="Sx3.E1.m1.1.1.1.1.1.1.3" xref="Sx3.E1.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="Sx3.E1.m1.2.2.2.2.2.4" xref="Sx3.E1.m1.2.2.2.2.3.cmml">,</mo><msub id="Sx3.E1.m1.2.2.2.2.2.2" xref="Sx3.E1.m1.2.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.2.2.2.2.2.2.2" xref="Sx3.E1.m1.2.2.2.2.2.2.2a.cmml">y</mtext><mi id="Sx3.E1.m1.2.2.2.2.2.2.3" xref="Sx3.E1.m1.2.2.2.2.2.2.3.cmml">p</mi></msub><mo id="Sx3.E1.m1.2.2.2.2.2.5" xref="Sx3.E1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="Sx3.E1.m1.4.4.5" xref="Sx3.E1.m1.4.4.5.cmml">=</mo><mrow id="Sx3.E1.m1.4.4.4" xref="Sx3.E1.m1.4.4.4.cmml"><mrow id="Sx3.E1.m1.4.4.4.2" xref="Sx3.E1.m1.4.4.4.2.cmml"><munderover id="Sx3.E1.m1.4.4.4.2.3" xref="Sx3.E1.m1.4.4.4.2.3.cmml"><mo movablelimits="false" id="Sx3.E1.m1.4.4.4.2.3.2.2" xref="Sx3.E1.m1.4.4.4.2.3.2.2.cmml">âˆ‘</mo><mrow id="Sx3.E1.m1.4.4.4.2.3.2.3" xref="Sx3.E1.m1.4.4.4.2.3.2.3.cmml"><mi id="Sx3.E1.m1.4.4.4.2.3.2.3.2" xref="Sx3.E1.m1.4.4.4.2.3.2.3.2.cmml">i</mi><mo id="Sx3.E1.m1.4.4.4.2.3.2.3.1" xref="Sx3.E1.m1.4.4.4.2.3.2.3.1.cmml">=</mo><mn id="Sx3.E1.m1.4.4.4.2.3.2.3.3" xref="Sx3.E1.m1.4.4.4.2.3.2.3.3.cmml">1</mn></mrow><mi id="Sx3.E1.m1.4.4.4.2.3.3" xref="Sx3.E1.m1.4.4.4.2.3.3.cmml">N</mi></munderover><mrow id="Sx3.E1.m1.4.4.4.2.2" xref="Sx3.E1.m1.4.4.4.2.2.cmml"><msub id="Sx3.E1.m1.4.4.4.2.2.4" xref="Sx3.E1.m1.4.4.4.2.2.4.cmml"><mi id="Sx3.E1.m1.4.4.4.2.2.4.2" xref="Sx3.E1.m1.4.4.4.2.2.4.2.cmml">Ï‰</mi><mi id="Sx3.E1.m1.4.4.4.2.2.4.3" xref="Sx3.E1.m1.4.4.4.2.2.4.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="Sx3.E1.m1.4.4.4.2.2.3" xref="Sx3.E1.m1.4.4.4.2.2.3.cmml">â€‹</mo><msub id="Sx3.E1.m1.4.4.4.2.2.5" xref="Sx3.E1.m1.4.4.4.2.2.5.cmml"><mi id="Sx3.E1.m1.4.4.4.2.2.5.2" xref="Sx3.E1.m1.4.4.4.2.2.5.2.cmml">L</mi><mi id="Sx3.E1.m1.4.4.4.2.2.5.3" xref="Sx3.E1.m1.4.4.4.2.2.5.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="Sx3.E1.m1.4.4.4.2.2.3a" xref="Sx3.E1.m1.4.4.4.2.2.3.cmml">â€‹</mo><mrow id="Sx3.E1.m1.4.4.4.2.2.2.2" xref="Sx3.E1.m1.4.4.4.2.2.2.3.cmml"><mo id="Sx3.E1.m1.4.4.4.2.2.2.2.3" xref="Sx3.E1.m1.4.4.4.2.2.2.3.cmml">(</mo><msub id="Sx3.E1.m1.3.3.3.1.1.1.1.1" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.3.3.3.1.1.1.1.1.2" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.2a.cmml">y</mtext><mi id="Sx3.E1.m1.3.3.3.1.1.1.1.1.3" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.3.cmml">t</mi></msub><mo id="Sx3.E1.m1.4.4.4.2.2.2.2.4" xref="Sx3.E1.m1.4.4.4.2.2.2.3.cmml">,</mo><msub id="Sx3.E1.m1.4.4.4.2.2.2.2.2" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.4.4.4.2.2.2.2.2.2" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.2a.cmml">y</mtext><mi id="Sx3.E1.m1.4.4.4.2.2.2.2.2.3" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.3.cmml">p</mi></msub><mo id="Sx3.E1.m1.4.4.4.2.2.2.2.5" xref="Sx3.E1.m1.4.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.055em" id="Sx3.E1.m1.4.4.4.3" xref="Sx3.E1.m1.4.4.4.3.cmml">+</mo><mrow id="Sx3.E1.m1.4.4.4.4" xref="Sx3.E1.m1.4.4.4.4.cmml"><munderover id="Sx3.E1.m1.4.4.4.4.1" xref="Sx3.E1.m1.4.4.4.4.1.cmml"><mo movablelimits="false" id="Sx3.E1.m1.4.4.4.4.1.2.2" xref="Sx3.E1.m1.4.4.4.4.1.2.2.cmml">âˆ‘</mo><mrow id="Sx3.E1.m1.4.4.4.4.1.2.3" xref="Sx3.E1.m1.4.4.4.4.1.2.3.cmml"><mi id="Sx3.E1.m1.4.4.4.4.1.2.3.2" xref="Sx3.E1.m1.4.4.4.4.1.2.3.2.cmml">j</mi><mo id="Sx3.E1.m1.4.4.4.4.1.2.3.1" xref="Sx3.E1.m1.4.4.4.4.1.2.3.1.cmml">=</mo><mn id="Sx3.E1.m1.4.4.4.4.1.2.3.3" xref="Sx3.E1.m1.4.4.4.4.1.2.3.3.cmml">1</mn></mrow><mi id="Sx3.E1.m1.4.4.4.4.1.3" xref="Sx3.E1.m1.4.4.4.4.1.3.cmml">M</mi></munderover><mrow id="Sx3.E1.m1.4.4.4.4.2" xref="Sx3.E1.m1.4.4.4.4.2.cmml"><msub id="Sx3.E1.m1.4.4.4.4.2.2" xref="Sx3.E1.m1.4.4.4.4.2.2.cmml"><mi id="Sx3.E1.m1.4.4.4.4.2.2.2" xref="Sx3.E1.m1.4.4.4.4.2.2.2.cmml">Î»</mi><mi id="Sx3.E1.m1.4.4.4.4.2.2.3" xref="Sx3.E1.m1.4.4.4.4.2.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="Sx3.E1.m1.4.4.4.4.2.1" xref="Sx3.E1.m1.4.4.4.4.2.1.cmml">â€‹</mo><msub id="Sx3.E1.m1.4.4.4.4.2.3" xref="Sx3.E1.m1.4.4.4.4.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx3.E1.m1.4.4.4.4.2.3.2" xref="Sx3.E1.m1.4.4.4.4.2.3.2.cmml">â„›</mi><mi id="Sx3.E1.m1.4.4.4.4.2.3.3" xref="Sx3.E1.m1.4.4.4.4.2.3.3.cmml">j</mi></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx3.E1.m1.4b"><apply id="Sx3.E1.m1.4.4.cmml" xref="Sx3.E1.m1.4.4"><eq id="Sx3.E1.m1.4.4.5.cmml" xref="Sx3.E1.m1.4.4.5"></eq><apply id="Sx3.E1.m1.2.2.2.cmml" xref="Sx3.E1.m1.2.2.2"><times id="Sx3.E1.m1.2.2.2.3.cmml" xref="Sx3.E1.m1.2.2.2.3"></times><ci id="Sx3.E1.m1.2.2.2.4.cmml" xref="Sx3.E1.m1.2.2.2.4">â„’</ci><interval closure="open" id="Sx3.E1.m1.2.2.2.2.3.cmml" xref="Sx3.E1.m1.2.2.2.2.2"><apply id="Sx3.E1.m1.1.1.1.1.1.1.cmml" xref="Sx3.E1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx3.E1.m1.1.1.1.1.1.1.1.cmml" xref="Sx3.E1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="Sx3.E1.m1.1.1.1.1.1.1.2a.cmml" xref="Sx3.E1.m1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.1.1.1.1.1.1.2.cmml" xref="Sx3.E1.m1.1.1.1.1.1.1.2">y</mtext></ci><ci id="Sx3.E1.m1.1.1.1.1.1.1.3.cmml" xref="Sx3.E1.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="Sx3.E1.m1.2.2.2.2.2.2.cmml" xref="Sx3.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx3.E1.m1.2.2.2.2.2.2.1.cmml" xref="Sx3.E1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="Sx3.E1.m1.2.2.2.2.2.2.2a.cmml" xref="Sx3.E1.m1.2.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.2.2.2.2.2.2.2.cmml" xref="Sx3.E1.m1.2.2.2.2.2.2.2">y</mtext></ci><ci id="Sx3.E1.m1.2.2.2.2.2.2.3.cmml" xref="Sx3.E1.m1.2.2.2.2.2.2.3">ğ‘</ci></apply></interval></apply><apply id="Sx3.E1.m1.4.4.4.cmml" xref="Sx3.E1.m1.4.4.4"><plus id="Sx3.E1.m1.4.4.4.3.cmml" xref="Sx3.E1.m1.4.4.4.3"></plus><apply id="Sx3.E1.m1.4.4.4.2.cmml" xref="Sx3.E1.m1.4.4.4.2"><apply id="Sx3.E1.m1.4.4.4.2.3.cmml" xref="Sx3.E1.m1.4.4.4.2.3"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.2.3.1.cmml" xref="Sx3.E1.m1.4.4.4.2.3">superscript</csymbol><apply id="Sx3.E1.m1.4.4.4.2.3.2.cmml" xref="Sx3.E1.m1.4.4.4.2.3"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.2.3.2.1.cmml" xref="Sx3.E1.m1.4.4.4.2.3">subscript</csymbol><sum id="Sx3.E1.m1.4.4.4.2.3.2.2.cmml" xref="Sx3.E1.m1.4.4.4.2.3.2.2"></sum><apply id="Sx3.E1.m1.4.4.4.2.3.2.3.cmml" xref="Sx3.E1.m1.4.4.4.2.3.2.3"><eq id="Sx3.E1.m1.4.4.4.2.3.2.3.1.cmml" xref="Sx3.E1.m1.4.4.4.2.3.2.3.1"></eq><ci id="Sx3.E1.m1.4.4.4.2.3.2.3.2.cmml" xref="Sx3.E1.m1.4.4.4.2.3.2.3.2">ğ‘–</ci><cn type="integer" id="Sx3.E1.m1.4.4.4.2.3.2.3.3.cmml" xref="Sx3.E1.m1.4.4.4.2.3.2.3.3">1</cn></apply></apply><ci id="Sx3.E1.m1.4.4.4.2.3.3.cmml" xref="Sx3.E1.m1.4.4.4.2.3.3">ğ‘</ci></apply><apply id="Sx3.E1.m1.4.4.4.2.2.cmml" xref="Sx3.E1.m1.4.4.4.2.2"><times id="Sx3.E1.m1.4.4.4.2.2.3.cmml" xref="Sx3.E1.m1.4.4.4.2.2.3"></times><apply id="Sx3.E1.m1.4.4.4.2.2.4.cmml" xref="Sx3.E1.m1.4.4.4.2.2.4"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.2.2.4.1.cmml" xref="Sx3.E1.m1.4.4.4.2.2.4">subscript</csymbol><ci id="Sx3.E1.m1.4.4.4.2.2.4.2.cmml" xref="Sx3.E1.m1.4.4.4.2.2.4.2">ğœ”</ci><ci id="Sx3.E1.m1.4.4.4.2.2.4.3.cmml" xref="Sx3.E1.m1.4.4.4.2.2.4.3">ğ‘–</ci></apply><apply id="Sx3.E1.m1.4.4.4.2.2.5.cmml" xref="Sx3.E1.m1.4.4.4.2.2.5"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.2.2.5.1.cmml" xref="Sx3.E1.m1.4.4.4.2.2.5">subscript</csymbol><ci id="Sx3.E1.m1.4.4.4.2.2.5.2.cmml" xref="Sx3.E1.m1.4.4.4.2.2.5.2">ğ¿</ci><ci id="Sx3.E1.m1.4.4.4.2.2.5.3.cmml" xref="Sx3.E1.m1.4.4.4.2.2.5.3">ğ‘–</ci></apply><interval closure="open" id="Sx3.E1.m1.4.4.4.2.2.2.3.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2"><apply id="Sx3.E1.m1.3.3.3.1.1.1.1.1.cmml" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx3.E1.m1.3.3.3.1.1.1.1.1.1.cmml" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1">subscript</csymbol><ci id="Sx3.E1.m1.3.3.3.1.1.1.1.1.2a.cmml" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.3.3.3.1.1.1.1.1.2.cmml" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.2">y</mtext></ci><ci id="Sx3.E1.m1.3.3.3.1.1.1.1.1.3.cmml" xref="Sx3.E1.m1.3.3.3.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="Sx3.E1.m1.4.4.4.2.2.2.2.2.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.2.2.2.2.2.1.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2">subscript</csymbol><ci id="Sx3.E1.m1.4.4.4.2.2.2.2.2.2a.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="Sx3.E1.m1.4.4.4.2.2.2.2.2.2.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.2">y</mtext></ci><ci id="Sx3.E1.m1.4.4.4.2.2.2.2.2.3.cmml" xref="Sx3.E1.m1.4.4.4.2.2.2.2.2.3">ğ‘</ci></apply></interval></apply></apply><apply id="Sx3.E1.m1.4.4.4.4.cmml" xref="Sx3.E1.m1.4.4.4.4"><apply id="Sx3.E1.m1.4.4.4.4.1.cmml" xref="Sx3.E1.m1.4.4.4.4.1"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.4.1.1.cmml" xref="Sx3.E1.m1.4.4.4.4.1">superscript</csymbol><apply id="Sx3.E1.m1.4.4.4.4.1.2.cmml" xref="Sx3.E1.m1.4.4.4.4.1"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.4.1.2.1.cmml" xref="Sx3.E1.m1.4.4.4.4.1">subscript</csymbol><sum id="Sx3.E1.m1.4.4.4.4.1.2.2.cmml" xref="Sx3.E1.m1.4.4.4.4.1.2.2"></sum><apply id="Sx3.E1.m1.4.4.4.4.1.2.3.cmml" xref="Sx3.E1.m1.4.4.4.4.1.2.3"><eq id="Sx3.E1.m1.4.4.4.4.1.2.3.1.cmml" xref="Sx3.E1.m1.4.4.4.4.1.2.3.1"></eq><ci id="Sx3.E1.m1.4.4.4.4.1.2.3.2.cmml" xref="Sx3.E1.m1.4.4.4.4.1.2.3.2">ğ‘—</ci><cn type="integer" id="Sx3.E1.m1.4.4.4.4.1.2.3.3.cmml" xref="Sx3.E1.m1.4.4.4.4.1.2.3.3">1</cn></apply></apply><ci id="Sx3.E1.m1.4.4.4.4.1.3.cmml" xref="Sx3.E1.m1.4.4.4.4.1.3">ğ‘€</ci></apply><apply id="Sx3.E1.m1.4.4.4.4.2.cmml" xref="Sx3.E1.m1.4.4.4.4.2"><times id="Sx3.E1.m1.4.4.4.4.2.1.cmml" xref="Sx3.E1.m1.4.4.4.4.2.1"></times><apply id="Sx3.E1.m1.4.4.4.4.2.2.cmml" xref="Sx3.E1.m1.4.4.4.4.2.2"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.4.2.2.1.cmml" xref="Sx3.E1.m1.4.4.4.4.2.2">subscript</csymbol><ci id="Sx3.E1.m1.4.4.4.4.2.2.2.cmml" xref="Sx3.E1.m1.4.4.4.4.2.2.2">ğœ†</ci><ci id="Sx3.E1.m1.4.4.4.4.2.2.3.cmml" xref="Sx3.E1.m1.4.4.4.4.2.2.3">ğ‘—</ci></apply><apply id="Sx3.E1.m1.4.4.4.4.2.3.cmml" xref="Sx3.E1.m1.4.4.4.4.2.3"><csymbol cd="ambiguous" id="Sx3.E1.m1.4.4.4.4.2.3.1.cmml" xref="Sx3.E1.m1.4.4.4.4.2.3">subscript</csymbol><ci id="Sx3.E1.m1.4.4.4.4.2.3.2.cmml" xref="Sx3.E1.m1.4.4.4.4.2.3.2">â„›</ci><ci id="Sx3.E1.m1.4.4.4.4.2.3.3.cmml" xref="Sx3.E1.m1.4.4.4.4.2.3.3">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.E1.m1.4c">\mathcal{L}\left(\textbf{y}_{t},\textbf{y}_{p}\right)=\sum_{i=1}^{N}\omega_{i}L_{i}\left(\textbf{y}_{t},\textbf{y}_{p}\right)+\sum_{j=1}^{M}\lambda_{j}\mathcal{R}_{j}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="Sx3.SSx4.p3" class="ltx_para">
<p id="Sx3.SSx4.p3.4" class="ltx_p">such that <math id="Sx3.SSx4.p3.1.m1.1" class="ltx_Math" alttext="\sum\omega_{i}=\sum\lambda_{i}=1" display="inline"><semantics id="Sx3.SSx4.p3.1.m1.1a"><mrow id="Sx3.SSx4.p3.1.m1.1.1" xref="Sx3.SSx4.p3.1.m1.1.1.cmml"><mrow id="Sx3.SSx4.p3.1.m1.1.1.2" xref="Sx3.SSx4.p3.1.m1.1.1.2.cmml"><mo id="Sx3.SSx4.p3.1.m1.1.1.2.1" xref="Sx3.SSx4.p3.1.m1.1.1.2.1.cmml">âˆ‘</mo><msub id="Sx3.SSx4.p3.1.m1.1.1.2.2" xref="Sx3.SSx4.p3.1.m1.1.1.2.2.cmml"><mi id="Sx3.SSx4.p3.1.m1.1.1.2.2.2" xref="Sx3.SSx4.p3.1.m1.1.1.2.2.2.cmml">Ï‰</mi><mi id="Sx3.SSx4.p3.1.m1.1.1.2.2.3" xref="Sx3.SSx4.p3.1.m1.1.1.2.2.3.cmml">i</mi></msub></mrow><mo rspace="0.111em" id="Sx3.SSx4.p3.1.m1.1.1.3" xref="Sx3.SSx4.p3.1.m1.1.1.3.cmml">=</mo><mrow id="Sx3.SSx4.p3.1.m1.1.1.4" xref="Sx3.SSx4.p3.1.m1.1.1.4.cmml"><mo id="Sx3.SSx4.p3.1.m1.1.1.4.1" xref="Sx3.SSx4.p3.1.m1.1.1.4.1.cmml">âˆ‘</mo><msub id="Sx3.SSx4.p3.1.m1.1.1.4.2" xref="Sx3.SSx4.p3.1.m1.1.1.4.2.cmml"><mi id="Sx3.SSx4.p3.1.m1.1.1.4.2.2" xref="Sx3.SSx4.p3.1.m1.1.1.4.2.2.cmml">Î»</mi><mi id="Sx3.SSx4.p3.1.m1.1.1.4.2.3" xref="Sx3.SSx4.p3.1.m1.1.1.4.2.3.cmml">i</mi></msub></mrow><mo id="Sx3.SSx4.p3.1.m1.1.1.5" xref="Sx3.SSx4.p3.1.m1.1.1.5.cmml">=</mo><mn id="Sx3.SSx4.p3.1.m1.1.1.6" xref="Sx3.SSx4.p3.1.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p3.1.m1.1b"><apply id="Sx3.SSx4.p3.1.m1.1.1.cmml" xref="Sx3.SSx4.p3.1.m1.1.1"><and id="Sx3.SSx4.p3.1.m1.1.1a.cmml" xref="Sx3.SSx4.p3.1.m1.1.1"></and><apply id="Sx3.SSx4.p3.1.m1.1.1b.cmml" xref="Sx3.SSx4.p3.1.m1.1.1"><eq id="Sx3.SSx4.p3.1.m1.1.1.3.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.3"></eq><apply id="Sx3.SSx4.p3.1.m1.1.1.2.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2"><sum id="Sx3.SSx4.p3.1.m1.1.1.2.1.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2.1"></sum><apply id="Sx3.SSx4.p3.1.m1.1.1.2.2.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="Sx3.SSx4.p3.1.m1.1.1.2.2.1.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2.2">subscript</csymbol><ci id="Sx3.SSx4.p3.1.m1.1.1.2.2.2.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2.2.2">ğœ”</ci><ci id="Sx3.SSx4.p3.1.m1.1.1.2.2.3.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.2.2.3">ğ‘–</ci></apply></apply><apply id="Sx3.SSx4.p3.1.m1.1.1.4.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4"><sum id="Sx3.SSx4.p3.1.m1.1.1.4.1.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4.1"></sum><apply id="Sx3.SSx4.p3.1.m1.1.1.4.2.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4.2"><csymbol cd="ambiguous" id="Sx3.SSx4.p3.1.m1.1.1.4.2.1.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4.2">subscript</csymbol><ci id="Sx3.SSx4.p3.1.m1.1.1.4.2.2.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4.2.2">ğœ†</ci><ci id="Sx3.SSx4.p3.1.m1.1.1.4.2.3.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.4.2.3">ğ‘–</ci></apply></apply></apply><apply id="Sx3.SSx4.p3.1.m1.1.1c.cmml" xref="Sx3.SSx4.p3.1.m1.1.1"><eq id="Sx3.SSx4.p3.1.m1.1.1.5.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.5"></eq><share href="#Sx3.SSx4.p3.1.m1.1.1.4.cmml" id="Sx3.SSx4.p3.1.m1.1.1d.cmml" xref="Sx3.SSx4.p3.1.m1.1.1"></share><cn type="integer" id="Sx3.SSx4.p3.1.m1.1.1.6.cmml" xref="Sx3.SSx4.p3.1.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p3.1.m1.1c">\sum\omega_{i}=\sum\lambda_{i}=1</annotation></semantics></math>. By default, the weights <math id="Sx3.SSx4.p3.2.m2.1" class="ltx_Math" alttext="\omega_{i}" display="inline"><semantics id="Sx3.SSx4.p3.2.m2.1a"><msub id="Sx3.SSx4.p3.2.m2.1.1" xref="Sx3.SSx4.p3.2.m2.1.1.cmml"><mi id="Sx3.SSx4.p3.2.m2.1.1.2" xref="Sx3.SSx4.p3.2.m2.1.1.2.cmml">Ï‰</mi><mi id="Sx3.SSx4.p3.2.m2.1.1.3" xref="Sx3.SSx4.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p3.2.m2.1b"><apply id="Sx3.SSx4.p3.2.m2.1.1.cmml" xref="Sx3.SSx4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="Sx3.SSx4.p3.2.m2.1.1.1.cmml" xref="Sx3.SSx4.p3.2.m2.1.1">subscript</csymbol><ci id="Sx3.SSx4.p3.2.m2.1.1.2.cmml" xref="Sx3.SSx4.p3.2.m2.1.1.2">ğœ”</ci><ci id="Sx3.SSx4.p3.2.m2.1.1.3.cmml" xref="Sx3.SSx4.p3.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p3.2.m2.1c">\omega_{i}</annotation></semantics></math> and <math id="Sx3.SSx4.p3.3.m3.1" class="ltx_Math" alttext="\lambda_{i}" display="inline"><semantics id="Sx3.SSx4.p3.3.m3.1a"><msub id="Sx3.SSx4.p3.3.m3.1.1" xref="Sx3.SSx4.p3.3.m3.1.1.cmml"><mi id="Sx3.SSx4.p3.3.m3.1.1.2" xref="Sx3.SSx4.p3.3.m3.1.1.2.cmml">Î»</mi><mi id="Sx3.SSx4.p3.3.m3.1.1.3" xref="Sx3.SSx4.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p3.3.m3.1b"><apply id="Sx3.SSx4.p3.3.m3.1.1.cmml" xref="Sx3.SSx4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="Sx3.SSx4.p3.3.m3.1.1.1.cmml" xref="Sx3.SSx4.p3.3.m3.1.1">subscript</csymbol><ci id="Sx3.SSx4.p3.3.m3.1.1.2.cmml" xref="Sx3.SSx4.p3.3.m3.1.1.2">ğœ†</ci><ci id="Sx3.SSx4.p3.3.m3.1.1.3.cmml" xref="Sx3.SSx4.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p3.3.m3.1c">\lambda_{i}</annotation></semantics></math> were initialised to equally contribute in the weighted sum, but can be set manually from a priori knowledge on initial loss and regularisation values. In our experiments, the default initialisation for the loss weights was used, except for the regularisation term, which was initialised to <math id="Sx3.SSx4.p3.4.m4.1" class="ltx_Math" alttext="5\times 10^{-3}" display="inline"><semantics id="Sx3.SSx4.p3.4.m4.1a"><mrow id="Sx3.SSx4.p3.4.m4.1.1" xref="Sx3.SSx4.p3.4.m4.1.1.cmml"><mn id="Sx3.SSx4.p3.4.m4.1.1.2" xref="Sx3.SSx4.p3.4.m4.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="Sx3.SSx4.p3.4.m4.1.1.1" xref="Sx3.SSx4.p3.4.m4.1.1.1.cmml">Ã—</mo><msup id="Sx3.SSx4.p3.4.m4.1.1.3" xref="Sx3.SSx4.p3.4.m4.1.1.3.cmml"><mn id="Sx3.SSx4.p3.4.m4.1.1.3.2" xref="Sx3.SSx4.p3.4.m4.1.1.3.2.cmml">10</mn><mrow id="Sx3.SSx4.p3.4.m4.1.1.3.3" xref="Sx3.SSx4.p3.4.m4.1.1.3.3.cmml"><mo id="Sx3.SSx4.p3.4.m4.1.1.3.3a" xref="Sx3.SSx4.p3.4.m4.1.1.3.3.cmml">âˆ’</mo><mn id="Sx3.SSx4.p3.4.m4.1.1.3.3.2" xref="Sx3.SSx4.p3.4.m4.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p3.4.m4.1b"><apply id="Sx3.SSx4.p3.4.m4.1.1.cmml" xref="Sx3.SSx4.p3.4.m4.1.1"><times id="Sx3.SSx4.p3.4.m4.1.1.1.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.1"></times><cn type="integer" id="Sx3.SSx4.p3.4.m4.1.1.2.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.2">5</cn><apply id="Sx3.SSx4.p3.4.m4.1.1.3.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="Sx3.SSx4.p3.4.m4.1.1.3.1.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3">superscript</csymbol><cn type="integer" id="Sx3.SSx4.p3.4.m4.1.1.3.2.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3.2">10</cn><apply id="Sx3.SSx4.p3.4.m4.1.1.3.3.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3.3"><minus id="Sx3.SSx4.p3.4.m4.1.1.3.3.1.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3.3"></minus><cn type="integer" id="Sx3.SSx4.p3.4.m4.1.1.3.3.2.cmml" xref="Sx3.SSx4.p3.4.m4.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p3.4.m4.1c">5\times 10^{-3}</annotation></semantics></math>.</p>
</div>
<div id="Sx3.SSx4.p4" class="ltx_para">
<p id="Sx3.SSx4.p4.2" class="ltx_p">For training the neural networks we used the Adam optimiser. Gradient accumulation was performed to overcome memory constraints and enable larger batch training. The batch size was set to one, but artificially increased by accumulating eight mini-batch gradients. The learning rate was set to <math id="Sx3.SSx4.p4.1.m1.1" class="ltx_Math" alttext="10^{-3}" display="inline"><semantics id="Sx3.SSx4.p4.1.m1.1a"><msup id="Sx3.SSx4.p4.1.m1.1.1" xref="Sx3.SSx4.p4.1.m1.1.1.cmml"><mn id="Sx3.SSx4.p4.1.m1.1.1.2" xref="Sx3.SSx4.p4.1.m1.1.1.2.cmml">10</mn><mrow id="Sx3.SSx4.p4.1.m1.1.1.3" xref="Sx3.SSx4.p4.1.m1.1.1.3.cmml"><mo id="Sx3.SSx4.p4.1.m1.1.1.3a" xref="Sx3.SSx4.p4.1.m1.1.1.3.cmml">âˆ’</mo><mn id="Sx3.SSx4.p4.1.m1.1.1.3.2" xref="Sx3.SSx4.p4.1.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p4.1.m1.1b"><apply id="Sx3.SSx4.p4.1.m1.1.1.cmml" xref="Sx3.SSx4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx4.p4.1.m1.1.1.1.cmml" xref="Sx3.SSx4.p4.1.m1.1.1">superscript</csymbol><cn type="integer" id="Sx3.SSx4.p4.1.m1.1.1.2.cmml" xref="Sx3.SSx4.p4.1.m1.1.1.2">10</cn><apply id="Sx3.SSx4.p4.1.m1.1.1.3.cmml" xref="Sx3.SSx4.p4.1.m1.1.1.3"><minus id="Sx3.SSx4.p4.1.m1.1.1.3.1.cmml" xref="Sx3.SSx4.p4.1.m1.1.1.3"></minus><cn type="integer" id="Sx3.SSx4.p4.1.m1.1.1.3.2.cmml" xref="Sx3.SSx4.p4.1.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p4.1.m1.1c">10^{-3}</annotation></semantics></math> with a scheduler to decrease by 10 whenever the validation loss plateaued with a patience of 10. The models were trained using a custom training pipeline. Training curves can be found in Figs A-D in S3 Appendix. The training was limited to <math id="Sx3.SSx4.p4.2.m2.1" class="ltx_Math" alttext="10^{5}" display="inline"><semantics id="Sx3.SSx4.p4.2.m2.1a"><msup id="Sx3.SSx4.p4.2.m2.1.1" xref="Sx3.SSx4.p4.2.m2.1.1.cmml"><mn id="Sx3.SSx4.p4.2.m2.1.1.2" xref="Sx3.SSx4.p4.2.m2.1.1.2.cmml">10</mn><mn id="Sx3.SSx4.p4.2.m2.1.1.3" xref="Sx3.SSx4.p4.2.m2.1.1.3.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="Sx3.SSx4.p4.2.m2.1b"><apply id="Sx3.SSx4.p4.2.m2.1.1.cmml" xref="Sx3.SSx4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="Sx3.SSx4.p4.2.m2.1.1.1.cmml" xref="Sx3.SSx4.p4.2.m2.1.1">superscript</csymbol><cn type="integer" id="Sx3.SSx4.p4.2.m2.1.1.2.cmml" xref="Sx3.SSx4.p4.2.m2.1.1.2">10</cn><cn type="integer" id="Sx3.SSx4.p4.2.m2.1.1.3.cmml" xref="Sx3.SSx4.p4.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx4.p4.2.m2.1c">10^{5}</annotation></semantics></math> epochs, and manually stopped if the model stopped converging. The model with the lowest validation loss was saved.</p>
</div>
</section>
<section id="Sx3.SSx5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Experiments</h3>

<div id="Sx3.SSx5.p1" class="ltx_para">
<p id="Sx3.SSx5.p1.1" class="ltx_p">The experiments were conducted on an Ubuntu 18.04 Linux desktop computer with an IntelÂ®XeonÂ®Silver 4110 CPU with 16 cores, 64 GB of RAM, an NVIDIA Quadro P5000 (16 GB VRAM) dedicated GPU, and SSD hard-drive. Our framework, DDMR, used to conduct the experiments was implemented in Python 3.6 using TensorFlow v1.14. To accelerate the research within the field, the source code is made openly available on GitHub (<a target="_blank" href="https://github.com/jpdefrutos/DDMR" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jpdefrutos/DDMR</a>).</p>
</div>
<div id="Sx3.SSx5.p2" class="ltx_para">
<p id="Sx3.SSx5.p2.1" class="ltx_p">As aforesaid, our aim was to improve the training phase of image registration for CNN models. To that extent, four experiments were carried out:</p>
</div>
<section id="Sx3.SSx5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">(i) Ablation study</h4>

<div id="Sx3.SSx5.SSS0.Px1.p1" class="ltx_para">
<p id="Sx3.SSx5.SSS0.Px1.p1.1" class="ltx_p">Different training strategies and loss function combinations were evaluated to identify the key components in deep image registration.
Three different training strategies were considered, all using weakly-supervised learning: 1) the baseline (BL) using only intensity information, 2) adding segmentation guidance (SG) to the baseline, and 3) adding uncertainty weighting (UW) to the segmentation-guided approach. For all experiments, the input size and CNN backbone were tuned prior and kept fixed. All designs are described in <a href="#Sx3.T1" title="In (i) Ablation study â€£ Experiments â€£ Materials and methods" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> and evaluated on both the IXI and Oslo-CoMet datasets. Six loss weighting schemes were tested, using different combinations of loss functions, including both intensity and segmentation-based loss functions. For the second experiment, the entire model was finetuned directly or in two steps, i.e., by first finetuning the decoder, keeping the encoder frozen, and then finetuning the full model. A learning rate of <math id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1a"><msup id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.2" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.2.cmml">10</mn><mrow id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mo id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3a" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.cmml">âˆ’</mo><mn id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.2" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1b"><apply id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.2">10</cn><apply id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3"><minus id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3"></minus><cn type="integer" id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="Sx3.SSx5.SSS0.Px1.p1.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx5.SSS0.Px1.p1.1.m1.1c">10^{-4}</annotation></semantics></math> was used when performing transfer learning.</p>
</div>
<figure id="Sx3.T1" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="Sx3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="Sx3.T1.3.2" class="ltx_text" style="font-size:90%;">Configurations trained on both the IXI and Oslo-CoMet datasets.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="Sx3.T1.4" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx3.T1.4.1.1" class="ltx_tr">
<th id="Sx3.T1.4.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<div id="Sx3.T1.4.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.4pt;height:8.699999999999999pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.1.1.1.1.1" class="ltx_p"><span id="Sx3.T1.4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Design</span></p>
</span></div>
</th>
<th id="Sx3.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<div id="Sx3.T1.4.1.1.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:27.2pt;height:6.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.1.1.2.1.1" class="ltx_p"><span id="Sx3.T1.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model</span></p>
</span></div>
</th>
<th id="Sx3.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<div id="Sx3.T1.4.1.1.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:58.3pt;height:6.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.1.1.3.1.1" class="ltx_p"><span id="Sx3.T1.4.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Loss function</span></p>
</span></div>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx3.T1.4.2.1" class="ltx_tr">
<th id="Sx3.T1.4.2.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx3.T1.4.2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:24.2pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.2.1.1.1.1" class="ltx_p"><span id="Sx3.T1.4.2.1.1.1.1.1" class="ltx_text ltx_font_bold">BL-N</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">Baseline</td>
<td id="Sx3.T1.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t">NCC</td>
</tr>
<tr id="Sx3.T1.4.3.2" class="ltx_tr">
<th id="Sx3.T1.4.3.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx3.T1.4.3.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.7pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.3.2.1.1.1" class="ltx_p"><span id="Sx3.T1.4.3.2.1.1.1.1" class="ltx_text ltx_font_bold">BL-NS</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.3.2.2" class="ltx_td ltx_align_left">Baseline</td>
<td id="Sx3.T1.4.3.2.3" class="ltx_td ltx_align_left">NCC, SSIM</td>
</tr>
<tr id="Sx3.T1.4.4.3" class="ltx_tr">
<th id="Sx3.T1.4.4.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx3.T1.4.4.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:31.9pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.4.3.1.1.1" class="ltx_p"><span id="Sx3.T1.4.4.3.1.1.1.1" class="ltx_text ltx_font_bold">SG-ND</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.4.3.2" class="ltx_td ltx_align_left">Segmentation-guided</td>
<td id="Sx3.T1.4.4.3.3" class="ltx_td ltx_align_left">NCC, DSC</td>
</tr>
<tr id="Sx3.T1.4.5.4" class="ltx_tr">
<th id="Sx3.T1.4.5.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx3.T1.4.5.4.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:37.4pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.5.4.1.1.1" class="ltx_p"><span id="Sx3.T1.4.5.4.1.1.1.1" class="ltx_text ltx_font_bold">SG-NSD</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.5.4.2" class="ltx_td ltx_align_left">Segmentation-guided</td>
<td id="Sx3.T1.4.5.4.3" class="ltx_td ltx_align_left">NCC, SSIM, DSC</td>
</tr>
<tr id="Sx3.T1.4.6.5" class="ltx_tr">
<th id="Sx3.T1.4.6.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx3.T1.4.6.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:41.8pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.6.5.1.1.1" class="ltx_p"><span id="Sx3.T1.4.6.5.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSD</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.6.5.2" class="ltx_td ltx_align_left">Uncertainty weighting</td>
<td id="Sx3.T1.4.6.5.3" class="ltx_td ltx_align_left">NCC, SSIM, DSC</td>
</tr>
<tr id="Sx3.T1.4.7.6" class="ltx_tr">
<th id="Sx3.T1.4.7.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb">
<div id="Sx3.T1.4.7.6.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:49.3pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx3.T1.4.7.6.1.1.1" class="ltx_p"><span id="Sx3.T1.4.7.6.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSDH</span></p>
</span></div>
</th>
<td id="Sx3.T1.4.7.6.2" class="ltx_td ltx_align_left ltx_border_bb">Uncertainty weighting</td>
<td id="Sx3.T1.4.7.6.3" class="ltx_td ltx_align_left ltx_border_bb">NCC, SSIM, DSC, HD</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="Sx3.T1.5" class="ltx_p ltx_figure_panel ltx_align_center">BL: baseline, SG: segmentation-guided, UW: uncertainty weighting, N: normalized cross correlation, S: structural similarity index measure, D: Dice similarity coefficient, H: Hausdorff distance.</p>
</div>
</div>
</figure>
</section>
<section id="Sx3.SSx5.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">(ii) Transfer learning</h4>

<div id="Sx3.SSx5.SSS0.Px2.p1" class="ltx_para">
<p id="Sx3.SSx5.SSS0.Px2.p1.1" class="ltx_p">To assess the benefit finetuning for deep image registration to applications with a small number of samples available, e.g., abdominal CT registration.</p>
</div>
</section>
<section id="Sx3.SSx5.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">(iii) Baseline comparison</h4>

<div id="Sx3.SSx5.SSS0.Px3.p1" class="ltx_para">
<p id="Sx3.SSx5.SSS0.Px3.p1.1" class="ltx_p">The trained models were evaluated against a traditional registration framework (ANTs), to better understand the potential of deep image registration.
This experiment was performed only on the Oslo-CoMet dataset, as ANTs was used to generate the segmentations on the IXI dataset. Two different configuration were tested: symmetric normalisation (SyN), with mutual information as optimisation metric, and SyN with cross-correlation as metric (SyNCC).</p>
</div>
</section>
<section id="Sx3.SSx5.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">(iv) Training runtime</h4>

<div id="Sx3.SSx5.SSS0.Px4.p1" class="ltx_para">
<p id="Sx3.SSx5.SSS0.Px4.p1.1" class="ltx_p">The last experiment was conducted to assess the impact of the augmentation layer (see Fig A in S2 Appendix). The GPU resources were monitored during training. Only the second epoch was considered, as the first one served as warm-up.</p>
</div>
</section>
</section>
<section id="Sx3.SSx6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Evaluation metrics</h3>

<div id="Sx3.SSx6.p1" class="ltx_para">
<p id="Sx3.SSx6.p1.1" class="ltx_p">The evaluation was done on the test sets of the IXI and Oslo-CoMet datasets, for which the fixed-moving image pairs were generated in advance, such that the same image pairs were used across methods during evaluation. After inference, the displacement maps were resampled back to isotropic resolution using piecewise 3D linear interpolation. The final predictions were then evaluated using four sets of metrics to cover all angles. Image similarity was assessed under computation of NCC and SSIM metrics. Segmentations were converted into one-hot encoding and evaluated using DSC, HD, and HD95 (95th percentile of HD) measured in millimetres. The background class was excluded in the segmentation metrics computation. For image registration, TRE was estimated using the centroids of the segmentation masks of the fixed image and the predicted image, also measured in millimetres. In addition, the methods were compared in terms of inference runtime, only measuring the prediction and application of the displacement map, as all other operations were the same between the methods.</p>
</div>
<div id="Sx3.SSx6.p2" class="ltx_para">
<p id="Sx3.SSx6.p2.1" class="ltx_p">Five sets of statistical tests were conducted to further assess: 1) performance contrasts between designs, 2) benefit of transfer learning, 3) benefit of segmentation-guiding, 4) benefit of uncertainty weighting, and 5) performance contrasts between the baseline and segmentation-guided models, and the traditional methods in ANTs (SyN and SyNCC). For the tests, the TRE metric was used, as it is considered the gold standard for surgical practitioners. Test 1) was conducted on the evaluations of the IXI test set, whereas tests 2) to 5) were performed using the results on the Oslo-CoMet test dataset only. Furthermore, for the tests only involving the Oslo-CoMet dataset, the two-step transfer learning approach was used as reference, as these models showed the best results.</p>
</div>
<div id="Sx3.SSx6.p3" class="ltx_para">
<p id="Sx3.SSx6.p3.1" class="ltx_p">For the statistical test 1), multiple pairwise Tukeyâ€™s range tests were conducted on the IXI experiment comparing all the designs described in <a href="#Sx3.T1" title="In (i) Ablation study â€£ Experiments â€£ Materials and methods" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. For 2), benefit of transfer learning was assessed using a one-sided, non-parametric test (Mann-Whitney U test), comparing the differences between the BL-N, SG-NSD, and UW-NSD designs on the Oslo-CoMet experience. The three generated p-values were corrected for multiple comparison using the Benjamini-Hochberg method. For 3)-5), Mann-Whitney U tests were conducted comparing BL-N and SG-NSD to assess benefit of segmentation-guiding, SG-NSD and UW-NSD to assess benefit for uncertainty weighting, and BL-N and SG-NSD against SyN and SyNCC to assess the difference in performance between deep image registration and traditional image registration solutions, respectively. The two p-values were corrected using the Benjamini-Hochberg method. The results for all five sets of tests can be found in S4 Appendix.</p>
</div>
<div id="Sx3.SSx6.p4" class="ltx_para">
<p id="Sx3.SSx6.p4.1" class="ltx_p">The Python libraries statsmodels (v0.12.2)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> and SciPy (v1.5.4)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> were used for the statistic computations. A significance level of <math id="Sx3.SSx6.p4.1.m1.1" class="ltx_Math" alttext="0.05" display="inline"><semantics id="Sx3.SSx6.p4.1.m1.1a"><mn id="Sx3.SSx6.p4.1.m1.1.1" xref="Sx3.SSx6.p4.1.m1.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="Sx3.SSx6.p4.1.m1.1b"><cn type="float" id="Sx3.SSx6.p4.1.m1.1.1.cmml" xref="Sx3.SSx6.p4.1.m1.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx6.p4.1.m1.1c">0.05</annotation></semantics></math> was used to determine statistical significance.</p>
</div>
</section>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Results</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">In <a href="#Sx4.T2" title="In Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tables</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#Sx4.T3" title="Table 3 â€£ Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#Sx5.T4" title="Table 4 â€£ Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> andÂ <a href="#Sx5.T5" title="Table 5 â€£ Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the best performing methods in terms of individual performance metrics, i.e., most optimal mean and lowest standard deviation, were highlighted in bold.
See the online resources for additional tables and figures not presented in this manuscript.</p>
</div>
<div id="Sx4.p2" class="ltx_para">
<p id="Sx4.p2.2" class="ltx_p">On the IXI dataset, fusing NCC and SSIM improved performance in terms of intensity-based metrics for the baseline model, whereas segmentation metrics were degraded (see <a href="#Sx4.T2" title="In Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>). Adding segmentation-guiding drastically increased performance across all metrics compared to the baseline. Minor improvement was observed using uncertainty weighting, whereas adding the Hausdorff loss was not beneficial. In terms of TRE, multiple pairwise Tukeyâ€™s range tests confirmed the benefit of segmentation-guiding (<math id="Sx4.p2.1.m1.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx4.p2.1.m1.1a"><mrow id="Sx4.p2.1.m1.1.1" xref="Sx4.p2.1.m1.1.1.cmml"><mi id="Sx4.p2.1.m1.1.1.2" xref="Sx4.p2.1.m1.1.1.2.cmml">p</mi><mo id="Sx4.p2.1.m1.1.1.1" xref="Sx4.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="Sx4.p2.1.m1.1.1.3" xref="Sx4.p2.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p2.1.m1.1b"><apply id="Sx4.p2.1.m1.1.1.cmml" xref="Sx4.p2.1.m1.1.1"><lt id="Sx4.p2.1.m1.1.1.1.cmml" xref="Sx4.p2.1.m1.1.1.1"></lt><ci id="Sx4.p2.1.m1.1.1.2.cmml" xref="Sx4.p2.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p2.1.m1.1.1.3.cmml" xref="Sx4.p2.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.1.m1.1c">p&lt;0.001</annotation></semantics></math>), however, no significant improvement was observed in introducing uncertainty-weighing (<math id="Sx4.p2.2.m2.1" class="ltx_Math" alttext="p=0.9" display="inline"><semantics id="Sx4.p2.2.m2.1a"><mrow id="Sx4.p2.2.m2.1.1" xref="Sx4.p2.2.m2.1.1.cmml"><mi id="Sx4.p2.2.m2.1.1.2" xref="Sx4.p2.2.m2.1.1.2.cmml">p</mi><mo id="Sx4.p2.2.m2.1.1.1" xref="Sx4.p2.2.m2.1.1.1.cmml">=</mo><mn id="Sx4.p2.2.m2.1.1.3" xref="Sx4.p2.2.m2.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p2.2.m2.1b"><apply id="Sx4.p2.2.m2.1.1.cmml" xref="Sx4.p2.2.m2.1.1"><eq id="Sx4.p2.2.m2.1.1.1.cmml" xref="Sx4.p2.2.m2.1.1.1"></eq><ci id="Sx4.p2.2.m2.1.1.2.cmml" xref="Sx4.p2.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p2.2.m2.1.1.3.cmml" xref="Sx4.p2.2.m2.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p2.2.m2.1c">p=0.9</annotation></semantics></math>). The complete pairwise comparison can be found in Table A in S1 Appendix.</p>
</div>
<div id="Sx4.p3" class="ltx_para">
<p id="Sx4.p3.2" class="ltx_p">On the Oslo-CoMet dataset, a similar trend as for the IXI dataset was observed (see <a href="#Sx4.T3" title="In Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>). However, in this case, the baseline model was more competitive, especially in terms of intensity-based metrics. Nonetheless, segmentation-guiding was still better overall (<math id="Sx4.p3.1.m1.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx4.p3.1.m1.1a"><mrow id="Sx4.p3.1.m1.1.1" xref="Sx4.p3.1.m1.1.1.cmml"><mi id="Sx4.p3.1.m1.1.1.2" xref="Sx4.p3.1.m1.1.1.2.cmml">p</mi><mo id="Sx4.p3.1.m1.1.1.1" xref="Sx4.p3.1.m1.1.1.1.cmml">&lt;</mo><mn id="Sx4.p3.1.m1.1.1.3" xref="Sx4.p3.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p3.1.m1.1b"><apply id="Sx4.p3.1.m1.1.1.cmml" xref="Sx4.p3.1.m1.1.1"><lt id="Sx4.p3.1.m1.1.1.1.cmml" xref="Sx4.p3.1.m1.1.1.1"></lt><ci id="Sx4.p3.1.m1.1.1.2.cmml" xref="Sx4.p3.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p3.1.m1.1.1.3.cmml" xref="Sx4.p3.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p3.1.m1.1c">p&lt;0.001</annotation></semantics></math> in terms of TRE), as well as uncertainty weighting (<math id="Sx4.p3.2.m2.1" class="ltx_Math" alttext="p=0.0093" display="inline"><semantics id="Sx4.p3.2.m2.1a"><mrow id="Sx4.p3.2.m2.1.1" xref="Sx4.p3.2.m2.1.1.cmml"><mi id="Sx4.p3.2.m2.1.1.2" xref="Sx4.p3.2.m2.1.1.2.cmml">p</mi><mo id="Sx4.p3.2.m2.1.1.1" xref="Sx4.p3.2.m2.1.1.1.cmml">=</mo><mn id="Sx4.p3.2.m2.1.1.3" xref="Sx4.p3.2.m2.1.1.3.cmml">0.0093</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p3.2.m2.1b"><apply id="Sx4.p3.2.m2.1.1.cmml" xref="Sx4.p3.2.m2.1.1"><eq id="Sx4.p3.2.m2.1.1.1.cmml" xref="Sx4.p3.2.m2.1.1.1"></eq><ci id="Sx4.p3.2.m2.1.1.2.cmml" xref="Sx4.p3.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p3.2.m2.1.1.3.cmml" xref="Sx4.p3.2.m2.1.1.3">0.0093</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p3.2.m2.1c">p=0.0093</annotation></semantics></math> in terms of TRE).</p>
</div>
<div id="Sx4.p4" class="ltx_para">
<p id="Sx4.p4.3" class="ltx_p">Finetuning the entire model trained on the IXI dataset to the Oslo-CoMet dataset (see <a href="#Sx5.T4" title="In Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>), yielded similar intensity-based metrics overall, but drastically improved the segmentation-guided and uncertainty weighted models in terms of segmentation metrics. The best performing models overall used uncertainty weighting. When finetuning the model in two steps, the uncertainty weighted designs were further improved to some extent (see <a href="#Sx5.T5" title="In Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>). The statistical analysis 2) shows significance improvement of the TRE when performing transfer learning and finetuning in two steps, for the UW-NSD model (<math id="Sx4.p4.1.m1.1" class="ltx_Math" alttext="p=0.0014" display="inline"><semantics id="Sx4.p4.1.m1.1a"><mrow id="Sx4.p4.1.m1.1.1" xref="Sx4.p4.1.m1.1.1.cmml"><mi id="Sx4.p4.1.m1.1.1.2" xref="Sx4.p4.1.m1.1.1.2.cmml">p</mi><mo id="Sx4.p4.1.m1.1.1.1" xref="Sx4.p4.1.m1.1.1.1.cmml">=</mo><mn id="Sx4.p4.1.m1.1.1.3" xref="Sx4.p4.1.m1.1.1.3.cmml">0.0014</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p4.1.m1.1b"><apply id="Sx4.p4.1.m1.1.1.cmml" xref="Sx4.p4.1.m1.1.1"><eq id="Sx4.p4.1.m1.1.1.1.cmml" xref="Sx4.p4.1.m1.1.1.1"></eq><ci id="Sx4.p4.1.m1.1.1.2.cmml" xref="Sx4.p4.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p4.1.m1.1.1.3.cmml" xref="Sx4.p4.1.m1.1.1.3">0.0014</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p4.1.m1.1c">p=0.0014</annotation></semantics></math>) and SG-NSD (<math id="Sx4.p4.2.m2.1" class="ltx_Math" alttext="p=0.0021" display="inline"><semantics id="Sx4.p4.2.m2.1a"><mrow id="Sx4.p4.2.m2.1.1" xref="Sx4.p4.2.m2.1.1.cmml"><mi id="Sx4.p4.2.m2.1.1.2" xref="Sx4.p4.2.m2.1.1.2.cmml">p</mi><mo id="Sx4.p4.2.m2.1.1.1" xref="Sx4.p4.2.m2.1.1.1.cmml">=</mo><mn id="Sx4.p4.2.m2.1.1.3" xref="Sx4.p4.2.m2.1.1.3.cmml">0.0021</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p4.2.m2.1b"><apply id="Sx4.p4.2.m2.1.1.cmml" xref="Sx4.p4.2.m2.1.1"><eq id="Sx4.p4.2.m2.1.1.1.cmml" xref="Sx4.p4.2.m2.1.1.1"></eq><ci id="Sx4.p4.2.m2.1.1.2.cmml" xref="Sx4.p4.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p4.2.m2.1.1.3.cmml" xref="Sx4.p4.2.m2.1.1.3">0.0021</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p4.2.m2.1c">p=0.0021</annotation></semantics></math>) models. No statistical significance was observed for the BL-N (<math id="Sx4.p4.3.m3.1" class="ltx_Math" alttext="p=0.8608" display="inline"><semantics id="Sx4.p4.3.m3.1a"><mrow id="Sx4.p4.3.m3.1.1" xref="Sx4.p4.3.m3.1.1.cmml"><mi id="Sx4.p4.3.m3.1.1.2" xref="Sx4.p4.3.m3.1.1.2.cmml">p</mi><mo id="Sx4.p4.3.m3.1.1.1" xref="Sx4.p4.3.m3.1.1.1.cmml">=</mo><mn id="Sx4.p4.3.m3.1.1.3" xref="Sx4.p4.3.m3.1.1.3.cmml">0.8608</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p4.3.m3.1b"><apply id="Sx4.p4.3.m3.1.1.cmml" xref="Sx4.p4.3.m3.1.1"><eq id="Sx4.p4.3.m3.1.1.1.cmml" xref="Sx4.p4.3.m3.1.1.1"></eq><ci id="Sx4.p4.3.m3.1.1.2.cmml" xref="Sx4.p4.3.m3.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p4.3.m3.1.1.3.cmml" xref="Sx4.p4.3.m3.1.1.3">0.8608</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p4.3.m3.1c">p=0.8608</annotation></semantics></math>).</p>
</div>
<div id="Sx4.p5" class="ltx_para">
<p id="Sx4.p5.4" class="ltx_p">The traditional methods, SyN and SyNCC, performed well on the Oslo-CoMet test set. However, the segmentation masks were distorted, in particular the vascular segmentations mask (see Fig C in S5 Appendix). Both methods performed similarly, but the SyNCC was considerably slower. Segmentation guidance was deemed critical in obtaining better performance in terms of TRE (<math id="Sx4.p5.1.m1.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx4.p5.1.m1.1a"><mrow id="Sx4.p5.1.m1.1.1" xref="Sx4.p5.1.m1.1.1.cmml"><mi id="Sx4.p5.1.m1.1.1.2" xref="Sx4.p5.1.m1.1.1.2.cmml">p</mi><mo id="Sx4.p5.1.m1.1.1.1" xref="Sx4.p5.1.m1.1.1.1.cmml">&lt;</mo><mn id="Sx4.p5.1.m1.1.1.3" xref="Sx4.p5.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p5.1.m1.1b"><apply id="Sx4.p5.1.m1.1.1.cmml" xref="Sx4.p5.1.m1.1.1"><lt id="Sx4.p5.1.m1.1.1.1.cmml" xref="Sx4.p5.1.m1.1.1.1"></lt><ci id="Sx4.p5.1.m1.1.1.2.cmml" xref="Sx4.p5.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p5.1.m1.1.1.3.cmml" xref="Sx4.p5.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p5.1.m1.1c">p&lt;0.001</annotation></semantics></math>) compared to SyN and SyNCC. Yet no significant difference was observed on the baseline models (<math id="Sx4.p5.2.m2.1" class="ltx_Math" alttext="p=0.5845" display="inline"><semantics id="Sx4.p5.2.m2.1a"><mrow id="Sx4.p5.2.m2.1.1" xref="Sx4.p5.2.m2.1.1.cmml"><mi id="Sx4.p5.2.m2.1.1.2" xref="Sx4.p5.2.m2.1.1.2.cmml">p</mi><mo id="Sx4.p5.2.m2.1.1.1" xref="Sx4.p5.2.m2.1.1.1.cmml">=</mo><mn id="Sx4.p5.2.m2.1.1.3" xref="Sx4.p5.2.m2.1.1.3.cmml">0.5845</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p5.2.m2.1b"><apply id="Sx4.p5.2.m2.1.1.cmml" xref="Sx4.p5.2.m2.1.1"><eq id="Sx4.p5.2.m2.1.1.1.cmml" xref="Sx4.p5.2.m2.1.1.1"></eq><ci id="Sx4.p5.2.m2.1.1.2.cmml" xref="Sx4.p5.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx4.p5.2.m2.1.1.3.cmml" xref="Sx4.p5.2.m2.1.1.3">0.5845</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p5.2.m2.1c">p=0.5845</annotation></semantics></math>). All deep learning models had similar inference runtimes of less than one second, which was expected as the final inference model architectures were identical. On average, the CNN-based methods were <math id="Sx4.p5.3.m3.1" class="ltx_math_unparsed" alttext="\sim 13\times" display="inline"><semantics id="Sx4.p5.3.m3.1a"><mrow id="Sx4.p5.3.m3.1b"><mo id="Sx4.p5.3.m3.1.1">âˆ¼</mo><mn id="Sx4.p5.3.m3.1.2">13</mn><mo lspace="0.222em" id="Sx4.p5.3.m3.1.3">Ã—</mo></mrow><annotation encoding="application/x-tex" id="Sx4.p5.3.m3.1c">\sim 13\times</annotation></semantics></math> and <math id="Sx4.p5.4.m4.1" class="ltx_math_unparsed" alttext="\sim 421\times" display="inline"><semantics id="Sx4.p5.4.m4.1a"><mrow id="Sx4.p5.4.m4.1b"><mo id="Sx4.p5.4.m4.1.1">âˆ¼</mo><mn id="Sx4.p5.4.m4.1.2">421</mn><mo lspace="0.222em" id="Sx4.p5.4.m4.1.3">Ã—</mo></mrow><annotation encoding="application/x-tex" id="Sx4.p5.4.m4.1c">\sim 421\times</annotation></semantics></math> faster than SyN and SyNCC, respectively.
The deep learning models struggled with image reconstruction, unlike ANTs (see Fig C in S5 Appendix). For instance, anatomical structures outside the segmentation masks were poorly reconstructed in the predicted image, e.g., the spine of the patient.</p>
</div>
<div id="Sx4.p6" class="ltx_para">
<p id="Sx4.p6.4" class="ltx_p">The use of the augmentation layer resulted in a negligible increase in training runtime of <math id="Sx4.p6.1.m1.1" class="ltx_Math" alttext="7.7" display="inline"><semantics id="Sx4.p6.1.m1.1a"><mn id="Sx4.p6.1.m1.1.1" xref="Sx4.p6.1.m1.1.1.cmml">7.7</mn><annotation-xml encoding="MathML-Content" id="Sx4.p6.1.m1.1b"><cn type="float" id="Sx4.p6.1.m1.1.1.cmml" xref="Sx4.p6.1.m1.1.1">7.7</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p6.1.m1.1c">7.7</annotation></semantics></math>% per epoch and <math id="Sx4.p6.2.m2.1" class="ltx_Math" alttext="0.47" display="inline"><semantics id="Sx4.p6.2.m2.1a"><mn id="Sx4.p6.2.m2.1.1" xref="Sx4.p6.2.m2.1.1.cmml">0.47</mn><annotation-xml encoding="MathML-Content" id="Sx4.p6.2.m2.1b"><cn type="float" id="Sx4.p6.2.m2.1.1.cmml" xref="Sx4.p6.2.m2.1.1">0.47</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p6.2.m2.1c">0.47</annotation></semantics></math>% (<math id="Sx4.p6.3.m3.1" class="ltx_Math" alttext="\sim 74" display="inline"><semantics id="Sx4.p6.3.m3.1a"><mrow id="Sx4.p6.3.m3.1.1" xref="Sx4.p6.3.m3.1.1.cmml"><mi id="Sx4.p6.3.m3.1.1.2" xref="Sx4.p6.3.m3.1.1.2.cmml"></mi><mo id="Sx4.p6.3.m3.1.1.1" xref="Sx4.p6.3.m3.1.1.1.cmml">âˆ¼</mo><mn id="Sx4.p6.3.m3.1.1.3" xref="Sx4.p6.3.m3.1.1.3.cmml">74</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx4.p6.3.m3.1b"><apply id="Sx4.p6.3.m3.1.1.cmml" xref="Sx4.p6.3.m3.1.1"><csymbol cd="latexml" id="Sx4.p6.3.m3.1.1.1.cmml" xref="Sx4.p6.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="Sx4.p6.3.m3.1.1.2.cmml" xref="Sx4.p6.3.m3.1.1.2">absent</csymbol><cn type="integer" id="Sx4.p6.3.m3.1.1.3.cmml" xref="Sx4.p6.3.m3.1.1.3">74</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p6.3.m3.1c">\sim 74</annotation></semantics></math> MB of <math id="Sx4.p6.4.m4.1" class="ltx_Math" alttext="16" display="inline"><semantics id="Sx4.p6.4.m4.1a"><mn id="Sx4.p6.4.m4.1.1" xref="Sx4.p6.4.m4.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="Sx4.p6.4.m4.1b"><cn type="integer" id="Sx4.p6.4.m4.1.1.cmml" xref="Sx4.p6.4.m4.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx4.p6.4.m4.1c">16</annotation></semantics></math> GB) increase in GPU memory usage (see Fig A in S2 Appendix).</p>
</div>
<figure id="Sx4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="Sx4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="Sx4.T2.3.2" class="ltx_text" style="font-size:90%;">Evaluation of the models trained on the IXI dataset.</span></figcaption>
<div id="Sx4.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:135.3pt;vertical-align:-9.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.4pt,9.1pt) scale(0.873547000645376,0.873547000645376) ;">
<table id="Sx4.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx4.T2.4.1.1.1" class="ltx_tr">
<th id="Sx4.T2.4.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_tt">Model</th>
<td id="Sx4.T2.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SSIM</td>
<td id="Sx4.T2.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">NCC</td>
<td id="Sx4.T2.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">DSC</td>
<td id="Sx4.T2.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HD</td>
<td id="Sx4.T2.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">HD95</td>
<td id="Sx4.T2.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">TRE</td>
<td id="Sx4.T2.4.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">Runtime</td>
</tr>
<tr id="Sx4.T2.4.1.2.2" class="ltx_tr">
<th id="Sx4.T2.4.1.2.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx4.T2.4.1.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:24.2pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.2.2.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">BL-N</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.23Â±0.16</td>
<td id="Sx4.T2.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">0.52Â±0.12</td>
<td id="Sx4.T2.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.03Â±0.01</td>
<td id="Sx4.T2.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">109.71Â±26.19</td>
<td id="Sx4.T2.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">100.26Â±27.91</td>
<td id="Sx4.T2.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">29.47Â±8.46</td>
<td id="Sx4.T2.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">0.83Â±0.77</td>
</tr>
<tr id="Sx4.T2.4.1.3.3" class="ltx_tr">
<th id="Sx4.T2.4.1.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T2.4.1.3.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.7pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.3.3.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">BL-NS</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.3.3.2" class="ltx_td ltx_align_center">0.25Â±0.16</td>
<td id="Sx4.T2.4.1.3.3.3" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.3.3.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.3.3.3.1.1" class="ltx_p"><span id="Sx4.T2.4.1.3.3.3.1.1.1" class="ltx_text ltx_font_bold">0.53Â±0.12</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.3.3.4" class="ltx_td ltx_align_center">0.02Â±0.01</td>
<td id="Sx4.T2.4.1.3.3.5" class="ltx_td ltx_align_center">145.36Â±22.41</td>
<td id="Sx4.T2.4.1.3.3.6" class="ltx_td ltx_align_center">138.19Â±23.48</td>
<td id="Sx4.T2.4.1.3.3.7" class="ltx_td ltx_align_center">30.06Â±9.07</td>
<td id="Sx4.T2.4.1.3.3.8" class="ltx_td ltx_align_center">0.73Â±0.56</td>
</tr>
<tr id="Sx4.T2.4.1.4.4" class="ltx_tr">
<th id="Sx4.T2.4.1.4.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T2.4.1.4.4.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:31.9pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.4.4.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">SG-ND</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.4.4.2" class="ltx_td ltx_align_center">0.45Â±0.24</td>
<td id="Sx4.T2.4.1.4.4.3" class="ltx_td ltx_align_center">0.46Â±0.10</td>
<td id="Sx4.T2.4.1.4.4.4" class="ltx_td ltx_align_center">0.61Â±0.08</td>
<td id="Sx4.T2.4.1.4.4.5" class="ltx_td ltx_align_center">4.64Â±1.37</td>
<td id="Sx4.T2.4.1.4.4.6" class="ltx_td ltx_align_center">2.15Â±0.54</td>
<td id="Sx4.T2.4.1.4.4.7" class="ltx_td ltx_align_center">1.08Â±0.39</td>
<td id="Sx4.T2.4.1.4.4.8" class="ltx_td ltx_align_center">0.82Â±0.58</td>
</tr>
<tr id="Sx4.T2.4.1.5.5" class="ltx_tr">
<th id="Sx4.T2.4.1.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T2.4.1.5.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:37.4pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.5.5.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">SG-NSD</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.5.5.2" class="ltx_td ltx_align_center">0.46Â±0.24</td>
<td id="Sx4.T2.4.1.5.5.3" class="ltx_td ltx_align_center">0.46Â±0.11</td>
<td id="Sx4.T2.4.1.5.5.4" class="ltx_td ltx_align_center">0.61Â±0.07</td>
<td id="Sx4.T2.4.1.5.5.5" class="ltx_td ltx_align_center">4.54Â±1.42</td>
<td id="Sx4.T2.4.1.5.5.6" class="ltx_td ltx_align_center">2.10Â±0.49</td>
<td id="Sx4.T2.4.1.5.5.7" class="ltx_td ltx_align_center">1.07Â±0.37</td>
<td id="Sx4.T2.4.1.5.5.8" class="ltx_td ltx_align_center">0.74Â±0.64</td>
</tr>
<tr id="Sx4.T2.4.1.6.6" class="ltx_tr">
<th id="Sx4.T2.4.1.6.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T2.4.1.6.6.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:41.8pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSD</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.6.6.2" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.2.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.2.1.1.1" class="ltx_text ltx_font_bold">0.47Â±0.24</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.6.6.3" class="ltx_td ltx_align_center">0.46Â±0.11</td>
<td id="Sx4.T2.4.1.6.6.4" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.4.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.4.1.1.1" class="ltx_text ltx_font_bold">0.63Â±0.08</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.6.6.5" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.5.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.5.1.1.1" class="ltx_text ltx_font_bold">4.44Â±1.40</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.6.6.6" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.6.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.6.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.6.1.1.1" class="ltx_text ltx_font_bold">2.03Â±0.51</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.6.6.7" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.7.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.7.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.7.1.1.1" class="ltx_text ltx_font_bold">0.97Â±0.36</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.6.6.8" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.6.6.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.6.6.8.1.1" class="ltx_p"><span id="Sx4.T2.4.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">0.72Â±0.59</span></p>
</span></div>
</td>
</tr>
<tr id="Sx4.T2.4.1.7.7" class="ltx_tr">
<th id="Sx4.T2.4.1.7.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T2.4.1.7.7.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:49.3pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.7.7.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSDH</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.7.7.2" class="ltx_td ltx_align_center">
<div id="Sx4.T2.4.1.7.7.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.7.7.2.1.1" class="ltx_p"><span id="Sx4.T2.4.1.7.7.2.1.1.1" class="ltx_text ltx_font_bold">0.47Â±0.24</span></p>
</span></div>
</td>
<td id="Sx4.T2.4.1.7.7.3" class="ltx_td ltx_align_center">0.46Â±0.11</td>
<td id="Sx4.T2.4.1.7.7.4" class="ltx_td ltx_align_center">0.61Â±0.07</td>
<td id="Sx4.T2.4.1.7.7.5" class="ltx_td ltx_align_center">4.63Â±1.49</td>
<td id="Sx4.T2.4.1.7.7.6" class="ltx_td ltx_align_center">2.14Â±0.52</td>
<td id="Sx4.T2.4.1.7.7.7" class="ltx_td ltx_align_center">1.06Â±0.36</td>
<td id="Sx4.T2.4.1.7.7.8" class="ltx_td ltx_align_center">0.75Â±0.59</td>
</tr>
<tr id="Sx4.T2.4.1.8.8" class="ltx_tr">
<th id="Sx4.T2.4.1.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<div id="Sx4.T2.4.1.8.8.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:55.4pt;height:8.800000000000001pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T2.4.1.8.8.1.1.1" class="ltx_p"><span id="Sx4.T2.4.1.8.8.1.1.1.1" class="ltx_text ltx_font_bold">Unregistered</span></p>
</span></div>
</th>
<td id="Sx4.T2.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.45Â±0.21</td>
<td id="Sx4.T2.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.24Â±0.07</td>
<td id="Sx4.T2.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.07Â±0.06</td>
<td id="Sx4.T2.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">21.77Â±5.15</td>
<td id="Sx4.T2.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">18.73Â±4.88</td>
<td id="Sx4.T2.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">11.53Â±3.01</td>
<td id="Sx4.T2.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</tbody>
</table>
<p id="Sx4.T2.4.2" class="ltx_p">The best performing methods for each metric are highlighted in bold.</p>
</span></div>
</figure>
<figure id="Sx4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="Sx4.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="Sx4.T3.3.2" class="ltx_text" style="font-size:90%;">Evaluation of the models trained on the Oslo-CoMet dataset.</span></figcaption>
<div id="Sx4.T3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:141pt;vertical-align:-9.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.4pt,6.5pt) scale(0.910220725095418,0.910220725095418) ;">
<table id="Sx4.T3.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx4.T3.4.1.1.1" class="ltx_tr">
<th id="Sx4.T3.4.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_tt">Model</th>
<td id="Sx4.T3.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SSIM</td>
<td id="Sx4.T3.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">NCC</td>
<td id="Sx4.T3.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">DSC</td>
<td id="Sx4.T3.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HD</td>
<td id="Sx4.T3.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">HD95</td>
<td id="Sx4.T3.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">TRE</td>
<td id="Sx4.T3.4.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">Runtime</td>
</tr>
<tr id="Sx4.T3.4.1.2.2" class="ltx_tr">
<th id="Sx4.T3.4.1.2.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx4.T3.4.1.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:24.2pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.2.2.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">BL-N</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.52Â±0.10</td>
<td id="Sx4.T3.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">
<div id="Sx4.T3.4.1.2.2.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.2.2.3.1.1" class="ltx_p"><span id="Sx4.T3.4.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">0.20Â±0.07</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.23Â±0.09</td>
<td id="Sx4.T3.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">54.10Â±7.22</td>
<td id="Sx4.T3.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">30.36Â±3.58</td>
<td id="Sx4.T3.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">18.11Â±7.62</td>
<td id="Sx4.T3.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">0.78Â±1.50</td>
</tr>
<tr id="Sx4.T3.4.1.3.3" class="ltx_tr">
<th id="Sx4.T3.4.1.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T3.4.1.3.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.7pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.3.3.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">BL-NS</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.3.3.2" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.3.3.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.3.3.2.1.1" class="ltx_p"><span id="Sx4.T3.4.1.3.3.2.1.1.1" class="ltx_text ltx_font_bold">0.62Â±0.13</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.3.3.3" class="ltx_td ltx_align_center">0.17Â±0.07</td>
<td id="Sx4.T3.4.1.3.3.4" class="ltx_td ltx_align_center">0.29Â±0.07</td>
<td id="Sx4.T3.4.1.3.3.5" class="ltx_td ltx_align_center">37.69Â±8.04</td>
<td id="Sx4.T3.4.1.3.3.6" class="ltx_td ltx_align_center">22.06Â±5.17</td>
<td id="Sx4.T3.4.1.3.3.7" class="ltx_td ltx_align_center">13.95Â±4.78</td>
<td id="Sx4.T3.4.1.3.3.8" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.3.3.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.3.3.8.1.1" class="ltx_p"><span id="Sx4.T3.4.1.3.3.8.1.1.1" class="ltx_text ltx_font_bold">0.76Â±1.44</span></p>
</span></div>
</td>
</tr>
<tr id="Sx4.T3.4.1.4.4" class="ltx_tr">
<th id="Sx4.T3.4.1.4.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T3.4.1.4.4.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:31.9pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.4.4.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">SG-ND</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.4.4.2" class="ltx_td ltx_align_center">0.55Â±0.15</td>
<td id="Sx4.T3.4.1.4.4.3" class="ltx_td ltx_align_center">0.16Â±0.06</td>
<td id="Sx4.T3.4.1.4.4.4" class="ltx_td ltx_align_center">0.38Â±0.14</td>
<td id="Sx4.T3.4.1.4.4.5" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.4.4.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:48.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.4.4.5.1.1" class="ltx_p"><span id="Sx4.T3.4.1.4.4.5.1.1.1" class="ltx_text ltx_font_bold">22.03Â±8.27</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.4.4.6" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.4.4.6.1" class="ltx_inline-block ltx_transformed_outer" style="width:48.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.4.4.6.1.1" class="ltx_p"><span id="Sx4.T3.4.1.4.4.6.1.1.1" class="ltx_text ltx_font_bold">12.74Â±6.12</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.4.4.7" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.4.4.7.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.4.4.7.1.1" class="ltx_p"><span id="Sx4.T3.4.1.4.4.7.1.1.1" class="ltx_text ltx_font_bold">7.60Â±3.96</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.4.4.8" class="ltx_td ltx_align_center">0.76Â±1.46</td>
</tr>
<tr id="Sx4.T3.4.1.5.5" class="ltx_tr">
<th id="Sx4.T3.4.1.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T3.4.1.5.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:37.4pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.5.5.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">SG-NSD</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.5.5.2" class="ltx_td ltx_align_center">0.58Â±0.13</td>
<td id="Sx4.T3.4.1.5.5.3" class="ltx_td ltx_align_center">0.12Â±0.07</td>
<td id="Sx4.T3.4.1.5.5.4" class="ltx_td ltx_align_center">
<div id="Sx4.T3.4.1.5.5.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.5.5.4.1.1" class="ltx_p"><span id="Sx4.T3.4.1.5.5.4.1.1.1" class="ltx_text ltx_font_bold">0.35Â±0.07</span></p>
</span></div>
</td>
<td id="Sx4.T3.4.1.5.5.5" class="ltx_td ltx_align_center">25.22Â±7.92</td>
<td id="Sx4.T3.4.1.5.5.6" class="ltx_td ltx_align_center">14.49Â±4.22</td>
<td id="Sx4.T3.4.1.5.5.7" class="ltx_td ltx_align_center">8.91Â±3.08</td>
<td id="Sx4.T3.4.1.5.5.8" class="ltx_td ltx_align_center">0.77Â±1.49</td>
</tr>
<tr id="Sx4.T3.4.1.6.6" class="ltx_tr">
<th id="Sx4.T3.4.1.6.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T3.4.1.6.6.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:41.8pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.6.6.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSD</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.6.6.2" class="ltx_td ltx_align_center">0.54Â±0.13</td>
<td id="Sx4.T3.4.1.6.6.3" class="ltx_td ltx_align_center">0.11Â±0.06</td>
<td id="Sx4.T3.4.1.6.6.4" class="ltx_td ltx_align_center">0.26Â±0.07</td>
<td id="Sx4.T3.4.1.6.6.5" class="ltx_td ltx_align_center">25.08Â±6.67</td>
<td id="Sx4.T3.4.1.6.6.6" class="ltx_td ltx_align_center">18.47Â±5.34</td>
<td id="Sx4.T3.4.1.6.6.7" class="ltx_td ltx_align_center">11.52Â±3.32</td>
<td id="Sx4.T3.4.1.6.6.8" class="ltx_td ltx_align_center">0.77Â±1.49</td>
</tr>
<tr id="Sx4.T3.4.1.7.7" class="ltx_tr">
<th id="Sx4.T3.4.1.7.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx4.T3.4.1.7.7.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:49.3pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.7.7.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSDH</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.7.7.2" class="ltx_td ltx_align_center">0.59Â±0.14</td>
<td id="Sx4.T3.4.1.7.7.3" class="ltx_td ltx_align_center">0.14Â±0.06</td>
<td id="Sx4.T3.4.1.7.7.4" class="ltx_td ltx_align_center">0.35Â±0.11</td>
<td id="Sx4.T3.4.1.7.7.5" class="ltx_td ltx_align_center">24.49Â±8.67</td>
<td id="Sx4.T3.4.1.7.7.6" class="ltx_td ltx_align_center">14.57Â±5.93</td>
<td id="Sx4.T3.4.1.7.7.7" class="ltx_td ltx_align_center">8.34Â±4.31</td>
<td id="Sx4.T3.4.1.7.7.8" class="ltx_td ltx_align_center">0.78Â±1.50</td>
</tr>
<tr id="Sx4.T3.4.1.8.8" class="ltx_tr">
<th id="Sx4.T3.4.1.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<div id="Sx4.T3.4.1.8.8.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:55.4pt;height:8.800000000000001pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx4.T3.4.1.8.8.1.1.1" class="ltx_p"><span id="Sx4.T3.4.1.8.8.1.1.1.1" class="ltx_text ltx_font_bold">Unregistered</span></p>
</span></div>
</th>
<td id="Sx4.T3.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.60Â±0.13</td>
<td id="Sx4.T3.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.09Â±0.05</td>
<td id="Sx4.T3.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.24Â±0.08</td>
<td id="Sx4.T3.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">24.60Â±5.56</td>
<td id="Sx4.T3.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">19.06Â±4.89</td>
<td id="Sx4.T3.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">11.86Â±2.75</td>
<td id="Sx4.T3.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</tbody>
</table>
<p id="Sx4.T3.4.2" class="ltx_p">The best performing methods for each metric are highlighted in bold.</p>
</span></div>
</figure>
</section>
<section id="Sx5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Discussion</h2>

<div id="Sx5.p1" class="ltx_para">
<p id="Sx5.p1.1" class="ltx_p">Development of CNNs for image registration is challenging, especially when data is scarce. We therefore developed a framework called DDMR to train deep registration models, which we have evaluated through an ablation study. By pretraining a model on a larger dataset, we found that performance can be greatly improved using transfer learning, even if the source domain is from a different image modality or anatomic origin. Through the development of novel augmentation and loss weighting layers, training was simplified by generating artificial moving images on-the-fly, removing the need to store augmented samples on disk, while simultaneously learning to weigh losses in a dynamic fashion. Furthermore, by guiding registration using automatically generated segmentations and adaptive loss weighting, registration performance was enhanced. In addition, negligible increase in inference runtime and GPU memory usage was observed. The added-value of our method lies in the use of generic concepts, which can therefore leverage most deep learning-based registration designs.</p>
</div>
<div id="Sx5.p2" class="ltx_para">
<p id="Sx5.p2.3" class="ltx_p">From <a href="#Sx4.T2" title="In Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tables</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#Sx4.T3" title="Table 3 â€£ Results" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#Sx5.T5" title="Table 5 â€£ Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> andÂ <a href="#Sx5.T4" title="Table 4 â€£ Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, segmentation guidance boosts the performance of the image registration both on the SG and UW models, further confirmed by the results of the performance contrast analysis shown in Table A in S4 Appendix (<math id="Sx5.p2.1.m1.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx5.p2.1.m1.1a"><mrow id="Sx5.p2.1.m1.1.1" xref="Sx5.p2.1.m1.1.1.cmml"><mi id="Sx5.p2.1.m1.1.1.2" xref="Sx5.p2.1.m1.1.1.2.cmml">p</mi><mo id="Sx5.p2.1.m1.1.1.1" xref="Sx5.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="Sx5.p2.1.m1.1.1.3" xref="Sx5.p2.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p2.1.m1.1b"><apply id="Sx5.p2.1.m1.1.1.cmml" xref="Sx5.p2.1.m1.1.1"><lt id="Sx5.p2.1.m1.1.1.1.cmml" xref="Sx5.p2.1.m1.1.1.1"></lt><ci id="Sx5.p2.1.m1.1.1.2.cmml" xref="Sx5.p2.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx5.p2.1.m1.1.1.3.cmml" xref="Sx5.p2.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p2.1.m1.1c">p&lt;0.001</annotation></semantics></math>), and Figs A-C in S5 Appendix, found in the online resources. The introduction of landmarks to guide the training, in the form of boundaries of the different segmentation masks, allows for a better understanding of the regions occupied by each anatomical structure. This observation is drawn by the improvement of the segmentation-based metrics on the finetuned models (see <a href="#Sx5.T5" title="In Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>). And further confirmed by the statistical tests 2) and 3), in which the Mann-Whitney U test showed significant difference for the segmentation guidance (<math id="Sx5.p2.2.m2.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx5.p2.2.m2.1a"><mrow id="Sx5.p2.2.m2.1.1" xref="Sx5.p2.2.m2.1.1.cmml"><mi id="Sx5.p2.2.m2.1.1.2" xref="Sx5.p2.2.m2.1.1.2.cmml">p</mi><mo id="Sx5.p2.2.m2.1.1.1" xref="Sx5.p2.2.m2.1.1.1.cmml">&lt;</mo><mn id="Sx5.p2.2.m2.1.1.3" xref="Sx5.p2.2.m2.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p2.2.m2.1b"><apply id="Sx5.p2.2.m2.1.1.cmml" xref="Sx5.p2.2.m2.1.1"><lt id="Sx5.p2.2.m2.1.1.1.cmml" xref="Sx5.p2.2.m2.1.1.1"></lt><ci id="Sx5.p2.2.m2.1.1.2.cmml" xref="Sx5.p2.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx5.p2.2.m2.1.1.3.cmml" xref="Sx5.p2.2.m2.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p2.2.m2.1c">p&lt;0.001</annotation></semantics></math>) and uncertainty weighting models (<math id="Sx5.p2.3.m3.1" class="ltx_Math" alttext="p=0.0093" display="inline"><semantics id="Sx5.p2.3.m3.1a"><mrow id="Sx5.p2.3.m3.1.1" xref="Sx5.p2.3.m3.1.1.cmml"><mi id="Sx5.p2.3.m3.1.1.2" xref="Sx5.p2.3.m3.1.1.2.cmml">p</mi><mo id="Sx5.p2.3.m3.1.1.1" xref="Sx5.p2.3.m3.1.1.1.cmml">=</mo><mn id="Sx5.p2.3.m3.1.1.3" xref="Sx5.p2.3.m3.1.1.3.cmml">0.0093</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p2.3.m3.1b"><apply id="Sx5.p2.3.m3.1.1.cmml" xref="Sx5.p2.3.m3.1.1"><eq id="Sx5.p2.3.m3.1.1.1.cmml" xref="Sx5.p2.3.m3.1.1.1"></eq><ci id="Sx5.p2.3.m3.1.1.2.cmml" xref="Sx5.p2.3.m3.1.1.2">ğ‘</ci><cn type="float" id="Sx5.p2.3.m3.1.1.3.cmml" xref="Sx5.p2.3.m3.1.1.3">0.0093</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p2.3.m3.1c">p=0.0093</annotation></semantics></math>) (see Table C in S4 Appendix). No statistical difference was observed for the baseline models (see <a href="#Sx5.T5" title="In Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>). A larger dataset is required to fully assess the significance of the transfer learning, as only eleven test samples were available for this study.</p>
</div>
<figure id="Sx5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="Sx5.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="Sx5.T4.3.2" class="ltx_text" style="font-size:90%;">Evaluation of models trained on the Oslo-CoMet dataset from finetuning the entire architecture.</span></figcaption>
<div id="Sx5.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:139.5pt;vertical-align:-9.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-23.9pt,7.1pt) scale(0.90076660691081,0.90076660691081) ;">
<table id="Sx5.T4.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T4.4.1.1.1" class="ltx_tr">
<th id="Sx5.T4.4.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_tt">Model</th>
<td id="Sx5.T4.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SSIM</td>
<td id="Sx5.T4.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">NCC</td>
<td id="Sx5.T4.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">DSC</td>
<td id="Sx5.T4.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HD</td>
<td id="Sx5.T4.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">HD95</td>
<td id="Sx5.T4.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">TRE</td>
<td id="Sx5.T4.4.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">Runtime</td>
</tr>
<tr id="Sx5.T4.4.1.2.2" class="ltx_tr">
<th id="Sx5.T4.4.1.2.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx5.T4.4.1.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:24.2pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.2.2.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">BL-N</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.52Â±0.08</td>
<td id="Sx5.T4.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">
<div id="Sx5.T4.4.1.2.2.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.2.2.3.1.1" class="ltx_p"><span id="Sx5.T4.4.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">0.17Â±0.07</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.23Â±0.07</td>
<td id="Sx5.T4.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">57.98Â±5.36</td>
<td id="Sx5.T4.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">33.00Â±5.14</td>
<td id="Sx5.T4.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">24.09Â±5.92</td>
<td id="Sx5.T4.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">0.77Â±1.45</td>
</tr>
<tr id="Sx5.T4.4.1.3.3" class="ltx_tr">
<th id="Sx5.T4.4.1.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T4.4.1.3.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.7pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.3.3.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">BL-NS</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.3.3.2" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.3.3.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.3.3.2.1.1" class="ltx_p"><span id="Sx5.T4.4.1.3.3.2.1.1.1" class="ltx_text ltx_font_bold">0.61Â±0.09</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.3.3.3" class="ltx_td ltx_align_center">0.16Â±0.07</td>
<td id="Sx5.T4.4.1.3.3.4" class="ltx_td ltx_align_center">0.14Â±0.03</td>
<td id="Sx5.T4.4.1.3.3.5" class="ltx_td ltx_align_center">82.91Â±6.96</td>
<td id="Sx5.T4.4.1.3.3.6" class="ltx_td ltx_align_center">59.94Â±6.41</td>
<td id="Sx5.T4.4.1.3.3.7" class="ltx_td ltx_align_center">34.41Â±13.03</td>
<td id="Sx5.T4.4.1.3.3.8" class="ltx_td ltx_align_center">0.77Â±1.46</td>
</tr>
<tr id="Sx5.T4.4.1.4.4" class="ltx_tr">
<th id="Sx5.T4.4.1.4.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T4.4.1.4.4.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:31.9pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.4.4.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">SG-ND</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.4.4.2" class="ltx_td ltx_align_center">0.56Â±0.13</td>
<td id="Sx5.T4.4.1.4.4.3" class="ltx_td ltx_align_center">0.14Â±0.07</td>
<td id="Sx5.T4.4.1.4.4.4" class="ltx_td ltx_align_center">0.43Â±0.09</td>
<td id="Sx5.T4.4.1.4.4.5" class="ltx_td ltx_align_center">15.81Â±5.56</td>
<td id="Sx5.T4.4.1.4.4.6" class="ltx_td ltx_align_center">9.05Â±3.18</td>
<td id="Sx5.T4.4.1.4.4.7" class="ltx_td ltx_align_center">5.89Â±3.10</td>
<td id="Sx5.T4.4.1.4.4.8" class="ltx_td ltx_align_center">0.79Â±1.56</td>
</tr>
<tr id="Sx5.T4.4.1.5.5" class="ltx_tr">
<th id="Sx5.T4.4.1.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T4.4.1.5.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:37.4pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.5.5.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">SG-NSD</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.5.5.2" class="ltx_td ltx_align_center">0.58Â±0.13</td>
<td id="Sx5.T4.4.1.5.5.3" class="ltx_td ltx_align_center">0.14Â±0.07</td>
<td id="Sx5.T4.4.1.5.5.4" class="ltx_td ltx_align_center">0.42Â±0.10</td>
<td id="Sx5.T4.4.1.5.5.5" class="ltx_td ltx_align_center">16.26Â±6.37</td>
<td id="Sx5.T4.4.1.5.5.6" class="ltx_td ltx_align_center">9.50Â±3.51</td>
<td id="Sx5.T4.4.1.5.5.7" class="ltx_td ltx_align_center">5.84Â±3.01</td>
<td id="Sx5.T4.4.1.5.5.8" class="ltx_td ltx_align_center">0.76Â±1.48</td>
</tr>
<tr id="Sx5.T4.4.1.6.6" class="ltx_tr">
<th id="Sx5.T4.4.1.6.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T4.4.1.6.6.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:41.8pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.6.6.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSD</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.6.6.2" class="ltx_td ltx_align_center">0.58Â±0.12</td>
<td id="Sx5.T4.4.1.6.6.3" class="ltx_td ltx_align_center">0.14Â±0.06</td>
<td id="Sx5.T4.4.1.6.6.4" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.6.6.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.6.6.4.1.1" class="ltx_p"><span id="Sx5.T4.4.1.6.6.4.1.1.1" class="ltx_text ltx_font_bold">0.48Â±0.11</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.6.6.5" class="ltx_td ltx_align_center">15.53Â±5.80</td>
<td id="Sx5.T4.4.1.6.6.6" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.6.6.6.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.6.6.6.1.1" class="ltx_p"><span id="Sx5.T4.4.1.6.6.6.1.1.1" class="ltx_text ltx_font_bold">7.84Â±3.17</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.6.6.7" class="ltx_td ltx_align_center">4.05Â±2.41</td>
<td id="Sx5.T4.4.1.6.6.8" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.6.6.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.6.6.8.1.1" class="ltx_p"><span id="Sx5.T4.4.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">0.76Â±1.47</span></p>
</span></div>
</td>
</tr>
<tr id="Sx5.T4.4.1.7.7" class="ltx_tr">
<th id="Sx5.T4.4.1.7.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T4.4.1.7.7.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:49.3pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.7.7.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSDH</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.7.7.2" class="ltx_td ltx_align_center">0.59Â±0.12</td>
<td id="Sx5.T4.4.1.7.7.3" class="ltx_td ltx_align_center">0.14Â±0.06</td>
<td id="Sx5.T4.4.1.7.7.4" class="ltx_td ltx_align_center">0.47Â±0.10</td>
<td id="Sx5.T4.4.1.7.7.5" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.7.7.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:48.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.7.7.5.1.1" class="ltx_p"><span id="Sx5.T4.4.1.7.7.5.1.1.1" class="ltx_text ltx_font_bold">15.29Â±5.65</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.7.7.6" class="ltx_td ltx_align_center">7.91Â±2.82</td>
<td id="Sx5.T4.4.1.7.7.7" class="ltx_td ltx_align_center">
<div id="Sx5.T4.4.1.7.7.7.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.7.7.7.1.1" class="ltx_p"><span id="Sx5.T4.4.1.7.7.7.1.1.1" class="ltx_text ltx_font_bold">3.95Â±2.09</span></p>
</span></div>
</td>
<td id="Sx5.T4.4.1.7.7.8" class="ltx_td ltx_align_center">0.78Â±1.51</td>
</tr>
<tr id="Sx5.T4.4.1.8.8" class="ltx_tr">
<th id="Sx5.T4.4.1.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<div id="Sx5.T4.4.1.8.8.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:55.4pt;height:8.800000000000001pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T4.4.1.8.8.1.1.1" class="ltx_p"><span id="Sx5.T4.4.1.8.8.1.1.1.1" class="ltx_text ltx_font_bold">Unregistered</span></p>
</span></div>
</th>
<td id="Sx5.T4.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.60Â±0.13</td>
<td id="Sx5.T4.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.09Â±0.05</td>
<td id="Sx5.T4.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.24Â±0.08</td>
<td id="Sx5.T4.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">24.60Â±5.56</td>
<td id="Sx5.T4.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">19.06Â±4.89</td>
<td id="Sx5.T4.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">11.86Â±2.75</td>
<td id="Sx5.T4.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</tbody>
</table>
<p id="Sx5.T4.4.2" class="ltx_p">The best performing methods for each metric are highlighted in bold.</p>
</span></div>
</figure>
<figure id="Sx5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="Sx5.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="Sx5.T5.3.2" class="ltx_text" style="font-size:90%;">Evaluation of the models trained on the Oslo-CoMet dataset from finetuning in two steps.</span></figcaption>
<div id="Sx5.T5.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:163.4pt;vertical-align:-9.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.4pt,12.9pt) scale(0.856296470127244,0.856296470127244) ;">
<table id="Sx5.T5.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx5.T5.4.1.1.1" class="ltx_tr">
<th id="Sx5.T5.4.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_tt">Model</th>
<td id="Sx5.T5.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">SSIM</td>
<td id="Sx5.T5.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">NCC</td>
<td id="Sx5.T5.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">DSC</td>
<td id="Sx5.T5.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">HD</td>
<td id="Sx5.T5.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">HD95</td>
<td id="Sx5.T5.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">TRE</td>
<td id="Sx5.T5.4.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">Runtime</td>
</tr>
<tr id="Sx5.T5.4.1.2.2" class="ltx_tr">
<th id="Sx5.T5.4.1.2.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx5.T5.4.1.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:24.2pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.2.2.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">BL-N</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.52Â±0.07</td>
<td id="Sx5.T5.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">
<div id="Sx5.T5.4.1.2.2.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.2.2.3.1.1" class="ltx_p"><span id="Sx5.T5.4.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">0.19Â±0.07</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.24Â±0.06</td>
<td id="Sx5.T5.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">60.92Â±26.06</td>
<td id="Sx5.T5.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">39.96Â±30.25</td>
<td id="Sx5.T5.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">22.34Â±8.60</td>
<td id="Sx5.T5.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">0.79Â±1.52</td>
</tr>
<tr id="Sx5.T5.4.1.3.3" class="ltx_tr">
<th id="Sx5.T5.4.1.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.3.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:29.7pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.3.3.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">BL-NS</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.3.3.2" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.3.3.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.3.3.2.1.1" class="ltx_p"><span id="Sx5.T5.4.1.3.3.2.1.1.1" class="ltx_text ltx_font_bold">0.62Â±0.10</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.3.3.3" class="ltx_td ltx_align_center">0.17Â±0.07</td>
<td id="Sx5.T5.4.1.3.3.4" class="ltx_td ltx_align_center">0.14Â±0.04</td>
<td id="Sx5.T5.4.1.3.3.5" class="ltx_td ltx_align_center">85.71Â±6.40</td>
<td id="Sx5.T5.4.1.3.3.6" class="ltx_td ltx_align_center">60.93Â±4.15</td>
<td id="Sx5.T5.4.1.3.3.7" class="ltx_td ltx_align_center">32.84Â±11.90</td>
<td id="Sx5.T5.4.1.3.3.8" class="ltx_td ltx_align_center">0.76Â±1.45</td>
</tr>
<tr id="Sx5.T5.4.1.4.4" class="ltx_tr">
<th id="Sx5.T5.4.1.4.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.4.4.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:31.9pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.4.4.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">SG-ND</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.4.4.2" class="ltx_td ltx_align_center">0.56Â±0.12</td>
<td id="Sx5.T5.4.1.4.4.3" class="ltx_td ltx_align_center">0.14Â±0.07</td>
<td id="Sx5.T5.4.1.4.4.4" class="ltx_td ltx_align_center">0.44Â±0.09</td>
<td id="Sx5.T5.4.1.4.4.5" class="ltx_td ltx_align_center">16.12Â±5.29</td>
<td id="Sx5.T5.4.1.4.4.6" class="ltx_td ltx_align_center">8.87Â±2.94</td>
<td id="Sx5.T5.4.1.4.4.7" class="ltx_td ltx_align_center">5.12Â±2.52</td>
<td id="Sx5.T5.4.1.4.4.8" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.4.4.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.4.4.8.1.1" class="ltx_p"><span id="Sx5.T5.4.1.4.4.8.1.1.1" class="ltx_text ltx_font_bold">0.77Â±1.48</span></p>
</span></div>
</td>
</tr>
<tr id="Sx5.T5.4.1.5.5" class="ltx_tr">
<th id="Sx5.T5.4.1.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.5.5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:37.4pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.5.5.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">SG-NSD</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.5.5.2" class="ltx_td ltx_align_center">0.58Â±0.12</td>
<td id="Sx5.T5.4.1.5.5.3" class="ltx_td ltx_align_center">0.15Â±0.07</td>
<td id="Sx5.T5.4.1.5.5.4" class="ltx_td ltx_align_center">0.43Â±0.08</td>
<td id="Sx5.T5.4.1.5.5.5" class="ltx_td ltx_align_center">16.93Â±6.50</td>
<td id="Sx5.T5.4.1.5.5.6" class="ltx_td ltx_align_center">9.17Â±3.02</td>
<td id="Sx5.T5.4.1.5.5.7" class="ltx_td ltx_align_center">5.21Â±2.40</td>
<td id="Sx5.T5.4.1.5.5.8" class="ltx_td ltx_align_center">0.77Â±1.49</td>
</tr>
<tr id="Sx5.T5.4.1.6.6" class="ltx_tr">
<th id="Sx5.T5.4.1.6.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.6.6.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:41.8pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.6.6.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSD</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.6.6.2" class="ltx_td ltx_align_center">0.60Â±0.11</td>
<td id="Sx5.T5.4.1.6.6.3" class="ltx_td ltx_align_center">0.15Â±0.06</td>
<td id="Sx5.T5.4.1.6.6.4" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.6.6.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.6.6.4.1.1" class="ltx_p"><span id="Sx5.T5.4.1.6.6.4.1.1.1" class="ltx_text ltx_font_bold">0.53Â±0.13</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.6.6.5" class="ltx_td ltx_align_center">15.13Â±5.68</td>
<td id="Sx5.T5.4.1.6.6.6" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.6.6.6.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.6.6.6.1.1" class="ltx_p"><span id="Sx5.T5.4.1.6.6.6.1.1.1" class="ltx_text ltx_font_bold">6.97Â±2.83</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.6.6.7" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.6.6.7.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.6.6.7.1.1" class="ltx_p"><span id="Sx5.T5.4.1.6.6.7.1.1.1" class="ltx_text ltx_font_bold">3.40Â±1.91</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.6.6.8" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.6.6.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.6.6.8.1.1" class="ltx_p"><span id="Sx5.T5.4.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">0.77Â±1.48</span></p>
</span></div>
</td>
</tr>
<tr id="Sx5.T5.4.1.7.7" class="ltx_tr">
<th id="Sx5.T5.4.1.7.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.7.7.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:49.3pt;height:6.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.7.7.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">UW-NSDH</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.7.7.2" class="ltx_td ltx_align_center">0.60Â±0.12</td>
<td id="Sx5.T5.4.1.7.7.3" class="ltx_td ltx_align_center">0.15Â±0.06</td>
<td id="Sx5.T5.4.1.7.7.4" class="ltx_td ltx_align_center">0.50Â±0.12</td>
<td id="Sx5.T5.4.1.7.7.5" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.7.7.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:48.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.7.7.5.1.1" class="ltx_p"><span id="Sx5.T5.4.1.7.7.5.1.1.1" class="ltx_text ltx_font_bold">14.79Â±5.79</span></p>
</span></div>
</td>
<td id="Sx5.T5.4.1.7.7.6" class="ltx_td ltx_align_center">7.37Â±2.99</td>
<td id="Sx5.T5.4.1.7.7.7" class="ltx_td ltx_align_center">3.55Â±2.14</td>
<td id="Sx5.T5.4.1.7.7.8" class="ltx_td ltx_align_center">
<div id="Sx5.T5.4.1.7.7.8.1" class="ltx_inline-block ltx_transformed_outer" style="width:43.3pt;height:7.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.7.7.8.1.1" class="ltx_p"><span id="Sx5.T5.4.1.7.7.8.1.1.1" class="ltx_text ltx_font_bold">0.77Â±1.48</span></p>
</span></div>
</td>
</tr>
<tr id="Sx5.T5.4.1.8.8" class="ltx_tr">
<th id="Sx5.T5.4.1.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">
<div id="Sx5.T5.4.1.8.8.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:18.3pt;height:8.699999999999999pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.8.8.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.8.8.1.1.1.1" class="ltx_text ltx_font_bold">SyN</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_t">0.61Â±0.13</td>
<td id="Sx5.T5.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t">0.20Â±0.07</td>
<td id="Sx5.T5.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_t">0.49Â±0.01</td>
<td id="Sx5.T5.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t">17.93Â±3.44</td>
<td id="Sx5.T5.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_t">9.62Â±1.57</td>
<td id="Sx5.T5.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">22.34Â±4.96</td>
<td id="Sx5.T5.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_t">10.01Â±3.69</td>
</tr>
<tr id="Sx5.T5.4.1.9.9" class="ltx_tr">
<th id="Sx5.T5.4.1.9.9.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">
<div id="Sx5.T5.4.1.9.9.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:32.8pt;height:8.699999999999999pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.9.9.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.9.9.1.1.1.1" class="ltx_text ltx_font_bold">SyNCC</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.9.9.2" class="ltx_td ltx_align_center">0.63Â±0.13</td>
<td id="Sx5.T5.4.1.9.9.3" class="ltx_td ltx_align_center">0.20Â±0.07</td>
<td id="Sx5.T5.4.1.9.9.4" class="ltx_td ltx_align_center">0.49Â±0.01</td>
<td id="Sx5.T5.4.1.9.9.5" class="ltx_td ltx_align_center">18.59Â±2.99</td>
<td id="Sx5.T5.4.1.9.9.6" class="ltx_td ltx_align_center">9.64Â±1.61</td>
<td id="Sx5.T5.4.1.9.9.7" class="ltx_td ltx_align_center">22.31Â±5.04</td>
<td id="Sx5.T5.4.1.9.9.8" class="ltx_td ltx_align_center">323.81Â±87.13</td>
</tr>
<tr id="Sx5.T5.4.1.10.10" class="ltx_tr">
<th id="Sx5.T5.4.1.10.10.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<div id="Sx5.T5.4.1.10.10.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:55.4pt;height:8.800000000000001pt;vertical-align:-1.9pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="Sx5.T5.4.1.10.10.1.1.1" class="ltx_p"><span id="Sx5.T5.4.1.10.10.1.1.1.1" class="ltx_text ltx_font_bold">Unregistered</span></p>
</span></div>
</th>
<td id="Sx5.T5.4.1.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.60Â±0.13</td>
<td id="Sx5.T5.4.1.10.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.09Â±0.05</td>
<td id="Sx5.T5.4.1.10.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.24Â±0.08</td>
<td id="Sx5.T5.4.1.10.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">24.60Â±5.56</td>
<td id="Sx5.T5.4.1.10.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">19.06Â±4.89</td>
<td id="Sx5.T5.4.1.10.10.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">11.86Â±2.75</td>
<td id="Sx5.T5.4.1.10.10.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</tbody>
</table>
<p id="Sx5.T5.4.2" class="ltx_p">The best performing methods for each metric are highlighted in bold.</p>
</span></div>
</figure>
<div id="Sx5.p3" class="ltx_para">
<p id="Sx5.p3.1" class="ltx_p">Surprisingly, adding HD to the set of losses had limited effect on the performance. We believe this is due to HD being sensitive to outliers and minor annotation errors, which is likely to happen as the annotations used in this study were automatically generated. Furthermore, NCC proved to be a well-suited intensity-based loss function, with no real benefit of adding an additional intensity-based loss function such as SSIM.</p>
</div>
<div id="Sx5.p4" class="ltx_para">
<p id="Sx5.p4.1" class="ltx_p">From studying the adaptive loss weights evolution during training (see Figs E-L in S3 Appendix), it is possible to deduce an interpretation regarding influence and benefit from each loss component over the network. Evidently, SSIM was favoured over NCC during training, even though SSIM was deemed less useful for image registration compared to NCC. A rationale can be hypothesised from SSIM being easier to optimise, being a perception-based loss. Interestingly, the loss weight curves all seemed to follow the same pattern. Upweighted losses are linearly increased until a plateau is reached and the opposite behaviour happens for the downweighted losses. This may indicate that uncertainty weighting lacks the capacity of task prioritisation, which could have been helpful at a later stage in training. Such an approach has been proposed in the literatureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, simply not for similar image registration tasks. Hence, a comparison of other multi-task learning designs might be worth investigating in future work.</p>
</div>
<div id="Sx5.p5" class="ltx_para">
<p id="Sx5.p5.2" class="ltx_p">From <a href="#Sx5.T4" title="In Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tables</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> andÂ <a href="#Sx5.T5" title="Table 5 â€£ Discussion" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> it can be observed the benefit of using segmentation guidance for training deep registration models. Furthermore, when compared to the traditional method ANTs, using SyN and SyNCC, a significant improvement on TRE is observed (<math id="Sx5.p5.1.m1.1" class="ltx_Math" alttext="p&lt;0.001" display="inline"><semantics id="Sx5.p5.1.m1.1a"><mrow id="Sx5.p5.1.m1.1.1" xref="Sx5.p5.1.m1.1.1.cmml"><mi id="Sx5.p5.1.m1.1.1.2" xref="Sx5.p5.1.m1.1.1.2.cmml">p</mi><mo id="Sx5.p5.1.m1.1.1.1" xref="Sx5.p5.1.m1.1.1.1.cmml">&lt;</mo><mn id="Sx5.p5.1.m1.1.1.3" xref="Sx5.p5.1.m1.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p5.1.m1.1b"><apply id="Sx5.p5.1.m1.1.1.cmml" xref="Sx5.p5.1.m1.1.1"><lt id="Sx5.p5.1.m1.1.1.1.cmml" xref="Sx5.p5.1.m1.1.1.1"></lt><ci id="Sx5.p5.1.m1.1.1.2.cmml" xref="Sx5.p5.1.m1.1.1.2">ğ‘</ci><cn type="float" id="Sx5.p5.1.m1.1.1.3.cmml" xref="Sx5.p5.1.m1.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p5.1.m1.1c">p&lt;0.001</annotation></semantics></math>) (Table D in S4 Appendix), with differences close to 17 mm on the Oslo-CoMet test set. Further improved using uncertainty weighting. No significant value was observed between the baseline model and ANTs (<math id="Sx5.p5.2.m2.1" class="ltx_Math" alttext="p=0.5845" display="inline"><semantics id="Sx5.p5.2.m2.1a"><mrow id="Sx5.p5.2.m2.1.1" xref="Sx5.p5.2.m2.1.1.cmml"><mi id="Sx5.p5.2.m2.1.1.2" xref="Sx5.p5.2.m2.1.1.2.cmml">p</mi><mo id="Sx5.p5.2.m2.1.1.1" xref="Sx5.p5.2.m2.1.1.1.cmml">=</mo><mn id="Sx5.p5.2.m2.1.1.3" xref="Sx5.p5.2.m2.1.1.3.cmml">0.5845</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p5.2.m2.1b"><apply id="Sx5.p5.2.m2.1.1.cmml" xref="Sx5.p5.2.m2.1.1"><eq id="Sx5.p5.2.m2.1.1.1.cmml" xref="Sx5.p5.2.m2.1.1.1"></eq><ci id="Sx5.p5.2.m2.1.1.2.cmml" xref="Sx5.p5.2.m2.1.1.2">ğ‘</ci><cn type="float" id="Sx5.p5.2.m2.1.1.3.cmml" xref="Sx5.p5.2.m2.1.1.3">0.5845</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p5.2.m2.1c">p=0.5845</annotation></semantics></math>), which shows that naive image-only training is not enough for the model to understand the registration task. Not surprisingly, runtimes of the deep registration models are dramatically better than those of ANTs, taking the latter up to five minutes on average using the SyNCC configuration.</p>
</div>
<div id="Sx5.p6" class="ltx_para">
<p id="Sx5.p6.1" class="ltx_p">A sizeable downside in training CNNs for image registration remains the long training runtime. Having access to pretrained models in order to perform transfer learning alleviates this issue, but the substantial amount of training data required, and in our use case annotated data, persists as another tremendous drawback.</p>
</div>
<div id="Sx5.p7" class="ltx_para">
<p id="Sx5.p7.1" class="ltx_p">Once deployed, such registration models often fail to generalise to other anatomies, imaging modalities, and data shifts in general, resulting in ad hoc solutions. As part of future work investigations, developing more generic deep image registration models would be of interest, tackling both training and deployment shortcomings.</p>
</div>
<div id="Sx5.p8" class="ltx_para">
<p id="Sx5.p8.1" class="ltx_p">In this study, only synthetic moving images and mostly algorithm-based annotations were used for evaluation. To verify the clinical relevance of the proposed models, a dataset with manual delineations of structures both for the fixed and moving images, and with clinically relevant movements, is required. To illustrate this situation, Table E in S4 Appendix shows a comparison between manual and automatic segmentations of the parenchyma and the vascular structures on the Oslo-CoMet test set images. Both DSC and HD95 are reported. A good concordance between the automatic and manual parenchyma segmentations can be observed. However, vascular segmentation poses a more challenging problem for automatic methods to tackle. In future work, assessment of the impact of vascular segmentations of diverse quality could be considered. This investigation would require the delineation of the entire training set, which itself is extremely challenging and was thus deemed outside the scope of this study. Nevertheless, such investigation is of definite value and should be part of future works, additionally including human qualitative evaluation of the clinical relevance.</p>
</div>
<div id="Sx5.p9" class="ltx_para">
<p id="Sx5.p9.1" class="ltx_p">The sole focus on mono-modal registration can be considered as a limitation from our work. Especially when selecting the loss functions. For instance, in multi-modal registration it is common to use mutual information. Hence, investigating the translation between mono and multi-modal designs is of value to assess applicability over various registration tasks. The recent introduction of the new Learn2Reg challenge datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> represents an adequate alley for further investigation over this aspect. While the U-Net architecture, used in this study, is not recent, a substantial number of publications have favoured it for image registration, as shown to outperform vision transformers on smaller datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Alternatively, generative adversarial models should be tested, as these networks have shown to produce more realistic looking imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Self-attentionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> for encoding anatomical information, or graph-based neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> for improved vascular segmentation-guided registration, are concepts that also should be considered in future work.</p>
</div>
</section>
<section id="Sx6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conclusion</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">In the presented study, we demonstrated that registration models can be improved through transfer learning and adaptive loss weighting even with minimal data without manual annotations. The proposed framework DDMR also enables on-the-fly generation of artificial moving images, without the need to store copies on disk. In future work, DDMR should be validated on data of other anatomies and imaging modalities to further assess its benefit.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ1.</span>
<span class="ltx_bibblock">
Fretland Ã…A, Dagenborg VJ, BjÃ¸rnelv GMW, Kazaryan AM, Kristiansen R,
Fagerland MW, etÂ al.

</span>
<span class="ltx_bibblock">Laparoscopic Versus Open Resection for Colorectal Liver Metastases.

</span>
<span class="ltx_bibblock">Annals of Surgery. 2018;267:199â€“207.

</span>
<span class="ltx_bibblock">doi:10.1097/SLA.0000000000002353.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ2.</span>
<span class="ltx_bibblock">
Alam F, Rahman SU, Ullah S, Gulati K.

</span>
<span class="ltx_bibblock">Medical image registration in image guided surgery: Issues,
challenges and research opportunities.

</span>
<span class="ltx_bibblock">Biocybernetics and Biomedical Engineering. 2018;38(1):71â€“89.

</span>
<span class="ltx_bibblock">doi:10.1016/j.bbe.2017.10.001.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ3.</span>
<span class="ltx_bibblock">
Cash DM, Miga MI, Glasgow SC, Dawant BM, Clements LW, Cao Z, etÂ al.

</span>
<span class="ltx_bibblock">Concepts and Preliminary Data Toward the Realization of Image-guided
Liver Surgery.

</span>
<span class="ltx_bibblock">Journal of Gastrointestinal Surgery. 2007;11:844â€“859.

</span>
<span class="ltx_bibblock">doi:10.1007/s11605-007-0090-6.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ4.</span>
<span class="ltx_bibblock">
Pelanis E, Teatini A, Eigl B, Regensburger A, Alzaga A, Kumar RP, etÂ al.

</span>
<span class="ltx_bibblock">Evaluation of a novel navigation platform for laparoscopic liver
surgery with organ deformation compensation using injected fiducials.

</span>
<span class="ltx_bibblock">Medical Image Analysis. 2021;69:101946.

</span>
<span class="ltx_bibblock">doi:https://doi.org/10.1016/j.media.2020.101946.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ5.</span>
<span class="ltx_bibblock">
Prevost GA, Eigl B, Paolucci I, Rudolph T, Peterhans M, Weber S, etÂ al.

</span>
<span class="ltx_bibblock">Efficiency, Accuracy and Clinical Applicability of a New Image-Guided
Surgery System in 3D Laparoscopic Liver Surgery.

</span>
<span class="ltx_bibblock">Journal of Gastrointestinal Surgery. 2020;24:2251â€“2258.

</span>
<span class="ltx_bibblock">doi:10.1007/S11605-019-04395-7/TABLES/3.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ6.</span>
<span class="ltx_bibblock">
Baisa NL, Bricq S, Lalande A.

</span>
<span class="ltx_bibblock">MRI-PET Registration with Automated Algorithm in Pre-clinical
Studies.

</span>
<span class="ltx_bibblock">arXiv. 2017;.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ7.</span>
<span class="ltx_bibblock">
MartÃ­nez-Cecilia D, Wicherts DA, Cipriani F, Berardi G, Barkhatov L, Lainas
P, etÂ al.

</span>
<span class="ltx_bibblock">Impact of resection margins for colorectal liver metastases in
laparoscopic and open liver resection: a propensity score analysis.

</span>
<span class="ltx_bibblock">Surgical Endoscopy. 2021;35(2):809â€“818.

</span>
<span class="ltx_bibblock">doi:10.1007/s00464-020-07452-4.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ8.</span>
<span class="ltx_bibblock">
Fusaglia M, Tinguely P, Banz V, Weber S, Lu H.

</span>
<span class="ltx_bibblock">A Novel Ultrasound-Based Registration for Image-Guided Laparoscopic
Liver Ablation.

</span>
<span class="ltx_bibblock">Surgical Innovation. 2016;23:397â€“406.

</span>
<span class="ltx_bibblock">doi:10.1177/1553350616637691.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ9.</span>
<span class="ltx_bibblock">
Balakrishnan G, Zhao A, Sabuncu MR, Guttag J, Dalca AV.

</span>
<span class="ltx_bibblock">VoxelMorph: A Learning Framework for Deformable Medical Image
Registration.

</span>
<span class="ltx_bibblock">IEEE Transactions on Medical Imaging. 2019;38(8):1788â€“1800.

</span>
<span class="ltx_bibblock">doi:10.1109/TMI.2019.2897538.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ10.</span>
<span class="ltx_bibblock">
Dosovitskiy A, Brox T.

</span>
<span class="ltx_bibblock">Generating Images with Perceptual Similarity Metrics based on Deep
Networks.

</span>
<span class="ltx_bibblock">In: Lee D, Sugiyama M, Luxburg U, Guyon I, Garnett R, editors.
Advances in Neural Information Processing Systems. vol.Â 29; 2016.Available
from:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2016/file/371bce7dc83817b7893bcdeed13799b5-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2016/file/371bce7dc83817b7893bcdeed13799b5-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ11.</span>
<span class="ltx_bibblock">
Survarachakan S, Prasad PJR, Naseem R, PÃ©rez de Frutos J, Kumar RP,
LangÃ¸ T, etÂ al.

</span>
<span class="ltx_bibblock">Deep learning for image-based liver analysis â€” A comprehensive
review focusing on malignant lesions.

</span>
<span class="ltx_bibblock">Artificial Intelligence in Medicine. 2022;130:102331.

</span>
<span class="ltx_bibblock">doi:https://doi.org/10.1016/j.artmed.2022.102331.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ12.</span>
<span class="ltx_bibblock">
Maurer CR, Fitzpatrick JM, Wang MY, Galloway RL, Maciunas RJ, Allen GS.

</span>
<span class="ltx_bibblock">Registration of head volume images using implantable fiducial
markers.

</span>
<span class="ltx_bibblock">IEEE Transactions on Medical Imaging. 1997;16(4):447â€“462.

</span>
<span class="ltx_bibblock">doi:10.1109/42.611354.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ13.</span>
<span class="ltx_bibblock">
Wu G, Kim M, Wang Q, Gao Y, Liao S, Shen D.

</span>
<span class="ltx_bibblock">Unsupervised Deep Feature Learning for Deformable Registration of MR
Brain Images.

</span>
<span class="ltx_bibblock">In: Medical Image Computing and Computer Assisted Intervention.
vol.Â 16; 2013. p. 649â€“656.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ14.</span>
<span class="ltx_bibblock">
Jaderberg M, Simonyan K, Zisserman A, kavukcuoglu k.

</span>
<span class="ltx_bibblock">Spatial Transformer Networks.

</span>
<span class="ltx_bibblock">In: Advances in Neural Information Processing Systems. vol.Â 28;
2015.Available from:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2015/file/33ceb07bf4eeb3da587e268d663aba1a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2015/file/33ceb07bf4eeb3da587e268d663aba1a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ15.</span>
<span class="ltx_bibblock">
Ronneberger O, Fischer P, Brox T.

</span>
<span class="ltx_bibblock">U-Net: Convolutional Networks for Biomedical Image Segmentation.

</span>
<span class="ltx_bibblock">In: Navab N, Hornegger J, Wells WM, Frangi AF, editors. Medical Image
Computing and Computer-Assisted Intervention â€“ MICCAI 2015. Cham: Springer
International Publishing; 2015. p. 234â€“241.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ16.</span>
<span class="ltx_bibblock">
Yang X, Kwitt R, Styner M, Niethammer M.

</span>
<span class="ltx_bibblock">Quicksilver: Fast predictive image registration â€“ A deep learning
approach.

</span>
<span class="ltx_bibblock">NeuroImage. 2017;158:378â€“396.

</span>
<span class="ltx_bibblock">doi:10.1016/j.neuroimage.2017.07.008.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ17.</span>
<span class="ltx_bibblock">
RohÃ© MM, Datar M, Heimann T, Sermesant M, Pennec X.

</span>
<span class="ltx_bibblock">SVF-Net: Learning Deformable Image Registration Using Shape
Matching.

</span>
<span class="ltx_bibblock">vol. 2878; 2017. p. 266â€“274.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ18.</span>
<span class="ltx_bibblock">
Mok TCW, Chung ACS.

</span>
<span class="ltx_bibblock">Large Deformation Diffeomorphic Image Registration with Laplacian
Pyramid Networks.

</span>
<span class="ltx_bibblock">In: Lecture Notes in Computer Science (including subseries Lecture
Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). vol.
12263; 2020. p. 211â€“221.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ19.</span>
<span class="ltx_bibblock">
Hu Y, Modat M, Gibson E, Li W, Ghavami N, Bonmati E, etÂ al.

</span>
<span class="ltx_bibblock">Weakly-supervised convolutional neural networks for multimodal image
registration.

</span>
<span class="ltx_bibblock">Medical Image Analysis. 2018;49:1â€“13.

</span>
<span class="ltx_bibblock">doi:https://doi.org/10.1016/j.media.2018.07.002.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ20.</span>
<span class="ltx_bibblock">
Li H, Fan Y.

</span>
<span class="ltx_bibblock">Non-rigid image registration using self-supervised fully
convolutional networks without training data.

</span>
<span class="ltx_bibblock">In: 2018 IEEE 15th International Symposium on Biomedical Imaging
(ISBI 2018); 2018. p. 1075â€“1078.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ21.</span>
<span class="ltx_bibblock">
Fu Y, Lei Y, Wang T, Higgins K, Bradley JD, Curran WJ, etÂ al.

</span>
<span class="ltx_bibblock">LungRegNet: An unsupervised deformable image registration method for
4D-CT lung.

</span>
<span class="ltx_bibblock">Medical Physics. 2020;47(4):1763â€“1774.

</span>
<span class="ltx_bibblock">doi:10.1002/MP.14065.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ22.</span>
<span class="ltx_bibblock">
Lei Y, Fu Y, Harms J, Wang T, Curran WJ, Liu T, etÂ al.

</span>
<span class="ltx_bibblock">4D-CT Deformable Image Registration Using an Unsupervised Deep
Convolutional Neural Network.

</span>
<span class="ltx_bibblock">Lecture Notes in Computer Science (including subseries Lecture Notes
in Artificial Intelligence and Lecture Notes in Bioinformatics).
2019;11850:26â€“33.

</span>
<span class="ltx_bibblock">doi:10.1007/978-3-030-32486-5_4.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ23.</span>
<span class="ltx_bibblock">
Hu J, Luo Z, Wang X, Sun S, Yin Y, Cao K, etÂ al.

</span>
<span class="ltx_bibblock">End-to-end multimodal image registration via reinforcement
learning.

</span>
<span class="ltx_bibblock">Medical Image Analysis. 2021;68.

</span>
<span class="ltx_bibblock">doi:10.1016/J.MEDIA.2020.101878.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ24.</span>
<span class="ltx_bibblock">
Hering A, Hansen L, Mok TCW, Chung ACS, Siebert H, HÃ¤ger S, etÂ al.

</span>
<span class="ltx_bibblock">Learn2Reg: comprehensive multi-task medical image registration
challenge, dataset and evaluation in the era of deep learning.

</span>
<span class="ltx_bibblock">IEEE Transactions on Medical Imaging. 2022; p. 1â€“1.

</span>
<span class="ltx_bibblock">doi:10.1109/TMI.2022.3213983.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ25.</span>
<span class="ltx_bibblock">
Fretland Ã…A, Kazaryan AM, BjÃ¸rnbeth BA, Flatmark K, Andersen MH,
TÃ¸nnessen TI, etÂ al.

</span>
<span class="ltx_bibblock">Open versus laparoscopic liver resection for colorectal liver
metastases (the Oslo-CoMet study): Study protocol for a randomized controlled
trial.

</span>
<span class="ltx_bibblock">Trials. 2015;16(1):73.

</span>
<span class="ltx_bibblock">doi:10.1186/s13063-015-0577-5.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ26.</span>
<span class="ltx_bibblock">
Avants BB, Tustison NJ, Song G, Cook PA, Klein A, Gee JC.

</span>
<span class="ltx_bibblock">A reproducible evaluation of ANTs similarity metric performance in
brain image registration.

</span>
<span class="ltx_bibblock">NeuroImage. 2011;54(3):2033â€“2044.

</span>
<span class="ltx_bibblock">doi:https://doi.org/10.1016/j.neuroimage.2010.09.025.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ27.</span>
<span class="ltx_bibblock">
Pedersen A. andreped/livermask: v1.3.1; 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ28.</span>
<span class="ltx_bibblock">
Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, etÂ al.. TensorFlow:
Large-Scale Machine Learning on Heterogeneous Distributed Systems; 20115.

</span>
<span class="ltx_bibblock">Available from: <a target="_blank" href="https://www.tensorflow.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ29.</span>
<span class="ltx_bibblock">
Ã‡iÃ§ek Ã–, Abdulkadir A, Lienkamp SS, Brox T, Ronneberger O.

</span>
<span class="ltx_bibblock">3D U-Net: Learning Dense Volumetric Segmentation from Sparse
Annotation.

</span>
<span class="ltx_bibblock">Springer, Cham; 2016. p. 424â€“432.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ30.</span>
<span class="ltx_bibblock">
Cipolla R, Gal Y, Kendall A.

</span>
<span class="ltx_bibblock">Multi-task Learning Using Uncertainty to Weigh Losses for Scene
Geometry and Semantics.

</span>
<span class="ltx_bibblock">In: 2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition; 2018. p. 7482â€“7491.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ31.</span>
<span class="ltx_bibblock">
Seabold S, Perktold J.

</span>
<span class="ltx_bibblock">statsmodels: Econometric and statistical modeling with python.

</span>
<span class="ltx_bibblock">In: 9th Python in Science Conference; 2010.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ32.</span>
<span class="ltx_bibblock">
Virtanen P, Gommers R, Oliphant TE, Haberland M, Reddy T, Cournapeau D, etÂ al.

</span>
<span class="ltx_bibblock">SciPy 1.0: Fundamental Algorithms for Scientific Computing in
Python.

</span>
<span class="ltx_bibblock">Nature Methods. 2020;17:261â€“272.

</span>
<span class="ltx_bibblock">doi:10.1038/s41592-019-0686-2.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ33.</span>
<span class="ltx_bibblock">
Guo M, Haque A, Huang DA, Yeung S, Fei-Fei L.

</span>
<span class="ltx_bibblock">Dynamic Task Prioritization for Multitask Learning.

</span>
<span class="ltx_bibblock">In: Proceedings of the European Conference on Computer Vision (ECCV);
2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ34.</span>
<span class="ltx_bibblock">
Jia X, Bartlett J, Zhang T, Lu W, Qiu Z, Duan J.

</span>
<span class="ltx_bibblock">U-Net vs Transformer: Is U-Net Outdated in Medical Image
Registration?

</span>
<span class="ltx_bibblock">arXiv. 2022;doi:10.48550/arxiv.2208.04939.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ35.</span>
<span class="ltx_bibblock">
Bhadra S, Zhou W, Anastasio MA.

</span>
<span class="ltx_bibblock">Medical image reconstruction with image-adaptive priors learned by
use of generative adversarial networks.

</span>
<span class="ltx_bibblock">https://doiorg/101117/122549750. 2020;11312:206â€“213.

</span>
<span class="ltx_bibblock">doi:10.1117/12.2549750.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ36.</span>
<span class="ltx_bibblock">
Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, etÂ al.

</span>
<span class="ltx_bibblock">Attention is All you Need.

</span>
<span class="ltx_bibblock">In: Advances in Neural Information Processing Systems. vol.Â 30;
2017.Available from:
<a target="_blank" href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">â€ƒ37.</span>
<span class="ltx_bibblock">
MontaÃ±a-Brown N, Ramalhinho Ja, Allam M, Davidson B, Hu Y, Clarkson MJ.

</span>
<span class="ltx_bibblock">Vessel segmentation for automatic registration of untracked
laparoscopic ultrasound to CT of the liver.

</span>
<span class="ltx_bibblock">International Journal of Computer Assisted Radiology and Surgery.
2021;16(7):1151â€“1160.

</span>
<span class="ltx_bibblock">doi:10.1007/S11548-021-02400-6.

</span>
</li>
</ul>
</section>
<section id="Sx7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Supplementary information</h2>

<div id="Sx7.p1" class="ltx_para">
<p id="Sx7.p1.1" class="ltx_p"><span id="Sx7.p1.1.1" class="ltx_text ltx_font_bold">S1 Appendix. Additional data details.</span> Additional details about the segmentations produced for the IXI dataset.
<br class="ltx_break"><span id="Sx7.p1.1.2" class="ltx_text ltx_font_bold">S2 Appendix. Resources impact of the augmentation layer.</span> Details on the GPU resources usage by the proposed augmentation layer
<br class="ltx_break"><span id="Sx7.p1.1.3" class="ltx_text ltx_font_bold">S3 Appendix. Training curves.</span> Figures of the training curves, as well as the adaptive loss weighting.
<br class="ltx_break"><span id="Sx7.p1.1.4" class="ltx_text ltx_font_bold">S4 Appendix. Statistical analysis.</span> Results of the statistical tests described in the manuscript, and additional comparison between manually and automatically generated segmentations.
<br class="ltx_break"><span id="Sx7.p1.1.5" class="ltx_text ltx_font_bold">S5 Appendix. Qualitative results.</span> Examples of predictions on the IXI and Oslo-CoMet test datasets.
<br class="ltx_break"><span id="Sx7.p1.1.6" class="ltx_text ltx_font_bold">S6 File. Evaluation metrics.</span> Collection of the evaluation metrics of the proposed models when tested on both the IXI and the Oslo-CoMet test datasets.
<br class="ltx_break"></p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.15716" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.15717" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.15717">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.15717" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.15718" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 09:45:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
