<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models</title>
<!--Generated on Wed Aug 21 17:59:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Recommender Systems,  Foundation Models,  Pretraining" lang="en" name="keywords"/>
<base href="/html/2409.14517v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S1" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S2" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.SS1" title="In 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.SS2" title="In 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.SS3" title="In 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Control Training Loop</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.SS4" title="In 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Sliding Window Training Loop</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.SS5" title="In 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Proposed Approach</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S4" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S5" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S6" title="In Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Author Bios</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Swanand Joshi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:swanandj@netflix.com">swanandj@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0003-6316-4440" title="ORCID identifier">0009-0003-6316-4440</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Netflix</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">,¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yesu Feng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yfeng@netflix.com">yfeng@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0008-4459-883X" title="ORCID identifier">0009-0008-4459-883X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Netflix</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">,¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ko-Jen Hsiao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:khsiao@netflix.com">khsiao@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0003-6784-7556" title="ORCID identifier">0009-0003-6784-7556</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Netflix</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">,¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhe Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:zhezhang@netflix.com">zhezhang@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-4056-1318" title="ORCID identifier">0000-0002-4056-1318</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Netflix</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id15.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before">¬†and¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sudarshan Lamkhede
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:slamkhede@netflix.com">slamkhede@netflix.com</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-8699-3776" title="ORCID identifier">0000-0001-8699-3776</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Netflix</span><span class="ltx_text ltx_affiliation_city" id="id18.2.id2">Los Gatos</span><span class="ltx_text ltx_affiliation_state" id="id19.3.id3">California</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024; 2024; 3 June 2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id21.id1">Long-lived recommender systems (RecSys) often encounter lengthy user-item interaction histories that span many years. To effectively learn long term user preferences, Large RecSys foundation models (FM) need to encode this information in pretraining. Usually, this is done by either generating a long enough sequence length to take all history sequences as input at the cost of large model input dimension or by dropping some parts of the user history to accommodate model size and latency requirements on the production serving side. In this paper, we introduce a sliding window training technique to incorporate long user history sequences during training time without increasing the model input dimension. We show the quantitative &amp; qualitative improvements this technique brings to the RecSys FM in learning user long term preferences. We additionally show that the average quality of items in the catalog learnt in pretraining also improves.</p>
</div>
<div class="ltx_keywords">Recommender Systems, Foundation Models, Pretraining
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14‚Äì18,
2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ‚Äô24), October 14‚Äì18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id6"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id7"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id8"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">conference: </span>18th ACM Conference on Recommender Systems; October 14‚Äì18, 2024; Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id9"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">booktitle: </span>18th ACM Conference on Recommender Systems (RecSys ‚Äô24), October 14‚Äì18, 2024, Bari, Italy</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id10"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">doi: </span>10.1145/3640457.3688051</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id11"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0505-2/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id12"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">ccs: </span>Information systems¬†Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Motivation</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Foundation models are increasingly becoming popular in recommendation systems <cite class="ltx_cite ltx_citemacro_citep">(Sun et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib9" title="">2019</a>)</cite>. The biggest leverage in using FMs for understanding what users are most interested in is user-item interaction sequences <cite class="ltx_cite ltx_citemacro_citep">(Xia et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib10" title="">2023</a>; Huang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib7" title="">2024</a>)</cite> . This pretrained FM is then used either to predict the next item to recommend in the recommendation system or to provide user and item representations for downstream use cases.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Oftentimes in industrial applications, foundation models that have inference time restrictions on serving memory footprint cannot exceed a certain input dimension and model size. This constraint raises a question on how to most effectively utilize a large-scale interaction corpus <cite class="ltx_cite ltx_citemacro_citep">(Chang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib2" title="">2023</a>)</cite>. The most straightforward way is to truncate historical interactions. This simplification, however, comes at the cost of not using valuable information about user journeys and their rich history of interactions during model training <cite class="ltx_cite ltx_citemacro_citep">(Hua et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib6" title="">2023</a>)</cite>. Only focusing on the recent items provides little or no knowledge of the long tail of items in the catalog <cite class="ltx_cite ltx_citemacro_citep">(Kitaev et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib8" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We hypothesize that the foundation model pretraining stage can benefit from receiving as much information as possible from interaction sequences. We then propose a method which involves curating input sequences for training samples using a hybrid method to include user item interactions from history along with most recent interactions. We provide an implementation approach using a sliding window sampling method to select portions of the interactions during each epoch. We also present quantitative and qualitative results that demonstrate the effectiveness of the method in learning long-term user preferences and in generating rich item representations.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="S1.F1.g1" src="extracted/5804287/control-training-loop.png" width="327"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span> Control training loop</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S1.F1.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S1.F1.2">Fixed window of length k is selected by truncating the large interaction sequence for all profiles in all epochs</p>
</div>
</div>
</figure>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S1.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.2.1" style="font-size:90%;">Perplexity</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.3.1" style="font-size:90%;">MRR</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.4.1" style="font-size:90%;">mAP</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.5.1" style="font-size:90%;">Recall</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.2.1.1"><span class="ltx_text" id="S1.T1.1.2.1.1.1" style="font-size:90%;">Control</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.2"><span class="ltx_text" id="S1.T1.1.2.1.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.3"><span class="ltx_text" id="S1.T1.1.2.1.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.4"><span class="ltx_text" id="S1.T1.1.2.1.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.5"><span class="ltx_text" id="S1.T1.1.2.1.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.1.3.2.1"><span class="ltx_text" id="S1.T1.1.3.2.1.1" style="font-size:90%;">All-Sliding</span></th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.2"><span class="ltx_text" id="S1.T1.1.3.2.2.1" style="font-size:90%;">-3.1%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.3"><span class="ltx_text" id="S1.T1.1.3.2.3.1" style="font-size:90%;">-1.2%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.4"><span class="ltx_text" id="S1.T1.1.3.2.4.1" style="font-size:90%;">+1.5%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.5"><span class="ltx_text" id="S1.T1.1.3.2.5.1" style="font-size:90%;">+7.01%</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.1.4.3.1"><span class="ltx_text" id="S1.T1.1.4.3.1.1" style="font-size:90%;">Mixed-500</span></th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.2"><span class="ltx_text" id="S1.T1.1.4.3.2.1" style="font-size:90%;">-1.66%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.3"><span class="ltx_text" id="S1.T1.1.4.3.3.1" style="font-size:90%;">+6.3%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S1.T1.1.4.3.4.1" style="font-size:90%;">+18.29%</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.5"><span class="ltx_text" id="S1.T1.1.4.3.5.1" style="font-size:90%;">+13.87%</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S1.T1.1.5.4.1"><span class="ltx_text" id="S1.T1.1.5.4.1.1" style="font-size:90%;">Mixed-1000</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.5.4.2.1" style="font-size:90%;">-2.43%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.5.4.3"><span class="ltx_text ltx_font_bold" id="S1.T1.1.5.4.3.1" style="font-size:90%;">+8.82%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.5.4.4"><span class="ltx_text" id="S1.T1.1.5.4.4.1" style="font-size:90%;">+14.04%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.5.4.5"><span class="ltx_text ltx_font_bold" id="S1.T1.1.5.4.5.1" style="font-size:90%;">+14.41%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>Results</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Foundation Models are now widely being adopted in RecSys <cite class="ltx_cite ltx_citemacro_citep">(Geng et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib5" title="">2023</a>)</cite>. Maximizing the interaction history of users is actively being explored to make learning more efficient <cite class="ltx_cite ltx_citemacro_citep">(Zhu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib12" title="">2024</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citep">(Zhai et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib11" title="">2024</a>)</cite> focuses on a setting with temporally repetitive user behaviors, enabling the use of artificial sparsification to reduce down long sequences. By contrast, we focus on data augmentation to improve the richness of representations under inference latency and model capacity constraints. Generally across large foundation models, there has been work on extending the context windows to a very large token size without affecting the model performance <cite class="ltx_cite ltx_citemacro_citep">(Ding et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib4" title="">2024</a>)</cite> but is largely orthogonal to our goal of exploiting long sequence corpora without increasing model context windows.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Approach</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Model</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We choose a recommendation model released in practice as our baseline that follows the same auto-regressive prediction objective. This baseline model has an input sequence limit of 100 items to satisfy online serving latency constraints. This choice is purely illustrative, as the technique itself is general to any context window size.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Dataset</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We use a large user interactions dataset of the order of 250M users and their interactions with the items in the content library. Example interaction sequences of users include video plays, video likes, add to watchlist, open video details page, etc. These interactions could span over long periods of time ranging from weeks to months.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Control Training Loop</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In the control training loop in baseline (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S1.F1" title="Figure 1 ‚Ä£ 1. Motivation ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_tag">1</span></a>), we process each training example in a batch using a truncating sampler that selects the latest k=100 items in the user‚Äôs interaction history. For users with less than K interactions, we take all of them. This method only focuses on the latest items the user interacted with.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="143" id="S3.F2.g1" src="extracted/5804287/treatment-training-loop.png" width="302"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span> Sliding window training loop</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S3.F2.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S3.F2.2">Sliding window of length k is selected by moving a sliding window over the large interaction sequence for all profiles in all epochs</p>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Sliding Window Training Loop</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this loop, we process each training example in a batch using a sliding window sampler. It creates a sliding window of the same size of K=100 items and slides the window over different contiguous parts of the user history sequence. During each epoch, the sliding window function selects a different portion of the user-item history as input to the FM. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S3.F2" title="Figure 2 ‚Ä£ 3.3. Control Training Loop ‚Ä£ 3. Approach ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the sliding window training loop. This enables two key benefits -</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">more user interaction sequences are encoded, and the model learns more about users‚Äô long-term interests, and</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">the average number of items observed during training increases as compared to the fixed window approach where each epoch trains with the same user-item sequence.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5. </span>Proposed Approach</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.4">The primary task of RecSys FM is to recommend new items that the user is most interested in. Naturally, newer interactions are more immediately relevant to current behaviors than older ones. Older interactions are useful for the model to learn user‚Äôs interaction patterns and long-term interest. To balance these two objectives - recency and long term interests, we choose a mixed approach in the training loop - during entire training on <math alttext="N" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">italic_N</annotation></semantics></math> epochs, we make <math alttext="X" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><mi id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><ci id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">ùëã</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.2.m2.1d">italic_X</annotation></semantics></math> epochs focus on the latest user item sequences using a fixed latest window and <math alttext="N-X" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1"><semantics id="S3.SS5.p1.3.m3.1a"><mrow id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml"><mi id="S3.SS5.p1.3.m3.1.1.2" xref="S3.SS5.p1.3.m3.1.1.2.cmml">N</mi><mo id="S3.SS5.p1.3.m3.1.1.1" xref="S3.SS5.p1.3.m3.1.1.1.cmml">‚àí</mo><mi id="S3.SS5.p1.3.m3.1.1.3" xref="S3.SS5.p1.3.m3.1.1.3.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><apply id="S3.SS5.p1.3.m3.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1"><minus id="S3.SS5.p1.3.m3.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1.1"></minus><ci id="S3.SS5.p1.3.m3.1.1.2.cmml" xref="S3.SS5.p1.3.m3.1.1.2">ùëÅ</ci><ci id="S3.SS5.p1.3.m3.1.1.3.cmml" xref="S3.SS5.p1.3.m3.1.1.3">ùëã</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">N-X</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.3.m3.1d">italic_N - italic_X</annotation></semantics></math> epochs focus on sliding window sampling that choose interactions from the entire history. After sweeping for an optimal <math alttext="X" class="ltx_Math" display="inline" id="S3.SS5.p1.4.m4.1"><semantics id="S3.SS5.p1.4.m4.1a"><mi id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><ci id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">ùëã</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.4.m4.1d">italic_X</annotation></semantics></math>, we find that this mixed method works well in accomplishing both objectives.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.4">We compare the baseline fixed window RecSys FM model with <math alttext="3" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn id="S4.p1.1.m1.1.1.cmml" type="integer" xref="S4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">3</annotation></semantics></math> treatment candidates -
<span class="ltx_text ltx_font_italic" id="S4.p1.4.1">All-Sliding</span> uses a sliding window training loop for all <math alttext="N" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_N</annotation></semantics></math> epochs without any focus on recent interactions. <span class="ltx_text ltx_font_italic" id="S4.p1.4.2">Mixed-500</span> uses a mixture of fixed recent &amp; sliding window epochs where sliding windows go as far back as <math alttext="500" class="ltx_Math" display="inline" id="S4.p1.3.m3.1"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn id="S4.p1.3.m3.1.1.cmml" type="integer" xref="S4.p1.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.p1.3.m3.1d">500</annotation></semantics></math> item interaction events, and <span class="ltx_text ltx_font_italic" id="S4.p1.4.3">Mixed-1000</span> where we slide far back as <math alttext="1000" class="ltx_Math" display="inline" id="S4.p1.4.m4.1"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn id="S4.p1.4.m4.1.1.cmml" type="integer" xref="S4.p1.4.m4.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S4.p1.4.m4.1d">1000</annotation></semantics></math> events.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We choose a combination of test sets containing recent interactions, random old item sequences &amp; unseen future held-out interactions after the training date. To assess the quality of item embedding learnt, we use internal item similarity datasets. Our evaluation metrics are perplexity, Mean Reciprocal Rank <cite class="ltx_cite ltx_citemacro_citep">(Craswell, <a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#bib.bib3" title="">2009</a>)</cite> (MRR) for next item prediction and mAP &amp; recall for item embedding quality.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Our results in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2409.14517v1#S1.T1" title="Table 1 ‚Ä£ 1. Motivation ‚Ä£ Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models"><span class="ltx_text ltx_ref_tag">1</span></a> show effectiveness of the sliding window training approach over baseline on all evaluation metrics.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">RecSys FMs that have tighter inference time limitations can maximize the utility of available user item interactions through a sliding window training approach for understanding long term user interests. Furthermore, this approach improves the overall quality of item representations learnt by the foundation model.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Future work includes optimizing hyper parameters of this method, improving training time &amp; memory efficiency while sliding through smarter parallelization and lastly, exploring of new sliding window functions that learn different aspects of user interests.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Author Bios</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Swanand Joshi</span> is an applied machine learning researcher at Netflix, focusing on personalization algorithms and member satisfaction.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Yesu Feng</span> is a research scientist at Netflix working on foundation models and interactive recommendations.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Ko-Jen Hsiao</span> is a staff research scientist/engineer at Netflix, with 7 years of experience working on Netflix‚Äôs core recommendation systems. His current focus is on developing foundational models for various algorithms that drive Netflix‚Äôs personalized experiences. He earned his PhD from the University of Michigan, where he specialized in combining disparate information for machine learning applications.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.1">Zhe Zhang</span>, Ph.D. in Computer Science, is a senior research scientist at Netflix. Previously, he was a research scientist at Meta AI and IBM, working on NLP, dialog systems and recommendations.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1"><span class="ltx_text ltx_font_bold" id="S6.p5.1.1">Sudarshan Lamkhede</span> is the Engineering Manager of the Machine Learning - Foundation Models, Search, and Recommendations at Netflix Research. Prior to Netflix, he led research engineering for Web Search algorithms at Yahoo! Research. He co-organizes the San Francisco Bay Area Machine Learning symposium (BayLearn).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et¬†al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jianxin Chang, Chenbin Zhang, Zhiyi Fu, Xiaoxue Zang, Lin Guan, Jing Lu, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, and Kun Gai. 2023.

</span>
<span class="ltx_bibblock">TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2302.02352¬†[cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Craswell (2009)</span>
<span class="ltx_bibblock">
Nick Craswell. 2009.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Mean Reciprocal Rank</em>.

</span>
<span class="ltx_bibblock">Springer US, Boston, MA, 1703‚Äì1703.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-0-387-39940-9_488" title="">https://doi.org/10.1007/978-0-387-39940-9_488</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et¬†al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yiran Ding, Li¬†Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu, Fan Yang, and Mao Yang. 2024.

</span>
<span class="ltx_bibblock">LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2402.13753¬†[cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et¬†al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2023.

</span>
<span class="ltx_bibblock">Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt ‚ÄòI&amp;‚Äô Predict Paradigm (P5).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2203.13366¬†[cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hua et¬†al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang. 2023.

</span>
<span class="ltx_bibblock">How to Index Item IDs for Recommendation Foundation Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region</em> <em class="ltx_emph ltx_font_italic" id="bib.bib6.4.2">(SIGIR-AP ‚Äô23)</em>. ACM.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3624918.3625339" title="">https://doi.org/10.1145/3624918.3625339</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et¬†al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Chengkai Huang, Tong Yu, Kaige Xie, Shuai Zhang, Lina Yao, and Julian McAuley. 2024.

</span>
<span class="ltx_bibblock">Foundation Models for Recommender Systems: A Survey and New Perspectives.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2402.11143¬†[cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitaev et¬†al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Nikita Kitaev, ≈Åukasz Kaiser, and Anselm Levskaya. 2020.

</span>
<span class="ltx_bibblock">Reformer: The Efficient Transformer.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2001.04451¬†[cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et¬†al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">CoRR</em> abs/1904.06690 (2019).

</span>
<span class="ltx_bibblock">arXiv:1904.06690

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1904.06690" title="">http://arxiv.org/abs/1904.06690</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et¬†al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xue Xia, Pong Eksombatchai, Nikil Pancha, Dhruvil¬†Deven Badani, Po-Wei Wang, Neng Gu, Saurabh¬†Vishwas Joshi, Nazanin Farahpour, Zhiyuan Zhang, and Andrew Zhai. 2023.

</span>
<span class="ltx_bibblock">TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2306.00248¬†[cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai et¬†al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li, Xuan Cao, Leon Gao, Zhaojie Gong, Fangda Gu, Michael He, Yinghai Lu, and Yu Shi. 2024.

</span>
<span class="ltx_bibblock">Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2402.17152¬†[cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et¬†al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Dawei Zhu, Nan Yang, Liang Wang, Yifan Song, Wenhao Wu, Furu Wei, and Sujian Li. 2024.

</span>
<span class="ltx_bibblock">PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2309.10400¬†[cs.CL]

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug 21 17:59:12 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
