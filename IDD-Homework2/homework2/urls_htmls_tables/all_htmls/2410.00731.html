<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion</title>
<!--Generated on Tue Oct  1 14:11:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Stable diffusion; Synthetic data generation; Generative AI
" lang="en" name="keywords"/>
<base href="/html/2410.00731v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S1" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S2" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work and Motivation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S3" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Diffusion â€“ Preliminaries</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S3.SS0.SSS1" title="In III Diffusion â€“ Preliminaries â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-</span>1 </span>Diffusion Model Architecture</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S4" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Feature-Aligned Diffusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS1" title="In V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Choice of Expert Model</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS2" title="In V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Diffusion Fine-tuning Hyper-parameters</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS3" title="In V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Evaluation Method</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS4" title="In V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS4.SSS1" title="In V-D Results â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span>1 </span>Quantitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.SS4.SSS2" title="In V-D Results â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span>2 </span>Qualitative Results</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S6" title="In Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Limitations and Future Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S6.SS1" title="In VI Limitations and Future Work â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-A</span> </span><span class="ltx_text ltx_font_italic">Potential Applications to Other Domains</span></span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lakshmi Nair
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.1.id1">Researcher</span>
<br class="ltx_break"/>Boston, Massachusetts, USA 
<br class="ltx_break"/>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Synthetic data generation is an important application of machine learning in the field of medical imaging. While existing approaches have successfully applied fine-tuned diffusion models for synthesizing medical images, we explore potential improvements to this pipeline through <span class="ltx_text ltx_font_italic" id="id1.1.1">feature-aligned diffusion</span>. Our approach aligns intermediate features of the diffusion model to the output features of an expert, and our preliminary findings show an improvement of 9% in generation accuracy and <math alttext="\approx 0.12" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml"></mi><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">0.12</mn></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><approx id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></approx><csymbol cd="latexml" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">absent</csymbol><cn id="id1.1.m1.1.1.3.cmml" type="float" xref="id1.1.m1.1.1.3">0.12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\approx 0.12</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">â‰ˆ 0.12</annotation></semantics></math> in SSIM diversity. Our approach is also synergistic with existing methods, and easily integrated into diffusion training pipelines for improvements. We make our code available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lnairGT/Feature-Aligned-Diffusion" title="">https://github.com/lnairGT/Feature-Aligned-Diffusion</a></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Stable diffusion; Synthetic data generation; Generative AI

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The field of healthcare has seen transformative changes following the recent advancements in generative AI, from protein folding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib1" title="">1</a>]</cite>, to foundational models for genomics data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib2" title="">2</a>]</cite>. Among the different applications of machine learning in healthcare, synthetic data generation is an important area of focus in order to address privacy concerns while decreasing costs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib3" title="">3</a>]</cite>. Additionally, synthetic data helps supplement limited training data availability that is common in healthcare applications, enabling the training of larger and better models. Particularly, in the medical imaging domain, data scarcity is a common problem caused due to factors such as expensive image acquisition, labeling procedures, privacy concerns and rare incidences of certain pathologies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work and Motivation</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Recent approaches to synthetic data generation leverages state-of-the-art performances of diffusion models. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib5" title="">5</a>]</cite>, the authors use a fine-tuned stable diffusion model with DreamBooth, for the synthesis of MRI scans. DreamBooth <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib6" title="">6</a>]</cite>, uses a few images of a new subject with a respective, unique text identifier to fine-tune the diffusion model. Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib7" title="">7</a>]</cite> use Stable diffusion and DreamBooth for generating synthetic images of skin lesions. In order to evaluate the synthetic generations, the authors use two state-of-the-art skin lesion classifiers: ViT and Mobilenet-v2. For synthetic generation of mammograms, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib4" title="">4</a>]</cite> introduce a two-part approach: one model for healthy mammogram generation and another for lesion in-painting. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib8" title="">8</a>]</cite>, the authors demonstrate synthetic generation of MRI and CT scans by applying fine-tuned diffusion models, evaluating the synthesized images with the help of expert radiologists. In contrast to diffusion models, prior work has also explored the use of GANs, particularly StyleGAN2, in the generation of synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib9" title="">9</a>]</cite>. While effective, the use of GAN-like architectures in medical image synthesis is challenging due to unstable training, low sample diversity and quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib10" title="">10</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="123" id="S2.F1.g1" src="extracted/5893087/imgs/overview.png" width="281"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">Overview of feature-aligned training of diffusion models. Example shows synthesis of Adipose tissue image.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">All the above approaches involve fine-tuning existing diffusion models directly, i.e., the relevant training data is pre-processed, and a diffusion model is fine-tuned on the desired data, either with or without DreamBooth. In this brief paper, <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S2.p2.1.1">we explore whether aligning the diffusion model with features extracted from an <span class="ltx_text ltx_font_italic" id="S2.p2.1.1.1">expert model</span>, can help improve the quality of generations</span>. Hence, one assumption of this work is the existence of an â€œexpertâ€ model. However, â€œexpertâ€ models are commonly used to evaluate synthetic generations and therefore <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">already available</span> in such scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib7" title="">7</a>]</cite>. Hence, <span class="ltx_text ltx_framed ltx_framed_underline" id="S2.p2.1.3">our approach is complementary to existing methods to further augment their generation accuracy, and is easily incorporated into existing diffusion training pipelines with only an additional loss term and projection layer</span>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Our key finding is that aligning the intermediate features of the diffusion model with output features of a classification expert during training, can lead to improved generations during inference. Interestingly, we observe that these improvements occur when the expert features are computed on the <span class="ltx_text ltx_font_italic" id="S2.p3.1.1">noise added inputs</span> that are fed to the diffusion model during training, as opposed to the noise free original training samples. In other words, aligning with the expert features of the <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">noisy image</span> as opposed to the noise-free image, leads to improvements during inference.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Diffusion â€“ Preliminaries</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Diffusion models are latent-variable generative models that generate data by iteratively de-noising a sample from Gaussian noise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib11" title="">11</a>]</cite>. The diffusion model formulation consists of a fixed forward process, that takes a data sample from an initial distribution, progressively corrupting it with Gaussian noise. It also consists of a reverse process that learns to undo this corruption, effectively recovering samples from the original data distribution.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.2">The forward process transforms a data point into a noisy version over discrete timesteps. At each timestep, noise is incrementally added according to a predefined variance schedule <math alttext="\alpha_{t}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">Î±</mi><mi id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">ğ›¼</ci><ci id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\alpha_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. In terms of samples <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, this process can be formulated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{t}=\alpha_{t}x_{0}+(1-\alpha_{t})\epsilon,\text{ }\epsilon\sim\mathcal{N}(0%
,1)" class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.2" xref="S3.E1.m1.4.4.3.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><msub id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.2" xref="S3.E1.m1.3.3.1.1.3.2.cmml">x</mi><mi id="S3.E1.m1.3.3.1.1.3.3" xref="S3.E1.m1.3.3.1.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.3.cmml"><msub id="S3.E1.m1.3.3.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.3.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.1.3.2.2.cmml">Î±</mi><mi id="S3.E1.m1.3.3.1.1.1.3.2.3" xref="S3.E1.m1.3.3.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.3.1" xref="S3.E1.m1.3.3.1.1.1.3.1.cmml">â¢</mo><msub id="S3.E1.m1.3.3.1.1.1.3.3" xref="S3.E1.m1.3.3.1.1.1.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3.3.2" xref="S3.E1.m1.3.3.1.1.1.3.3.2.cmml">x</mi><mn id="S3.E1.m1.3.3.1.1.1.3.3.3" xref="S3.E1.m1.3.3.1.1.1.3.3.3.cmml">0</mn></msub></mrow><mo id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml">+</mo><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">Î±</mi><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml">â¢</mo><mi id="S3.E1.m1.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.3.cmml">Ïµ</mi></mrow></mrow></mrow><mo id="S3.E1.m1.4.4.2.3" xref="S3.E1.m1.4.4.3a.cmml">,</mo><mrow id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.2.cmml"><mrow id="S3.E1.m1.4.4.2.2.2" xref="S3.E1.m1.4.4.2.2.2.cmml"><mtext id="S3.E1.m1.4.4.2.2.2.2" xref="S3.E1.m1.4.4.2.2.2.2a.cmml">Â </mtext><mo id="S3.E1.m1.4.4.2.2.2.1" xref="S3.E1.m1.4.4.2.2.2.1.cmml">â¢</mo><mi id="S3.E1.m1.4.4.2.2.2.3" xref="S3.E1.m1.4.4.2.2.2.3.cmml">Ïµ</mi></mrow><mo id="S3.E1.m1.4.4.2.2.1" xref="S3.E1.m1.4.4.2.2.1.cmml">âˆ¼</mo><mrow id="S3.E1.m1.4.4.2.2.3" xref="S3.E1.m1.4.4.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.4.4.2.2.3.2" xref="S3.E1.m1.4.4.2.2.3.2.cmml">ğ’©</mi><mo id="S3.E1.m1.4.4.2.2.3.1" xref="S3.E1.m1.4.4.2.2.3.1.cmml">â¢</mo><mrow id="S3.E1.m1.4.4.2.2.3.3.2" xref="S3.E1.m1.4.4.2.2.3.3.1.cmml"><mo id="S3.E1.m1.4.4.2.2.3.3.2.1" stretchy="false" xref="S3.E1.m1.4.4.2.2.3.3.1.cmml">(</mo><mn id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">0</mn><mo id="S3.E1.m1.4.4.2.2.3.3.2.2" xref="S3.E1.m1.4.4.2.2.3.3.1.cmml">,</mo><mn id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">1</mn><mo id="S3.E1.m1.4.4.2.2.3.3.2.3" stretchy="false" xref="S3.E1.m1.4.4.2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.3.cmml" xref="S3.E1.m1.4.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3a.cmml" xref="S3.E1.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1"><eq id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"></eq><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2">ğ‘¥</ci><ci id="S3.E1.m1.3.3.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><plus id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"></plus><apply id="S3.E1.m1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3"><times id="S3.E1.m1.3.3.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.3.1"></times><apply id="S3.E1.m1.3.3.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.3.2.2">ğ›¼</ci><ci id="S3.E1.m1.3.3.1.1.1.3.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.3.3.2">ğ‘¥</ci><cn id="S3.E1.m1.3.3.1.1.1.3.3.3.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.1.3.3.3">0</cn></apply></apply><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2"></times><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1"><minus id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1"></minus><cn id="S3.E1.m1.3.3.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.2">ğ›¼</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply><ci id="S3.E1.m1.3.3.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3">italic-Ïµ</ci></apply></apply></apply><apply id="S3.E1.m1.4.4.2.2.cmml" xref="S3.E1.m1.4.4.2.2"><csymbol cd="latexml" id="S3.E1.m1.4.4.2.2.1.cmml" xref="S3.E1.m1.4.4.2.2.1">similar-to</csymbol><apply id="S3.E1.m1.4.4.2.2.2.cmml" xref="S3.E1.m1.4.4.2.2.2"><times id="S3.E1.m1.4.4.2.2.2.1.cmml" xref="S3.E1.m1.4.4.2.2.2.1"></times><ci id="S3.E1.m1.4.4.2.2.2.2a.cmml" xref="S3.E1.m1.4.4.2.2.2.2"><mtext id="S3.E1.m1.4.4.2.2.2.2.cmml" xref="S3.E1.m1.4.4.2.2.2.2">Â </mtext></ci><ci id="S3.E1.m1.4.4.2.2.2.3.cmml" xref="S3.E1.m1.4.4.2.2.2.3">italic-Ïµ</ci></apply><apply id="S3.E1.m1.4.4.2.2.3.cmml" xref="S3.E1.m1.4.4.2.2.3"><times id="S3.E1.m1.4.4.2.2.3.1.cmml" xref="S3.E1.m1.4.4.2.2.3.1"></times><ci id="S3.E1.m1.4.4.2.2.3.2.cmml" xref="S3.E1.m1.4.4.2.2.3.2">ğ’©</ci><interval closure="open" id="S3.E1.m1.4.4.2.2.3.3.1.cmml" xref="S3.E1.m1.4.4.2.2.3.3.2"><cn id="S3.E1.m1.1.1.cmml" type="integer" xref="S3.E1.m1.1.1">0</cn><cn id="S3.E1.m1.2.2.cmml" type="integer" xref="S3.E1.m1.2.2">1</cn></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">x_{t}=\alpha_{t}x_{0}+(1-\alpha_{t})\epsilon,\text{ }\epsilon\sim\mathcal{N}(0%
,1)</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + ( 1 - italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) italic_Ïµ , italic_Ïµ âˆ¼ caligraphic_N ( 0 , 1 )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.p2.3">The reverse process involves learning a model that predicts the noise added at each step, directly recovering an estimate of <math alttext="x_{0}" class="ltx_Math" display="inline" id="S3.p2.3.m1.1"><semantics id="S3.p2.3.m1.1a"><msub id="S3.p2.3.m1.1.1" xref="S3.p2.3.m1.1.1.cmml"><mi id="S3.p2.3.m1.1.1.2" xref="S3.p2.3.m1.1.1.2.cmml">x</mi><mn id="S3.p2.3.m1.1.1.3" xref="S3.p2.3.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p2.3.m1.1b"><apply id="S3.p2.3.m1.1.1.cmml" xref="S3.p2.3.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m1.1.1.1.cmml" xref="S3.p2.3.m1.1.1">subscript</csymbol><ci id="S3.p2.3.m1.1.1.2.cmml" xref="S3.p2.3.m1.1.1.2">ğ‘¥</ci><cn id="S3.p2.3.m1.1.1.3.cmml" type="integer" xref="S3.p2.3.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m1.1c">x_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m1.1d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>. This is typically done with a loss function as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{noise}=\|\epsilon-\epsilon_{\theta}(x_{t},t)\|^{2}_{2}" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><msub id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml"><mi id="S3.E2.m1.2.2.3.2" xref="S3.E2.m1.2.2.3.2.cmml">L</mi><mrow id="S3.E2.m1.2.2.3.3" xref="S3.E2.m1.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.3.3.2" xref="S3.E2.m1.2.2.3.3.2.cmml">n</mi><mo id="S3.E2.m1.2.2.3.3.1" xref="S3.E2.m1.2.2.3.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.3.3.3" xref="S3.E2.m1.2.2.3.3.3.cmml">o</mi><mo id="S3.E2.m1.2.2.3.3.1a" xref="S3.E2.m1.2.2.3.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.3.3.4" xref="S3.E2.m1.2.2.3.3.4.cmml">i</mi><mo id="S3.E2.m1.2.2.3.3.1b" xref="S3.E2.m1.2.2.3.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.3.3.5" xref="S3.E2.m1.2.2.3.3.5.cmml">s</mi><mo id="S3.E2.m1.2.2.3.3.1c" xref="S3.E2.m1.2.2.3.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.3.3.6" xref="S3.E2.m1.2.2.3.3.6.cmml">e</mi></mrow></msub><mo id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml">=</mo><msubsup id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.cmml">Ïµ</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.2.cmml">Ïµ</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">t</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.4" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E2.m1.2.2.1.3" xref="S3.E2.m1.2.2.1.3.cmml">2</mn><mn id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"></eq><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.3.2">ğ¿</ci><apply id="S3.E2.m1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.3.3"><times id="S3.E2.m1.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.3.3.1"></times><ci id="S3.E2.m1.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.3.3.2">ğ‘›</ci><ci id="S3.E2.m1.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.3.3.3">ğ‘œ</ci><ci id="S3.E2.m1.2.2.3.3.4.cmml" xref="S3.E2.m1.2.2.3.3.4">ğ‘–</ci><ci id="S3.E2.m1.2.2.3.3.5.cmml" xref="S3.E2.m1.2.2.3.3.5">ğ‘ </ci><ci id="S3.E2.m1.2.2.3.3.6.cmml" xref="S3.E2.m1.2.2.3.3.6">ğ‘’</ci></apply></apply><apply id="S3.E2.m1.2.2.1.cmml" xref="S3.E2.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.2.cmml" xref="S3.E2.m1.2.2.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2"></minus><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3">italic-Ïµ</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.2">italic-Ïµ</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ‘¡</ci></interval></apply></apply></apply><cn id="S3.E2.m1.2.2.1.1.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.3">2</cn></apply><cn id="S3.E2.m1.2.2.1.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">L_{noise}=\|\epsilon-\epsilon_{\theta}(x_{t},t)\|^{2}_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_L start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_e end_POSTSUBSCRIPT = âˆ¥ italic_Ïµ - italic_Ïµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) âˆ¥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.p2.4">The generations can be conditioned on class labels, where the model additionally takes the desired class label in the form of their corresponding text embeddings (obtained with a text encoder). It is then incorporated into the diffusion model via cross-attention layers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib12" title="">12</a>]</cite>, allowing the generations to be controlled by the specific label.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS0.SSS1.5.1.1">III-</span>1 </span>Diffusion Model Architecture</h4>
<div class="ltx_para" id="S3.SS0.SSS1.p1">
<p class="ltx_p" id="S3.SS0.SSS1.p1.1">U-Net architectures are a common choice for diffusion models that demonstrate state-of-the-art performances <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib12" title="">12</a>]</cite>. A U-Net consists of a downsampling block (contracting path) and an upsampling block (expanding path), with residual connections between the two paths. The downsampling block consists of a series of layers that gradually reduce spatial information while capturing <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS1.p1.1.1">feature</span> information. In contrast, the upsampling block gradually recovers the spatial information from the feature information of the downsampling block.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Feature-Aligned Diffusion</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We propose feature-aligned diffusion to improve model generations, by aligning intermediate features of the diffusion model with the output features of an expert during fine-tuning. In this context, the expert model refers to a classification model, often used to evaluate synthetic generations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib9" title="">9</a>]</cite>. Our approach is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S2.F1" title="Figure 1 â€£ II Related Work and Motivation â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.3">Typical diffusion model training involves adding noise according to a pre-specified schedule to each training sample passed into the diffusion model. Here, the loss function (from Section <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S3" title="III Diffusion â€“ Preliminaries â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">III</span></a>) compares the model predicted noise to the true noise added to the sample. Feature alignment incorporates one additional step into the typical flow: we additionally pass the <span class="ltx_text ltx_font_italic" id="S4.p2.3.1">noisy</span> training sample to the expert model, to compute the corresponding output features. Intermediate features of the diffusion model are then extracted and aligned with the expert features. In our case, the intermediate features are obtained from the output of the downsampling block of the diffusion U-Net (shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S2.F1" title="Figure 1 â€£ II Related Work and Motivation â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">1</span></a>). In order to align the intermediate diffusion model features to the output features of the expert, we introduce the following loss function that maximizes the cosine similarity between the two. Computing cosine similarity in this manner requires the expert feature dimensions <math alttext="E_{e}" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><msub id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">E</mi><mi id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">ğ¸</ci><ci id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">E_{e}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> to match the intermediate diffusion feature dimensions <math alttext="E_{d}" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">E</mi><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">ğ¸</ci><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">E_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>. Hence, we also add an additional trainable projection <math alttext="W_{p}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">W</mi><mi id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">ğ‘Š</ci><ci id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">W_{p}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x^{\prime}_{t}=f_{e}(x_{t})" class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><msubsup id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.3.2.2" xref="S4.E3.m1.1.1.3.2.2.cmml">x</mi><mi id="S4.E3.m1.1.1.3.3" xref="S4.E3.m1.1.1.3.3.cmml">t</mi><mo id="S4.E3.m1.1.1.3.2.3" xref="S4.E3.m1.1.1.3.2.3.cmml">â€²</mo></msubsup><mo id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">=</mo><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.cmml"><msub id="S4.E3.m1.1.1.1.3" xref="S4.E3.m1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.3.2.cmml">f</mi><mi id="S4.E3.m1.1.1.1.3.3" xref="S4.E3.m1.1.1.1.3.3.cmml">e</mi></msub><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.2.cmml">â¢</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.E3.m1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2"></eq><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3">subscript</csymbol><apply id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.3">superscript</csymbol><ci id="S4.E3.m1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2">ğ‘¥</ci><ci id="S4.E3.m1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.3.2.3">â€²</ci></apply><ci id="S4.E3.m1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><times id="S4.E3.m1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.2"></times><apply id="S4.E3.m1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.3.2">ğ‘“</ci><ci id="S4.E3.m1.1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.1.3.3">ğ‘’</ci></apply><apply id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S4.E3.m1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">x^{\prime}_{t}=f_{e}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">italic_x start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{align}=-D_{c}(W_{p}\cdot x^{\prime}_{t},\text{ }f_{d}(x_{t}))" class="ltx_Math" display="block" id="S4.E4.m1.2"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><msub id="S4.E4.m1.2.2.4" xref="S4.E4.m1.2.2.4.cmml"><mi id="S4.E4.m1.2.2.4.2" xref="S4.E4.m1.2.2.4.2.cmml">L</mi><mrow id="S4.E4.m1.2.2.4.3" xref="S4.E4.m1.2.2.4.3.cmml"><mi id="S4.E4.m1.2.2.4.3.2" xref="S4.E4.m1.2.2.4.3.2.cmml">a</mi><mo id="S4.E4.m1.2.2.4.3.1" xref="S4.E4.m1.2.2.4.3.1.cmml">â¢</mo><mi id="S4.E4.m1.2.2.4.3.3" xref="S4.E4.m1.2.2.4.3.3.cmml">l</mi><mo id="S4.E4.m1.2.2.4.3.1a" xref="S4.E4.m1.2.2.4.3.1.cmml">â¢</mo><mi id="S4.E4.m1.2.2.4.3.4" xref="S4.E4.m1.2.2.4.3.4.cmml">i</mi><mo id="S4.E4.m1.2.2.4.3.1b" xref="S4.E4.m1.2.2.4.3.1.cmml">â¢</mo><mi id="S4.E4.m1.2.2.4.3.5" xref="S4.E4.m1.2.2.4.3.5.cmml">g</mi><mo id="S4.E4.m1.2.2.4.3.1c" xref="S4.E4.m1.2.2.4.3.1.cmml">â¢</mo><mi id="S4.E4.m1.2.2.4.3.6" xref="S4.E4.m1.2.2.4.3.6.cmml">n</mi></mrow></msub><mo id="S4.E4.m1.2.2.3" xref="S4.E4.m1.2.2.3.cmml">=</mo><mrow id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml"><mo id="S4.E4.m1.2.2.2a" xref="S4.E4.m1.2.2.2.cmml">âˆ’</mo><mrow id="S4.E4.m1.2.2.2.2" xref="S4.E4.m1.2.2.2.2.cmml"><msub id="S4.E4.m1.2.2.2.2.4" xref="S4.E4.m1.2.2.2.2.4.cmml"><mi id="S4.E4.m1.2.2.2.2.4.2" xref="S4.E4.m1.2.2.2.2.4.2.cmml">D</mi><mi id="S4.E4.m1.2.2.2.2.4.3" xref="S4.E4.m1.2.2.2.2.4.3.cmml">c</mi></msub><mo id="S4.E4.m1.2.2.2.2.3" xref="S4.E4.m1.2.2.2.2.3.cmml">â¢</mo><mrow id="S4.E4.m1.2.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.2.3.cmml"><mo id="S4.E4.m1.2.2.2.2.2.2.3" stretchy="false" xref="S4.E4.m1.2.2.2.2.2.3.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.2.2" xref="S4.E4.m1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.1.1.1.1.2.3.cmml">p</mi></msub><mo id="S4.E4.m1.1.1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">â‹…</mo><msubsup id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.3.2.2" xref="S4.E4.m1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.1.1.1.3.3.cmml">t</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1.3.2.3" xref="S4.E4.m1.1.1.1.1.1.1.1.3.2.3.cmml">â€²</mo></msubsup></mrow><mo id="S4.E4.m1.2.2.2.2.2.2.4" xref="S4.E4.m1.2.2.2.2.2.3.cmml">,</mo><mrow id="S4.E4.m1.2.2.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.2.2.2.cmml"><mtext id="S4.E4.m1.2.2.2.2.2.2.2.3" xref="S4.E4.m1.2.2.2.2.2.2.2.3a.cmml">Â </mtext><mo id="S4.E4.m1.2.2.2.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.2.2.2.2.cmml">â¢</mo><msub id="S4.E4.m1.2.2.2.2.2.2.2.4" xref="S4.E4.m1.2.2.2.2.2.2.2.4.cmml"><mi id="S4.E4.m1.2.2.2.2.2.2.2.4.2" xref="S4.E4.m1.2.2.2.2.2.2.2.4.2.cmml">f</mi><mi id="S4.E4.m1.2.2.2.2.2.2.2.4.3" xref="S4.E4.m1.2.2.2.2.2.2.2.4.3.cmml">d</mi></msub><mo id="S4.E4.m1.2.2.2.2.2.2.2.2a" xref="S4.E4.m1.2.2.2.2.2.2.2.2.cmml">â¢</mo><mrow id="S4.E4.m1.2.2.2.2.2.2.2.1.1" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.cmml"><mo id="S4.E4.m1.2.2.2.2.2.2.2.1.1.2" stretchy="false" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.cmml">(</mo><msub id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.cmml"><mi id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.2" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.2.cmml">x</mi><mi id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.3" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S4.E4.m1.2.2.2.2.2.2.2.1.1.3" stretchy="false" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.2.2.2.2.2.2.5" stretchy="false" xref="S4.E4.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><eq id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2.3"></eq><apply id="S4.E4.m1.2.2.4.cmml" xref="S4.E4.m1.2.2.4"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.4.1.cmml" xref="S4.E4.m1.2.2.4">subscript</csymbol><ci id="S4.E4.m1.2.2.4.2.cmml" xref="S4.E4.m1.2.2.4.2">ğ¿</ci><apply id="S4.E4.m1.2.2.4.3.cmml" xref="S4.E4.m1.2.2.4.3"><times id="S4.E4.m1.2.2.4.3.1.cmml" xref="S4.E4.m1.2.2.4.3.1"></times><ci id="S4.E4.m1.2.2.4.3.2.cmml" xref="S4.E4.m1.2.2.4.3.2">ğ‘</ci><ci id="S4.E4.m1.2.2.4.3.3.cmml" xref="S4.E4.m1.2.2.4.3.3">ğ‘™</ci><ci id="S4.E4.m1.2.2.4.3.4.cmml" xref="S4.E4.m1.2.2.4.3.4">ğ‘–</ci><ci id="S4.E4.m1.2.2.4.3.5.cmml" xref="S4.E4.m1.2.2.4.3.5">ğ‘”</ci><ci id="S4.E4.m1.2.2.4.3.6.cmml" xref="S4.E4.m1.2.2.4.3.6">ğ‘›</ci></apply></apply><apply id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"><minus id="S4.E4.m1.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2"></minus><apply id="S4.E4.m1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2"><times id="S4.E4.m1.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.2.3"></times><apply id="S4.E4.m1.2.2.2.2.4.cmml" xref="S4.E4.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.2.4.1.cmml" xref="S4.E4.m1.2.2.2.2.4">subscript</csymbol><ci id="S4.E4.m1.2.2.2.2.4.2.cmml" xref="S4.E4.m1.2.2.2.2.4.2">ğ·</ci><ci id="S4.E4.m1.2.2.2.2.4.3.cmml" xref="S4.E4.m1.2.2.2.2.4.3">ğ‘</ci></apply><interval closure="open" id="S4.E4.m1.2.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.2.2.2"><apply id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1">â‹…</ci><apply id="S4.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2.2">ğ‘Š</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S4.E4.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3.2.3">â€²</ci></apply><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply><apply id="S4.E4.m1.2.2.2.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2"><times id="S4.E4.m1.2.2.2.2.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.2"></times><ci id="S4.E4.m1.2.2.2.2.2.2.2.3a.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.3"><mtext id="S4.E4.m1.2.2.2.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.3">Â </mtext></ci><apply id="S4.E4.m1.2.2.2.2.2.2.2.4.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.2.2.2.2.4.1.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.4">subscript</csymbol><ci id="S4.E4.m1.2.2.2.2.2.2.2.4.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.4.2">ğ‘“</ci><ci id="S4.E4.m1.2.2.2.2.2.2.2.4.3.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.4.3">ğ‘‘</ci></apply><apply id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1">subscript</csymbol><ci id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.3.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2.1.1.1.3">ğ‘¡</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">L_{align}=-D_{c}(W_{p}\cdot x^{\prime}_{t},\text{ }f_{d}(x_{t}))</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.2d">italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT = - italic_D start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT â‹… italic_x start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.11">Here, <math alttext="D_{c}" class="ltx_Math" display="inline" id="S4.p2.4.m1.1"><semantics id="S4.p2.4.m1.1a"><msub id="S4.p2.4.m1.1.1" xref="S4.p2.4.m1.1.1.cmml"><mi id="S4.p2.4.m1.1.1.2" xref="S4.p2.4.m1.1.1.2.cmml">D</mi><mi id="S4.p2.4.m1.1.1.3" xref="S4.p2.4.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.4.m1.1b"><apply id="S4.p2.4.m1.1.1.cmml" xref="S4.p2.4.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.4.m1.1.1.1.cmml" xref="S4.p2.4.m1.1.1">subscript</csymbol><ci id="S4.p2.4.m1.1.1.2.cmml" xref="S4.p2.4.m1.1.1.2">ğ·</ci><ci id="S4.p2.4.m1.1.1.3.cmml" xref="S4.p2.4.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m1.1c">D_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m1.1d">italic_D start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> denotes cosine similarity, <math alttext="x_{t}" class="ltx_Math" display="inline" id="S4.p2.5.m2.1"><semantics id="S4.p2.5.m2.1a"><msub id="S4.p2.5.m2.1.1" xref="S4.p2.5.m2.1.1.cmml"><mi id="S4.p2.5.m2.1.1.2" xref="S4.p2.5.m2.1.1.2.cmml">x</mi><mi id="S4.p2.5.m2.1.1.3" xref="S4.p2.5.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.5.m2.1b"><apply id="S4.p2.5.m2.1.1.cmml" xref="S4.p2.5.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m2.1.1.1.cmml" xref="S4.p2.5.m2.1.1">subscript</csymbol><ci id="S4.p2.5.m2.1.1.2.cmml" xref="S4.p2.5.m2.1.1.2">ğ‘¥</ci><ci id="S4.p2.5.m2.1.1.3.cmml" xref="S4.p2.5.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m2.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.5.m2.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the input image <span class="ltx_text ltx_font_italic" id="S4.p2.11.1">with added noise</span> (Eqn 1); <math alttext="W_{p}" class="ltx_Math" display="inline" id="S4.p2.6.m3.1"><semantics id="S4.p2.6.m3.1a"><msub id="S4.p2.6.m3.1.1" xref="S4.p2.6.m3.1.1.cmml"><mi id="S4.p2.6.m3.1.1.2" xref="S4.p2.6.m3.1.1.2.cmml">W</mi><mi id="S4.p2.6.m3.1.1.3" xref="S4.p2.6.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.6.m3.1b"><apply id="S4.p2.6.m3.1.1.cmml" xref="S4.p2.6.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.6.m3.1.1.1.cmml" xref="S4.p2.6.m3.1.1">subscript</csymbol><ci id="S4.p2.6.m3.1.1.2.cmml" xref="S4.p2.6.m3.1.1.2">ğ‘Š</ci><ci id="S4.p2.6.m3.1.1.3.cmml" xref="S4.p2.6.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m3.1c">W_{p}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.6.m3.1d">italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> denotes the projection layer <math alttext="\mathbb{R}^{E_{e}\times E_{d}}" class="ltx_Math" display="inline" id="S4.p2.7.m4.1"><semantics id="S4.p2.7.m4.1a"><msup id="S4.p2.7.m4.1.1" xref="S4.p2.7.m4.1.1.cmml"><mi id="S4.p2.7.m4.1.1.2" xref="S4.p2.7.m4.1.1.2.cmml">â„</mi><mrow id="S4.p2.7.m4.1.1.3" xref="S4.p2.7.m4.1.1.3.cmml"><msub id="S4.p2.7.m4.1.1.3.2" xref="S4.p2.7.m4.1.1.3.2.cmml"><mi id="S4.p2.7.m4.1.1.3.2.2" xref="S4.p2.7.m4.1.1.3.2.2.cmml">E</mi><mi id="S4.p2.7.m4.1.1.3.2.3" xref="S4.p2.7.m4.1.1.3.2.3.cmml">e</mi></msub><mo id="S4.p2.7.m4.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.p2.7.m4.1.1.3.1.cmml">Ã—</mo><msub id="S4.p2.7.m4.1.1.3.3" xref="S4.p2.7.m4.1.1.3.3.cmml"><mi id="S4.p2.7.m4.1.1.3.3.2" xref="S4.p2.7.m4.1.1.3.3.2.cmml">E</mi><mi id="S4.p2.7.m4.1.1.3.3.3" xref="S4.p2.7.m4.1.1.3.3.3.cmml">d</mi></msub></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.p2.7.m4.1b"><apply id="S4.p2.7.m4.1.1.cmml" xref="S4.p2.7.m4.1.1"><csymbol cd="ambiguous" id="S4.p2.7.m4.1.1.1.cmml" xref="S4.p2.7.m4.1.1">superscript</csymbol><ci id="S4.p2.7.m4.1.1.2.cmml" xref="S4.p2.7.m4.1.1.2">â„</ci><apply id="S4.p2.7.m4.1.1.3.cmml" xref="S4.p2.7.m4.1.1.3"><times id="S4.p2.7.m4.1.1.3.1.cmml" xref="S4.p2.7.m4.1.1.3.1"></times><apply id="S4.p2.7.m4.1.1.3.2.cmml" xref="S4.p2.7.m4.1.1.3.2"><csymbol cd="ambiguous" id="S4.p2.7.m4.1.1.3.2.1.cmml" xref="S4.p2.7.m4.1.1.3.2">subscript</csymbol><ci id="S4.p2.7.m4.1.1.3.2.2.cmml" xref="S4.p2.7.m4.1.1.3.2.2">ğ¸</ci><ci id="S4.p2.7.m4.1.1.3.2.3.cmml" xref="S4.p2.7.m4.1.1.3.2.3">ğ‘’</ci></apply><apply id="S4.p2.7.m4.1.1.3.3.cmml" xref="S4.p2.7.m4.1.1.3.3"><csymbol cd="ambiguous" id="S4.p2.7.m4.1.1.3.3.1.cmml" xref="S4.p2.7.m4.1.1.3.3">subscript</csymbol><ci id="S4.p2.7.m4.1.1.3.3.2.cmml" xref="S4.p2.7.m4.1.1.3.3.2">ğ¸</ci><ci id="S4.p2.7.m4.1.1.3.3.3.cmml" xref="S4.p2.7.m4.1.1.3.3.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m4.1c">\mathbb{R}^{E_{e}\times E_{d}}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.7.m4.1d">blackboard_R start_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT Ã— italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>; <math alttext="f_{e}(\cdot)" class="ltx_Math" display="inline" id="S4.p2.8.m5.1"><semantics id="S4.p2.8.m5.1a"><mrow id="S4.p2.8.m5.1.2" xref="S4.p2.8.m5.1.2.cmml"><msub id="S4.p2.8.m5.1.2.2" xref="S4.p2.8.m5.1.2.2.cmml"><mi id="S4.p2.8.m5.1.2.2.2" xref="S4.p2.8.m5.1.2.2.2.cmml">f</mi><mi id="S4.p2.8.m5.1.2.2.3" xref="S4.p2.8.m5.1.2.2.3.cmml">e</mi></msub><mo id="S4.p2.8.m5.1.2.1" xref="S4.p2.8.m5.1.2.1.cmml">â¢</mo><mrow id="S4.p2.8.m5.1.2.3.2" xref="S4.p2.8.m5.1.2.cmml"><mo id="S4.p2.8.m5.1.2.3.2.1" stretchy="false" xref="S4.p2.8.m5.1.2.cmml">(</mo><mo id="S4.p2.8.m5.1.1" lspace="0em" rspace="0em" xref="S4.p2.8.m5.1.1.cmml">â‹…</mo><mo id="S4.p2.8.m5.1.2.3.2.2" stretchy="false" xref="S4.p2.8.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.8.m5.1b"><apply id="S4.p2.8.m5.1.2.cmml" xref="S4.p2.8.m5.1.2"><times id="S4.p2.8.m5.1.2.1.cmml" xref="S4.p2.8.m5.1.2.1"></times><apply id="S4.p2.8.m5.1.2.2.cmml" xref="S4.p2.8.m5.1.2.2"><csymbol cd="ambiguous" id="S4.p2.8.m5.1.2.2.1.cmml" xref="S4.p2.8.m5.1.2.2">subscript</csymbol><ci id="S4.p2.8.m5.1.2.2.2.cmml" xref="S4.p2.8.m5.1.2.2.2">ğ‘“</ci><ci id="S4.p2.8.m5.1.2.2.3.cmml" xref="S4.p2.8.m5.1.2.2.3">ğ‘’</ci></apply><ci id="S4.p2.8.m5.1.1.cmml" xref="S4.p2.8.m5.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m5.1c">f_{e}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.p2.8.m5.1d">italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( â‹… )</annotation></semantics></math> is the output of the expert model, and <math alttext="f_{d}(\cdot)" class="ltx_Math" display="inline" id="S4.p2.9.m6.1"><semantics id="S4.p2.9.m6.1a"><mrow id="S4.p2.9.m6.1.2" xref="S4.p2.9.m6.1.2.cmml"><msub id="S4.p2.9.m6.1.2.2" xref="S4.p2.9.m6.1.2.2.cmml"><mi id="S4.p2.9.m6.1.2.2.2" xref="S4.p2.9.m6.1.2.2.2.cmml">f</mi><mi id="S4.p2.9.m6.1.2.2.3" xref="S4.p2.9.m6.1.2.2.3.cmml">d</mi></msub><mo id="S4.p2.9.m6.1.2.1" xref="S4.p2.9.m6.1.2.1.cmml">â¢</mo><mrow id="S4.p2.9.m6.1.2.3.2" xref="S4.p2.9.m6.1.2.cmml"><mo id="S4.p2.9.m6.1.2.3.2.1" stretchy="false" xref="S4.p2.9.m6.1.2.cmml">(</mo><mo id="S4.p2.9.m6.1.1" lspace="0em" rspace="0em" xref="S4.p2.9.m6.1.1.cmml">â‹…</mo><mo id="S4.p2.9.m6.1.2.3.2.2" stretchy="false" xref="S4.p2.9.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.9.m6.1b"><apply id="S4.p2.9.m6.1.2.cmml" xref="S4.p2.9.m6.1.2"><times id="S4.p2.9.m6.1.2.1.cmml" xref="S4.p2.9.m6.1.2.1"></times><apply id="S4.p2.9.m6.1.2.2.cmml" xref="S4.p2.9.m6.1.2.2"><csymbol cd="ambiguous" id="S4.p2.9.m6.1.2.2.1.cmml" xref="S4.p2.9.m6.1.2.2">subscript</csymbol><ci id="S4.p2.9.m6.1.2.2.2.cmml" xref="S4.p2.9.m6.1.2.2.2">ğ‘“</ci><ci id="S4.p2.9.m6.1.2.2.3.cmml" xref="S4.p2.9.m6.1.2.2.3">ğ‘‘</ci></apply><ci id="S4.p2.9.m6.1.1.cmml" xref="S4.p2.9.m6.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.9.m6.1c">f_{d}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.p2.9.m6.1d">italic_f start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( â‹… )</annotation></semantics></math> are intermediate features of the diffusion model, extracted at the output of the downsampling block. When training the feature-aligned diffusion model, we use a weighted sum of <math alttext="L_{noise}" class="ltx_Math" display="inline" id="S4.p2.10.m7.1"><semantics id="S4.p2.10.m7.1a"><msub id="S4.p2.10.m7.1.1" xref="S4.p2.10.m7.1.1.cmml"><mi id="S4.p2.10.m7.1.1.2" xref="S4.p2.10.m7.1.1.2.cmml">L</mi><mrow id="S4.p2.10.m7.1.1.3" xref="S4.p2.10.m7.1.1.3.cmml"><mi id="S4.p2.10.m7.1.1.3.2" xref="S4.p2.10.m7.1.1.3.2.cmml">n</mi><mo id="S4.p2.10.m7.1.1.3.1" xref="S4.p2.10.m7.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.10.m7.1.1.3.3" xref="S4.p2.10.m7.1.1.3.3.cmml">o</mi><mo id="S4.p2.10.m7.1.1.3.1a" xref="S4.p2.10.m7.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.10.m7.1.1.3.4" xref="S4.p2.10.m7.1.1.3.4.cmml">i</mi><mo id="S4.p2.10.m7.1.1.3.1b" xref="S4.p2.10.m7.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.10.m7.1.1.3.5" xref="S4.p2.10.m7.1.1.3.5.cmml">s</mi><mo id="S4.p2.10.m7.1.1.3.1c" xref="S4.p2.10.m7.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.10.m7.1.1.3.6" xref="S4.p2.10.m7.1.1.3.6.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p2.10.m7.1b"><apply id="S4.p2.10.m7.1.1.cmml" xref="S4.p2.10.m7.1.1"><csymbol cd="ambiguous" id="S4.p2.10.m7.1.1.1.cmml" xref="S4.p2.10.m7.1.1">subscript</csymbol><ci id="S4.p2.10.m7.1.1.2.cmml" xref="S4.p2.10.m7.1.1.2">ğ¿</ci><apply id="S4.p2.10.m7.1.1.3.cmml" xref="S4.p2.10.m7.1.1.3"><times id="S4.p2.10.m7.1.1.3.1.cmml" xref="S4.p2.10.m7.1.1.3.1"></times><ci id="S4.p2.10.m7.1.1.3.2.cmml" xref="S4.p2.10.m7.1.1.3.2">ğ‘›</ci><ci id="S4.p2.10.m7.1.1.3.3.cmml" xref="S4.p2.10.m7.1.1.3.3">ğ‘œ</ci><ci id="S4.p2.10.m7.1.1.3.4.cmml" xref="S4.p2.10.m7.1.1.3.4">ğ‘–</ci><ci id="S4.p2.10.m7.1.1.3.5.cmml" xref="S4.p2.10.m7.1.1.3.5">ğ‘ </ci><ci id="S4.p2.10.m7.1.1.3.6.cmml" xref="S4.p2.10.m7.1.1.3.6">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.10.m7.1c">L_{noise}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.10.m7.1d">italic_L start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_e end_POSTSUBSCRIPT</annotation></semantics></math> (Eqn 2) and <math alttext="L_{align}" class="ltx_Math" display="inline" id="S4.p2.11.m8.1"><semantics id="S4.p2.11.m8.1a"><msub id="S4.p2.11.m8.1.1" xref="S4.p2.11.m8.1.1.cmml"><mi id="S4.p2.11.m8.1.1.2" xref="S4.p2.11.m8.1.1.2.cmml">L</mi><mrow id="S4.p2.11.m8.1.1.3" xref="S4.p2.11.m8.1.1.3.cmml"><mi id="S4.p2.11.m8.1.1.3.2" xref="S4.p2.11.m8.1.1.3.2.cmml">a</mi><mo id="S4.p2.11.m8.1.1.3.1" xref="S4.p2.11.m8.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.11.m8.1.1.3.3" xref="S4.p2.11.m8.1.1.3.3.cmml">l</mi><mo id="S4.p2.11.m8.1.1.3.1a" xref="S4.p2.11.m8.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.11.m8.1.1.3.4" xref="S4.p2.11.m8.1.1.3.4.cmml">i</mi><mo id="S4.p2.11.m8.1.1.3.1b" xref="S4.p2.11.m8.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.11.m8.1.1.3.5" xref="S4.p2.11.m8.1.1.3.5.cmml">g</mi><mo id="S4.p2.11.m8.1.1.3.1c" xref="S4.p2.11.m8.1.1.3.1.cmml">â¢</mo><mi id="S4.p2.11.m8.1.1.3.6" xref="S4.p2.11.m8.1.1.3.6.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p2.11.m8.1b"><apply id="S4.p2.11.m8.1.1.cmml" xref="S4.p2.11.m8.1.1"><csymbol cd="ambiguous" id="S4.p2.11.m8.1.1.1.cmml" xref="S4.p2.11.m8.1.1">subscript</csymbol><ci id="S4.p2.11.m8.1.1.2.cmml" xref="S4.p2.11.m8.1.1.2">ğ¿</ci><apply id="S4.p2.11.m8.1.1.3.cmml" xref="S4.p2.11.m8.1.1.3"><times id="S4.p2.11.m8.1.1.3.1.cmml" xref="S4.p2.11.m8.1.1.3.1"></times><ci id="S4.p2.11.m8.1.1.3.2.cmml" xref="S4.p2.11.m8.1.1.3.2">ğ‘</ci><ci id="S4.p2.11.m8.1.1.3.3.cmml" xref="S4.p2.11.m8.1.1.3.3">ğ‘™</ci><ci id="S4.p2.11.m8.1.1.3.4.cmml" xref="S4.p2.11.m8.1.1.3.4">ğ‘–</ci><ci id="S4.p2.11.m8.1.1.3.5.cmml" xref="S4.p2.11.m8.1.1.3.5">ğ‘”</ci><ci id="S4.p2.11.m8.1.1.3.6.cmml" xref="S4.p2.11.m8.1.1.3.6">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.11.m8.1c">L_{align}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.11.m8.1d">italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math> (Eqn 4) for the combined loss function:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L=w_{1}\cdot L_{noise}+w_{2}\cdot L_{align}" class="ltx_Math" display="block" id="S4.E5.m1.1"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml"><mi id="S4.E5.m1.1.1.2" xref="S4.E5.m1.1.1.2.cmml">L</mi><mo id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml">=</mo><mrow id="S4.E5.m1.1.1.3" xref="S4.E5.m1.1.1.3.cmml"><mrow id="S4.E5.m1.1.1.3.2" xref="S4.E5.m1.1.1.3.2.cmml"><msub id="S4.E5.m1.1.1.3.2.2" xref="S4.E5.m1.1.1.3.2.2.cmml"><mi id="S4.E5.m1.1.1.3.2.2.2" xref="S4.E5.m1.1.1.3.2.2.2.cmml">w</mi><mn id="S4.E5.m1.1.1.3.2.2.3" xref="S4.E5.m1.1.1.3.2.2.3.cmml">1</mn></msub><mo id="S4.E5.m1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S4.E5.m1.1.1.3.2.1.cmml">â‹…</mo><msub id="S4.E5.m1.1.1.3.2.3" xref="S4.E5.m1.1.1.3.2.3.cmml"><mi id="S4.E5.m1.1.1.3.2.3.2" xref="S4.E5.m1.1.1.3.2.3.2.cmml">L</mi><mrow id="S4.E5.m1.1.1.3.2.3.3" xref="S4.E5.m1.1.1.3.2.3.3.cmml"><mi id="S4.E5.m1.1.1.3.2.3.3.2" xref="S4.E5.m1.1.1.3.2.3.3.2.cmml">n</mi><mo id="S4.E5.m1.1.1.3.2.3.3.1" xref="S4.E5.m1.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.2.3.3.3" xref="S4.E5.m1.1.1.3.2.3.3.3.cmml">o</mi><mo id="S4.E5.m1.1.1.3.2.3.3.1a" xref="S4.E5.m1.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.2.3.3.4" xref="S4.E5.m1.1.1.3.2.3.3.4.cmml">i</mi><mo id="S4.E5.m1.1.1.3.2.3.3.1b" xref="S4.E5.m1.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.2.3.3.5" xref="S4.E5.m1.1.1.3.2.3.3.5.cmml">s</mi><mo id="S4.E5.m1.1.1.3.2.3.3.1c" xref="S4.E5.m1.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.2.3.3.6" xref="S4.E5.m1.1.1.3.2.3.3.6.cmml">e</mi></mrow></msub></mrow><mo id="S4.E5.m1.1.1.3.1" xref="S4.E5.m1.1.1.3.1.cmml">+</mo><mrow id="S4.E5.m1.1.1.3.3" xref="S4.E5.m1.1.1.3.3.cmml"><msub id="S4.E5.m1.1.1.3.3.2" xref="S4.E5.m1.1.1.3.3.2.cmml"><mi id="S4.E5.m1.1.1.3.3.2.2" xref="S4.E5.m1.1.1.3.3.2.2.cmml">w</mi><mn id="S4.E5.m1.1.1.3.3.2.3" xref="S4.E5.m1.1.1.3.3.2.3.cmml">2</mn></msub><mo id="S4.E5.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.E5.m1.1.1.3.3.1.cmml">â‹…</mo><msub id="S4.E5.m1.1.1.3.3.3" xref="S4.E5.m1.1.1.3.3.3.cmml"><mi id="S4.E5.m1.1.1.3.3.3.2" xref="S4.E5.m1.1.1.3.3.3.2.cmml">L</mi><mrow id="S4.E5.m1.1.1.3.3.3.3" xref="S4.E5.m1.1.1.3.3.3.3.cmml"><mi id="S4.E5.m1.1.1.3.3.3.3.2" xref="S4.E5.m1.1.1.3.3.3.3.2.cmml">a</mi><mo id="S4.E5.m1.1.1.3.3.3.3.1" xref="S4.E5.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.3.3.3.3" xref="S4.E5.m1.1.1.3.3.3.3.3.cmml">l</mi><mo id="S4.E5.m1.1.1.3.3.3.3.1a" xref="S4.E5.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.3.3.3.4" xref="S4.E5.m1.1.1.3.3.3.3.4.cmml">i</mi><mo id="S4.E5.m1.1.1.3.3.3.3.1b" xref="S4.E5.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.3.3.3.5" xref="S4.E5.m1.1.1.3.3.3.3.5.cmml">g</mi><mo id="S4.E5.m1.1.1.3.3.3.3.1c" xref="S4.E5.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S4.E5.m1.1.1.3.3.3.3.6" xref="S4.E5.m1.1.1.3.3.3.3.6.cmml">n</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1"><eq id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"></eq><ci id="S4.E5.m1.1.1.2.cmml" xref="S4.E5.m1.1.1.2">ğ¿</ci><apply id="S4.E5.m1.1.1.3.cmml" xref="S4.E5.m1.1.1.3"><plus id="S4.E5.m1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.3.1"></plus><apply id="S4.E5.m1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.3.2"><ci id="S4.E5.m1.1.1.3.2.1.cmml" xref="S4.E5.m1.1.1.3.2.1">â‹…</ci><apply id="S4.E5.m1.1.1.3.2.2.cmml" xref="S4.E5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.2.2.1.cmml" xref="S4.E5.m1.1.1.3.2.2">subscript</csymbol><ci id="S4.E5.m1.1.1.3.2.2.2.cmml" xref="S4.E5.m1.1.1.3.2.2.2">ğ‘¤</ci><cn id="S4.E5.m1.1.1.3.2.2.3.cmml" type="integer" xref="S4.E5.m1.1.1.3.2.2.3">1</cn></apply><apply id="S4.E5.m1.1.1.3.2.3.cmml" xref="S4.E5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.2.3.1.cmml" xref="S4.E5.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E5.m1.1.1.3.2.3.2.cmml" xref="S4.E5.m1.1.1.3.2.3.2">ğ¿</ci><apply id="S4.E5.m1.1.1.3.2.3.3.cmml" xref="S4.E5.m1.1.1.3.2.3.3"><times id="S4.E5.m1.1.1.3.2.3.3.1.cmml" xref="S4.E5.m1.1.1.3.2.3.3.1"></times><ci id="S4.E5.m1.1.1.3.2.3.3.2.cmml" xref="S4.E5.m1.1.1.3.2.3.3.2">ğ‘›</ci><ci id="S4.E5.m1.1.1.3.2.3.3.3.cmml" xref="S4.E5.m1.1.1.3.2.3.3.3">ğ‘œ</ci><ci id="S4.E5.m1.1.1.3.2.3.3.4.cmml" xref="S4.E5.m1.1.1.3.2.3.3.4">ğ‘–</ci><ci id="S4.E5.m1.1.1.3.2.3.3.5.cmml" xref="S4.E5.m1.1.1.3.2.3.3.5">ğ‘ </ci><ci id="S4.E5.m1.1.1.3.2.3.3.6.cmml" xref="S4.E5.m1.1.1.3.2.3.3.6">ğ‘’</ci></apply></apply></apply><apply id="S4.E5.m1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.3.3"><ci id="S4.E5.m1.1.1.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.1">â‹…</ci><apply id="S4.E5.m1.1.1.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.3.2.1.cmml" xref="S4.E5.m1.1.1.3.3.2">subscript</csymbol><ci id="S4.E5.m1.1.1.3.3.2.2.cmml" xref="S4.E5.m1.1.1.3.3.2.2">ğ‘¤</ci><cn id="S4.E5.m1.1.1.3.3.2.3.cmml" type="integer" xref="S4.E5.m1.1.1.3.3.2.3">2</cn></apply><apply id="S4.E5.m1.1.1.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.3.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.3">subscript</csymbol><ci id="S4.E5.m1.1.1.3.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.3.2">ğ¿</ci><apply id="S4.E5.m1.1.1.3.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3.3"><times id="S4.E5.m1.1.1.3.3.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.3.3.1"></times><ci id="S4.E5.m1.1.1.3.3.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.3.3.2">ğ‘</ci><ci id="S4.E5.m1.1.1.3.3.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3.3.3">ğ‘™</ci><ci id="S4.E5.m1.1.1.3.3.3.3.4.cmml" xref="S4.E5.m1.1.1.3.3.3.3.4">ğ‘–</ci><ci id="S4.E5.m1.1.1.3.3.3.3.5.cmml" xref="S4.E5.m1.1.1.3.3.3.3.5">ğ‘”</ci><ci id="S4.E5.m1.1.1.3.3.3.3.6.cmml" xref="S4.E5.m1.1.1.3.3.3.3.6">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">L=w_{1}\cdot L_{noise}+w_{2}\cdot L_{align}</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.1d">italic_L = italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT â‹… italic_L start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_e end_POSTSUBSCRIPT + italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT â‹… italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.12">We note that the expert feature alignment is <span class="ltx_text ltx_font_italic" id="S4.p2.12.1">only applied during fine-tuning</span>, i.e., the expert model is <span class="ltx_text ltx_font_italic" id="S4.p2.12.2">not</span> needed during inference. During inference, the diffusion model is provided with a class label and input noise to generate images corresponding to the class.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.8"><span class="ltx_text ltx_font_bold" id="S4.p3.8.1">Note on processing of features:</span> Common in architectures like ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib13" title="">13</a>]</cite>, the expert features of dimensions <math alttext="(B,E_{e},H,W)" class="ltx_Math" display="inline" id="S4.p3.1.m1.4"><semantics id="S4.p3.1.m1.4a"><mrow id="S4.p3.1.m1.4.4.1" xref="S4.p3.1.m1.4.4.2.cmml"><mo id="S4.p3.1.m1.4.4.1.2" stretchy="false" xref="S4.p3.1.m1.4.4.2.cmml">(</mo><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">B</mi><mo id="S4.p3.1.m1.4.4.1.3" xref="S4.p3.1.m1.4.4.2.cmml">,</mo><msub id="S4.p3.1.m1.4.4.1.1" xref="S4.p3.1.m1.4.4.1.1.cmml"><mi id="S4.p3.1.m1.4.4.1.1.2" xref="S4.p3.1.m1.4.4.1.1.2.cmml">E</mi><mi id="S4.p3.1.m1.4.4.1.1.3" xref="S4.p3.1.m1.4.4.1.1.3.cmml">e</mi></msub><mo id="S4.p3.1.m1.4.4.1.4" xref="S4.p3.1.m1.4.4.2.cmml">,</mo><mi id="S4.p3.1.m1.2.2" xref="S4.p3.1.m1.2.2.cmml">H</mi><mo id="S4.p3.1.m1.4.4.1.5" xref="S4.p3.1.m1.4.4.2.cmml">,</mo><mi id="S4.p3.1.m1.3.3" xref="S4.p3.1.m1.3.3.cmml">W</mi><mo id="S4.p3.1.m1.4.4.1.6" stretchy="false" xref="S4.p3.1.m1.4.4.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.4b"><vector id="S4.p3.1.m1.4.4.2.cmml" xref="S4.p3.1.m1.4.4.1"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">ğµ</ci><apply id="S4.p3.1.m1.4.4.1.1.cmml" xref="S4.p3.1.m1.4.4.1.1"><csymbol cd="ambiguous" id="S4.p3.1.m1.4.4.1.1.1.cmml" xref="S4.p3.1.m1.4.4.1.1">subscript</csymbol><ci id="S4.p3.1.m1.4.4.1.1.2.cmml" xref="S4.p3.1.m1.4.4.1.1.2">ğ¸</ci><ci id="S4.p3.1.m1.4.4.1.1.3.cmml" xref="S4.p3.1.m1.4.4.1.1.3">ğ‘’</ci></apply><ci id="S4.p3.1.m1.2.2.cmml" xref="S4.p3.1.m1.2.2">ğ»</ci><ci id="S4.p3.1.m1.3.3.cmml" xref="S4.p3.1.m1.3.3">ğ‘Š</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.4c">(B,E_{e},H,W)</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.4d">( italic_B , italic_E start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_H , italic_W )</annotation></semantics></math> are typically passed through an adaptive average pooling layer, resulting in a <math alttext="(B,E_{e})" class="ltx_Math" display="inline" id="S4.p3.2.m2.2"><semantics id="S4.p3.2.m2.2a"><mrow id="S4.p3.2.m2.2.2.1" xref="S4.p3.2.m2.2.2.2.cmml"><mo id="S4.p3.2.m2.2.2.1.2" stretchy="false" xref="S4.p3.2.m2.2.2.2.cmml">(</mo><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">B</mi><mo id="S4.p3.2.m2.2.2.1.3" xref="S4.p3.2.m2.2.2.2.cmml">,</mo><msub id="S4.p3.2.m2.2.2.1.1" xref="S4.p3.2.m2.2.2.1.1.cmml"><mi id="S4.p3.2.m2.2.2.1.1.2" xref="S4.p3.2.m2.2.2.1.1.2.cmml">E</mi><mi id="S4.p3.2.m2.2.2.1.1.3" xref="S4.p3.2.m2.2.2.1.1.3.cmml">e</mi></msub><mo id="S4.p3.2.m2.2.2.1.4" stretchy="false" xref="S4.p3.2.m2.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.2b"><interval closure="open" id="S4.p3.2.m2.2.2.2.cmml" xref="S4.p3.2.m2.2.2.1"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">ğµ</ci><apply id="S4.p3.2.m2.2.2.1.1.cmml" xref="S4.p3.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.p3.2.m2.2.2.1.1.1.cmml" xref="S4.p3.2.m2.2.2.1.1">subscript</csymbol><ci id="S4.p3.2.m2.2.2.1.1.2.cmml" xref="S4.p3.2.m2.2.2.1.1.2">ğ¸</ci><ci id="S4.p3.2.m2.2.2.1.1.3.cmml" xref="S4.p3.2.m2.2.2.1.1.3">ğ‘’</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.2c">(B,E_{e})</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.2d">( italic_B , italic_E start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT )</annotation></semantics></math> output. Here, <math alttext="B" class="ltx_Math" display="inline" id="S4.p3.3.m3.1"><semantics id="S4.p3.3.m3.1a"><mi id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><ci id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.p3.3.m3.1d">italic_B</annotation></semantics></math> is the batch size, and <math alttext="(H,W)" class="ltx_Math" display="inline" id="S4.p3.4.m4.2"><semantics id="S4.p3.4.m4.2a"><mrow id="S4.p3.4.m4.2.3.2" xref="S4.p3.4.m4.2.3.1.cmml"><mo id="S4.p3.4.m4.2.3.2.1" stretchy="false" xref="S4.p3.4.m4.2.3.1.cmml">(</mo><mi id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml">H</mi><mo id="S4.p3.4.m4.2.3.2.2" xref="S4.p3.4.m4.2.3.1.cmml">,</mo><mi id="S4.p3.4.m4.2.2" xref="S4.p3.4.m4.2.2.cmml">W</mi><mo id="S4.p3.4.m4.2.3.2.3" stretchy="false" xref="S4.p3.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.2b"><interval closure="open" id="S4.p3.4.m4.2.3.1.cmml" xref="S4.p3.4.m4.2.3.2"><ci id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1">ğ»</ci><ci id="S4.p3.4.m4.2.2.cmml" xref="S4.p3.4.m4.2.2">ğ‘Š</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.2c">(H,W)</annotation><annotation encoding="application/x-llamapun" id="S4.p3.4.m4.2d">( italic_H , italic_W )</annotation></semantics></math> denote the spatial dimensions of the image. This pooling is done prior to the output being used for classification (via linear and softmax layers). We extract the output of the adaptive average pooling layer and pass it into the projection <math alttext="W_{p}" class="ltx_Math" display="inline" id="S4.p3.5.m5.1"><semantics id="S4.p3.5.m5.1a"><msub id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml"><mi id="S4.p3.5.m5.1.1.2" xref="S4.p3.5.m5.1.1.2.cmml">W</mi><mi id="S4.p3.5.m5.1.1.3" xref="S4.p3.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><apply id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.1.cmml" xref="S4.p3.5.m5.1.1">subscript</csymbol><ci id="S4.p3.5.m5.1.1.2.cmml" xref="S4.p3.5.m5.1.1.2">ğ‘Š</ci><ci id="S4.p3.5.m5.1.1.3.cmml" xref="S4.p3.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">W_{p}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.5.m5.1d">italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> to create an output of size <math alttext="(B,E_{d})" class="ltx_Math" display="inline" id="S4.p3.6.m6.2"><semantics id="S4.p3.6.m6.2a"><mrow id="S4.p3.6.m6.2.2.1" xref="S4.p3.6.m6.2.2.2.cmml"><mo id="S4.p3.6.m6.2.2.1.2" stretchy="false" xref="S4.p3.6.m6.2.2.2.cmml">(</mo><mi id="S4.p3.6.m6.1.1" xref="S4.p3.6.m6.1.1.cmml">B</mi><mo id="S4.p3.6.m6.2.2.1.3" xref="S4.p3.6.m6.2.2.2.cmml">,</mo><msub id="S4.p3.6.m6.2.2.1.1" xref="S4.p3.6.m6.2.2.1.1.cmml"><mi id="S4.p3.6.m6.2.2.1.1.2" xref="S4.p3.6.m6.2.2.1.1.2.cmml">E</mi><mi id="S4.p3.6.m6.2.2.1.1.3" xref="S4.p3.6.m6.2.2.1.1.3.cmml">d</mi></msub><mo id="S4.p3.6.m6.2.2.1.4" stretchy="false" xref="S4.p3.6.m6.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.6.m6.2b"><interval closure="open" id="S4.p3.6.m6.2.2.2.cmml" xref="S4.p3.6.m6.2.2.1"><ci id="S4.p3.6.m6.1.1.cmml" xref="S4.p3.6.m6.1.1">ğµ</ci><apply id="S4.p3.6.m6.2.2.1.1.cmml" xref="S4.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S4.p3.6.m6.2.2.1.1.1.cmml" xref="S4.p3.6.m6.2.2.1.1">subscript</csymbol><ci id="S4.p3.6.m6.2.2.1.1.2.cmml" xref="S4.p3.6.m6.2.2.1.1.2">ğ¸</ci><ci id="S4.p3.6.m6.2.2.1.1.3.cmml" xref="S4.p3.6.m6.2.2.1.1.3">ğ‘‘</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.6.m6.2c">(B,E_{d})</annotation><annotation encoding="application/x-llamapun" id="S4.p3.6.m6.2d">( italic_B , italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT )</annotation></semantics></math>. For the diffusion model, the downsampling block similarly yields an output of dimensions <math alttext="(B,E_{d},H^{\prime},W^{\prime})" class="ltx_Math" display="inline" id="S4.p3.7.m7.4"><semantics id="S4.p3.7.m7.4a"><mrow id="S4.p3.7.m7.4.4.3" xref="S4.p3.7.m7.4.4.4.cmml"><mo id="S4.p3.7.m7.4.4.3.4" stretchy="false" xref="S4.p3.7.m7.4.4.4.cmml">(</mo><mi id="S4.p3.7.m7.1.1" xref="S4.p3.7.m7.1.1.cmml">B</mi><mo id="S4.p3.7.m7.4.4.3.5" xref="S4.p3.7.m7.4.4.4.cmml">,</mo><msub id="S4.p3.7.m7.2.2.1.1" xref="S4.p3.7.m7.2.2.1.1.cmml"><mi id="S4.p3.7.m7.2.2.1.1.2" xref="S4.p3.7.m7.2.2.1.1.2.cmml">E</mi><mi id="S4.p3.7.m7.2.2.1.1.3" xref="S4.p3.7.m7.2.2.1.1.3.cmml">d</mi></msub><mo id="S4.p3.7.m7.4.4.3.6" xref="S4.p3.7.m7.4.4.4.cmml">,</mo><msup id="S4.p3.7.m7.3.3.2.2" xref="S4.p3.7.m7.3.3.2.2.cmml"><mi id="S4.p3.7.m7.3.3.2.2.2" xref="S4.p3.7.m7.3.3.2.2.2.cmml">H</mi><mo id="S4.p3.7.m7.3.3.2.2.3" xref="S4.p3.7.m7.3.3.2.2.3.cmml">â€²</mo></msup><mo id="S4.p3.7.m7.4.4.3.7" xref="S4.p3.7.m7.4.4.4.cmml">,</mo><msup id="S4.p3.7.m7.4.4.3.3" xref="S4.p3.7.m7.4.4.3.3.cmml"><mi id="S4.p3.7.m7.4.4.3.3.2" xref="S4.p3.7.m7.4.4.3.3.2.cmml">W</mi><mo id="S4.p3.7.m7.4.4.3.3.3" xref="S4.p3.7.m7.4.4.3.3.3.cmml">â€²</mo></msup><mo id="S4.p3.7.m7.4.4.3.8" stretchy="false" xref="S4.p3.7.m7.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.7.m7.4b"><vector id="S4.p3.7.m7.4.4.4.cmml" xref="S4.p3.7.m7.4.4.3"><ci id="S4.p3.7.m7.1.1.cmml" xref="S4.p3.7.m7.1.1">ğµ</ci><apply id="S4.p3.7.m7.2.2.1.1.cmml" xref="S4.p3.7.m7.2.2.1.1"><csymbol cd="ambiguous" id="S4.p3.7.m7.2.2.1.1.1.cmml" xref="S4.p3.7.m7.2.2.1.1">subscript</csymbol><ci id="S4.p3.7.m7.2.2.1.1.2.cmml" xref="S4.p3.7.m7.2.2.1.1.2">ğ¸</ci><ci id="S4.p3.7.m7.2.2.1.1.3.cmml" xref="S4.p3.7.m7.2.2.1.1.3">ğ‘‘</ci></apply><apply id="S4.p3.7.m7.3.3.2.2.cmml" xref="S4.p3.7.m7.3.3.2.2"><csymbol cd="ambiguous" id="S4.p3.7.m7.3.3.2.2.1.cmml" xref="S4.p3.7.m7.3.3.2.2">superscript</csymbol><ci id="S4.p3.7.m7.3.3.2.2.2.cmml" xref="S4.p3.7.m7.3.3.2.2.2">ğ»</ci><ci id="S4.p3.7.m7.3.3.2.2.3.cmml" xref="S4.p3.7.m7.3.3.2.2.3">â€²</ci></apply><apply id="S4.p3.7.m7.4.4.3.3.cmml" xref="S4.p3.7.m7.4.4.3.3"><csymbol cd="ambiguous" id="S4.p3.7.m7.4.4.3.3.1.cmml" xref="S4.p3.7.m7.4.4.3.3">superscript</csymbol><ci id="S4.p3.7.m7.4.4.3.3.2.cmml" xref="S4.p3.7.m7.4.4.3.3.2">ğ‘Š</ci><ci id="S4.p3.7.m7.4.4.3.3.3.cmml" xref="S4.p3.7.m7.4.4.3.3.3">â€²</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.7.m7.4c">(B,E_{d},H^{\prime},W^{\prime})</annotation><annotation encoding="application/x-llamapun" id="S4.p3.7.m7.4d">( italic_B , italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_H start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , italic_W start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT )</annotation></semantics></math>. We pass this into an adaptive average pooling layer to yield a <math alttext="(B,E_{d})" class="ltx_Math" display="inline" id="S4.p3.8.m8.2"><semantics id="S4.p3.8.m8.2a"><mrow id="S4.p3.8.m8.2.2.1" xref="S4.p3.8.m8.2.2.2.cmml"><mo id="S4.p3.8.m8.2.2.1.2" stretchy="false" xref="S4.p3.8.m8.2.2.2.cmml">(</mo><mi id="S4.p3.8.m8.1.1" xref="S4.p3.8.m8.1.1.cmml">B</mi><mo id="S4.p3.8.m8.2.2.1.3" xref="S4.p3.8.m8.2.2.2.cmml">,</mo><msub id="S4.p3.8.m8.2.2.1.1" xref="S4.p3.8.m8.2.2.1.1.cmml"><mi id="S4.p3.8.m8.2.2.1.1.2" xref="S4.p3.8.m8.2.2.1.1.2.cmml">E</mi><mi id="S4.p3.8.m8.2.2.1.1.3" xref="S4.p3.8.m8.2.2.1.1.3.cmml">d</mi></msub><mo id="S4.p3.8.m8.2.2.1.4" stretchy="false" xref="S4.p3.8.m8.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.8.m8.2b"><interval closure="open" id="S4.p3.8.m8.2.2.2.cmml" xref="S4.p3.8.m8.2.2.1"><ci id="S4.p3.8.m8.1.1.cmml" xref="S4.p3.8.m8.1.1">ğµ</ci><apply id="S4.p3.8.m8.2.2.1.1.cmml" xref="S4.p3.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="S4.p3.8.m8.2.2.1.1.1.cmml" xref="S4.p3.8.m8.2.2.1.1">subscript</csymbol><ci id="S4.p3.8.m8.2.2.1.1.2.cmml" xref="S4.p3.8.m8.2.2.1.1.2">ğ¸</ci><ci id="S4.p3.8.m8.2.2.1.1.3.cmml" xref="S4.p3.8.m8.2.2.1.1.3">ğ‘‘</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.8.m8.2c">(B,E_{d})</annotation><annotation encoding="application/x-llamapun" id="S4.p3.8.m8.2d">( italic_B , italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT )</annotation></semantics></math> output. Following this processing, the expert features and intermediate diffusion features can be directly compared via cosine similarity.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="113" id="S4.F2.g1" src="extracted/5893087/imgs/expert_val.png" width="284"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">Fine-tuning validation accuracy of expert models â€“ ResNet50 (left) with 93% and ViT with 87%.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="S4.F3.g1" src="extracted/5893087/imgs/loss.png" width="281"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Loss during fine-tuning with feature alignment.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">Generation accuracy when aligning to expert features computed on the original noise-free training samples vs. expert features computed on noise-added training inputs.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T1.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.1.1.1">Alignment</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T1.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.1.2.1">Generation Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.4.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.2.1.1">To noise-free input</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.2">28.57%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.3.2.1">To noise-added input</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.2">67.14%</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1">Why would feature-aligned diffusion work?</span> Our intuition comes from prior work demonstrating that preference optimization is possible within the noisy, latent space of the U-Net model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib14" title="">14</a>]</cite>. Their work evaluates the downsampling output at timestep <math alttext="t-1" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mrow id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mi id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">t</mi><mo id="S4.p4.1.m1.1.1.1" xref="S4.p4.1.m1.1.1.1.cmml">âˆ’</mo><mn id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><minus id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1"></minus><ci id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">ğ‘¡</ci><cn id="S4.p4.1.m1.1.1.3.cmml" type="integer" xref="S4.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">t-1</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">italic_t - 1</annotation></semantics></math>: one timestep before the predicted noise, comparing it to the ground truth of applying one reverse step to the true added noise, in order to improve model generations. In contrast to their work, we explore whether a direct alignment between an expert and the diffusion model can be performed within this noisy, latent space.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Experiments</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">For our experiments, we use an existing dataset of histological images of colorectal cancer across 8 tissue classes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib15" title="">15</a>]</cite>. We convert the images from the dataset to gray-scale in this work. For the model architecture, we use an open-source Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib12" title="">12</a>]</cite> model from HuggingFace (<span class="ltx_text ltx_font_italic" id="S5.p1.1.1">segmind/tiny-sd</span>) consisting of interleaved resnet and cross-attention blocks in the upsampling and downsampling paths. We make our code available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lnairGT/Feature-Aligned-Diffusion" title="">https://github.com/lnairGT/Feature-Aligned-Diffusion</a>.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">Choice of Expert Model</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">For the expert model, we explored fine-tuning of two different architectures: ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib13" title="">13</a>]</cite> and ViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib16" title="">16</a>]</cite> â€“ both models were pretrained on the ImageNet-1k dataset. The models were fine-tuned with a learning rate of 1e-4, batch size of 64 and image size of 224. We fine-tuned for 15 epochs with a weight decay of 0.7. We found that ResNet50 achieved a classification accuracy of 93%, whereas ViT achieved 87% (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S4.F2" title="Figure 2 â€£ IV Feature-Aligned Diffusion â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">2</span></a>). Hence, we use ResNet50 as our expert.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="171" id="S5.F4.g1" src="extracted/5893087/imgs/box.png" width="228"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">Generation accuracy of feature-aligned vs. baseline diffusion for two fine-tuning pipelines: typical and DreamBooth</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="551" id="S5.F5.sf1.g1" src="extracted/5893087/imgs/cf_diff.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="581" id="S5.F5.sf2.g1" src="extracted/5893087/imgs/baseline_cf_mat.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="551" id="S5.F5.sf3.g1" src="extracted/5893087/imgs/cf_exp.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf3.2.1.1" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S5.F5.3.2" style="font-size:90%;">(a) Confusion matrix of expert on feature-aligned diffusion generations, (b) Confusion matrix of expert on baseline diffusion generations (c) Confusion matrix of expert on original dataset. The expert does not mis-classify tumor, stroma, and lympho as debris within the original dataset.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="209" id="S5.F6.g1" src="extracted/5893087/imgs/boxcompare.png" width="278"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.4.2.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.2.1" style="font-size:90%;">SSIM of baseline, feature-aligned diffusion and original dataset. Note: Lower SSIM <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.F6.2.1.m1.1"><semantics id="S5.F6.2.1.m1.1b"><mo id="S5.F6.2.1.m1.1.1" stretchy="false" xref="S5.F6.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.F6.2.1.m1.1c"><ci id="S5.F6.2.1.m1.1.1.cmml" xref="S5.F6.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.2.1.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.F6.2.1.m1.1e">â†’</annotation></semantics></math> better sample diversity.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Diffusion Fine-tuning Hyper-parameters</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We fine-tune the diffusion models for 20 epochs, either with or without feature alignment, using a learning rate of 1e-4. We use a batch size of 4, and image size of 64. During expert evaluation, the images are resized to 224. For the loss with feature alignment (Eqn 5), we set <math alttext="w_{1}=w_{2}=1.0" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><msub id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2.2" xref="S5.SS2.p1.1.m1.1.1.2.2.cmml">w</mi><mn id="S5.SS2.p1.1.m1.1.1.2.3" xref="S5.SS2.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">=</mo><msub id="S5.SS2.p1.1.m1.1.1.4" xref="S5.SS2.p1.1.m1.1.1.4.cmml"><mi id="S5.SS2.p1.1.m1.1.1.4.2" xref="S5.SS2.p1.1.m1.1.1.4.2.cmml">w</mi><mn id="S5.SS2.p1.1.m1.1.1.4.3" xref="S5.SS2.p1.1.m1.1.1.4.3.cmml">2</mn></msub><mo id="S5.SS2.p1.1.m1.1.1.5" xref="S5.SS2.p1.1.m1.1.1.5.cmml">=</mo><mn id="S5.SS2.p1.1.m1.1.1.6" xref="S5.SS2.p1.1.m1.1.1.6.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><and id="S5.SS2.p1.1.m1.1.1a.cmml" xref="S5.SS2.p1.1.m1.1.1"></and><apply id="S5.SS2.p1.1.m1.1.1b.cmml" xref="S5.SS2.p1.1.m1.1.1"><eq id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3"></eq><apply id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.2.1.cmml" xref="S5.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2.2">ğ‘¤</ci><cn id="S5.SS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.2.3">1</cn></apply><apply id="S5.SS2.p1.1.m1.1.1.4.cmml" xref="S5.SS2.p1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.4.1.cmml" xref="S5.SS2.p1.1.m1.1.1.4">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.4.2.cmml" xref="S5.SS2.p1.1.m1.1.1.4.2">ğ‘¤</ci><cn id="S5.SS2.p1.1.m1.1.1.4.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.4.3">2</cn></apply></apply><apply id="S5.SS2.p1.1.m1.1.1c.cmml" xref="S5.SS2.p1.1.m1.1.1"><eq id="S5.SS2.p1.1.m1.1.1.5.cmml" xref="S5.SS2.p1.1.m1.1.1.5"></eq><share href="https://arxiv.org/html/2410.00731v1#S5.SS2.p1.1.m1.1.1.4.cmml" id="S5.SS2.p1.1.m1.1.1d.cmml" xref="S5.SS2.p1.1.m1.1.1"></share><cn id="S5.SS2.p1.1.m1.1.1.6.cmml" type="float" xref="S5.SS2.p1.1.m1.1.1.6">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">w_{1}=w_{2}=1.0</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1.0</annotation></semantics></math>. Diffusion timesteps are set to 1000. We use HuggingFace <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.1">diffusers</span>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.4">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S4.F3" title="Figure 3 â€£ IV Feature-Aligned Diffusion â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">3</span></a> shows the loss curves during feature-aligned fine-tuning, for the combined loss (<math alttext="L_{noise}" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><msub id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">L</mi><mrow id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml"><mi id="S5.SS2.p2.1.m1.1.1.3.2" xref="S5.SS2.p2.1.m1.1.1.3.2.cmml">n</mi><mo id="S5.SS2.p2.1.m1.1.1.3.1" xref="S5.SS2.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.1.m1.1.1.3.3" xref="S5.SS2.p2.1.m1.1.1.3.3.cmml">o</mi><mo id="S5.SS2.p2.1.m1.1.1.3.1a" xref="S5.SS2.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.1.m1.1.1.3.4" xref="S5.SS2.p2.1.m1.1.1.3.4.cmml">i</mi><mo id="S5.SS2.p2.1.m1.1.1.3.1b" xref="S5.SS2.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.1.m1.1.1.3.5" xref="S5.SS2.p2.1.m1.1.1.3.5.cmml">s</mi><mo id="S5.SS2.p2.1.m1.1.1.3.1c" xref="S5.SS2.p2.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.1.m1.1.1.3.6" xref="S5.SS2.p2.1.m1.1.1.3.6.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">ğ¿</ci><apply id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3"><times id="S5.SS2.p2.1.m1.1.1.3.1.cmml" xref="S5.SS2.p2.1.m1.1.1.3.1"></times><ci id="S5.SS2.p2.1.m1.1.1.3.2.cmml" xref="S5.SS2.p2.1.m1.1.1.3.2">ğ‘›</ci><ci id="S5.SS2.p2.1.m1.1.1.3.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S5.SS2.p2.1.m1.1.1.3.4.cmml" xref="S5.SS2.p2.1.m1.1.1.3.4">ğ‘–</ci><ci id="S5.SS2.p2.1.m1.1.1.3.5.cmml" xref="S5.SS2.p2.1.m1.1.1.3.5">ğ‘ </ci><ci id="S5.SS2.p2.1.m1.1.1.3.6.cmml" xref="S5.SS2.p2.1.m1.1.1.3.6">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">L_{noise}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_L start_POSTSUBSCRIPT italic_n italic_o italic_i italic_s italic_e end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="L_{align}" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><msub id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">L</mi><mrow id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml"><mi id="S5.SS2.p2.2.m2.1.1.3.2" xref="S5.SS2.p2.2.m2.1.1.3.2.cmml">a</mi><mo id="S5.SS2.p2.2.m2.1.1.3.1" xref="S5.SS2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.2.m2.1.1.3.3" xref="S5.SS2.p2.2.m2.1.1.3.3.cmml">l</mi><mo id="S5.SS2.p2.2.m2.1.1.3.1a" xref="S5.SS2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.2.m2.1.1.3.4" xref="S5.SS2.p2.2.m2.1.1.3.4.cmml">i</mi><mo id="S5.SS2.p2.2.m2.1.1.3.1b" xref="S5.SS2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.2.m2.1.1.3.5" xref="S5.SS2.p2.2.m2.1.1.3.5.cmml">g</mi><mo id="S5.SS2.p2.2.m2.1.1.3.1c" xref="S5.SS2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.2.m2.1.1.3.6" xref="S5.SS2.p2.2.m2.1.1.3.6.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">ğ¿</ci><apply id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3"><times id="S5.SS2.p2.2.m2.1.1.3.1.cmml" xref="S5.SS2.p2.2.m2.1.1.3.1"></times><ci id="S5.SS2.p2.2.m2.1.1.3.2.cmml" xref="S5.SS2.p2.2.m2.1.1.3.2">ğ‘</ci><ci id="S5.SS2.p2.2.m2.1.1.3.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3.3">ğ‘™</ci><ci id="S5.SS2.p2.2.m2.1.1.3.4.cmml" xref="S5.SS2.p2.2.m2.1.1.3.4">ğ‘–</ci><ci id="S5.SS2.p2.2.m2.1.1.3.5.cmml" xref="S5.SS2.p2.2.m2.1.1.3.5">ğ‘”</ci><ci id="S5.SS2.p2.2.m2.1.1.3.6.cmml" xref="S5.SS2.p2.2.m2.1.1.3.6">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">L_{align}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>), and for just <math alttext="L_{align}" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><msub id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml"><mi id="S5.SS2.p2.3.m3.1.1.2" xref="S5.SS2.p2.3.m3.1.1.2.cmml">L</mi><mrow id="S5.SS2.p2.3.m3.1.1.3" xref="S5.SS2.p2.3.m3.1.1.3.cmml"><mi id="S5.SS2.p2.3.m3.1.1.3.2" xref="S5.SS2.p2.3.m3.1.1.3.2.cmml">a</mi><mo id="S5.SS2.p2.3.m3.1.1.3.1" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.3.m3.1.1.3.3" xref="S5.SS2.p2.3.m3.1.1.3.3.cmml">l</mi><mo id="S5.SS2.p2.3.m3.1.1.3.1a" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.3.m3.1.1.3.4" xref="S5.SS2.p2.3.m3.1.1.3.4.cmml">i</mi><mo id="S5.SS2.p2.3.m3.1.1.3.1b" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.3.m3.1.1.3.5" xref="S5.SS2.p2.3.m3.1.1.3.5.cmml">g</mi><mo id="S5.SS2.p2.3.m3.1.1.3.1c" xref="S5.SS2.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.3.m3.1.1.3.6" xref="S5.SS2.p2.3.m3.1.1.3.6.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><apply id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.3.m3.1.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.p2.3.m3.1.1.2.cmml" xref="S5.SS2.p2.3.m3.1.1.2">ğ¿</ci><apply id="S5.SS2.p2.3.m3.1.1.3.cmml" xref="S5.SS2.p2.3.m3.1.1.3"><times id="S5.SS2.p2.3.m3.1.1.3.1.cmml" xref="S5.SS2.p2.3.m3.1.1.3.1"></times><ci id="S5.SS2.p2.3.m3.1.1.3.2.cmml" xref="S5.SS2.p2.3.m3.1.1.3.2">ğ‘</ci><ci id="S5.SS2.p2.3.m3.1.1.3.3.cmml" xref="S5.SS2.p2.3.m3.1.1.3.3">ğ‘™</ci><ci id="S5.SS2.p2.3.m3.1.1.3.4.cmml" xref="S5.SS2.p2.3.m3.1.1.3.4">ğ‘–</ci><ci id="S5.SS2.p2.3.m3.1.1.3.5.cmml" xref="S5.SS2.p2.3.m3.1.1.3.5">ğ‘”</ci><ci id="S5.SS2.p2.3.m3.1.1.3.6.cmml" xref="S5.SS2.p2.3.m3.1.1.3.6">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">L_{align}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>. We see the model effectively optimize for <math alttext="L_{align}" class="ltx_Math" display="inline" id="S5.SS2.p2.4.m4.1"><semantics id="S5.SS2.p2.4.m4.1a"><msub id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml"><mi id="S5.SS2.p2.4.m4.1.1.2" xref="S5.SS2.p2.4.m4.1.1.2.cmml">L</mi><mrow id="S5.SS2.p2.4.m4.1.1.3" xref="S5.SS2.p2.4.m4.1.1.3.cmml"><mi id="S5.SS2.p2.4.m4.1.1.3.2" xref="S5.SS2.p2.4.m4.1.1.3.2.cmml">a</mi><mo id="S5.SS2.p2.4.m4.1.1.3.1" xref="S5.SS2.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.4.m4.1.1.3.3" xref="S5.SS2.p2.4.m4.1.1.3.3.cmml">l</mi><mo id="S5.SS2.p2.4.m4.1.1.3.1a" xref="S5.SS2.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.4.m4.1.1.3.4" xref="S5.SS2.p2.4.m4.1.1.3.4.cmml">i</mi><mo id="S5.SS2.p2.4.m4.1.1.3.1b" xref="S5.SS2.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.4.m4.1.1.3.5" xref="S5.SS2.p2.4.m4.1.1.3.5.cmml">g</mi><mo id="S5.SS2.p2.4.m4.1.1.3.1c" xref="S5.SS2.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S5.SS2.p2.4.m4.1.1.3.6" xref="S5.SS2.p2.4.m4.1.1.3.6.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><apply id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.4.m4.1.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p2.4.m4.1.1.2.cmml" xref="S5.SS2.p2.4.m4.1.1.2">ğ¿</ci><apply id="S5.SS2.p2.4.m4.1.1.3.cmml" xref="S5.SS2.p2.4.m4.1.1.3"><times id="S5.SS2.p2.4.m4.1.1.3.1.cmml" xref="S5.SS2.p2.4.m4.1.1.3.1"></times><ci id="S5.SS2.p2.4.m4.1.1.3.2.cmml" xref="S5.SS2.p2.4.m4.1.1.3.2">ğ‘</ci><ci id="S5.SS2.p2.4.m4.1.1.3.3.cmml" xref="S5.SS2.p2.4.m4.1.1.3.3">ğ‘™</ci><ci id="S5.SS2.p2.4.m4.1.1.3.4.cmml" xref="S5.SS2.p2.4.m4.1.1.3.4">ğ‘–</ci><ci id="S5.SS2.p2.4.m4.1.1.3.5.cmml" xref="S5.SS2.p2.4.m4.1.1.3.5">ğ‘”</ci><ci id="S5.SS2.p2.4.m4.1.1.3.6.cmml" xref="S5.SS2.p2.4.m4.1.1.3.6">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">L_{align}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.4.m4.1d">italic_L start_POSTSUBSCRIPT italic_a italic_l italic_i italic_g italic_n end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="278" id="S5.F7.g1" src="extracted/5893087/imgs/Generations.png" width="522"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S5.F7.3.2" style="font-size:90%;">Example generations of the feature-aligned diffusion model.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Evaluation Method</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We generate 10 synthetic images per class of tissue, excluding the â€œemptyâ€ class (since it contains no tissue). We use the expert ResNet50 model to classify the generated images and report the resultant accuracy. We compare performances of the baseline diffusion model (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S3" title="III Diffusion â€“ Preliminaries â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">III</span></a>) against the feature-aligned diffusion model (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S4" title="IV Feature-Aligned Diffusion â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">IV</span></a>) for the two pipelines most commonly used in medical image synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib4" title="">4</a>]</cite>: a) typical/vanilla fine-tuning, and b) DreamBooth fine-tuning for one class of images (we use the â€œTumorâ€ class). When comparing the models, we fix the random seeds used for generation to ensure a fair comparison of the model outputs. We note average performance of the models across 15 seeds.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">Results</span>
</h3>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS4.SSS1.5.1.1">V-D</span>1 </span>Quantitative Results</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S4.T1" title="TABLE I â€£ IV Feature-Aligned Diffusion â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">I</span></a>, we first compare how feature-aligned diffusion performs when the intermediate features are aligned to: a) expert features computed on the noise-free original training samples, and b) expert features computed on the noise-added training samples. We see a significant improvement when computing expert features on the noise-added inputs, making this the de-facto choice for our approach. We attribute this to the latent space of the downsampling block encoding information on the noisy image, as opposed to the noise-free image. That is, output at that stage will still contain the noise, before it is denoised through the upsampling path.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS1.p2">
<p class="ltx_p" id="S5.SS4.SSS1.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F4" title="Figure 4 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">4</span></a> compares the expert classification accuracy on the synthetically generated images, between the baseline diffusion model and the feature-aligned diffusion model across different seeds, for the two fine-tuning pipelines. The expert model serves as a â€œproxyâ€ for whether the generated images contain the features necessary to distinguish the respective classes. The dotted green line in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F4" title="Figure 4 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">4</span></a> shows the mean generation accuracy. <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.SS4.SSS1.p2.1.2">Feature-aligned diffusion <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p2.1.2.1">consistently</span> outperforms the baseline diffusion approach</span><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS1.p2.1.1"> (by <math alttext="9\%" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.1.1.m1.1"><semantics id="S5.SS4.SSS1.p2.1.1.m1.1a"><mrow id="S5.SS4.SSS1.p2.1.1.m1.1.1" xref="S5.SS4.SSS1.p2.1.1.m1.1.1.cmml"><mn id="S5.SS4.SSS1.p2.1.1.m1.1.1.2" xref="S5.SS4.SSS1.p2.1.1.m1.1.1.2.cmml">9</mn><mo id="S5.SS4.SSS1.p2.1.1.m1.1.1.1" xref="S5.SS4.SSS1.p2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.1.1.m1.1b"><apply id="S5.SS4.SSS1.p2.1.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS4.SSS1.p2.1.1.m1.1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS4.SSS1.p2.1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS4.SSS1.p2.1.1.m1.1.1.2">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.1.1.m1.1c">9\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.SSS1.p2.1.1.m1.1d">9 %</annotation></semantics></math> on average, across all seed settings). Feature-aligned diffusion improves model performances both with typical/vanilla fine-tuning and fine-tuning with DreamBooth, highlighting its <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS4.SSS1.p2.1.1.1">synergistic potential with existing pipelines</span></span>.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS1.p3">
<p class="ltx_p" id="S5.SS4.SSS1.p3.1">For individual classes, we show the confusion matrices of the expert predictions on synthetic generations of the feature-aligned and baseline diffusion in Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf1" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf2" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(b)</span></a>. We compare this to the confusion matrix of the expert model predictions on the original data in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf3" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(c)</span></a>. With synthetic generations, we see that the expert model tends to mis-classify â€œtumorâ€, â€œstromaâ€ and â€œlymphoâ€ classes as â€œdebrisâ€. We see several more â€œdebrisâ€ mis-classifications with the baseline diffusion. However, in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf3" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(c)</span></a> we see that similar mis-classifications rarely occur on the original dataset. This implies that the diffusion model likely introduces specific artefacts that cause mis-classifications into the â€œdebrisâ€ category. Such â€œhallucinationsâ€ occur in the context of diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib17" title="">17</a>]</cite>, possibly related to the high intra-class variability of debris images.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS1.p4">
<p class="ltx_p" id="S5.SS4.SSS1.p4.1">For quantitatively measuring sample diversity, we follow prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#bib.bib4" title="">4</a>]</cite> and measure SSIM (Structural Similarity Index Measure) which is used to assess the generation diversity of generative models. We compute SSIM between the generated synthetic images to measure the similarity between the generations â€“ <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p4.1.1">lower</span> the SSIM, the <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p4.1.2">better</span> the generation diversity. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F6" title="Figure 6 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">6</span></a> shows the SSIM values for the baseline and feature-aligned diffusion models for each class, and the overall averaged SSIM values across all classes. We see that <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.SS4.SSS1.p4.1.3">feature-aligned diffusion generations have better overall sample diversity compared to the baseline approach</span>. In some cases the SSIM of feature-aligned diffusion is close to the original dataset indicating similar diversity as the original data. While there are a few classes where the baseline diffusion has a slightly lower SSIM, we note that <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p4.1.4">SSIM alone does not imply â€œaccurateâ€ generations</span>. For instance, while baseline diffusion has a slightly lower SSIM for the â€œmucosaâ€ class than feature-aligned diffusion, the corresponding classification accuracy is poor (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf2" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(b)</span></a>) when compared to the feature-aligned model (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F5.sf1" title="In Figure 5 â€£ V-A Choice of Expert Model â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) . Hence, putting the SSIM metric alongside the classification accuracy, shows that feature-aligned diffusion clearly outperforms the baseline diffusion approach.</p>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="334" id="S5.F8.g1" src="extracted/5893087/imgs/baseline_gen.png" width="234"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S5.F8.3.2" style="font-size:90%;">Example generations of baseline diffusion.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S5.SS4.SSS2.5.1.1">V-D</span>2 </span>Qualitative Results</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">Synthetic generations of the feature-aligned diffusion model are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F7" title="Figure 7 â€£ V-B Diffusion Fine-tuning Hyper-parameters â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">7</span></a>. We see similarities between the synthetic generations, and images sampled from the original dataset. Some classes like â€œdebrisâ€ exhibit higher intra-class variability in the images, whereas classes like â€œadiposeâ€ and â€œmucosaâ€ show much less variability. Visually comparing the â€œtumorâ€ and â€œstromaâ€ class generations, we see that some properties of the generated images align with visual features of the â€œdebrisâ€ class, possibly reinforcing the confusion matrix observations.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS2.p2">
<p class="ltx_p" id="S5.SS4.SSS2.p2.1">The synthetic generations of the baseline diffusion model is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F8" title="Figure 8 â€£ V-D1 Quantitative Results â€£ V-D Results â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">8</span></a>. Comparing Figures <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F7" title="Figure 7 â€£ V-B Diffusion Fine-tuning Hyper-parameters â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.00731v1#S5.F8" title="Figure 8 â€£ V-D1 Quantitative Results â€£ V-D Results â€£ V Experiments â€£ Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion"><span class="ltx_text ltx_ref_tag">8</span></a>, we see that particularly for certain classes like â€œtumorâ€, â€œcomplexâ€, â€œdebrisâ€, and â€œmucosaâ€, the synthetic generations of the baseline model are visually quite different from the original dataset. <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.SS4.SSS2.p2.1.1">Qualitatively, we see that the synthetic generations of the feature-aligned diffusion model match the original dataset more closely than the baseline diffusion model</span>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Limitations and Future Work</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.2">We explored feature-aligned diffusion, that is easily integrated into existing diffusion pipelines to improve synthetic generations. Our future work seeks to improve sample diversity further across all the classes for feature-aligned diffusion, through studying the influence of <math alttext="w_{1}" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><msub id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mi id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">w</mi><mn id="S6.p1.1.m1.1.1.3" xref="S6.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1">subscript</csymbol><ci id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">ğ‘¤</ci><cn id="S6.p1.1.m1.1.1.3.cmml" type="integer" xref="S6.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">w_{1}</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="w_{2}" class="ltx_Math" display="inline" id="S6.p1.2.m2.1"><semantics id="S6.p1.2.m2.1a"><msub id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml"><mi id="S6.p1.2.m2.1.1.2" xref="S6.p1.2.m2.1.1.2.cmml">w</mi><mn id="S6.p1.2.m2.1.1.3" xref="S6.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><apply id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S6.p1.2.m2.1.1.1.cmml" xref="S6.p1.2.m2.1.1">subscript</csymbol><ci id="S6.p1.2.m2.1.1.2.cmml" xref="S6.p1.2.m2.1.1.2">ğ‘¤</ci><cn id="S6.p1.2.m2.1.1.3.cmml" type="integer" xref="S6.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">w_{2}</annotation><annotation encoding="application/x-llamapun" id="S6.p1.2.m2.1d">italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> in the loss terms. We will expand to additional datasets and explore the use of the synthetic data to improve the expert, alongside a deeper investigation of the source of the â€œdebrisâ€ mis-classifications.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS1.5.1.1">VI-A</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS1.6.2">Potential Applications to Other Domains</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Although we discuss feature-aligned diffusion specifically in the context of medical image synthesis, the approach may be applicable to other image synthesis domains, e.g., natural images (CIFAR10/100, ImageNet). The benefit of our approach may be more evident in cases where finer details need to be captured well in the synthetic generations (e.g., shapes of cells), and our future work seeks to quantitatively evaluate this hypothesis with feature-aligned diffusion for other domains.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J.Â Abramson, J.Â Adler, J.Â Dunger, R.Â Evans, T.Â Green, A.Â Pritzel, O.Â Ronneberger, L.Â Willmore, A.Â J. Ballard, J.Â Bambrick <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">etÂ al.</em>, â€œAccurate structure prediction of biomolecular interactions with alphafold 3,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib1.2.2">Nature</em>, pp. 1â€“3, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H.Â Cui, C.Â Wang, H.Â Maan, K.Â Pang, F.Â Luo, N.Â Duan, and B.Â Wang, â€œscgpt: toward building a foundation model for single-cell multi-omics using generative ai,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Nature Methods</em>, pp. 1â€“11, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M.Â GiuffrÃ¨ and D.Â L. Shung, â€œHarnessing the power of synthetic data in healthcare: innovation, application, and privacy,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">NPJ digital medicine</em>, vol.Â 6, no.Â 1, p. 186, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
R.Â Montoya-del Angel, K.Â Sam-Millan, J.Â C. Vilanova, and R.Â MartÃ­, â€œMam-e: Mammographic synthetic image generation with diffusion models,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Sensors</em>, vol.Â 24, no.Â 7, p. 2076, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B.Â L. Kidder, â€œAdvanced image generation for cancer using diffusion models,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">bioRxiv</em>, pp. 2023â€“08, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
N.Â Ruiz, Y.Â Li, V.Â Jampani, Y.Â Pritch, M.Â Rubinstein, and K.Â Aberman, â€œDreambooth: Fine tuning text-to-image diffusion models for subject-driven generation,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2023, pp. 22â€‰500â€“22â€‰510.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M.Â A. Farooq, W.Â Yao, M.Â Schukat, M.Â A. Little, and P.Â Corcoran, â€œDerm-t2im: Harnessing synthetic skin lesion data via stable diffusion models for enhanced skin disease classification using vit and cnn,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2401.05159</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
F.Â Khader, G.Â MÃ¼ller-Franzes, S.Â TayebiÂ Arasteh, T.Â Han, C.Â Haarburger, M.Â Schulze-Hagen, P.Â Schad, S.Â Engelhardt, B.Â BaeÃŸler, S.Â Foersch <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">etÂ al.</em>, â€œDenoising diffusion probabilistic models for 3d medical image generation,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2">Scientific Reports</em>, vol.Â 13, no.Â 1, p. 7303, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
K.Â Ding, M.Â Zhou, H.Â Wang, O.Â Gevaert, D.Â Metaxas, and S.Â Zhang, â€œA large-scale synthetic pathological dataset for deep learning-enabled segmentation of breast cancer,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Scientific Data</em>, vol.Â 10, no.Â 1, p. 231, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A.Â Kazerouni, E.Â K. Aghdam, M.Â Heidari, R.Â Azad, M.Â Fayyaz, I.Â Hacihaliloglu, and D.Â Merhof, â€œDiffusion models in medical imaging: A comprehensive survey,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Medical Image Analysis</em>, vol.Â 88, p. 102846, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J.Â Ho, A.Â Jain, and P.Â Abbeel, â€œDenoising diffusion probabilistic models,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in neural information processing systems</em>, vol.Â 33, pp. 6840â€“6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
R.Â Rombach, A.Â Blattmann, D.Â Lorenz, P.Â Esser, and B.Â Ommer, â€œHigh-resolution image synthesis with latent diffusion models, 2021,â€ 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun, â€œDeep residual learning for image recognition. arxiv e-prints,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:1512.03385</em>, vol.Â 10, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A.Â Gambashidze, A.Â Kulikov, Y.Â Sosnin, and I.Â Makarov, â€œAligning diffusion models with noise-conditioned perception,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2406.17636</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J.Â N. Kather, C.-A. Weis, F.Â Bianconi, S.Â M. Melchers, L.Â R. Schad, T.Â Gaiser, A.Â Marx, and F.Â G. ZÃ¶llner, â€œMulti-class texture analysis in colorectal cancer histology,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Scientific reports</em>, vol.Â 6, no.Â 1, pp. 1â€“11, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A.Â Dosovitskiy, L.Â Beyer, A.Â Kolesnikov, D.Â Weissenborn, X.Â Zhai, T.Â Unterthiner, M.Â Dehghani, M.Â Minderer, G.Â Heigold, S.Â Gelly <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">etÂ al.</em>, â€œAn image is worth 16x16 words: Transformers for image recognition at scale,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2">arXiv preprint arXiv:2010.11929</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S.Â K. Aithal, P.Â Maini, Z.Â C. Lipton, and J.Â Z. Kolter, â€œUnderstanding hallucinations in diffusion models through mode interpolation,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2406.09358</em>, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  1 14:11:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
