<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2012.12401] Turn Signal Prediction: A Federated Learning Case Study</title><meta property="og:description" content="Driving etiquette takes a different flavor for each locality as drivers not only comply with rules/laws but also abide by local unspoken convention. When to have the turn signal (indicator) on/off is one such etiquette…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Turn Signal Prediction: A Federated Learning Case Study">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Turn Signal Prediction: A Federated Learning Case Study">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2012.12401">

<!--Generated on Fri Mar  1 13:31:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Turn Signal Prediction: A Federated Learning Case Study</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sonal Doomra 
<br class="ltx_break">Ford Motor Company
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">sdoomra@ford.com</span> 
<br class="ltx_break">Naman Kohli 
<br class="ltx_break">Ford Motor Company 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">nkohli2@ford.com</span> 
<br class="ltx_break">Shounak Athavale 
<br class="ltx_break">Ford Motor Company 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">sathaval@ford.com</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Driving etiquette takes a different flavor for each locality as drivers not only comply with rules/laws but also abide by local unspoken convention. When to have the turn signal (indicator) on/off is one such etiquette which does not have a definitive right or wrong answer. Learning this behavior from the abundance of data generated from various sensor modalities integrated in the vehicle is a suitable candidate for deep learning. But what makes it a prime candidate for Federated Learning are privacy concerns and bandwidth limitations for any data aggregation. This paper presents a long short-term memory (LSTM) based Turn Signal Prediction (on or off) model using vehicle control area network (CAN) signal data. The model is trained using two approaches, one by centrally aggregating the data and the other in a federated manner. Centrally trained models and federated models are compared under similar hyperparameter settings. This research demonstrates the efficacy of federated learning, paving the way for in-vehicle learning of driving etiquette.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Neural networks have been used in engine controls for over twenty years but recently deep neural networks (DNNs) have found varied applications both in the enterprise and transportation mobility services <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Current work of automotive related deep learning work is focused on leveraging sensor data produced by vehicles <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Vehicle sensors data is streamed via control area network (CAN) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> at speeds ranging from 1Gbit/s to 40GBit/s. To aggregate this data in a data center is challenging due to limited bandwidth, high latency and data breach risks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Therefore, it has led to the need for machine learning methods that are not only efficient in a large-scale industrial deployment but are also privacy-sustaining.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turn1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="409" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turn2.png" id="S1.F1.2.g1" class="ltx_graphics ltx_img_landscape" width="586" height="325" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/lane1.png" id="S1.F1.3.g1" class="ltx_graphics ltx_img_landscape" width="586" height="444" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.6.2" class="ltx_text" style="font-size:90%;">Vehicle turns/lane changes (from A to B) prompting the off-on-off turn signal sequence</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated Learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> is a variant of distributed machine learning algorithms where edge devices train individual AI models and share model parameters with the server instead of their data. Model parameters from edge devices are averaged to generate the global federated model that is redeployed back to the edge devices <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. This back and forth of model communications ensures privacy as data never leaves the device and drastically lowers the communication bandwidth.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, Federated Learning is utilized to simulate an “in-vehicle” use case for predicting driver behavior at the next time-step. Recommending drivers to switch on/off their turn indicator while driving is an application that would benefit by learning from a large number of drivers but at the same time faces the practical issues related to data transfer. Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> displays some of the cases when turn signal indicator needs to be switched on when a vehicle is either making a turn (left or right) or changing lanes. The predictive model developed in this work can be used to alert the driver to turn on or off left/right indicator at an appropriate time.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Problem Description and Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Turn signal indication does not have a precise answer to when it should be turned on or off. Individual driving styles and forgetting to turn indicator on/off can catch other drivers off-guard. A study by Society of Automotive Engineers published in 2012 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> showed that in the US alone, 48% drivers do not use turn signals while changing lanes and 25% while turning vehicles. Consequently, as much as 2 million car crashes are estimated to occur due to the neglected use of turn signals. Thus, a smart turn signal indicator in vehicles could help avoid them and enforce the right driving etiquette. Moreover, there are many different situations when the turn signal needs to be switched on, such as, when a driver is making a complete turn, changing lanes, or making a U turn. For instance, Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Problem Description and Related Work ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> showcases the values of different CAN data signals as a vehicle is making a complete left turn. The regularities in CAN signals’ patterns can be learned to predict future turn indicator status.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turn4.png" id="S2.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="440" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turnsignal.png" id="S2.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="586" height="426" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/steeringsignal.png" id="S2.F2.3.g1" class="ltx_graphics ltx_img_landscape" width="586" height="451" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/vehiclespeed.png" id="S2.F2.4.g1" class="ltx_graphics ltx_img_landscape" width="586" height="451" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/accelerator.png" id="S2.F2.5.g1" class="ltx_graphics ltx_img_landscape" width="586" height="471" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/brakestatus.png" id="S2.F2.6.g1" class="ltx_graphics ltx_img_landscape" width="586" height="440" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.8.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.9.2" class="ltx_text" style="font-size:90%;">As the vehicle is about to make a left turn (A-B), the driver indicates their intent of turning left by turning on the indicator. The plots depict change in signal value patterns as the vehicle makes the left turn.</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Since there is no right or wrong answer when it comes to turn signal timing, Federated Learning can help to learn a global behavior from drivers from different regions or countries while localizing it to adapt to local driving norms. Another important consideration for this task is that the data from vehicle’s CAN bus like GPS coordinates is PII (Personally Identifiable Information) data and must be dealt with appropriately. Federated Learning gives an instant advantage of data privacy by ensuring that raw data never leaves the device (i.e. vehicles) it is stored on.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Federated Learning was first introduced in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> by Google where they focused on building a distributed machine learning model that doesn’t leak data. Since then, a number of research papers have focused on improving the statistical challenges <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> associated with training a global model, and improving the security aspect of the communication round <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Federated Learning has been shown to converge in practical situations and has been used in multiple real-world applications like Google Swipe <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. There have also been efforts to utilize federated learning in personalization task <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Federated learning has also been used in transfer learning where authors in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> utilized feature transfer learning for secure training. In this work, we evaluate if Federated Learning can be utilized for converging machine learning models for turn signal prediction.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The prediction task is designed as a classification task, where the turn signal status is determined at the next time step, given the multi-input signals collected at previous time steps. The data utilized in this research is a subset of data stored in Ford’s Big Data Drive (BDD) dataset. This work utilizes tensorflow-federated <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which is an open source framework for research and experimentation with Federated Learning.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Preprocessing</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">This problem is formulated as a multi variate time series forecasting problem, where each signal from the CAN bus represents a time series. Multiple CAN signals were identified as useful features for predicting the turn signal status at a given time, such as Steering Wheel Angle (in degrees), Vehicle Speed (in kph), Turn Signal Status (serves as label for next time step), Accelerator Pedal Position, Brake Status, GPS coordinates, and Vehicle Direction (in degrees). Since the driver switches on the turn status only in specific situations, trips with turn signal status sequence off-on-off needs to be extracted for training &amp; test data sets.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The raw signal data collected in the BDD are recorded at different sampling frequencies. This required a few pre-processing steps before transforming those signals into useful features for the deep learning model. To begin with, all signal frequencies were sampled to one second (or 1Hz), missing values for continuous variables were linearly interpolated and missing categorical values were set to the last known value. The pre-processing steps were performed for each vehicle individually. Only the trips with continuous timestamps were included in the final data set. Every trip consisted of 40 seconds of data before the turn signal was on (for look-back) and 10 seconds of data after it was turned off.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turndist1.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="351" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/turndist2.png" id="S3.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="586" height="261" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.5.2" class="ltx_text" style="font-size:90%;">Distribution of Turn Signal Indicators data in training set</span></figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">With the above preprocessing steps, the dataset was successfully prepared with 66 distinct vehicles. Our final train dataset has about 8M training data points and 700K data points in the test set. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Data Preprocessing ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows data distribution for turn signal status in our final training dataset. It can be inferred from Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Data Preprocessing ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> that the turn signal indicator is on for about the same number of times as it is off. However, since the BDD data lake consists of vehicles primarily from USA where right turn is mostly free, right indicator is on for a smaller number of times than the left indicator. This distribution is maintained in the test dataset as well. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Data Preprocessing ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> also shows a distribution of duration for how long the turn signal status is ON. Interestingly, majority of the turn signal duration is in the range of 0-100 seconds. There are certain cases when the duration is significantly less which could correspond to lane changes/quick turns and certain cases when the duration is significantly high which could indicate vehicle at traffic light or driver forgot to turn signal off.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2012.12401/assets/images/lstm.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">LSTM model architecture for turn signal prediction task. The output layer of the fully connected network has three states, each corresponding to left, right or off state of the turn signal.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Architecture</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">A multi-variate Long Short-term memory (LSTM) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> network is chosen as the model architecture for modeling the Turn Signal prediction problem because of the temporal nature of the data as shown in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.1 Data Preprocessing ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The input to the LSTM network is a multi-step time series of multiple features (Steering wheel angle, vehicle speed, etc.). The output is a 3-dimensional vector, each of which corresponds to the state of turn signal indicator value at the future time step (t+1). The output layer is followed by a softmax activation function to get the final prediction.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Design of Experiments</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To understand the performance of federated learning, the results from two sets of experiments were compared – one on centralized data training and the other on federated data training, using the design setup shown in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.3 Design of Experiments ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. For centralized training, data from each vehicle is divided to form training, validation and test datasets such that there is no overlap in each of these datasets. For federated training, data from each vehicle is used to simulate a client. Aggregation at the server is performed using FedAvg algorithm as introduced in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. F1-score and test accuracy are used as evaluation metrics for both set of experiments. The hyperparameters chosen for federated learning models are a subset of the ones used for centralized training as shown in Table <a href="#S3.T1" title="Table 1 ‣ 3.3 Design of Experiments ‣ 3 Methodology ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Adam is used as the optimizer in both sets of experiments.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2012.12401/assets/images/doe.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">For centralized training, data from each client is stored in the train and test set. For federated training, each vehicle is treated as a client and each local LSTM model is trained using local data. The client models are federated at the server to form a global model. Clients are randomly chosen for participation during the training step every round. (red x represents the vehicles not participating in that individual round, but eventually all will participate via multiple rounds)</span></figcaption>
</figure>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.8.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.9.2" class="ltx_text" style="font-size:90%;">Hyperparameters utilized for training LSTM model for turn signal prediction</span></figcaption>
<table id="S3.T1.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.6.7.1" class="ltx_tr">
<th id="S3.T1.6.7.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S3.T1.6.7.1.2" class="ltx_td ltx_align_center ltx_border_tt">Central</td>
<td id="S3.T1.6.7.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">Federated</td>
</tr>
<tr id="S3.T1.6.8.2" class="ltx_tr">
<th id="S3.T1.6.8.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Batch Size</th>
<td id="S3.T1.6.8.2.2" class="ltx_td ltx_align_center ltx_border_t">64, 128, 256</td>
<td id="S3.T1.6.8.2.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">64, 128</td>
</tr>
<tr id="S3.T1.6.9.3" class="ltx_tr">
<th id="S3.T1.6.9.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Window (time steps)</th>
<td id="S3.T1.6.9.3.2" class="ltx_td ltx_align_center">5, 10, 15, 20, 30, 40</td>
<td id="S3.T1.6.9.3.3" class="ltx_td ltx_nopad_r ltx_align_center">5</td>
</tr>
<tr id="S3.T1.6.10.4" class="ltx_tr">
<th id="S3.T1.6.10.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Hidden Units</th>
<td id="S3.T1.6.10.4.2" class="ltx_td ltx_align_center">50, 100, 150</td>
<td id="S3.T1.6.10.4.3" class="ltx_td ltx_nopad_r ltx_align_center">50</td>
</tr>
<tr id="S3.T1.6.6" class="ltx_tr">
<th id="S3.T1.6.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row">Learning Rate</th>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center">
<math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="1\mathrm{e}{-3}" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml"><mrow id="S3.T1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.m1.1.1.2.cmml"><mn id="S3.T1.1.1.1.m1.1.1.2.2" xref="S3.T1.1.1.1.m1.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.1.1.1.m1.1.1.2.1" xref="S3.T1.1.1.1.m1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.1.1.1.m1.1.1.2.3" xref="S3.T1.1.1.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.1.1.1.m1.1.1.1" xref="S3.T1.1.1.1.m1.1.1.1.cmml">−</mo><mn id="S3.T1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1"><minus id="S3.T1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1.1"></minus><apply id="S3.T1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2"><times id="S3.T1.1.1.1.m1.1.1.2.1.cmml" xref="S3.T1.1.1.1.m1.1.1.2.1"></times><cn type="integer" id="S3.T1.1.1.1.m1.1.1.2.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2.2">1</cn><ci id="S3.T1.1.1.1.m1.1.1.2.3.cmml" xref="S3.T1.1.1.1.m1.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">1\mathrm{e}{-3}</annotation></semantics></math>,<math id="S3.T1.2.2.2.m2.1" class="ltx_Math" alttext="1\mathrm{e}{-4}" display="inline"><semantics id="S3.T1.2.2.2.m2.1a"><mrow id="S3.T1.2.2.2.m2.1.1" xref="S3.T1.2.2.2.m2.1.1.cmml"><mrow id="S3.T1.2.2.2.m2.1.1.2" xref="S3.T1.2.2.2.m2.1.1.2.cmml"><mn id="S3.T1.2.2.2.m2.1.1.2.2" xref="S3.T1.2.2.2.m2.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.2.2.2.m2.1.1.2.1" xref="S3.T1.2.2.2.m2.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.2.2.2.m2.1.1.2.3" xref="S3.T1.2.2.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.2.2.2.m2.1.1.1" xref="S3.T1.2.2.2.m2.1.1.1.cmml">−</mo><mn id="S3.T1.2.2.2.m2.1.1.3" xref="S3.T1.2.2.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m2.1b"><apply id="S3.T1.2.2.2.m2.1.1.cmml" xref="S3.T1.2.2.2.m2.1.1"><minus id="S3.T1.2.2.2.m2.1.1.1.cmml" xref="S3.T1.2.2.2.m2.1.1.1"></minus><apply id="S3.T1.2.2.2.m2.1.1.2.cmml" xref="S3.T1.2.2.2.m2.1.1.2"><times id="S3.T1.2.2.2.m2.1.1.2.1.cmml" xref="S3.T1.2.2.2.m2.1.1.2.1"></times><cn type="integer" id="S3.T1.2.2.2.m2.1.1.2.2.cmml" xref="S3.T1.2.2.2.m2.1.1.2.2">1</cn><ci id="S3.T1.2.2.2.m2.1.1.2.3.cmml" xref="S3.T1.2.2.2.m2.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.2.2.2.m2.1.1.3.cmml" xref="S3.T1.2.2.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m2.1c">1\mathrm{e}{-4}</annotation></semantics></math>,<math id="S3.T1.3.3.3.m3.1" class="ltx_Math" alttext="1\mathrm{e}{-5}" display="inline"><semantics id="S3.T1.3.3.3.m3.1a"><mrow id="S3.T1.3.3.3.m3.1.1" xref="S3.T1.3.3.3.m3.1.1.cmml"><mrow id="S3.T1.3.3.3.m3.1.1.2" xref="S3.T1.3.3.3.m3.1.1.2.cmml"><mn id="S3.T1.3.3.3.m3.1.1.2.2" xref="S3.T1.3.3.3.m3.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.3.3.3.m3.1.1.2.1" xref="S3.T1.3.3.3.m3.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.3.3.3.m3.1.1.2.3" xref="S3.T1.3.3.3.m3.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.3.3.3.m3.1.1.1" xref="S3.T1.3.3.3.m3.1.1.1.cmml">−</mo><mn id="S3.T1.3.3.3.m3.1.1.3" xref="S3.T1.3.3.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m3.1b"><apply id="S3.T1.3.3.3.m3.1.1.cmml" xref="S3.T1.3.3.3.m3.1.1"><minus id="S3.T1.3.3.3.m3.1.1.1.cmml" xref="S3.T1.3.3.3.m3.1.1.1"></minus><apply id="S3.T1.3.3.3.m3.1.1.2.cmml" xref="S3.T1.3.3.3.m3.1.1.2"><times id="S3.T1.3.3.3.m3.1.1.2.1.cmml" xref="S3.T1.3.3.3.m3.1.1.2.1"></times><cn type="integer" id="S3.T1.3.3.3.m3.1.1.2.2.cmml" xref="S3.T1.3.3.3.m3.1.1.2.2">1</cn><ci id="S3.T1.3.3.3.m3.1.1.2.3.cmml" xref="S3.T1.3.3.3.m3.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.3.3.3.m3.1.1.3.cmml" xref="S3.T1.3.3.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m3.1c">1\mathrm{e}{-5}</annotation></semantics></math>
</td>
<td id="S3.T1.6.6.6" class="ltx_td ltx_nopad_r ltx_align_center">
<math id="S3.T1.4.4.4.m1.1" class="ltx_Math" alttext="1\mathrm{e}{-3}" display="inline"><semantics id="S3.T1.4.4.4.m1.1a"><mrow id="S3.T1.4.4.4.m1.1.1" xref="S3.T1.4.4.4.m1.1.1.cmml"><mrow id="S3.T1.4.4.4.m1.1.1.2" xref="S3.T1.4.4.4.m1.1.1.2.cmml"><mn id="S3.T1.4.4.4.m1.1.1.2.2" xref="S3.T1.4.4.4.m1.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.4.4.4.m1.1.1.2.1" xref="S3.T1.4.4.4.m1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.4.4.4.m1.1.1.2.3" xref="S3.T1.4.4.4.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.4.4.4.m1.1.1.1" xref="S3.T1.4.4.4.m1.1.1.1.cmml">−</mo><mn id="S3.T1.4.4.4.m1.1.1.3" xref="S3.T1.4.4.4.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.m1.1b"><apply id="S3.T1.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.m1.1.1"><minus id="S3.T1.4.4.4.m1.1.1.1.cmml" xref="S3.T1.4.4.4.m1.1.1.1"></minus><apply id="S3.T1.4.4.4.m1.1.1.2.cmml" xref="S3.T1.4.4.4.m1.1.1.2"><times id="S3.T1.4.4.4.m1.1.1.2.1.cmml" xref="S3.T1.4.4.4.m1.1.1.2.1"></times><cn type="integer" id="S3.T1.4.4.4.m1.1.1.2.2.cmml" xref="S3.T1.4.4.4.m1.1.1.2.2">1</cn><ci id="S3.T1.4.4.4.m1.1.1.2.3.cmml" xref="S3.T1.4.4.4.m1.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.4.4.4.m1.1.1.3.cmml" xref="S3.T1.4.4.4.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.m1.1c">1\mathrm{e}{-3}</annotation></semantics></math>, <math id="S3.T1.5.5.5.m2.1" class="ltx_Math" alttext="1\mathrm{e}{-4}" display="inline"><semantics id="S3.T1.5.5.5.m2.1a"><mrow id="S3.T1.5.5.5.m2.1.1" xref="S3.T1.5.5.5.m2.1.1.cmml"><mrow id="S3.T1.5.5.5.m2.1.1.2" xref="S3.T1.5.5.5.m2.1.1.2.cmml"><mn id="S3.T1.5.5.5.m2.1.1.2.2" xref="S3.T1.5.5.5.m2.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.5.5.5.m2.1.1.2.1" xref="S3.T1.5.5.5.m2.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.5.5.5.m2.1.1.2.3" xref="S3.T1.5.5.5.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.5.5.5.m2.1.1.1" xref="S3.T1.5.5.5.m2.1.1.1.cmml">−</mo><mn id="S3.T1.5.5.5.m2.1.1.3" xref="S3.T1.5.5.5.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.m2.1b"><apply id="S3.T1.5.5.5.m2.1.1.cmml" xref="S3.T1.5.5.5.m2.1.1"><minus id="S3.T1.5.5.5.m2.1.1.1.cmml" xref="S3.T1.5.5.5.m2.1.1.1"></minus><apply id="S3.T1.5.5.5.m2.1.1.2.cmml" xref="S3.T1.5.5.5.m2.1.1.2"><times id="S3.T1.5.5.5.m2.1.1.2.1.cmml" xref="S3.T1.5.5.5.m2.1.1.2.1"></times><cn type="integer" id="S3.T1.5.5.5.m2.1.1.2.2.cmml" xref="S3.T1.5.5.5.m2.1.1.2.2">1</cn><ci id="S3.T1.5.5.5.m2.1.1.2.3.cmml" xref="S3.T1.5.5.5.m2.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.5.5.5.m2.1.1.3.cmml" xref="S3.T1.5.5.5.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.m2.1c">1\mathrm{e}{-4}</annotation></semantics></math>, <math id="S3.T1.6.6.6.m3.1" class="ltx_Math" alttext="1\mathrm{e}{-5}" display="inline"><semantics id="S3.T1.6.6.6.m3.1a"><mrow id="S3.T1.6.6.6.m3.1.1" xref="S3.T1.6.6.6.m3.1.1.cmml"><mrow id="S3.T1.6.6.6.m3.1.1.2" xref="S3.T1.6.6.6.m3.1.1.2.cmml"><mn id="S3.T1.6.6.6.m3.1.1.2.2" xref="S3.T1.6.6.6.m3.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.T1.6.6.6.m3.1.1.2.1" xref="S3.T1.6.6.6.m3.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.T1.6.6.6.m3.1.1.2.3" xref="S3.T1.6.6.6.m3.1.1.2.3.cmml">e</mi></mrow><mo id="S3.T1.6.6.6.m3.1.1.1" xref="S3.T1.6.6.6.m3.1.1.1.cmml">−</mo><mn id="S3.T1.6.6.6.m3.1.1.3" xref="S3.T1.6.6.6.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.m3.1b"><apply id="S3.T1.6.6.6.m3.1.1.cmml" xref="S3.T1.6.6.6.m3.1.1"><minus id="S3.T1.6.6.6.m3.1.1.1.cmml" xref="S3.T1.6.6.6.m3.1.1.1"></minus><apply id="S3.T1.6.6.6.m3.1.1.2.cmml" xref="S3.T1.6.6.6.m3.1.1.2"><times id="S3.T1.6.6.6.m3.1.1.2.1.cmml" xref="S3.T1.6.6.6.m3.1.1.2.1"></times><cn type="integer" id="S3.T1.6.6.6.m3.1.1.2.2.cmml" xref="S3.T1.6.6.6.m3.1.1.2.2">1</cn><ci id="S3.T1.6.6.6.m3.1.1.2.3.cmml" xref="S3.T1.6.6.6.m3.1.1.2.3">e</ci></apply><cn type="integer" id="S3.T1.6.6.6.m3.1.1.3.cmml" xref="S3.T1.6.6.6.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.m3.1c">1\mathrm{e}{-5}</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.6.11.5" class="ltx_tr">
<th id="S3.T1.6.11.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Num Clients</th>
<td id="S3.T1.6.11.5.2" class="ltx_td ltx_align_center">N/A</td>
<td id="S3.T1.6.11.5.3" class="ltx_td ltx_nopad_r ltx_align_center">10,25,all</td>
</tr>
<tr id="S3.T1.6.12.6" class="ltx_tr">
<th id="S3.T1.6.12.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Num Rounds</th>
<td id="S3.T1.6.12.6.2" class="ltx_td ltx_align_center">N/A</td>
<td id="S3.T1.6.12.6.3" class="ltx_td ltx_nopad_r ltx_align_center">100</td>
</tr>
<tr id="S3.T1.6.13.7" class="ltx_tr">
<th id="S3.T1.6.13.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Local Epochs</th>
<td id="S3.T1.6.13.7.2" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S3.T1.6.13.7.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">1,5,10</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Analysis</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents empirical results for the experiments described in the previous section. For our purpose, an exhaustive grid search was performed on hyperparameters to find the optimal combination of model hyperparameters that results in most accurate performance on the test dataset. To evaluate our models’ performances, average F1-scores over all prediction classes (right, left and off) and test set accuracy were chosen as evaluation metrics. From the centralized training experiments, it was found that the window size of 5 seconds was best for our application. Figure <a href="#S4.F6" title="Figure 6 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the distribution of test accuracy and average F1-scores of all models for both centralized and federated training experiments across various hyperparameters used in training. The paired t-test on test accuracy and average F1-scores for both central and federated experiments confirm that the distributions are similar. There is no significant difference in the accuracies and average F1-scores of central and federated models. In federated learning, there is more variation in the result distributions because the number of clients participating per round are also varied as a part of hyperparameter tuning. When small number of clients (for instance, only 10) participate every round, the performance of the model measured after 100 communication rounds is lower as compared to when all clients participate every round. This is because the data used for overall training is less.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div id="S4.F6.1" class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" style="width:216.8pt;">
<img src="/html/2012.12401/assets/images/paired_t_test_FL.png" id="S4.F6.1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="426" alt="Refer to caption">
<p id="S4.F6.1.1" class="ltx_p ltx_align_center">(a) Centralized training vs Federated training</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;">Turn Signal Prediction performance across various hyperparameters for both centralized and federated learning</span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">For Federated Learning experiments, window size of 5 seconds is utilized for the client LSTM models as determined from the central training experiments. For Federated Learning experimentation, a subset of hyperparameters from central training experiments are chosen. One important hyperparameter to be considered for Federated Learning is the number of clients participating every round. It simulates the practical scenario where not all clients (vehicles) would be present at the same time for training and communicating their local updates to the server. When 25 or all clients participated in every round, similar high performance is observed for those models. However, when only 10 clients participate every round, the global model accuracy is lower for some combinations of hyperparameters. The best federated model showed similar performance as the best centrally trained model on the same held-out test dataset as shown in Table <a href="#S4.T2" title="Table 2 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It is observed that both the models performed better in predicting the ’Off’ status which is also evident from the classwise F1-score shown in Table <a href="#S4.T2" title="Table 2 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The model accuracy can be improved by adding more turn signals (left and right) in the training dataset.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy and F1 scores of best centrally trained and global federated model</span></figcaption>
<table id="S4.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.1.1" class="ltx_tr">
<th id="S4.T2.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Approach</th>
<th id="S4.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="4">Accuracy(%)</th>
<th id="S4.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="4">F1-Score</th>
</tr>
<tr id="S4.T2.4.2.2" class="ltx_tr">
<th id="S4.T2.4.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"></th>
<th id="S4.T2.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<table id="S4.T2.4.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.4.2.2.2.1.1" class="ltx_tr">
<td id="S4.T2.4.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">Overall</td>
</tr>
<tr id="S4.T2.4.2.2.2.1.2" class="ltx_tr">
<td id="S4.T2.4.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">Weighted</td>
</tr>
</table>
</th>
<th id="S4.T2.4.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Off</th>
<th id="S4.T2.4.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Left</th>
<th id="S4.T2.4.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Right</th>
<th id="S4.T2.4.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Average</th>
<th id="S4.T2.4.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Off</th>
<th id="S4.T2.4.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Left</th>
<th id="S4.T2.4.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Right</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.3.1" class="ltx_tr">
<th id="S4.T2.4.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Central</th>
<td id="S4.T2.4.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">90.4</td>
<td id="S4.T2.4.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">92.3</td>
<td id="S4.T2.4.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">85.6</td>
<td id="S4.T2.4.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">86.5</td>
<td id="S4.T2.4.3.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.866</td>
<td id="S4.T2.4.3.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.932</td>
<td id="S4.T2.4.3.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.859</td>
<td id="S4.T2.4.3.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.807</td>
</tr>
<tr id="S4.T2.4.4.2" class="ltx_tr">
<th id="S4.T2.4.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;">Federated</th>
<td id="S4.T2.4.4.2.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">91.1</td>
<td id="S4.T2.4.4.2.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">93.9</td>
<td id="S4.T2.4.4.2.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">85.4</td>
<td id="S4.T2.4.4.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;">82.3</td>
<td id="S4.T2.4.4.2.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.874</td>
<td id="S4.T2.4.4.2.7" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.938</td>
<td id="S4.T2.4.4.2.8" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.859</td>
<td id="S4.T2.4.4.2.9" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.826</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Upon visually analyzing some of these turns in the test set, it is observed that the federated model is able to predict the correct turn indicator status as shown in Figure <a href="#S4.F7.sf1" title="In Figure 7 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a>. Interestingly, our model is able to pick on lane changes and correctly indicates that turn signal should be on when changing lanes as can be seen from Figure <a href="#S4.F7.sf2" title="In Figure 7 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a>. From Figure <a href="#S4.F7" title="Figure 7 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, it is observed that the model predictions vary from the ground truth mostly in the beginning and the end of the turn signal changes. It is important to understand that in this problem, the ground truth does not necessarily hold true because the drivers may start the turn signal earlier than they need or sometimes even forget to switch it off long after they have made the turn. For us, the goal was not to match the ground truth but to learn the turn signal change behavior collaboratively from different driver behaviors.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/rightturnresults.png" id="S4.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="568" height="723" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/leftlanechangeresults.png" id="S4.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="568" height="730" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;"> a) A vehicle making a right turn and federated model predicting correctly. b) A vehicle makes a left lane change and the federated model predicts that left turn signal should be on. </span></figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Another interesting observation is that the federated model is able to predict that turn signal should be on even when the ground truth is off (i.e., the driver did not switch on the turn signal) and the vehicle is in fact making a turn. Figure <a href="#S4.F8" title="Figure 8 ‣ 4 Results and Analysis ‣ Turn Signal Prediction: A Federated Learning Case Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows such scenarios with both a right turn and a left turn. Our federated model is able to predict the correct behavior in such cases because Federated Learning learns a shared model from multiple clients, driver patterns in our case, in a collaborative manner, thus learning a more accurate model from multiple different situations.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/leftnoturn.png" id="S4.F8.1.g1" class="ltx_graphics ltx_img_portrait" width="568" height="740" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.12401/assets/images/rightnoturn.png" id="S4.F8.2.g1" class="ltx_graphics ltx_img_square" width="568" height="690" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.4.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.5.2" class="ltx_text" style="font-size:90%;"> a) A vehicle makes a left turn and the federated model predicts that left turn signal should be on when the driver did not switch on the turn signal. b) For a right turn the federated model predicts that the right turn signal should be on when the driver did not switch on the turn signal. </span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this research, we have trained a federated model to predict turn signal at next time step using vehicle CAN signal data from previous time steps. We observe that the performance of federated model is similar to a model that was trained centrally. This leads us to advantages of this solution wherein the data has never left the device (vehicle) preserving privacy and network bandwidth. Federated Learning, thus helps in utilizing machine learning in scenarios, especially learning in-vehicles, that were previously not considered due to privacy reasons or data bandwidth constraints.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The experiments presented in this paper were run in a simulated environment. The next phase of this research would be to move this into a real-world environment by setting up devices that stream the models from the vehicle. This would help us in evaluating practical challenges of Federated Learning such as communication frameworks, latency requirements, device scheduling and scheduling model training at the clients. Other aspects from the research side would be to look at the effect of heterogeneous clients where the data distribution of each client is varied and impact of adversaries during the federation.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Broader Impact</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Virtual driver models that mimic local etiquette are essential for both virtual driving systems and driver assist features. This methodology can be used to develop these features. Further, transportation mobility services can be developed and tested. However, learning from multiple driving behaviors can create a biased system. Federated learning does help in mitigating bias in the global model by averaging local models but it must be tested broadly in different geographic locations. Additionally, having the turn signal on and off at appropriate time is a safety feature that can prevent accidents. Instead of monitoring driving behavior a posteriori using plug-in devices, the insurance companies can proactively assist the drivers. These models can clearly be extended using V2X data for others in the mobility ecosystem from pedestrians to various transportation modes. Although the Federated learning mitigates the communication and server storage data breach, individual data on the devices has to be protected &amp; purged. However, it does prevent mass scale data breaches that were observed recently.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shayler et al. [1997]</span>
<span class="ltx_bibblock">
P.J. Shayler, M.S. Goodman, and T. Ma.

</span>
<span class="ltx_bibblock">Applications of neural networks in automotive engine management
systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IFAC Proceedings Volumes</em>, 30(18):899 –
905, 1997.

</span>
<span class="ltx_bibblock">ISSN 1474-6670.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luckow et al. [2016]</span>
<span class="ltx_bibblock">
A. Luckow, M. Cook, N. Ashcraft, E. Weill, E. Djerekarov, and
B. Vorster.

</span>
<span class="ltx_bibblock">Deep learning in the automotive industry: Applications and tools.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Big Data (Big Data)</em>,
pages 3759–3768, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. [2020]</span>
<span class="ltx_bibblock">
Siddharth Agarwal, Ankit Vora, Gaurav Pandey, Wayne Williams, Helen Kourous,
and James McBride.

</span>
<span class="ltx_bibblock">Ford Multi-AV Seasonal Dataset.

</span>
<span class="ltx_bibblock">abs/2003.07969, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2003.07969" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2003.07969</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Ford.

</span>
<span class="ltx_bibblock">Openxc platform.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://openxcplatform.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://openxcplatform.com/</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Joel Obstfeld.

</span>
<span class="ltx_bibblock">Connected cars-All That Data - Cost and Impact on the
Network.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://blogs.cisco.com/sp/connected-car-all-that-data-cost-and-impact-on-the-network" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blogs.cisco.com/sp/connected-car-all-that-data-cost-and-impact-on-the-network</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 37(3):50–60, May 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized
Data.

</span>
<span class="ltx_bibblock">volume 54 of <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages
1273–1282. PMLR, 20–22 Apr 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ponziani [2012]</span>
<span class="ltx_bibblock">
Richard Ponziani.

</span>
<span class="ltx_bibblock">Turn signal usage rate results: A comprehensive field study of 12,000
observed turning vehicles.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">SAE Technical Paper</em>. SAE International, 04 2012.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.4271/2012-01-0261</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.4271/2012-01-0261" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.4271/2012-01-0261</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konecný et al. [2016]</span>
<span class="ltx_bibblock">
Jakub Konecný, H. Brendan McMahan, Daniel Ramage, and Peter
Richtárik.

</span>
<span class="ltx_bibblock">Federated optimization: Distributed machine learning for on-device
intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1610.02527, 2016.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečný et al. [2016]</span>
<span class="ltx_bibblock">
Jakub Konečný, H. Brendan McMahan, Felix X. Yu, Peter Richtarik,
Ananda Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">NIPS Workshop on Private Multi-Party Machine Learning</em>,
2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2016]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise Agüera
y Arcas.

</span>
<span class="ltx_bibblock">Federated learning of deep networks using model averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1602.05629, 2016.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. [2017]</span>
<span class="ltx_bibblock">
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar.

</span>
<span class="ltx_bibblock">Federated multi-task learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 30</em>, pages
4424–4434. 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2018]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1806.00582, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. [2019]</span>
<span class="ltx_bibblock">
Xin Yao, Tianchi Huang, Rui-Xiao Zhang, Ruiyu Li, and Lifeng Sun.

</span>
<span class="ltx_bibblock">Federated learning with unbiased gradient aggregation and
controllable meta updating.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Neurips Workshop on Federated Learning for Data Privacy and
Confidentiality</em>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2017]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving machine learning.

</span>
<span class="ltx_bibblock">CCS ’17, page 1175–1191, NY, USA, 2017. Association for Computing
Machinery.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geyer et al. [2017]</span>
<span class="ltx_bibblock">
Robin C. Geyer, Tassilo Klein, and Moin Nabi.

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client level
perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1712.07557, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. [2018]</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Françoise Beaufays, Sean
Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1811.03604, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2018]</span>
<span class="ltx_bibblock">
Fei Chen, Zhenhua Dong, Zhenguo Li, and Xiuqiang He.

</span>
<span class="ltx_bibblock">Federated meta-learning for recommendation.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1802.07876, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1802.07876" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1802.07876</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. [2019]</span>
<span class="ltx_bibblock">
Yihan Jiang, Jakub Konečný, Keith Rush, and Sreeram Kannan.

</span>
<span class="ltx_bibblock">Improving federated learning personalization via model agnostic meta
learning, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2020]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang.

</span>
<span class="ltx_bibblock">A secure federated transfer learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 35(4):70–82,
2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Tensorflow federated.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.tensorflow.org/federated/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated/</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber [1997]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Neural computation</em>, 9:1735–80, 12 1997.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/neco.1997.9.8.1735</span>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2012.12400" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2012.12401" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2012.12401">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2012.12401" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2012.12402" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 13:31:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
