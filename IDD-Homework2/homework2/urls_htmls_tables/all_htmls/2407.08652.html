<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.08652] DART: A Solution for Decentralized Federated Learning Model Robustness Analysis</title><meta property="og:description" content="Federated Learning (FL) has emerged as a promising approach to address privacy concerns inherent in Machine Learning (ML) practices. However, conventional FL methods, particularly those following the Centralized FL (CF…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DART: A Solution for Decentralized Federated Learning Model Robustness Analysis">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="DART: A Solution for Decentralized Federated Learning Model Robustness Analysis">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.08652">

<!--Generated on Mon Aug  5 13:11:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">[orcid=0000-0002-0672-1090]
[orcid=0000-0001-7125-1710]
[orcid=0000-0002-0591-8887]
[orcid=0000-0002-5169-2815]
[orcid=0000-0002-4534-3483]
[orcid=0000-0002-7461-7463]</p>
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\cortext</span>
<p id="p2.2" class="ltx_p">[cor1]Corresponding author.
Email address: cfeng@ifi.uzh.ch (C. Feng)</p>
</div>
<h1 class="ltx_title ltx_title_document">
<span id="id1.id1" class="ltx_text ltx_font_italic">DART</span>: A Solution for Decentralized Federated Learning Model Robustness Analysis</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chao Feng
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alberto Huertas Celdrán
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jan von der Assen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Enrique Tomás Martínez Beltrán
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gérôme Bovet
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Burkhard Stiller
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Communication Systems Group CSG, Department of Informatics IfI, University of Zurich UZH, 8050 Zürich, Switzerland
</span>
<span class="ltx_contact ltx_role_address">Department of Information and Communications Engineering, University of Murcia, 30100 Murcia, Spain
</span>
<span class="ltx_contact ltx_role_address">Cyber-Defence Campus within Armasuisse Science &amp; Technology, 3602 Thun, Switzerland
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Federated Learning (FL) has emerged as a promising approach to address privacy concerns inherent in Machine Learning (ML) practices. However, conventional FL methods, particularly those following the Centralized FL (CFL) paradigm, utilize a central server for global aggregation, which exhibits limitations such as bottleneck and single point of failure. To address these issues, the Decentralized FL (DFL) paradigm has been proposed, which removes the client-server boundary and enables all participants to engage in model training and aggregation tasks. Nevertheless, as CFL, DFL remains vulnerable to adversarial attacks, notably poisoning attacks that undermine model performance. While existing research on model robustness has predominantly focused on CFL, there is a noteworthy gap in understanding the model robustness of the DFL paradigm. In this paper, a thorough review of poisoning attacks targeting the model robustness in DFL systems, as well as their corresponding countermeasures, are presented. Additionally, a solution called <span id="id2.id1.1" class="ltx_text ltx_font_italic">DART</span> is proposed to evaluate the robustness of DFL models, which is implemented and integrated into a DFL platform. Through extensive experiments, this paper compares the behavior of CFL and DFL under diverse poisoning attacks, pinpointing key factors affecting attack spread and effectiveness within the DFL. It also evaluates the performance of different defense mechanisms and investigates whether defense mechanisms designed for CFL are compatible with DFL. The empirical results provide insights into research challenges and suggest ways to improve the robustness of DFL models for future research.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Decentralized Federated Learning <span id="id3.id1" class="ltx_ERROR undefined">\sep</span>Poisoning Attack <span id="id4.id2" class="ltx_ERROR undefined">\sep</span>Cybersecurity <span id="id5.id3" class="ltx_ERROR undefined">\sep</span>Model Robustness

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The rapid expansion of the Internet-of-Things (IoT) has led to the interconnection of more than 15 billion devices, resulting in the generation of a staggering 330 Exabytes of data on a daily basis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">15</span></a>]</cite>. Machine Learning (ML) has become a crucial tool for efficiently handling and analyzing such immense datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">54</span></a>]</cite>. The ML pipeline involves various stages, such as data collection, centralization, preprocessing, training, and inference. However, data aggregation into a single server or data center presents challenges, particularly in IoT environments where data is collected and stored in a distributed manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">5</span></a>]</cite>. Centralizing data is challenging due to network and storage limitations, and sharing data online raises security and privacy concerns, users are wary of sharing sensitive information from IoT devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>]</cite>. Consequently, there is a growing research interest in designing an innovative ML paradigm that effectively tackles the challenges related to data processing and privacy preservation.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2407.08652/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="240" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Federation Aggregation Architecture of FL</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated Learning (FL) is a privacy-preserving ML paradigm where data is distributed and retained locally across clients (<span id="S1.p2.1.1" class="ltx_text ltx_font_italic">e.g., </span>IoT devices) instead of centralized in a single location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">50</span></a>]</cite>. As illustrated in the left side of Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the local dataset in each client is employed to feed and train the local model algorithm and evaluate the model outcomes. These local models are then sent to a central aggregation server, where a global model is generated and distributed back to the clients for further training. This iterative process continues until the global model reaches convergence or a predefined number of aggregation rounds is reached. Throughout this federated procedure, clients prioritize privacy by only transmitting the models over the network while keeping the underlying data securely stored on their devices. Additionally, the smaller size of the models compared to the raw data helps overcome bandwidth and storage limitations. Thus, FL is well-suited for implementation in distributed networks that prioritize privacy preservation, such as healthcare and autonomous driving sections <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">28</span></a>]</cite>. Nevertheless, the incorporation of the central aggregation server, referred to as Centralized FL (CFL), introduces new risks to the system. The central aggregator becomes a single-point-of-failure risk of the CFL paradigm, leading to network congestion and processing bottleneck <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">5</span></a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To cope with the single-point-of-failure risk of the CFL paradigm, a decentralized approach known as Decentralized FL (DFL) has been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">5</span></a>]</cite>. The DFL paradigm eliminates the distinction between servers and clients, allowing all participants to serve as trainers and aggregators, as shown on the right side of Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In this approach, participants train models using their own local data and then exchange these models with other participants through the network. Local model aggregation occurs within each participant, incorporating knowledge shared by others while ensuring that data privacy is preserved as only the models are shared. This decentralization allows the FL process to be fully autonomous and more resistant to network failures. Moreover, the DFL system offers increased stability by avoiding the risks associated with a single aggregator, distinguishing it from the CFL paradigm. Besides, the DFL paradigm allows for flexible interconnection using various network topologies, providing greater adaptability.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">However, in addition to the benefits that CFL and DFL offer, the inherently distributed nature of this FL system makes it vulnerable to poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">57</span></a>]</cite>. These attacks involve malicious participants manipulating the training data or inserting malicious elements into their local models, resulting in inaccurate outputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. These compromised models are distributed across the FL system and aggregated with benign models. This aggregation results in declining performance for benign models, reducing their robustness. These poisoning attacks can target both CFL and DFL systems. Therefore, there is a growing body of research dedicated to protecting the model robustness of FL systems and mitigating the detrimental effects of poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">37</span></a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Given the significance of poisoning attacks on DFL, it is crucial to prioritize the strength and security of the models. However, existing studies predominantly focus on the impact of poisoning attacks on CFL, indicating the need for greater attention to safeguarding DFL systems against such attacks. Moreover, there is a scarcity of practical tools available for effectively analyzing the robustness of DFL. Therefore, this work proposes and implements a DFL model robustness analysis solution. The contributions of this work can be summarized as follows:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">An analysis of the poisoning attacks targeting DFL. This paper offers a comprehensive overview of poisoning attacks, classifying and examining these attacks from the perspectives of both attack intention and attack strategy.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">An overview of existing defenses against poisoning attacks. This paper comprehensively reviews defense mechanisms to protect FL (both CFL and DFL) from poisoning attacks. The existing defense mechanisms are thoroughly examined, categorized, and analyzed from various perspectives.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Design and prototype a model robustness analysis solution for DFL. This paper proposes a model robustness analysis solution for DFL, called <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">DART</span>. <span id="S1.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">DART</span> comprises an attack component that enables the execution of untargeted and targeted poisoning attacks, as well as a defense component that incorporates multiple defense mechanisms to protect DFL models from poisoning attacks. Meanwhile, <span id="S1.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">DART</span> is prototypically implemented and integrated into a real DFL platform to benchmark the performance of different attacks and the effectiveness of defense mechanisms.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Experimental comparison of the model robustness between CFL and DFL and benchmark of the effectiveness of defense mechanisms. This paper conducts a series of experiments to compare the behavior and evaluate the robustness of CFL and DFL paradigms when subjected to targeted and untargeted attacks in MNIST, FashionMNIST, and Cifar10 datasets. Besides, this study conducts extensive experiments to benchmark the effectiveness of various defense mechanisms and offers recommendations for selecting the optimal defense mechanism.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Analysis of the challenges and opportunities in the field of mode robustness. The paper delves into the learning lessons and highlights the research challenges from the literature review and experimental analysis while pinpointing the potential avenues for exploration in the DFL model robustness field.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In summary, the primary innovation of this work lies in its comprehensive review of existing literature on model robustness in DFL, as well as its empirical assessment of defense mechanisms against poisoning attacks. Then, this paper argues that DFL overlay network topology plays a crucial role in model robustness, underscoring the importance of considering topology when designing novel attacks or defenses. In addition, it analyzes the potential issues and challenges for improving the security of the DFL model against poisoning attacks in real-world scenarios, including both offensive and defensive considerations. Finally, this work offers recommendations for improving the robustness of the model in DFL and proposes practical roadmaps for implementation.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The subsequent sections of this paper are structured as follows: Section <a href="#S2" title="2 Related Work ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents an introduction to the relevant literature, while Section <a href="#S3" title="3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides a comprehensive overview of poisoning attacks and the corresponding defense mechanisms. Afterwards, Section <a href="#S4" title="4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> introduces the framework proposed in the paper, encompassing the overarching architecture, conception, and implementation, as well as the integration with a DFL platform. The experimental study is detailed in Section <a href="#S5" title="5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Lastly, Section <a href="#S6" title="6 Lessons Learned, Open Challenges, and Research Opportunities ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> discusses lessons learned, challenges encountered, and potential research opportunities, while Section <a href="#S7" title="7 Conclusion ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> offers concluding remarks.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Comparison of Attributes among Existing Robustness Analysis of FL Research </span></figcaption>
<div id="S2.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:253pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-50.9pt,29.6pt) scale(0.809788478076495,0.809788478076495) ;">
<table id="S2.T1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Research</td>
<td id="S2.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">CFL</td>
<td id="S2.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">DFL</td>
<td id="S2.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S2.T1.4.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.4.1.1.4.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Defense</td>
</tr>
<tr id="S2.T1.4.1.1.4.1.2" class="ltx_tr">
<td id="S2.T1.4.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Included</td>
</tr>
</table>
</td>
<td id="S2.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S2.T1.4.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.4.1.1.5.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Overview</td>
</tr>
<tr id="S2.T1.4.1.1.5.1.2" class="ltx_tr">
<td id="S2.T1.4.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">of Attacks</td>
</tr>
</table>
</td>
<td id="S2.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S2.T1.4.1.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.4.1.1.6.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Experimental</td>
</tr>
<tr id="S2.T1.4.1.1.6.1.2" class="ltx_tr">
<td id="S2.T1.4.1.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Analysis</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.4.1.2" class="ltx_tr">
<td id="S2.T1.4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">6</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S2.T1.4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S2.T1.4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S2.T1.4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S2.T1.4.1.2.6" class="ltx_td ltx_align_center ltx_border_t">x</td>
</tr>
<tr id="S2.T1.4.1.3" class="ltx_tr">
<td id="S2.T1.4.1.3.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">8</span></a>]</cite> 2021</td>
<td id="S2.T1.4.1.3.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.3.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.3.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.3.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.3.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S2.T1.4.1.4" class="ltx_tr">
<td id="S2.T1.4.1.4.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">14</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.4.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.4.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.4.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.4.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.4.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.5" class="ltx_tr">
<td id="S2.T1.4.1.5.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">29</span></a>]</cite> 2021</td>
<td id="S2.T1.4.1.5.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.5.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.5.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.5.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.5.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.6" class="ltx_tr">
<td id="S2.T1.4.1.6.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">31</span></a>]</cite> 2023</td>
<td id="S2.T1.4.1.6.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.6.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.6.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.6.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.6.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.7" class="ltx_tr">
<td id="S2.T1.4.1.7.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">36</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.7.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.7.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.7.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.7.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.7.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.8" class="ltx_tr">
<td id="S2.T1.4.1.8.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">37</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.8.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.8.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.8.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.8.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.8.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.9" class="ltx_tr">
<td id="S2.T1.4.1.9.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">40</span></a>]</cite> 2021</td>
<td id="S2.T1.4.1.9.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.9.3" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.9.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.9.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.9.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.10" class="ltx_tr">
<td id="S2.T1.4.1.10.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">42</span></a>]</cite> 2023</td>
<td id="S2.T1.4.1.10.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.10.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.10.4" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.10.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.10.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.11" class="ltx_tr">
<td id="S2.T1.4.1.11.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">49</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.11.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.11.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.11.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.11.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.11.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.12" class="ltx_tr">
<td id="S2.T1.4.1.12.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>]</cite> 2023</td>
<td id="S2.T1.4.1.12.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.12.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.12.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.12.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.12.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S2.T1.4.1.13" class="ltx_tr">
<td id="S2.T1.4.1.13.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">59</span></a>]</cite> 2022</td>
<td id="S2.T1.4.1.13.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.13.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.13.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.13.5" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.13.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.14" class="ltx_tr">
<td id="S2.T1.4.1.14.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite> 2023</td>
<td id="S2.T1.4.1.14.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.14.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.14.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.14.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.14.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.15" class="ltx_tr">
<td id="S2.T1.4.1.15.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">69</span></a>]</cite> 2021</td>
<td id="S2.T1.4.1.15.2" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.15.3" class="ltx_td ltx_align_center">x</td>
<td id="S2.T1.4.1.15.4" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.15.5" class="ltx_td ltx_align_center">✓</td>
<td id="S2.T1.4.1.15.6" class="ltx_td ltx_align_center">x</td>
</tr>
<tr id="S2.T1.4.1.16" class="ltx_tr">
<td id="S2.T1.4.1.16.1" class="ltx_td ltx_align_left ltx_border_b">This Work</td>
<td id="S2.T1.4.1.16.2" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S2.T1.4.1.16.3" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S2.T1.4.1.16.4" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S2.T1.4.1.16.5" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S2.T1.4.1.16.6" class="ltx_td ltx_align_center ltx_border_b">✓</td>
</tr>
</table>
</span></div>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There have been a few overview and survey articles for FL model robustness studies, discussing both theoretical and practical considerations related to adversarial attacks and defense mechanisms. This section conducts a comparative analysis of these articles and presents an overview in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">40</span></a>]</cite> analyzed the security and privacy risks faced by FL from the perspectives of the sources of vulnerabilities and the types of adversarial attacks. A comparison was made between FL and other distributed ML methods regarding their vulnerability to adversarial attacks. The authors analyzed both CFL and fully-connected DFL architectures within the FL framework. However, the analysis was predominantly qualitative, lacking quantitative assessment and neglecting to compare the distinctions between CFL and DFL. Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">37</span></a>]</cite> presented a comprehensive assessment of the risks and threats confronting FL, outlining the impact of potential attacks. Furthermore, this survey presented an overview of defensive measures and assessed their susceptibility to compromise.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">31</span></a>]</cite> summarized the security risks and impacts of adversarial attacks on FL systems and proposed a multidimensional analysis framework from the source of the attack, the attack’s impact, the attack’s budget, and the attack’s visibility. A taxonomy of adversarial attacks is also proposed. In terms of defense mechanisms, the effects of different defense mechanisms are compared through quantitative literature analysis. Nevertheless, this survey lacks empirical analysis to validate the legitimacy of these attacks and defense measures.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">8</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>]</cite> employed a combination of literature analysis and empirical analysis to examine and summarize the security and privacy risks associated with FL systems. The study presented an overview of attacks and defenses regarding security and privacy and utilized experimental methods to validate various types of attacks empirically. However, it is important to note that the survey solely focused on CFL and did not address the emerging challenges faced by DFL systems.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">69</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">29</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">49</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">6</span></a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">42</span></a>]</cite> conducted extensive research on the vulnerabilities of FL systems. They developed taxonomies of adversarial attacks. While <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">36</span></a>]</cite> focused on analyzing the threats throughout the entire life cycle of FL, considering various stages of the FL pipeline. They classified and summarized the attacks, examined their potential impact, and analyzed the available defense strategies concurrently. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">14</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">59</span></a>]</cite> evaluated the efficacy and viability of various defense strategies, classifying and categorizing defenses according to which attacks can be effectively mitigated. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite> centered on examining poisoning attacks, where various types of such attacks were categorized, and diverse strategies and methods for carrying out these attacks were elucidated. Additionally, the research entailed an analysis of the countermeasures employed against different attacks, their effectiveness, and the vulnerability of data distribution.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">In conclusion, the current research examining and analyzing the security of FL mainly focuses on CFL systems, with only a limited number of articles and surveys exploring DFL. Additionally, these works rely on qualitative analysis and theoretical taxonomies, which are lacking in quantitative and experimental analysis. Thus, there is a need for a practical-oriented module that can quantitatively evaluate and analyze the robustness of DFL models using experiments while also appraising the efficacy of different defense mechanisms.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Poisoning Attacks and Defense Mechanisms</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Malicious attacks pose a significant obstacle in FL, especially poisoning attacks, which are designed to undermine the robustness of the FL model and diminish the usability of its output. Given the distributed nature of FL, detecting and mitigating poisoning attacks presents a substantial challenge. This Section provides an overview of poisoning attacks and reviews existing defense mechanisms on both CFL and DFL.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Poisoning Attacks on FL</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In FL systems, where nodes are distributed across various entities, adversaries can tamper with data or models to disrupt the effectiveness and robustness of benign models. In contrast to CFL, detecting malicious activity in DFL poses greater challenges due to the absence of a central entity controlling the entire process. Poisoning attacks targeting DFL can be categorized based on two viewpoints: the attack intention and attack strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. The attack intention indicates the desired outcome of the adversary, whether it is to misclassify a particular target or to undermine the overall performance. The attack strategy entails the creation of a poisoning attack through the manipulation of either the data or the model.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Poisoning attacks can be categorized into three groups based on the intentions of the adversary, namely untargeted, targeted, and backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">57</span></a>, <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. The goal of untargeted attacks is to reduce the overall performance of the model, hindering its convergence. Conversely, targeted attacks involve intentional manipulation of the training data by the adversary to cause incorrect or biased predictions for specific target inputs. The objective of the targeted attacks is to infiltrate the model in such a way that only a particular target set or class is misclassified, while the rest of the set is correctly classified <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. Another type of attack is the backdoor attack, where the adversary inserts one or more triggers into the model during training, which can then be exploited during the inference process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">3</span></a>]</cite>. Essentially, the model behaves normally without the trigger, but an attacker can elicit a desired prediction or classification by presenting the trigger during the inference stage.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In the CFL paradigm, targeted attacks are data-driven processes and thus tend to be launched at the client side. Untargeted attacks in the CFL paradigm can be executed without reliance on data, enabling them to be launched from either the client or server side. In contrast, in the DFL paradigm, the traditional differentiation between client and server is eliminated, allowing any node to launch both targeted and untargeted attacks. Consequently, the attack surfaces in the DFL paradigm are increased.</p>
</div>
<figure id="S3.T2" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.3.2" class="ltx_text" style="font-size:90%;">Overview of Defense Mechanisms Against Poisoning Attacks in FL</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle">
<tr id="S3.T2.4.1" class="ltx_tr">
<td id="S3.T2.4.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding:1.75pt 3.0pt;" rowspan="2"><span id="S3.T2.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Category</span></td>
<td id="S3.T2.4.1.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding:1.75pt 3.0pt;" rowspan="2"><span id="S3.T2.4.1.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Type</span></td>
<td id="S3.T2.4.1.3" class="ltx_td ltx_align_left ltx_border_tt" style="padding:1.75pt 3.0pt;" rowspan="2"><span id="S3.T2.4.1.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Method</span></td>
<td id="S3.T2.4.1.4" class="ltx_td ltx_align_left ltx_border_tt" style="padding:1.75pt 3.0pt;" rowspan="2"><span id="S3.T2.4.1.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Technique</span></td>
<td id="S3.T2.4.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1.75pt 3.0pt;" rowspan="2"><span id="S3.T2.4.1.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Paradigm</span></td>
<td id="S3.T2.4.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1.75pt 3.0pt;" colspan="2"><span id="S3.T2.4.1.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Objective</span></td>
</tr>
<tr id="S3.T2.4.2" class="ltx_tr">
<td id="S3.T2.4.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.2.1.1" class="ltx_text" style="font-size:70%;">U</span></td>
<td id="S3.T2.4.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.2.2.1" class="ltx_text" style="font-size:70%;">T</span></td>
</tr>
<tr id="S3.T2.4.3" class="ltx_tr">
<td id="S3.T2.4.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="6"><span id="S3.T2.4.3.1.1" class="ltx_text" style="font-size:70%;">Byzantine-Robust</span></td>
<td id="S3.T2.4.3.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="6"><span id="S3.T2.4.3.2.1" class="ltx_text" style="font-size:70%;">Geometry</span></td>
<td id="S3.T2.4.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.3.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">COMED</span><span id="S3.T2.4.3.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.3.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">67</span></a><span id="S3.T2.4.3.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.3.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.3.4.1" class="ltx_text" style="font-size:70%;">Coordinate-wise median</span></td>
<td id="S3.T2.4.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.3.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.3.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.3.7.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<td id="S3.T2.4.4.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.4.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">TrimmedMean</span><span id="S3.T2.4.4.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.4.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">66</span></a><span id="S3.T2.4.4.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.4.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.4.2.1" class="ltx_text" style="font-size:70%;">Filtered mean</span></td>
<td id="S3.T2.4.4.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.4.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.4.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.4.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.4.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.4.5.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.5" class="ltx_tr">
<td id="S3.T2.4.5.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.5.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">RFA</span><span id="S3.T2.4.5.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.5.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">48</span></a><span id="S3.T2.4.5.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.5.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.5.2.1" class="ltx_text" style="font-size:70%;">Geometric median</span></td>
<td id="S3.T2.4.5.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.5.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.5.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.5.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.5.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.5.5.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.6" class="ltx_tr">
<td id="S3.T2.4.6.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.6.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Krum</span><span id="S3.T2.4.6.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.6.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">7</span></a><span id="S3.T2.4.6.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.6.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.6.2.1" class="ltx_text" style="font-size:70%;">Euclidean distance</span></td>
<td id="S3.T2.4.6.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.6.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.6.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.6.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.6.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.6.5.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.7" class="ltx_tr">
<td id="S3.T2.4.7.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.7.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Multi-Krum</span><span id="S3.T2.4.7.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.7.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">7</span></a><span id="S3.T2.4.7.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.7.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.7.2.1" class="ltx_text" style="font-size:70%;">Euclidean distance</span></td>
<td id="S3.T2.4.7.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.7.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.7.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.7.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.7.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.7.5.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.8" class="ltx_tr">
<td id="S3.T2.4.8.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.8.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Bulyan</span><span id="S3.T2.4.8.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.8.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">39</span></a><span id="S3.T2.4.8.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.8.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.8.2.1" class="ltx_text" style="font-size:70%;">Krum and TrimmedMean</span></td>
<td id="S3.T2.4.8.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.8.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.8.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.8.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.8.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.8.5.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.9" class="ltx_tr">
<td id="S3.T2.4.9.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.9.1.1" class="ltx_text" style="font-size:70%;">Aggregation</span></td>
<td id="S3.T2.4.9.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="3"><span id="S3.T2.4.9.2.1" class="ltx_text" style="font-size:70%;">Regularization</span></td>
<td id="S3.T2.4.9.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.9.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Zeno++</span><span id="S3.T2.4.9.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.9.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">65</span></a><span id="S3.T2.4.9.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.9.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.9.4.1" class="ltx_text" style="font-size:70%;">Approximated gradient descent score</span></td>
<td id="S3.T2.4.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.9.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.9.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.9.7.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.10" class="ltx_tr">
<td id="S3.T2.4.10.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.10.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.10.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">AFA</span><span id="S3.T2.4.10.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.10.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">41</span></a><span id="S3.T2.4.10.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.10.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.10.3.1" class="ltx_text" style="font-size:70%;">Gradient similarity, Hidden Markov model</span></td>
<td id="S3.T2.4.10.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.10.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.10.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.10.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.10.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.10.6.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.11" class="ltx_tr">
<td id="S3.T2.4.11.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.11.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.11.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">RSA</span><span id="S3.T2.4.11.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.11.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">34</span></a><span id="S3.T2.4.11.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.11.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.11.3.1" class="ltx_text" style="font-size:70%;">Norm regularization</span></td>
<td id="S3.T2.4.11.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.11.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.11.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.11.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.11.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.11.6.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.12" class="ltx_tr">
<td id="S3.T2.4.12.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.12.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.12.2.1" class="ltx_text" style="font-size:70%;">Decomposition</span></td>
<td id="S3.T2.4.12.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.12.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">DnC</span><span id="S3.T2.4.12.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.12.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">53</span></a><span id="S3.T2.4.12.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.12.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.12.4.1" class="ltx_text" style="font-size:70%;">Dimensionality Reduction (PCA) and SVD</span></td>
<td id="S3.T2.4.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.12.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.12.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.12.7.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.13" class="ltx_tr">
<td id="S3.T2.4.13.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.13.2" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.13.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.13.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">RLR</span><span id="S3.T2.4.13.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.13.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">46</span></a><span id="S3.T2.4.13.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.13.4" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.13.4.1" class="ltx_text" style="font-size:70%;">Learning rate decomposition</span></td>
<td id="S3.T2.4.13.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.13.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.13.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.13.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.4.13.7" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.13.7.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.14" class="ltx_tr">
<td id="S3.T2.4.14.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="6"><span id="S3.T2.4.14.1.1" class="ltx_text" style="font-size:70%;">Anomaly Detection</span></td>
<td id="S3.T2.4.14.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.14.2.1" class="ltx_text" style="font-size:70%;">Validation</span></td>
<td id="S3.T2.4.14.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.14.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">ERR, LFR</span><span id="S3.T2.4.14.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.14.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">18</span></a><span id="S3.T2.4.14.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.14.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.14.4.1" class="ltx_text" style="font-size:70%;">Global validation</span></td>
<td id="S3.T2.4.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.14.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.14.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.14.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.14.7.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.15" class="ltx_tr">
<td id="S3.T2.4.15.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.15.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.15.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">PDGA</span><span id="S3.T2.4.15.2.2" class="ltx_text" style="font-size:70%;">N </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.15.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">73</span></a><span id="S3.T2.4.15.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.15.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.15.3.1" class="ltx_text" style="font-size:70%;">Model accuracy auditing</span></td>
<td id="S3.T2.4.15.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.15.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.15.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.15.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.15.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.15.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.16" class="ltx_tr">
<td id="S3.T2.4.16.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="4"><span id="S3.T2.4.16.1.1" class="ltx_text" style="font-size:70%;">Gradient-based</span></td>
<td id="S3.T2.4.16.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.16.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">FoolsGold</span><span id="S3.T2.4.16.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.16.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">24</span></a><span id="S3.T2.4.16.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.16.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.16.3.1" class="ltx_text" style="font-size:70%;">Gradient similarity (cosine)</span></td>
<td id="S3.T2.4.16.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.16.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.16.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.16.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.16.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.16.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.17" class="ltx_tr">
<td id="S3.T2.4.17.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.17.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">FLDetector</span><span id="S3.T2.4.17.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.17.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">71</span></a><span id="S3.T2.4.17.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.17.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.17.2.1" class="ltx_text" style="font-size:70%;">Hessian-based gradient consistency</span></td>
<td id="S3.T2.4.17.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.17.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.17.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.17.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.17.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.17.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.18" class="ltx_tr">
<td id="S3.T2.4.18.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.18.1.1" class="ltx_text" style="font-size:70%;">Li et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.18.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">35</span></a><span id="S3.T2.4.18.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.18.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.18.2.1" class="ltx_text" style="font-size:70%;">Spectral anomaly detection</span></td>
<td id="S3.T2.4.18.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.18.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.18.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.18.4.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.18.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.18.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.19" class="ltx_tr">
<td id="S3.T2.4.19.1" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.19.1.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Sniper</span><span id="S3.T2.4.19.1.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.19.1.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">73</span></a><span id="S3.T2.4.19.1.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.19.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.19.2.1" class="ltx_text" style="font-size:70%;">Graph clustering</span></td>
<td id="S3.T2.4.19.3" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.19.3.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.19.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.19.4.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.4.19.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.19.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.20" class="ltx_tr">
<td id="S3.T2.4.20.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.20.1.1" class="ltx_text" style="font-size:70%;">MTD</span></td>
<td id="S3.T2.4.20.2" class="ltx_td ltx_border_t" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.20.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.20.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Voyager</span><span id="S3.T2.4.20.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.20.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">21</span></a><span id="S3.T2.4.20.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.20.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.20.4.1" class="ltx_text" style="font-size:70%;">Manipulating of the network topology</span></td>
<td id="S3.T2.4.20.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.20.5.1" class="ltx_text" style="font-size:70%;">DFL</span></td>
<td id="S3.T2.4.20.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.20.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.20.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.20.7.1" class="ltx_text" style="font-size:70%;">x</span></td>
</tr>
<tr id="S3.T2.4.21" class="ltx_tr">
<td id="S3.T2.4.21.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;" rowspan="7"><span id="S3.T2.4.21.1.1" class="ltx_text" style="font-size:70%;">Hybrid Mechanism</span></td>
<td id="S3.T2.4.21.2" class="ltx_td ltx_border_t" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.21.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.21.3.1" class="ltx_text ltx_font_italic" style="font-size:70%;">FLTrust</span><span id="S3.T2.4.21.3.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.21.3.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">12</span></a><span id="S3.T2.4.21.3.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.21.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.21.4.1" class="ltx_text" style="font-size:70%;">ReLU-clipped cosine similarity, norm thresholding</span></td>
<td id="S3.T2.4.21.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.21.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.21.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.21.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.21.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.21.7.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.22" class="ltx_tr">
<td id="S3.T2.4.22.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.22.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.22.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Trusted DFL</span><span id="S3.T2.4.22.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.22.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">25</span></a><span id="S3.T2.4.22.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.22.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.22.3.1" class="ltx_text" style="font-size:70%;">Trusted aggregation</span></td>
<td id="S3.T2.4.22.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.22.4.1" class="ltx_text" style="font-size:70%;">DFL</span></td>
<td id="S3.T2.4.22.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.22.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.22.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.22.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
</tr>
<tr id="S3.T2.4.23" class="ltx_tr">
<td id="S3.T2.4.23.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.23.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.23.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">FedInv</span><span id="S3.T2.4.23.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.23.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">72</span></a><span id="S3.T2.4.23.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.23.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.23.3.1" class="ltx_text" style="font-size:70%;">Gradient-based clustering distribution divergences</span></td>
<td id="S3.T2.4.23.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.23.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.23.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.23.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.23.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.23.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.24" class="ltx_tr">
<td id="S3.T2.4.24.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.24.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.24.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Norm Clipping <cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.24.2.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">46</span></a><span id="S3.T2.4.24.2.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span></td>
<td id="S3.T2.4.24.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.24.3.1" class="ltx_text" style="font-size:70%;">Clipping and worker momentum</span></td>
<td id="S3.T2.4.24.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.24.4.1" class="ltx_text" style="font-size:70%;">DFL</span></td>
<td id="S3.T2.4.24.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.24.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.24.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.24.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.25" class="ltx_tr">
<td id="S3.T2.4.25.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.25.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.25.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">DeepSight</span><span id="S3.T2.4.25.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.25.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">51</span></a><span id="S3.T2.4.25.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.25.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.25.3.1" class="ltx_text" style="font-size:70%;">Classification and clustering with update fingerprinting</span></td>
<td id="S3.T2.4.25.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.25.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.25.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.25.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.25.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.25.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.26" class="ltx_tr">
<td id="S3.T2.4.26.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.26.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.26.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">FLAME</span><span id="S3.T2.4.26.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.26.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">43</span></a><span id="S3.T2.4.26.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.26.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.26.3.1" class="ltx_text" style="font-size:70%;">Clustering (cosine similarity), adaptive clipping, noising</span></td>
<td id="S3.T2.4.26.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.26.4.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.26.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.26.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.26.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.26.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.27" class="ltx_tr">
<td id="S3.T2.4.27.1" class="ltx_td" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.27.2" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.27.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">Sentinel</span><span id="S3.T2.4.27.2.2" class="ltx_text" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.27.2.3.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">19</span></a><span id="S3.T2.4.27.2.4.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.27.3" class="ltx_td ltx_align_left" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.27.3.1" class="ltx_text" style="font-size:70%;">Model similarity, bootstrap validation and normalization</span></td>
<td id="S3.T2.4.27.4" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.27.4.1" class="ltx_text" style="font-size:70%;">DFL</span></td>
<td id="S3.T2.4.27.5" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.27.5.1" class="ltx_text" style="font-size:70%;">✓</span></td>
<td id="S3.T2.4.27.6" class="ltx_td ltx_align_center" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.27.6.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.28" class="ltx_tr">
<td id="S3.T2.4.28.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.28.1.1" class="ltx_text" style="font-size:70%;">Post-Aggregation</span></td>
<td id="S3.T2.4.28.2" class="ltx_td ltx_border_t" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.28.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.28.3.1" class="ltx_text" style="font-size:70%;">Wu et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.28.3.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">61</span></a><span id="S3.T2.4.28.3.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.28.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.28.4.1" class="ltx_text" style="font-size:70%;">Neuron Pruning</span></td>
<td id="S3.T2.4.28.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.28.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.28.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.28.6.1" class="ltx_text" style="font-size:70%;">x</span></td>
<td id="S3.T2.4.28.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.28.7.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
<tr id="S3.T2.4.29" class="ltx_tr">
<td id="S3.T2.4.29.1" class="ltx_td ltx_border_bb" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.29.2" class="ltx_td ltx_border_bb" style="padding:1.75pt 3.0pt;"></td>
<td id="S3.T2.4.29.3" class="ltx_td ltx_align_left ltx_border_bb" style="padding:1.75pt 3.0pt;">
<span id="S3.T2.4.29.3.1" class="ltx_text" style="font-size:70%;">Sun et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.29.3.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">55</span></a><span id="S3.T2.4.29.3.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.4.29.4" class="ltx_td ltx_align_left ltx_border_bb" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.29.4.1" class="ltx_text" style="font-size:70%;">Weak Differential Privacy</span></td>
<td id="S3.T2.4.29.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.29.5.1" class="ltx_text" style="font-size:70%;">CFL</span></td>
<td id="S3.T2.4.29.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.29.6.1" class="ltx_text" style="font-size:70%;">x</span></td>
<td id="S3.T2.4.29.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1.75pt 3.0pt;"><span id="S3.T2.4.29.7.1" class="ltx_text" style="font-size:70%;">✓</span></td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T2.5" class="ltx_p ltx_figure_panel ltx_align_center"><span id="S3.T2.5.1" class="ltx_text" style="font-size:70%;">Untargeted Attacks (U), Targeted Attacks (T)</span></p>
</div>
</div>
</figure>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">From the attack strategy perspective, poisoning attacks can be divided into data poisoning and model poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. Data poisoning involves manipulating training data to indirectly affect the model’s training process, such as changing labels, <span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_italic">i.e., </span>label flipping, or inserting malicious samples, <span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_italic">i.e., </span>sample poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>]</cite>. Both label flipping and sample poisoning can be used as untargeted attacks or targeted attacks. In the context of backdoor attacks, the attacker can choose to incorporate either semantic or artificial backdoors. Semantic backdoors use naturally existing cues, like a specific colored striped background, as triggers. Artificial backdoors are intentionally created by injecting particular triggers, such as adding certain symbols to a sample <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">44</span></a>]</cite>. The effectiveness of data poisoning attacks is limited by the need for a large number of poisoned samples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>]</cite>. In model poisoning attacks, malicious participants can manipulate the locally trained model directly by modifying shared weights or gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">62</span></a>]</cite>. These attacks pose a greater threat as they have a higher success rate and are more difficult to detect. Model poisoning can be divided into two categories: random weights generation, which involves adding random noise to the transmitted model, and optimized weights generation, which involves optimizing the distribution of the added noise to decrease the chances of detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">52</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">57</span></a>]</cite>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">In DFL, participants possess knowledge not only of their own local data and models but also of the models belonging to their neighboring nodes. Therefore, malicious nodes can strategically optimize their attacks and execute more threatening attacks while avoiding detection, thereby heightening the complexity of designing effective defense mechanisms.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Theoretically, while DFL improves system fault tolerance and mitigates single-point-of-failure, it also expands the attack surface and potentially exposes the system to a greater array of attack vectors. Thereby, DFL does not offer superiority over CFL in terms of model robustness.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Defense Mechanisms</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Most defense methods are designed for the centralized setting, which involves a less complex model aggregation process by a single aggregation server. However, in DFL, the lack of a centralized control entity and the increased array of attack vectors mentioned in Section <a href="#S3.SS1" title="3.1 Poisoning Attacks on FL ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> pose challenges when developing defense strategies for DFL. This paper categorizes the approaches for mitigating model poisoning attacks into five categories: Byzantine-robust aggregation, anomaly detection, Moving Target Defense (MTD), hybrid, and post-aggregation.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">As shown in Table <a href="#S3.T2" title="Table 2 ‣ 3.1 Poisoning Attacks on FL ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, these articles have been reviewed, compared, and analyzed across various dimensions, such as the techniques employed, the paradigms in which they are implemented (CFL or DFL), and their effectiveness in addressing both targeted and untargeted attacks.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Byzantine-Robust Aggregation</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The main objective of Byzantine-robust defense techniques is to establish a robust (referred to as Byzantine resilience) aggregation rule that prevents the model’s performance from being compromised by malicious updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">39</span></a>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">51</span></a>]</cite>. These defense methods can be categorized into geometric measures, regularization, and decomposition.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">There are two types of geometric approaches: coordinate-wise filtering and vector-wise filtering. The Coordinate-wise Median (<span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">COMED</span>) is a defensive strategy that uses dimension-wise filtering to protect against attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">67</span></a>]</cite>. <span id="S3.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_italic">COMED</span> is like the median concept but applied in high-dimensional spaces to remove outliers. This approach is effective against model replacement attacks. Another approach called <span id="S3.SS2.SSS1.p2.1.3" class="ltx_text ltx_font_italic">TrimmedMean</span> method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">66</span></a>]</cite> also uses dimension-wise filtering. It eliminates the lowest and highest values in each dimension using a trimming parameter. The underlying assumption of this approach is that malicious updates can be identified as outliers compared to benign updates.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">Vector-wise filtering is a commonly used geometric measure. <span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_italic">RFA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">48</span></a>]</cite> utilizes the geometric median as an aggregation function, which helps defend against untargeted poisoning attacks. However, this defense mechanism can be compromised if an attacker uses a singular-flipping attack to manipulate the geometric center <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">35</span></a>]</cite>. <span id="S3.SS2.SSS1.p3.1.2" class="ltx_text ltx_font_italic">Krum</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">7</span></a>]</cite> is a widely used robust aggregation function that assigns scores to client updates based on their similarity to other updates and selects the update with the lowest score to update the global model. <span id="S3.SS2.SSS1.p3.1.3" class="ltx_text ltx_font_italic">Multi-Krum</span> is a modified version that selects multiple client updates for the next global model. <span id="S3.SS2.SSS1.p3.1.4" class="ltx_text ltx_font_italic">Bulyan</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">39</span></a>]</cite> is proposed as a two-stage aggregation protocol that overcomes the limitations of <span id="S3.SS2.SSS1.p3.1.5" class="ltx_text ltx_font_italic">Krum</span>, but experiments have shown that it performs worse than<span id="S3.SS2.SSS1.p3.1.6" class="ltx_text ltx_font_italic"> Multi-Krum</span> by potentially reducing benign updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">55</span></a>]</cite>.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p">The second category of Byzantine-robust methods is the regularization-based approach. <span id="S3.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_italic">Zeno++</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">65</span></a>]</cite> is an asynchronous protocol for robust CFL. This approach proposes an estimated score for gradient descent that considers the loss and update magnitude. This helps reduce the impact of malicious gradient updates. However, a drawback is that the server needs a validation dataset, which is a constraint in a federated setting. Additionally, relying on performance rather than parameters adds extra computational burden<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">26</span></a>]</cite>. Adaptive Federated Averaging (<span id="S3.SS2.SSS1.p4.1.2" class="ltx_text ltx_font_italic">AFA</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">41</span></a>]</cite> not only filters out potentially malicious updates but also completely blocks adversaries from participating. <span id="S3.SS2.SSS1.p4.1.3" class="ltx_text ltx_font_italic">AFA</span> employs a Hidden Markov Model (HMM) based on gradient cosine similarity to predict a client’s behavior, thereby incorporating a learning component into the defense system. This predictive score is then utilized as a weight factor in the aggregation process, serving as a regularization term. Another method, <span id="S3.SS2.SSS1.p4.1.4" class="ltx_text ltx_font_italic">RSA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">34</span></a>]</cite>, integrates <math id="S3.SS2.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\ell_{1}" display="inline"><semantics id="S3.SS2.SSS1.p4.1.m1.1a"><msub id="S3.SS2.SSS1.p4.1.m1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.SSS1.p4.1.m1.1.1.2" xref="S3.SS2.SSS1.p4.1.m1.1.1.2.cmml">ℓ</mi><mn id="S3.SS2.SSS1.p4.1.m1.1.1.3" xref="S3.SS2.SSS1.p4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.1.m1.1b"><apply id="S3.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S3.SS2.SSS1.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.1.m1.1c">\ell_{1}</annotation></semantics></math>-norm regularization into Stochastic Gradient Descent (SGD) to enhance robustness against Byzantine attacks.</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.1" class="ltx_p">The last class of Byzantine-robust is the decomposition-based approach. Divide-and-Conquer (<span id="S3.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_italic">DnC</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">53</span></a>]</cite> uses spectral analysis, <span id="S3.SS2.SSS1.p5.1.2" class="ltx_text ltx_font_italic">i.e., </span>singular value decomposition, to identify and filter out poisoned updates. The evaluations show that these techniques perform well in scenarios where the data is Independent and Identically Distributed (IID). However, when dealing with non-IID datasets, <span id="S3.SS2.SSS1.p5.1.3" class="ltx_text ltx_font_italic">DnC</span> is not effective in preventing attacks if the adversary has knowledge from benign clients. Robust Learning Rate (<span id="S3.SS2.SSS1.p5.1.4" class="ltx_text ltx_font_italic">RLR</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">46</span></a>]</cite> tackles this problem by implementing a mechanism where clients vote for the direction of the global model update based on the algebraic sign of their update vector. Each dimension of the update vector requires a certain learning threshold to be met by the total number of votes. However, a challenge in <span id="S3.SS2.SSS1.p5.1.5" class="ltx_text ltx_font_italic">RLR</span> is determining an appropriate learning threshold that the number of malicious clients cannot exceed.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Anomaly Detection</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Defense mechanisms that employ anomaly detection, also known as Byzantine detection, aim to identify and eliminate potentially harmful updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">70</span></a>]</cite>. Unlike Byzantine robustness, these anomaly detection schemes do not incorporate the defense strategy into the aggregation rules.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">Error Rate-based Rejection (<span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">ERR</span>) and Loss Function-based Rejection (<span id="S3.SS2.SSS2.p2.1.2" class="ltx_text ltx_font_italic">LFR</span>) are designed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">18</span></a>]</cite> to enhance the robustness of CFL. These methods involve evaluating the performance of client models using a validation dataset on the server side. Before combining the received models, a certain number of updates that have the most impact on either the loss or validation error are discarded. However, a drawback of these methods is that the server needs to collect a clean dataset, which goes against the privacy-preserving principles of FL. To address this limitation, <span id="S3.SS2.SSS2.p2.1.3" class="ltx_text ltx_font_italic">PDGAN</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">73</span></a>]</cite> utilizes a generative adversarial network (GAN) to generate a synthetic dataset for outlier model detection. However, it should be noted that the GAN needs to be trained before the task starts, and the server must have sufficient computing power to train an ML model in a reasonable time while performing aggregation.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2407.08652/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">DART<span id="S3.F2.4.2.1" class="ltx_text ltx_font_upright"> within the DFL Procedure</span></span></figcaption>
</figure>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p"><span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_italic">FoolsGold</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">24</span></a>]</cite> is a gradient similarity-based anomaly detection method that aims to identify grouped adversaries. It utilizes the calculation of gradient cosine similarity to detect malicious attacks that exhibit high similarity. However, <span id="S3.SS2.SSS2.p3.1.2" class="ltx_text ltx_font_italic">FoolsGold</span> is ineffective against individual adversaries. <span id="S3.SS2.SSS2.p3.1.3" class="ltx_text ltx_font_italic">FLDetector</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">71</span></a>]</cite> predicts a client’s update by analyzing its past contributions. This defense mechanism has shown effectiveness against various adaptive attacks, such as scaling attacks, distributed backdoors, and untargeted model poisoning. However, the computational cost of predicting consistency is high. Another proposed defense mechanism suggested in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">35</span></a>]</cite> involves training a spectral anomaly detection model to identify malicious updates in a low-dimensional latent space. This approach trains an autoencoder model on benign model updates to detect anomalous models. However, selecting appropriate benign model updates for training the autoencoder model is crucial. <span id="S3.SS2.SSS2.p3.1.4" class="ltx_text ltx_font_italic">Sniper</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">11</span></a>]</cite>maps client updates into a graph-cluster using gradient similarity and effectively defends against poisoning attacks, but its performance is reduced in a more heterogeneous setting.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>MTD-based Techniques</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">MTD is an innovative security strategy that seeks to minimize the consequences of cyberattacks by actively or passively modifying specific system elements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">10</span></a>]</cite>. Proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">21</span></a>]</cite>, <span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">Voyager</span> is an MTD-based aggregation protocol that reactively alters the network topology to enhance the resilience of the DFL system. The <span id="S3.SS2.SSS3.p1.1.2" class="ltx_text ltx_font_italic">Voyager</span> protocol comprises three stages: an anomaly detector, a network topology explorer, and a connection deployer. The anomaly detector assesses the received models against shared models from other participants to identify any abnormal models, thereby triggering the MTD policy. The network topology explorer aims to identify more reliable participants. Lastly, the connection deployer establishes connections with these candidate participants and exchanges their respective models to create an aggregated model.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Hybrid Defense Techniques</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">Hybrid defenses combine robust aggregation and anomaly detection techniques. In the <span id="S3.SS2.SSS4.p1.1.1" class="ltx_text ltx_font_italic">FLTrust</span> approach  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">12</span></a>]</cite>, the server uses a clean dataset to train a reference model and compares it to received model updates using cosine similarity. These updates are then aggregated based on their trust scores. However, obtaining a root dataset may not be possible in a CFL architecture. <span id="S3.SS2.SSS4.p1.1.2" class="ltx_text ltx_font_italic">Trusted DFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">25</span></a>]</cite> introduces trusted aggregation in a decentralized architecture by evaluating nodes based on their behavior and update consistency. Each node shares its local trust score, enabling other nodes to compute a global trust score for aggregation. <span id="S3.SS2.SSS4.p1.1.3" class="ltx_text ltx_font_italic">FedInv</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">72</span></a>]</cite> addresses the limitations of <span id="S3.SS2.SSS4.p1.1.4" class="ltx_text ltx_font_italic">FLTrust</span> and <span id="S3.SS2.SSS4.p1.1.5" class="ltx_text ltx_font_italic">PDGAN</span> by using a privacy-preserving model inversion strategy to generate dummy data from clients’ gradient updates. These updates are scored based on distribution divergence and aggregated using majority clustering. However, the computational complexity of <span id="S3.SS2.SSS4.p1.1.6" class="ltx_text ltx_font_italic">FedInv</span> is currently being discussed.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2407.08652/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="741" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">Sequence Diagram Showing the Procedure of <span id="S3.F3.4.2.1" class="ltx_text ltx_font_italic">DART</span></span></figcaption>
</figure>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p"><span id="S3.SS2.SSS4.p2.1.1" class="ltx_text ltx_font_italic">Norm Clipping</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">46</span></a>]</cite> is a defense mechanism that limits the scale of model weights to protect against semantic backdoor attacks in CFL. However, it only considers the magnitude of an update and not its direction, making it difficult to determine an appropriate threshold. <span id="S3.SS2.SSS4.p2.1.2" class="ltx_text ltx_font_italic">DeepSight</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">51</span></a>]</cite> combines filtering and clipping to significantly reduce an attacker’s possibilities by analyzing the neural network structure and creating fingerprints. <span id="S3.SS2.SSS4.p2.1.3" class="ltx_text ltx_font_italic">DeepSight</span> is effective but computationally complex. <span id="S3.SS2.SSS4.p2.1.4" class="ltx_text ltx_font_italic">FLAME</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">43</span></a>]</cite> proposes a hybrid approach using dynamic clustering, adaptive clipping, and noising. Client updates are clustered based on similarity, filtered for outliers, and then clipped. The aggregated model is smoothed using adaptive noising. However, <span id="S3.SS2.SSS4.p2.1.5" class="ltx_text ltx_font_italic">FLAME</span> fails when the number of attackers exceeds half of the cluster.</p>
</div>
<div id="S3.SS2.SSS4.p3" class="ltx_para">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p"><span id="S3.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_italic">Sentinel</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">19</span></a>]</cite> is a hybrid defense strategy to enhance the resilience of DFL against poisoning attacks. It introduces a three-phase aggregation protocol to strengthen security measures. In the first phase, a layer-wise average cosine similarity metric is used to identify and filter out suspicious model updates. The remaining updates are then aggregated based on local bootstrap validation loss, with aggregation weights determined through adaptive loss distance mapping. In the final phase, trusted models are normalized using the local model norm as a threshold to minimize the impact of potential stealth attacks.</p>
</div>
</section>
<section id="S3.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.5 </span>Post-Aggregation Techniques</h4>

<div id="S3.SS2.SSS5.p1" class="ltx_para">
<p id="S3.SS2.SSS5.p1.1" class="ltx_p">Post-aggregation techniques refer to approaches that do not disrupt the process of aggregation. Instead, modifications to model updates are made after the aggregation has taken place. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">61</span></a>]</cite> proposed a method to defend against backdoor attacks in the CFL setting. They use neuron pruning to identify and deactivate maliciously activated neurons during an attack. Clients submit voting sequences based on their averaged activation values, and the server aggregates these votes to determine which neurons to prune. To enhance the defense, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">55</span></a>]</cite> suggested incorporating weak differential privacy using Gaussian noise. Adding even small amounts of noise can protect against attacks, but it may decrease the accuracy of the main task. However, determining the right amount of noise to add is challenging.</p>
</div>
<div id="S3.SS2.SSS5.p2" class="ltx_para">
<p id="S3.SS2.SSS5.p2.1" class="ltx_p">Overall, a significant amount of ongoing research is focused on enhancing the robustness of the FL systems model. However, most of the research focuses on CFL and does not consider DFL’s unique characteristics. These studies also have limitations, such as being computationally complex and sensitive to data distribution.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_italic">DART</span> Solution</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section bridges the research gap highlighted in the previous section by designing and implementing a robustness analysis module for DFL systems. This module enables analysis of the robustness of DFL models when confronted with poisoning attacks and evaluation of the effectiveness of various defense mechanisms.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Design of the <span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">DART</span> module</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In general, the training procedure of a DFL model can be divided into four stages, as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2.2 Anomaly Detection ‣ 3.2 Defense Mechanisms ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Initially, on the DFL platform, the user establishes the fundamental configuration of the federation, including the desired number of participants, the dataset to be used for training, the client interconnection topology, or the number of rounds of aggregation. After that, the user-defined configuration is transformed into specific bootstrapping for each individual node, encompassing details such as the actual training samples for each node, the neighbors to which they are connected, and the specific model architecture. With this configuration information, nodes start local model training while establishing communication channels with their neighboring nodes. Once the local model training is finished, each node exchanges and aggregates its respective models. These local training and model aggregation processes are repeated until the model reaches convergence or reaches a predetermined number of aggregation rounds.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">However, this procedure lacks consideration for the robustness analysis of the DFL model, meaning users cannot customize and execute poisoning attacks or select and implement defense mechanisms. Therefore, this study proposes the <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">DART</span> module, consisting of two components: the attack component (highlighted red in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2.2 Anomaly Detection ‣ 3.2 Defense Mechanisms ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) and the defense component (highlighted green in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2.2 Anomaly Detection ‣ 3.2 Defense Mechanisms ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). When defining the desired federation, users can choose the type of poisoning attack they wish to deploy. Depending on whether the user wants to evaluate only the robustness of the DFL model or to assess the effectiveness of the defenses against poisoning attacks, the user can choose to deploy a defense mechanism. During the bootstrapping phase, the benign node selects the defense mechanism while the malicious node chooses the desired poisoning attack. In the model training node, the malicious node trains the poisoned model and the benign node trains the uninfected model. During the aggregation phase, the benign node implements defenses to filter or mitigate attacks from the malicious node.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2407.08652/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="213" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.4.2" class="ltx_text" style="font-size:90%;">Attack Component of <span id="S4.F4.4.2.1" class="ltx_text ltx_font_italic">DART</span></span></figcaption>
</figure>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Specifically, as depicted in the sequence diagram shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2.4 Hybrid Defense Techniques ‣ 3.2 Defense Mechanisms ‣ 3 Poisoning Attacks and Defense Mechanisms ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, upon selecting the DFL scenario in the frontend interface, the user could also choose the desired attack and defense settings to be executed. These configuration parameters are then communicated to the controller through the REST API. Subsequently, the controller writes these configuration parameters to the bootstrap items of each node, specifying which nodes are functioning as benign nodes and which are operating as malicious nodes. The core creates instances of the nodes based on their respective configuration parameters and starts executing the scenario. A normal dataset is provided for benign nodes to train the local model, which is then shared with neighboring nodes. In contrast, malicious nodes are supplied with poisoned data and either train a malicious model through data poisoning or directly tamper with the trained local model through model poisoning, transmitting the malicious model to neighboring nodes. Next, the node follows the robust aggregation algorithm chosen in the configuration for model aggregation, proceeding to the next round of the scenario execution loop.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">DART</span> Module in <span id="S4.SS2.2.2" class="ltx_text ltx_font_italic">Fedstellar</span> Platform</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">Fedstellar</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">4</span></a>]</cite> is a DFL platform that provides a user-friendly interface to easily deploy and train DFL models. Therefore, this paper adopts <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">Fedstellar</span> as the infrastructure and incorporates a model robustness analysis module, called <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">DART</span>. As shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Implementation of DART ‣ 4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">Fedstellar</span> consists of three layers, the frontend, the controller, and the core, corresponding to the four steps of the DFL model training process.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">Frontend</span>. This layer corresponds to the federation setup step and enables the user and system interaction, allowing the user to personalize their own FL scenario through diverse configurations. Moreover, the system provides real-time monitoring functionalities, including the tracking of resource usage and model performance during the training process. Building upon this layer, <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">DART</span> provides the option to choose attacks and defense mechanisms.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">Controller</span>. This layer corresponds to the bootstrapping step and functions as the central hub of the platform. It receives user configurations from the frontend, manages the federated scenario, selects appropriate learning algorithms and datasets, and establishes network connections to enable a FL process. The attack and defense are specified within this layer.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">Core</span>. This layer corresponds to the training and aggregation steps. Its operations entail data preparation, model training, ensuring secure communication among participants, and storing the federated models. Therefore, this layer encompasses the primary functionality of <span id="S4.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">DART</span>, including the deployment and execution of attacks and defenses.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2407.08652/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="213" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">Defense Component of <span id="S4.F5.4.2.1" class="ltx_text ltx_font_italic">DART</span></span></figcaption>
</figure>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span><span id="S4.SS2.SSS1.1.1" class="ltx_text ltx_font_italic">DART</span>: Attack Component</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">DART</span> attack component consists of three parts, as illustrated in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 Design of the DART module ‣ 4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The process includes four steps; first, when the user selects the DFL configuration in the Frontend, the user can also select the attack definitions, such as what type of attack is performed, the percentage of nodes to be attacked, and the percentage of noise injection. These configurations are transmitted to the Controller as JSON files. The Controller then sets up specific attacks in the nodes based on these attack configurations, such as which nodes are configured as malicious nodes and what attack strategies these nodes use.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">The Controller utilizes this attack information along with other configurations to bootstrap the node’s operation. In the fourth step, the Core starts the execution of these attacks. These attacks encompass two parts: one involves manipulating the data, such as altering the training data of the model to facilitate a data poisoning attack, while the other entails directly modifying the model, known as a model poisoning attack. The attack component of <span id="S4.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_italic">DART</span> integrates the following poisoning attacks: Untargeted Label Flipping, Untargeted Sample Poisoning, Random Model Poisoning, Targeted Label Flipping, and Backdoor Attack.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span><span id="S4.SS2.SSS2.1.1" class="ltx_text ltx_font_italic">DART</span>: Defense Component</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">Similarly to the previous component, the <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">DART</span> defense component is incorporated within the three layers of <span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Fedstellar</span> and operates based on the same underlying principles, as shown in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2 DART Module in Fedstellar Platform ‣ 4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Firstly, the user operating the Frontend chooses the specific defense mechanism that they wish to evaluate. In the second step, these configurations are transmitted to the backend Controller as JSON files. In the third step, the Controller converts these configurations into bootstrap for the node, including which defense mechanisms to employ. In the fourth step, the Core starts to train the local model, as well as run the defense mechanisms to protect its model from malicious models. The defense component incorporates a range of defense mechanisms, namely <span id="S4.SS2.SSS2.p1.1.3" class="ltx_text ltx_font_italic">Krum</span>, <span id="S4.SS2.SSS2.p1.1.4" class="ltx_text ltx_font_italic">Median</span>, <span id="S4.SS2.SSS2.p1.1.5" class="ltx_text ltx_font_italic">TrimmedMean</span>, <span id="S4.SS2.SSS2.p1.1.6" class="ltx_text ltx_font_italic">FLTrust</span>, <span id="S4.SS2.SSS2.p1.1.7" class="ltx_text ltx_font_italic">Sentinel</span>, and the MTD-based <span id="S4.SS2.SSS2.p1.1.8" class="ltx_text ltx_font_italic">Voyager</span>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation of <span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">DART</span>
</h3>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2407.08652/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="248" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.4.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.5.2" class="ltx_text" style="font-size:90%;">Integration of <span id="S4.F6.5.2.1" class="ltx_text ltx_font_italic">DART</span> Module in <span id="S4.F6.5.2.2" class="ltx_text ltx_font_italic">Fedstellar</span> Platform</span></figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Implementation of DART ‣ 4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the implementation and integration of DART within the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">Fedstellar</span> platform. <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">Fedstellar</span> provides the fundamental DFL scenario configuration elements on the frontend, while <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">DART</span> enhances this by introducing the option for malicious attacks and defense mechanisms. Users are able to select which attacks to execute and determine the ratio of malicious nodes within the federation. Additionally, users can choose from various robust aggregation functions for defense, such as <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_italic">Krum</span> and <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_italic">TrimmedMean</span>. The frontend of <span id="S4.SS3.p1.1.6" class="ltx_text ltx_font_italic">DART</span> is developed using the Flask framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">22</span></a>]</cite>, with user selections communicated to the backend controller through the REST API.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">The controller generates bootstrapping details for each node based on the user’s selections, encompassing network settings, neighbor connections, and datasets. <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">DART</span> adds configuration specifics for attacks and defenses. Malicious nodes are configured with attack settings, while benign nodes are designated as "no attack". The chosen robust aggregation function for defense is incorporated into the node’s bootstrap as the model aggregation algorithm. Configuration details for each node are stored in JSON format on the file system to facilitate node bootstrap and are also transmitted to the core system through REST API.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.3.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> <span id="alg1.4.2" class="ltx_text ltx_font_italic">DART</span> PROCESS IN EACH NODE</figcaption>
<div id="alg1.5" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><math id="alg1.l1.m1.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.l1.m1.1a"><msub id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">D</mi><mi mathsize="90%" id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">𝐷</ci><ci id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">D_{i}</annotation></semantics></math><span id="alg1.l1.2" class="ltx_text" style="font-size:90%;">: Local Dataset, </span><math id="alg1.l1.m2.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="alg1.l1.m2.1a"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\mathcal{F}</annotation></semantics></math><span id="alg1.l1.3" class="ltx_text" style="font-size:90%;">: Model Training, </span><math id="alg1.l1.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="alg1.l1.m3.1a"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">\mathcal{A}</annotation></semantics></math><span id="alg1.l1.4" class="ltx_text" style="font-size:90%;">: Aggregation Function, </span><math id="alg1.l1.m4.1" class="ltx_Math" alttext="P" display="inline"><semantics id="alg1.l1.m4.1a"><mi mathsize="90%" id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">P</annotation></semantics></math><span id="alg1.l1.5" class="ltx_text" style="font-size:90%;">: Neighbor List, </span><math id="alg1.l1.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="alg1.l1.m5.1a"><mi mathsize="90%" id="alg1.l1.m5.1.1" xref="alg1.l1.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m5.1b"><ci id="alg1.l1.m5.1.1.cmml" xref="alg1.l1.m5.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m5.1c">R</annotation></semantics></math><span id="alg1.l1.6" class="ltx_text" style="font-size:90%;">: Total Rounds, </span><math id="alg1.l1.m6.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="alg1.l1.m6.1a"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m6.1.1" xref="alg1.l1.m6.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m6.1b"><ci id="alg1.l1.m6.1.1.cmml" xref="alg1.l1.m6.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m6.1c">\mathcal{T}</annotation></semantics></math><span id="alg1.l1.7" class="ltx_text" style="font-size:90%;">: Model Transmission, </span><math id="alg1.l1.m7.1" class="ltx_Math" alttext="\mathcal{DP}" display="inline"><semantics id="alg1.l1.m7.1a"><mrow id="alg1.l1.m7.1.1" xref="alg1.l1.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m7.1.1.2" xref="alg1.l1.m7.1.1.2.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="alg1.l1.m7.1.1.1" xref="alg1.l1.m7.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m7.1.1.3" xref="alg1.l1.m7.1.1.3.cmml">𝒫</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m7.1b"><apply id="alg1.l1.m7.1.1.cmml" xref="alg1.l1.m7.1.1"><times id="alg1.l1.m7.1.1.1.cmml" xref="alg1.l1.m7.1.1.1"></times><ci id="alg1.l1.m7.1.1.2.cmml" xref="alg1.l1.m7.1.1.2">𝒟</ci><ci id="alg1.l1.m7.1.1.3.cmml" xref="alg1.l1.m7.1.1.3">𝒫</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m7.1c">\mathcal{DP}</annotation></semantics></math><span id="alg1.l1.8" class="ltx_text" style="font-size:90%;">: Data Poisoning, </span><math id="alg1.l1.m8.1" class="ltx_Math" alttext="\mathcal{MP}" display="inline"><semantics id="alg1.l1.m8.1a"><mrow id="alg1.l1.m8.1.1" xref="alg1.l1.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m8.1.1.2" xref="alg1.l1.m8.1.1.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="alg1.l1.m8.1.1.1" xref="alg1.l1.m8.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l1.m8.1.1.3" xref="alg1.l1.m8.1.1.3.cmml">𝒫</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m8.1b"><apply id="alg1.l1.m8.1.1.cmml" xref="alg1.l1.m8.1.1"><times id="alg1.l1.m8.1.1.1.cmml" xref="alg1.l1.m8.1.1.1"></times><ci id="alg1.l1.m8.1.1.2.cmml" xref="alg1.l1.m8.1.1.2">ℳ</ci><ci id="alg1.l1.m8.1.1.3.cmml" xref="alg1.l1.m8.1.1.3">𝒫</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m8.1c">\mathcal{MP}</annotation></semantics></math><span id="alg1.l1.9" class="ltx_text" style="font-size:90%;">: Model Poisoning.
</span>
</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span><math id="alg1.l2.m1.1" class="ltx_Math" alttext="r\leftarrow" display="inline"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">r</mi><mo mathsize="90%" stretchy="false" id="alg1.l2.m1.1.1.1" xref="alg1.l2.m1.1.1.1.cmml">←</mo><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><ci id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1">←</ci><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝑟</ci><csymbol cd="latexml" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">r\leftarrow</annotation></semantics></math><span id="alg1.l2.2" class="ltx_text" style="font-size:90%;"> 0
</span>
</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span><math id="alg1.l3.m1.1" class="ltx_Math" alttext="m_{i}\leftarrow" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><msub id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">m</mi><mi mathsize="90%" id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">←</mo><mi id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">←</ci><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">𝑚</ci><ci id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">𝑖</ci></apply><csymbol cd="latexml" id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">m_{i}\leftarrow</annotation></semantics></math><span id="alg1.l3.2" class="ltx_text" style="font-size:90%;"> Local Model
</span>
</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span><math id="alg1.l4.m1.1" class="ltx_Math" alttext="M_{i}\leftarrow" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><msub id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">M</mi><mi mathsize="90%" id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">←</mo><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">←</ci><apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">𝑀</ci><ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">𝑖</ci></apply><csymbol cd="latexml" id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">M_{i}\leftarrow</annotation></semantics></math><span id="alg1.l4.2" class="ltx_text" style="font-size:90%;"> Neighbor Model List
</span>
</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.2.1.1" class="ltx_text" style="font-size:80%;">5:</span></span><span id="alg1.l5.3" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span><span id="alg1.l5.4" class="ltx_text" style="font-size:90%;"> Data Poisoning </span><span id="alg1.l5.5" class="ltx_text ltx_font_bold" style="font-size:90%;">then</span><span id="alg1.l5.6" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l5.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l5.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l5.1.m1.1a"><mo id="alg1.l5.1.m1.1.1" xref="alg1.l5.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l5.1.m1.1b"><ci id="alg1.l5.1.m1.1.1.cmml" xref="alg1.l5.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.1.m1.1c">\triangleright</annotation></semantics></math> Poison Local Dataset
</span>
</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span><span id="alg1.l6.2" class="ltx_text" style="font-size:90%;">    </span><math id="alg1.l6.m1.1" class="ltx_Math" alttext="D_{i}\leftarrow\mathcal{DP}(D_{i})" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msub id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">D</mi><mi mathsize="90%" id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">←</mo><mrow id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l6.m1.1.1.1.3" xref="alg1.l6.m1.1.1.1.3.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.1.1.1.2" xref="alg1.l6.m1.1.1.1.2.cmml">​</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l6.m1.1.1.1.4" xref="alg1.l6.m1.1.1.1.4.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.1.1.1.2a" xref="alg1.l6.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l6.m1.1.1.1.1.1" xref="alg1.l6.m1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l6.m1.1.1.1.1.1.2" xref="alg1.l6.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l6.m1.1.1.1.1.1.1" xref="alg1.l6.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l6.m1.1.1.1.1.1.1.2" xref="alg1.l6.m1.1.1.1.1.1.1.2.cmml">D</mi><mi mathsize="90%" id="alg1.l6.m1.1.1.1.1.1.1.3" xref="alg1.l6.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="alg1.l6.m1.1.1.1.1.1.3" xref="alg1.l6.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">←</ci><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3">subscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">𝐷</ci><ci id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">𝑖</ci></apply><apply id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"><times id="alg1.l6.m1.1.1.1.2.cmml" xref="alg1.l6.m1.1.1.1.2"></times><ci id="alg1.l6.m1.1.1.1.3.cmml" xref="alg1.l6.m1.1.1.1.3">𝒟</ci><ci id="alg1.l6.m1.1.1.1.4.cmml" xref="alg1.l6.m1.1.1.1.4">𝒫</ci><apply id="alg1.l6.m1.1.1.1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l6.m1.1.1.1.1.1.1.2">𝐷</ci><ci id="alg1.l6.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l6.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">D_{i}\leftarrow\mathcal{DP}(D_{i})</annotation></semantics></math><span id="alg1.l6.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span><span id="alg1.l7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l7.3" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l7.4" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span><span id="alg1.l8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l8.3" class="ltx_text" style="font-size:90%;"> </span><math id="alg1.l8.m1.1" class="ltx_Math" alttext="r\leq R" display="inline"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml">r</mi><mo mathsize="90%" id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">≤</mo><mi mathsize="90%" id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><leq id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1"></leq><ci id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2">𝑟</ci><ci id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">r\leq R</annotation></semantics></math><span id="alg1.l8.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l8.5" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l8.6" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span><span id="alg1.l9.2" class="ltx_text" style="font-size:90%;">    </span><math id="alg1.l9.m1.1" class="ltx_Math" alttext="M_{i}\leftarrow[\ ]" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msub id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi mathsize="90%" id="alg1.l9.m1.1.1.2.2" xref="alg1.l9.m1.1.1.2.2.cmml">M</mi><mi mathsize="90%" id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">←</mo><mrow id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.cmml"><mo maxsize="90%" minsize="90%" rspace="0.450em" id="alg1.l9.m1.1.1.3.2.1" xref="alg1.l9.m1.1.1.3.1.cmml">[</mo><mo maxsize="90%" minsize="90%" id="alg1.l9.m1.1.1.3.2.2" xref="alg1.l9.m1.1.1.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><ci id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1">←</ci><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">𝑀</ci><ci id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3">𝑖</ci></apply><list id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">M_{i}\leftarrow[\ ]</annotation></semantics></math><span id="alg1.l9.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.2.1.1" class="ltx_text" style="font-size:80%;">10:</span></span><span id="alg1.l10.3" class="ltx_text" style="font-size:90%;">    </span><math id="alg1.l10.m1.2" class="ltx_Math" alttext="m_{i}\leftarrow\mathcal{F}(D_{i},m_{i})" display="inline"><semantics id="alg1.l10.m1.2a"><mrow id="alg1.l10.m1.2.2" xref="alg1.l10.m1.2.2.cmml"><msub id="alg1.l10.m1.2.2.4" xref="alg1.l10.m1.2.2.4.cmml"><mi mathsize="90%" id="alg1.l10.m1.2.2.4.2" xref="alg1.l10.m1.2.2.4.2.cmml">m</mi><mi mathsize="90%" id="alg1.l10.m1.2.2.4.3" xref="alg1.l10.m1.2.2.4.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l10.m1.2.2.3" xref="alg1.l10.m1.2.2.3.cmml">←</mo><mrow id="alg1.l10.m1.2.2.2" xref="alg1.l10.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l10.m1.2.2.2.4" xref="alg1.l10.m1.2.2.2.4.cmml">ℱ</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.2.2.2.3" xref="alg1.l10.m1.2.2.2.3.cmml">​</mo><mrow id="alg1.l10.m1.2.2.2.2.2" xref="alg1.l10.m1.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l10.m1.2.2.2.2.2.3" xref="alg1.l10.m1.2.2.2.2.3.cmml">(</mo><msub id="alg1.l10.m1.1.1.1.1.1.1" xref="alg1.l10.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l10.m1.1.1.1.1.1.1.2" xref="alg1.l10.m1.1.1.1.1.1.1.2.cmml">D</mi><mi mathsize="90%" id="alg1.l10.m1.1.1.1.1.1.1.3" xref="alg1.l10.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="alg1.l10.m1.2.2.2.2.2.4" xref="alg1.l10.m1.2.2.2.2.3.cmml">,</mo><msub id="alg1.l10.m1.2.2.2.2.2.2" xref="alg1.l10.m1.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="alg1.l10.m1.2.2.2.2.2.2.2" xref="alg1.l10.m1.2.2.2.2.2.2.2.cmml">m</mi><mi mathsize="90%" id="alg1.l10.m1.2.2.2.2.2.2.3" xref="alg1.l10.m1.2.2.2.2.2.2.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="alg1.l10.m1.2.2.2.2.2.5" xref="alg1.l10.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.2b"><apply id="alg1.l10.m1.2.2.cmml" xref="alg1.l10.m1.2.2"><ci id="alg1.l10.m1.2.2.3.cmml" xref="alg1.l10.m1.2.2.3">←</ci><apply id="alg1.l10.m1.2.2.4.cmml" xref="alg1.l10.m1.2.2.4"><csymbol cd="ambiguous" id="alg1.l10.m1.2.2.4.1.cmml" xref="alg1.l10.m1.2.2.4">subscript</csymbol><ci id="alg1.l10.m1.2.2.4.2.cmml" xref="alg1.l10.m1.2.2.4.2">𝑚</ci><ci id="alg1.l10.m1.2.2.4.3.cmml" xref="alg1.l10.m1.2.2.4.3">𝑖</ci></apply><apply id="alg1.l10.m1.2.2.2.cmml" xref="alg1.l10.m1.2.2.2"><times id="alg1.l10.m1.2.2.2.3.cmml" xref="alg1.l10.m1.2.2.2.3"></times><ci id="alg1.l10.m1.2.2.2.4.cmml" xref="alg1.l10.m1.2.2.2.4">ℱ</ci><interval closure="open" id="alg1.l10.m1.2.2.2.2.3.cmml" xref="alg1.l10.m1.2.2.2.2.2"><apply id="alg1.l10.m1.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l10.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l10.m1.1.1.1.1.1.1.2">𝐷</ci><ci id="alg1.l10.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l10.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="alg1.l10.m1.2.2.2.2.2.2.cmml" xref="alg1.l10.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l10.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l10.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l10.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l10.m1.2.2.2.2.2.2.2">𝑚</ci><ci id="alg1.l10.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l10.m1.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.2c">m_{i}\leftarrow\mathcal{F}(D_{i},m_{i})</annotation></semantics></math><span id="alg1.l10.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l10.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l10.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l10.1.m1.1a"><mo id="alg1.l10.1.m1.1.1" xref="alg1.l10.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l10.1.m1.1b"><ci id="alg1.l10.1.m1.1.1.cmml" xref="alg1.l10.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.1.m1.1c">\triangleright</annotation></semantics></math> Local Model Training
</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.2.1.1" class="ltx_text" style="font-size:80%;">11:</span></span><span id="alg1.l11.3" class="ltx_text" style="font-size:90%;">    </span><span id="alg1.l11.4" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span><span id="alg1.l11.5" class="ltx_text" style="font-size:90%;"> Model Poisoning </span><span id="alg1.l11.6" class="ltx_text ltx_font_bold" style="font-size:90%;">then</span><span id="alg1.l11.7" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l11.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l11.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l11.1.m1.1a"><mo id="alg1.l11.1.m1.1.1" xref="alg1.l11.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l11.1.m1.1b"><ci id="alg1.l11.1.m1.1.1.cmml" xref="alg1.l11.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.1.m1.1c">\triangleright</annotation></semantics></math> Poison Local Model
</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span><span id="alg1.l12.2" class="ltx_text" style="font-size:90%;">         </span><math id="alg1.l12.m1.1" class="ltx_Math" alttext="M_{i}\leftarrow\mathcal{MP}(M_{i})" display="inline"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><msub id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l12.m1.1.1.3.2" xref="alg1.l12.m1.1.1.3.2.cmml">M</mi><mi mathsize="90%" id="alg1.l12.m1.1.1.3.3" xref="alg1.l12.m1.1.1.3.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml">←</mo><mrow id="alg1.l12.m1.1.1.1" xref="alg1.l12.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l12.m1.1.1.1.3" xref="alg1.l12.m1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.1.2" xref="alg1.l12.m1.1.1.1.2.cmml">​</mo><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l12.m1.1.1.1.4" xref="alg1.l12.m1.1.1.1.4.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.1.2a" xref="alg1.l12.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l12.m1.1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l12.m1.1.1.1.1.1.2" xref="alg1.l12.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l12.m1.1.1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l12.m1.1.1.1.1.1.1.2" xref="alg1.l12.m1.1.1.1.1.1.1.2.cmml">M</mi><mi mathsize="90%" id="alg1.l12.m1.1.1.1.1.1.1.3" xref="alg1.l12.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="alg1.l12.m1.1.1.1.1.1.3" xref="alg1.l12.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><ci id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2">←</ci><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3">subscript</csymbol><ci id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3.2">𝑀</ci><ci id="alg1.l12.m1.1.1.3.3.cmml" xref="alg1.l12.m1.1.1.3.3">𝑖</ci></apply><apply id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1"><times id="alg1.l12.m1.1.1.1.2.cmml" xref="alg1.l12.m1.1.1.1.2"></times><ci id="alg1.l12.m1.1.1.1.3.cmml" xref="alg1.l12.m1.1.1.1.3">ℳ</ci><ci id="alg1.l12.m1.1.1.1.4.cmml" xref="alg1.l12.m1.1.1.1.4">𝒫</ci><apply id="alg1.l12.m1.1.1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l12.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l12.m1.1.1.1.1.1.1.2">𝑀</ci><ci id="alg1.l12.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l12.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">M_{i}\leftarrow\mathcal{MP}(M_{i})</annotation></semantics></math><span id="alg1.l12.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span><span id="alg1.l13.2" class="ltx_text" style="font-size:90%;">    </span><span id="alg1.l13.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l13.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l13.5" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.2.1.1" class="ltx_text" style="font-size:80%;">14:</span></span><span id="alg1.l14.3" class="ltx_text" style="font-size:90%;">    </span><math id="alg1.l14.m1.2" class="ltx_Math" alttext="\mathcal{T}(M_{i},P)" display="inline"><semantics id="alg1.l14.m1.2a"><mrow id="alg1.l14.m1.2.2" xref="alg1.l14.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l14.m1.2.2.3" xref="alg1.l14.m1.2.2.3.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="alg1.l14.m1.2.2.2" xref="alg1.l14.m1.2.2.2.cmml">​</mo><mrow id="alg1.l14.m1.2.2.1.1" xref="alg1.l14.m1.2.2.1.2.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l14.m1.2.2.1.1.2" xref="alg1.l14.m1.2.2.1.2.cmml">(</mo><msub id="alg1.l14.m1.2.2.1.1.1" xref="alg1.l14.m1.2.2.1.1.1.cmml"><mi mathsize="90%" id="alg1.l14.m1.2.2.1.1.1.2" xref="alg1.l14.m1.2.2.1.1.1.2.cmml">M</mi><mi mathsize="90%" id="alg1.l14.m1.2.2.1.1.1.3" xref="alg1.l14.m1.2.2.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="alg1.l14.m1.2.2.1.1.3" xref="alg1.l14.m1.2.2.1.2.cmml">,</mo><mi mathsize="90%" id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">P</mi><mo maxsize="90%" minsize="90%" id="alg1.l14.m1.2.2.1.1.4" xref="alg1.l14.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.2b"><apply id="alg1.l14.m1.2.2.cmml" xref="alg1.l14.m1.2.2"><times id="alg1.l14.m1.2.2.2.cmml" xref="alg1.l14.m1.2.2.2"></times><ci id="alg1.l14.m1.2.2.3.cmml" xref="alg1.l14.m1.2.2.3">𝒯</ci><interval closure="open" id="alg1.l14.m1.2.2.1.2.cmml" xref="alg1.l14.m1.2.2.1.1"><apply id="alg1.l14.m1.2.2.1.1.1.cmml" xref="alg1.l14.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l14.m1.2.2.1.1.1.1.cmml" xref="alg1.l14.m1.2.2.1.1.1">subscript</csymbol><ci id="alg1.l14.m1.2.2.1.1.1.2.cmml" xref="alg1.l14.m1.2.2.1.1.1.2">𝑀</ci><ci id="alg1.l14.m1.2.2.1.1.1.3.cmml" xref="alg1.l14.m1.2.2.1.1.1.3">𝑖</ci></apply><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">𝑃</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.2c">\mathcal{T}(M_{i},P)</annotation></semantics></math><span id="alg1.l14.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l14.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l14.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l14.1.m1.1a"><mo id="alg1.l14.1.m1.1.1" xref="alg1.l14.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l14.1.m1.1b"><ci id="alg1.l14.1.m1.1.1.cmml" xref="alg1.l14.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.1.m1.1c">\triangleright</annotation></semantics></math> Transmit Local Model to Neighbors
</span>
</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.2.1.1" class="ltx_text" style="font-size:80%;">15:</span></span><span id="alg1.l15.3" class="ltx_text" style="font-size:90%;">    </span><span id="alg1.l15.4" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l15.5" class="ltx_text" style="font-size:90%;"> </span><math id="alg1.l15.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="alg1.l15.m1.1a"><mi mathsize="90%" id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><ci id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">j</annotation></semantics></math><span id="alg1.l15.6" class="ltx_text" style="font-size:90%;"> in </span><math id="alg1.l15.m2.1" class="ltx_Math" alttext="P" display="inline"><semantics id="alg1.l15.m2.1a"><mi mathsize="90%" id="alg1.l15.m2.1.1" xref="alg1.l15.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="alg1.l15.m2.1b"><ci id="alg1.l15.m2.1.1.cmml" xref="alg1.l15.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m2.1c">P</annotation></semantics></math><span id="alg1.l15.7" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l15.8" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l15.9" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l15.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l15.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l15.1.m1.1a"><mo id="alg1.l15.1.m1.1.1" xref="alg1.l15.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l15.1.m1.1b"><ci id="alg1.l15.1.m1.1.1.cmml" xref="alg1.l15.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.1.m1.1c">\triangleright</annotation></semantics></math> Receive Models from Neighbors
</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span><span id="alg1.l16.2" class="ltx_text" style="font-size:90%;">         </span><math id="alg1.l16.m1.1" class="ltx_Math" alttext="M_{i}\leftarrow M_{i}\cup\{e\}" display="inline"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.2" xref="alg1.l16.m1.1.2.cmml"><msub id="alg1.l16.m1.1.2.2" xref="alg1.l16.m1.1.2.2.cmml"><mi mathsize="90%" id="alg1.l16.m1.1.2.2.2" xref="alg1.l16.m1.1.2.2.2.cmml">M</mi><mi mathsize="90%" id="alg1.l16.m1.1.2.2.3" xref="alg1.l16.m1.1.2.2.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l16.m1.1.2.1" xref="alg1.l16.m1.1.2.1.cmml">←</mo><mrow id="alg1.l16.m1.1.2.3" xref="alg1.l16.m1.1.2.3.cmml"><msub id="alg1.l16.m1.1.2.3.2" xref="alg1.l16.m1.1.2.3.2.cmml"><mi mathsize="90%" id="alg1.l16.m1.1.2.3.2.2" xref="alg1.l16.m1.1.2.3.2.2.cmml">M</mi><mi mathsize="90%" id="alg1.l16.m1.1.2.3.2.3" xref="alg1.l16.m1.1.2.3.2.3.cmml">i</mi></msub><mo mathsize="90%" id="alg1.l16.m1.1.2.3.1" xref="alg1.l16.m1.1.2.3.1.cmml">∪</mo><mrow id="alg1.l16.m1.1.2.3.3.2" xref="alg1.l16.m1.1.2.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.1.2.3.3.2.1" xref="alg1.l16.m1.1.2.3.3.1.cmml">{</mo><mi mathsize="90%" id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">e</mi><mo maxsize="90%" minsize="90%" id="alg1.l16.m1.1.2.3.3.2.2" xref="alg1.l16.m1.1.2.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.2.cmml" xref="alg1.l16.m1.1.2"><ci id="alg1.l16.m1.1.2.1.cmml" xref="alg1.l16.m1.1.2.1">←</ci><apply id="alg1.l16.m1.1.2.2.cmml" xref="alg1.l16.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.2.2.1.cmml" xref="alg1.l16.m1.1.2.2">subscript</csymbol><ci id="alg1.l16.m1.1.2.2.2.cmml" xref="alg1.l16.m1.1.2.2.2">𝑀</ci><ci id="alg1.l16.m1.1.2.2.3.cmml" xref="alg1.l16.m1.1.2.2.3">𝑖</ci></apply><apply id="alg1.l16.m1.1.2.3.cmml" xref="alg1.l16.m1.1.2.3"><union id="alg1.l16.m1.1.2.3.1.cmml" xref="alg1.l16.m1.1.2.3.1"></union><apply id="alg1.l16.m1.1.2.3.2.cmml" xref="alg1.l16.m1.1.2.3.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.2.3.2.1.cmml" xref="alg1.l16.m1.1.2.3.2">subscript</csymbol><ci id="alg1.l16.m1.1.2.3.2.2.cmml" xref="alg1.l16.m1.1.2.3.2.2">𝑀</ci><ci id="alg1.l16.m1.1.2.3.2.3.cmml" xref="alg1.l16.m1.1.2.3.2.3">𝑖</ci></apply><set id="alg1.l16.m1.1.2.3.3.1.cmml" xref="alg1.l16.m1.1.2.3.3.2"><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">𝑒</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">M_{i}\leftarrow M_{i}\cup\{e\}</annotation></semantics></math><span id="alg1.l16.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span><span id="alg1.l17.2" class="ltx_text" style="font-size:90%;">    </span><span id="alg1.l17.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l17.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l17.5" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.2.1.1" class="ltx_text" style="font-size:80%;">18:</span></span><span id="alg1.l18.3" class="ltx_text" style="font-size:90%;">    </span><math id="alg1.l18.m1.2" class="ltx_Math" alttext="m_{i}\leftarrow\mathcal{A}(m_{i},M_{i})" display="inline"><semantics id="alg1.l18.m1.2a"><mrow id="alg1.l18.m1.2.2" xref="alg1.l18.m1.2.2.cmml"><msub id="alg1.l18.m1.2.2.4" xref="alg1.l18.m1.2.2.4.cmml"><mi mathsize="90%" id="alg1.l18.m1.2.2.4.2" xref="alg1.l18.m1.2.2.4.2.cmml">m</mi><mi mathsize="90%" id="alg1.l18.m1.2.2.4.3" xref="alg1.l18.m1.2.2.4.3.cmml">i</mi></msub><mo mathsize="90%" stretchy="false" id="alg1.l18.m1.2.2.3" xref="alg1.l18.m1.2.2.3.cmml">←</mo><mrow id="alg1.l18.m1.2.2.2" xref="alg1.l18.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="alg1.l18.m1.2.2.2.4" xref="alg1.l18.m1.2.2.2.4.cmml">𝒜</mi><mo lspace="0em" rspace="0em" id="alg1.l18.m1.2.2.2.3" xref="alg1.l18.m1.2.2.2.3.cmml">​</mo><mrow id="alg1.l18.m1.2.2.2.2.2" xref="alg1.l18.m1.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="alg1.l18.m1.2.2.2.2.2.3" xref="alg1.l18.m1.2.2.2.2.3.cmml">(</mo><msub id="alg1.l18.m1.1.1.1.1.1.1" xref="alg1.l18.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="alg1.l18.m1.1.1.1.1.1.1.2" xref="alg1.l18.m1.1.1.1.1.1.1.2.cmml">m</mi><mi mathsize="90%" id="alg1.l18.m1.1.1.1.1.1.1.3" xref="alg1.l18.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="alg1.l18.m1.2.2.2.2.2.4" xref="alg1.l18.m1.2.2.2.2.3.cmml">,</mo><msub id="alg1.l18.m1.2.2.2.2.2.2" xref="alg1.l18.m1.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="alg1.l18.m1.2.2.2.2.2.2.2" xref="alg1.l18.m1.2.2.2.2.2.2.2.cmml">M</mi><mi mathsize="90%" id="alg1.l18.m1.2.2.2.2.2.2.3" xref="alg1.l18.m1.2.2.2.2.2.2.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="alg1.l18.m1.2.2.2.2.2.5" xref="alg1.l18.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.2b"><apply id="alg1.l18.m1.2.2.cmml" xref="alg1.l18.m1.2.2"><ci id="alg1.l18.m1.2.2.3.cmml" xref="alg1.l18.m1.2.2.3">←</ci><apply id="alg1.l18.m1.2.2.4.cmml" xref="alg1.l18.m1.2.2.4"><csymbol cd="ambiguous" id="alg1.l18.m1.2.2.4.1.cmml" xref="alg1.l18.m1.2.2.4">subscript</csymbol><ci id="alg1.l18.m1.2.2.4.2.cmml" xref="alg1.l18.m1.2.2.4.2">𝑚</ci><ci id="alg1.l18.m1.2.2.4.3.cmml" xref="alg1.l18.m1.2.2.4.3">𝑖</ci></apply><apply id="alg1.l18.m1.2.2.2.cmml" xref="alg1.l18.m1.2.2.2"><times id="alg1.l18.m1.2.2.2.3.cmml" xref="alg1.l18.m1.2.2.2.3"></times><ci id="alg1.l18.m1.2.2.2.4.cmml" xref="alg1.l18.m1.2.2.2.4">𝒜</ci><interval closure="open" id="alg1.l18.m1.2.2.2.2.3.cmml" xref="alg1.l18.m1.2.2.2.2.2"><apply id="alg1.l18.m1.1.1.1.1.1.1.cmml" xref="alg1.l18.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l18.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l18.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l18.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l18.m1.1.1.1.1.1.1.2">𝑚</ci><ci id="alg1.l18.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l18.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="alg1.l18.m1.2.2.2.2.2.2.cmml" xref="alg1.l18.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l18.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l18.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l18.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l18.m1.2.2.2.2.2.2.2">𝑀</ci><ci id="alg1.l18.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l18.m1.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.2c">m_{i}\leftarrow\mathcal{A}(m_{i},M_{i})</annotation></semantics></math><span id="alg1.l18.4" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l18.1" class="ltx_text" style="font-size:90%;float:right;"><math id="alg1.l18.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l18.1.m1.1a"><mo id="alg1.l18.1.m1.1.1" xref="alg1.l18.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l18.1.m1.1b"><ci id="alg1.l18.1.m1.1.1.cmml" xref="alg1.l18.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.1.m1.1c">\triangleright</annotation></semantics></math> Model Aggregation
</span>
</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l19.1.1.1" class="ltx_text" style="font-size:80%;">19:</span></span><span id="alg1.l19.2" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l19.3" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l19.4" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
</div>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">The core system creates instances of individual nodes through the bootstrap information. Docker containers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">38</span></a>]</cite> are used to virtualize the nodes. When the docker instance is started, the nodes follow the configuration information and get the local data. The <span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">DART</span> process in each node is shown in Algorithm <a href="#alg1" title="Algorithm 1 ‣ 4.3 Implementation of DART ‣ 4 DART Solution ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. If a node is benign, it will use the regular model training pipeline to train the model locally, transmit the local model to its neighbors, and wait for the model from its neighbors. If a node is malicious, then it will manipulate the data according to attack configuration, get the poisoned local dataset, train the malicious model, and then share it with the neighbors; or the node modifies the local model, gets the poisoned model, and shares it with the neighbors. The local model is developed using the Pytorch framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">47</span></a>]</cite>, with Pytorch Lightning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">17</span></a>]</cite> serving as the model trainer for model optimization.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">Following the acquisition of models shared by neighboring nodes, the node utilizes the selected algorithm outlined in the bootstrap configuration to aggregate models. After the aggregation is completed, the next round of local model training and model aggregation is performed. Throughout the model training and testing phases, metrics, including model performance, attack, and defense effectiveness, are transmitted from core to frontend utilizing a REST API. The frontend then visualizes these metrics via TensorBoard <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Analysis</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section compares and analyzes the impact of poisoning attacks on the model robustness of CFL and DFL paradigms and identifies the factors influencing their efficacy. Besides, this section benchmarks various defense mechanisms in diverse attack scenarios.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets and Federation Setups</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The following datasets and deep learning model are chosen to evaluate the aggregation algorithms implemented for the Fedstellar framework:</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.5" class="ltx_p"><span id="S5.I1.i1.p1.5.1" class="ltx_text ltx_font_bold">MNIST</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">33</span></a>]</cite> consists of handwritten digits represented by 28×28 grayscale images. It compromises <math id="S5.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="60\,000" display="inline"><semantics id="S5.I1.i1.p1.1.m1.1a"><mn id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml">60 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><cn type="integer" id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1">60000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">60\,000</annotation></semantics></math> training samples and <math id="S5.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="10\,000" display="inline"><semantics id="S5.I1.i1.p1.2.m2.1a"><mn id="S5.I1.i1.p1.2.m2.1.1" xref="S5.I1.i1.p1.2.m2.1.1.cmml">10 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.2.m2.1b"><cn type="integer" id="S5.I1.i1.p1.2.m2.1.1.cmml" xref="S5.I1.i1.p1.2.m2.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.2.m2.1c">10\,000</annotation></semantics></math> test samples. A three layers multilayer perceptron (MLP) with a linear input layer of size <math id="S5.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="784\times 256" display="inline"><semantics id="S5.I1.i1.p1.3.m3.1a"><mrow id="S5.I1.i1.p1.3.m3.1.1" xref="S5.I1.i1.p1.3.m3.1.1.cmml"><mn id="S5.I1.i1.p1.3.m3.1.1.2" xref="S5.I1.i1.p1.3.m3.1.1.2.cmml">784</mn><mo lspace="0.222em" rspace="0.222em" id="S5.I1.i1.p1.3.m3.1.1.1" xref="S5.I1.i1.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.I1.i1.p1.3.m3.1.1.3" xref="S5.I1.i1.p1.3.m3.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.3.m3.1b"><apply id="S5.I1.i1.p1.3.m3.1.1.cmml" xref="S5.I1.i1.p1.3.m3.1.1"><times id="S5.I1.i1.p1.3.m3.1.1.1.cmml" xref="S5.I1.i1.p1.3.m3.1.1.1"></times><cn type="integer" id="S5.I1.i1.p1.3.m3.1.1.2.cmml" xref="S5.I1.i1.p1.3.m3.1.1.2">784</cn><cn type="integer" id="S5.I1.i1.p1.3.m3.1.1.3.cmml" xref="S5.I1.i1.p1.3.m3.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.3.m3.1c">784\times 256</annotation></semantics></math>, a linear hidden layer of size <math id="S5.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="256\times 128" display="inline"><semantics id="S5.I1.i1.p1.4.m4.1a"><mrow id="S5.I1.i1.p1.4.m4.1.1" xref="S5.I1.i1.p1.4.m4.1.1.cmml"><mn id="S5.I1.i1.p1.4.m4.1.1.2" xref="S5.I1.i1.p1.4.m4.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.I1.i1.p1.4.m4.1.1.1" xref="S5.I1.i1.p1.4.m4.1.1.1.cmml">×</mo><mn id="S5.I1.i1.p1.4.m4.1.1.3" xref="S5.I1.i1.p1.4.m4.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.4.m4.1b"><apply id="S5.I1.i1.p1.4.m4.1.1.cmml" xref="S5.I1.i1.p1.4.m4.1.1"><times id="S5.I1.i1.p1.4.m4.1.1.1.cmml" xref="S5.I1.i1.p1.4.m4.1.1.1"></times><cn type="integer" id="S5.I1.i1.p1.4.m4.1.1.2.cmml" xref="S5.I1.i1.p1.4.m4.1.1.2">256</cn><cn type="integer" id="S5.I1.i1.p1.4.m4.1.1.3.cmml" xref="S5.I1.i1.p1.4.m4.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.4.m4.1c">256\times 128</annotation></semantics></math>, and a linear output layer of size <math id="S5.I1.i1.p1.5.m5.1" class="ltx_Math" alttext="128\times 10" display="inline"><semantics id="S5.I1.i1.p1.5.m5.1a"><mrow id="S5.I1.i1.p1.5.m5.1.1" xref="S5.I1.i1.p1.5.m5.1.1.cmml"><mn id="S5.I1.i1.p1.5.m5.1.1.2" xref="S5.I1.i1.p1.5.m5.1.1.2.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="S5.I1.i1.p1.5.m5.1.1.1" xref="S5.I1.i1.p1.5.m5.1.1.1.cmml">×</mo><mn id="S5.I1.i1.p1.5.m5.1.1.3" xref="S5.I1.i1.p1.5.m5.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.5.m5.1b"><apply id="S5.I1.i1.p1.5.m5.1.1.cmml" xref="S5.I1.i1.p1.5.m5.1.1"><times id="S5.I1.i1.p1.5.m5.1.1.1.cmml" xref="S5.I1.i1.p1.5.m5.1.1.1"></times><cn type="integer" id="S5.I1.i1.p1.5.m5.1.1.2.cmml" xref="S5.I1.i1.p1.5.m5.1.1.2">128</cn><cn type="integer" id="S5.I1.i1.p1.5.m5.1.1.3.cmml" xref="S5.I1.i1.p1.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.5.m5.1c">128\times 10</annotation></semantics></math> is used for classification.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.2" class="ltx_p"><span id="S5.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">FashionMNIST</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">63</span></a>]</cite> consists of <math id="S5.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="60\,000" display="inline"><semantics id="S5.I1.i2.p1.1.m1.1a"><mn id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml">60 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><cn type="integer" id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1">60000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">60\,000</annotation></semantics></math> training samples and <math id="S5.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="10\,000" display="inline"><semantics id="S5.I1.i2.p1.2.m2.1a"><mn id="S5.I1.i2.p1.2.m2.1.1" xref="S5.I1.i2.p1.2.m2.1.1.cmml">10 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.2.m2.1b"><cn type="integer" id="S5.I1.i2.p1.2.m2.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.2.m2.1c">10\,000</annotation></semantics></math> test samples, which are 28×28 grayscale images with 10 classes.For the FashionMNIST dataset, the same MLP as for MNIST is used.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.2" class="ltx_p"><span id="S5.I1.i3.p1.2.1" class="ltx_text ltx_font_bold">Cifar10</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">30</span></a>]</cite> consists of <math id="S5.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="50\,000" display="inline"><semantics id="S5.I1.i3.p1.1.m1.1a"><mn id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">50 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b"><cn type="integer" id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">50000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">50\,000</annotation></semantics></math> training and <math id="S5.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="10\,000" display="inline"><semantics id="S5.I1.i3.p1.2.m2.1a"><mn id="S5.I1.i3.p1.2.m2.1.1" xref="S5.I1.i3.p1.2.m2.1.1.cmml">10 000</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.2.m2.1b"><cn type="integer" id="S5.I1.i3.p1.2.m2.1.1.cmml" xref="S5.I1.i3.p1.2.m2.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.2.m2.1c">10\,000</annotation></semantics></math> test images with 10 classes of 32×32 color images. A small convolutional neural network (CNN) designed for mobile applications is used for this task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">27</span></a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S5.T3.3.2" class="ltx_text" style="font-size:90%;">Configuration of Experiments</span></figcaption>
<div id="S5.T3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:439.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(40.3pt,-40.9pt) scale(1.22809312527715,1.22809312527715) ;">
<table id="S5.T3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.1.1" class="ltx_tr">
<td id="S5.T3.4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" colspan="2"><span id="S5.T3.4.1.1.1.1" class="ltx_text ltx_font_bold">CONFIGURATION</span></td>
<td id="S5.T3.4.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T3.4.1.1.2.1" class="ltx_text ltx_font_bold">VALUE</span></td>
</tr>
<tr id="S5.T3.4.1.2" class="ltx_tr">
<td id="S5.T3.4.1.2.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="5"><span id="S5.T3.4.1.2.1.1" class="ltx_text ltx_font_bold">Federation</span></td>
<td id="S5.T3.4.1.2.2" class="ltx_td ltx_align_left ltx_border_t">Number of Clients</td>
<td id="S5.T3.4.1.2.3" class="ltx_td ltx_align_left ltx_border_t">10</td>
</tr>
<tr id="S5.T3.4.1.3" class="ltx_tr">
<td id="S5.T3.4.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Total Rounds</td>
<td id="S5.T3.4.1.3.2" class="ltx_td ltx_align_left ltx_border_t">10</td>
</tr>
<tr id="S5.T3.4.1.4" class="ltx_tr">
<td id="S5.T3.4.1.4.1" class="ltx_td ltx_align_left ltx_border_t">Epochs in Each Round</td>
<td id="S5.T3.4.1.4.2" class="ltx_td ltx_align_left ltx_border_t">3</td>
</tr>
<tr id="S5.T3.4.1.5" class="ltx_tr">
<td id="S5.T3.4.1.5.1" class="ltx_td ltx_align_left ltx_border_t">Paradigm</td>
<td id="S5.T3.4.1.5.2" class="ltx_td ltx_align_left ltx_border_t">CFL, DFL</td>
</tr>
<tr id="S5.T3.4.1.6" class="ltx_tr">
<td id="S5.T3.4.1.6.1" class="ltx_td ltx_align_left ltx_border_t">Data Distribution</td>
<td id="S5.T3.4.1.6.2" class="ltx_td ltx_align_left ltx_border_t">IID</td>
</tr>
<tr id="S5.T3.4.1.7" class="ltx_tr">
<td id="S5.T3.4.1.7.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S5.T3.4.1.7.1.1" class="ltx_text ltx_font_bold">Robustness</span></td>
<td id="S5.T3.4.1.7.2" class="ltx_td ltx_align_left ltx_border_t">Attacks</td>
<td id="S5.T3.4.1.7.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T3.4.1.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.1.7.3.1.1" class="ltx_tr">
<td id="S5.T3.4.1.7.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Untargeted Label Flipping</td>
</tr>
<tr id="S5.T3.4.1.7.3.1.2" class="ltx_tr">
<td id="S5.T3.4.1.7.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Untargeted Sample Poisoning</td>
</tr>
<tr id="S5.T3.4.1.7.3.1.3" class="ltx_tr">
<td id="S5.T3.4.1.7.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Random Model Poisoning</td>
</tr>
<tr id="S5.T3.4.1.7.3.1.4" class="ltx_tr">
<td id="S5.T3.4.1.7.3.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">Targeted Label Flipping</td>
</tr>
<tr id="S5.T3.4.1.7.3.1.5" class="ltx_tr">
<td id="S5.T3.4.1.7.3.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">Backdoor Attack</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T3.4.1.8" class="ltx_tr">
<td id="S5.T3.4.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Poisoned Node Ratios (PNR)</td>
<td id="S5.T3.4.1.8.2" class="ltx_td ltx_align_left ltx_border_t">0%, 10%, 30%, 50%, 70%, 90%</td>
</tr>
<tr id="S5.T3.4.1.9" class="ltx_tr">
<td id="S5.T3.4.1.9.1" class="ltx_td ltx_align_left ltx_border_t">Aggregation Function</td>
<td id="S5.T3.4.1.9.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T3.4.1.9.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.1.9.2.1.1" class="ltx_tr">
<td id="S5.T3.4.1.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S5.T3.4.1.9.2.1.1.1.1" class="ltx_text ltx_font_italic">FedAvg</span>, <span id="S5.T3.4.1.9.2.1.1.1.2" class="ltx_text ltx_font_italic">Krum</span>, <span id="S5.T3.4.1.9.2.1.1.1.3" class="ltx_text ltx_font_italic">Median</span>,</td>
</tr>
<tr id="S5.T3.4.1.9.2.1.2" class="ltx_tr">
<td id="S5.T3.4.1.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S5.T3.4.1.9.2.1.2.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span>, <span id="S5.T3.4.1.9.2.1.2.1.2" class="ltx_text ltx_font_italic">FLTrust</span>,</td>
</tr>
<tr id="S5.T3.4.1.9.2.1.3" class="ltx_tr">
<td id="S5.T3.4.1.9.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S5.T3.4.1.9.2.1.3.1.1" class="ltx_text ltx_font_italic">Sentinal</span>, <span id="S5.T3.4.1.9.2.1.3.1.2" class="ltx_text ltx_font_italic">Voyager</span>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T3.4.1.10" class="ltx_tr">
<td id="S5.T3.4.1.10.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" rowspan="3"><span id="S5.T3.4.1.10.1.1" class="ltx_text ltx_font_bold">Network</span></td>
<td id="S5.T3.4.1.10.2" class="ltx_td ltx_align_left ltx_border_t">Bandwidth</td>
<td id="S5.T3.4.1.10.3" class="ltx_td ltx_align_left ltx_border_t">1 Mbps</td>
</tr>
<tr id="S5.T3.4.1.11" class="ltx_tr">
<td id="S5.T3.4.1.11.1" class="ltx_td ltx_align_left ltx_border_t">Delay</td>
<td id="S5.T3.4.1.11.2" class="ltx_td ltx_align_left ltx_border_t">0 ms</td>
</tr>
<tr id="S5.T3.4.1.12" class="ltx_tr">
<td id="S5.T3.4.1.12.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">Topology</td>
<td id="S5.T3.4.1.12.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S5.T3.4.1.12.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.1.12.2.1.1" class="ltx_tr">
<td id="S5.T3.4.1.12.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Fully connected, Ring,</td>
</tr>
<tr id="S5.T3.4.1.12.2.1.2" class="ltx_tr">
<td id="S5.T3.4.1.12.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Star, Random</td>
</tr>
</table>
</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2407.08652/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="322" height="331" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.3.2" class="ltx_text" style="font-size:90%;">Average F1-Score Results for Untargeted Poisoning Attacks</span></figcaption>
</figure>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The experiment configurations are listed in Table <a href="#S5.T3" title="Table 3 ‣ 5.1 Datasets and Federation Setups ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The learning process is designed to run for a total of 10 rounds, with each round comprising three epochs. All experiments are performed in the federation composed of 10 clients, and the data are evenly distributed across the clients in an IID manner. All experiments are carried out on the <span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_italic">Fedstellar</span> platform in synchronous mode. The federation network has a bandwidth of 1 Mbps without loss and delay. For the experiments with different attacks, the Poisoned Node Ratios (PNR) are increased from 0% to 90%. The defense mechanisms <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">Krum</span>, <span id="S5.SS1.p3.1.3" class="ltx_text ltx_font_italic">Median</span>, <span id="S5.SS1.p3.1.4" class="ltx_text ltx_font_italic">TrimmedMean</span>, <span id="S5.SS1.p3.1.5" class="ltx_text ltx_font_italic">FLTrust</span>, <span id="S5.SS1.p3.1.6" class="ltx_text ltx_font_italic">Sentinal</span>, and <span id="S5.SS1.p3.1.7" class="ltx_text ltx_font_italic">Voyager</span> are implemented, assessed, and compared. Furthermore, the experiments employ four different participants interconnection topologies, <span id="S5.SS1.p3.1.8" class="ltx_text ltx_font_italic">i.e., </span>ring, star, random, and fully connected.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Poisoning Attack on CFL and DFL</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">This experiment first analyzes the performance of CFL and DFL in the presence of different types of poisoning attacks. When executing the attacks, it assumes that all the attacks occur during the model training process and recur in each round. These attacks encompass both data poisoning and model poisoning strategies with untargeted and targeted intentions. Experiments with malicious client proportions ranging from 0% to 90% are executed to observe the effect of different degrees of maliciousness on the model robustness.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Experimental Analysis of Untargeted Attacks</h4>

<figure id="S5.F8" class="ltx_figure"><img src="/html/2407.08652/assets/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_square" width="322" height="331" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S5.F8.3.2" class="ltx_text" style="font-size:90%;">Average F1-Score Results for Untargeted Poisoning Attacks with Random Topologies</span></figcaption>
</figure>
<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Three untargeted attacks have been implemented to compare the attack performance in CFL and DFL, including Untargeted Label Flipping, Untargeted Sample Poisoning, and Random Model Poisoning attacks. The detailed attack setups are listed below:</p>
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p"><span id="S5.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Untargeted Label Flipping</span>: Randomly replacing all the labels corresponding to the samples in the training set such that the model is unable to map the data patterns of the samples to the correct labels. Thus, the loss function cannot correctly guide the optimization direction of the model.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p"><span id="S5.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Untargeted Sample Poisoning</span>: 30% of Gaussian noise is added to all of the samples in the training set to mask the correct features in the data. As a result, the model fails to recognize effective patterns in the data and cannot classify the data correctly.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p id="S5.I2.i3.p1.1" class="ltx_p"><span id="S5.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Random Model Poisoning</span>: Before sending the model for aggregation, the malicious node directly adds 30% of Gaussian noise to the parameters of the trained local model to devastate the model’s effectiveness.</p>
</div>
</li>
</ul>
</div>
<section id="S5.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(i)<span id="S5.SS2.SSS1.Px1.1.1" class="ltx_text ltx_font_upright"> Evaluation Metrics for Untargeted Attacks</span>
</h5>

<div id="S5.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px1.p1.1" class="ltx_p"><span id="S5.SS2.SSS1.Px1.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS1.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.Px1.p2.1" class="ltx_p">The purpose of an untargeted attack is to spread malice in the FL system and reduce the effectiveness of the models of all nodes. Therefore, the average F1-Score in the model’s benign nodes is calculated as the metric to evaluate the model’s robustness and the effectiveness of the untargeted attack. A lower F1-Score indicates that the untargeted attack is more effective, but the FL models have lower robustness. This experiment is carried out in CFL and DFL utilizing fully connected, ring, and star network topologies. Besides, FedAvg is employed as the aggregation function across all nodes without additional defense mechanisms.</p>
</div>
</section>
<section id="S5.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(ii)<span id="S5.SS2.SSS1.Px2.1.1" class="ltx_text ltx_font_upright"> Attack Effectiveness</span>
</h5>

<div id="S5.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px2.p1.1" class="ltx_p"><span id="S5.SS2.SSS1.Px2.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS1.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS1.Px2.p2.1" class="ltx_p">Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1 Datasets and Federation Setups ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates the impact, <span id="S5.SS2.SSS1.Px2.p2.1.1" class="ltx_text ltx_font_italic">i.e., </span>average F1-Score, of three untargeted attacks on CFL and DFL with three datasets as the PNR increases. Overall, the effects of the Model Poisoning attack are much more destructive, with 10% of the nodes attacked having a significant reduction in the modeling effects of both CFL and DFL. With more than 30% of the nodes attacked, the model of the benign node is close to being completely destroyed and no longer able to provide meaningful inferences in all of these three datasets. The Label Flipping Attack shows a strong effect only after more than 30% of malicious nodes, and the model of benign nodes is destroyed when the percentage of malicious nodes exceeds 50%. In contrast, the effect of Sample Poisoning is weaker, and the effect of the attack is shown when the percentage of malicious nodes is greater than 50%, but even if the number of nodes attacked reaches 90%, for the MNIST dataset, the rest of the benign node model still has close to 80% of the F1-Score, which suggests that Sample Poisoning in the attack strategy is not as effective as the other two in the untargeted attack. The reason is that since the noise injected by Sample Poisoning does not always cover all of the features, the model is able to learn some patterns from limited information.</p>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2407.08652/assets/x9.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="241" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S5.F9.3.2" class="ltx_text" style="font-size:90%;">Average F1-Score Results for Targeted Poisoning Attacks</span></figcaption>
</figure>
</section>
<section id="S5.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(iii)<span id="S5.SS2.SSS1.Px3.1.1" class="ltx_text ltx_font_upright"> Model Robustness in Different Paradigms and Topologies</span>
</h5>

<div id="S5.SS2.SSS1.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p1.1" class="ltx_p"><span id="S5.SS2.SSS1.Px3.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS1.Px3.p2" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p2.1" class="ltx_p">For different FL paradigms, the CFL and DFL with fully connected topology exhibit a similar decrease in the model F1-Score across the attacks. However, the model robustness of DFL is affected by the manner in which participants are interconnected, <span id="S5.SS2.SSS1.Px3.p2.1.1" class="ltx_text ltx_font_italic">i.e., </span>the topology. The results from Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1 Datasets and Federation Setups ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> indicate that DFL with the ring and star topology exhibit reduced levels of model robustness in counter when faced with untargeted poisoning attacks.</p>
</div>
<div id="S5.SS2.SSS1.Px3.p3" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">21</span></a>]</cite> suggests that a benign node’s connections to malicious nodes follow a hypergeometric distribution. Nodes with fewer average neighbors in a DFL network are more susceptible to poisoned attacks. Compared to fully connected, star and ring topologies are sparser, resulting in a lower decrease in F1-Score when facing untargeted attacks. To validate this hypothesis, this paper conducts an experiment on different DFL connected by random networks, using the Watts-Strogatz <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">60</span></a>]</cite> model to generate random small-world networks with average neighbor numbers of 2, 4, 6, and 8.</p>
</div>
<div id="S5.SS2.SSS1.Px3.p4" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p4.1" class="ltx_p">Figure <a href="#S5.F8" title="Figure 8 ‣ 5.2.1 Experimental Analysis of Untargeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates the average F1-Score of three untargeted attacks on the random topology of DFL with different average connected neighbors with three datasets as the PNR increases. The DFL model with 8 neighbors performs the best against the three attacks, followed by 6 neighbors, while 2 neighbors perform the worst. These results demonstrate that the network sparsity significantly influences the model robustness of DFL. Specifically, a denser network, characterized by a higher average number of connected neighbors, enhances the robustness of the model against poisoning attacks. This is because nodes need to aggregate fewer models when the average number of connected neighbors is small. Therefore, once aggregated with a malicious model, the benign node model will be greatly affected by the malicious ones. Whereas for a dense network, such as fully connected, although there is a high probability for a benign node to aggregate with a malicious node since the aggregation occurs in a large number of models, the maliciousness is thereby diluted and demonstrates better robustness.</p>
</div>
<div id="S5.SS2.SSS1.Px3.p5" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p5.1" class="ltx_p">In conclusion, when confronted with untargeted attacks, CFL and DFL exhibit similar performance. The model robustness of DFL is influenced by the network topology, with denser networks yield greater robustness. In terms of attacks, Model Poisoning Attacks prove to be the most efficient across various attack strategies. Label Flipping produces comparable outcomes but necessitates a higher proportion of malicious nodes. Conversely, Sample Poisoning Attacks are less effective than the aforementioned strategies regarding untargeted attacks.</p>
</div>
</section>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Experimental Analysis of Targeted Attacks</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">In this section, two targeted attacks are designed and implemented: Targeted Label Flipping and Backdoor Attack. The detailed attack setups are listed below:</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<ul id="S5.I3" class="ltx_itemize">
<li id="S5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i1.p1" class="ltx_para">
<p id="S5.I3.i1.p1.1" class="ltx_p"><span id="S5.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Targeted Label Flipping</span>: Replacing only specific labels, specifically, replacing all the label 7 with 4 in the training dataset. Thus, for the model, the feature patterns of the training samples originally belonging to label 7 will be recognized as label 4. Consequently, all the samples that should have corresponded to 7 will be incorrectly classified as label 4, whereas for the other labels, their classification results are not affected.</p>
</div>
</li>
<li id="S5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i2.p1" class="ltx_para">
<p id="S5.I3.i2.p1.1" class="ltx_p"><span id="S5.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Backdoor Attack</span>: A <math id="S5.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="10\times 10" display="inline"><semantics id="S5.I3.i2.p1.1.m1.1a"><mrow id="S5.I3.i2.p1.1.m1.1.1" xref="S5.I3.i2.p1.1.m1.1.1.cmml"><mn id="S5.I3.i2.p1.1.m1.1.1.2" xref="S5.I3.i2.p1.1.m1.1.1.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="S5.I3.i2.p1.1.m1.1.1.1" xref="S5.I3.i2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.I3.i2.p1.1.m1.1.1.3" xref="S5.I3.i2.p1.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I3.i2.p1.1.m1.1b"><apply id="S5.I3.i2.p1.1.m1.1.1.cmml" xref="S5.I3.i2.p1.1.m1.1.1"><times id="S5.I3.i2.p1.1.m1.1.1.1.cmml" xref="S5.I3.i2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.I3.i2.p1.1.m1.1.1.2.cmml" xref="S5.I3.i2.p1.1.m1.1.1.2">10</cn><cn type="integer" id="S5.I3.i2.p1.1.m1.1.1.3.cmml" xref="S5.I3.i2.p1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.i2.p1.1.m1.1c">10\times 10</annotation></semantics></math> pixels of an X shape watermark is added to the top right corner of the samples that belong to label 4 in the training dataset, such that the model learns the pattern corresponding to label 4 as the implanted watermark. In the testing phase, when this watermark does not appear, the model behaves normally, while the samples containing the watermark are misclassified as label 4.</p>
</div>
</li>
</ul>
</div>
<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F10.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.08652/assets/x10.png" id="S5.F10.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="181" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F10.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.08652/assets/x11.png" id="S5.F10.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="167" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.4.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S5.F10.5.2" class="ltx_text" style="font-size:90%;">Average ASR Results for Targeted Poisoning Attacks</span></figcaption>
</figure>
<section id="S5.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(i)<span id="S5.SS2.SSS2.Px1.1.1" class="ltx_text ltx_font_upright"> Evaluation Metrics for Targeted Attacks</span>
</h5>

<div id="S5.SS2.SSS2.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p1.1" class="ltx_p"><span id="S5.SS2.SSS2.Px1.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS2.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p2.1" class="ltx_p">This experiment first evaluates the overall performance of the model, <span id="S5.SS2.SSS2.Px1.p2.1.1" class="ltx_text ltx_font_italic">i.e., </span>the F1-Score, when subjected to these targeted attacks, as shown in Figure <a href="#S5.F9" title="Figure 9 ‣ (ii) Attack Effectiveness ‣ 5.2.1 Experimental Analysis of Untargeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. The results show that even when 90% of the nodes in both CFL and DFL models are suffering from targeted attacks, the overall performance on the model is not significantly dropped compared with no attack presence. This finding suggests that targeted attacks are more challenging to be detected through overall performance metrics. Therefore, this section adopts Attack Success Rate (ASR) to measure the effectiveness of targeted attacks.</p>
</div>
<div id="S5.SS2.SSS2.Px1.p3" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p3.8" class="ltx_p">The objective of Targeted Label Flipping is to cause misclassification of a source label <math id="S5.SS2.SSS2.Px1.p3.1.m1.1" class="ltx_Math" alttext="l_{src}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.1.m1.1a"><msub id="S5.SS2.SSS2.Px1.p3.1.m1.1.1" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.2" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.2.cmml">l</mi><mrow id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.cmml"><mi id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.2" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.3" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1a" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.4" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.1.m1.1b"><apply id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.2">𝑙</ci><apply id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3"><times id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.1"></times><ci id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.2.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.2">𝑠</ci><ci id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.3">𝑟</ci><ci id="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.4.cmml" xref="S5.SS2.SSS2.Px1.p3.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.1.m1.1c">l_{src}</annotation></semantics></math> to a desired target label <math id="S5.SS2.SSS2.Px1.p3.2.m2.1" class="ltx_Math" alttext="l_{t}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.2.m2.1a"><msub id="S5.SS2.SSS2.Px1.p3.2.m2.1.1" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.2" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1.2.cmml">l</mi><mi id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.3" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.2.m2.1b"><apply id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1.2">𝑙</ci><ci id="S5.SS2.SSS2.Px1.p3.2.m2.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.2.m2.1c">l_{t}</annotation></semantics></math>. The ASR-Targeted is determined by the number of samples in which the true label <math id="S5.SS2.SSS2.Px1.p3.3.m3.1" class="ltx_Math" alttext="y=l_{src}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.3.m3.1a"><mrow id="S5.SS2.SSS2.Px1.p3.3.m3.1.1" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.2" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.2.cmml">y</mi><mo id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.1" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.1.cmml">=</mo><msub id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.cmml"><mi id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.2" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.2.cmml">l</mi><mrow id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.cmml"><mi id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.2" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.3" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1a" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.4" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.4.cmml">c</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.3.m3.1b"><apply id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1"><eq id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.1"></eq><ci id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.2">𝑦</ci><apply id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.2.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.2">𝑙</ci><apply id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3"><times id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.1"></times><ci id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.2.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.2">𝑠</ci><ci id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.3.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.3">𝑟</ci><ci id="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.4.cmml" xref="S5.SS2.SSS2.Px1.p3.3.m3.1.1.3.3.4">𝑐</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.3.m3.1c">y=l_{src}</annotation></semantics></math> is incorrectly predicted as the target label <math id="S5.SS2.SSS2.Px1.p3.4.m4.1" class="ltx_Math" alttext="\hat{y}=l_{t}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.4.m4.1a"><mrow id="S5.SS2.SSS2.Px1.p3.4.m4.1.1" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.cmml"><mover accent="true" id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.cmml"><mi id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.2" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.2.cmml">y</mi><mo id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.1" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.1.cmml">^</mo></mover><mo id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.1" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.1.cmml">=</mo><msub id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.cmml"><mi id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.2" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.2.cmml">l</mi><mi id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.3" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.4.m4.1b"><apply id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1"><eq id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.1"></eq><apply id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2"><ci id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.1.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.1">^</ci><ci id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.2.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.2.2">𝑦</ci></apply><apply id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.1.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.2.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.2">𝑙</ci><ci id="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.3.cmml" xref="S5.SS2.SSS2.Px1.p3.4.m4.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.4.m4.1c">\hat{y}=l_{t}</annotation></semantics></math>, as described in Equation (<a href="#S5.E1" title="In (i) Evaluation Metrics for Targeted Attacks ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). <math id="S5.SS2.SSS2.Px1.p3.5.m5.1" class="ltx_Math" alttext="c_{ij}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.5.m5.1a"><msub id="S5.SS2.SSS2.Px1.p3.5.m5.1.1" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.2" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.2.cmml">c</mi><mrow id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.cmml"><mi id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.2" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.1" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.3" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.5.m5.1b"><apply id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.2">𝑐</ci><apply id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3"><times id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.1.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.1"></times><ci id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.2.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.2">𝑖</ci><ci id="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.3.cmml" xref="S5.SS2.SSS2.Px1.p3.5.m5.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.5.m5.1c">c_{ij}</annotation></semantics></math> represents the count of samples with the true label <math id="S5.SS2.SSS2.Px1.p3.6.m6.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.6.m6.1a"><msub id="S5.SS2.SSS2.Px1.p3.6.m6.1.1" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.2" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1.2.cmml">y</mi><mi id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.3" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.6.m6.1b"><apply id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1.2">𝑦</ci><ci id="S5.SS2.SSS2.Px1.p3.6.m6.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.6.m6.1c">y_{i}</annotation></semantics></math> and predicted label <math id="S5.SS2.SSS2.Px1.p3.7.m7.1" class="ltx_Math" alttext="\hat{y}_{j}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.7.m7.1a"><msub id="S5.SS2.SSS2.Px1.p3.7.m7.1.1" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.cmml"><mover accent="true" id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.cmml"><mi id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.2" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.2.cmml">y</mi><mo id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.1" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.1.cmml">^</mo></mover><mi id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.3" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.7.m7.1b"><apply id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1">subscript</csymbol><apply id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2"><ci id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.1.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.1">^</ci><ci id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.2.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.2.2">𝑦</ci></apply><ci id="S5.SS2.SSS2.Px1.p3.7.m7.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p3.7.m7.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.7.m7.1c">\hat{y}_{j}</annotation></semantics></math>, and the set <math id="S5.SS2.SSS2.Px1.p3.8.m8.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S5.SS2.SSS2.Px1.p3.8.m8.1a"><mi id="S5.SS2.SSS2.Px1.p3.8.m8.1.1" xref="S5.SS2.SSS2.Px1.p3.8.m8.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p3.8.m8.1b"><ci id="S5.SS2.SSS2.Px1.p3.8.m8.1.1.cmml" xref="S5.SS2.SSS2.Px1.p3.8.m8.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p3.8.m8.1c">L</annotation></semantics></math> represents the labels present in the dataset.</p>
</div>
<div id="S5.SS2.SSS2.Px1.p4" class="ltx_para">
<table id="S5.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S5.E1.m1.5" class="ltx_Math" alttext="ASR-Targeted=\frac{c_{src,t}}{\sum_{j=0}^{|L|}c_{src,j}}" display="block"><semantics id="S5.E1.m1.5a"><mrow id="S5.E1.m1.5.6" xref="S5.E1.m1.5.6.cmml"><mrow id="S5.E1.m1.5.6.2" xref="S5.E1.m1.5.6.2.cmml"><mrow id="S5.E1.m1.5.6.2.2" xref="S5.E1.m1.5.6.2.2.cmml"><mi id="S5.E1.m1.5.6.2.2.2" xref="S5.E1.m1.5.6.2.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.2.1" xref="S5.E1.m1.5.6.2.2.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.2.3" xref="S5.E1.m1.5.6.2.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.2.1a" xref="S5.E1.m1.5.6.2.2.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.2.4" xref="S5.E1.m1.5.6.2.2.4.cmml">R</mi></mrow><mo id="S5.E1.m1.5.6.2.1" xref="S5.E1.m1.5.6.2.1.cmml">−</mo><mrow id="S5.E1.m1.5.6.2.3" xref="S5.E1.m1.5.6.2.3.cmml"><mi id="S5.E1.m1.5.6.2.3.2" xref="S5.E1.m1.5.6.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.3" xref="S5.E1.m1.5.6.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1a" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.4" xref="S5.E1.m1.5.6.2.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1b" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.5" xref="S5.E1.m1.5.6.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1c" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.6" xref="S5.E1.m1.5.6.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1d" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.7" xref="S5.E1.m1.5.6.2.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1e" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.8" xref="S5.E1.m1.5.6.2.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.6.2.3.1f" xref="S5.E1.m1.5.6.2.3.1.cmml">​</mo><mi id="S5.E1.m1.5.6.2.3.9" xref="S5.E1.m1.5.6.2.3.9.cmml">d</mi></mrow></mrow><mo id="S5.E1.m1.5.6.1" xref="S5.E1.m1.5.6.1.cmml">=</mo><mfrac id="S5.E1.m1.5.5" xref="S5.E1.m1.5.5.cmml"><msub id="S5.E1.m1.2.2.2" xref="S5.E1.m1.2.2.2.cmml"><mi id="S5.E1.m1.2.2.2.4" xref="S5.E1.m1.2.2.2.4.cmml">c</mi><mrow id="S5.E1.m1.2.2.2.2.2.2" xref="S5.E1.m1.2.2.2.2.2.3.cmml"><mrow id="S5.E1.m1.2.2.2.2.2.2.1" xref="S5.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S5.E1.m1.2.2.2.2.2.2.1.2" xref="S5.E1.m1.2.2.2.2.2.2.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.2.2.2.2.1.1" xref="S5.E1.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S5.E1.m1.2.2.2.2.2.2.1.3" xref="S5.E1.m1.2.2.2.2.2.2.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.2.2.2.2.1.1a" xref="S5.E1.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S5.E1.m1.2.2.2.2.2.2.1.4" xref="S5.E1.m1.2.2.2.2.2.2.1.4.cmml">c</mi></mrow><mo id="S5.E1.m1.2.2.2.2.2.2.2" xref="S5.E1.m1.2.2.2.2.2.3.cmml">,</mo><mi id="S5.E1.m1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.cmml">t</mi></mrow></msub><mrow id="S5.E1.m1.5.5.5" xref="S5.E1.m1.5.5.5.cmml"><msubsup id="S5.E1.m1.5.5.5.4" xref="S5.E1.m1.5.5.5.4.cmml"><mo id="S5.E1.m1.5.5.5.4.2.2" xref="S5.E1.m1.5.5.5.4.2.2.cmml">∑</mo><mrow id="S5.E1.m1.5.5.5.4.2.3" xref="S5.E1.m1.5.5.5.4.2.3.cmml"><mi id="S5.E1.m1.5.5.5.4.2.3.2" xref="S5.E1.m1.5.5.5.4.2.3.2.cmml">j</mi><mo id="S5.E1.m1.5.5.5.4.2.3.1" xref="S5.E1.m1.5.5.5.4.2.3.1.cmml">=</mo><mn id="S5.E1.m1.5.5.5.4.2.3.3" xref="S5.E1.m1.5.5.5.4.2.3.3.cmml">0</mn></mrow><mrow id="S5.E1.m1.3.3.3.1.1.3" xref="S5.E1.m1.3.3.3.1.1.2.cmml"><mo stretchy="false" id="S5.E1.m1.3.3.3.1.1.3.1" xref="S5.E1.m1.3.3.3.1.1.2.1.cmml">|</mo><mi id="S5.E1.m1.3.3.3.1.1.1" xref="S5.E1.m1.3.3.3.1.1.1.cmml">L</mi><mo stretchy="false" id="S5.E1.m1.3.3.3.1.1.3.2" xref="S5.E1.m1.3.3.3.1.1.2.1.cmml">|</mo></mrow></msubsup><msub id="S5.E1.m1.5.5.5.5" xref="S5.E1.m1.5.5.5.5.cmml"><mi id="S5.E1.m1.5.5.5.5.2" xref="S5.E1.m1.5.5.5.5.2.cmml">c</mi><mrow id="S5.E1.m1.5.5.5.3.2.2" xref="S5.E1.m1.5.5.5.3.2.3.cmml"><mrow id="S5.E1.m1.5.5.5.3.2.2.1" xref="S5.E1.m1.5.5.5.3.2.2.1.cmml"><mi id="S5.E1.m1.5.5.5.3.2.2.1.2" xref="S5.E1.m1.5.5.5.3.2.2.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.5.5.3.2.2.1.1" xref="S5.E1.m1.5.5.5.3.2.2.1.1.cmml">​</mo><mi id="S5.E1.m1.5.5.5.3.2.2.1.3" xref="S5.E1.m1.5.5.5.3.2.2.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.5.5.5.3.2.2.1.1a" xref="S5.E1.m1.5.5.5.3.2.2.1.1.cmml">​</mo><mi id="S5.E1.m1.5.5.5.3.2.2.1.4" xref="S5.E1.m1.5.5.5.3.2.2.1.4.cmml">c</mi></mrow><mo id="S5.E1.m1.5.5.5.3.2.2.2" xref="S5.E1.m1.5.5.5.3.2.3.cmml">,</mo><mi id="S5.E1.m1.4.4.4.2.1.1" xref="S5.E1.m1.4.4.4.2.1.1.cmml">j</mi></mrow></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.5b"><apply id="S5.E1.m1.5.6.cmml" xref="S5.E1.m1.5.6"><eq id="S5.E1.m1.5.6.1.cmml" xref="S5.E1.m1.5.6.1"></eq><apply id="S5.E1.m1.5.6.2.cmml" xref="S5.E1.m1.5.6.2"><minus id="S5.E1.m1.5.6.2.1.cmml" xref="S5.E1.m1.5.6.2.1"></minus><apply id="S5.E1.m1.5.6.2.2.cmml" xref="S5.E1.m1.5.6.2.2"><times id="S5.E1.m1.5.6.2.2.1.cmml" xref="S5.E1.m1.5.6.2.2.1"></times><ci id="S5.E1.m1.5.6.2.2.2.cmml" xref="S5.E1.m1.5.6.2.2.2">𝐴</ci><ci id="S5.E1.m1.5.6.2.2.3.cmml" xref="S5.E1.m1.5.6.2.2.3">𝑆</ci><ci id="S5.E1.m1.5.6.2.2.4.cmml" xref="S5.E1.m1.5.6.2.2.4">𝑅</ci></apply><apply id="S5.E1.m1.5.6.2.3.cmml" xref="S5.E1.m1.5.6.2.3"><times id="S5.E1.m1.5.6.2.3.1.cmml" xref="S5.E1.m1.5.6.2.3.1"></times><ci id="S5.E1.m1.5.6.2.3.2.cmml" xref="S5.E1.m1.5.6.2.3.2">𝑇</ci><ci id="S5.E1.m1.5.6.2.3.3.cmml" xref="S5.E1.m1.5.6.2.3.3">𝑎</ci><ci id="S5.E1.m1.5.6.2.3.4.cmml" xref="S5.E1.m1.5.6.2.3.4">𝑟</ci><ci id="S5.E1.m1.5.6.2.3.5.cmml" xref="S5.E1.m1.5.6.2.3.5">𝑔</ci><ci id="S5.E1.m1.5.6.2.3.6.cmml" xref="S5.E1.m1.5.6.2.3.6">𝑒</ci><ci id="S5.E1.m1.5.6.2.3.7.cmml" xref="S5.E1.m1.5.6.2.3.7">𝑡</ci><ci id="S5.E1.m1.5.6.2.3.8.cmml" xref="S5.E1.m1.5.6.2.3.8">𝑒</ci><ci id="S5.E1.m1.5.6.2.3.9.cmml" xref="S5.E1.m1.5.6.2.3.9">𝑑</ci></apply></apply><apply id="S5.E1.m1.5.5.cmml" xref="S5.E1.m1.5.5"><divide id="S5.E1.m1.5.5.6.cmml" xref="S5.E1.m1.5.5"></divide><apply id="S5.E1.m1.2.2.2.cmml" xref="S5.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2">subscript</csymbol><ci id="S5.E1.m1.2.2.2.4.cmml" xref="S5.E1.m1.2.2.2.4">𝑐</ci><list id="S5.E1.m1.2.2.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2.2.2.2"><apply id="S5.E1.m1.2.2.2.2.2.2.1.cmml" xref="S5.E1.m1.2.2.2.2.2.2.1"><times id="S5.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S5.E1.m1.2.2.2.2.2.2.1.1"></times><ci id="S5.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S5.E1.m1.2.2.2.2.2.2.1.2">𝑠</ci><ci id="S5.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S5.E1.m1.2.2.2.2.2.2.1.3">𝑟</ci><ci id="S5.E1.m1.2.2.2.2.2.2.1.4.cmml" xref="S5.E1.m1.2.2.2.2.2.2.1.4">𝑐</ci></apply><ci id="S5.E1.m1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1">𝑡</ci></list></apply><apply id="S5.E1.m1.5.5.5.cmml" xref="S5.E1.m1.5.5.5"><apply id="S5.E1.m1.5.5.5.4.cmml" xref="S5.E1.m1.5.5.5.4"><csymbol cd="ambiguous" id="S5.E1.m1.5.5.5.4.1.cmml" xref="S5.E1.m1.5.5.5.4">superscript</csymbol><apply id="S5.E1.m1.5.5.5.4.2.cmml" xref="S5.E1.m1.5.5.5.4"><csymbol cd="ambiguous" id="S5.E1.m1.5.5.5.4.2.1.cmml" xref="S5.E1.m1.5.5.5.4">subscript</csymbol><sum id="S5.E1.m1.5.5.5.4.2.2.cmml" xref="S5.E1.m1.5.5.5.4.2.2"></sum><apply id="S5.E1.m1.5.5.5.4.2.3.cmml" xref="S5.E1.m1.5.5.5.4.2.3"><eq id="S5.E1.m1.5.5.5.4.2.3.1.cmml" xref="S5.E1.m1.5.5.5.4.2.3.1"></eq><ci id="S5.E1.m1.5.5.5.4.2.3.2.cmml" xref="S5.E1.m1.5.5.5.4.2.3.2">𝑗</ci><cn type="integer" id="S5.E1.m1.5.5.5.4.2.3.3.cmml" xref="S5.E1.m1.5.5.5.4.2.3.3">0</cn></apply></apply><apply id="S5.E1.m1.3.3.3.1.1.2.cmml" xref="S5.E1.m1.3.3.3.1.1.3"><abs id="S5.E1.m1.3.3.3.1.1.2.1.cmml" xref="S5.E1.m1.3.3.3.1.1.3.1"></abs><ci id="S5.E1.m1.3.3.3.1.1.1.cmml" xref="S5.E1.m1.3.3.3.1.1.1">𝐿</ci></apply></apply><apply id="S5.E1.m1.5.5.5.5.cmml" xref="S5.E1.m1.5.5.5.5"><csymbol cd="ambiguous" id="S5.E1.m1.5.5.5.5.1.cmml" xref="S5.E1.m1.5.5.5.5">subscript</csymbol><ci id="S5.E1.m1.5.5.5.5.2.cmml" xref="S5.E1.m1.5.5.5.5.2">𝑐</ci><list id="S5.E1.m1.5.5.5.3.2.3.cmml" xref="S5.E1.m1.5.5.5.3.2.2"><apply id="S5.E1.m1.5.5.5.3.2.2.1.cmml" xref="S5.E1.m1.5.5.5.3.2.2.1"><times id="S5.E1.m1.5.5.5.3.2.2.1.1.cmml" xref="S5.E1.m1.5.5.5.3.2.2.1.1"></times><ci id="S5.E1.m1.5.5.5.3.2.2.1.2.cmml" xref="S5.E1.m1.5.5.5.3.2.2.1.2">𝑠</ci><ci id="S5.E1.m1.5.5.5.3.2.2.1.3.cmml" xref="S5.E1.m1.5.5.5.3.2.2.1.3">𝑟</ci><ci id="S5.E1.m1.5.5.5.3.2.2.1.4.cmml" xref="S5.E1.m1.5.5.5.3.2.2.1.4">𝑐</ci></apply><ci id="S5.E1.m1.4.4.4.2.1.1.cmml" xref="S5.E1.m1.4.4.4.2.1.1">𝑗</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.5c">ASR-Targeted=\frac{c_{src,t}}{\sum_{j=0}^{|L|}c_{src,j}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS2.SSS2.Px1.p5" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p5.5" class="ltx_p">The Backdoor attack involves the adversary inserting a trigger into local data samples that are associated with a particular target label <math id="S5.SS2.SSS2.Px1.p5.1.m1.1" class="ltx_Math" alttext="l_{t}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p5.1.m1.1a"><msub id="S5.SS2.SSS2.Px1.p5.1.m1.1.1" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.2" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1.2.cmml">l</mi><mi id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.3" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p5.1.m1.1b"><apply id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1.2">𝑙</ci><ci id="S5.SS2.SSS2.Px1.p5.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p5.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p5.1.m1.1c">l_{t}</annotation></semantics></math>. The effectiveness of the Backdoor attack is evaluated using ASR-Backdoor, which is defined in Equation (<a href="#S5.E2" title="In (i) Evaluation Metrics for Targeted Attacks ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Here, <math id="S5.SS2.SSS2.Px1.p5.2.m2.1" class="ltx_Math" alttext="c_{ij}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p5.2.m2.1a"><msub id="S5.SS2.SSS2.Px1.p5.2.m2.1.1" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.2" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.2.cmml">c</mi><mrow id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.cmml"><mi id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.2" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.1" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.3" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p5.2.m2.1b"><apply id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.2">𝑐</ci><apply id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3"><times id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.1.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.1"></times><ci id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.2.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.2">𝑖</ci><ci id="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.3.cmml" xref="S5.SS2.SSS2.Px1.p5.2.m2.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p5.2.m2.1c">c_{ij}</annotation></semantics></math> denotes the number of samples that have a true label <math id="S5.SS2.SSS2.Px1.p5.3.m3.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p5.3.m3.1a"><msub id="S5.SS2.SSS2.Px1.p5.3.m3.1.1" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1.cmml"><mi id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.2" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1.2.cmml">y</mi><mi id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.3" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p5.3.m3.1b"><apply id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1.2">𝑦</ci><ci id="S5.SS2.SSS2.Px1.p5.3.m3.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p5.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p5.3.m3.1c">y_{i}</annotation></semantics></math> but a predicted label <math id="S5.SS2.SSS2.Px1.p5.4.m4.1" class="ltx_Math" alttext="\hat{y}_{j}" display="inline"><semantics id="S5.SS2.SSS2.Px1.p5.4.m4.1a"><msub id="S5.SS2.SSS2.Px1.p5.4.m4.1.1" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.cmml"><mover accent="true" id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.cmml"><mi id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.2" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.2.cmml">y</mi><mo id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.1" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.1.cmml">^</mo></mover><mi id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.3" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p5.4.m4.1b"><apply id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1">subscript</csymbol><apply id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2"><ci id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.1.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.1">^</ci><ci id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.2.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.2.2">𝑦</ci></apply><ci id="S5.SS2.SSS2.Px1.p5.4.m4.1.1.3.cmml" xref="S5.SS2.SSS2.Px1.p5.4.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p5.4.m4.1c">\hat{y}_{j}</annotation></semantics></math>, while <math id="S5.SS2.SSS2.Px1.p5.5.m5.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S5.SS2.SSS2.Px1.p5.5.m5.1a"><mi id="S5.SS2.SSS2.Px1.p5.5.m5.1.1" xref="S5.SS2.SSS2.Px1.p5.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.Px1.p5.5.m5.1b"><ci id="S5.SS2.SSS2.Px1.p5.5.m5.1.1.cmml" xref="S5.SS2.SSS2.Px1.p5.5.m5.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.Px1.p5.5.m5.1c">L</annotation></semantics></math> represents the set of labels in the dataset under consideration.</p>
</div>
<div id="S5.SS2.SSS2.Px1.p6" class="ltx_para">
<table id="S5.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S5.E2.m1.8" class="ltx_Math" alttext="ASR-Backdoor=\frac{\sum_{j=0}^{|L|}c_{j,t}-c_{t,t}}{|D|-c_{t,t}}" display="block"><semantics id="S5.E2.m1.8a"><mrow id="S5.E2.m1.8.9" xref="S5.E2.m1.8.9.cmml"><mrow id="S5.E2.m1.8.9.2" xref="S5.E2.m1.8.9.2.cmml"><mrow id="S5.E2.m1.8.9.2.2" xref="S5.E2.m1.8.9.2.2.cmml"><mi id="S5.E2.m1.8.9.2.2.2" xref="S5.E2.m1.8.9.2.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.2.1" xref="S5.E2.m1.8.9.2.2.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.2.3" xref="S5.E2.m1.8.9.2.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.2.1a" xref="S5.E2.m1.8.9.2.2.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.2.4" xref="S5.E2.m1.8.9.2.2.4.cmml">R</mi></mrow><mo id="S5.E2.m1.8.9.2.1" xref="S5.E2.m1.8.9.2.1.cmml">−</mo><mrow id="S5.E2.m1.8.9.2.3" xref="S5.E2.m1.8.9.2.3.cmml"><mi id="S5.E2.m1.8.9.2.3.2" xref="S5.E2.m1.8.9.2.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.3" xref="S5.E2.m1.8.9.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1a" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.4" xref="S5.E2.m1.8.9.2.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1b" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.5" xref="S5.E2.m1.8.9.2.3.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1c" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.6" xref="S5.E2.m1.8.9.2.3.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1d" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.7" xref="S5.E2.m1.8.9.2.3.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1e" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.8" xref="S5.E2.m1.8.9.2.3.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.8.9.2.3.1f" xref="S5.E2.m1.8.9.2.3.1.cmml">​</mo><mi id="S5.E2.m1.8.9.2.3.9" xref="S5.E2.m1.8.9.2.3.9.cmml">r</mi></mrow></mrow><mo id="S5.E2.m1.8.9.1" xref="S5.E2.m1.8.9.1.cmml">=</mo><mfrac id="S5.E2.m1.8.8" xref="S5.E2.m1.8.8.cmml"><mrow id="S5.E2.m1.5.5.5" xref="S5.E2.m1.5.5.5.cmml"><mrow id="S5.E2.m1.5.5.5.7" xref="S5.E2.m1.5.5.5.7.cmml"><msubsup id="S5.E2.m1.5.5.5.7.1" xref="S5.E2.m1.5.5.5.7.1.cmml"><mo id="S5.E2.m1.5.5.5.7.1.2.2" xref="S5.E2.m1.5.5.5.7.1.2.2.cmml">∑</mo><mrow id="S5.E2.m1.5.5.5.7.1.2.3" xref="S5.E2.m1.5.5.5.7.1.2.3.cmml"><mi id="S5.E2.m1.5.5.5.7.1.2.3.2" xref="S5.E2.m1.5.5.5.7.1.2.3.2.cmml">j</mi><mo id="S5.E2.m1.5.5.5.7.1.2.3.1" xref="S5.E2.m1.5.5.5.7.1.2.3.1.cmml">=</mo><mn id="S5.E2.m1.5.5.5.7.1.2.3.3" xref="S5.E2.m1.5.5.5.7.1.2.3.3.cmml">0</mn></mrow><mrow id="S5.E2.m1.1.1.1.1.1.3" xref="S5.E2.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E2.m1.1.1.1.1.1.3.1" xref="S5.E2.m1.1.1.1.1.1.2.1.cmml">|</mo><mi id="S5.E2.m1.1.1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.1.1.cmml">L</mi><mo stretchy="false" id="S5.E2.m1.1.1.1.1.1.3.2" xref="S5.E2.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></msubsup><msub id="S5.E2.m1.5.5.5.7.2" xref="S5.E2.m1.5.5.5.7.2.cmml"><mi id="S5.E2.m1.5.5.5.7.2.2" xref="S5.E2.m1.5.5.5.7.2.2.cmml">c</mi><mrow id="S5.E2.m1.3.3.3.3.2.4" xref="S5.E2.m1.3.3.3.3.2.3.cmml"><mi id="S5.E2.m1.2.2.2.2.1.1" xref="S5.E2.m1.2.2.2.2.1.1.cmml">j</mi><mo id="S5.E2.m1.3.3.3.3.2.4.1" xref="S5.E2.m1.3.3.3.3.2.3.cmml">,</mo><mi id="S5.E2.m1.3.3.3.3.2.2" xref="S5.E2.m1.3.3.3.3.2.2.cmml">t</mi></mrow></msub></mrow><mo id="S5.E2.m1.5.5.5.6" xref="S5.E2.m1.5.5.5.6.cmml">−</mo><msub id="S5.E2.m1.5.5.5.8" xref="S5.E2.m1.5.5.5.8.cmml"><mi id="S5.E2.m1.5.5.5.8.2" xref="S5.E2.m1.5.5.5.8.2.cmml">c</mi><mrow id="S5.E2.m1.5.5.5.5.2.4" xref="S5.E2.m1.5.5.5.5.2.3.cmml"><mi id="S5.E2.m1.4.4.4.4.1.1" xref="S5.E2.m1.4.4.4.4.1.1.cmml">t</mi><mo id="S5.E2.m1.5.5.5.5.2.4.1" xref="S5.E2.m1.5.5.5.5.2.3.cmml">,</mo><mi id="S5.E2.m1.5.5.5.5.2.2" xref="S5.E2.m1.5.5.5.5.2.2.cmml">t</mi></mrow></msub></mrow><mrow id="S5.E2.m1.8.8.8" xref="S5.E2.m1.8.8.8.cmml"><mrow id="S5.E2.m1.8.8.8.5.2" xref="S5.E2.m1.8.8.8.5.1.cmml"><mo stretchy="false" id="S5.E2.m1.8.8.8.5.2.1" xref="S5.E2.m1.8.8.8.5.1.1.cmml">|</mo><mi id="S5.E2.m1.8.8.8.3" xref="S5.E2.m1.8.8.8.3.cmml">D</mi><mo stretchy="false" id="S5.E2.m1.8.8.8.5.2.2" xref="S5.E2.m1.8.8.8.5.1.1.cmml">|</mo></mrow><mo id="S5.E2.m1.8.8.8.4" xref="S5.E2.m1.8.8.8.4.cmml">−</mo><msub id="S5.E2.m1.8.8.8.6" xref="S5.E2.m1.8.8.8.6.cmml"><mi id="S5.E2.m1.8.8.8.6.2" xref="S5.E2.m1.8.8.8.6.2.cmml">c</mi><mrow id="S5.E2.m1.7.7.7.2.2.4" xref="S5.E2.m1.7.7.7.2.2.3.cmml"><mi id="S5.E2.m1.6.6.6.1.1.1" xref="S5.E2.m1.6.6.6.1.1.1.cmml">t</mi><mo id="S5.E2.m1.7.7.7.2.2.4.1" xref="S5.E2.m1.7.7.7.2.2.3.cmml">,</mo><mi id="S5.E2.m1.7.7.7.2.2.2" xref="S5.E2.m1.7.7.7.2.2.2.cmml">t</mi></mrow></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.8b"><apply id="S5.E2.m1.8.9.cmml" xref="S5.E2.m1.8.9"><eq id="S5.E2.m1.8.9.1.cmml" xref="S5.E2.m1.8.9.1"></eq><apply id="S5.E2.m1.8.9.2.cmml" xref="S5.E2.m1.8.9.2"><minus id="S5.E2.m1.8.9.2.1.cmml" xref="S5.E2.m1.8.9.2.1"></minus><apply id="S5.E2.m1.8.9.2.2.cmml" xref="S5.E2.m1.8.9.2.2"><times id="S5.E2.m1.8.9.2.2.1.cmml" xref="S5.E2.m1.8.9.2.2.1"></times><ci id="S5.E2.m1.8.9.2.2.2.cmml" xref="S5.E2.m1.8.9.2.2.2">𝐴</ci><ci id="S5.E2.m1.8.9.2.2.3.cmml" xref="S5.E2.m1.8.9.2.2.3">𝑆</ci><ci id="S5.E2.m1.8.9.2.2.4.cmml" xref="S5.E2.m1.8.9.2.2.4">𝑅</ci></apply><apply id="S5.E2.m1.8.9.2.3.cmml" xref="S5.E2.m1.8.9.2.3"><times id="S5.E2.m1.8.9.2.3.1.cmml" xref="S5.E2.m1.8.9.2.3.1"></times><ci id="S5.E2.m1.8.9.2.3.2.cmml" xref="S5.E2.m1.8.9.2.3.2">𝐵</ci><ci id="S5.E2.m1.8.9.2.3.3.cmml" xref="S5.E2.m1.8.9.2.3.3">𝑎</ci><ci id="S5.E2.m1.8.9.2.3.4.cmml" xref="S5.E2.m1.8.9.2.3.4">𝑐</ci><ci id="S5.E2.m1.8.9.2.3.5.cmml" xref="S5.E2.m1.8.9.2.3.5">𝑘</ci><ci id="S5.E2.m1.8.9.2.3.6.cmml" xref="S5.E2.m1.8.9.2.3.6">𝑑</ci><ci id="S5.E2.m1.8.9.2.3.7.cmml" xref="S5.E2.m1.8.9.2.3.7">𝑜</ci><ci id="S5.E2.m1.8.9.2.3.8.cmml" xref="S5.E2.m1.8.9.2.3.8">𝑜</ci><ci id="S5.E2.m1.8.9.2.3.9.cmml" xref="S5.E2.m1.8.9.2.3.9">𝑟</ci></apply></apply><apply id="S5.E2.m1.8.8.cmml" xref="S5.E2.m1.8.8"><divide id="S5.E2.m1.8.8.9.cmml" xref="S5.E2.m1.8.8"></divide><apply id="S5.E2.m1.5.5.5.cmml" xref="S5.E2.m1.5.5.5"><minus id="S5.E2.m1.5.5.5.6.cmml" xref="S5.E2.m1.5.5.5.6"></minus><apply id="S5.E2.m1.5.5.5.7.cmml" xref="S5.E2.m1.5.5.5.7"><apply id="S5.E2.m1.5.5.5.7.1.cmml" xref="S5.E2.m1.5.5.5.7.1"><csymbol cd="ambiguous" id="S5.E2.m1.5.5.5.7.1.1.cmml" xref="S5.E2.m1.5.5.5.7.1">superscript</csymbol><apply id="S5.E2.m1.5.5.5.7.1.2.cmml" xref="S5.E2.m1.5.5.5.7.1"><csymbol cd="ambiguous" id="S5.E2.m1.5.5.5.7.1.2.1.cmml" xref="S5.E2.m1.5.5.5.7.1">subscript</csymbol><sum id="S5.E2.m1.5.5.5.7.1.2.2.cmml" xref="S5.E2.m1.5.5.5.7.1.2.2"></sum><apply id="S5.E2.m1.5.5.5.7.1.2.3.cmml" xref="S5.E2.m1.5.5.5.7.1.2.3"><eq id="S5.E2.m1.5.5.5.7.1.2.3.1.cmml" xref="S5.E2.m1.5.5.5.7.1.2.3.1"></eq><ci id="S5.E2.m1.5.5.5.7.1.2.3.2.cmml" xref="S5.E2.m1.5.5.5.7.1.2.3.2">𝑗</ci><cn type="integer" id="S5.E2.m1.5.5.5.7.1.2.3.3.cmml" xref="S5.E2.m1.5.5.5.7.1.2.3.3">0</cn></apply></apply><apply id="S5.E2.m1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.1.1.1.1.1.3"><abs id="S5.E2.m1.1.1.1.1.1.2.1.cmml" xref="S5.E2.m1.1.1.1.1.1.3.1"></abs><ci id="S5.E2.m1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1">𝐿</ci></apply></apply><apply id="S5.E2.m1.5.5.5.7.2.cmml" xref="S5.E2.m1.5.5.5.7.2"><csymbol cd="ambiguous" id="S5.E2.m1.5.5.5.7.2.1.cmml" xref="S5.E2.m1.5.5.5.7.2">subscript</csymbol><ci id="S5.E2.m1.5.5.5.7.2.2.cmml" xref="S5.E2.m1.5.5.5.7.2.2">𝑐</ci><list id="S5.E2.m1.3.3.3.3.2.3.cmml" xref="S5.E2.m1.3.3.3.3.2.4"><ci id="S5.E2.m1.2.2.2.2.1.1.cmml" xref="S5.E2.m1.2.2.2.2.1.1">𝑗</ci><ci id="S5.E2.m1.3.3.3.3.2.2.cmml" xref="S5.E2.m1.3.3.3.3.2.2">𝑡</ci></list></apply></apply><apply id="S5.E2.m1.5.5.5.8.cmml" xref="S5.E2.m1.5.5.5.8"><csymbol cd="ambiguous" id="S5.E2.m1.5.5.5.8.1.cmml" xref="S5.E2.m1.5.5.5.8">subscript</csymbol><ci id="S5.E2.m1.5.5.5.8.2.cmml" xref="S5.E2.m1.5.5.5.8.2">𝑐</ci><list id="S5.E2.m1.5.5.5.5.2.3.cmml" xref="S5.E2.m1.5.5.5.5.2.4"><ci id="S5.E2.m1.4.4.4.4.1.1.cmml" xref="S5.E2.m1.4.4.4.4.1.1">𝑡</ci><ci id="S5.E2.m1.5.5.5.5.2.2.cmml" xref="S5.E2.m1.5.5.5.5.2.2">𝑡</ci></list></apply></apply><apply id="S5.E2.m1.8.8.8.cmml" xref="S5.E2.m1.8.8.8"><minus id="S5.E2.m1.8.8.8.4.cmml" xref="S5.E2.m1.8.8.8.4"></minus><apply id="S5.E2.m1.8.8.8.5.1.cmml" xref="S5.E2.m1.8.8.8.5.2"><abs id="S5.E2.m1.8.8.8.5.1.1.cmml" xref="S5.E2.m1.8.8.8.5.2.1"></abs><ci id="S5.E2.m1.8.8.8.3.cmml" xref="S5.E2.m1.8.8.8.3">𝐷</ci></apply><apply id="S5.E2.m1.8.8.8.6.cmml" xref="S5.E2.m1.8.8.8.6"><csymbol cd="ambiguous" id="S5.E2.m1.8.8.8.6.1.cmml" xref="S5.E2.m1.8.8.8.6">subscript</csymbol><ci id="S5.E2.m1.8.8.8.6.2.cmml" xref="S5.E2.m1.8.8.8.6.2">𝑐</ci><list id="S5.E2.m1.7.7.7.2.2.3.cmml" xref="S5.E2.m1.7.7.7.2.2.4"><ci id="S5.E2.m1.6.6.6.1.1.1.cmml" xref="S5.E2.m1.6.6.6.1.1.1">𝑡</ci><ci id="S5.E2.m1.7.7.7.2.2.2.cmml" xref="S5.E2.m1.7.7.7.2.2.2">𝑡</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.8c">ASR-Backdoor=\frac{\sum_{j=0}^{|L|}c_{j,t}-c_{t,t}}{|D|-c_{t,t}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS2.SSS2.Px1.p7" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p7.1" class="ltx_p">The ASR metrics are calculated as the mean result across all benign participants, with higher values indicating greater effectiveness of the targeted attack.</p>
</div>
<figure id="S5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F11.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.08652/assets/x12.png" id="S5.F11.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="181" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F11.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.08652/assets/x13.png" id="S5.F11.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="167" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.4.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S5.F11.5.2" class="ltx_text" style="font-size:90%;">Average ASR Results for Targeted Poisoning Attacks with Random Topologies</span></figcaption>
</figure>
</section>
<section id="S5.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(ii)<span id="S5.SS2.SSS2.Px2.1.1" class="ltx_text ltx_font_upright"> Attack Effectiveness</span>
</h5>

<div id="S5.SS2.SSS2.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px2.p1.1" class="ltx_p"><span id="S5.SS2.SSS2.Px2.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS2.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.Px2.p2.1" class="ltx_p">Figure <a href="#S5.F10" title="Figure 10 ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents the average ASR metrics of Targeted Label Flipping and Backdoor attacks on CFL and DFL with three datasets as the PNR increases. Based on the results, in terms of attack effectiveness, the Backdoor Attack, which utilizes manipulated data samples, is found to be more effective than the Targeted Label Flipping attack, which uses manipulated labels. From the experimental results, it becomes evident that more than 30% of nodes injected with a backdoor can lead to a backdoor injection success rate of over 50% in all three datasets. Targeted Label Flipping requires at least 50% of the nodes to be attacked to achieve similar results, and if the PNR is below 30%, the influence on the models is considered negligible.</p>
</div>
</section>
<section id="S5.SS2.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(iii)<span id="S5.SS2.SSS2.Px3.1.1" class="ltx_text ltx_font_upright"> Model Robustness in Different Paradigms and Topologies</span>
</h5>

<div id="S5.SS2.SSS2.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px3.p1.1" class="ltx_p"><span id="S5.SS2.SSS2.Px3.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS2.Px3.p2" class="ltx_para">
<p id="S5.SS2.SSS2.Px3.p2.1" class="ltx_p">As in the case of untargeted attacks, CFL and DFL with fully connected topology demonstrate similar model robustness against targeted attacks. When the poisoned node proportion is low, the influence of this type of attack on the overall performance of the federation is insignificant, particularly in the case of Targeted Label Flipping.</p>
</div>
<div id="S5.SS2.SSS2.Px3.p3" class="ltx_para">
<p id="S5.SS2.SSS2.Px3.p3.1" class="ltx_p">This section evaluates the impact of different topologies on targeted poisoning attacks by implementing the same setups of random topology experiments of untargeted attacks. The results of this experiment are shown in Figure <a href="#S5.F11" title="Figure 11 ‣ (i) Evaluation Metrics for Targeted Attacks ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. Similar to untargeted attacks, topology has an impact on the effectiveness of targeted attacks. A denser network facilitates the spread of targeted attacks, but the aggregation of more models also has a negative effect on the maliciousness. Thus, a higher ASR is observed in a low-density network than in a high-density network. However, for the Backdoor Attack, once the PNR exceeds 50%, the impact of topology becomes less significant.</p>
</div>
<div id="S5.SS2.SSS2.Px3.p4" class="ltx_para">
<p id="S5.SS2.SSS2.Px3.p4.1" class="ltx_p">To summarize, Backdoor attacks by manipulating data are more effective than Target Label Flipping attacks by manipulating labels. Meanwhile, similar to untargeted attacks, the robustness of the model against targeted poisoning attacks for CFL and DFL with fully connected topology is roughly the same. Besides, the topology of the network plays a crucial role in the spread of maliciousness. When benign nodes are directly connected to malicious nodes, the more sparse the network, the more vulnerable they are to attacks.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.3.2" class="ltx_text" style="font-size:90%;">Benchmark of Average F1-Score Results for Defense Mechanisms in Mitigating Untargeted Poisoning Attacks</span></figcaption>
<div id="S5.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:843.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-181.0pt,352.2pt) scale(0.545013927834098,0.545013927834098) ;">
<table id="S5.T4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T4.4.1.1" class="ltx_tr">
<td id="S5.T4.4.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S5.T4.4.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S5.T4.4.1.1.3" class="ltx_td ltx_border_tt"></td>
<td id="S5.T4.4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T4.4.1.1.4.1" class="ltx_text ltx_font_bold">Label Flipping</span></td>
<td id="S5.T4.4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T4.4.1.1.5.1" class="ltx_text ltx_font_bold">Model Poisoning</span></td>
<td id="S5.T4.4.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T4.4.1.1.6.1" class="ltx_text ltx_font_bold">Sample Poisoning</span></td>
</tr>
<tr id="S5.T4.4.1.2" class="ltx_tr">
<td id="S5.T4.4.1.2.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T4.4.1.2.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T4.4.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.3.1" class="ltx_text ltx_font_bold">[PNR (%)]</span></td>
<td id="S5.T4.4.1.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.4.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T4.4.1.2.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.5.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T4.4.1.2.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.6.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T4.4.1.2.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.7.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T4.4.1.2.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T4.4.1.2.8.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T4.4.1.2.9" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.9.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T4.4.1.2.10" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.10.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T4.4.1.2.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.11.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T4.4.1.2.12" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.12.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T4.4.1.2.13" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T4.4.1.2.13.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T4.4.1.2.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.14.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T4.4.1.2.15" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.15.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T4.4.1.2.16" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.16.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T4.4.1.2.17" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.17.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T4.4.1.2.18" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.2.18.1" class="ltx_text ltx_font_bold">90</span></td>
</tr>
<tr id="S5.T4.4.1.3" class="ltx_tr">
<td id="S5.T4.4.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="28"><span id="S5.T4.4.1.3.1.1" class="ltx_text ltx_font_bold">CIFAR10</span></td>
<td id="S5.T4.4.1.3.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.3.2.1" class="ltx_text ltx_font_bold">CFL</span></td>
<td id="S5.T4.4.1.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.3.3.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.3.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.3.4.1" class="ltx_text ltx_font_bold">69.2%</span></td>
<td id="S5.T4.4.1.3.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.3.5.1" class="ltx_text ltx_font_bold">67.8%</span></td>
<td id="S5.T4.4.1.3.6" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.3.7" class="ltx_td ltx_align_left ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.3.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.3.9" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.3.10" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.3.11" class="ltx_td ltx_align_left ltx_border_t">2.0%</td>
<td id="S5.T4.4.1.3.12" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.3.13" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.0%</td>
<td id="S5.T4.4.1.3.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.3.14.1" class="ltx_text ltx_font_bold">71.2%</span></td>
<td id="S5.T4.4.1.3.15" class="ltx_td ltx_align_left ltx_border_t">58.7%</td>
<td id="S5.T4.4.1.3.16" class="ltx_td ltx_align_left ltx_border_t">20.9%</td>
<td id="S5.T4.4.1.3.17" class="ltx_td ltx_align_left ltx_border_t">8.0%</td>
<td id="S5.T4.4.1.3.18" class="ltx_td ltx_align_left ltx_border_t">3.3%</td>
</tr>
<tr id="S5.T4.4.1.4" class="ltx_tr">
<td id="S5.T4.4.1.4.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.4.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.4.2" class="ltx_td ltx_align_left">60.1%</td>
<td id="S5.T4.4.1.4.3" class="ltx_td ltx_align_left">61.0%</td>
<td id="S5.T4.4.1.4.4" class="ltx_td ltx_align_left">59.6%</td>
<td id="S5.T4.4.1.4.5" class="ltx_td ltx_align_left">56.2%</td>
<td id="S5.T4.4.1.4.6" class="ltx_td ltx_align_left ltx_border_r">29.5%</td>
<td id="S5.T4.4.1.4.7" class="ltx_td ltx_align_left">41.4%</td>
<td id="S5.T4.4.1.4.8" class="ltx_td ltx_align_left">54.7%</td>
<td id="S5.T4.4.1.4.9" class="ltx_td ltx_align_left">50.2%</td>
<td id="S5.T4.4.1.4.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.4.11" class="ltx_td ltx_align_left ltx_border_r">2.9%</td>
<td id="S5.T4.4.1.4.12" class="ltx_td ltx_align_left">63.2%</td>
<td id="S5.T4.4.1.4.13" class="ltx_td ltx_align_left">59.0%</td>
<td id="S5.T4.4.1.4.14" class="ltx_td ltx_align_left">49.8%</td>
<td id="S5.T4.4.1.4.15" class="ltx_td ltx_align_left">39.6%</td>
<td id="S5.T4.4.1.4.16" class="ltx_td ltx_align_left">2.2%</td>
</tr>
<tr id="S5.T4.4.1.5" class="ltx_tr">
<td id="S5.T4.4.1.5.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.5.2" class="ltx_td ltx_align_left">62.7%</td>
<td id="S5.T4.4.1.5.3" class="ltx_td ltx_align_left">63.6%</td>
<td id="S5.T4.4.1.5.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.4.1" class="ltx_text ltx_font_bold">61.8%</span></td>
<td id="S5.T4.4.1.5.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.5.1" class="ltx_text ltx_font_bold">60.8%</span></td>
<td id="S5.T4.4.1.5.6" class="ltx_td ltx_align_left ltx_border_r">30.2%</td>
<td id="S5.T4.4.1.5.7" class="ltx_td ltx_align_left">52.9%</td>
<td id="S5.T4.4.1.5.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.8.1" class="ltx_text ltx_font_bold">63.6%</span></td>
<td id="S5.T4.4.1.5.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.9.1" class="ltx_text ltx_font_bold">61.8%</span></td>
<td id="S5.T4.4.1.5.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.5.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.5.12" class="ltx_td ltx_align_left">65.2%</td>
<td id="S5.T4.4.1.5.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.13.1" class="ltx_text ltx_font_bold">63.3%</span></td>
<td id="S5.T4.4.1.5.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.14.1" class="ltx_text ltx_font_bold">61.8%</span></td>
<td id="S5.T4.4.1.5.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.5.15.1" class="ltx_text ltx_font_bold">43.8%</span></td>
<td id="S5.T4.4.1.5.16" class="ltx_td ltx_align_left">1.9%</td>
</tr>
<tr id="S5.T4.4.1.6" class="ltx_tr">
<td id="S5.T4.4.1.6.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.6.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.6.2" class="ltx_td ltx_align_left">68.9%</td>
<td id="S5.T4.4.1.6.3" class="ltx_td ltx_align_left">52.7%</td>
<td id="S5.T4.4.1.6.4" class="ltx_td ltx_align_left">55.0%</td>
<td id="S5.T4.4.1.6.5" class="ltx_td ltx_align_left">47.3%</td>
<td id="S5.T4.4.1.6.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.6.6.1" class="ltx_text ltx_font_bold">32.5%</span></td>
<td id="S5.T4.4.1.6.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.6.7.1" class="ltx_text ltx_font_bold">60.5%</span></td>
<td id="S5.T4.4.1.6.8" class="ltx_td ltx_align_left">40.3%</td>
<td id="S5.T4.4.1.6.9" class="ltx_td ltx_align_left">18.2%</td>
<td id="S5.T4.4.1.6.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.6.10.1" class="ltx_text ltx_font_bold">14.3%</span></td>
<td id="S5.T4.4.1.6.11" class="ltx_td ltx_align_left ltx_border_r">6.3%</td>
<td id="S5.T4.4.1.6.12" class="ltx_td ltx_align_left">62.7%</td>
<td id="S5.T4.4.1.6.13" class="ltx_td ltx_align_left">43.1%</td>
<td id="S5.T4.4.1.6.14" class="ltx_td ltx_align_left">57.4%</td>
<td id="S5.T4.4.1.6.15" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.6.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.6.16.1" class="ltx_text ltx_font_bold">27.1%</span></td>
</tr>
<tr id="S5.T4.4.1.7" class="ltx_tr">
<td id="S5.T4.4.1.7.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.7.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.7.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.7.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.7.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.7.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.8" class="ltx_tr">
<td id="S5.T4.4.1.8.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.8.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.8.2" class="ltx_td ltx_align_left">60.6%</td>
<td id="S5.T4.4.1.8.3" class="ltx_td ltx_align_left">54.9%</td>
<td id="S5.T4.4.1.8.4" class="ltx_td ltx_align_left">53.0%</td>
<td id="S5.T4.4.1.8.5" class="ltx_td ltx_align_left">47.3%</td>
<td id="S5.T4.4.1.8.6" class="ltx_td ltx_align_left ltx_border_r">32.2%</td>
<td id="S5.T4.4.1.8.7" class="ltx_td ltx_align_left">2.6%</td>
<td id="S5.T4.4.1.8.8" class="ltx_td ltx_align_left">22.5%</td>
<td id="S5.T4.4.1.8.9" class="ltx_td ltx_align_left">7.3%</td>
<td id="S5.T4.4.1.8.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.8.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.8.11.1" class="ltx_text ltx_font_bold">8.0%</span></td>
<td id="S5.T4.4.1.8.12" class="ltx_td ltx_align_left">68.1%</td>
<td id="S5.T4.4.1.8.13" class="ltx_td ltx_align_left">54.6%</td>
<td id="S5.T4.4.1.8.14" class="ltx_td ltx_align_left">13.7%</td>
<td id="S5.T4.4.1.8.15" class="ltx_td ltx_align_left">32.7%</td>
<td id="S5.T4.4.1.8.16" class="ltx_td ltx_align_left">4.2%</td>
</tr>
<tr id="S5.T4.4.1.9" class="ltx_tr">
<td id="S5.T4.4.1.9.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.9.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.9.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.9.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.9.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.9.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.10" class="ltx_tr">
<td id="S5.T4.4.1.10.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S5.T4.4.1.10.1.1" class="ltx_text ltx_font_bold">DFL-Fully</span></td>
<td id="S5.T4.4.1.10.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.10.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.10.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.10.3.1" class="ltx_text ltx_font_bold">72.9%</span></td>
<td id="S5.T4.4.1.10.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.10.4.1" class="ltx_text ltx_font_bold">70.4%</span></td>
<td id="S5.T4.4.1.10.5" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.10.6" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.10.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.10.8" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.10.9" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.10.10" class="ltx_td ltx_align_left ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.10.11" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.10.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.0%</td>
<td id="S5.T4.4.1.10.13" class="ltx_td ltx_align_left ltx_border_t">69.9%</td>
<td id="S5.T4.4.1.10.14" class="ltx_td ltx_align_left ltx_border_t">58.9%</td>
<td id="S5.T4.4.1.10.15" class="ltx_td ltx_align_left ltx_border_t">21.9%</td>
<td id="S5.T4.4.1.10.16" class="ltx_td ltx_align_left ltx_border_t">8.0%</td>
<td id="S5.T4.4.1.10.17" class="ltx_td ltx_align_left ltx_border_t">3.2%</td>
</tr>
<tr id="S5.T4.4.1.11" class="ltx_tr">
<td id="S5.T4.4.1.11.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.11.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.11.2" class="ltx_td ltx_align_left">51.9%</td>
<td id="S5.T4.4.1.11.3" class="ltx_td ltx_align_left">52.2%</td>
<td id="S5.T4.4.1.11.4" class="ltx_td ltx_align_left">34.4%</td>
<td id="S5.T4.4.1.11.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.11.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.11.7" class="ltx_td ltx_align_left">52.3%</td>
<td id="S5.T4.4.1.11.8" class="ltx_td ltx_align_left">51.3%</td>
<td id="S5.T4.4.1.11.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.11.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.11.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.11.12" class="ltx_td ltx_align_left">68.1%</td>
<td id="S5.T4.4.1.11.13" class="ltx_td ltx_align_left">61.9%</td>
<td id="S5.T4.4.1.11.14" class="ltx_td ltx_align_left">38.5%</td>
<td id="S5.T4.4.1.11.15" class="ltx_td ltx_align_left">2.5%</td>
<td id="S5.T4.4.1.11.16" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.12" class="ltx_tr">
<td id="S5.T4.4.1.12.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.12.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.12.2" class="ltx_td ltx_align_left">65.6%</td>
<td id="S5.T4.4.1.12.3" class="ltx_td ltx_align_left">65.8%</td>
<td id="S5.T4.4.1.12.4" class="ltx_td ltx_align_left">43.8%</td>
<td id="S5.T4.4.1.12.5" class="ltx_td ltx_align_left">2.0%</td>
<td id="S5.T4.4.1.12.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.12.7" class="ltx_td ltx_align_left">66.0%</td>
<td id="S5.T4.4.1.12.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.12.8.1" class="ltx_text ltx_font_bold">67.7%</span></td>
<td id="S5.T4.4.1.12.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.12.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.12.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.12.12" class="ltx_td ltx_align_left">66.5%</td>
<td id="S5.T4.4.1.12.13" class="ltx_td ltx_align_left">65.3%</td>
<td id="S5.T4.4.1.12.14" class="ltx_td ltx_align_left">47.8%</td>
<td id="S5.T4.4.1.12.15" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.12.16" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.13" class="ltx_tr">
<td id="S5.T4.4.1.13.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.13.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.13.2" class="ltx_td ltx_align_left">66.1%</td>
<td id="S5.T4.4.1.13.3" class="ltx_td ltx_align_left">68.4%</td>
<td id="S5.T4.4.1.13.4" class="ltx_td ltx_align_left">12.5%</td>
<td id="S5.T4.4.1.13.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.13.6" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.13.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.13.7.1" class="ltx_text ltx_font_bold">70.1%</span></td>
<td id="S5.T4.4.1.13.8" class="ltx_td ltx_align_left">18.7%</td>
<td id="S5.T4.4.1.13.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.13.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.13.11" class="ltx_td ltx_align_left ltx_border_r">1.6%</td>
<td id="S5.T4.4.1.13.12" class="ltx_td ltx_align_left">70.3%</td>
<td id="S5.T4.4.1.13.13" class="ltx_td ltx_align_left">61.2%</td>
<td id="S5.T4.4.1.13.14" class="ltx_td ltx_align_left">39.0%</td>
<td id="S5.T4.4.1.13.15" class="ltx_td ltx_align_left">3.6%</td>
<td id="S5.T4.4.1.13.16" class="ltx_td ltx_align_left">2.3%</td>
</tr>
<tr id="S5.T4.4.1.14" class="ltx_tr">
<td id="S5.T4.4.1.14.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.1.1" class="ltx_text ltx_font_bold">Connected</span></td>
<td id="S5.T4.4.1.14.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.2.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.14.3" class="ltx_td ltx_align_left">66.4%</td>
<td id="S5.T4.4.1.14.4" class="ltx_td ltx_align_left">66.0%</td>
<td id="S5.T4.4.1.14.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.5.1" class="ltx_text ltx_font_bold">67.0%</span></td>
<td id="S5.T4.4.1.14.6" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.6.1" class="ltx_text ltx_font_bold">65.9%</span></td>
<td id="S5.T4.4.1.14.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.14.7.1" class="ltx_text ltx_font_bold">67.4%</span></td>
<td id="S5.T4.4.1.14.8" class="ltx_td ltx_align_left">67.1%</td>
<td id="S5.T4.4.1.14.9" class="ltx_td ltx_align_left">65.5%</td>
<td id="S5.T4.4.1.14.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.10.1" class="ltx_text ltx_font_bold">67.1%</span></td>
<td id="S5.T4.4.1.14.11" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.11.1" class="ltx_text ltx_font_bold">66.8%</span></td>
<td id="S5.T4.4.1.14.12" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.14.12.1" class="ltx_text ltx_font_bold">67.4%</span></td>
<td id="S5.T4.4.1.14.13" class="ltx_td ltx_align_left">66.1%</td>
<td id="S5.T4.4.1.14.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.14.1" class="ltx_text ltx_font_bold">67.4%</span></td>
<td id="S5.T4.4.1.14.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.15.1" class="ltx_text ltx_font_bold">65.4%</span></td>
<td id="S5.T4.4.1.14.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.16.1" class="ltx_text ltx_font_bold">66.4%</span></td>
<td id="S5.T4.4.1.14.17" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.14.17.1" class="ltx_text ltx_font_bold">67.4%</span></td>
</tr>
<tr id="S5.T4.4.1.15" class="ltx_tr">
<td id="S5.T4.4.1.15.1" class="ltx_td"></td>
<td id="S5.T4.4.1.15.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.15.2.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.15.3" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.4" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.6" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.7" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.15.8" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.15.11" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.15.12" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.15.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.15.13.1" class="ltx_text ltx_font_bold">72.1%</span></td>
<td id="S5.T4.4.1.15.14" class="ltx_td ltx_align_left">56.7%</td>
<td id="S5.T4.4.1.15.15" class="ltx_td ltx_align_left">11.9%</td>
<td id="S5.T4.4.1.15.16" class="ltx_td ltx_align_left">6.1%</td>
<td id="S5.T4.4.1.15.17" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.16" class="ltx_tr">
<td id="S5.T4.4.1.16.1" class="ltx_td"></td>
<td id="S5.T4.4.1.16.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.16.2.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.16.3" class="ltx_td ltx_align_left">63.8%</td>
<td id="S5.T4.4.1.16.4" class="ltx_td ltx_align_left">64.6%</td>
<td id="S5.T4.4.1.16.5" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T4.4.1.16.6" class="ltx_td ltx_align_left">62.8%</td>
<td id="S5.T4.4.1.16.7" class="ltx_td ltx_align_left ltx_border_r">65.5%</td>
<td id="S5.T4.4.1.16.8" class="ltx_td ltx_align_left">65.4%</td>
<td id="S5.T4.4.1.16.9" class="ltx_td ltx_align_left">64.0%</td>
<td id="S5.T4.4.1.16.10" class="ltx_td ltx_align_left">65.2%</td>
<td id="S5.T4.4.1.16.11" class="ltx_td ltx_align_left">64.3%</td>
<td id="S5.T4.4.1.16.12" class="ltx_td ltx_align_left ltx_border_r">64.3%</td>
<td id="S5.T4.4.1.16.13" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T4.4.1.16.14" class="ltx_td ltx_align_left">65.9%</td>
<td id="S5.T4.4.1.16.15" class="ltx_td ltx_align_left">63.3%</td>
<td id="S5.T4.4.1.16.16" class="ltx_td ltx_align_left">63.9%</td>
<td id="S5.T4.4.1.16.17" class="ltx_td ltx_align_left">65.2%</td>
</tr>
<tr id="S5.T4.4.1.17" class="ltx_tr">
<td id="S5.T4.4.1.17.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.17.1.1" class="ltx_text ltx_font_bold">DFL-Ring</span></td>
<td id="S5.T4.4.1.17.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.17.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.17.3" class="ltx_td ltx_align_left ltx_border_t">64.0%</td>
<td id="S5.T4.4.1.17.4" class="ltx_td ltx_align_left ltx_border_t">62.6%</td>
<td id="S5.T4.4.1.17.5" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.17.6" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.17.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.17.8" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.17.9" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.17.10" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.17.11" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.17.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.17.13" class="ltx_td ltx_align_left ltx_border_t">64.1%</td>
<td id="S5.T4.4.1.17.14" class="ltx_td ltx_align_left ltx_border_t">54.2%</td>
<td id="S5.T4.4.1.17.15" class="ltx_td ltx_align_left ltx_border_t">19.4%</td>
<td id="S5.T4.4.1.17.16" class="ltx_td ltx_align_left ltx_border_t">7.4%</td>
<td id="S5.T4.4.1.17.17" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
</tr>
<tr id="S5.T4.4.1.18" class="ltx_tr">
<td id="S5.T4.4.1.18.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.18.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.18.2" class="ltx_td ltx_align_left">52.8%</td>
<td id="S5.T4.4.1.18.3" class="ltx_td ltx_align_left">51.3%</td>
<td id="S5.T4.4.1.18.4" class="ltx_td ltx_align_left">21.8%</td>
<td id="S5.T4.4.1.18.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.18.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.18.7" class="ltx_td ltx_align_left">53.1%</td>
<td id="S5.T4.4.1.18.8" class="ltx_td ltx_align_left">52.2%</td>
<td id="S5.T4.4.1.18.9" class="ltx_td ltx_align_left">3.5%</td>
<td id="S5.T4.4.1.18.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.18.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.18.12" class="ltx_td ltx_align_left">64.8%</td>
<td id="S5.T4.4.1.18.13" class="ltx_td ltx_align_left">62.2%</td>
<td id="S5.T4.4.1.18.14" class="ltx_td ltx_align_left">45.3%</td>
<td id="S5.T4.4.1.18.15" class="ltx_td ltx_align_left">5.1%</td>
<td id="S5.T4.4.1.18.16" class="ltx_td ltx_align_left">4.6%</td>
</tr>
<tr id="S5.T4.4.1.19" class="ltx_tr">
<td id="S5.T4.4.1.19.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.19.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.19.2" class="ltx_td ltx_align_left">65.9%</td>
<td id="S5.T4.4.1.19.3" class="ltx_td ltx_align_left">65.3%</td>
<td id="S5.T4.4.1.19.4" class="ltx_td ltx_align_left">27.1%</td>
<td id="S5.T4.4.1.19.5" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.19.6" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.19.7" class="ltx_td ltx_align_left">67.0%</td>
<td id="S5.T4.4.1.19.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.19.8.1" class="ltx_text ltx_font_bold">66.8%</span></td>
<td id="S5.T4.4.1.19.9" class="ltx_td ltx_align_left">4.0%</td>
<td id="S5.T4.4.1.19.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.19.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.19.12" class="ltx_td ltx_align_left">67.2%</td>
<td id="S5.T4.4.1.19.13" class="ltx_td ltx_align_left">64.8%</td>
<td id="S5.T4.4.1.19.14" class="ltx_td ltx_align_left">51.2%</td>
<td id="S5.T4.4.1.19.15" class="ltx_td ltx_align_left">2.3%</td>
<td id="S5.T4.4.1.19.16" class="ltx_td ltx_align_left">5.4%</td>
</tr>
<tr id="S5.T4.4.1.20" class="ltx_tr">
<td id="S5.T4.4.1.20.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.20.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.20.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.20.2.1" class="ltx_text ltx_font_bold">72.7%</span></td>
<td id="S5.T4.4.1.20.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.20.3.1" class="ltx_text ltx_font_bold">70.5%</span></td>
<td id="S5.T4.4.1.20.4" class="ltx_td ltx_align_left">63.7%</td>
<td id="S5.T4.4.1.20.5" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.20.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.20.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.20.7.1" class="ltx_text ltx_font_bold">71.0%</span></td>
<td id="S5.T4.4.1.20.8" class="ltx_td ltx_align_left">4.6%</td>
<td id="S5.T4.4.1.20.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.20.10" class="ltx_td ltx_align_left">2.0%</td>
<td id="S5.T4.4.1.20.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.20.12" class="ltx_td ltx_align_left">69.6%</td>
<td id="S5.T4.4.1.20.13" class="ltx_td ltx_align_left">66.3%</td>
<td id="S5.T4.4.1.20.14" class="ltx_td ltx_align_left">59.3%</td>
<td id="S5.T4.4.1.20.15" class="ltx_td ltx_align_left">8.5%</td>
<td id="S5.T4.4.1.20.16" class="ltx_td ltx_align_left">4.3%</td>
</tr>
<tr id="S5.T4.4.1.21" class="ltx_tr">
<td id="S5.T4.4.1.21.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.21.2" class="ltx_td ltx_align_left">65.7%</td>
<td id="S5.T4.4.1.21.3" class="ltx_td ltx_align_left">65.6%</td>
<td id="S5.T4.4.1.21.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.4.1" class="ltx_text ltx_font_bold">66.3%</span></td>
<td id="S5.T4.4.1.21.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.5.1" class="ltx_text ltx_font_bold">65.1%</span></td>
<td id="S5.T4.4.1.21.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.21.6.1" class="ltx_text ltx_font_bold">65.4%</span></td>
<td id="S5.T4.4.1.21.7" class="ltx_td ltx_align_left">67.0%</td>
<td id="S5.T4.4.1.21.8" class="ltx_td ltx_align_left">66.1%</td>
<td id="S5.T4.4.1.21.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.9.1" class="ltx_text ltx_font_bold">66.5%</span></td>
<td id="S5.T4.4.1.21.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.10.1" class="ltx_text ltx_font_bold">66.5%</span></td>
<td id="S5.T4.4.1.21.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.21.11.1" class="ltx_text ltx_font_bold">66.6%</span></td>
<td id="S5.T4.4.1.21.12" class="ltx_td ltx_align_left">64.5%</td>
<td id="S5.T4.4.1.21.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.13.1" class="ltx_text ltx_font_bold">67.0%</span></td>
<td id="S5.T4.4.1.21.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.14.1" class="ltx_text ltx_font_bold">66.3%</span></td>
<td id="S5.T4.4.1.21.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.15.1" class="ltx_text ltx_font_bold">65.5%</span></td>
<td id="S5.T4.4.1.21.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.21.16.1" class="ltx_text ltx_font_bold">67.0%</span></td>
</tr>
<tr id="S5.T4.4.1.22" class="ltx_tr">
<td id="S5.T4.4.1.22.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.22.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.22.2" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.22.3" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.22.4" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.22.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.22.6" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.22.7" class="ltx_td ltx_align_left">2.1%</td>
<td id="S5.T4.4.1.22.8" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.22.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.22.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.22.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.22.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.22.12.1" class="ltx_text ltx_font_bold">70.2%</span></td>
<td id="S5.T4.4.1.22.13" class="ltx_td ltx_align_left">61.5%</td>
<td id="S5.T4.4.1.22.14" class="ltx_td ltx_align_left">27.4%</td>
<td id="S5.T4.4.1.22.15" class="ltx_td ltx_align_left">15.9%</td>
<td id="S5.T4.4.1.22.16" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.23" class="ltx_tr">
<td id="S5.T4.4.1.23.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.23.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.23.2" class="ltx_td ltx_align_left">63.2%</td>
<td id="S5.T4.4.1.23.3" class="ltx_td ltx_align_left">62.9%</td>
<td id="S5.T4.4.1.23.4" class="ltx_td ltx_align_left">64.2%</td>
<td id="S5.T4.4.1.23.5" class="ltx_td ltx_align_left">63.6%</td>
<td id="S5.T4.4.1.23.6" class="ltx_td ltx_align_left ltx_border_r">65.2%</td>
<td id="S5.T4.4.1.23.7" class="ltx_td ltx_align_left">64.2%</td>
<td id="S5.T4.4.1.23.8" class="ltx_td ltx_align_left">63.0%</td>
<td id="S5.T4.4.1.23.9" class="ltx_td ltx_align_left">65.1%</td>
<td id="S5.T4.4.1.23.10" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T4.4.1.23.11" class="ltx_td ltx_align_left ltx_border_r">63.8%</td>
<td id="S5.T4.4.1.23.12" class="ltx_td ltx_align_left">62.6%</td>
<td id="S5.T4.4.1.23.13" class="ltx_td ltx_align_left">64.5%</td>
<td id="S5.T4.4.1.23.14" class="ltx_td ltx_align_left">64.1%</td>
<td id="S5.T4.4.1.23.15" class="ltx_td ltx_align_left">64.5%</td>
<td id="S5.T4.4.1.23.16" class="ltx_td ltx_align_left">64.6%</td>
</tr>
<tr id="S5.T4.4.1.24" class="ltx_tr">
<td id="S5.T4.4.1.24.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.24.1.1" class="ltx_text ltx_font_bold">DFL-Star</span></td>
<td id="S5.T4.4.1.24.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.24.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.24.3" class="ltx_td ltx_align_left ltx_border_t">62.9%</td>
<td id="S5.T4.4.1.24.4" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.24.5" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.24.6" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.24.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.24.8" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.24.9" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.24.10" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.24.11" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.24.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.24.13" class="ltx_td ltx_align_left ltx_border_t">57.5%</td>
<td id="S5.T4.4.1.24.14" class="ltx_td ltx_align_left ltx_border_t">52.2%</td>
<td id="S5.T4.4.1.24.15" class="ltx_td ltx_align_left ltx_border_t">19.0%</td>
<td id="S5.T4.4.1.24.16" class="ltx_td ltx_align_left ltx_border_t">3.1%</td>
<td id="S5.T4.4.1.24.17" class="ltx_td ltx_align_left ltx_border_t">3.0%</td>
</tr>
<tr id="S5.T4.4.1.25" class="ltx_tr">
<td id="S5.T4.4.1.25.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.25.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.25.2" class="ltx_td ltx_align_left">53.8%</td>
<td id="S5.T4.4.1.25.3" class="ltx_td ltx_align_left">49.3%</td>
<td id="S5.T4.4.1.25.4" class="ltx_td ltx_align_left">52.5%</td>
<td id="S5.T4.4.1.25.5" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.25.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.25.7" class="ltx_td ltx_align_left">50.1%</td>
<td id="S5.T4.4.1.25.8" class="ltx_td ltx_align_left">51.5%</td>
<td id="S5.T4.4.1.25.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.25.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.25.11" class="ltx_td ltx_align_left ltx_border_r">2.0%</td>
<td id="S5.T4.4.1.25.12" class="ltx_td ltx_align_left">62.2%</td>
<td id="S5.T4.4.1.25.13" class="ltx_td ltx_align_left">59.3%</td>
<td id="S5.T4.4.1.25.14" class="ltx_td ltx_align_left">53.2%</td>
<td id="S5.T4.4.1.25.15" class="ltx_td ltx_align_left">4.6%</td>
<td id="S5.T4.4.1.25.16" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.26" class="ltx_tr">
<td id="S5.T4.4.1.26.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.26.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.26.2" class="ltx_td ltx_align_left">69.1%</td>
<td id="S5.T4.4.1.26.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.26.3.1" class="ltx_text ltx_font_bold">63.9%</span></td>
<td id="S5.T4.4.1.26.4" class="ltx_td ltx_align_left">65.4%</td>
<td id="S5.T4.4.1.26.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.26.6" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.26.7" class="ltx_td ltx_align_left">64.8%</td>
<td id="S5.T4.4.1.26.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.26.8.1" class="ltx_text ltx_font_bold">67.2%</span></td>
<td id="S5.T4.4.1.26.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.26.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.26.11" class="ltx_td ltx_align_left ltx_border_r">2.0%</td>
<td id="S5.T4.4.1.26.12" class="ltx_td ltx_align_left">63.6%</td>
<td id="S5.T4.4.1.26.13" class="ltx_td ltx_align_left">62.7%</td>
<td id="S5.T4.4.1.26.14" class="ltx_td ltx_align_left">60.4%</td>
<td id="S5.T4.4.1.26.15" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.26.16" class="ltx_td ltx_align_left">1.8%</td>
</tr>
<tr id="S5.T4.4.1.27" class="ltx_tr">
<td id="S5.T4.4.1.27.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.27.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.27.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.27.2.1" class="ltx_text ltx_font_bold">71.2%</span></td>
<td id="S5.T4.4.1.27.3" class="ltx_td ltx_align_left">24.5%</td>
<td id="S5.T4.4.1.27.4" class="ltx_td ltx_align_left">36.7%</td>
<td id="S5.T4.4.1.27.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.27.6" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.27.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.27.7.1" class="ltx_text ltx_font_bold">71.0%</span></td>
<td id="S5.T4.4.1.27.8" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.27.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.27.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.27.11" class="ltx_td ltx_align_left ltx_border_r">1.6%</td>
<td id="S5.T4.4.1.27.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.27.12.1" class="ltx_text ltx_font_bold">71.1%</span></td>
<td id="S5.T4.4.1.27.13" class="ltx_td ltx_align_left">36.1%</td>
<td id="S5.T4.4.1.27.14" class="ltx_td ltx_align_left">30.5%</td>
<td id="S5.T4.4.1.27.15" class="ltx_td ltx_align_left">4.9%</td>
<td id="S5.T4.4.1.27.16" class="ltx_td ltx_align_left">2.1%</td>
</tr>
<tr id="S5.T4.4.1.28" class="ltx_tr">
<td id="S5.T4.4.1.28.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.28.2" class="ltx_td ltx_align_left">67.5%</td>
<td id="S5.T4.4.1.28.3" class="ltx_td ltx_align_left">65.5%</td>
<td id="S5.T4.4.1.28.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.4.1" class="ltx_text ltx_font_bold">66.4%</span></td>
<td id="S5.T4.4.1.28.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.5.1" class="ltx_text ltx_font_bold">65.5%</span></td>
<td id="S5.T4.4.1.28.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.28.6.1" class="ltx_text ltx_font_bold">65.6%</span></td>
<td id="S5.T4.4.1.28.7" class="ltx_td ltx_align_left">66.8%</td>
<td id="S5.T4.4.1.28.8" class="ltx_td ltx_align_left">66.3%</td>
<td id="S5.T4.4.1.28.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.9.1" class="ltx_text ltx_font_bold">67.0%</span></td>
<td id="S5.T4.4.1.28.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.10.1" class="ltx_text ltx_font_bold">67.0%</span></td>
<td id="S5.T4.4.1.28.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.28.11.1" class="ltx_text ltx_font_bold">67.6%</span></td>
<td id="S5.T4.4.1.28.12" class="ltx_td ltx_align_left">66.2%</td>
<td id="S5.T4.4.1.28.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.13.1" class="ltx_text ltx_font_bold">67.8%</span></td>
<td id="S5.T4.4.1.28.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.14.1" class="ltx_text ltx_font_bold">68.4%</span></td>
<td id="S5.T4.4.1.28.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.15.1" class="ltx_text ltx_font_bold">66.3%</span></td>
<td id="S5.T4.4.1.28.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.28.16.1" class="ltx_text ltx_font_bold">67.1%</span></td>
</tr>
<tr id="S5.T4.4.1.29" class="ltx_tr">
<td id="S5.T4.4.1.29.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.29.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.29.2" class="ltx_td ltx_align_left">2.0%</td>
<td id="S5.T4.4.1.29.3" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.29.4" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.29.5" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.29.6" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.29.7" class="ltx_td ltx_align_left">3.5%</td>
<td id="S5.T4.4.1.29.8" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.29.9" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.29.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.29.11" class="ltx_td ltx_align_left ltx_border_r">2.1%</td>
<td id="S5.T4.4.1.29.12" class="ltx_td ltx_align_left">70.5%</td>
<td id="S5.T4.4.1.29.13" class="ltx_td ltx_align_left">60.0%</td>
<td id="S5.T4.4.1.29.14" class="ltx_td ltx_align_left">34.6%</td>
<td id="S5.T4.4.1.29.15" class="ltx_td ltx_align_left">16.7%</td>
<td id="S5.T4.4.1.29.16" class="ltx_td ltx_align_left">2.2%</td>
</tr>
<tr id="S5.T4.4.1.30" class="ltx_tr">
<td id="S5.T4.4.1.30.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.30.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.30.2" class="ltx_td ltx_align_left">63.7%</td>
<td id="S5.T4.4.1.30.3" class="ltx_td ltx_align_left">65.3%</td>
<td id="S5.T4.4.1.30.4" class="ltx_td ltx_align_left">65.8%</td>
<td id="S5.T4.4.1.30.5" class="ltx_td ltx_align_left">63.8%</td>
<td id="S5.T4.4.1.30.6" class="ltx_td ltx_align_left ltx_border_r">64.6%</td>
<td id="S5.T4.4.1.30.7" class="ltx_td ltx_align_left">65.6%</td>
<td id="S5.T4.4.1.30.8" class="ltx_td ltx_align_left">64.2%</td>
<td id="S5.T4.4.1.30.9" class="ltx_td ltx_align_left">64.9%</td>
<td id="S5.T4.4.1.30.10" class="ltx_td ltx_align_left">64.3%</td>
<td id="S5.T4.4.1.30.11" class="ltx_td ltx_align_left ltx_border_r">65.1%</td>
<td id="S5.T4.4.1.30.12" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T4.4.1.30.13" class="ltx_td ltx_align_left">64.6%</td>
<td id="S5.T4.4.1.30.14" class="ltx_td ltx_align_left">64.9%</td>
<td id="S5.T4.4.1.30.15" class="ltx_td ltx_align_left">63.7%</td>
<td id="S5.T4.4.1.30.16" class="ltx_td ltx_align_left">64.0%</td>
</tr>
<tr id="S5.T4.4.1.31" class="ltx_tr">
<td id="S5.T4.4.1.31.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="28"><span id="S5.T4.4.1.31.1.1" class="ltx_text ltx_font_bold">FASHIONMNIST</span></td>
<td id="S5.T4.4.1.31.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.31.2.1" class="ltx_text ltx_font_bold">CFL</span></td>
<td id="S5.T4.4.1.31.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.31.3.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.31.4" class="ltx_td ltx_align_left ltx_border_t">80.5%</td>
<td id="S5.T4.4.1.31.5" class="ltx_td ltx_align_left ltx_border_t">75.0%</td>
<td id="S5.T4.4.1.31.6" class="ltx_td ltx_align_left ltx_border_t">48.5%</td>
<td id="S5.T4.4.1.31.7" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.31.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.5%</td>
<td id="S5.T4.4.1.31.9" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.31.10" class="ltx_td ltx_align_left ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.31.11" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.31.12" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.31.13" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.31.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.31.14.1" class="ltx_text ltx_font_bold">82.1%</span></td>
<td id="S5.T4.4.1.31.15" class="ltx_td ltx_align_left ltx_border_t">71.4%</td>
<td id="S5.T4.4.1.31.16" class="ltx_td ltx_align_left ltx_border_t">70.4%</td>
<td id="S5.T4.4.1.31.17" class="ltx_td ltx_align_left ltx_border_t">64.5%</td>
<td id="S5.T4.4.1.31.18" class="ltx_td ltx_align_left ltx_border_t">55.2%</td>
</tr>
<tr id="S5.T4.4.1.32" class="ltx_tr">
<td id="S5.T4.4.1.32.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.32.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.32.2" class="ltx_td ltx_align_left">71.6%</td>
<td id="S5.T4.4.1.32.3" class="ltx_td ltx_align_left">69.0%</td>
<td id="S5.T4.4.1.32.4" class="ltx_td ltx_align_left">77.3%</td>
<td id="S5.T4.4.1.32.5" class="ltx_td ltx_align_left">59.5%</td>
<td id="S5.T4.4.1.32.6" class="ltx_td ltx_align_left ltx_border_r">40.8%</td>
<td id="S5.T4.4.1.32.7" class="ltx_td ltx_align_left">76.6%</td>
<td id="S5.T4.4.1.32.8" class="ltx_td ltx_align_left">76.0%</td>
<td id="S5.T4.4.1.32.9" class="ltx_td ltx_align_left">72.5%</td>
<td id="S5.T4.4.1.32.10" class="ltx_td ltx_align_left">46.0%</td>
<td id="S5.T4.4.1.32.11" class="ltx_td ltx_align_left ltx_border_r">28.6%</td>
<td id="S5.T4.4.1.32.12" class="ltx_td ltx_align_left">70.3%</td>
<td id="S5.T4.4.1.32.13" class="ltx_td ltx_align_left">68.8%</td>
<td id="S5.T4.4.1.32.14" class="ltx_td ltx_align_left">67.7%</td>
<td id="S5.T4.4.1.32.15" class="ltx_td ltx_align_left">61.9%</td>
<td id="S5.T4.4.1.32.16" class="ltx_td ltx_align_left">46.0%</td>
</tr>
<tr id="S5.T4.4.1.33" class="ltx_tr">
<td id="S5.T4.4.1.33.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.33.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.33.2" class="ltx_td ltx_align_left">72.4%</td>
<td id="S5.T4.4.1.33.3" class="ltx_td ltx_align_left">68.9%</td>
<td id="S5.T4.4.1.33.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.33.4.1" class="ltx_text ltx_font_bold">80.9%</span></td>
<td id="S5.T4.4.1.33.5" class="ltx_td ltx_align_left">60.8%</td>
<td id="S5.T4.4.1.33.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.33.6.1" class="ltx_text ltx_font_bold">42.0%</span></td>
<td id="S5.T4.4.1.33.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.33.7.1" class="ltx_text ltx_font_bold">81.0%</span></td>
<td id="S5.T4.4.1.33.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.33.8.1" class="ltx_text ltx_font_bold">81.8%</span></td>
<td id="S5.T4.4.1.33.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.33.9.1" class="ltx_text ltx_font_bold">80.8%</span></td>
<td id="S5.T4.4.1.33.10" class="ltx_td ltx_align_left">44.4%</td>
<td id="S5.T4.4.1.33.11" class="ltx_td ltx_align_left ltx_border_r">26.1%</td>
<td id="S5.T4.4.1.33.12" class="ltx_td ltx_align_left">72.6%</td>
<td id="S5.T4.4.1.33.13" class="ltx_td ltx_align_left">69.9%</td>
<td id="S5.T4.4.1.33.14" class="ltx_td ltx_align_left">67.9%</td>
<td id="S5.T4.4.1.33.15" class="ltx_td ltx_align_left">62.7%</td>
<td id="S5.T4.4.1.33.16" class="ltx_td ltx_align_left">42.4%</td>
</tr>
<tr id="S5.T4.4.1.34" class="ltx_tr">
<td id="S5.T4.4.1.34.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.34.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.34.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.34.2.1" class="ltx_text ltx_font_bold">81.4%</span></td>
<td id="S5.T4.4.1.34.3" class="ltx_td ltx_align_left">77.9%</td>
<td id="S5.T4.4.1.34.4" class="ltx_td ltx_align_left">80.0%</td>
<td id="S5.T4.4.1.34.5" class="ltx_td ltx_align_left">62.0%</td>
<td id="S5.T4.4.1.34.6" class="ltx_td ltx_align_left ltx_border_r">0.3%</td>
<td id="S5.T4.4.1.34.7" class="ltx_td ltx_align_left">80.2%</td>
<td id="S5.T4.4.1.34.8" class="ltx_td ltx_align_left">70.7%</td>
<td id="S5.T4.4.1.34.9" class="ltx_td ltx_align_left">67.7%</td>
<td id="S5.T4.4.1.34.10" class="ltx_td ltx_align_left">23.0%</td>
<td id="S5.T4.4.1.34.11" class="ltx_td ltx_align_left ltx_border_r">39.2%</td>
<td id="S5.T4.4.1.34.12" class="ltx_td ltx_align_left">80.9%</td>
<td id="S5.T4.4.1.34.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.34.13.1" class="ltx_text ltx_font_bold">81.2%</span></td>
<td id="S5.T4.4.1.34.14" class="ltx_td ltx_align_left">78.8%</td>
<td id="S5.T4.4.1.34.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.34.15.1" class="ltx_text ltx_font_bold">68.9%</span></td>
<td id="S5.T4.4.1.34.16" class="ltx_td ltx_align_left">40.5%</td>
</tr>
<tr id="S5.T4.4.1.35" class="ltx_tr">
<td id="S5.T4.4.1.35.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.35.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.35.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.35.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.35.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.35.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.36" class="ltx_tr">
<td id="S5.T4.4.1.36.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.36.2" class="ltx_td ltx_align_left">81.3%</td>
<td id="S5.T4.4.1.36.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.3.1" class="ltx_text ltx_font_bold">80.8%</span></td>
<td id="S5.T4.4.1.36.4" class="ltx_td ltx_align_left">80.0%</td>
<td id="S5.T4.4.1.36.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.5.1" class="ltx_text ltx_font_bold">65.7%</span></td>
<td id="S5.T4.4.1.36.6" class="ltx_td ltx_align_left ltx_border_r">41.2%</td>
<td id="S5.T4.4.1.36.7" class="ltx_td ltx_align_left">72.6%</td>
<td id="S5.T4.4.1.36.8" class="ltx_td ltx_align_left">65.8%</td>
<td id="S5.T4.4.1.36.9" class="ltx_td ltx_align_left">63.5%</td>
<td id="S5.T4.4.1.36.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.10.1" class="ltx_text ltx_font_bold">59.1%</span></td>
<td id="S5.T4.4.1.36.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.36.11.1" class="ltx_text ltx_font_bold">40.7%</span></td>
<td id="S5.T4.4.1.36.12" class="ltx_td ltx_align_left">80.3%</td>
<td id="S5.T4.4.1.36.13" class="ltx_td ltx_align_left">78.8%</td>
<td id="S5.T4.4.1.36.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.14.1" class="ltx_text ltx_font_bold">80.2%</span></td>
<td id="S5.T4.4.1.36.15" class="ltx_td ltx_align_left">65.7%</td>
<td id="S5.T4.4.1.36.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.36.16.1" class="ltx_text ltx_font_bold">66.6%</span></td>
</tr>
<tr id="S5.T4.4.1.37" class="ltx_tr">
<td id="S5.T4.4.1.37.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.37.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.37.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.37.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.37.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.37.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.38" class="ltx_tr">
<td id="S5.T4.4.1.38.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S5.T4.4.1.38.1.1" class="ltx_text ltx_font_bold">DFL-Fully</span></td>
<td id="S5.T4.4.1.38.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.38.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.38.3" class="ltx_td ltx_align_left ltx_border_t">84.5%</td>
<td id="S5.T4.4.1.38.4" class="ltx_td ltx_align_left ltx_border_t">79.4%</td>
<td id="S5.T4.4.1.38.5" class="ltx_td ltx_align_left ltx_border_t">47.9%</td>
<td id="S5.T4.4.1.38.6" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.38.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.5%</td>
<td id="S5.T4.4.1.38.8" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.38.9" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.38.10" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.38.11" class="ltx_td ltx_align_left ltx_border_t">1.9%</td>
<td id="S5.T4.4.1.38.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.38.13" class="ltx_td ltx_align_left ltx_border_t">83.8%</td>
<td id="S5.T4.4.1.38.14" class="ltx_td ltx_align_left ltx_border_t">71.2%</td>
<td id="S5.T4.4.1.38.15" class="ltx_td ltx_align_left ltx_border_t">69.2%</td>
<td id="S5.T4.4.1.38.16" class="ltx_td ltx_align_left ltx_border_t">64.1%</td>
<td id="S5.T4.4.1.38.17" class="ltx_td ltx_align_left ltx_border_t">57.0%</td>
</tr>
<tr id="S5.T4.4.1.39" class="ltx_tr">
<td id="S5.T4.4.1.39.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.39.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.39.2" class="ltx_td ltx_align_left">80.8%</td>
<td id="S5.T4.4.1.39.3" class="ltx_td ltx_align_left">67.0%</td>
<td id="S5.T4.4.1.39.4" class="ltx_td ltx_align_left">2.0%</td>
<td id="S5.T4.4.1.39.5" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T4.4.1.39.6" class="ltx_td ltx_align_left ltx_border_r">1.6%</td>
<td id="S5.T4.4.1.39.7" class="ltx_td ltx_align_left">67.8%</td>
<td id="S5.T4.4.1.39.8" class="ltx_td ltx_align_left">64.1%</td>
<td id="S5.T4.4.1.39.9" class="ltx_td ltx_align_left">63.9%</td>
<td id="S5.T4.4.1.39.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.39.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.39.12" class="ltx_td ltx_align_left">80.3%</td>
<td id="S5.T4.4.1.39.13" class="ltx_td ltx_align_left">78.6%</td>
<td id="S5.T4.4.1.39.14" class="ltx_td ltx_align_left">14.7%</td>
<td id="S5.T4.4.1.39.15" class="ltx_td ltx_align_left">10.6%</td>
<td id="S5.T4.4.1.39.16" class="ltx_td ltx_align_left">11.4%</td>
</tr>
<tr id="S5.T4.4.1.40" class="ltx_tr">
<td id="S5.T4.4.1.40.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.40.2" class="ltx_td ltx_align_left">83.7%</td>
<td id="S5.T4.4.1.40.3" class="ltx_td ltx_align_left">69.4%</td>
<td id="S5.T4.4.1.40.4" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T4.4.1.40.5" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T4.4.1.40.6" class="ltx_td ltx_align_left ltx_border_r">0.5%</td>
<td id="S5.T4.4.1.40.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.7.1" class="ltx_text ltx_font_bold">83.2%</span></td>
<td id="S5.T4.4.1.40.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.8.1" class="ltx_text ltx_font_bold">83.0%</span></td>
<td id="S5.T4.4.1.40.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.9.1" class="ltx_text ltx_font_bold">82.5%</span></td>
<td id="S5.T4.4.1.40.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.40.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.40.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.12.1" class="ltx_text ltx_font_bold">83.7%</span></td>
<td id="S5.T4.4.1.40.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.40.13.1" class="ltx_text ltx_font_bold">81.6%</span></td>
<td id="S5.T4.4.1.40.14" class="ltx_td ltx_align_left">2.9%</td>
<td id="S5.T4.4.1.40.15" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.40.16" class="ltx_td ltx_align_left">1.3%</td>
</tr>
<tr id="S5.T4.4.1.41" class="ltx_tr">
<td id="S5.T4.4.1.41.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.41.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.41.2" class="ltx_td ltx_align_left">84.1%</td>
<td id="S5.T4.4.1.41.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.41.3.1" class="ltx_text ltx_font_bold">79.6%</span></td>
<td id="S5.T4.4.1.41.4" class="ltx_td ltx_align_left">55.9%</td>
<td id="S5.T4.4.1.41.5" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T4.4.1.41.6" class="ltx_td ltx_align_left ltx_border_r">0.7%</td>
<td id="S5.T4.4.1.41.7" class="ltx_td ltx_align_left">75.8%</td>
<td id="S5.T4.4.1.41.8" class="ltx_td ltx_align_left">20.6%</td>
<td id="S5.T4.4.1.41.9" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.41.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.41.11" class="ltx_td ltx_align_left ltx_border_r">2.0%</td>
<td id="S5.T4.4.1.41.12" class="ltx_td ltx_align_left">83.4%</td>
<td id="S5.T4.4.1.41.13" class="ltx_td ltx_align_left">76.5%</td>
<td id="S5.T4.4.1.41.14" class="ltx_td ltx_align_left">64.1%</td>
<td id="S5.T4.4.1.41.15" class="ltx_td ltx_align_left">47.0%</td>
<td id="S5.T4.4.1.41.16" class="ltx_td ltx_align_left">9.4%</td>
</tr>
<tr id="S5.T4.4.1.42" class="ltx_tr">
<td id="S5.T4.4.1.42.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.1.1" class="ltx_text ltx_font_bold">Connected</span></td>
<td id="S5.T4.4.1.42.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.2.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.42.3" class="ltx_td ltx_align_left">77.9%</td>
<td id="S5.T4.4.1.42.4" class="ltx_td ltx_align_left">75.6%</td>
<td id="S5.T4.4.1.42.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.5.1" class="ltx_text ltx_font_bold">79.3%</span></td>
<td id="S5.T4.4.1.42.6" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.6.1" class="ltx_text ltx_font_bold">74.3%</span></td>
<td id="S5.T4.4.1.42.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.42.7.1" class="ltx_text ltx_font_bold">75.2%</span></td>
<td id="S5.T4.4.1.42.8" class="ltx_td ltx_align_left">77.2%</td>
<td id="S5.T4.4.1.42.9" class="ltx_td ltx_align_left">75.5%</td>
<td id="S5.T4.4.1.42.10" class="ltx_td ltx_align_left">76.0%</td>
<td id="S5.T4.4.1.42.11" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.11.1" class="ltx_text ltx_font_bold">75.6%</span></td>
<td id="S5.T4.4.1.42.12" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.42.12.1" class="ltx_text ltx_font_bold">76.6%</span></td>
<td id="S5.T4.4.1.42.13" class="ltx_td ltx_align_left">76.7%</td>
<td id="S5.T4.4.1.42.14" class="ltx_td ltx_align_left">76.3%</td>
<td id="S5.T4.4.1.42.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.15.1" class="ltx_text ltx_font_bold">77.8%</span></td>
<td id="S5.T4.4.1.42.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.16.1" class="ltx_text ltx_font_bold">74.7%</span></td>
<td id="S5.T4.4.1.42.17" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.42.17.1" class="ltx_text ltx_font_bold">75.4%</span></td>
</tr>
<tr id="S5.T4.4.1.43" class="ltx_tr">
<td id="S5.T4.4.1.43.1" class="ltx_td"></td>
<td id="S5.T4.4.1.43.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.43.2.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.43.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.43.3.1" class="ltx_text ltx_font_bold">84.7%</span></td>
<td id="S5.T4.4.1.43.4" class="ltx_td ltx_align_left">78.5%</td>
<td id="S5.T4.4.1.43.5" class="ltx_td ltx_align_left">9.2%</td>
<td id="S5.T4.4.1.43.6" class="ltx_td ltx_align_left">2.3%</td>
<td id="S5.T4.4.1.43.7" class="ltx_td ltx_align_left ltx_border_r">6.1%</td>
<td id="S5.T4.4.1.43.8" class="ltx_td ltx_align_left">13.9%</td>
<td id="S5.T4.4.1.43.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.43.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.43.11" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.43.12" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.43.13" class="ltx_td ltx_align_left">82.4%</td>
<td id="S5.T4.4.1.43.14" class="ltx_td ltx_align_left">76.3%</td>
<td id="S5.T4.4.1.43.15" class="ltx_td ltx_align_left">69.5%</td>
<td id="S5.T4.4.1.43.16" class="ltx_td ltx_align_left">48.1%</td>
<td id="S5.T4.4.1.43.17" class="ltx_td ltx_align_left">55.7%</td>
</tr>
<tr id="S5.T4.4.1.44" class="ltx_tr">
<td id="S5.T4.4.1.44.1" class="ltx_td"></td>
<td id="S5.T4.4.1.44.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.44.2.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.44.3" class="ltx_td ltx_align_left">75.2%</td>
<td id="S5.T4.4.1.44.4" class="ltx_td ltx_align_left">73.7%</td>
<td id="S5.T4.4.1.44.5" class="ltx_td ltx_align_left">75.7%</td>
<td id="S5.T4.4.1.44.6" class="ltx_td ltx_align_left">73.3%</td>
<td id="S5.T4.4.1.44.7" class="ltx_td ltx_align_left ltx_border_r">74.9%</td>
<td id="S5.T4.4.1.44.8" class="ltx_td ltx_align_left">75.3%</td>
<td id="S5.T4.4.1.44.9" class="ltx_td ltx_align_left">73.8%</td>
<td id="S5.T4.4.1.44.10" class="ltx_td ltx_align_left">73.3%</td>
<td id="S5.T4.4.1.44.11" class="ltx_td ltx_align_left">74.2%</td>
<td id="S5.T4.4.1.44.12" class="ltx_td ltx_align_left ltx_border_r">73.7%</td>
<td id="S5.T4.4.1.44.13" class="ltx_td ltx_align_left">74.2%</td>
<td id="S5.T4.4.1.44.14" class="ltx_td ltx_align_left">72.6%</td>
<td id="S5.T4.4.1.44.15" class="ltx_td ltx_align_left">75.5%</td>
<td id="S5.T4.4.1.44.16" class="ltx_td ltx_align_left">72.9%</td>
<td id="S5.T4.4.1.44.17" class="ltx_td ltx_align_left">72.7%</td>
</tr>
<tr id="S5.T4.4.1.45" class="ltx_tr">
<td id="S5.T4.4.1.45.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.45.1.1" class="ltx_text ltx_font_bold">DFL-Ring</span></td>
<td id="S5.T4.4.1.45.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.45.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.45.3" class="ltx_td ltx_align_left ltx_border_t">74.4%</td>
<td id="S5.T4.4.1.45.4" class="ltx_td ltx_align_left ltx_border_t">55.0%</td>
<td id="S5.T4.4.1.45.5" class="ltx_td ltx_align_left ltx_border_t">4.4%</td>
<td id="S5.T4.4.1.45.6" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.45.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.2%</td>
<td id="S5.T4.4.1.45.8" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.45.9" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.45.10" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.45.11" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.45.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.5%</td>
<td id="S5.T4.4.1.45.13" class="ltx_td ltx_align_left ltx_border_t">75.8%</td>
<td id="S5.T4.4.1.45.14" class="ltx_td ltx_align_left ltx_border_t">63.6%</td>
<td id="S5.T4.4.1.45.15" class="ltx_td ltx_align_left ltx_border_t">60.0%</td>
<td id="S5.T4.4.1.45.16" class="ltx_td ltx_align_left ltx_border_t">47.6%</td>
<td id="S5.T4.4.1.45.17" class="ltx_td ltx_align_left ltx_border_t">44.7%</td>
</tr>
<tr id="S5.T4.4.1.46" class="ltx_tr">
<td id="S5.T4.4.1.46.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.46.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.46.2" class="ltx_td ltx_align_left">81.3%</td>
<td id="S5.T4.4.1.46.3" class="ltx_td ltx_align_left">69.8%</td>
<td id="S5.T4.4.1.46.4" class="ltx_td ltx_align_left">12.1%</td>
<td id="S5.T4.4.1.46.5" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T4.4.1.46.6" class="ltx_td ltx_align_left ltx_border_r">61.0%</td>
<td id="S5.T4.4.1.46.7" class="ltx_td ltx_align_left">64.2%</td>
<td id="S5.T4.4.1.46.8" class="ltx_td ltx_align_left">36.2%</td>
<td id="S5.T4.4.1.46.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.46.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.46.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.46.12" class="ltx_td ltx_align_left">80.6%</td>
<td id="S5.T4.4.1.46.13" class="ltx_td ltx_align_left">45.4%</td>
<td id="S5.T4.4.1.46.14" class="ltx_td ltx_align_left">46.2%</td>
<td id="S5.T4.4.1.46.15" class="ltx_td ltx_align_left">27.1%</td>
<td id="S5.T4.4.1.46.16" class="ltx_td ltx_align_left">16.6%</td>
</tr>
<tr id="S5.T4.4.1.47" class="ltx_tr">
<td id="S5.T4.4.1.47.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.47.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.47.2" class="ltx_td ltx_align_left">83.9%</td>
<td id="S5.T4.4.1.47.3" class="ltx_td ltx_align_left">71.1%</td>
<td id="S5.T4.4.1.47.4" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T4.4.1.47.5" class="ltx_td ltx_align_left">0.5%</td>
<td id="S5.T4.4.1.47.6" class="ltx_td ltx_align_left ltx_border_r">77.3%</td>
<td id="S5.T4.4.1.47.7" class="ltx_td ltx_align_left">84.2%</td>
<td id="S5.T4.4.1.47.8" class="ltx_td ltx_align_left">45.9%</td>
<td id="S5.T4.4.1.47.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.47.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.47.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.47.12" class="ltx_td ltx_align_left">83.1%</td>
<td id="S5.T4.4.1.47.13" class="ltx_td ltx_align_left">40.3%</td>
<td id="S5.T4.4.1.47.14" class="ltx_td ltx_align_left">40.8%</td>
<td id="S5.T4.4.1.47.15" class="ltx_td ltx_align_left">21.4%</td>
<td id="S5.T4.4.1.47.16" class="ltx_td ltx_align_left">7.3%</td>
</tr>
<tr id="S5.T4.4.1.48" class="ltx_tr">
<td id="S5.T4.4.1.48.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.48.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.48.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.48.2.1" class="ltx_text ltx_font_bold">84.7%</span></td>
<td id="S5.T4.4.1.48.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.48.3.1" class="ltx_text ltx_font_bold">83.5%</span></td>
<td id="S5.T4.4.1.48.4" class="ltx_td ltx_align_left">55.0%</td>
<td id="S5.T4.4.1.48.5" class="ltx_td ltx_align_left">41.5%</td>
<td id="S5.T4.4.1.48.6" class="ltx_td ltx_align_left ltx_border_r">0.0%</td>
<td id="S5.T4.4.1.48.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.48.7.1" class="ltx_text ltx_font_bold">85.2%</span></td>
<td id="S5.T4.4.1.48.8" class="ltx_td ltx_align_left">50.7%</td>
<td id="S5.T4.4.1.48.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.48.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.48.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.48.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.48.12.1" class="ltx_text ltx_font_bold">84.9%</span></td>
<td id="S5.T4.4.1.48.13" class="ltx_td ltx_align_left">73.2%</td>
<td id="S5.T4.4.1.48.14" class="ltx_td ltx_align_left">69.6%</td>
<td id="S5.T4.4.1.48.15" class="ltx_td ltx_align_left">75.3%</td>
<td id="S5.T4.4.1.48.16" class="ltx_td ltx_align_left">34.9%</td>
</tr>
<tr id="S5.T4.4.1.49" class="ltx_tr">
<td id="S5.T4.4.1.49.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.49.2" class="ltx_td ltx_align_left">82.9%</td>
<td id="S5.T4.4.1.49.3" class="ltx_td ltx_align_left">76.7%</td>
<td id="S5.T4.4.1.49.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.4.1" class="ltx_text ltx_font_bold">75.8%</span></td>
<td id="S5.T4.4.1.49.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.5.1" class="ltx_text ltx_font_bold">78.3%</span></td>
<td id="S5.T4.4.1.49.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.49.6.1" class="ltx_text ltx_font_bold">77.2%</span></td>
<td id="S5.T4.4.1.49.7" class="ltx_td ltx_align_left">81.3%</td>
<td id="S5.T4.4.1.49.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.8.1" class="ltx_text ltx_font_bold">75.1%</span></td>
<td id="S5.T4.4.1.49.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.9.1" class="ltx_text ltx_font_bold">76.3%</span></td>
<td id="S5.T4.4.1.49.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.10.1" class="ltx_text ltx_font_bold">75.8%</span></td>
<td id="S5.T4.4.1.49.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.49.11.1" class="ltx_text ltx_font_bold">75.6%</span></td>
<td id="S5.T4.4.1.49.12" class="ltx_td ltx_align_left">76.2%</td>
<td id="S5.T4.4.1.49.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.13.1" class="ltx_text ltx_font_bold">77.6%</span></td>
<td id="S5.T4.4.1.49.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.14.1" class="ltx_text ltx_font_bold">77.3%</span></td>
<td id="S5.T4.4.1.49.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.15.1" class="ltx_text ltx_font_bold">76.2%</span></td>
<td id="S5.T4.4.1.49.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.49.16.1" class="ltx_text ltx_font_bold">77.2%</span></td>
</tr>
<tr id="S5.T4.4.1.50" class="ltx_tr">
<td id="S5.T4.4.1.50.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.50.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.50.2" class="ltx_td ltx_align_left">84.6%</td>
<td id="S5.T4.4.1.50.3" class="ltx_td ltx_align_left">79.8%</td>
<td id="S5.T4.4.1.50.4" class="ltx_td ltx_align_left">59.0%</td>
<td id="S5.T4.4.1.50.5" class="ltx_td ltx_align_left">1.5%</td>
<td id="S5.T4.4.1.50.6" class="ltx_td ltx_align_left ltx_border_r">0.8%</td>
<td id="S5.T4.4.1.50.7" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.50.8" class="ltx_td ltx_align_left">5.3%</td>
<td id="S5.T4.4.1.50.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.50.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.50.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.50.12" class="ltx_td ltx_align_left">84.3%</td>
<td id="S5.T4.4.1.50.13" class="ltx_td ltx_align_left">74.6%</td>
<td id="S5.T4.4.1.50.14" class="ltx_td ltx_align_left">72.1%</td>
<td id="S5.T4.4.1.50.15" class="ltx_td ltx_align_left">53.9%</td>
<td id="S5.T4.4.1.50.16" class="ltx_td ltx_align_left">56.4%</td>
</tr>
<tr id="S5.T4.4.1.51" class="ltx_tr">
<td id="S5.T4.4.1.51.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.51.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.51.2" class="ltx_td ltx_align_left">74.2%</td>
<td id="S5.T4.4.1.51.3" class="ltx_td ltx_align_left">75.0%</td>
<td id="S5.T4.4.1.51.4" class="ltx_td ltx_align_left">75.0%</td>
<td id="S5.T4.4.1.51.5" class="ltx_td ltx_align_left">75.4%</td>
<td id="S5.T4.4.1.51.6" class="ltx_td ltx_align_left ltx_border_r">74.7%</td>
<td id="S5.T4.4.1.51.7" class="ltx_td ltx_align_left">72.7%</td>
<td id="S5.T4.4.1.51.8" class="ltx_td ltx_align_left">73.4%</td>
<td id="S5.T4.4.1.51.9" class="ltx_td ltx_align_left">74.7%</td>
<td id="S5.T4.4.1.51.10" class="ltx_td ltx_align_left">75.6%</td>
<td id="S5.T4.4.1.51.11" class="ltx_td ltx_align_left ltx_border_r">72.8%</td>
<td id="S5.T4.4.1.51.12" class="ltx_td ltx_align_left">73.0%</td>
<td id="S5.T4.4.1.51.13" class="ltx_td ltx_align_left">74.3%</td>
<td id="S5.T4.4.1.51.14" class="ltx_td ltx_align_left">74.8%</td>
<td id="S5.T4.4.1.51.15" class="ltx_td ltx_align_left">73.3%</td>
<td id="S5.T4.4.1.51.16" class="ltx_td ltx_align_left">75.5%</td>
</tr>
<tr id="S5.T4.4.1.52" class="ltx_tr">
<td id="S5.T4.4.1.52.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.52.1.1" class="ltx_text ltx_font_bold">DFL-Star</span></td>
<td id="S5.T4.4.1.52.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.52.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.52.3" class="ltx_td ltx_align_left ltx_border_t">73.1%</td>
<td id="S5.T4.4.1.52.4" class="ltx_td ltx_align_left ltx_border_t">47.6%</td>
<td id="S5.T4.4.1.52.5" class="ltx_td ltx_align_left ltx_border_t">44.1%</td>
<td id="S5.T4.4.1.52.6" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.52.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.5%</td>
<td id="S5.T4.4.1.52.8" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.52.9" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.52.10" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.52.11" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.52.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.5%</td>
<td id="S5.T4.4.1.52.13" class="ltx_td ltx_align_left ltx_border_t">74.6%</td>
<td id="S5.T4.4.1.52.14" class="ltx_td ltx_align_left ltx_border_t">64.9%</td>
<td id="S5.T4.4.1.52.15" class="ltx_td ltx_align_left ltx_border_t">53.1%</td>
<td id="S5.T4.4.1.52.16" class="ltx_td ltx_align_left ltx_border_t">22.8%</td>
<td id="S5.T4.4.1.52.17" class="ltx_td ltx_align_left ltx_border_t">45.3%</td>
</tr>
<tr id="S5.T4.4.1.53" class="ltx_tr">
<td id="S5.T4.4.1.53.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.53.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.53.2" class="ltx_td ltx_align_left">81.8%</td>
<td id="S5.T4.4.1.53.3" class="ltx_td ltx_align_left">14.8%</td>
<td id="S5.T4.4.1.53.4" class="ltx_td ltx_align_left">68.0%</td>
<td id="S5.T4.4.1.53.5" class="ltx_td ltx_align_left">26.5%</td>
<td id="S5.T4.4.1.53.6" class="ltx_td ltx_align_left ltx_border_r">0.4%</td>
<td id="S5.T4.4.1.53.7" class="ltx_td ltx_align_left">65.3%</td>
<td id="S5.T4.4.1.53.8" class="ltx_td ltx_align_left">66.0%</td>
<td id="S5.T4.4.1.53.9" class="ltx_td ltx_align_left">23.4%</td>
<td id="S5.T4.4.1.53.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.53.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.53.12" class="ltx_td ltx_align_left">81.8%</td>
<td id="S5.T4.4.1.53.13" class="ltx_td ltx_align_left">76.7%</td>
<td id="S5.T4.4.1.53.14" class="ltx_td ltx_align_left">77.6%</td>
<td id="S5.T4.4.1.53.15" class="ltx_td ltx_align_left">11.6%</td>
<td id="S5.T4.4.1.53.16" class="ltx_td ltx_align_left">12.1%</td>
</tr>
<tr id="S5.T4.4.1.54" class="ltx_tr">
<td id="S5.T4.4.1.54.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.54.2" class="ltx_td ltx_align_left">80.7%</td>
<td id="S5.T4.4.1.54.3" class="ltx_td ltx_align_left">0.6%</td>
<td id="S5.T4.4.1.54.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.4.1" class="ltx_text ltx_font_bold">80.2%</span></td>
<td id="S5.T4.4.1.54.5" class="ltx_td ltx_align_left">27.6%</td>
<td id="S5.T4.4.1.54.6" class="ltx_td ltx_align_left ltx_border_r">0.4%</td>
<td id="S5.T4.4.1.54.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.7.1" class="ltx_text ltx_font_bold">83.5%</span></td>
<td id="S5.T4.4.1.54.8" class="ltx_td ltx_align_left">83.3%</td>
<td id="S5.T4.4.1.54.9" class="ltx_td ltx_align_left">30.0%</td>
<td id="S5.T4.4.1.54.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.54.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.54.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.12.1" class="ltx_text ltx_font_bold">84.4%</span></td>
<td id="S5.T4.4.1.54.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.13.1" class="ltx_text ltx_font_bold">80.9%</span></td>
<td id="S5.T4.4.1.54.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.54.14.1" class="ltx_text ltx_font_bold">81.6%</span></td>
<td id="S5.T4.4.1.54.15" class="ltx_td ltx_align_left">2.2%</td>
<td id="S5.T4.4.1.54.16" class="ltx_td ltx_align_left">3.3%</td>
</tr>
<tr id="S5.T4.4.1.55" class="ltx_tr">
<td id="S5.T4.4.1.55.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.55.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.55.2" class="ltx_td ltx_align_left">84.2%</td>
<td id="S5.T4.4.1.55.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.55.3.1" class="ltx_text ltx_font_bold">84.4%</span></td>
<td id="S5.T4.4.1.55.4" class="ltx_td ltx_align_left">77.6%</td>
<td id="S5.T4.4.1.55.5" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T4.4.1.55.6" class="ltx_td ltx_align_left ltx_border_r">0.3%</td>
<td id="S5.T4.4.1.55.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.55.7.1" class="ltx_text ltx_font_bold">85.0%</span></td>
<td id="S5.T4.4.1.55.8" class="ltx_td ltx_align_left">31.5%</td>
<td id="S5.T4.4.1.55.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.55.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.55.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.55.12" class="ltx_td ltx_align_left">72.8%</td>
<td id="S5.T4.4.1.55.13" class="ltx_td ltx_align_left">72.1%</td>
<td id="S5.T4.4.1.55.14" class="ltx_td ltx_align_left">62.9%</td>
<td id="S5.T4.4.1.55.15" class="ltx_td ltx_align_left">27.3%</td>
<td id="S5.T4.4.1.55.16" class="ltx_td ltx_align_left">73.4%</td>
</tr>
<tr id="S5.T4.4.1.56" class="ltx_tr">
<td id="S5.T4.4.1.56.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.56.2" class="ltx_td ltx_align_left">78.1%</td>
<td id="S5.T4.4.1.56.3" class="ltx_td ltx_align_left">75.0%</td>
<td id="S5.T4.4.1.56.4" class="ltx_td ltx_align_left">76.9%</td>
<td id="S5.T4.4.1.56.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.5.1" class="ltx_text ltx_font_bold">76.0%</span></td>
<td id="S5.T4.4.1.56.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.56.6.1" class="ltx_text ltx_font_bold">76.7%</span></td>
<td id="S5.T4.4.1.56.7" class="ltx_td ltx_align_left">76.8%</td>
<td id="S5.T4.4.1.56.8" class="ltx_td ltx_align_left">76.9%</td>
<td id="S5.T4.4.1.56.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.9.1" class="ltx_text ltx_font_bold">76.6%</span></td>
<td id="S5.T4.4.1.56.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.10.1" class="ltx_text ltx_font_bold">76.7%</span></td>
<td id="S5.T4.4.1.56.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.56.11.1" class="ltx_text ltx_font_bold">76.9%</span></td>
<td id="S5.T4.4.1.56.12" class="ltx_td ltx_align_left">77.3%</td>
<td id="S5.T4.4.1.56.13" class="ltx_td ltx_align_left">75.8%</td>
<td id="S5.T4.4.1.56.14" class="ltx_td ltx_align_left">77.9%</td>
<td id="S5.T4.4.1.56.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.15.1" class="ltx_text ltx_font_bold">76.4%</span></td>
<td id="S5.T4.4.1.56.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.56.16.1" class="ltx_text ltx_font_bold">75.7%</span></td>
</tr>
<tr id="S5.T4.4.1.57" class="ltx_tr">
<td id="S5.T4.4.1.57.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.57.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.57.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.57.2.1" class="ltx_text ltx_font_bold">84.6%</span></td>
<td id="S5.T4.4.1.57.3" class="ltx_td ltx_align_left">73.0%</td>
<td id="S5.T4.4.1.57.4" class="ltx_td ltx_align_left">40.5%</td>
<td id="S5.T4.4.1.57.5" class="ltx_td ltx_align_left">29.7%</td>
<td id="S5.T4.4.1.57.6" class="ltx_td ltx_align_left ltx_border_r">0.2%</td>
<td id="S5.T4.4.1.57.7" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.57.8" class="ltx_td ltx_align_left">3.8%</td>
<td id="S5.T4.4.1.57.9" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.57.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.57.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.57.12" class="ltx_td ltx_align_left">83.4%</td>
<td id="S5.T4.4.1.57.13" class="ltx_td ltx_align_left">79.2%</td>
<td id="S5.T4.4.1.57.14" class="ltx_td ltx_align_left">61.6%</td>
<td id="S5.T4.4.1.57.15" class="ltx_td ltx_align_left">49.9%</td>
<td id="S5.T4.4.1.57.16" class="ltx_td ltx_align_left">52.8%</td>
</tr>
<tr id="S5.T4.4.1.58" class="ltx_tr">
<td id="S5.T4.4.1.58.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.58.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.58.2" class="ltx_td ltx_align_left">74.5%</td>
<td id="S5.T4.4.1.58.3" class="ltx_td ltx_align_left">73.6%</td>
<td id="S5.T4.4.1.58.4" class="ltx_td ltx_align_left">74.1%</td>
<td id="S5.T4.4.1.58.5" class="ltx_td ltx_align_left">72.2%</td>
<td id="S5.T4.4.1.58.6" class="ltx_td ltx_align_left ltx_border_r">73.5%</td>
<td id="S5.T4.4.1.58.7" class="ltx_td ltx_align_left">73.6%</td>
<td id="S5.T4.4.1.58.8" class="ltx_td ltx_align_left">74.6%</td>
<td id="S5.T4.4.1.58.9" class="ltx_td ltx_align_left">73.9%</td>
<td id="S5.T4.4.1.58.10" class="ltx_td ltx_align_left">74.5%</td>
<td id="S5.T4.4.1.58.11" class="ltx_td ltx_align_left ltx_border_r">74.0%</td>
<td id="S5.T4.4.1.58.12" class="ltx_td ltx_align_left">74.4%</td>
<td id="S5.T4.4.1.58.13" class="ltx_td ltx_align_left">73.5%</td>
<td id="S5.T4.4.1.58.14" class="ltx_td ltx_align_left">76.6%</td>
<td id="S5.T4.4.1.58.15" class="ltx_td ltx_align_left">75.1%</td>
<td id="S5.T4.4.1.58.16" class="ltx_td ltx_align_left">73.7%</td>
</tr>
<tr id="S5.T4.4.1.59" class="ltx_tr">
<td id="S5.T4.4.1.59.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="28"><span id="S5.T4.4.1.59.1.1" class="ltx_text ltx_font_bold">MNIST</span></td>
<td id="S5.T4.4.1.59.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.59.2.1" class="ltx_text ltx_font_bold">CFL</span></td>
<td id="S5.T4.4.1.59.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.3.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.59.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.4.1" class="ltx_text ltx_font_bold">95.3%</span></td>
<td id="S5.T4.4.1.59.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.5.1" class="ltx_text ltx_font_bold">94.7%</span></td>
<td id="S5.T4.4.1.59.6" class="ltx_td ltx_align_left ltx_border_t">80.5%</td>
<td id="S5.T4.4.1.59.7" class="ltx_td ltx_align_left ltx_border_t">35.3%</td>
<td id="S5.T4.4.1.59.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.8%</td>
<td id="S5.T4.4.1.59.9" class="ltx_td ltx_align_left ltx_border_t">18.8%</td>
<td id="S5.T4.4.1.59.10" class="ltx_td ltx_align_left ltx_border_t">15.0%</td>
<td id="S5.T4.4.1.59.11" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.59.12" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.59.13" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.5%</td>
<td id="S5.T4.4.1.59.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.14.1" class="ltx_text ltx_font_bold">99.8%</span></td>
<td id="S5.T4.4.1.59.15" class="ltx_td ltx_align_left ltx_border_t">93.0%</td>
<td id="S5.T4.4.1.59.16" class="ltx_td ltx_align_left ltx_border_t">90.9%</td>
<td id="S5.T4.4.1.59.17" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.17.1" class="ltx_text ltx_font_bold">88.0%</span></td>
<td id="S5.T4.4.1.59.18" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.59.18.1" class="ltx_text ltx_font_bold">73.6%</span></td>
</tr>
<tr id="S5.T4.4.1.60" class="ltx_tr">
<td id="S5.T4.4.1.60.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.60.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.60.2" class="ltx_td ltx_align_left">88.6%</td>
<td id="S5.T4.4.1.60.3" class="ltx_td ltx_align_left">89.9%</td>
<td id="S5.T4.4.1.60.4" class="ltx_td ltx_align_left">87.2%</td>
<td id="S5.T4.4.1.60.5" class="ltx_td ltx_align_left">67.6%</td>
<td id="S5.T4.4.1.60.6" class="ltx_td ltx_align_left ltx_border_r">43.9%</td>
<td id="S5.T4.4.1.60.7" class="ltx_td ltx_align_left">88.3%</td>
<td id="S5.T4.4.1.60.8" class="ltx_td ltx_align_left">86.2%</td>
<td id="S5.T4.4.1.60.9" class="ltx_td ltx_align_left">88.8%</td>
<td id="S5.T4.4.1.60.10" class="ltx_td ltx_align_left">62.6%</td>
<td id="S5.T4.4.1.60.11" class="ltx_td ltx_align_left ltx_border_r">24.8%</td>
<td id="S5.T4.4.1.60.12" class="ltx_td ltx_align_left">92.0%</td>
<td id="S5.T4.4.1.60.13" class="ltx_td ltx_align_left">81.0%</td>
<td id="S5.T4.4.1.60.14" class="ltx_td ltx_align_left">77.2%</td>
<td id="S5.T4.4.1.60.15" class="ltx_td ltx_align_left">71.7%</td>
<td id="S5.T4.4.1.60.16" class="ltx_td ltx_align_left">46.8%</td>
</tr>
<tr id="S5.T4.4.1.61" class="ltx_tr">
<td id="S5.T4.4.1.61.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.61.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.61.2" class="ltx_td ltx_align_left">93.5%</td>
<td id="S5.T4.4.1.61.3" class="ltx_td ltx_align_left">92.8%</td>
<td id="S5.T4.4.1.61.4" class="ltx_td ltx_align_left">93.2%</td>
<td id="S5.T4.4.1.61.5" class="ltx_td ltx_align_left">69.5%</td>
<td id="S5.T4.4.1.61.6" class="ltx_td ltx_align_left ltx_border_r">44.7%</td>
<td id="S5.T4.4.1.61.7" class="ltx_td ltx_align_left">93.3%</td>
<td id="S5.T4.4.1.61.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.61.8.1" class="ltx_text ltx_font_bold">93.2%</span></td>
<td id="S5.T4.4.1.61.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.61.9.1" class="ltx_text ltx_font_bold">93.9%</span></td>
<td id="S5.T4.4.1.61.10" class="ltx_td ltx_align_left">64.6%</td>
<td id="S5.T4.4.1.61.11" class="ltx_td ltx_align_left ltx_border_r">21.8%</td>
<td id="S5.T4.4.1.61.12" class="ltx_td ltx_align_left">92.7%</td>
<td id="S5.T4.4.1.61.13" class="ltx_td ltx_align_left">79.5%</td>
<td id="S5.T4.4.1.61.14" class="ltx_td ltx_align_left">77.2%</td>
<td id="S5.T4.4.1.61.15" class="ltx_td ltx_align_left">70.2%</td>
<td id="S5.T4.4.1.61.16" class="ltx_td ltx_align_left">47.4%</td>
</tr>
<tr id="S5.T4.4.1.62" class="ltx_tr">
<td id="S5.T4.4.1.62.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.62.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.62.2" class="ltx_td ltx_align_left">94.1%</td>
<td id="S5.T4.4.1.62.3" class="ltx_td ltx_align_left">93.5%</td>
<td id="S5.T4.4.1.62.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.62.4.1" class="ltx_text ltx_font_bold">95.4%</span></td>
<td id="S5.T4.4.1.62.5" class="ltx_td ltx_align_left">70.0%</td>
<td id="S5.T4.4.1.62.6" class="ltx_td ltx_align_left ltx_border_r">44.4%</td>
<td id="S5.T4.4.1.62.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.62.7.1" class="ltx_text ltx_font_bold">93.9%</span></td>
<td id="S5.T4.4.1.62.8" class="ltx_td ltx_align_left">85.2%</td>
<td id="S5.T4.4.1.62.9" class="ltx_td ltx_align_left">83.7%</td>
<td id="S5.T4.4.1.62.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.62.10.1" class="ltx_text ltx_font_bold">68.4%</span></td>
<td id="S5.T4.4.1.62.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.62.11.1" class="ltx_text ltx_font_bold">48.3%</span></td>
<td id="S5.T4.4.1.62.12" class="ltx_td ltx_align_left">94.4%</td>
<td id="S5.T4.4.1.62.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.62.13.1" class="ltx_text ltx_font_bold">93.3%</span></td>
<td id="S5.T4.4.1.62.14" class="ltx_td ltx_align_left">92.9%</td>
<td id="S5.T4.4.1.62.15" class="ltx_td ltx_align_left">71.4%</td>
<td id="S5.T4.4.1.62.16" class="ltx_td ltx_align_left">48.0%</td>
</tr>
<tr id="S5.T4.4.1.63" class="ltx_tr">
<td id="S5.T4.4.1.63.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.63.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.63.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.63.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.63.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.63.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.64" class="ltx_tr">
<td id="S5.T4.4.1.64.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.64.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.64.2" class="ltx_td ltx_align_left">93.7%</td>
<td id="S5.T4.4.1.64.3" class="ltx_td ltx_align_left">80.7%</td>
<td id="S5.T4.4.1.64.4" class="ltx_td ltx_align_left">91.1%</td>
<td id="S5.T4.4.1.64.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.64.5.1" class="ltx_text ltx_font_bold">88.0%</span></td>
<td id="S5.T4.4.1.64.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.64.6.1" class="ltx_text ltx_font_bold">46.0%</span></td>
<td id="S5.T4.4.1.64.7" class="ltx_td ltx_align_left">90.6%</td>
<td id="S5.T4.4.1.64.8" class="ltx_td ltx_align_left">78.0%</td>
<td id="S5.T4.4.1.64.9" class="ltx_td ltx_align_left">77.1%</td>
<td id="S5.T4.4.1.64.10" class="ltx_td ltx_align_left">66.3%</td>
<td id="S5.T4.4.1.64.11" class="ltx_td ltx_align_left ltx_border_r">40.9%</td>
<td id="S5.T4.4.1.64.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.64.12.1" class="ltx_text ltx_font_bold">93.3%</span></td>
<td id="S5.T4.4.1.64.13" class="ltx_td ltx_align_left">92.7%</td>
<td id="S5.T4.4.1.64.14" class="ltx_td ltx_align_left">93.3%</td>
<td id="S5.T4.4.1.64.15" class="ltx_td ltx_align_left">83.1%</td>
<td id="S5.T4.4.1.64.16" class="ltx_td ltx_align_left">53.9%</td>
</tr>
<tr id="S5.T4.4.1.65" class="ltx_tr">
<td id="S5.T4.4.1.65.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.65.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.65.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.65.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T4.4.1.65.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T4.4.1.65.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T4.4.1.66" class="ltx_tr">
<td id="S5.T4.4.1.66.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S5.T4.4.1.66.1.1" class="ltx_text ltx_font_bold">DFL-Fully</span></td>
<td id="S5.T4.4.1.66.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.66.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.66.3" class="ltx_td ltx_align_left ltx_border_t">94.1%</td>
<td id="S5.T4.4.1.66.4" class="ltx_td ltx_align_left ltx_border_t">95.9%</td>
<td id="S5.T4.4.1.66.5" class="ltx_td ltx_align_left ltx_border_t">82.7%</td>
<td id="S5.T4.4.1.66.6" class="ltx_td ltx_align_left ltx_border_t">35.2%</td>
<td id="S5.T4.4.1.66.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.9%</td>
<td id="S5.T4.4.1.66.8" class="ltx_td ltx_align_left ltx_border_t">19.5%</td>
<td id="S5.T4.4.1.66.9" class="ltx_td ltx_align_left ltx_border_t">15.4%</td>
<td id="S5.T4.4.1.66.10" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.66.11" class="ltx_td ltx_align_left ltx_border_t">1.8%</td>
<td id="S5.T4.4.1.66.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.66.13" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.66.13.1" class="ltx_text ltx_font_bold">97.3%</span></td>
<td id="S5.T4.4.1.66.14" class="ltx_td ltx_align_left ltx_border_t">96.3%</td>
<td id="S5.T4.4.1.66.15" class="ltx_td ltx_align_left ltx_border_t">93.9%</td>
<td id="S5.T4.4.1.66.16" class="ltx_td ltx_align_left ltx_border_t">91.3%</td>
<td id="S5.T4.4.1.66.17" class="ltx_td ltx_align_left ltx_border_t">75.8%</td>
</tr>
<tr id="S5.T4.4.1.67" class="ltx_tr">
<td id="S5.T4.4.1.67.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.67.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.67.2" class="ltx_td ltx_align_left">93.0%</td>
<td id="S5.T4.4.1.67.3" class="ltx_td ltx_align_left">90.0%</td>
<td id="S5.T4.4.1.67.4" class="ltx_td ltx_align_left">48.7%</td>
<td id="S5.T4.4.1.67.5" class="ltx_td ltx_align_left">32.8%</td>
<td id="S5.T4.4.1.67.6" class="ltx_td ltx_align_left ltx_border_r">0.3%</td>
<td id="S5.T4.4.1.67.7" class="ltx_td ltx_align_left">78.6%</td>
<td id="S5.T4.4.1.67.8" class="ltx_td ltx_align_left">77.2%</td>
<td id="S5.T4.4.1.67.9" class="ltx_td ltx_align_left">57.2%</td>
<td id="S5.T4.4.1.67.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.67.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.67.12" class="ltx_td ltx_align_left">88.3%</td>
<td id="S5.T4.4.1.67.13" class="ltx_td ltx_align_left">90.0%</td>
<td id="S5.T4.4.1.67.14" class="ltx_td ltx_align_left">19.9%</td>
<td id="S5.T4.4.1.67.15" class="ltx_td ltx_align_left">21.9%</td>
<td id="S5.T4.4.1.67.16" class="ltx_td ltx_align_left">18.7%</td>
</tr>
<tr id="S5.T4.4.1.68" class="ltx_tr">
<td id="S5.T4.4.1.68.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.68.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.68.2" class="ltx_td ltx_align_left">95.8%</td>
<td id="S5.T4.4.1.68.3" class="ltx_td ltx_align_left">95.6%</td>
<td id="S5.T4.4.1.68.4" class="ltx_td ltx_align_left">47.4%</td>
<td id="S5.T4.4.1.68.5" class="ltx_td ltx_align_left">30.5%</td>
<td id="S5.T4.4.1.68.6" class="ltx_td ltx_align_left ltx_border_r">0.3%</td>
<td id="S5.T4.4.1.68.7" class="ltx_td ltx_align_left">95.6%</td>
<td id="S5.T4.4.1.68.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.68.8.1" class="ltx_text ltx_font_bold">95.8%</span></td>
<td id="S5.T4.4.1.68.9" class="ltx_td ltx_align_left">72.7%</td>
<td id="S5.T4.4.1.68.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.68.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.68.12" class="ltx_td ltx_align_left">95.6%</td>
<td id="S5.T4.4.1.68.13" class="ltx_td ltx_align_left">93.2%</td>
<td id="S5.T4.4.1.68.14" class="ltx_td ltx_align_left">2.1%</td>
<td id="S5.T4.4.1.68.15" class="ltx_td ltx_align_left">4.6%</td>
<td id="S5.T4.4.1.68.16" class="ltx_td ltx_align_left">2.2%</td>
</tr>
<tr id="S5.T4.4.1.69" class="ltx_tr">
<td id="S5.T4.4.1.69.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.69.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.69.2" class="ltx_td ltx_align_left">97.1%</td>
<td id="S5.T4.4.1.69.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.69.3.1" class="ltx_text ltx_font_bold">96.0%</span></td>
<td id="S5.T4.4.1.69.4" class="ltx_td ltx_align_left">75.3%</td>
<td id="S5.T4.4.1.69.5" class="ltx_td ltx_align_left">18.4%</td>
<td id="S5.T4.4.1.69.6" class="ltx_td ltx_align_left ltx_border_r">0.1%</td>
<td id="S5.T4.4.1.69.7" class="ltx_td ltx_align_left">96.7%</td>
<td id="S5.T4.4.1.69.8" class="ltx_td ltx_align_left">76.0%</td>
<td id="S5.T4.4.1.69.9" class="ltx_td ltx_align_left">1.6%</td>
<td id="S5.T4.4.1.69.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.69.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.69.12" class="ltx_td ltx_align_left">95.3%</td>
<td id="S5.T4.4.1.69.13" class="ltx_td ltx_align_left">94.6%</td>
<td id="S5.T4.4.1.69.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.69.14.1" class="ltx_text ltx_font_bold">93.2%</span></td>
<td id="S5.T4.4.1.69.15" class="ltx_td ltx_align_left">60.4%</td>
<td id="S5.T4.4.1.69.16" class="ltx_td ltx_align_left">2.2%</td>
</tr>
<tr id="S5.T4.4.1.70" class="ltx_tr">
<td id="S5.T4.4.1.70.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.1.1" class="ltx_text ltx_font_bold">Connected</span></td>
<td id="S5.T4.4.1.70.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.2.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.70.3" class="ltx_td ltx_align_left">95.1%</td>
<td id="S5.T4.4.1.70.4" class="ltx_td ltx_align_left">85.9%</td>
<td id="S5.T4.4.1.70.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.5.1" class="ltx_text ltx_font_bold">88.9%</span></td>
<td id="S5.T4.4.1.70.6" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.6.1" class="ltx_text ltx_font_bold">88.4%</span></td>
<td id="S5.T4.4.1.70.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.70.7.1" class="ltx_text ltx_font_bold">89.2%</span></td>
<td id="S5.T4.4.1.70.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.8.1" class="ltx_text ltx_font_bold">97.8%</span></td>
<td id="S5.T4.4.1.70.9" class="ltx_td ltx_align_left">89.2%</td>
<td id="S5.T4.4.1.70.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.10.1" class="ltx_text ltx_font_bold">88.3%</span></td>
<td id="S5.T4.4.1.70.11" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.11.1" class="ltx_text ltx_font_bold">87.7%</span></td>
<td id="S5.T4.4.1.70.12" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.70.12.1" class="ltx_text ltx_font_bold">87.6%</span></td>
<td id="S5.T4.4.1.70.13" class="ltx_td ltx_align_left">95.6%</td>
<td id="S5.T4.4.1.70.14" class="ltx_td ltx_align_left">87.4%</td>
<td id="S5.T4.4.1.70.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.15.1" class="ltx_text ltx_font_bold">86.0%</span></td>
<td id="S5.T4.4.1.70.16" class="ltx_td ltx_align_left">86.9%</td>
<td id="S5.T4.4.1.70.17" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.70.17.1" class="ltx_text ltx_font_bold">87.9%</span></td>
</tr>
<tr id="S5.T4.4.1.71" class="ltx_tr">
<td id="S5.T4.4.1.71.1" class="ltx_td"></td>
<td id="S5.T4.4.1.71.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.71.2.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.71.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.71.3.1" class="ltx_text ltx_font_bold">97.3%</span></td>
<td id="S5.T4.4.1.71.4" class="ltx_td ltx_align_left">88.1%</td>
<td id="S5.T4.4.1.71.5" class="ltx_td ltx_align_left">67.4%</td>
<td id="S5.T4.4.1.71.6" class="ltx_td ltx_align_left">45.2%</td>
<td id="S5.T4.4.1.71.7" class="ltx_td ltx_align_left ltx_border_r">0.4%</td>
<td id="S5.T4.4.1.71.8" class="ltx_td ltx_align_left">23.2%</td>
<td id="S5.T4.4.1.71.9" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.71.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.71.11" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.71.12" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.71.13" class="ltx_td ltx_align_left">96.0%</td>
<td id="S5.T4.4.1.71.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.71.14.1" class="ltx_text ltx_font_bold">96.8%</span></td>
<td id="S5.T4.4.1.71.15" class="ltx_td ltx_align_left">92.7%</td>
<td id="S5.T4.4.1.71.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.71.16.1" class="ltx_text ltx_font_bold">93.2%</span></td>
<td id="S5.T4.4.1.71.17" class="ltx_td ltx_align_left">80.3%</td>
</tr>
<tr id="S5.T4.4.1.72" class="ltx_tr">
<td id="S5.T4.4.1.72.1" class="ltx_td"></td>
<td id="S5.T4.4.1.72.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.72.2.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.72.3" class="ltx_td ltx_align_left">93.8%</td>
<td id="S5.T4.4.1.72.4" class="ltx_td ltx_align_left">84.8%</td>
<td id="S5.T4.4.1.72.5" class="ltx_td ltx_align_left">86.2%</td>
<td id="S5.T4.4.1.72.6" class="ltx_td ltx_align_left">84.7%</td>
<td id="S5.T4.4.1.72.7" class="ltx_td ltx_align_left ltx_border_r">85.6%</td>
<td id="S5.T4.4.1.72.8" class="ltx_td ltx_align_left">94.4%</td>
<td id="S5.T4.4.1.72.9" class="ltx_td ltx_align_left">86.1%</td>
<td id="S5.T4.4.1.72.10" class="ltx_td ltx_align_left">86.0%</td>
<td id="S5.T4.4.1.72.11" class="ltx_td ltx_align_left">84.8%</td>
<td id="S5.T4.4.1.72.12" class="ltx_td ltx_align_left ltx_border_r">84.7%</td>
<td id="S5.T4.4.1.72.13" class="ltx_td ltx_align_left">94.1%</td>
<td id="S5.T4.4.1.72.14" class="ltx_td ltx_align_left">85.0%</td>
<td id="S5.T4.4.1.72.15" class="ltx_td ltx_align_left">83.2%</td>
<td id="S5.T4.4.1.72.16" class="ltx_td ltx_align_left">84.4%</td>
<td id="S5.T4.4.1.72.17" class="ltx_td ltx_align_left">87.2%</td>
</tr>
<tr id="S5.T4.4.1.73" class="ltx_tr">
<td id="S5.T4.4.1.73.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T4.4.1.73.1.1" class="ltx_text ltx_font_bold">DFL-Ring</span></td>
<td id="S5.T4.4.1.73.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.73.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.73.3" class="ltx_td ltx_align_left ltx_border_t">88.0%</td>
<td id="S5.T4.4.1.73.4" class="ltx_td ltx_align_left ltx_border_t">87.5%</td>
<td id="S5.T4.4.1.73.5" class="ltx_td ltx_align_left ltx_border_t">42.3%</td>
<td id="S5.T4.4.1.73.6" class="ltx_td ltx_align_left ltx_border_t">15.5%</td>
<td id="S5.T4.4.1.73.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.4%</td>
<td id="S5.T4.4.1.73.8" class="ltx_td ltx_align_left ltx_border_t">8.2%</td>
<td id="S5.T4.4.1.73.9" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.73.10" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.73.11" class="ltx_td ltx_align_left ltx_border_t">1.5%</td>
<td id="S5.T4.4.1.73.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.4%</td>
<td id="S5.T4.4.1.73.13" class="ltx_td ltx_align_left ltx_border_t">88.0%</td>
<td id="S5.T4.4.1.73.14" class="ltx_td ltx_align_left ltx_border_t">85.9%</td>
<td id="S5.T4.4.1.73.15" class="ltx_td ltx_align_left ltx_border_t">84.0%</td>
<td id="S5.T4.4.1.73.16" class="ltx_td ltx_align_left ltx_border_t">81.3%</td>
<td id="S5.T4.4.1.73.17" class="ltx_td ltx_align_left ltx_border_t">64.6%</td>
</tr>
<tr id="S5.T4.4.1.74" class="ltx_tr">
<td id="S5.T4.4.1.74.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.74.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.74.2" class="ltx_td ltx_align_left">94.9%</td>
<td id="S5.T4.4.1.74.3" class="ltx_td ltx_align_left">19.1%</td>
<td id="S5.T4.4.1.74.4" class="ltx_td ltx_align_left">18.2%</td>
<td id="S5.T4.4.1.74.5" class="ltx_td ltx_align_left">75.2%</td>
<td id="S5.T4.4.1.74.6" class="ltx_td ltx_align_left ltx_border_r">0.4%</td>
<td id="S5.T4.4.1.74.7" class="ltx_td ltx_align_left">27.8%</td>
<td id="S5.T4.4.1.74.8" class="ltx_td ltx_align_left">74.5%</td>
<td id="S5.T4.4.1.74.9" class="ltx_td ltx_align_left">17.9%</td>
<td id="S5.T4.4.1.74.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.74.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.74.12" class="ltx_td ltx_align_left">94.3%</td>
<td id="S5.T4.4.1.74.13" class="ltx_td ltx_align_left">88.0%</td>
<td id="S5.T4.4.1.74.14" class="ltx_td ltx_align_left">78.2%</td>
<td id="S5.T4.4.1.74.15" class="ltx_td ltx_align_left">85.6%</td>
<td id="S5.T4.4.1.74.16" class="ltx_td ltx_align_left">16.5%</td>
</tr>
<tr id="S5.T4.4.1.75" class="ltx_tr">
<td id="S5.T4.4.1.75.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.75.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.75.2" class="ltx_td ltx_align_left">96.1%</td>
<td id="S5.T4.4.1.75.3" class="ltx_td ltx_align_left">1.6%</td>
<td id="S5.T4.4.1.75.4" class="ltx_td ltx_align_left">1.2%</td>
<td id="S5.T4.4.1.75.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.75.5.1" class="ltx_text ltx_font_bold">94.3%</span></td>
<td id="S5.T4.4.1.75.6" class="ltx_td ltx_align_left ltx_border_r">0.3%</td>
<td id="S5.T4.4.1.75.7" class="ltx_td ltx_align_left">36.0%</td>
<td id="S5.T4.4.1.75.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.75.8.1" class="ltx_text ltx_font_bold">93.8%</span></td>
<td id="S5.T4.4.1.75.9" class="ltx_td ltx_align_left">23.0%</td>
<td id="S5.T4.4.1.75.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.75.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.75.12" class="ltx_td ltx_align_left">95.6%</td>
<td id="S5.T4.4.1.75.13" class="ltx_td ltx_align_left">90.4%</td>
<td id="S5.T4.4.1.75.14" class="ltx_td ltx_align_left">80.7%</td>
<td id="S5.T4.4.1.75.15" class="ltx_td ltx_align_left">86.3%</td>
<td id="S5.T4.4.1.75.16" class="ltx_td ltx_align_left">2.0%</td>
</tr>
<tr id="S5.T4.4.1.76" class="ltx_tr">
<td id="S5.T4.4.1.76.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.76.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.76.2" class="ltx_td ltx_align_left">96.9%</td>
<td id="S5.T4.4.1.76.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.76.3.1" class="ltx_text ltx_font_bold">95.7%</span></td>
<td id="S5.T4.4.1.76.4" class="ltx_td ltx_align_left">86.8%</td>
<td id="S5.T4.4.1.76.5" class="ltx_td ltx_align_left">72.1%</td>
<td id="S5.T4.4.1.76.6" class="ltx_td ltx_align_left ltx_border_r">0.4%</td>
<td id="S5.T4.4.1.76.7" class="ltx_td ltx_align_left">94.8%</td>
<td id="S5.T4.4.1.76.8" class="ltx_td ltx_align_left">67.6%</td>
<td id="S5.T4.4.1.76.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.76.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.76.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.76.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.76.12.1" class="ltx_text ltx_font_bold">97.0%</span></td>
<td id="S5.T4.4.1.76.13" class="ltx_td ltx_align_left">95.7%</td>
<td id="S5.T4.4.1.76.14" class="ltx_td ltx_align_left">86.4%</td>
<td id="S5.T4.4.1.76.15" class="ltx_td ltx_align_left">74.9%</td>
<td id="S5.T4.4.1.76.16" class="ltx_td ltx_align_left">2.0%</td>
</tr>
<tr id="S5.T4.4.1.77" class="ltx_tr">
<td id="S5.T4.4.1.77.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.77.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.77.2" class="ltx_td ltx_align_left">96.5%</td>
<td id="S5.T4.4.1.77.3" class="ltx_td ltx_align_left">87.4%</td>
<td id="S5.T4.4.1.77.4" class="ltx_td ltx_align_left">87.1%</td>
<td id="S5.T4.4.1.77.5" class="ltx_td ltx_align_left">88.4%</td>
<td id="S5.T4.4.1.77.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.77.6.1" class="ltx_text ltx_font_bold">86.5%</span></td>
<td id="S5.T4.4.1.77.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.77.7.1" class="ltx_text ltx_font_bold">96.7%</span></td>
<td id="S5.T4.4.1.77.8" class="ltx_td ltx_align_left">88.4%</td>
<td id="S5.T4.4.1.77.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.77.9.1" class="ltx_text ltx_font_bold">87.2%</span></td>
<td id="S5.T4.4.1.77.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.77.10.1" class="ltx_text ltx_font_bold">88.3%</span></td>
<td id="S5.T4.4.1.77.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.77.11.1" class="ltx_text ltx_font_bold">88.2%</span></td>
<td id="S5.T4.4.1.77.12" class="ltx_td ltx_align_left">90.7%</td>
<td id="S5.T4.4.1.77.13" class="ltx_td ltx_align_left">84.5%</td>
<td id="S5.T4.4.1.77.14" class="ltx_td ltx_align_left">87.3%</td>
<td id="S5.T4.4.1.77.15" class="ltx_td ltx_align_left">87.8%</td>
<td id="S5.T4.4.1.77.16" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.77.16.1" class="ltx_text ltx_font_bold">90.3%</span></td>
</tr>
<tr id="S5.T4.4.1.78" class="ltx_tr">
<td id="S5.T4.4.1.78.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.78.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.2.1" class="ltx_text ltx_font_bold">97.4%</span></td>
<td id="S5.T4.4.1.78.3" class="ltx_td ltx_align_left">95.5%</td>
<td id="S5.T4.4.1.78.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.4.1" class="ltx_text ltx_font_bold">88.3%</span></td>
<td id="S5.T4.4.1.78.5" class="ltx_td ltx_align_left">5.9%</td>
<td id="S5.T4.4.1.78.6" class="ltx_td ltx_align_left ltx_border_r">1.1%</td>
<td id="S5.T4.4.1.78.7" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.78.8" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.78.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.78.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.78.11" class="ltx_td ltx_align_left ltx_border_r">1.9%</td>
<td id="S5.T4.4.1.78.12" class="ltx_td ltx_align_left">96.9%</td>
<td id="S5.T4.4.1.78.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.13.1" class="ltx_text ltx_font_bold">96.8%</span></td>
<td id="S5.T4.4.1.78.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.14.1" class="ltx_text ltx_font_bold">95.3%</span></td>
<td id="S5.T4.4.1.78.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.78.15.1" class="ltx_text ltx_font_bold">90.5%</span></td>
<td id="S5.T4.4.1.78.16" class="ltx_td ltx_align_left">73.0%</td>
</tr>
<tr id="S5.T4.4.1.79" class="ltx_tr">
<td id="S5.T4.4.1.79.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.79.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.79.2" class="ltx_td ltx_align_left">95.2%</td>
<td id="S5.T4.4.1.79.3" class="ltx_td ltx_align_left">84.0%</td>
<td id="S5.T4.4.1.79.4" class="ltx_td ltx_align_left">83.9%</td>
<td id="S5.T4.4.1.79.5" class="ltx_td ltx_align_left">85.9%</td>
<td id="S5.T4.4.1.79.6" class="ltx_td ltx_align_left ltx_border_r">84.9%</td>
<td id="S5.T4.4.1.79.7" class="ltx_td ltx_align_left">83.7%</td>
<td id="S5.T4.4.1.79.8" class="ltx_td ltx_align_left">85.3%</td>
<td id="S5.T4.4.1.79.9" class="ltx_td ltx_align_left">83.9%</td>
<td id="S5.T4.4.1.79.10" class="ltx_td ltx_align_left">85.0%</td>
<td id="S5.T4.4.1.79.11" class="ltx_td ltx_align_left ltx_border_r">86.7%</td>
<td id="S5.T4.4.1.79.12" class="ltx_td ltx_align_left">86.5%</td>
<td id="S5.T4.4.1.79.13" class="ltx_td ltx_align_left">83.8%</td>
<td id="S5.T4.4.1.79.14" class="ltx_td ltx_align_left">86.0%</td>
<td id="S5.T4.4.1.79.15" class="ltx_td ltx_align_left">86.6%</td>
<td id="S5.T4.4.1.79.16" class="ltx_td ltx_align_left">86.2%</td>
</tr>
<tr id="S5.T4.4.1.80" class="ltx_tr">
<td id="S5.T4.4.1.80.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="7"><span id="S5.T4.4.1.80.1.1" class="ltx_text ltx_font_bold">DFL-Star</span></td>
<td id="S5.T4.4.1.80.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.4.1.80.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T4.4.1.80.3" class="ltx_td ltx_align_left ltx_border_t">86.5%</td>
<td id="S5.T4.4.1.80.4" class="ltx_td ltx_align_left ltx_border_t">85.7%</td>
<td id="S5.T4.4.1.80.5" class="ltx_td ltx_align_left ltx_border_t">46.8%</td>
<td id="S5.T4.4.1.80.6" class="ltx_td ltx_align_left ltx_border_t">9.9%</td>
<td id="S5.T4.4.1.80.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.8%</td>
<td id="S5.T4.4.1.80.8" class="ltx_td ltx_align_left ltx_border_t">1.7%</td>
<td id="S5.T4.4.1.80.9" class="ltx_td ltx_align_left ltx_border_t">3.4%</td>
<td id="S5.T4.4.1.80.10" class="ltx_td ltx_align_left ltx_border_t">1.6%</td>
<td id="S5.T4.4.1.80.11" class="ltx_td ltx_align_left ltx_border_t">1.5%</td>
<td id="S5.T4.4.1.80.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.4%</td>
<td id="S5.T4.4.1.80.13" class="ltx_td ltx_align_left ltx_border_t">88.0%</td>
<td id="S5.T4.4.1.80.14" class="ltx_td ltx_align_left ltx_border_t">84.5%</td>
<td id="S5.T4.4.1.80.15" class="ltx_td ltx_align_left ltx_border_t">82.6%</td>
<td id="S5.T4.4.1.80.16" class="ltx_td ltx_align_left ltx_border_t">77.4%</td>
<td id="S5.T4.4.1.80.17" class="ltx_td ltx_align_left ltx_border_t">66.8%</td>
</tr>
<tr id="S5.T4.4.1.81" class="ltx_tr">
<td id="S5.T4.4.1.81.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.81.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T4.4.1.81.2" class="ltx_td ltx_align_left">89.2%</td>
<td id="S5.T4.4.1.81.3" class="ltx_td ltx_align_left">93.4%</td>
<td id="S5.T4.4.1.81.4" class="ltx_td ltx_align_left">89.6%</td>
<td id="S5.T4.4.1.81.5" class="ltx_td ltx_align_left">10.2%</td>
<td id="S5.T4.4.1.81.6" class="ltx_td ltx_align_left ltx_border_r">0.7%</td>
<td id="S5.T4.4.1.81.7" class="ltx_td ltx_align_left">59.9%</td>
<td id="S5.T4.4.1.81.8" class="ltx_td ltx_align_left">55.4%</td>
<td id="S5.T4.4.1.81.9" class="ltx_td ltx_align_left">43.3%</td>
<td id="S5.T4.4.1.81.10" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.81.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.81.12" class="ltx_td ltx_align_left">91.8%</td>
<td id="S5.T4.4.1.81.13" class="ltx_td ltx_align_left">93.4%</td>
<td id="S5.T4.4.1.81.14" class="ltx_td ltx_align_left">87.1%</td>
<td id="S5.T4.4.1.81.15" class="ltx_td ltx_align_left">18.2%</td>
<td id="S5.T4.4.1.81.16" class="ltx_td ltx_align_left">17.4%</td>
</tr>
<tr id="S5.T4.4.1.82" class="ltx_tr">
<td id="S5.T4.4.1.82.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.82.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T4.4.1.82.2" class="ltx_td ltx_align_left">95.2%</td>
<td id="S5.T4.4.1.82.3" class="ltx_td ltx_align_left">95.0%</td>
<td id="S5.T4.4.1.82.4" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.82.4.1" class="ltx_text ltx_font_bold">94.5%</span></td>
<td id="S5.T4.4.1.82.5" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T4.4.1.82.6" class="ltx_td ltx_align_left ltx_border_r">0.6%</td>
<td id="S5.T4.4.1.82.7" class="ltx_td ltx_align_left">74.8%</td>
<td id="S5.T4.4.1.82.8" class="ltx_td ltx_align_left">69.6%</td>
<td id="S5.T4.4.1.82.9" class="ltx_td ltx_align_left">55.6%</td>
<td id="S5.T4.4.1.82.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.82.11" class="ltx_td ltx_align_left ltx_border_r">1.8%</td>
<td id="S5.T4.4.1.82.12" class="ltx_td ltx_align_left">94.4%</td>
<td id="S5.T4.4.1.82.13" class="ltx_td ltx_align_left">94.2%</td>
<td id="S5.T4.4.1.82.14" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.82.14.1" class="ltx_text ltx_font_bold">93.5%</span></td>
<td id="S5.T4.4.1.82.15" class="ltx_td ltx_align_left">2.0%</td>
<td id="S5.T4.4.1.82.16" class="ltx_td ltx_align_left">2.3%</td>
</tr>
<tr id="S5.T4.4.1.83" class="ltx_tr">
<td id="S5.T4.4.1.83.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.83.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T4.4.1.83.2" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.83.2.1" class="ltx_text ltx_font_bold">97.2%</span></td>
<td id="S5.T4.4.1.83.3" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.83.3.1" class="ltx_text ltx_font_bold">96.5%</span></td>
<td id="S5.T4.4.1.83.4" class="ltx_td ltx_align_left">67.9%</td>
<td id="S5.T4.4.1.83.5" class="ltx_td ltx_align_left">50.0%</td>
<td id="S5.T4.4.1.83.6" class="ltx_td ltx_align_left ltx_border_r">1.1%</td>
<td id="S5.T4.4.1.83.7" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.83.7.1" class="ltx_text ltx_font_bold">97.2%</span></td>
<td id="S5.T4.4.1.83.8" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.83.9" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T4.4.1.83.10" class="ltx_td ltx_align_left">1.9%</td>
<td id="S5.T4.4.1.83.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.83.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.83.12.1" class="ltx_text ltx_font_bold">97.1%</span></td>
<td id="S5.T4.4.1.83.13" class="ltx_td ltx_align_left">93.8%</td>
<td id="S5.T4.4.1.83.14" class="ltx_td ltx_align_left">79.4%</td>
<td id="S5.T4.4.1.83.15" class="ltx_td ltx_align_left">70.7%</td>
<td id="S5.T4.4.1.83.16" class="ltx_td ltx_align_left">2.1%</td>
</tr>
<tr id="S5.T4.4.1.84" class="ltx_tr">
<td id="S5.T4.4.1.84.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.84.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T4.4.1.84.2" class="ltx_td ltx_align_left">86.9%</td>
<td id="S5.T4.4.1.84.3" class="ltx_td ltx_align_left">85.6%</td>
<td id="S5.T4.4.1.84.4" class="ltx_td ltx_align_left">87.0%</td>
<td id="S5.T4.4.1.84.5" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.84.5.1" class="ltx_text ltx_font_bold">88.5%</span></td>
<td id="S5.T4.4.1.84.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.84.6.1" class="ltx_text ltx_font_bold">90.0%</span></td>
<td id="S5.T4.4.1.84.7" class="ltx_td ltx_align_left">86.7%</td>
<td id="S5.T4.4.1.84.8" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.84.8.1" class="ltx_text ltx_font_bold">88.0%</span></td>
<td id="S5.T4.4.1.84.9" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.84.9.1" class="ltx_text ltx_font_bold">88.3%</span></td>
<td id="S5.T4.4.1.84.10" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.84.10.1" class="ltx_text ltx_font_bold">88.2%</span></td>
<td id="S5.T4.4.1.84.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T4.4.1.84.11.1" class="ltx_text ltx_font_bold">87.7%</span></td>
<td id="S5.T4.4.1.84.12" class="ltx_td ltx_align_left">87.3%</td>
<td id="S5.T4.4.1.84.13" class="ltx_td ltx_align_left">87.9%</td>
<td id="S5.T4.4.1.84.14" class="ltx_td ltx_align_left">87.5%</td>
<td id="S5.T4.4.1.84.15" class="ltx_td ltx_align_left">87.7%</td>
<td id="S5.T4.4.1.84.16" class="ltx_td ltx_align_left">84.4%</td>
</tr>
<tr id="S5.T4.4.1.85" class="ltx_tr">
<td id="S5.T4.4.1.85.1" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.85.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T4.4.1.85.2" class="ltx_td ltx_align_left">91.8%</td>
<td id="S5.T4.4.1.85.3" class="ltx_td ltx_align_left">95.5%</td>
<td id="S5.T4.4.1.85.4" class="ltx_td ltx_align_left">85.2%</td>
<td id="S5.T4.4.1.85.5" class="ltx_td ltx_align_left">51.2%</td>
<td id="S5.T4.4.1.85.6" class="ltx_td ltx_align_left ltx_border_r">1.0%</td>
<td id="S5.T4.4.1.85.7" class="ltx_td ltx_align_left">6.7%</td>
<td id="S5.T4.4.1.85.8" class="ltx_td ltx_align_left">6.9%</td>
<td id="S5.T4.4.1.85.9" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.85.10" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T4.4.1.85.11" class="ltx_td ltx_align_left ltx_border_r">1.7%</td>
<td id="S5.T4.4.1.85.12" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.85.12.1" class="ltx_text ltx_font_bold">97.1%</span></td>
<td id="S5.T4.4.1.85.13" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.85.13.1" class="ltx_text ltx_font_bold">96.0%</span></td>
<td id="S5.T4.4.1.85.14" class="ltx_td ltx_align_left">91.0%</td>
<td id="S5.T4.4.1.85.15" class="ltx_td ltx_align_left"><span id="S5.T4.4.1.85.15.1" class="ltx_text ltx_font_bold">89.0%</span></td>
<td id="S5.T4.4.1.85.16" class="ltx_td ltx_align_left">82.2%</td>
</tr>
<tr id="S5.T4.4.1.86" class="ltx_tr">
<td id="S5.T4.4.1.86.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T4.4.1.86.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T4.4.1.86.2" class="ltx_td ltx_align_left ltx_border_bb">85.0%</td>
<td id="S5.T4.4.1.86.3" class="ltx_td ltx_align_left ltx_border_bb">84.2%</td>
<td id="S5.T4.4.1.86.4" class="ltx_td ltx_align_left ltx_border_bb">86.8%</td>
<td id="S5.T4.4.1.86.5" class="ltx_td ltx_align_left ltx_border_bb">85.4%</td>
<td id="S5.T4.4.1.86.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">87.4%</td>
<td id="S5.T4.4.1.86.7" class="ltx_td ltx_align_left ltx_border_bb">85.3%</td>
<td id="S5.T4.4.1.86.8" class="ltx_td ltx_align_left ltx_border_bb">86.2%</td>
<td id="S5.T4.4.1.86.9" class="ltx_td ltx_align_left ltx_border_bb">86.4%</td>
<td id="S5.T4.4.1.86.10" class="ltx_td ltx_align_left ltx_border_bb">85.0%</td>
<td id="S5.T4.4.1.86.11" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">84.4%</td>
<td id="S5.T4.4.1.86.12" class="ltx_td ltx_align_left ltx_border_bb">84.5%</td>
<td id="S5.T4.4.1.86.13" class="ltx_td ltx_align_left ltx_border_bb">84.4%</td>
<td id="S5.T4.4.1.86.14" class="ltx_td ltx_align_left ltx_border_bb">83.0%</td>
<td id="S5.T4.4.1.86.15" class="ltx_td ltx_align_left ltx_border_bb">86.6%</td>
<td id="S5.T4.4.1.86.16" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T4.4.1.86.16.1" class="ltx_text ltx_font_bold">84.7%</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.3.2" class="ltx_text" style="font-size:90%;">Benchmark of Average ASR-Targeted Results for Defense Mechanisms in Mitigating Targeted Label Flipping Attack</span></figcaption>
<div id="S5.T5.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:339pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.5pt,100.5pt) scale(0.627801695951702,0.627801695951702) ;">
<table id="S5.T5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T5.4.1.1" class="ltx_tr">
<td id="S5.T5.4.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S5.T5.4.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S5.T5.4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T5.4.1.1.3.1" class="ltx_text ltx_font_bold">CIFAR10</span></td>
<td id="S5.T5.4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T5.4.1.1.4.1" class="ltx_text ltx_font_bold">FASHIONMNIST</span></td>
<td id="S5.T5.4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T5.4.1.1.5.1" class="ltx_text ltx_font_bold">MNIST</span></td>
</tr>
<tr id="S5.T5.4.1.2" class="ltx_tr">
<td id="S5.T5.4.1.2.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T5.4.1.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.2.1" class="ltx_text ltx_font_bold">[PNR (%)]</span></td>
<td id="S5.T5.4.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.3.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T5.4.1.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.4.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T5.4.1.2.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.5.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T5.4.1.2.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.6.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T5.4.1.2.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T5.4.1.2.7.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T5.4.1.2.8" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.8.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T5.4.1.2.9" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.9.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T5.4.1.2.10" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.10.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T5.4.1.2.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.11.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T5.4.1.2.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T5.4.1.2.12.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T5.4.1.2.13" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.13.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T5.4.1.2.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.14.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T5.4.1.2.15" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.15.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T5.4.1.2.16" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.16.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T5.4.1.2.17" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.2.17.1" class="ltx_text ltx_font_bold">90</span></td>
</tr>
<tr id="S5.T5.4.1.3" class="ltx_tr">
<td id="S5.T5.4.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T5.4.1.3.1.1" class="ltx_text ltx_font_bold">CFL</span></td>
<td id="S5.T5.4.1.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.3.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T5.4.1.3.3" class="ltx_td ltx_align_left ltx_border_t">0.3%</td>
<td id="S5.T5.4.1.3.4" class="ltx_td ltx_align_left ltx_border_t">4.5%</td>
<td id="S5.T5.4.1.3.5" class="ltx_td ltx_align_left ltx_border_t">18.0%</td>
<td id="S5.T5.4.1.3.6" class="ltx_td ltx_align_left ltx_border_t">39.0%</td>
<td id="S5.T5.4.1.3.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.9%</td>
<td id="S5.T5.4.1.3.8" class="ltx_td ltx_align_left ltx_border_t">0.4%</td>
<td id="S5.T5.4.1.3.9" class="ltx_td ltx_align_left ltx_border_t">0.0%</td>
<td id="S5.T5.4.1.3.10" class="ltx_td ltx_align_left ltx_border_t">6.4%</td>
<td id="S5.T5.4.1.3.11" class="ltx_td ltx_align_left ltx_border_t">48.0%</td>
<td id="S5.T5.4.1.3.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">66.9%</td>
<td id="S5.T5.4.1.3.13" class="ltx_td ltx_align_left ltx_border_t">0.5%</td>
<td id="S5.T5.4.1.3.14" class="ltx_td ltx_align_left ltx_border_t">24.6%</td>
<td id="S5.T5.4.1.3.15" class="ltx_td ltx_align_left ltx_border_t">79.9%</td>
<td id="S5.T5.4.1.3.16" class="ltx_td ltx_align_left ltx_border_t">76.6%</td>
<td id="S5.T5.4.1.3.17" class="ltx_td ltx_align_left ltx_border_t">77.5%</td>
</tr>
<tr id="S5.T5.4.1.4" class="ltx_tr">
<td id="S5.T5.4.1.4.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.4.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T5.4.1.4.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.4.3" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.4.3.1" class="ltx_text ltx_font_bold">4.2%</span></td>
<td id="S5.T5.4.1.4.4" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.4.4.1" class="ltx_text ltx_font_bold">16.8%</span></td>
<td id="S5.T5.4.1.4.5" class="ltx_td ltx_align_left">34.6%</td>
<td id="S5.T5.4.1.4.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.4.6.1" class="ltx_text ltx_font_bold">41.7%</span></td>
<td id="S5.T5.4.1.4.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.4.8" class="ltx_td ltx_align_left">1.6%</td>
<td id="S5.T5.4.1.4.9" class="ltx_td ltx_align_left">11.1%</td>
<td id="S5.T5.4.1.4.10" class="ltx_td ltx_align_left">17.6%</td>
<td id="S5.T5.4.1.4.11" class="ltx_td ltx_align_left ltx_border_r">39.8%</td>
<td id="S5.T5.4.1.4.12" class="ltx_td ltx_align_left">1.0%</td>
<td id="S5.T5.4.1.4.13" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.4.13.1" class="ltx_text ltx_font_bold">0.8%</span></td>
<td id="S5.T5.4.1.4.14" class="ltx_td ltx_align_left">15.6%</td>
<td id="S5.T5.4.1.4.15" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.4.15.1" class="ltx_text ltx_font_bold">21.6%</span></td>
<td id="S5.T5.4.1.4.16" class="ltx_td ltx_align_left">48.4%</td>
</tr>
<tr id="S5.T5.4.1.5" class="ltx_tr">
<td id="S5.T5.4.1.5.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.5.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T5.4.1.5.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.5.3" class="ltx_td ltx_align_left">4.4%</td>
<td id="S5.T5.4.1.5.4" class="ltx_td ltx_align_left">17.1%</td>
<td id="S5.T5.4.1.5.5" class="ltx_td ltx_align_left">38.6%</td>
<td id="S5.T5.4.1.5.6" class="ltx_td ltx_align_left ltx_border_r">41.8%</td>
<td id="S5.T5.4.1.5.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.5.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.5.9" class="ltx_td ltx_align_left">11.5%</td>
<td id="S5.T5.4.1.5.10" class="ltx_td ltx_align_left">19.2%</td>
<td id="S5.T5.4.1.5.11" class="ltx_td ltx_align_left ltx_border_r">40.7%</td>
<td id="S5.T5.4.1.5.12" class="ltx_td ltx_align_left">1.0%</td>
<td id="S5.T5.4.1.5.13" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T5.4.1.5.14" class="ltx_td ltx_align_left">16.5%</td>
<td id="S5.T5.4.1.5.15" class="ltx_td ltx_align_left">22.5%</td>
<td id="S5.T5.4.1.5.16" class="ltx_td ltx_align_left">49.6%</td>
</tr>
<tr id="S5.T5.4.1.6" class="ltx_tr">
<td id="S5.T5.4.1.6.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.6.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T5.4.1.6.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.6.3" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.6.4" class="ltx_td ltx_align_left">21.1%</td>
<td id="S5.T5.4.1.6.5" class="ltx_td ltx_align_left">46.7%</td>
<td id="S5.T5.4.1.6.6" class="ltx_td ltx_align_left ltx_border_r">44.2%</td>
<td id="S5.T5.4.1.6.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.6.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.6.9" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.6.9.1" class="ltx_text ltx_font_bold">2.7%</span></td>
<td id="S5.T5.4.1.6.10" class="ltx_td ltx_align_left">15.9%</td>
<td id="S5.T5.4.1.6.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.6.11.1" class="ltx_text ltx_font_bold">39.0%</span></td>
<td id="S5.T5.4.1.6.12" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T5.4.1.6.13" class="ltx_td ltx_align_left">1.2%</td>
<td id="S5.T5.4.1.6.14" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.6.14.1" class="ltx_text ltx_font_bold">3.0%</span></td>
<td id="S5.T5.4.1.6.15" class="ltx_td ltx_align_left">22.9%</td>
<td id="S5.T5.4.1.6.16" class="ltx_td ltx_align_left">48.3%</td>
</tr>
<tr id="S5.T5.4.1.7" class="ltx_tr">
<td id="S5.T5.4.1.7.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.7.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T5.4.1.7.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T5.4.1.7.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T5.4.1.7.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.7.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T5.4.1.8" class="ltx_tr">
<td id="S5.T5.4.1.8.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.8.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T5.4.1.8.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.8.3" class="ltx_td ltx_align_left">4.8%</td>
<td id="S5.T5.4.1.8.4" class="ltx_td ltx_align_left">25.5%</td>
<td id="S5.T5.4.1.8.5" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.8.5.1" class="ltx_text ltx_font_bold">31.7%</span></td>
<td id="S5.T5.4.1.8.6" class="ltx_td ltx_align_left ltx_border_r">44.8%</td>
<td id="S5.T5.4.1.8.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.8.8" class="ltx_td ltx_align_left">8.8%</td>
<td id="S5.T5.4.1.8.9" class="ltx_td ltx_align_left">9.9%</td>
<td id="S5.T5.4.1.8.10" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.8.10.1" class="ltx_text ltx_font_bold">14.8%</span></td>
<td id="S5.T5.4.1.8.11" class="ltx_td ltx_align_left ltx_border_r">41.2%</td>
<td id="S5.T5.4.1.8.12" class="ltx_td ltx_align_left">1.1%</td>
<td id="S5.T5.4.1.8.13" class="ltx_td ltx_align_left">1.2%</td>
<td id="S5.T5.4.1.8.14" class="ltx_td ltx_align_left">15.5%</td>
<td id="S5.T5.4.1.8.15" class="ltx_td ltx_align_left">22.9%</td>
<td id="S5.T5.4.1.8.16" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.8.16.1" class="ltx_text ltx_font_bold">47.3%</span></td>
</tr>
<tr id="S5.T5.4.1.9" class="ltx_tr">
<td id="S5.T5.4.1.9.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.9.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T5.4.1.9.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T5.4.1.9.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T5.4.1.9.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T5.4.1.9.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T5.4.1.10" class="ltx_tr">
<td id="S5.T5.4.1.10.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S5.T5.4.1.10.1.1" class="ltx_text ltx_font_bold">DFL-Fully</span></td>
<td id="S5.T5.4.1.10.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.10.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T5.4.1.10.3" class="ltx_td ltx_align_left ltx_border_t">0.3%</td>
<td id="S5.T5.4.1.10.4" class="ltx_td ltx_align_left ltx_border_t">4.9%</td>
<td id="S5.T5.4.1.10.5" class="ltx_td ltx_align_left ltx_border_t">18.7%</td>
<td id="S5.T5.4.1.10.6" class="ltx_td ltx_align_left ltx_border_t">41.0%</td>
<td id="S5.T5.4.1.10.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.5%</td>
<td id="S5.T5.4.1.10.8" class="ltx_td ltx_align_left ltx_border_t">0.4%</td>
<td id="S5.T5.4.1.10.9" class="ltx_td ltx_align_left ltx_border_t">0.0%</td>
<td id="S5.T5.4.1.10.10" class="ltx_td ltx_align_left ltx_border_t">6.2%</td>
<td id="S5.T5.4.1.10.11" class="ltx_td ltx_align_left ltx_border_t">49.8%</td>
<td id="S5.T5.4.1.10.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">65.9%</td>
<td id="S5.T5.4.1.10.13" class="ltx_td ltx_align_left ltx_border_t">0.4%</td>
<td id="S5.T5.4.1.10.14" class="ltx_td ltx_align_left ltx_border_t">25.5%</td>
<td id="S5.T5.4.1.10.15" class="ltx_td ltx_align_left ltx_border_t">74.9%</td>
<td id="S5.T5.4.1.10.16" class="ltx_td ltx_align_left ltx_border_t">76.5%</td>
<td id="S5.T5.4.1.10.17" class="ltx_td ltx_align_left ltx_border_t">78.8%</td>
</tr>
<tr id="S5.T5.4.1.11" class="ltx_tr">
<td id="S5.T5.4.1.11.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.11.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T5.4.1.11.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.11.3" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.11.4" class="ltx_td ltx_align_left">16.2%</td>
<td id="S5.T5.4.1.11.5" class="ltx_td ltx_align_left">35.6%</td>
<td id="S5.T5.4.1.11.6" class="ltx_td ltx_align_left ltx_border_r">41.8%</td>
<td id="S5.T5.4.1.11.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.11.8" class="ltx_td ltx_align_left">19.7%</td>
<td id="S5.T5.4.1.11.9" class="ltx_td ltx_align_left">12.8%</td>
<td id="S5.T5.4.1.11.10" class="ltx_td ltx_align_left">82.9%</td>
<td id="S5.T5.4.1.11.11" class="ltx_td ltx_align_left ltx_border_r">82.1%</td>
<td id="S5.T5.4.1.11.12" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T5.4.1.11.13" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T5.4.1.11.14" class="ltx_td ltx_align_left">91.7%</td>
<td id="S5.T5.4.1.11.15" class="ltx_td ltx_align_left">91.5%</td>
<td id="S5.T5.4.1.11.16" class="ltx_td ltx_align_left">90.6%</td>
</tr>
<tr id="S5.T5.4.1.12" class="ltx_tr">
<td id="S5.T5.4.1.12.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.12.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T5.4.1.12.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.12.3" class="ltx_td ltx_align_left">4.4%</td>
<td id="S5.T5.4.1.12.4" class="ltx_td ltx_align_left">16.6%</td>
<td id="S5.T5.4.1.12.5" class="ltx_td ltx_align_left">42.7%</td>
<td id="S5.T5.4.1.12.6" class="ltx_td ltx_align_left ltx_border_r">52.6%</td>
<td id="S5.T5.4.1.12.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.12.8" class="ltx_td ltx_align_left">25.0%</td>
<td id="S5.T5.4.1.12.9" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.12.10" class="ltx_td ltx_align_left">89.4%</td>
<td id="S5.T5.4.1.12.11" class="ltx_td ltx_align_left ltx_border_r">84.1%</td>
<td id="S5.T5.4.1.12.12" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T5.4.1.12.13" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T5.4.1.12.14" class="ltx_td ltx_align_left">97.3%</td>
<td id="S5.T5.4.1.12.15" class="ltx_td ltx_align_left">96.3%</td>
<td id="S5.T5.4.1.12.16" class="ltx_td ltx_align_left">97.0%</td>
</tr>
<tr id="S5.T5.4.1.13" class="ltx_tr">
<td id="S5.T5.4.1.13.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.13.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T5.4.1.13.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.13.3" class="ltx_td ltx_align_left">4.5%</td>
<td id="S5.T5.4.1.13.4" class="ltx_td ltx_align_left">15.3%</td>
<td id="S5.T5.4.1.13.5" class="ltx_td ltx_align_left">38.3%</td>
<td id="S5.T5.4.1.13.6" class="ltx_td ltx_align_left ltx_border_r">60.0%</td>
<td id="S5.T5.4.1.13.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.13.8" class="ltx_td ltx_align_left">0.6%</td>
<td id="S5.T5.4.1.13.9" class="ltx_td ltx_align_left">25.7%</td>
<td id="S5.T5.4.1.13.10" class="ltx_td ltx_align_left">76.3%</td>
<td id="S5.T5.4.1.13.11" class="ltx_td ltx_align_left ltx_border_r">86.4%</td>
<td id="S5.T5.4.1.13.12" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T5.4.1.13.13" class="ltx_td ltx_align_left">5.1%</td>
<td id="S5.T5.4.1.13.14" class="ltx_td ltx_align_left">22.2%</td>
<td id="S5.T5.4.1.13.15" class="ltx_td ltx_align_left">89.3%</td>
<td id="S5.T5.4.1.13.16" class="ltx_td ltx_align_left">97.8%</td>
</tr>
<tr id="S5.T5.4.1.14" class="ltx_tr">
<td id="S5.T5.4.1.14.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.1.1" class="ltx_text ltx_font_bold">Connected</span></td>
<td id="S5.T5.4.1.14.2" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.2.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T5.4.1.14.3" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.14.4" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.4.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.14.5" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.5.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.14.6" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.6.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.14.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.14.7.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.14.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.14.9" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.9.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.14.10" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.10.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.14.11" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.11.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.14.12" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.14.12.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.14.13" class="ltx_td ltx_align_left">0.1%</td>
<td id="S5.T5.4.1.14.14" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.14.1" class="ltx_text ltx_font_bold">1.3%</span></td>
<td id="S5.T5.4.1.14.15" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.15.1" class="ltx_text ltx_font_bold">1.2%</span></td>
<td id="S5.T5.4.1.14.16" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.16.1" class="ltx_text ltx_font_bold">0.8%</span></td>
<td id="S5.T5.4.1.14.17" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.14.17.1" class="ltx_text ltx_font_bold">1.6%</span></td>
</tr>
<tr id="S5.T5.4.1.15" class="ltx_tr">
<td id="S5.T5.4.1.15.1" class="ltx_td"></td>
<td id="S5.T5.4.1.15.2" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.15.2.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T5.4.1.15.3" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.15.4" class="ltx_td ltx_align_left">4.4%</td>
<td id="S5.T5.4.1.15.5" class="ltx_td ltx_align_left">17.1%</td>
<td id="S5.T5.4.1.15.6" class="ltx_td ltx_align_left">47.1%</td>
<td id="S5.T5.4.1.15.7" class="ltx_td ltx_align_left ltx_border_r">45.6%</td>
<td id="S5.T5.4.1.15.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.15.9" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T5.4.1.15.10" class="ltx_td ltx_align_left">67.1%</td>
<td id="S5.T5.4.1.15.11" class="ltx_td ltx_align_left">75.9%</td>
<td id="S5.T5.4.1.15.12" class="ltx_td ltx_align_left ltx_border_r">86.9%</td>
<td id="S5.T5.4.1.15.13" class="ltx_td ltx_align_left">0.7%</td>
<td id="S5.T5.4.1.15.14" class="ltx_td ltx_align_left">3.0%</td>
<td id="S5.T5.4.1.15.15" class="ltx_td ltx_align_left">75.8%</td>
<td id="S5.T5.4.1.15.16" class="ltx_td ltx_align_left">96.8%</td>
<td id="S5.T5.4.1.15.17" class="ltx_td ltx_align_left">95.3%</td>
</tr>
<tr id="S5.T5.4.1.16" class="ltx_tr">
<td id="S5.T5.4.1.16.1" class="ltx_td"></td>
<td id="S5.T5.4.1.16.2" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.16.2.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T5.4.1.16.3" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.16.4" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.16.5" class="ltx_td ltx_align_left">16.6%</td>
<td id="S5.T5.4.1.16.6" class="ltx_td ltx_align_left">36.7%</td>
<td id="S5.T5.4.1.16.7" class="ltx_td ltx_align_left ltx_border_r">42.3%</td>
<td id="S5.T5.4.1.16.8" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.16.9" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.16.10" class="ltx_td ltx_align_left">5.4%</td>
<td id="S5.T5.4.1.16.11" class="ltx_td ltx_align_left">44.0%</td>
<td id="S5.T5.4.1.16.12" class="ltx_td ltx_align_left ltx_border_r">57.6%</td>
<td id="S5.T5.4.1.16.13" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T5.4.1.16.14" class="ltx_td ltx_align_left">22.4%</td>
<td id="S5.T5.4.1.16.15" class="ltx_td ltx_align_left">64.7%</td>
<td id="S5.T5.4.1.16.16" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T5.4.1.16.17" class="ltx_td ltx_align_left">68.7%</td>
</tr>
<tr id="S5.T5.4.1.17" class="ltx_tr">
<td id="S5.T5.4.1.17.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T5.4.1.17.1.1" class="ltx_text ltx_font_bold">DFL-Ring</span></td>
<td id="S5.T5.4.1.17.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.17.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T5.4.1.17.3" class="ltx_td ltx_align_left ltx_border_t">0.1%</td>
<td id="S5.T5.4.1.17.4" class="ltx_td ltx_align_left ltx_border_t">4.3%</td>
<td id="S5.T5.4.1.17.5" class="ltx_td ltx_align_left ltx_border_t">17.6%</td>
<td id="S5.T5.4.1.17.6" class="ltx_td ltx_align_left ltx_border_t">40.9%</td>
<td id="S5.T5.4.1.17.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">61.6%</td>
<td id="S5.T5.4.1.17.8" class="ltx_td ltx_align_left ltx_border_t">0.0%</td>
<td id="S5.T5.4.1.17.9" class="ltx_td ltx_align_left ltx_border_t">0.8%</td>
<td id="S5.T5.4.1.17.10" class="ltx_td ltx_align_left ltx_border_t">0.4%</td>
<td id="S5.T5.4.1.17.11" class="ltx_td ltx_align_left ltx_border_t">42.7%</td>
<td id="S5.T5.4.1.17.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.9%</td>
<td id="S5.T5.4.1.17.13" class="ltx_td ltx_align_left ltx_border_t">0.6%</td>
<td id="S5.T5.4.1.17.14" class="ltx_td ltx_align_left ltx_border_t">19.9%</td>
<td id="S5.T5.4.1.17.15" class="ltx_td ltx_align_left ltx_border_t">81.9%</td>
<td id="S5.T5.4.1.17.16" class="ltx_td ltx_align_left ltx_border_t">93.1%</td>
<td id="S5.T5.4.1.17.17" class="ltx_td ltx_align_left ltx_border_t">96.3%</td>
</tr>
<tr id="S5.T5.4.1.18" class="ltx_tr">
<td id="S5.T5.4.1.18.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.18.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T5.4.1.18.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.18.3" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.18.4" class="ltx_td ltx_align_left">16.5%</td>
<td id="S5.T5.4.1.18.5" class="ltx_td ltx_align_left">35.8%</td>
<td id="S5.T5.4.1.18.6" class="ltx_td ltx_align_left ltx_border_r">43.3%</td>
<td id="S5.T5.4.1.18.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.18.8" class="ltx_td ltx_align_left">0.1%</td>
<td id="S5.T5.4.1.18.9" class="ltx_td ltx_align_left">41.2%</td>
<td id="S5.T5.4.1.18.10" class="ltx_td ltx_align_left">57.8%</td>
<td id="S5.T5.4.1.18.11" class="ltx_td ltx_align_left ltx_border_r">82.1%</td>
<td id="S5.T5.4.1.18.12" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T5.4.1.18.13" class="ltx_td ltx_align_left">12.3%</td>
<td id="S5.T5.4.1.18.14" class="ltx_td ltx_align_left">78.8%</td>
<td id="S5.T5.4.1.18.15" class="ltx_td ltx_align_left">17.1%</td>
<td id="S5.T5.4.1.18.16" class="ltx_td ltx_align_left">91.9%</td>
</tr>
<tr id="S5.T5.4.1.19" class="ltx_tr">
<td id="S5.T5.4.1.19.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.19.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T5.4.1.19.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.19.3" class="ltx_td ltx_align_left">6.5%</td>
<td id="S5.T5.4.1.19.4" class="ltx_td ltx_align_left">20.0%</td>
<td id="S5.T5.4.1.19.5" class="ltx_td ltx_align_left">32.5%</td>
<td id="S5.T5.4.1.19.6" class="ltx_td ltx_align_left ltx_border_r">48.8%</td>
<td id="S5.T5.4.1.19.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.19.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.19.9" class="ltx_td ltx_align_left">47.9%</td>
<td id="S5.T5.4.1.19.10" class="ltx_td ltx_align_left">56.6%</td>
<td id="S5.T5.4.1.19.11" class="ltx_td ltx_align_left ltx_border_r">84.5%</td>
<td id="S5.T5.4.1.19.12" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T5.4.1.19.13" class="ltx_td ltx_align_left">15.3%</td>
<td id="S5.T5.4.1.19.14" class="ltx_td ltx_align_left">97.7%</td>
<td id="S5.T5.4.1.19.15" class="ltx_td ltx_align_left">1.0%</td>
<td id="S5.T5.4.1.19.16" class="ltx_td ltx_align_left">95.2%</td>
</tr>
<tr id="S5.T5.4.1.20" class="ltx_tr">
<td id="S5.T5.4.1.20.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.20.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T5.4.1.20.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.20.3" class="ltx_td ltx_align_left">5.1%</td>
<td id="S5.T5.4.1.20.4" class="ltx_td ltx_align_left">15.3%</td>
<td id="S5.T5.4.1.20.5" class="ltx_td ltx_align_left">42.1%</td>
<td id="S5.T5.4.1.20.6" class="ltx_td ltx_align_left ltx_border_r">42.6%</td>
<td id="S5.T5.4.1.20.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.20.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.20.9" class="ltx_td ltx_align_left">62.1%</td>
<td id="S5.T5.4.1.20.10" class="ltx_td ltx_align_left">59.7%</td>
<td id="S5.T5.4.1.20.11" class="ltx_td ltx_align_left ltx_border_r">72.6%</td>
<td id="S5.T5.4.1.20.12" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T5.4.1.20.13" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.20.14" class="ltx_td ltx_align_left">56.3%</td>
<td id="S5.T5.4.1.20.15" class="ltx_td ltx_align_left">96.0%</td>
<td id="S5.T5.4.1.20.16" class="ltx_td ltx_align_left">94.5%</td>
</tr>
<tr id="S5.T5.4.1.21" class="ltx_tr">
<td id="S5.T5.4.1.21.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T5.4.1.21.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.21.3" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.3.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.21.4" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.4.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.21.5" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.5.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.21.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.21.6.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.21.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.21.8" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.8.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.21.9" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.9.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.21.10" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.10.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.21.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.21.11.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.21.12" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.12.1" class="ltx_text ltx_font_bold">0.5%</span></td>
<td id="S5.T5.4.1.21.13" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.13.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T5.4.1.21.14" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.14.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T5.4.1.21.15" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.15.1" class="ltx_text ltx_font_bold">0.8%</span></td>
<td id="S5.T5.4.1.21.16" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.21.16.1" class="ltx_text ltx_font_bold">1.1%</span></td>
</tr>
<tr id="S5.T5.4.1.22" class="ltx_tr">
<td id="S5.T5.4.1.22.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.22.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T5.4.1.22.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.22.3" class="ltx_td ltx_align_left">5.0%</td>
<td id="S5.T5.4.1.22.4" class="ltx_td ltx_align_left">17.9%</td>
<td id="S5.T5.4.1.22.5" class="ltx_td ltx_align_left">47.4%</td>
<td id="S5.T5.4.1.22.6" class="ltx_td ltx_align_left ltx_border_r">41.4%</td>
<td id="S5.T5.4.1.22.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.22.8" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.22.9" class="ltx_td ltx_align_left">19.9%</td>
<td id="S5.T5.4.1.22.10" class="ltx_td ltx_align_left">70.1%</td>
<td id="S5.T5.4.1.22.11" class="ltx_td ltx_align_left ltx_border_r">83.5%</td>
<td id="S5.T5.4.1.22.12" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T5.4.1.22.13" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T5.4.1.22.14" class="ltx_td ltx_align_left">9.8%</td>
<td id="S5.T5.4.1.22.15" class="ltx_td ltx_align_left">96.8%</td>
<td id="S5.T5.4.1.22.16" class="ltx_td ltx_align_left">95.3%</td>
</tr>
<tr id="S5.T5.4.1.23" class="ltx_tr">
<td id="S5.T5.4.1.23.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.23.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T5.4.1.23.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.23.3" class="ltx_td ltx_align_left">4.4%</td>
<td id="S5.T5.4.1.23.4" class="ltx_td ltx_align_left">16.2%</td>
<td id="S5.T5.4.1.23.5" class="ltx_td ltx_align_left">35.1%</td>
<td id="S5.T5.4.1.23.6" class="ltx_td ltx_align_left ltx_border_r">41.8%</td>
<td id="S5.T5.4.1.23.7" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.23.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.23.9" class="ltx_td ltx_align_left">5.5%</td>
<td id="S5.T5.4.1.23.10" class="ltx_td ltx_align_left">44.3%</td>
<td id="S5.T5.4.1.23.11" class="ltx_td ltx_align_left ltx_border_r">57.9%</td>
<td id="S5.T5.4.1.23.12" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T5.4.1.23.13" class="ltx_td ltx_align_left">22.1%</td>
<td id="S5.T5.4.1.23.14" class="ltx_td ltx_align_left">65.0%</td>
<td id="S5.T5.4.1.23.15" class="ltx_td ltx_align_left">66.1%</td>
<td id="S5.T5.4.1.23.16" class="ltx_td ltx_align_left">68.5%</td>
</tr>
<tr id="S5.T5.4.1.24" class="ltx_tr">
<td id="S5.T5.4.1.24.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="7"><span id="S5.T5.4.1.24.1.1" class="ltx_text ltx_font_bold">DFL-Star</span></td>
<td id="S5.T5.4.1.24.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T5.4.1.24.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T5.4.1.24.3" class="ltx_td ltx_align_left ltx_border_t">0.3%</td>
<td id="S5.T5.4.1.24.4" class="ltx_td ltx_align_left ltx_border_t">6.3%</td>
<td id="S5.T5.4.1.24.5" class="ltx_td ltx_align_left ltx_border_t">20.9%</td>
<td id="S5.T5.4.1.24.6" class="ltx_td ltx_align_left ltx_border_t">51.3%</td>
<td id="S5.T5.4.1.24.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">63.7%</td>
<td id="S5.T5.4.1.24.8" class="ltx_td ltx_align_left ltx_border_t">0.5%</td>
<td id="S5.T5.4.1.24.9" class="ltx_td ltx_align_left ltx_border_t">0.0%</td>
<td id="S5.T5.4.1.24.10" class="ltx_td ltx_align_left ltx_border_t">7.6%</td>
<td id="S5.T5.4.1.24.11" class="ltx_td ltx_align_left ltx_border_t">61.5%</td>
<td id="S5.T5.4.1.24.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.5%</td>
<td id="S5.T5.4.1.24.13" class="ltx_td ltx_align_left ltx_border_t">0.6%</td>
<td id="S5.T5.4.1.24.14" class="ltx_td ltx_align_left ltx_border_t">32.2%</td>
<td id="S5.T5.4.1.24.15" class="ltx_td ltx_align_left ltx_border_t">93.7%</td>
<td id="S5.T5.4.1.24.16" class="ltx_td ltx_align_left ltx_border_t">96.3%</td>
<td id="S5.T5.4.1.24.17" class="ltx_td ltx_align_left ltx_border_t">98.0%</td>
</tr>
<tr id="S5.T5.4.1.25" class="ltx_tr">
<td id="S5.T5.4.1.25.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.25.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T5.4.1.25.2" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.25.3" class="ltx_td ltx_align_left">4.3%</td>
<td id="S5.T5.4.1.25.4" class="ltx_td ltx_align_left">16.1%</td>
<td id="S5.T5.4.1.25.5" class="ltx_td ltx_align_left">35.8%</td>
<td id="S5.T5.4.1.25.6" class="ltx_td ltx_align_left ltx_border_r">41.4%</td>
<td id="S5.T5.4.1.25.7" class="ltx_td ltx_align_left">15.9%</td>
<td id="S5.T5.4.1.25.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.25.9" class="ltx_td ltx_align_left">79.7%</td>
<td id="S5.T5.4.1.25.10" class="ltx_td ltx_align_left">88.1%</td>
<td id="S5.T5.4.1.25.11" class="ltx_td ltx_align_left ltx_border_r">85.2%</td>
<td id="S5.T5.4.1.25.12" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T5.4.1.25.13" class="ltx_td ltx_align_left">1.8%</td>
<td id="S5.T5.4.1.25.14" class="ltx_td ltx_align_left">17.9%</td>
<td id="S5.T5.4.1.25.15" class="ltx_td ltx_align_left">17.4%</td>
<td id="S5.T5.4.1.25.16" class="ltx_td ltx_align_left">94.1%</td>
</tr>
<tr id="S5.T5.4.1.26" class="ltx_tr">
<td id="S5.T5.4.1.26.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.26.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T5.4.1.26.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.26.3" class="ltx_td ltx_align_left">5.3%</td>
<td id="S5.T5.4.1.26.4" class="ltx_td ltx_align_left">19.0%</td>
<td id="S5.T5.4.1.26.5" class="ltx_td ltx_align_left">45.5%</td>
<td id="S5.T5.4.1.26.6" class="ltx_td ltx_align_left ltx_border_r">39.1%</td>
<td id="S5.T5.4.1.26.7" class="ltx_td ltx_align_left">20.3%</td>
<td id="S5.T5.4.1.26.8" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.26.9" class="ltx_td ltx_align_left">89.1%</td>
<td id="S5.T5.4.1.26.10" class="ltx_td ltx_align_left">91.6%</td>
<td id="S5.T5.4.1.26.11" class="ltx_td ltx_align_left ltx_border_r">92.1%</td>
<td id="S5.T5.4.1.26.12" class="ltx_td ltx_align_left">0.4%</td>
<td id="S5.T5.4.1.26.13" class="ltx_td ltx_align_left">1.6%</td>
<td id="S5.T5.4.1.26.14" class="ltx_td ltx_align_left">1.4%</td>
<td id="S5.T5.4.1.26.15" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.26.15.1" class="ltx_text ltx_font_bold">0.7%</span></td>
<td id="S5.T5.4.1.26.16" class="ltx_td ltx_align_left">99.1%</td>
</tr>
<tr id="S5.T5.4.1.27" class="ltx_tr">
<td id="S5.T5.4.1.27.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.27.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T5.4.1.27.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.27.3" class="ltx_td ltx_align_left">5.7%</td>
<td id="S5.T5.4.1.27.4" class="ltx_td ltx_align_left">20.8%</td>
<td id="S5.T5.4.1.27.5" class="ltx_td ltx_align_left">46.4%</td>
<td id="S5.T5.4.1.27.6" class="ltx_td ltx_align_left ltx_border_r">48.0%</td>
<td id="S5.T5.4.1.27.7" class="ltx_td ltx_align_left">4.1%</td>
<td id="S5.T5.4.1.27.8" class="ltx_td ltx_align_left">64.5%</td>
<td id="S5.T5.4.1.27.9" class="ltx_td ltx_align_left">56.4%</td>
<td id="S5.T5.4.1.27.10" class="ltx_td ltx_align_left">78.3%</td>
<td id="S5.T5.4.1.27.11" class="ltx_td ltx_align_left ltx_border_r">0.0%</td>
<td id="S5.T5.4.1.27.12" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T5.4.1.27.13" class="ltx_td ltx_align_left">0.8%</td>
<td id="S5.T5.4.1.27.14" class="ltx_td ltx_align_left">98.2%</td>
<td id="S5.T5.4.1.27.15" class="ltx_td ltx_align_left">93.5%</td>
<td id="S5.T5.4.1.27.16" class="ltx_td ltx_align_left">97.8%</td>
</tr>
<tr id="S5.T5.4.1.28" class="ltx_tr">
<td id="S5.T5.4.1.28.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T5.4.1.28.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.28.3" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.3.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.28.4" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.4.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.28.5" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.5.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.28.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.28.6.1" class="ltx_text ltx_font_bold">0.2%</span></td>
<td id="S5.T5.4.1.28.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.28.8" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.8.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.28.9" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.9.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.28.10" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.10.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.28.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T5.4.1.28.11.1" class="ltx_text ltx_font_bold">0.0%</span></td>
<td id="S5.T5.4.1.28.12" class="ltx_td ltx_align_left">0.5%</td>
<td id="S5.T5.4.1.28.13" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.13.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T5.4.1.28.14" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.14.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T5.4.1.28.15" class="ltx_td ltx_align_left">0.9%</td>
<td id="S5.T5.4.1.28.16" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.28.16.1" class="ltx_text ltx_font_bold">1.2%</span></td>
</tr>
<tr id="S5.T5.4.1.29" class="ltx_tr">
<td id="S5.T5.4.1.29.1" class="ltx_td ltx_align_left"><span id="S5.T5.4.1.29.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T5.4.1.29.2" class="ltx_td ltx_align_left">0.3%</td>
<td id="S5.T5.4.1.29.3" class="ltx_td ltx_align_left">5.6%</td>
<td id="S5.T5.4.1.29.4" class="ltx_td ltx_align_left">18.2%</td>
<td id="S5.T5.4.1.29.5" class="ltx_td ltx_align_left">42.8%</td>
<td id="S5.T5.4.1.29.6" class="ltx_td ltx_align_left ltx_border_r">42.0%</td>
<td id="S5.T5.4.1.29.7" class="ltx_td ltx_align_left">0.0%</td>
<td id="S5.T5.4.1.29.8" class="ltx_td ltx_align_left">0.2%</td>
<td id="S5.T5.4.1.29.9" class="ltx_td ltx_align_left">60.9%</td>
<td id="S5.T5.4.1.29.10" class="ltx_td ltx_align_left">79.8%</td>
<td id="S5.T5.4.1.29.11" class="ltx_td ltx_align_left ltx_border_r">78.6%</td>
<td id="S5.T5.4.1.29.12" class="ltx_td ltx_align_left">0.6%</td>
<td id="S5.T5.4.1.29.13" class="ltx_td ltx_align_left">3.1%</td>
<td id="S5.T5.4.1.29.14" class="ltx_td ltx_align_left">95.0%</td>
<td id="S5.T5.4.1.29.15" class="ltx_td ltx_align_left">95.4%</td>
<td id="S5.T5.4.1.29.16" class="ltx_td ltx_align_left">98.0%</td>
</tr>
<tr id="S5.T5.4.1.30" class="ltx_tr">
<td id="S5.T5.4.1.30.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T5.4.1.30.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T5.4.1.30.2" class="ltx_td ltx_align_left ltx_border_bb">0.2%</td>
<td id="S5.T5.4.1.30.3" class="ltx_td ltx_align_left ltx_border_bb">4.2%</td>
<td id="S5.T5.4.1.30.4" class="ltx_td ltx_align_left ltx_border_bb">16.0%</td>
<td id="S5.T5.4.1.30.5" class="ltx_td ltx_align_left ltx_border_bb">36.2%</td>
<td id="S5.T5.4.1.30.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">42.3%</td>
<td id="S5.T5.4.1.30.7" class="ltx_td ltx_align_left ltx_border_bb">0.3%</td>
<td id="S5.T5.4.1.30.8" class="ltx_td ltx_align_left ltx_border_bb">0.0%</td>
<td id="S5.T5.4.1.30.9" class="ltx_td ltx_align_left ltx_border_bb">5.5%</td>
<td id="S5.T5.4.1.30.10" class="ltx_td ltx_align_left ltx_border_bb">44.0%</td>
<td id="S5.T5.4.1.30.11" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">56.2%</td>
<td id="S5.T5.4.1.30.12" class="ltx_td ltx_align_left ltx_border_bb">0.4%</td>
<td id="S5.T5.4.1.30.13" class="ltx_td ltx_align_left ltx_border_bb">22.5%</td>
<td id="S5.T5.4.1.30.14" class="ltx_td ltx_align_left ltx_border_bb">64.6%</td>
<td id="S5.T5.4.1.30.15" class="ltx_td ltx_align_left ltx_border_bb">65.4%</td>
<td id="S5.T5.4.1.30.16" class="ltx_td ltx_align_left ltx_border_bb">65.1%</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.3.2" class="ltx_text" style="font-size:90%;">Benchmark of Average ASR-Backdoor Results for Defense Mechanisms in Mitigating Backdoor Attack</span></figcaption>
<div id="S5.T6.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:334.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-133.5pt,102.9pt) scale(0.618841979284247,0.618841979284247) ;">
<table id="S5.T6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T6.4.1.1" class="ltx_tr">
<td id="S5.T6.4.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S5.T6.4.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S5.T6.4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T6.4.1.1.3.1" class="ltx_text ltx_font_bold">CIFAR10</span></td>
<td id="S5.T6.4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T6.4.1.1.4.1" class="ltx_text ltx_font_bold">FASHIONMNIST</span></td>
<td id="S5.T6.4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S5.T6.4.1.1.5.1" class="ltx_text ltx_font_bold">MNIST</span></td>
</tr>
<tr id="S5.T6.4.1.2" class="ltx_tr">
<td id="S5.T6.4.1.2.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T6.4.1.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.2.1" class="ltx_text ltx_font_bold">[PNR (%)]</span></td>
<td id="S5.T6.4.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.3.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T6.4.1.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.4.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T6.4.1.2.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.5.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T6.4.1.2.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.6.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T6.4.1.2.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.7.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T6.4.1.2.8" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.8.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T6.4.1.2.9" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.9.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T6.4.1.2.10" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.10.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T6.4.1.2.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.11.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T6.4.1.2.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.12.1" class="ltx_text ltx_font_bold">90</span></td>
<td id="S5.T6.4.1.2.13" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.13.1" class="ltx_text ltx_font_bold">10</span></td>
<td id="S5.T6.4.1.2.14" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.14.1" class="ltx_text ltx_font_bold">30</span></td>
<td id="S5.T6.4.1.2.15" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.15.1" class="ltx_text ltx_font_bold">50</span></td>
<td id="S5.T6.4.1.2.16" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.16.1" class="ltx_text ltx_font_bold">70</span></td>
<td id="S5.T6.4.1.2.17" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.2.17.1" class="ltx_text ltx_font_bold">90</span></td>
</tr>
<tr id="S5.T6.4.1.3" class="ltx_tr">
<td id="S5.T6.4.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T6.4.1.3.1.1" class="ltx_text ltx_font_bold">CFL</span></td>
<td id="S5.T6.4.1.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.3.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T6.4.1.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.3.3.1" class="ltx_text ltx_font_bold">2.5%</span></td>
<td id="S5.T6.4.1.3.4" class="ltx_td ltx_align_left ltx_border_t">36.3%</td>
<td id="S5.T6.4.1.3.5" class="ltx_td ltx_align_left ltx_border_t">46.5%</td>
<td id="S5.T6.4.1.3.6" class="ltx_td ltx_align_left ltx_border_t">62.7%</td>
<td id="S5.T6.4.1.3.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">69.8%</td>
<td id="S5.T6.4.1.3.8" class="ltx_td ltx_align_left ltx_border_t">12.3%</td>
<td id="S5.T6.4.1.3.9" class="ltx_td ltx_align_left ltx_border_t">67.7%</td>
<td id="S5.T6.4.1.3.10" class="ltx_td ltx_align_left ltx_border_t">65.4%</td>
<td id="S5.T6.4.1.3.11" class="ltx_td ltx_align_left ltx_border_t">74.4%</td>
<td id="S5.T6.4.1.3.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">70.3%</td>
<td id="S5.T6.4.1.3.13" class="ltx_td ltx_align_left ltx_border_t">22.2%</td>
<td id="S5.T6.4.1.3.14" class="ltx_td ltx_align_left ltx_border_t">78.9%</td>
<td id="S5.T6.4.1.3.15" class="ltx_td ltx_align_left ltx_border_t">91.1%</td>
<td id="S5.T6.4.1.3.16" class="ltx_td ltx_align_left ltx_border_t">87.6%</td>
<td id="S5.T6.4.1.3.17" class="ltx_td ltx_align_left ltx_border_t">85.9%</td>
</tr>
<tr id="S5.T6.4.1.4" class="ltx_tr">
<td id="S5.T6.4.1.4.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.4.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T6.4.1.4.2" class="ltx_td ltx_align_left">3.9%</td>
<td id="S5.T6.4.1.4.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.4.3.1" class="ltx_text ltx_font_bold">8.3%</span></td>
<td id="S5.T6.4.1.4.4" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.4.4.1" class="ltx_text ltx_font_bold">6.4%</span></td>
<td id="S5.T6.4.1.4.5" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.4.5.1" class="ltx_text ltx_font_bold">33.2%</span></td>
<td id="S5.T6.4.1.4.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.4.6.1" class="ltx_text ltx_font_bold">49.6%</span></td>
<td id="S5.T6.4.1.4.7" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.4.7.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.4.8" class="ltx_td ltx_align_left">21.4%</td>
<td id="S5.T6.4.1.4.9" class="ltx_td ltx_align_left">29.1%</td>
<td id="S5.T6.4.1.4.10" class="ltx_td ltx_align_left">39.5%</td>
<td id="S5.T6.4.1.4.11" class="ltx_td ltx_align_left ltx_border_r">70.5%</td>
<td id="S5.T6.4.1.4.12" class="ltx_td ltx_align_left">3.2%</td>
<td id="S5.T6.4.1.4.13" class="ltx_td ltx_align_left">53.1%</td>
<td id="S5.T6.4.1.4.14" class="ltx_td ltx_align_left">60.2%</td>
<td id="S5.T6.4.1.4.15" class="ltx_td ltx_align_left">57.9%</td>
<td id="S5.T6.4.1.4.16" class="ltx_td ltx_align_left">63.7%</td>
</tr>
<tr id="S5.T6.4.1.5" class="ltx_tr">
<td id="S5.T6.4.1.5.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.5.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T6.4.1.5.2" class="ltx_td ltx_align_left">2.5%</td>
<td id="S5.T6.4.1.5.3" class="ltx_td ltx_align_left">34.3%</td>
<td id="S5.T6.4.1.5.4" class="ltx_td ltx_align_left">48.8%</td>
<td id="S5.T6.4.1.5.5" class="ltx_td ltx_align_left">51.0%</td>
<td id="S5.T6.4.1.5.6" class="ltx_td ltx_align_left ltx_border_r">68.3%</td>
<td id="S5.T6.4.1.5.7" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.5.7.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.5.8" class="ltx_td ltx_align_left">25.9%</td>
<td id="S5.T6.4.1.5.9" class="ltx_td ltx_align_left">34.6%</td>
<td id="S5.T6.4.1.5.10" class="ltx_td ltx_align_left">46.4%</td>
<td id="S5.T6.4.1.5.11" class="ltx_td ltx_align_left ltx_border_r">73.5%</td>
<td id="S5.T6.4.1.5.12" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.5.12.1" class="ltx_text ltx_font_bold">2.5%</span></td>
<td id="S5.T6.4.1.5.13" class="ltx_td ltx_align_left">59.4%</td>
<td id="S5.T6.4.1.5.14" class="ltx_td ltx_align_left">65.3%</td>
<td id="S5.T6.4.1.5.15" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.5.15.1" class="ltx_text ltx_font_bold">57.6%</span></td>
<td id="S5.T6.4.1.5.16" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.5.16.1" class="ltx_text ltx_font_bold">57.1%</span></td>
</tr>
<tr id="S5.T6.4.1.6" class="ltx_tr">
<td id="S5.T6.4.1.6.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.6.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T6.4.1.6.2" class="ltx_td ltx_align_left">2.7%</td>
<td id="S5.T6.4.1.6.3" class="ltx_td ltx_align_left">33.6%</td>
<td id="S5.T6.4.1.6.4" class="ltx_td ltx_align_left">34.6%</td>
<td id="S5.T6.4.1.6.5" class="ltx_td ltx_align_left">59.6%</td>
<td id="S5.T6.4.1.6.6" class="ltx_td ltx_align_left ltx_border_r">73.2%</td>
<td id="S5.T6.4.1.6.7" class="ltx_td ltx_align_left">1.2%</td>
<td id="S5.T6.4.1.6.8" class="ltx_td ltx_align_left">4.9%</td>
<td id="S5.T6.4.1.6.9" class="ltx_td ltx_align_left">20.8%</td>
<td id="S5.T6.4.1.6.10" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.6.10.1" class="ltx_text ltx_font_bold">14.9%</span></td>
<td id="S5.T6.4.1.6.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.6.11.1" class="ltx_text ltx_font_bold">42.6%</span></td>
<td id="S5.T6.4.1.6.12" class="ltx_td ltx_align_left">5.4%</td>
<td id="S5.T6.4.1.6.13" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.6.13.1" class="ltx_text ltx_font_bold">11.3%</span></td>
<td id="S5.T6.4.1.6.14" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.6.14.1" class="ltx_text ltx_font_bold">24.1%</span></td>
<td id="S5.T6.4.1.6.15" class="ltx_td ltx_align_left">59.0%</td>
<td id="S5.T6.4.1.6.16" class="ltx_td ltx_align_left">97.1%</td>
</tr>
<tr id="S5.T6.4.1.7" class="ltx_tr">
<td id="S5.T6.4.1.7.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.7.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T6.4.1.7.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T6.4.1.7.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T6.4.1.7.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.7.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T6.4.1.8" class="ltx_tr">
<td id="S5.T6.4.1.8.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.8.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T6.4.1.8.2" class="ltx_td ltx_align_left">2.5%</td>
<td id="S5.T6.4.1.8.3" class="ltx_td ltx_align_left">35.3%</td>
<td id="S5.T6.4.1.8.4" class="ltx_td ltx_align_left">39.9%</td>
<td id="S5.T6.4.1.8.5" class="ltx_td ltx_align_left">65.5%</td>
<td id="S5.T6.4.1.8.6" class="ltx_td ltx_align_left ltx_border_r">70.1%</td>
<td id="S5.T6.4.1.8.7" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.8.7.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.8.8" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.8.8.1" class="ltx_text ltx_font_bold">4.7%</span></td>
<td id="S5.T6.4.1.8.9" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.8.9.1" class="ltx_text ltx_font_bold">13.0%</span></td>
<td id="S5.T6.4.1.8.10" class="ltx_td ltx_align_left">23.4%</td>
<td id="S5.T6.4.1.8.11" class="ltx_td ltx_align_left ltx_border_r">66.5%</td>
<td id="S5.T6.4.1.8.12" class="ltx_td ltx_align_left">6.9%</td>
<td id="S5.T6.4.1.8.13" class="ltx_td ltx_align_left">31.1%</td>
<td id="S5.T6.4.1.8.14" class="ltx_td ltx_align_left">36.9%</td>
<td id="S5.T6.4.1.8.15" class="ltx_td ltx_align_left">70.0%</td>
<td id="S5.T6.4.1.8.16" class="ltx_td ltx_align_left">97.0%</td>
</tr>
<tr id="S5.T6.4.1.9" class="ltx_tr">
<td id="S5.T6.4.1.9.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.9.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T6.4.1.9.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.5" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T6.4.1.9.7" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.8" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.9" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.10" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.11" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T6.4.1.9.12" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.13" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.14" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.15" class="ltx_td ltx_align_left">-</td>
<td id="S5.T6.4.1.9.16" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S5.T6.4.1.10" class="ltx_tr">
<td id="S5.T6.4.1.10.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S5.T6.4.1.10.1.1" class="ltx_text ltx_font_bold">DFL-Fully</span></td>
<td id="S5.T6.4.1.10.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.10.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T6.4.1.10.3" class="ltx_td ltx_align_left ltx_border_t">2.6%</td>
<td id="S5.T6.4.1.10.4" class="ltx_td ltx_align_left ltx_border_t">38.3%</td>
<td id="S5.T6.4.1.10.5" class="ltx_td ltx_align_left ltx_border_t">46.7%</td>
<td id="S5.T6.4.1.10.6" class="ltx_td ltx_align_left ltx_border_t">60.2%</td>
<td id="S5.T6.4.1.10.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">71.6%</td>
<td id="S5.T6.4.1.10.8" class="ltx_td ltx_align_left ltx_border_t">12.3%</td>
<td id="S5.T6.4.1.10.9" class="ltx_td ltx_align_left ltx_border_t">65.2%</td>
<td id="S5.T6.4.1.10.10" class="ltx_td ltx_align_left ltx_border_t">62.7%</td>
<td id="S5.T6.4.1.10.11" class="ltx_td ltx_align_left ltx_border_t">70.8%</td>
<td id="S5.T6.4.1.10.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.1%</td>
<td id="S5.T6.4.1.10.13" class="ltx_td ltx_align_left ltx_border_t">22.7%</td>
<td id="S5.T6.4.1.10.14" class="ltx_td ltx_align_left ltx_border_t">77.2%</td>
<td id="S5.T6.4.1.10.15" class="ltx_td ltx_align_left ltx_border_t">87.8%</td>
<td id="S5.T6.4.1.10.16" class="ltx_td ltx_align_left ltx_border_t">93.1%</td>
<td id="S5.T6.4.1.10.17" class="ltx_td ltx_align_left ltx_border_t">83.1%</td>
</tr>
<tr id="S5.T6.4.1.11" class="ltx_tr">
<td id="S5.T6.4.1.11.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.11.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T6.4.1.11.2" class="ltx_td ltx_align_left">3.5%</td>
<td id="S5.T6.4.1.11.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.11.3.1" class="ltx_text ltx_font_bold">18.3%</span></td>
<td id="S5.T6.4.1.11.4" class="ltx_td ltx_align_left">61.2%</td>
<td id="S5.T6.4.1.11.5" class="ltx_td ltx_align_left">60.3%</td>
<td id="S5.T6.4.1.11.6" class="ltx_td ltx_align_left ltx_border_r">91.8%</td>
<td id="S5.T6.4.1.11.7" class="ltx_td ltx_align_left">10.8%</td>
<td id="S5.T6.4.1.11.8" class="ltx_td ltx_align_left">35.9%</td>
<td id="S5.T6.4.1.11.9" class="ltx_td ltx_align_left">74.6%</td>
<td id="S5.T6.4.1.11.10" class="ltx_td ltx_align_left">63.7%</td>
<td id="S5.T6.4.1.11.11" class="ltx_td ltx_align_left ltx_border_r">75.6%</td>
<td id="S5.T6.4.1.11.12" class="ltx_td ltx_align_left">36.1%</td>
<td id="S5.T6.4.1.11.13" class="ltx_td ltx_align_left">77.6%</td>
<td id="S5.T6.4.1.11.14" class="ltx_td ltx_align_left">94.1%</td>
<td id="S5.T6.4.1.11.15" class="ltx_td ltx_align_left">68.8%</td>
<td id="S5.T6.4.1.11.16" class="ltx_td ltx_align_left">96.1%</td>
</tr>
<tr id="S5.T6.4.1.12" class="ltx_tr">
<td id="S5.T6.4.1.12.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.12.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T6.4.1.12.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.12.2.1" class="ltx_text ltx_font_bold">2.3%</span></td>
<td id="S5.T6.4.1.12.3" class="ltx_td ltx_align_left">36.9%</td>
<td id="S5.T6.4.1.12.4" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.12.4.1" class="ltx_text ltx_font_bold">37.0%</span></td>
<td id="S5.T6.4.1.12.5" class="ltx_td ltx_align_left">58.5%</td>
<td id="S5.T6.4.1.12.6" class="ltx_td ltx_align_left ltx_border_r">61.5%</td>
<td id="S5.T6.4.1.12.7" class="ltx_td ltx_align_left">9.9%</td>
<td id="S5.T6.4.1.12.8" class="ltx_td ltx_align_left">32.9%</td>
<td id="S5.T6.4.1.12.9" class="ltx_td ltx_align_left">78.2%</td>
<td id="S5.T6.4.1.12.10" class="ltx_td ltx_align_left">60.5%</td>
<td id="S5.T6.4.1.12.11" class="ltx_td ltx_align_left ltx_border_r">78.1%</td>
<td id="S5.T6.4.1.12.12" class="ltx_td ltx_align_left">37.5%</td>
<td id="S5.T6.4.1.12.13" class="ltx_td ltx_align_left">78.5%</td>
<td id="S5.T6.4.1.12.14" class="ltx_td ltx_align_left">93.3%</td>
<td id="S5.T6.4.1.12.15" class="ltx_td ltx_align_left">65.4%</td>
<td id="S5.T6.4.1.12.16" class="ltx_td ltx_align_left">99.6%</td>
</tr>
<tr id="S5.T6.4.1.13" class="ltx_tr">
<td id="S5.T6.4.1.13.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.13.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T6.4.1.13.2" class="ltx_td ltx_align_left">2.6%</td>
<td id="S5.T6.4.1.13.3" class="ltx_td ltx_align_left">31.3%</td>
<td id="S5.T6.4.1.13.4" class="ltx_td ltx_align_left">45.2%</td>
<td id="S5.T6.4.1.13.5" class="ltx_td ltx_align_left">60.5%</td>
<td id="S5.T6.4.1.13.6" class="ltx_td ltx_align_left ltx_border_r">71.0%</td>
<td id="S5.T6.4.1.13.7" class="ltx_td ltx_align_left">3.1%</td>
<td id="S5.T6.4.1.13.8" class="ltx_td ltx_align_left">61.0%</td>
<td id="S5.T6.4.1.13.9" class="ltx_td ltx_align_left">74.4%</td>
<td id="S5.T6.4.1.13.10" class="ltx_td ltx_align_left">89.1%</td>
<td id="S5.T6.4.1.13.11" class="ltx_td ltx_align_left ltx_border_r">84.5%</td>
<td id="S5.T6.4.1.13.12" class="ltx_td ltx_align_left">12.0%</td>
<td id="S5.T6.4.1.13.13" class="ltx_td ltx_align_left">70.5%</td>
<td id="S5.T6.4.1.13.14" class="ltx_td ltx_align_left">97.8%</td>
<td id="S5.T6.4.1.13.15" class="ltx_td ltx_align_left">96.8%</td>
<td id="S5.T6.4.1.13.16" class="ltx_td ltx_align_left">98.5%</td>
</tr>
<tr id="S5.T6.4.1.14" class="ltx_tr">
<td id="S5.T6.4.1.14.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.1.1" class="ltx_text ltx_font_bold">Connected</span></td>
<td id="S5.T6.4.1.14.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.2.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T6.4.1.14.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.3.1" class="ltx_text ltx_font_bold">2.3%</span></td>
<td id="S5.T6.4.1.14.4" class="ltx_td ltx_align_left">38.5%</td>
<td id="S5.T6.4.1.14.5" class="ltx_td ltx_align_left">36.8%</td>
<td id="S5.T6.4.1.14.6" class="ltx_td ltx_align_left">53.5%</td>
<td id="S5.T6.4.1.14.7" class="ltx_td ltx_align_left ltx_border_r">67.5%</td>
<td id="S5.T6.4.1.14.8" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.8.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.14.9" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.9.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.14.10" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.10.1" class="ltx_text ltx_font_bold">1.2%</span></td>
<td id="S5.T6.4.1.14.11" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.11.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.14.12" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.14.12.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.14.13" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.13.1" class="ltx_text ltx_font_bold">3.2%</span></td>
<td id="S5.T6.4.1.14.14" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.14.1" class="ltx_text ltx_font_bold">5.4%</span></td>
<td id="S5.T6.4.1.14.15" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.15.1" class="ltx_text ltx_font_bold">2.5%</span></td>
<td id="S5.T6.4.1.14.16" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.16.1" class="ltx_text ltx_font_bold">3.2%</span></td>
<td id="S5.T6.4.1.14.17" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.14.17.1" class="ltx_text ltx_font_bold">6.9%</span></td>
</tr>
<tr id="S5.T6.4.1.15" class="ltx_tr">
<td id="S5.T6.4.1.15.1" class="ltx_td"></td>
<td id="S5.T6.4.1.15.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.15.2.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T6.4.1.15.3" class="ltx_td ltx_align_left">2.6%</td>
<td id="S5.T6.4.1.15.4" class="ltx_td ltx_align_left">36.9%</td>
<td id="S5.T6.4.1.15.5" class="ltx_td ltx_align_left">44.5%</td>
<td id="S5.T6.4.1.15.6" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.15.6.1" class="ltx_text ltx_font_bold">48.4%</span></td>
<td id="S5.T6.4.1.15.7" class="ltx_td ltx_align_left ltx_border_r">65.5%</td>
<td id="S5.T6.4.1.15.8" class="ltx_td ltx_align_left">17.1%</td>
<td id="S5.T6.4.1.15.9" class="ltx_td ltx_align_left">53.4%</td>
<td id="S5.T6.4.1.15.10" class="ltx_td ltx_align_left">72.5%</td>
<td id="S5.T6.4.1.15.11" class="ltx_td ltx_align_left">85.3%</td>
<td id="S5.T6.4.1.15.12" class="ltx_td ltx_align_left ltx_border_r">74.6%</td>
<td id="S5.T6.4.1.15.13" class="ltx_td ltx_align_left">39.8%</td>
<td id="S5.T6.4.1.15.14" class="ltx_td ltx_align_left">92.5%</td>
<td id="S5.T6.4.1.15.15" class="ltx_td ltx_align_left">98.8%</td>
<td id="S5.T6.4.1.15.16" class="ltx_td ltx_align_left">97.9%</td>
<td id="S5.T6.4.1.15.17" class="ltx_td ltx_align_left">99.0%</td>
</tr>
<tr id="S5.T6.4.1.16" class="ltx_tr">
<td id="S5.T6.4.1.16.1" class="ltx_td"></td>
<td id="S5.T6.4.1.16.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.16.2.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T6.4.1.16.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.16.3.1" class="ltx_text ltx_font_bold">2.3%</span></td>
<td id="S5.T6.4.1.16.4" class="ltx_td ltx_align_left">32.8%</td>
<td id="S5.T6.4.1.16.5" class="ltx_td ltx_align_left">40.9%</td>
<td id="S5.T6.4.1.16.6" class="ltx_td ltx_align_left">52.1%</td>
<td id="S5.T6.4.1.16.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.16.7.1" class="ltx_text ltx_font_bold">62.4%</span></td>
<td id="S5.T6.4.1.16.8" class="ltx_td ltx_align_left">10.7%</td>
<td id="S5.T6.4.1.16.9" class="ltx_td ltx_align_left">57.2%</td>
<td id="S5.T6.4.1.16.10" class="ltx_td ltx_align_left">54.6%</td>
<td id="S5.T6.4.1.16.11" class="ltx_td ltx_align_left">62.2%</td>
<td id="S5.T6.4.1.16.12" class="ltx_td ltx_align_left ltx_border_r">62.7%</td>
<td id="S5.T6.4.1.16.13" class="ltx_td ltx_align_left">19.2%</td>
<td id="S5.T6.4.1.16.14" class="ltx_td ltx_align_left">68.1%</td>
<td id="S5.T6.4.1.16.15" class="ltx_td ltx_align_left">78.8%</td>
<td id="S5.T6.4.1.16.16" class="ltx_td ltx_align_left">80.7%</td>
<td id="S5.T6.4.1.16.17" class="ltx_td ltx_align_left">70.3%</td>
</tr>
<tr id="S5.T6.4.1.17" class="ltx_tr">
<td id="S5.T6.4.1.17.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T6.4.1.17.1.1" class="ltx_text ltx_font_bold">DFL-Ring</span></td>
<td id="S5.T6.4.1.17.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.17.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T6.4.1.17.3" class="ltx_td ltx_align_left ltx_border_t">2.9%</td>
<td id="S5.T6.4.1.17.4" class="ltx_td ltx_align_left ltx_border_t">42.4%</td>
<td id="S5.T6.4.1.17.5" class="ltx_td ltx_align_left ltx_border_t">51.1%</td>
<td id="S5.T6.4.1.17.6" class="ltx_td ltx_align_left ltx_border_t">65.6%</td>
<td id="S5.T6.4.1.17.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">78.5%</td>
<td id="S5.T6.4.1.17.8" class="ltx_td ltx_align_left ltx_border_t">12.5%</td>
<td id="S5.T6.4.1.17.9" class="ltx_td ltx_align_left ltx_border_t">73.1%</td>
<td id="S5.T6.4.1.17.10" class="ltx_td ltx_align_left ltx_border_t">70.1%</td>
<td id="S5.T6.4.1.17.11" class="ltx_td ltx_align_left ltx_border_t">83.6%</td>
<td id="S5.T6.4.1.17.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80.2%</td>
<td id="S5.T6.4.1.17.13" class="ltx_td ltx_align_left ltx_border_t">24.5%</td>
<td id="S5.T6.4.1.17.14" class="ltx_td ltx_align_left ltx_border_t">88.2%</td>
<td id="S5.T6.4.1.17.15" class="ltx_td ltx_align_left ltx_border_t">95.8%</td>
<td id="S5.T6.4.1.17.16" class="ltx_td ltx_align_left ltx_border_t">94.6%</td>
<td id="S5.T6.4.1.17.17" class="ltx_td ltx_align_left ltx_border_t">97.5%</td>
</tr>
<tr id="S5.T6.4.1.18" class="ltx_tr">
<td id="S5.T6.4.1.18.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.18.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T6.4.1.18.2" class="ltx_td ltx_align_left">3.0%</td>
<td id="S5.T6.4.1.18.3" class="ltx_td ltx_align_left">32.3%</td>
<td id="S5.T6.4.1.18.4" class="ltx_td ltx_align_left">64.5%</td>
<td id="S5.T6.4.1.18.5" class="ltx_td ltx_align_left">80.8%</td>
<td id="S5.T6.4.1.18.6" class="ltx_td ltx_align_left ltx_border_r">85.9%</td>
<td id="S5.T6.4.1.18.7" class="ltx_td ltx_align_left">3.0%</td>
<td id="S5.T6.4.1.18.8" class="ltx_td ltx_align_left">28.2%</td>
<td id="S5.T6.4.1.18.9" class="ltx_td ltx_align_left">64.0%</td>
<td id="S5.T6.4.1.18.10" class="ltx_td ltx_align_left">84.9%</td>
<td id="S5.T6.4.1.18.11" class="ltx_td ltx_align_left ltx_border_r">80.7%</td>
<td id="S5.T6.4.1.18.12" class="ltx_td ltx_align_left">11.7%</td>
<td id="S5.T6.4.1.18.13" class="ltx_td ltx_align_left">93.0%</td>
<td id="S5.T6.4.1.18.14" class="ltx_td ltx_align_left">92.3%</td>
<td id="S5.T6.4.1.18.15" class="ltx_td ltx_align_left">96.4%</td>
<td id="S5.T6.4.1.18.16" class="ltx_td ltx_align_left">90.3%</td>
</tr>
<tr id="S5.T6.4.1.19" class="ltx_tr">
<td id="S5.T6.4.1.19.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.19.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T6.4.1.19.2" class="ltx_td ltx_align_left">3.0%</td>
<td id="S5.T6.4.1.19.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.19.3.1" class="ltx_text ltx_font_bold">31.1%</span></td>
<td id="S5.T6.4.1.19.4" class="ltx_td ltx_align_left">62.0%</td>
<td id="S5.T6.4.1.19.5" class="ltx_td ltx_align_left">53.6%</td>
<td id="S5.T6.4.1.19.6" class="ltx_td ltx_align_left ltx_border_r">69.1%</td>
<td id="S5.T6.4.1.19.7" class="ltx_td ltx_align_left">1.4%</td>
<td id="S5.T6.4.1.19.8" class="ltx_td ltx_align_left">23.5%</td>
<td id="S5.T6.4.1.19.9" class="ltx_td ltx_align_left">65.7%</td>
<td id="S5.T6.4.1.19.10" class="ltx_td ltx_align_left">90.6%</td>
<td id="S5.T6.4.1.19.11" class="ltx_td ltx_align_left ltx_border_r">83.6%</td>
<td id="S5.T6.4.1.19.12" class="ltx_td ltx_align_left">5.6%</td>
<td id="S5.T6.4.1.19.13" class="ltx_td ltx_align_left">98.6%</td>
<td id="S5.T6.4.1.19.14" class="ltx_td ltx_align_left">97.7%</td>
<td id="S5.T6.4.1.19.15" class="ltx_td ltx_align_left">99.3%</td>
<td id="S5.T6.4.1.19.16" class="ltx_td ltx_align_left">90.8%</td>
</tr>
<tr id="S5.T6.4.1.20" class="ltx_tr">
<td id="S5.T6.4.1.20.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.20.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T6.4.1.20.2" class="ltx_td ltx_align_left">2.7%</td>
<td id="S5.T6.4.1.20.3" class="ltx_td ltx_align_left">38.9%</td>
<td id="S5.T6.4.1.20.4" class="ltx_td ltx_align_left">42.7%</td>
<td id="S5.T6.4.1.20.5" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.20.5.1" class="ltx_text ltx_font_bold">44.1%</span></td>
<td id="S5.T6.4.1.20.6" class="ltx_td ltx_align_left ltx_border_r">70.3%</td>
<td id="S5.T6.4.1.20.7" class="ltx_td ltx_align_left">6.3%</td>
<td id="S5.T6.4.1.20.8" class="ltx_td ltx_align_left">54.1%</td>
<td id="S5.T6.4.1.20.9" class="ltx_td ltx_align_left">72.2%</td>
<td id="S5.T6.4.1.20.10" class="ltx_td ltx_align_left">86.6%</td>
<td id="S5.T6.4.1.20.11" class="ltx_td ltx_align_left ltx_border_r">86.7%</td>
<td id="S5.T6.4.1.20.12" class="ltx_td ltx_align_left">18.8%</td>
<td id="S5.T6.4.1.20.13" class="ltx_td ltx_align_left">67.0%</td>
<td id="S5.T6.4.1.20.14" class="ltx_td ltx_align_left">78.5%</td>
<td id="S5.T6.4.1.20.15" class="ltx_td ltx_align_left">98.7%</td>
<td id="S5.T6.4.1.20.16" class="ltx_td ltx_align_left">99.1%</td>
</tr>
<tr id="S5.T6.4.1.21" class="ltx_tr">
<td id="S5.T6.4.1.21.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T6.4.1.21.2" class="ltx_td ltx_align_left">2.5%</td>
<td id="S5.T6.4.1.21.3" class="ltx_td ltx_align_left">34.5%</td>
<td id="S5.T6.4.1.21.4" class="ltx_td ltx_align_left">50.9%</td>
<td id="S5.T6.4.1.21.5" class="ltx_td ltx_align_left">76.3%</td>
<td id="S5.T6.4.1.21.6" class="ltx_td ltx_align_left ltx_border_r">81.3%</td>
<td id="S5.T6.4.1.21.7" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.7.1" class="ltx_text ltx_font_bold">1.2%</span></td>
<td id="S5.T6.4.1.21.8" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.8.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.21.9" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.9.1" class="ltx_text ltx_font_bold">1.2%</span></td>
<td id="S5.T6.4.1.21.10" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.10.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.21.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.21.11.1" class="ltx_text ltx_font_bold">1.0%</span></td>
<td id="S5.T6.4.1.21.12" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.12.1" class="ltx_text ltx_font_bold">2.5%</span></td>
<td id="S5.T6.4.1.21.13" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.13.1" class="ltx_text ltx_font_bold">7.5%</span></td>
<td id="S5.T6.4.1.21.14" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.14.1" class="ltx_text ltx_font_bold">5.3%</span></td>
<td id="S5.T6.4.1.21.15" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.15.1" class="ltx_text ltx_font_bold">11.5%</span></td>
<td id="S5.T6.4.1.21.16" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.21.16.1" class="ltx_text ltx_font_bold">5.8%</span></td>
</tr>
<tr id="S5.T6.4.1.22" class="ltx_tr">
<td id="S5.T6.4.1.22.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.22.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T6.4.1.22.2" class="ltx_td ltx_align_left">2.8%</td>
<td id="S5.T6.4.1.22.3" class="ltx_td ltx_align_left">41.4%</td>
<td id="S5.T6.4.1.22.4" class="ltx_td ltx_align_left">53.9%</td>
<td id="S5.T6.4.1.22.5" class="ltx_td ltx_align_left">52.5%</td>
<td id="S5.T6.4.1.22.6" class="ltx_td ltx_align_left ltx_border_r">61.8%</td>
<td id="S5.T6.4.1.22.7" class="ltx_td ltx_align_left">9.6%</td>
<td id="S5.T6.4.1.22.8" class="ltx_td ltx_align_left">50.6%</td>
<td id="S5.T6.4.1.22.9" class="ltx_td ltx_align_left">60.9%</td>
<td id="S5.T6.4.1.22.10" class="ltx_td ltx_align_left">79.1%</td>
<td id="S5.T6.4.1.22.11" class="ltx_td ltx_align_left ltx_border_r">81.9%</td>
<td id="S5.T6.4.1.22.12" class="ltx_td ltx_align_left">38.7%</td>
<td id="S5.T6.4.1.22.13" class="ltx_td ltx_align_left">89.5%</td>
<td id="S5.T6.4.1.22.14" class="ltx_td ltx_align_left">98.0%</td>
<td id="S5.T6.4.1.22.15" class="ltx_td ltx_align_left">99.7%</td>
<td id="S5.T6.4.1.22.16" class="ltx_td ltx_align_left">98.5%</td>
</tr>
<tr id="S5.T6.4.1.23" class="ltx_tr">
<td id="S5.T6.4.1.23.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.23.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T6.4.1.23.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.23.2.1" class="ltx_text ltx_font_bold">2.2%</span></td>
<td id="S5.T6.4.1.23.3" class="ltx_td ltx_align_left">32.5%</td>
<td id="S5.T6.4.1.23.4" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.23.4.1" class="ltx_text ltx_font_bold">40.9%</span></td>
<td id="S5.T6.4.1.23.5" class="ltx_td ltx_align_left">52.2%</td>
<td id="S5.T6.4.1.23.6" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.23.6.1" class="ltx_text ltx_font_bold">61.1%</span></td>
<td id="S5.T6.4.1.23.7" class="ltx_td ltx_align_left">11.2%</td>
<td id="S5.T6.4.1.23.8" class="ltx_td ltx_align_left">58.6%</td>
<td id="S5.T6.4.1.23.9" class="ltx_td ltx_align_left">54.5%</td>
<td id="S5.T6.4.1.23.10" class="ltx_td ltx_align_left">61.4%</td>
<td id="S5.T6.4.1.23.11" class="ltx_td ltx_align_left ltx_border_r">63.1%</td>
<td id="S5.T6.4.1.23.12" class="ltx_td ltx_align_left">19.6%</td>
<td id="S5.T6.4.1.23.13" class="ltx_td ltx_align_left">65.9%</td>
<td id="S5.T6.4.1.23.14" class="ltx_td ltx_align_left">76.4%</td>
<td id="S5.T6.4.1.23.15" class="ltx_td ltx_align_left">80.9%</td>
<td id="S5.T6.4.1.23.16" class="ltx_td ltx_align_left">72.1%</td>
</tr>
<tr id="S5.T6.4.1.24" class="ltx_tr">
<td id="S5.T6.4.1.24.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="7"><span id="S5.T6.4.1.24.1.1" class="ltx_text ltx_font_bold">DFL-Star</span></td>
<td id="S5.T6.4.1.24.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T6.4.1.24.2.1" class="ltx_text ltx_font_italic">FedAvg</span></td>
<td id="S5.T6.4.1.24.3" class="ltx_td ltx_align_left ltx_border_t">2.8%</td>
<td id="S5.T6.4.1.24.4" class="ltx_td ltx_align_left ltx_border_t">41.8%</td>
<td id="S5.T6.4.1.24.5" class="ltx_td ltx_align_left ltx_border_t">52.6%</td>
<td id="S5.T6.4.1.24.6" class="ltx_td ltx_align_left ltx_border_t">68.3%</td>
<td id="S5.T6.4.1.24.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">78.5%</td>
<td id="S5.T6.4.1.24.8" class="ltx_td ltx_align_left ltx_border_t">13.2%</td>
<td id="S5.T6.4.1.24.9" class="ltx_td ltx_align_left ltx_border_t">73.1%</td>
<td id="S5.T6.4.1.24.10" class="ltx_td ltx_align_left ltx_border_t">70.1%</td>
<td id="S5.T6.4.1.24.11" class="ltx_td ltx_align_left ltx_border_t">83.6%</td>
<td id="S5.T6.4.1.24.12" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">79.1%</td>
<td id="S5.T6.4.1.24.13" class="ltx_td ltx_align_left ltx_border_t">25.2%</td>
<td id="S5.T6.4.1.24.14" class="ltx_td ltx_align_left ltx_border_t">86.7%</td>
<td id="S5.T6.4.1.24.15" class="ltx_td ltx_align_left ltx_border_t">95.0%</td>
<td id="S5.T6.4.1.24.16" class="ltx_td ltx_align_left ltx_border_t">95.0%</td>
<td id="S5.T6.4.1.24.17" class="ltx_td ltx_align_left ltx_border_t">92.6%</td>
</tr>
<tr id="S5.T6.4.1.25" class="ltx_tr">
<td id="S5.T6.4.1.25.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.25.1.1" class="ltx_text ltx_font_italic">FLTrust</span></td>
<td id="S5.T6.4.1.25.2" class="ltx_td ltx_align_left">4.7%</td>
<td id="S5.T6.4.1.25.3" class="ltx_td ltx_align_left">44.6%</td>
<td id="S5.T6.4.1.25.4" class="ltx_td ltx_align_left">61.9%</td>
<td id="S5.T6.4.1.25.5" class="ltx_td ltx_align_left">72.9%</td>
<td id="S5.T6.4.1.25.6" class="ltx_td ltx_align_left ltx_border_r">87.5%</td>
<td id="S5.T6.4.1.25.7" class="ltx_td ltx_align_left">1.7%</td>
<td id="S5.T6.4.1.25.8" class="ltx_td ltx_align_left">55.8%</td>
<td id="S5.T6.4.1.25.9" class="ltx_td ltx_align_left">70.4%</td>
<td id="S5.T6.4.1.25.10" class="ltx_td ltx_align_left">72.5%</td>
<td id="S5.T6.4.1.25.11" class="ltx_td ltx_align_left ltx_border_r">78.7%</td>
<td id="S5.T6.4.1.25.12" class="ltx_td ltx_align_left">7.5%</td>
<td id="S5.T6.4.1.25.13" class="ltx_td ltx_align_left">76.0%</td>
<td id="S5.T6.4.1.25.14" class="ltx_td ltx_align_left">91.1%</td>
<td id="S5.T6.4.1.25.15" class="ltx_td ltx_align_left">96.0%</td>
<td id="S5.T6.4.1.25.16" class="ltx_td ltx_align_left">84.6%</td>
</tr>
<tr id="S5.T6.4.1.26" class="ltx_tr">
<td id="S5.T6.4.1.26.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.26.1.1" class="ltx_text ltx_font_italic">Krum</span></td>
<td id="S5.T6.4.1.26.2" class="ltx_td ltx_align_left">2.6%</td>
<td id="S5.T6.4.1.26.3" class="ltx_td ltx_align_left">35.4%</td>
<td id="S5.T6.4.1.26.4" class="ltx_td ltx_align_left">42.3%</td>
<td id="S5.T6.4.1.26.5" class="ltx_td ltx_align_left">56.2%</td>
<td id="S5.T6.4.1.26.6" class="ltx_td ltx_align_left ltx_border_r">80.8%</td>
<td id="S5.T6.4.1.26.7" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.26.7.1" class="ltx_text ltx_font_bold">0.9%</span></td>
<td id="S5.T6.4.1.26.8" class="ltx_td ltx_align_left">59.4%</td>
<td id="S5.T6.4.1.26.9" class="ltx_td ltx_align_left">70.8%</td>
<td id="S5.T6.4.1.26.10" class="ltx_td ltx_align_left">73.6%</td>
<td id="S5.T6.4.1.26.11" class="ltx_td ltx_align_left ltx_border_r">81.3%</td>
<td id="S5.T6.4.1.26.12" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.26.12.1" class="ltx_text ltx_font_bold">2.4%</span></td>
<td id="S5.T6.4.1.26.13" class="ltx_td ltx_align_left">72.8%</td>
<td id="S5.T6.4.1.26.14" class="ltx_td ltx_align_left">92.1%</td>
<td id="S5.T6.4.1.26.15" class="ltx_td ltx_align_left">97.4%</td>
<td id="S5.T6.4.1.26.16" class="ltx_td ltx_align_left">88.0%</td>
</tr>
<tr id="S5.T6.4.1.27" class="ltx_tr">
<td id="S5.T6.4.1.27.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.27.1.1" class="ltx_text ltx_font_italic">Median</span></td>
<td id="S5.T6.4.1.27.2" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.27.2.1" class="ltx_text ltx_font_bold">2.1%</span></td>
<td id="S5.T6.4.1.27.3" class="ltx_td ltx_align_left">40.2%</td>
<td id="S5.T6.4.1.27.4" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.27.4.1" class="ltx_text ltx_font_bold">38.6%</span></td>
<td id="S5.T6.4.1.27.5" class="ltx_td ltx_align_left">61.8%</td>
<td id="S5.T6.4.1.27.6" class="ltx_td ltx_align_left ltx_border_r">66.1%</td>
<td id="S5.T6.4.1.27.7" class="ltx_td ltx_align_left">2.8%</td>
<td id="S5.T6.4.1.27.8" class="ltx_td ltx_align_left">58.1%</td>
<td id="S5.T6.4.1.27.9" class="ltx_td ltx_align_left">73.0%</td>
<td id="S5.T6.4.1.27.10" class="ltx_td ltx_align_left">85.8%</td>
<td id="S5.T6.4.1.27.11" class="ltx_td ltx_align_left ltx_border_r">68.0%</td>
<td id="S5.T6.4.1.27.12" class="ltx_td ltx_align_left">41.9%</td>
<td id="S5.T6.4.1.27.13" class="ltx_td ltx_align_left">88.2%</td>
<td id="S5.T6.4.1.27.14" class="ltx_td ltx_align_left">97.7%</td>
<td id="S5.T6.4.1.27.15" class="ltx_td ltx_align_left">98.5%</td>
<td id="S5.T6.4.1.27.16" class="ltx_td ltx_align_left">97.6%</td>
</tr>
<tr id="S5.T6.4.1.28" class="ltx_tr">
<td id="S5.T6.4.1.28.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.1.1" class="ltx_text ltx_font_italic">Sentinel</span></td>
<td id="S5.T6.4.1.28.2" class="ltx_td ltx_align_left">2.9%</td>
<td id="S5.T6.4.1.28.3" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.3.1" class="ltx_text ltx_font_bold">31.7%</span></td>
<td id="S5.T6.4.1.28.4" class="ltx_td ltx_align_left">44.9%</td>
<td id="S5.T6.4.1.28.5" class="ltx_td ltx_align_left">56.4%</td>
<td id="S5.T6.4.1.28.6" class="ltx_td ltx_align_left ltx_border_r">76.9%</td>
<td id="S5.T6.4.1.28.7" class="ltx_td ltx_align_left">2.7%</td>
<td id="S5.T6.4.1.28.8" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.8.1" class="ltx_text ltx_font_bold">4.9%</span></td>
<td id="S5.T6.4.1.28.9" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.9.1" class="ltx_text ltx_font_bold">5.4%</span></td>
<td id="S5.T6.4.1.28.10" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.10.1" class="ltx_text ltx_font_bold">6.4%</span></td>
<td id="S5.T6.4.1.28.11" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T6.4.1.28.11.1" class="ltx_text ltx_font_bold">7.1%</span></td>
<td id="S5.T6.4.1.28.12" class="ltx_td ltx_align_left">13.0%</td>
<td id="S5.T6.4.1.28.13" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.13.1" class="ltx_text ltx_font_bold">6.0%</span></td>
<td id="S5.T6.4.1.28.14" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.14.1" class="ltx_text ltx_font_bold">11.7%</span></td>
<td id="S5.T6.4.1.28.15" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.15.1" class="ltx_text ltx_font_bold">13.0%</span></td>
<td id="S5.T6.4.1.28.16" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.28.16.1" class="ltx_text ltx_font_bold">5.9%</span></td>
</tr>
<tr id="S5.T6.4.1.29" class="ltx_tr">
<td id="S5.T6.4.1.29.1" class="ltx_td ltx_align_left"><span id="S5.T6.4.1.29.1.1" class="ltx_text ltx_font_italic">TrimmedMean</span></td>
<td id="S5.T6.4.1.29.2" class="ltx_td ltx_align_left">2.2%</td>
<td id="S5.T6.4.1.29.3" class="ltx_td ltx_align_left">46.1%</td>
<td id="S5.T6.4.1.29.4" class="ltx_td ltx_align_left">56.2%</td>
<td id="S5.T6.4.1.29.5" class="ltx_td ltx_align_left">52.6%</td>
<td id="S5.T6.4.1.29.6" class="ltx_td ltx_align_left ltx_border_r">76.8%</td>
<td id="S5.T6.4.1.29.7" class="ltx_td ltx_align_left">5.3%</td>
<td id="S5.T6.4.1.29.8" class="ltx_td ltx_align_left">59.3%</td>
<td id="S5.T6.4.1.29.9" class="ltx_td ltx_align_left">74.0%</td>
<td id="S5.T6.4.1.29.10" class="ltx_td ltx_align_left">80.0%</td>
<td id="S5.T6.4.1.29.11" class="ltx_td ltx_align_left ltx_border_r">80.0%</td>
<td id="S5.T6.4.1.29.12" class="ltx_td ltx_align_left">28.9%</td>
<td id="S5.T6.4.1.29.13" class="ltx_td ltx_align_left">94.6%</td>
<td id="S5.T6.4.1.29.14" class="ltx_td ltx_align_left">99.1%</td>
<td id="S5.T6.4.1.29.15" class="ltx_td ltx_align_left">98.7%</td>
<td id="S5.T6.4.1.29.16" class="ltx_td ltx_align_left">98.6%</td>
</tr>
<tr id="S5.T6.4.1.30" class="ltx_tr">
<td id="S5.T6.4.1.30.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T6.4.1.30.1.1" class="ltx_text ltx_font_italic">Voyager</span></td>
<td id="S5.T6.4.1.30.2" class="ltx_td ltx_align_left ltx_border_bb">2.3%</td>
<td id="S5.T6.4.1.30.3" class="ltx_td ltx_align_left ltx_border_bb">33.0%</td>
<td id="S5.T6.4.1.30.4" class="ltx_td ltx_align_left ltx_border_bb">40.1%</td>
<td id="S5.T6.4.1.30.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T6.4.1.30.5.1" class="ltx_text ltx_font_bold">51.8%</span></td>
<td id="S5.T6.4.1.30.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S5.T6.4.1.30.6.1" class="ltx_text ltx_font_bold">61.0%</span></td>
<td id="S5.T6.4.1.30.7" class="ltx_td ltx_align_left ltx_border_bb">10.5%</td>
<td id="S5.T6.4.1.30.8" class="ltx_td ltx_align_left ltx_border_bb">57.6%</td>
<td id="S5.T6.4.1.30.9" class="ltx_td ltx_align_left ltx_border_bb">54.7%</td>
<td id="S5.T6.4.1.30.10" class="ltx_td ltx_align_left ltx_border_bb">61.6%</td>
<td id="S5.T6.4.1.30.11" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">62.6%</td>
<td id="S5.T6.4.1.30.12" class="ltx_td ltx_align_left ltx_border_bb">19.6%</td>
<td id="S5.T6.4.1.30.13" class="ltx_td ltx_align_left ltx_border_bb">68.2%</td>
<td id="S5.T6.4.1.30.14" class="ltx_td ltx_align_left ltx_border_bb">77.9%</td>
<td id="S5.T6.4.1.30.15" class="ltx_td ltx_align_left ltx_border_bb">79.8%</td>
<td id="S5.T6.4.1.30.16" class="ltx_td ltx_align_left ltx_border_bb">72.6%</td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Benchmark of Defense Mechanisms for Untargeted Poisoning Attacks</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">This section conducts extensive experiments to assess the effectiveness of defense mechanisms against poisoning attacks. It specifically looks at how well these mechanisms, initially designed for CFL, can adapt to DFL. The experiments benchmark these defense mechanisms across diverse datasets against various attack strategies.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">This benchmark includes a variety of defense mechanisms, including:</p>
<ul id="S5.I4" class="ltx_itemize">
<li id="S5.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i1.p1" class="ltx_para">
<p id="S5.I4.i1.p1.1" class="ltx_p"><span id="S5.I4.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FedAvg</span>: Averaging over the received models, designed for CFL, without providing additional protection.</p>
</div>
</li>
<li id="S5.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i2.p1" class="ltx_para">
<p id="S5.I4.i2.p1.1" class="ltx_p"><span id="S5.I4.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">FLTrust</span>: Filtering anomalous models using ReLU-clipped cosine similarity, designed for CFL.</p>
</div>
</li>
<li id="S5.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i3.p1" class="ltx_para">
<p id="S5.I4.i3.p1.1" class="ltx_p"><span id="S5.I4.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Krum</span>: Finding the model with the shortest distance to all other models as the aggregated model, designed for CFL.</p>
</div>
</li>
<li id="S5.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i4.p1" class="ltx_para">
<p id="S5.I4.i4.p1.1" class="ltx_p"><span id="S5.I4.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Median</span>: Finding the median model of all models as the aggregated model, designed for CFL.</p>
</div>
</li>
<li id="S5.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i5.p1" class="ltx_para">
<p id="S5.I4.i5.p1.1" class="ltx_p"><span id="S5.I4.i5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Sentinel</span>: Combining similarity and loss-based methods to filter and regularize models, designed for DFL.</p>
</div>
</li>
<li id="S5.I4.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i6.p1" class="ltx_para">
<p id="S5.I4.i6.p1.1" class="ltx_p"><span id="S5.I4.i6.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">TrimmedMean</span>: Filtering the extreme values in the received models and then averaging them to get the aggregated model, designed for CFL.</p>
</div>
</li>
<li id="S5.I4.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I4.i7.p1" class="ltx_para">
<p id="S5.I4.i7.p1.1" class="ltx_p"><span id="S5.I4.i7.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Voyager</span>: An MTD-based defense that isolates malicious nodes by means of dynamic topology, designed for DFL.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para">
<p id="S5.SS2.SSS3.p3.1" class="ltx_p">The first experiment seeks to evaluate the effectiveness of these defense mechanisms in mitigating Untargeted Label Flipping, Untargeted Sample Poisoning, and Random Model Poisoning attacks. The effectiveness of the defense mechanisms is assessed using the F1-Score, with higher values indicating better protection against adversarial attacks.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p id="S5.SS2.SSS3.p4.1" class="ltx_p">For those defense mechanisms originally designed for CFL, such as <span id="S5.SS2.SSS3.p4.1.1" class="ltx_text ltx_font_italic">FedAvg</span>, <span id="S5.SS2.SSS3.p4.1.2" class="ltx_text ltx_font_italic">FLTrust</span>, <span id="S5.SS2.SSS3.p4.1.3" class="ltx_text ltx_font_italic">Krum</span>, <span id="S5.SS2.SSS3.p4.1.4" class="ltx_text ltx_font_italic">Median</span>, and <span id="S5.SS2.SSS3.p4.1.5" class="ltx_text ltx_font_italic">TrimmedMean</span>, they are tested on both CFL and DFL. For the defense mechanisms designed for DFL, <span id="S5.SS2.SSS3.p4.1.6" class="ltx_text ltx_font_italic">Sentinel</span> and <span id="S5.SS2.SSS3.p4.1.7" class="ltx_text ltx_font_italic">Voyager</span>, since they do not work on CFL, the testing is done on DFL only.</p>
</div>
<section id="S5.SS2.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(i)<span id="S5.SS2.SSS3.Px1.1.1" class="ltx_text ltx_font_upright"> Defense Effectiveness</span>
</h5>

<div id="S5.SS2.SSS3.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS3.Px1.p1.1" class="ltx_p"><span id="S5.SS2.SSS3.Px1.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS3.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS3.Px1.p2.1" class="ltx_p">The average F1-Score of the defense mechanisms under three datasets, three attack strategies, and different PNRs is shown in Table <a href="#S5.T4" title="Table 4 ‣ (iii) Model Robustness in Different Paradigms and Topologies ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Overall, <span id="S5.SS2.SSS3.Px1.p2.1.1" class="ltx_text ltx_font_italic">Sentinel</span> achieves the best defense against untargeted attacks and is able to maintain the maximum model robustness, with <span id="S5.SS2.SSS3.Px1.p2.1.2" class="ltx_text ltx_font_italic">Voyager</span> coming in second. However, when the percentage of poisoned nodes exceeds 50%, most defenses prove to be ineffective. This is due to Byzantine-robust aggregation techniques, such as<span id="S5.SS2.SSS3.Px1.p2.1.3" class="ltx_text ltx_font_italic">Krum</span>, <span id="S5.SS2.SSS3.Px1.p2.1.4" class="ltx_text ltx_font_italic">Median</span>, and <span id="S5.SS2.SSS3.Px1.p2.1.5" class="ltx_text ltx_font_italic">TrimmedMean</span>, being more likely to select malicious models over benign ones in such scenarios. Although <span id="S5.SS2.SSS3.Px1.p2.1.6" class="ltx_text ltx_font_italic">FLTrust</span> demonstrates a good result at low PNR, the results show that it does not exhibit an advantage for Byzantine-robust aggregation techniques. These defense strategies exhibit similar outcomes to <span id="S5.SS2.SSS3.Px1.p2.1.7" class="ltx_text ltx_font_italic">FedAvg</span> across different network topologies and datasets. Meanwhile, the defense mechanism is more effective against Sample Poisoning and Label Flipping than Model Poisoning. Except for <span id="S5.SS2.SSS3.Px1.p2.1.8" class="ltx_text ltx_font_italic">Sentinel</span> and <span id="S5.SS2.SSS3.Px1.p2.1.9" class="ltx_text ltx_font_italic">Voyager</span>, most defense mechanisms are ineffective in mitigating Model Poisoning attacks.</p>
</div>
</section>
<section id="S5.SS2.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(ii)<span id="S5.SS2.SSS3.Px2.1.1" class="ltx_text ltx_font_upright"> Compatibility in DFL</span>
</h5>

<div id="S5.SS2.SSS3.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS3.Px2.p1.1" class="ltx_p"><span id="S5.SS2.SSS3.Px2.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS3.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS3.Px2.p2.1" class="ltx_p">In contrast to CFL, the network topologies influence the effectiveness of Byzantine defense strategies and <span id="S5.SS2.SSS3.Px2.p2.1.1" class="ltx_text ltx_font_italic">FLTrust</span> in DFL. A smaller average number of connected neighbors in the network results in malicious nodes posing a greater threat to their directly connected benign nodes. In such cases, benign nodes are more likely to aggregate with more than 50% of malicious neighbors, rendering Byzantine-robust aggregation techniques ineffective. It can be seen from the results in Table <a href="#S5.T4" title="Table 4 ‣ (iii) Model Robustness in Different Paradigms and Topologies ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that the results in the ring and star topologies are worse than the fully connected ones. Therefore, those defense mechanisms designed for CFL have some difficulties adapting to DFL, and they are more effective in dense topologies.</p>
</div>
<div id="S5.SS2.SSS3.Px2.p3" class="ltx_para">
<p id="S5.SS2.SSS3.Px2.p3.1" class="ltx_p">To conclude, when the FL system contains a small number of malicious nodes, all defense mechanisms prove to be effective. However, if the percentage of malicious nodes exceeds 50%, the Byzantine-robust defenses and <span id="S5.SS2.SSS3.Px2.p3.1.1" class="ltx_text ltx_font_italic">FLTrust</span> become ineffective. In contrast, the DFL-focused defense mechanisms, Voyager and Sentinel, are capable of effectively countering attacks from a high percentage of malicious nodes. Furthermore, the network’s topology also plays a role in the effectiveness of the defenses, with Byzantine-robust defenses and <span id="S5.SS2.SSS3.Px2.p3.1.2" class="ltx_text ltx_font_italic">FLTrust</span> being less effective in sparse networks but performing better in dense networks.</p>
</div>
</section>
</section>
<section id="S5.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.4 </span>Benchmark of Defense Mechanisms for Targeted Poisoning Attacks</h4>

<div id="S5.SS2.SSS4.p1" class="ltx_para">
<p id="S5.SS2.SSS4.p1.1" class="ltx_p">As analyzed in Section <a href="#S5.SS2.SSS2" title="5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.2</span></a>, targeted attacks are more difficult to detect. Therefore, this section experimentally benchmarks the performance of defense mechanisms listed in section <a href="#S5.SS2.SSS3" title="5.2.3 Benchmark of Defense Mechanisms for Untargeted Poisoning Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.3</span></a> under targeted attacks, including Targeted Label Flipping and Backdoor Attacks.</p>
</div>
<section id="S5.SS2.SSS4.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(i)<span id="S5.SS2.SSS4.Px1.1.1" class="ltx_text ltx_font_upright"> Defense Effectiveness for Targeted Label Flipping</span>
</h5>

<div id="S5.SS2.SSS4.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS4.Px1.p1.1" class="ltx_p"><span id="S5.SS2.SSS4.Px1.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS4.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS4.Px1.p2.1" class="ltx_p">Overall, <span id="S5.SS2.SSS4.Px1.p2.1.1" class="ltx_text ltx_font_italic">Krum</span>, <span id="S5.SS2.SSS4.Px1.p2.1.2" class="ltx_text ltx_font_italic">TrimmedMean</span>, <span id="S5.SS2.SSS4.Px1.p2.1.3" class="ltx_text ltx_font_italic">Median</span>, <span id="S5.SS2.SSS4.Px1.p2.1.4" class="ltx_text ltx_font_italic">Voyager</span>, and <span id="S5.SS2.SSS4.Px1.p2.1.5" class="ltx_text ltx_font_italic">FLTrust</span> are not effective against Targeted Label Flipping attacks, as shown in the Table <a href="#S5.T5" title="Table 5 ‣ (iii) Model Robustness in Different Paradigms and Topologies ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The reason is that since the Targeted Label Flipping attacks have a small impact on the overall model, it is difficult for distance-based or extreme value filtering defenses to work. In contrast, <span id="S5.SS2.SSS4.Px1.p2.1.6" class="ltx_text ltx_font_italic">Sentinel</span>’s loss-based layer-wise normalization mechanism is much more effective against Targeted Label Flipping, and the experimental results show that <span id="S5.SS2.SSS4.Px1.p2.1.7" class="ltx_text ltx_font_italic">Sentinel</span> can effectively prevent the spread of Targeted Label Flipping attacks.</p>
</div>
</section>
<section id="S5.SS2.SSS4.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_font_italic ltx_title_paragraph">(ii)<span id="S5.SS2.SSS4.Px2.1.1" class="ltx_text ltx_font_upright"> Defense Effectiveness for Backdoor Attack</span>
</h5>

<div id="S5.SS2.SSS4.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS4.Px2.p1.1" class="ltx_p"><span id="S5.SS2.SSS4.Px2.p1.1.1" class="ltx_text"></span>
<br class="ltx_break"></p>
</div>
<div id="S5.SS2.SSS4.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS4.Px2.p2.1" class="ltx_p">According to the data presented in the Table <a href="#S5.T6" title="Table 6 ‣ (iii) Model Robustness in Different Paradigms and Topologies ‣ 5.2.2 Experimental Analysis of Targeted Attacks ‣ 5.2 Poisoning Attack on CFL and DFL ‣ 5 Experimental Analysis ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the defense mechanisms exhibit weaknesses when confronted with the Backdoor Attack. In general, <span id="S5.SS2.SSS4.Px2.p2.1.1" class="ltx_text ltx_font_italic">Sentinel</span> successfully counters the Backdoor Attack on the MNIST and FashionMNIST datasets. However, it fails to effectively address this attack on the Cifar10 dataset, which task is more complex and has a larger number of model parameters. The reason behind this failure is that in more complex models, the implanted backdoor has a limited effect on both the similarity and the loss of the model. Therefore, neither the Byzantine-robust defense mechanisms nor the hybrid <span id="S5.SS2.SSS4.Px2.p2.1.2" class="ltx_text ltx_font_italic">Sentinel</span> and <span id="S5.SS2.SSS4.Px2.p2.1.3" class="ltx_text ltx_font_italic">FLTrust</span> approaches are able to mitigate this type of attack effectively.</p>
</div>
<div id="S5.SS2.SSS4.Px2.p3" class="ltx_para">
<p id="S5.SS2.SSS4.Px2.p3.1" class="ltx_p">In conclusion, compared to untargeted attacks, targeted attacks are more difficult to defend, and the Byzantine-robust defense is often ineffective. On the contrary, the combination of model similarity and loss-based layer-wise normalization, <span id="S5.SS2.SSS4.Px2.p3.1.1" class="ltx_text ltx_font_italic">i.e., Sentinel</span>, can effectively defend against targeted attacks.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Lessons Learned, Open Challenges, and Research Opportunities</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Drawing on the analysis of the diverse model robustness of DFL in previous sections, this section endeavors to address the lessons learned and challenges that have surfaced in the research of DFL model robustness. Additionally, it suggests potential avenues for further research.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Lessons Learned</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Through the literature research and experimental analysis on both attack and defense sides, the following lessons were summarized:</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">There is limited research on model robustness for DFL. The current research on model robustness is mainly focused on CFL. In addition, there is a lack of research on designing attacks optimized for DFL from an attack perspective or designing defense mechanisms to enhance the robustness of DFL models from a defense perspective.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">The model robustness degradation caused by untargeted attacks is more tangible than with targeted attacks. The latter have an insignificant impact on the overall effectiveness of the model and are more challenging to detect by common metrics. When considering attack strategy, sample poisoning is found to be less effective in untargeted attacks, but it exhibits higher efficacy in targeted attacks. In terms of the extent of harm inflicted by the attacks, untargeted attacks, particularly those involving model poisoning, result in significant damage.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">Topology plays a crucial role in determining the success of an attack in DFL. A densely connected network is more vulnerable to the spread of malicious attacks, while a sparse network can result in more severe consequences when under attack.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p">The majority of defense mechanisms are ineffective in a high percentage (<span id="S6.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">i.e., </span>more than 50%) of malicious nodes. Meanwhile, defense mechanisms designed for CFL encounter challenges when applied to DFL. Byzantine-robust countermeasures, such as <span id="S6.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">Krum</span> and <span id="S6.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">TrimmedMean</span>, have limited effectiveness in sparse DFL networks.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p">Most defense mechanisms are insufficient when mitigating targeted attacks, either in CFL or DFL. The limited effect of targeted attacks on the model’s parameters poses challenges for distance- or similarity-based defense mechanisms.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Application in Practical Scenarios</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In general, current research on model robustness for FL, especially DFL, still tends to focus on the general problem rather than practical scenarios, i.e., most of the studies are validated on commonly used benchmark datasets, such as MNIST and FashionMNIST. There is a limited amount of research exploring the impacts of poisoning attacks on the robustness of FL models in practical scenarios, particularly in the fields of IoT, finance, and healthcare.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">45</span></a>]</cite> discussed the feasibility of implementing poisoning attacks on FL systems in IoT environments and evaluated the hazards caused by poisoning attacks in an IoT Intrusion Detection System. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">20</span></a>]</cite> proposed a framework for Federated Reinforcement Learning (FRL) to recognize malware attacks and automatically implement mitigation strategies in IoT environments. They verified the robustness of their proposed FRL framework to data poisoning and model poisoning attacks. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">68</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">2</span></a>]</cite> provided an overview of the various problems associated with FL applications in medical and healthcare scenarios, including the problems associated with heterogeneities, and also the security problems associated with poisoning attacks. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">32</span></a>]</cite> proposed a framework for data poisoning attacks against healthcare FL, by comparing local models of different rounds and models from other nodes. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">64</span></a>]</cite>, a distributed backdoor attack approach was proposed and validated on a dataset in the financial domain. The research on FL in practical applications has garnered significant attention, yet there remains a noticeable absence of discourse surrounding the robustness of its models to both offensive and defensive sides.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">Through the experimental validation in this paper, there are the following insights for the deployment of FL in practice scenarios, especially in the fields of IoT, healthcare, and finance:</p>
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p">The decentralized nature of DFL results in a lack of model auditing and verification mechanisms for the federation, leading to potential security concerns that participants should be mindful of. While the FedAvg algorithm demonstrates strong performance in non-attacked scenarios, the presence of a malicious node within the federation can compromise the security of all nodes. To mitigate these risks, aggregation methods specifically tailored for DFL are advised, especially in scenarios where heightened security is required.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p">Since overlay topology greatly impacts the model robustness of DFL, nodes should carefully consider which neighbors to connect and aggregate with. The remarkable performance of the <span id="S6.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">Voyager</span> algorithm, which relies on altering the connections with neighbors in DFL, indicates that employing a dynamic topology can effectively reduce the impact of poisoning attacks.</p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.1" class="ltx_p">Due to the minimal alterations made by targeted attacks, particularly backdoor attacks, conventional methods of model auditing that focus on performance or similarity between nodes have shown limited efficacy. Nevertheless, these attacks can have significant consequences in critical sectors like healthcare and finance. Therefore, additional audit analysis should be counted for targeted attacks, such as analyzing the stability of model results across categories.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Real-World Applicability</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">When deploying the DART method for evaluating the robustness of DFL models in a real-world environment, the following difficulties pose limitations and difficulties:</p>
<ul id="S6.I3" class="ltx_itemize">
<li id="S6.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i1.p1" class="ltx_para">
<p id="S6.I3.i1.p1.1" class="ltx_p"><span id="S6.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Limited Datasets.</span> As mentioned in Section <a href="#S6.SS2" title="6.2 Application in Practical Scenarios ‣ 6 Lessons Learned, Open Challenges, and Research Opportunities ‣ DART: A Solution for Decentralized Federated Learning Model Robustness Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>, current evaluations of DFL model robustness focus on commonly used datasets and lack domain datasets, especially real-world datasets. However, datasets may contain sensitive information, and sharing them directly may bring privacy and security concerns. Hence, the process of desensitizing and restructuring authentic data using techniques like data augmentation and synthetic data generation presents viable options <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">23</span></a>]</cite>. These methods serve to eliminate private information within the raw data, while maintaining the raw data’s characteristics and patterns. This, in turn, allows for a more thorough examination of the potential challenges in deploying DFL models in practical settings.</p>
</div>
</li>
<li id="S6.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i2.p1" class="ltx_para">
<p id="S6.I3.i2.p1.1" class="ltx_p"><span id="S6.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Realistic Attacks.</span> In the research on poisoning attacks, it is commonly assumed that malicious nodes can coordinate with each other to target benign nodes. However, in real-world scenarios of DFL, individual nodes often have different affiliations that complement each other. This poses a challenge for attackers, as the lack of synergy between malicious nodes can diminish the impact of their attacks or even cancel out the effect brought by the attack. Combining poisoning attacks with Sybil attacks can have a more significant impact, particularly when a large number of manipulated nodes are present in a DFL. Experimental findings indicate that a high proportion of malicious nodes within a federation can render defense mechanisms ineffective. Thus, if the Sybil attack has more than half of the manipulated nodes in the federation, defenses, including Krum and TrimmedMean, fail. Besides, a combination of poisoning attacks and Eclipse attacks can isolate a target benign node from other benign nodes. In such a case, the target node is surrounded by malicious nodes, and most of the defenses are ineffective. The same attacker can execute these two types of attacks and does not require collaboration with other attackers. However, they require attackers to know the overlay topology of the DFL in advance. Consequently, a topology manipulation defense mechanism can effectively defend against such attacks.</p>
</div>
</li>
<li id="S6.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i3.p1" class="ltx_para">
<p id="S6.I3.i3.p1.1" class="ltx_p"><span id="S6.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Collaboration of Defenses.</span> Decentralization not only poses a synchronization difficulty for the attacker but also a collaboration difficulty for the defender. Ideally, if a benign node in a DFL detects an attack, it should notify the other benign nodes to take appropriate defense measures. However, these collaborative messages can be intercepted and tampered with by the attacker, making collaboration among defenders difficult in real-world scenarios.DFL participants can adopt a more "selfish" defense, i.e., proactive defenses, to protect their models from attacks and not rely on notifications from other nodes. Possible proactive strategies include dynamically changing the aggregation algorithm, or proactively changing connected neighbors.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Ethical Considerations</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">Although DFL offers advantages regarding privacy and effectiveness, it still has some ethical concerns:</p>
<ul id="S6.I4" class="ltx_itemize">
<li id="S6.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I4.i1.p1" class="ltx_para">
<p id="S6.I4.i1.p1.1" class="ltx_p"><span id="S6.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Privacy.</span> Although in DFL, only the parameters or gradients of the model are transmitted through the network, studies have shown that this can still cause privacy leakage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">6</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">37</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">31</span></a>]</cite>. An attacker can infer privacy information from model parameters, model gradients, or model outputs, including the hyper-parameters of model training, or restore the original training data. This type of attack is called an inference attack, bringing privacy concerns to DFL. Since the successful implementation of inference attacks relies on model overfitting, pruning and data augmentation techniques can be used to mitigate inference attacks. Besides, differential privacy or homomorphic encryption techniques can be used to protect the privacy-preserving capabilities of DFL models.</p>
</div>
</li>
<li id="S6.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I4.i2.p1" class="ltx_para">
<p id="S6.I4.i2.p1.1" class="ltx_p"><span id="S6.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Fairness and Bias.</span> As a data-driven process, the bias of the data brings about the bias of the DFL model. Therefore, the fairness and bias of the DFL model are also important aspects of the ethical consideration of DFL. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">56</span></a>]</cite> proposed a qualitative analysis method for FL fairness, which can effectively measure the fairness of FL models.</p>
</div>
</li>
<li id="S6.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I4.i3.p1" class="ltx_para">
<p id="S6.I4.i3.p1.1" class="ltx_p"><span id="S6.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">Sustainability.</span> The training of DFL models consumes energy and produces greenhouse gases. Thus, it poses concerns in terms of sustainability. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">13</span></a>]</cite> proposed a framework for measuring the sustainability of FL, which calculates the sustainability of FL models by considering multiple aspects such as grid efficiency, hardware efficiency, and computational efficiency.</p>
</div>
</li>
<li id="S6.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I4.i4.p1" class="ltx_para">
<p id="S6.I4.i4.p1.1" class="ltx_p"><span id="S6.I4.i4.p1.1.1" class="ltx_text ltx_font_bold">Compliance with Regulations.</span> DFL is required to comply to a range of data protection regulations, such as General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">16</span></a>]</cite> and Health Insurance Portability and Accountability Act (HIPAA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">58</span></a>]</cite>. These regulations were not specifically tailored to address the challenges faced by DFL, making compliance a complex undertaking. The concept of the right to be forgotten, as outlined in GDPR, presents particular challenges for DFL, as the deletion of user data from one node may not guarantee its removal from other nodes through model aggregation. Research on machine unlearning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">9</span></a>]</cite> is gaining attention as a potential avenue for DFL to align with data protection requirements.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Open Challenges and Opportunities</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">Regarding the lessons learned, application in practical scenarios, and ethical considerations, the following challenges and opportunities for model robustness research are identified:</p>
</div>
<div id="S6.SS5.p2" class="ltx_para">
<ul id="S6.I5" class="ltx_itemize">
<li id="S6.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I5.i1.p1" class="ltx_para">
<p id="S6.I5.i1.p1.1" class="ltx_p"><span id="S6.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Increased Attack Surfaces.</span> In CFL, only the central aggregator has a global view of the whole federation and has model information of all nodes. However, in DFL, depending on the topology, any node may have model information about all other nodes in the federation, which actually increases the security vulnerabilities. These increased attack surfaces pose a persistent challenge in preserving the robustness of DFL models. Therefore, it is crucial to customize defense mechanisms specifically for DFL systems. The robustness of DFL heavily relies on topology, suggesting that incorporating dynamic topology could serve as a viable defense mechanism. Additionally, leveraging nodes’ local data and models within DFL systems can enhance the effectiveness of defense mechanisms against attacks.</p>
</div>
</li>
<li id="S6.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I5.i2.p1" class="ltx_para">
<p id="S6.I5.i2.p1.1" class="ltx_p"><span id="S6.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Optimized Attacks.</span> In DFL, nodes receive models from their neighbors. Therefore, it is possible for malicious nodes to exploit the models received from their neighboring nodes as knowledge to optimize their attack strategies. By incorporating their own knowledge of defense mechanisms, these malicious nodes can manipulate the attack direction and increase the likelihood of achieving their objectives. This increases the difficulty and challenge for defense. In benign nodes, dynamic changes in aggregation functions can increase the difficulty of the attacker learning about the defense mechanism and increase the cost of executing the optimized attack. Besides, techniques such as homomorphic encryption can effectively increase the cost of such attacks.</p>
</div>
</li>
<li id="S6.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I5.i3.p1" class="ltx_para">
<p id="S6.I5.i3.p1.1" class="ltx_p"><span id="S6.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Balance between Overhead and Robustness.</span> Incorporating defense mechanisms can enhance the robustness of DFL models, but it also presents challenges like increased network overhead, high computational resource usage, and scalability limitations. For example, when employing filtering-based strategies as a defense approach, setting a threshold too low may lead to ineffective filtering of malicious models, while setting the threshold too high may result in the exclusion of valuable models and the loss of benefits from information sharing. In terms of network traffic, defenses with inter-node connection operations may introduce communication overhead since they may change the overlay topology. Besides, more complex defenses may necessitate a higher number of computations, resulting in computation overhead and increased communication latency. This can lead to prolonged convergence times for the federation. It is crucial to balance overhead and robustness when designing defenses. MTD is a dynamic defense framework that enables defenders to adjust security levels based on specific requirements rather than striving for absolute security. As such, MTD is suggested as a design framework for DFL defenses to manage the trade-off between security and overhead effectively. Viable MTD strategies include model backup and rollback, dynamic topology, and dynamic aggregation. Furthermore, conducting data auditing and validation for each node before starting federated training can effectively protect against data poisoning attacks.</p>
</div>
</li>
<li id="S6.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I5.i4.p1" class="ltx_para">
<p id="S6.I5.i4.p1.1" class="ltx_p"><span id="S6.I5.i4.p1.1.1" class="ltx_text ltx_font_bold">Data Heterogeneity.</span> As a data-driven process, performance of DFL relies on how the data is distributed across the nodes. It is often assumed that the data follows the IID settings when investigating the robustness of DFL models. Algorithms like Krum are based on the assumption that models trained on similar data should be highly similar, but anomalies are not. However, this assumption is invalidated in non-IID scenarios where data distribution across nodes is highly varsion. In non-IID settings, model similarity decreases, making it challenging to differentiate between benign and malicious models using similarity or clustering. In these cases, data-independent metrics can be utilized to detect malicious models. Rather than solely depending on model similarity, utilizing intrinsic model characteristics, such as eXplainable AI (XAI) metrics, can improve the performance of defense mechanisms while preserving the knowledge exchanged by non-IID nodes.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Roadmap for Future Work</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">Based on the preceding discussion, the following aspects can serve as a guiding framework for future studies aimed at strengthening the robustness of DFL models:</p>
<ul id="S6.I6" class="ltx_itemize">
<li id="S6.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I6.i1.p1" class="ltx_para">
<p id="S6.I6.i1.p1.1" class="ltx_p"><span id="S6.I6.i1.p1.1.1" class="ltx_text ltx_font_bold">Topology is the Key.</span> As mentioned several times above, overlay topology is the key factor affecting model robustness in DFL. Therefore, adopting the strategy of dynamic topology, either proactive or reactive, can mitigate the effects of different kinds of poisoning attacks while optimizing the model performance of DFL.</p>
</div>
</li>
<li id="S6.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I6.i2.p1" class="ltx_para">
<p id="S6.I6.i2.p1.1" class="ltx_p"><span id="S6.I6.i2.p1.1.1" class="ltx_text ltx_font_bold">Dynamic Aggregation.</span> Advanced attacks optimize attack strategies for specific aggregation functions. Therefore, using dynamic aggregation functions, such as changing the aggregation algorithm in every round, can effectively prevent the knowledge of aggregation strategies from being identified by the attackers.</p>
</div>
</li>
<li id="S6.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I6.i3.p1" class="ltx_para">
<p id="S6.I6.i3.p1.1" class="ltx_p"><span id="S6.I6.i3.p1.1.1" class="ltx_text ltx_font_bold">Endogenous Properties of Models.</span> Metrics such as model similarity strongly depend on the distribution of the data and thus are inefficient in the non-IID environment. The endogenous properties of the model, such as convergence and entropy and other metrics used in XAI, are a viable way to enhance the robustness of the model in the non-IID environment.</p>
</div>
</li>
<li id="S6.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I6.i4.p1" class="ltx_para">
<p id="S6.I6.i4.p1.1" class="ltx_p"><span id="S6.I6.i4.p1.1.1" class="ltx_text ltx_font_bold">Data Augmentation and Synthetic Data.</span> Utilizing techniques such as data augmentation and synthetic data generation can maintain the integrity of the original data while also ensuring data privacy. Consequently, these approaches can be employed in DFL to generate synthetic data that balances data distribution among nodes. By leveraging the synthetic data generated, it is possible to approximate non-IID as IID, thereby enabling the detection and mitigation of poisoning attacks.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">DFL is gaining prominence as a novel paradigm for achieving stable, collaborative, and privacy-preserving ML. Its distinctive architecture renders it vulnerable to various forms of malicious attacks, particularly poisoning attacks. There is a growing interest in researching model robustness in FL. However, existing research, which explores both offensive and defensive approaches, mainly concentrates on investigating the CFL paradigm. Therefore, there is a great need for studies on model robustness for DFL paradigm.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Therefore, this paper provides a comprehensive literature review of poisoning attacks that target model robustness in the DFL paradigm, along with the corresponding defense mechanisms. Additionally, a novel module named <span id="S7.p2.1.1" class="ltx_text ltx_font_italic">DART</span> is introduced to assess the robustness of DFL models, which is then implemented and integrated into a DFL platform. Through a series of thorough experiments, this study contrasts the behavior of CFL and DFL when subjected to various poisoning attacks, identifying the critical factors that influence the spread and effectiveness of attacks within DFL. Furthermore, it benchmarks the efficacy of different defense mechanisms and explores the compatibility of CFL-based defense strategies with DFL.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">The empirical findings offer valuable insights into the challenges of research and propose potential directions to enhance the robustness of DFL models for future research.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Declaration of Competing Interest</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">CRediT authorship contribution statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p"><span id="Sx2.p1.1.1" class="ltx_text ltx_font_bold">Chao Feng.</span> Methodology, Conceptualization, Writing, Review &amp; Editing.
<span id="Sx2.p1.1.2" class="ltx_text ltx_font_bold">Alberto Huertas Celdran.</span> Methodology, Writing, Review.
<span id="Sx2.p1.1.3" class="ltx_text ltx_font_bold">Jan von der Assen.</span> Writing, Review.
<span id="Sx2.p1.1.4" class="ltx_text ltx_font_bold">Enrique Tomás Martínez Beltrán.</span> Writing, Review.
<span id="Sx2.p1.1.5" class="ltx_text ltx_font_bold">Gérôme Bovet.</span> Project administration, Funding acquisition.
<span id="Sx2.p1.1.6" class="ltx_text ltx_font_bold">Burkhard Stiller.</span> Supervision, Funding acquisition.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">This work has been partially supported by <span id="Sx3.p1.1.1" class="ltx_text ltx_font_italic">(a)</span> the Swiss Federal Office for Defense Procurement (armasuisse) with the CyberMind and DATRIS (CYD-C-2020003) projects and <span id="Sx3.p1.1.2" class="ltx_text ltx_font_italic">(b)</span> the University of Zürich UZH.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. [2016]</span>
<span class="ltx_bibblock">
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., Zheng, X., 2016.

</span>
<span class="ltx_bibblock">Tensorflow: A system for large-scale machine learning.

</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://www.tensorflow.org/tensorboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/tensorboard</a>, <a target="_blank" href="http://arxiv.org/abs/1605.08695" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1605.08695</a><span id="bib.bib1.1.1" class="ltx_text ltx_font_typewriter">. Last Visit July 2024.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text ltx_font_typewriter">Ali et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text ltx_font_typewriter">
Ali, M., Naeem, F., Tariq, M., Kaddoum, G., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text ltx_font_typewriter">Federated learning for privacy preservation in smart healthcare systems: A comprehensive survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text ltx_font_typewriter">IEEE journal of biomedical and health informatics 27, 778--789.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text ltx_font_typewriter">Bagdasaryan et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text ltx_font_typewriter">
Bagdasaryan, E., Veit, A., Hua, Y., Estrin, D., Shmatikov, V., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text ltx_font_typewriter">How To Backdoor Federated Learning, in: arXiv:1807.00459 [cs], pp. 1--15.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text ltx_font_typewriter">Beltran et al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text ltx_font_typewriter">
Beltran, E.T.M., Gómez, a.L.P., Feng, C., Sanchez, P.M.S., Bernal, S.L., Bovet, G., Perez, M.G., Perez, G.M., Celdran, A.H., 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text ltx_font_typewriter">Fedstellar: A platform for decentralized federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text ltx_font_typewriter">Expert Systems with Applications 242, 122861.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text ltx_font_typewriter">Beltran et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text ltx_font_typewriter">
Beltran, E.T.M., Perez, M.Q., Sanchez, P.M.S., Bernal, S.L., Bovet, G., Perez, M.G., Perez, G.M., Celdran, A.H., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text ltx_font_typewriter">Decentralized Federated Learning: Fundamentals, State-of-the-art, Frameworks, Trends, and Challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text ltx_font_typewriter">IEEE Communications Surveys and Tutorials 25, 2983--3013.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text ltx_font_typewriter">Benmalek et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text ltx_font_typewriter">
Benmalek, M., Benrekia, M.A., Challal, Y., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text ltx_font_typewriter">Security of Federated Learning: Attacks, Defensive Mechanisms, and Challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text ltx_font_typewriter">Revue des Sciences et Technologies de l’Information - Série RIA : Revue d’Intelligence Artificielle 36, 49--59.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text ltx_font_typewriter">Blanchard et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text ltx_font_typewriter">
Blanchard, P., El Mhamdi, E.M., Guerraoui, R., Stainer, J., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text ltx_font_typewriter">Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent, in: Proceedings of the 31st International Conference on Neural Information Processing Systems, California, USA. pp. 118--128.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text ltx_font_typewriter">Blanco-Justicia et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text ltx_font_typewriter">
Blanco-Justicia, A., Domingo-Ferrer, J., Martínez, S., Sánchez, D., Flanagan, A., Tan, K.E., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text ltx_font_typewriter">Achieving security and privacy in federated learning systems: Survey, research challenges and future directions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text ltx_font_typewriter">Engineering Applications of Artificial Intelligence 106, 104468.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text ltx_font_typewriter">Bourtoule et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text ltx_font_typewriter">
Bourtoule, L., Chandrasekaran, V., Choquette-Choo, C.A., Jia, H., Travers, A., Zhang, B., Lie, D., Papernot, N., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text ltx_font_typewriter">Machine unlearning, in: 2021 IEEE Symposium on Security and Privacy (SP), pp. 141--159.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text ltx_font_typewriter">doi:</span><a target="_blank" href="https:/doi.org/10.1109/SP40001.2021.00019" title="" class="ltx_ref ltx_font_typewriter">10.1109/SP40001.2021.00019</a><span id="bib.bib9.10.2" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text ltx_font_typewriter">Cai et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text ltx_font_typewriter">
Cai, G., Wang, B., Hu, W., Wang, T., 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text ltx_font_typewriter">Moving Target Defense: State of the Art and Characteristics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text ltx_font_typewriter">Frontiers of Information Technology &amp; Electronic Engineering 17, 1122--1153.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text ltx_font_typewriter">Cao et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text ltx_font_typewriter">
Cao, D., Chang, S., Lin, Z., Liu, G., Sun, D., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text ltx_font_typewriter">Understanding Distributed Poisoning Attack in Federated Learning, in: IEEE 25th International Conference on Parallel and Distributed Systems.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text ltx_font_typewriter">Cao et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text ltx_font_typewriter">
Cao, X., Fang, M., Liu, J., Gong, N.Z., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text ltx_font_typewriter">FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping, in: Proceedings 2021 Network and Distributed System Security Symposium.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text ltx_font_typewriter">Celdran et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text ltx_font_typewriter">
Celdran, A.H., Feng, C., Sanchez, P.M.S., Zumtaugwald, L., Bovet, G., Stiller, B., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text ltx_font_typewriter">Assessing the sustainability and trustworthiness of federated learning models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://arxiv.org/abs/2310.20435" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2310.20435</a><span id="bib.bib13.10.2" class="ltx_text ltx_font_typewriter">, </span><a target="_blank" href="http://arxiv.org/abs/2310.20435" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:2310.20435</a><span id="bib.bib13.11.3" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text ltx_font_typewriter">Chen et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text ltx_font_typewriter">
Chen, Y., Gui, Y., Lin, H., Gan, W., Wu, Y., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text ltx_font_typewriter">Federated learning attacks and defenses: A survey, in: 2022 IEEE International Conference on Big Data (Big Data), pp. 4256--4265.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.4.4.1" class="ltx_text ltx_font_typewriter">Duarte [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text ltx_font_typewriter">
Duarte, F., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text ltx_font_typewriter">Number of IOT devices (2023-2030).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://explodingtopics.com/blog/number-of-iot-devices" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://explodingtopics.com/blog/number-of-iot-devices</a><span id="bib.bib15.9.2" class="ltx_text ltx_font_typewriter">. Last Visit December 2023.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.4.4.1" class="ltx_text ltx_font_typewriter">European Parliament and Council of the European Union [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text ltx_font_typewriter">
European Parliament and Council of the European Union, 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text ltx_font_typewriter">Regulation (eu) 2016/679 of the european parliament and of the council of 27 april 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing directive 95/46/ec (general data protection regulation).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://eur-lex.europa.eu/eli/reg/2016/679/oj" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a><span id="bib.bib16.9.2" class="ltx_text ltx_font_typewriter">. Last Visit July 2024.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.4.4.1" class="ltx_text ltx_font_typewriter">Falcon and team [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text ltx_font_typewriter">
Falcon, W., team, T.P.L., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text ltx_font_typewriter">Pytorch lightning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://www.pytorchlightning.ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.pytorchlightning.ai</a><span id="bib.bib17.9.2" class="ltx_text ltx_font_typewriter">. Last Visit July 2024.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text ltx_font_typewriter">Fang et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text ltx_font_typewriter">
Fang, M., Cao, X., Jia, J., Gong, N.Z., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text ltx_font_typewriter">Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1911.11815 [cs].
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text ltx_font_typewriter">Feng et al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text ltx_font_typewriter">
Feng, C., Celdran, A.H., Baltensperger, J., Beltran, E.T.M., Bovet, G., Stiller, B., 2023a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text ltx_font_typewriter">Sentinel: An aggregation function to secure decentralized federated learning.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text ltx_font_typewriter">Feng et al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text ltx_font_typewriter">
Feng, C., Celdran, A.H., Sanchez, P.M.S., Kreischer, J., von der Assen, J., Bovet, G., Perez, G.M., Stiller, B., 2023b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text ltx_font_typewriter">Cyberforce: A federated reinforcement learning framework for malware mitigation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://arxiv.org/abs/2308.05978" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2308.05978</a><span id="bib.bib20.10.2" class="ltx_text ltx_font_typewriter">, </span><a target="_blank" href="http://arxiv.org/abs/2308.05978" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:2308.05978</a><span id="bib.bib20.11.3" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text ltx_font_typewriter">Feng et al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text ltx_font_typewriter">
Feng, C., Celdran, A.H., Vuong, M., Bovet, G., Stiller, B., 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text ltx_font_typewriter">Voyager: Mtd-based aggregation protocol for mitigating poisoning attacks on dfl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text ltx_font_typewriter">IEEE/IFIP Network Operations and Management Symposium .
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.4.4.1" class="ltx_text ltx_font_typewriter">Flask [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text ltx_font_typewriter">
Flask, 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text ltx_font_typewriter">Flask.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://flask.palletsprojects.com/en/3.0.x/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://flask.palletsprojects.com/en/3.0.x/</a><span id="bib.bib22.9.2" class="ltx_text ltx_font_typewriter">. Last Visit July 2024.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text ltx_font_typewriter">Frid-Adar et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text ltx_font_typewriter">
Frid-Adar, M., Klang, E., Amitai, M., Goldberger, J., Greenspan, H., 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text ltx_font_typewriter">Synthetic data augmentation using gan for improved liver lesion classification, in: 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), pp. 289--293.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text ltx_font_typewriter">doi:</span><a target="_blank" href="https:/doi.org/10.1109/ISBI.2018.8363576" title="" class="ltx_ref ltx_font_typewriter">10.1109/ISBI.2018.8363576</a><span id="bib.bib23.10.2" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text ltx_font_typewriter">Fung et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text ltx_font_typewriter">
Fung, C., Yoon, C.J.M., Beschastnikh, I., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text ltx_font_typewriter">Mitigating Sybils in Federated Learning Poisoning.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text ltx_font_typewriter">Gholami et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text ltx_font_typewriter">
Gholami, A., Torkzaban, N., Baras, J.S., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text ltx_font_typewriter">Trusted Decentralized Federated Learning, in: 2022 IEEE 19th Annual Consumer Communications &amp; Networking Conference (CCNC), IEEE, Las Vegas, NV, USA. pp. 1--6.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text ltx_font_typewriter">Guo et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text ltx_font_typewriter">
Guo, S., Zhang, T., Yu, H., Xie, X., Ma, L., Xiang, T., Liu, Y., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text ltx_font_typewriter">Byzantine-resilient Decentralized Stochastic Gradient Descent.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2002.08569.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text ltx_font_typewriter">Howard et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text ltx_font_typewriter">
Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text ltx_font_typewriter">Mobilenets: Efficient convolutional neural networks for mobile vision applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text ltx_font_typewriter">arXiv preprint arXiv:1704.04861 .
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text ltx_font_typewriter">Huertas Celdran et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text ltx_font_typewriter">
Huertas Celdran, A., Sanchez Sanchez, P.M., Feng, C., Bovet, G., Perez, G.M., Stiller, B., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text ltx_font_typewriter">Privacy-Preserving and Syscall-Based Intrusion Detection System for IoT Spectrum Sensors Affected by Data Falsification Attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text ltx_font_typewriter">IEEE Internet of Things Journal 10, 8408--8415.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text ltx_font_typewriter">Jere et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text ltx_font_typewriter">
Jere, M.S., Farnan, T., Koushanfar, F., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text ltx_font_typewriter">A taxonomy of attacks on federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text ltx_font_typewriter">IEEE Security &amp; Privacy 19, 20--28.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.4.4.1" class="ltx_text ltx_font_typewriter">Krizhevsky [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text ltx_font_typewriter">
Krizhevsky, A., 2009.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text ltx_font_typewriter">Learning multiple layers of features from tiny images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text ltx_font_typewriter">Technical Report.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text ltx_font_typewriter">Kumar et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text ltx_font_typewriter">
Kumar, K.N., Mohan, C.K., Cenkeramaddi, L.R., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text ltx_font_typewriter">The impact of adversarial attacks on federated learning: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text ltx_font_typewriter">IEEE Transactions on Pattern Analysis and Machine Intelligence , 1--20.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.4.4.1" class="ltx_text ltx_font_typewriter">Kuo and Pham [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.6.1" class="ltx_text ltx_font_typewriter">
Kuo, T.T., Pham, A., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text ltx_font_typewriter">Detecting model misconducts in decentralized healthcare federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text ltx_font_typewriter">International journal of medical informatics 158, 104658.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.4.4.1" class="ltx_text ltx_font_typewriter">LeCun and Cortes [2010]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text ltx_font_typewriter">
LeCun, Y., Cortes, C., 2010.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text ltx_font_typewriter">MNIST handwritten digit database .
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text ltx_font_typewriter">Li et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text ltx_font_typewriter">
Li, L., Xu, W., Chen, T., Giannakis, G.B., Ling, Q., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text ltx_font_typewriter">RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text ltx_font_typewriter">Proceedings of the AAAI Conference on Artificial Intelligence 33, 1544--1551.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text ltx_font_typewriter">Li et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text ltx_font_typewriter">
Li, S., Cheng, Y., Wang, W., Liu, Y., Chen, T., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text ltx_font_typewriter">Learning to Detect Malicious Clients for Robust Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2002.00211.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text ltx_font_typewriter">Liu et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text ltx_font_typewriter">
Liu, P., Xu, X., Wang, W., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text ltx_font_typewriter">Threats, attacks and defenses to federated learning: issues, taxonomy and perspectives.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text ltx_font_typewriter">Cybersecurity 5, 1--19.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text ltx_font_typewriter">Lyu et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text ltx_font_typewriter">
Lyu, L., Yu, H., Ma, X., Chen, C., Sun, L., Zhao, J., Yang, Q., Yu, P.S., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text ltx_font_typewriter">Privacy and Robustness in Federated Learning: Attacks and Defenses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text ltx_font_typewriter">IEEE Transactions on Neural Networks and Learning Systems , 1--21.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.4.4.1" class="ltx_text ltx_font_typewriter">Merkel [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text ltx_font_typewriter">
Merkel, D., 2014.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text ltx_font_typewriter">Docker: Lightweight linux containers for consistent development and deployment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://doi.org/10.1016/B978-0-12-800729-7.00004-2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/B978-0-12-800729-7.00004-2</a><span id="bib.bib38.9.2" class="ltx_text ltx_font_typewriter">. accessed: 2024-07-09.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text ltx_font_typewriter">Mhamdi et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text ltx_font_typewriter">
Mhamdi, E.M.E., Guerraoui, R., Rouault, S., 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text ltx_font_typewriter">The Hidden Vulnerability of Distributed Learning in Byzantium.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text ltx_font_typewriter">arXiv preprint arXiv:1802.07927 .
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text ltx_font_typewriter">Mothukuri et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text ltx_font_typewriter">
Mothukuri, V., Parizi, R.M., Pouriyeh, S., Huang, Y., Dehghantanha, A., Srivastava, G., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text ltx_font_typewriter">A survey on security and privacy of federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text ltx_font_typewriter">Future Generation Computer Systems 115, 619--640.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text ltx_font_typewriter">Muñoz-Gonzalez et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text ltx_font_typewriter">
Muñoz-Gonzalez, L., Co, K.T., Lupu, E.C., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text ltx_font_typewriter">Byzantine-Robust Federated Machine Learning through Adaptive Model Averaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1909.05125.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text ltx_font_typewriter">Nair et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text ltx_font_typewriter">
Nair, A.K., Raj, E.D., Sahoo, J., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text ltx_font_typewriter">A robust analysis of adversarial attacks on federated learning environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text ltx_font_typewriter">Computer Standards &amp; Interfaces 86, 103723.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text ltx_font_typewriter">Nguyen et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text ltx_font_typewriter">
Nguyen, T., Rieger, P., Chen, H., Yalame, H., Möllering, H., Fereidooni, H., Marchal, S., Miettinen, M., Mirhoseini, A., Zeitouni, S., Koushanfar, F., Sadeghi, A., Schneider, T., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text ltx_font_typewriter">FLAME: Taming Backdoors in Federated Learning.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text ltx_font_typewriter">Nguyen et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text ltx_font_typewriter">
Nguyen, T.D., Nguyen, T., Nguyen, P.L., Pham, H.H., Doan, K., Wong, K.S., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text ltx_font_typewriter">Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2303.02213.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text ltx_font_typewriter">Nguyen et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text ltx_font_typewriter">
Nguyen, T.D., Rieger, P., Miettinen, M., Sadeghi, A.R., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text ltx_font_typewriter">Poisoning attacks on federated learning-based iot intrusion detection system, in: Proc. Workshop Decentralized IoT Syst. Secur.(DISS).
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text ltx_font_typewriter">Ozdayi et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text ltx_font_typewriter">
Ozdayi, M.S., Kantarcioglu, M., Gel, Y.R., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text ltx_font_typewriter">Defending against Backdoors in Federated Learning with Robust Learning Rate.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text ltx_font_typewriter">Proceedings of the AAAI Conference on Artificial Intelligence 35, 9268--9276.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text ltx_font_typewriter">Paszke et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text ltx_font_typewriter">
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text ltx_font_typewriter">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://arxiv.org/abs/1912.01703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1912.01703</a><span id="bib.bib47.10.2" class="ltx_text ltx_font_typewriter">, </span><a target="_blank" href="http://arxiv.org/abs/1912.01703" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1912.01703</a><span id="bib.bib47.11.3" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text ltx_font_typewriter">Pillutla et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text ltx_font_typewriter">
Pillutla, K., Kakade, S.M., Harchaoui, Z., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text ltx_font_typewriter">Robust Aggregation for Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1912.13445.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text ltx_font_typewriter">Qammar et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text ltx_font_typewriter">
Qammar, A., Ding, J., Ning, H., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text ltx_font_typewriter">Federated learning attack surface: taxonomy, cyber defences, challenges, and future directions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text ltx_font_typewriter">Artificial Intelligence Review , 1--38.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.4.4.1" class="ltx_text ltx_font_typewriter">Research [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text ltx_font_typewriter">
Research, G., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text ltx_font_typewriter">Federated Learning: Collaborative Machine Learning without Centralized Training Data.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text ltx_font_typewriter">Rieger et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text ltx_font_typewriter">
Rieger, P., Nguyen, T., Miettinen, M., Sadeghi, A., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text ltx_font_typewriter">DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection, in: Proceedings Network and Distributed System Security Symposium.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text ltx_font_typewriter">Rodríguez-Barroso et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text ltx_font_typewriter">
Rodríguez-Barroso, N., Jimenez-López, D., Luzón, M.V., Herrera, F., Martínez-Camara, E., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text ltx_font_typewriter">Survey on Federated Learning Threats: Concepts, Taxonomy on Attacks and Defences, Experimental Study and Challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text ltx_font_typewriter">Information Fusion 90, 148--173.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.4.4.1" class="ltx_text ltx_font_typewriter">Shejwalkar and Houmansadr [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.6.1" class="ltx_text ltx_font_typewriter">
Shejwalkar, V., Houmansadr, A., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text ltx_font_typewriter">Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning, in: Proceedings 2021 Network and Distributed System Security Symposium.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text ltx_font_typewriter">Silva et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text ltx_font_typewriter">
Silva, P.R., Vinagre, J., Gama, J., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.8.1" class="ltx_text ltx_font_typewriter">Towards Federated Learning: An Overview of Methods and Applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.9.1" class="ltx_text ltx_font_typewriter">WIREs Data Mining and Knowledge Discovery .
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.5.5.1" class="ltx_text ltx_font_typewriter">Sun et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text ltx_font_typewriter">
Sun, Z., Kairouz, P., Suresh, A.T., McMahan, H.B., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.8.1" class="ltx_text ltx_font_typewriter">Can You Really Backdoor Federated Learning?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1911.07963.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text ltx_font_typewriter">Sánchez Sánchez et al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text ltx_font_typewriter">
Sánchez Sánchez, P.M., Huertas Celdrán, A., Xie, N., Bovet, G., Martínez Pérez, G., Stiller, B., 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text ltx_font_typewriter">Federatedtrust: A solution for trustworthy federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.9.1" class="ltx_text ltx_font_typewriter">Future Generation Computer Systems 152, 83--98.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.10.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0167739X23003886" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0167739X23003886</a><span id="bib.bib56.11.2" class="ltx_text ltx_font_typewriter">, doi:</span><a target="_blank" href="https:/doi.org/https://doi.org/10.1016/j.future.2023.10.013" title="" class="ltx_ref ltx_font_typewriter">https://doi.org/10.1016/j.future.2023.10.013</a><span id="bib.bib56.12.3" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text ltx_font_typewriter">Tian et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text ltx_font_typewriter">
Tian, Z., Cui, L., Liang, J., Yu, S., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text ltx_font_typewriter">A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.9.1" class="ltx_text ltx_font_typewriter">ACM Computing Surveys 55, 1--35.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.4.4.1" class="ltx_text ltx_font_typewriter">U.S. Department of Health and Human Services [1996]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.6.1" class="ltx_text ltx_font_typewriter">
U.S. Department of Health and Human Services, 1996.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text ltx_font_typewriter">Health insurance portability and accountability act of 1996 (hipaa).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.8.1" class="ltx_text ltx_font_typewriter">URL: </span><a target="_blank" href="https://www.hhs.gov/hipaa/for-professionals/privacy/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.hhs.gov/hipaa/for-professionals/privacy/index.html</a><span id="bib.bib58.9.2" class="ltx_text ltx_font_typewriter">. Last Visit July 2024.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text ltx_font_typewriter">Wang et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text ltx_font_typewriter">
Wang, Z., Kang, Q., Zhang, X., Hu, Q., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.8.1" class="ltx_text ltx_font_typewriter">Defense strategies toward model poisoning attacks in federated learning: A survey, in: 2022 IEEE Wireless Communications and Networking Conference (WCNC), pp. 548--553.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.4.4.1" class="ltx_text ltx_font_typewriter">Watts and Strogatz [1998]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.6.1" class="ltx_text ltx_font_typewriter">
Watts, D.J., Strogatz, S.H., 1998.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text ltx_font_typewriter">Collective dynamics of ‘small-world’networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text ltx_font_typewriter">nature 393, 440--442.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.5.5.1" class="ltx_text ltx_font_typewriter">Wu et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.7.1" class="ltx_text ltx_font_typewriter">
Wu, C., Yang, X., Zhu, S., Mitra, P., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.8.1" class="ltx_text ltx_font_typewriter">Mitigating Backdoor Attacks in Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2011.01767.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.5.5.1" class="ltx_text ltx_font_typewriter">Xia et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.7.1" class="ltx_text ltx_font_typewriter">
Xia, G., Chen, J., Yu, C., Ma, J., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.8.1" class="ltx_text ltx_font_typewriter">Poisoning Attacks in Federated Learning: A Survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.9.1" class="ltx_text ltx_font_typewriter">IEEE Access 11, 10708--10722.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.5.5.1" class="ltx_text ltx_font_typewriter">Xiao et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.7.1" class="ltx_text ltx_font_typewriter">
Xiao, H., Rasul, K., Vollgraf, R., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.8.1" class="ltx_text ltx_font_typewriter">Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1708.07747 [cs, stat].
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.5.5.1" class="ltx_text ltx_font_typewriter">Xie et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.7.1" class="ltx_text ltx_font_typewriter">
Xie, C., Huang, K., Chen, P.Y., Li, B., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.8.1" class="ltx_text ltx_font_typewriter">Dba: Distributed backdoor attacks against federated learning, in: International conference on learning representations.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.5.5.1" class="ltx_text ltx_font_typewriter">Xie et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.7.1" class="ltx_text ltx_font_typewriter">
Xie, C., Koyejo, S., Gupta, I., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.8.1" class="ltx_text ltx_font_typewriter">Zeno++: Robust Fully Asynchronous SGD.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.9.1" class="ltx_text ltx_font_typewriter">ArXiv:1903.07020 [cs, stat].
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.5.5.1" class="ltx_text ltx_font_typewriter">Yin et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.7.1" class="ltx_text ltx_font_typewriter">
Yin, D., Chen, Y., Kannan, R., Bartlett, P., 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.8.1" class="ltx_text ltx_font_typewriter">Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates, in: Proceedings of the 35th international conference on machine learning, pp. 5650--5659.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.5.5.1" class="ltx_text ltx_font_typewriter">Yin et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.7.1" class="ltx_text ltx_font_typewriter">
Yin, J., Cui, X., Li, K., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.8.1" class="ltx_text ltx_font_typewriter">A Reputation-Based Resilient and Recoverable P2P Botnet, in: 2017 IEEE Second International Conference on Data Science in Cyberspace (DSC), pp. 275--282.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.5.5.1" class="ltx_text ltx_font_typewriter">Yoo et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.7.1" class="ltx_text ltx_font_typewriter">
Yoo, J.H., Jeong, H., Lee, J., Chung, T.M., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.8.1" class="ltx_text ltx_font_typewriter">Federated learning: Issues in medical application, in: Future Data and Security Engineering: 8th International Conference, FDSE 2021, Virtual Event, November 24--26, 2021, Proceedings 8, Springer. pp. 3--22.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.5.5.1" class="ltx_text ltx_font_typewriter">Zhang et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.7.1" class="ltx_text ltx_font_typewriter">
Zhang, J., Li, M., Zeng, S., Xie, B., Zhao, D., 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.8.1" class="ltx_text ltx_font_typewriter">A survey on security and privacy threats to federated learning, in: 2021 International Conference on Networking and Network Applications (NaNA), pp. 319--326.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.5.5.1" class="ltx_text ltx_font_typewriter">Zhang et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.7.1" class="ltx_text ltx_font_typewriter">
Zhang, Y., Zeng, D., Luo, J., Xu, Z., King, I., 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.8.1" class="ltx_text ltx_font_typewriter">A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2302.10637 [cs].
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.5.5.1" class="ltx_text ltx_font_typewriter">Zhang et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.7.1" class="ltx_text ltx_font_typewriter">
Zhang, Z., Cao, X., Jia, J., Gong, N.Z., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.8.1" class="ltx_text ltx_font_typewriter">FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.9.1" class="ltx_text ltx_font_typewriter">ArXiv:2207.09209 [cs].
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.5.5.1" class="ltx_text ltx_font_typewriter">Zhao et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.7.1" class="ltx_text ltx_font_typewriter">
Zhao, B., Sun, P., Wang, T., Jiang, K., 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.8.1" class="ltx_text ltx_font_typewriter">FedInv: Byzantine-Robust Federated Learning by Inversing Local Model Updates.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.9.1" class="ltx_text ltx_font_typewriter">Proceedings of the AAAI Conference on Artificial Intelligence 36, 9171--9179.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.10.1" class="ltx_text ltx_font_typewriter">Number: 8.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.5.5.1" class="ltx_text ltx_font_typewriter">Zhao et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.7.1" class="ltx_text ltx_font_typewriter">
Zhao, Y., Chen, J., Zhang, J., Wu, D., Teng, J., Yu, S., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.8.1" class="ltx_text ltx_font_typewriter">PDGAN: A Novel Poisoning Defense Method in Federated Learning Using Generative Adversarial Network, in: Algorithms and Architectures for Parallel Processing.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.08651" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.08652" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.08652">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.08652" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.08653" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 13:11:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
