<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.02253] Advancing Post-OCR Correction: A Comparative Study of Synthetic Data</title><meta property="og:description" content="This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on modeâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advancing Post-OCR Correction: A Comparative Study of Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advancing Post-OCR Correction: A Comparative Study of Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.02253">

<!--Generated on Thu Sep  5 15:17:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Advancing Post-OCR Correction: 
<br class="ltx_break">A Comparative Study of Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shuhao Guan, Derek Greene 
<br class="ltx_break">Insight Centre for Data Analytics, Dublin 
<br class="ltx_break">School of Computer Science, University College Dublin, Ireland 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">shuhao.guan@ucdconnect.ie, derek.greene@ucd.ie</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p"><span id="id2.id1.1" class="ltx_text">This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages computer vision feature detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several low-resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually annotated data, and our proposed synthetic data generation method shows advantages over traditional methods, particularly in low-resource languages<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code and data are available at <a target="_blank" href="https://github.com/NikoGuan/P_OCR" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/NikoGuan/P_OCR</a></span></span></span>.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Digital libraries, like the Internet Archive, offer a vast collection of historical and culturally important books in image formats, including works written in low-resource and endangered languages. However, their image-only format limits content accessibility, hindering the use of these essential resources.
Therefore, Optical Character Recognition (OCR) technologies are evidently useful in this context. However, OCR outputs frequently contain errors, particularly when working with texts featuring complex styles, archaic fonts, or unconventional layouts. These errors may include character recognition mistakes, formatting issues, and hyphenation problems, which are particularly prominent when dealing with low-resource languages <cite class="ltx_cite ltx_citemacro_cite">Ignat etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. Poor quality OCR can reduce the usefulness of these digital texts, adversely affecting downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(LinharesÂ Pontes etÂ al., <a href="#bib.bib41" title="" class="ltx_ref">2019</a>; Koudoro-Parfait etÂ al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Post-OCR correction is crucial for multiple reasons, including cultural heritage preservation <cite class="ltx_cite ltx_citemacro_cite">Jarlbrink and Snickars (<a href="#bib.bib29" title="" class="ltx_ref">2017</a>)</cite>, expanding the accessibility of knowledge and information <cite class="ltx_cite ltx_citemacro_cite">Bazzo etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, and supporting further downstream tasks in cultural analytics <cite class="ltx_cite ltx_citemacro_cite">Stubbs (<a href="#bib.bib60" title="" class="ltx_ref">1996</a>)</cite>. Additionally, accurate historical text data is extremely important for training large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">Bubeck etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>, which require high-quality data to improve their ability to handle complex queries, especially those involving history and culture.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Crowdsourcing has been the primary approach to acquire post-OCR training data in this domain <cite class="ltx_cite ltx_citemacro_cite">Clematide etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2016</a>); Richter etÂ al. (<a href="#bib.bib52" title="" class="ltx_ref">2018</a>); Maheshwari etÂ al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>. While this can provide highly accurate training data, the process is often time consuming and expensive. With the advent of Transformer architecture and attention mechanisms <cite class="ltx_cite ltx_citemacro_cite">Vaswani etÂ al. (<a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite>, deep learning models have emerged as the standard approach for post-OCR tasks. These models require large amounts of data for training. Thus, synthetic data has been increasingly adopted in this context. <cite class="ltx_cite ltx_citemacro_cite">Dâ€™hondt etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>); Davydkin etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>); Jasonarson etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>. However, most existing literature on generating synthetic data relies on additional existing data for generation, and no comprehensive comparison has been made between different methods to understand how the synthetic data generated in various ways affects post-OCR performance.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address these issues, this paper explores the impact of data volume and data augmentation methods on the performance of post-OCR models. We examine several common methods for creating synthetic data in the post-OCR domain and propose a novel method based on feature detection algorithms from computer vision to calculate glyph similarity for synthetic data construction. We conduct experiments on eight languages, including several low-resource languages, achieving significant CER reductions ranging from 12.41% to 48.18%.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Popular OCR systems include the Google Vision API OCR system <cite class="ltx_cite ltx_citemacro_cite">Fujii etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite> and the Tesseract OCR engine <cite class="ltx_cite ltx_citemacro_cite">Smith (<a href="#bib.bib57" title="" class="ltx_ref">2007</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Jatowt etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> performed statistical analysis on the types of errors commonly produced by OCR systems.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Post-OCR correction, while often overlooked, is an important NLP task. Lexical approaches to post-correction concentrate on character and word level inaccuracies, primarily employing dictionaries and heuristic rules. <cite class="ltx_cite ltx_citemacro_citet">Bassil and Alwani (<a href="#bib.bib4" title="" class="ltx_ref">2012</a>)</cite> exploited Googleâ€™s search suggestions for context-based corrections, circumventing the need for exhaustive dictionaries. Strategies specific to certain domains, such as those proposed by <cite class="ltx_cite ltx_citemacro_citet">Furrer and Volk (<a href="#bib.bib20" title="" class="ltx_ref">2011</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Estrella and Paliza (<a href="#bib.bib17" title="" class="ltx_ref">2014</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citet">Kettunen (<a href="#bib.bib33" title="" class="ltx_ref">2016</a>)</cite>, highlight the necessity of tailored dictionaries for texts that possess unique features, like historical typefaces. <cite class="ltx_cite ltx_citemacro_citet">Wemhoener etÂ al. (<a href="#bib.bib64" title="" class="ltx_ref">2013</a>)</cite> focused on aligning and merging outputs from various scans, including those from different editions, to rectify errors.
Recent studies have framed post-OCR tasks as Seq2Seq tasks, with researchers applying both Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) models <cite class="ltx_cite ltx_citemacro_citep">(Amrhein and Clematide, <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Nguyen etÂ al. (<a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Soper etÂ al. (<a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite> employed BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite> and BART <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite> models, respectively. <cite class="ltx_cite ltx_citemacro_citet">Maheshwari etÂ al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> conducted a comparison between pre-trained models and traditional Seq2Seq models, with their findings indicating that pre-trained models like ByT5 <cite class="ltx_cite ltx_citemacro_cite">Xue etÂ al. (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite> outperform the conventional models. <cite class="ltx_cite ltx_citemacro_citet">Ramirez-Orta etÂ al. (<a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> segmented documents into character n-grams, before aggregating their corrections into the final output via majority voting <cite class="ltx_cite ltx_citemacro_cite">Lam and Suen (<a href="#bib.bib38" title="" class="ltx_ref">1997</a>)</cite>, essentially acting as an ensemble of sequence models.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Data is fundamental to the success of deep learning, as an increasing amount of research is directed towards leveraging data-driven strategies. These strategies aim to significantly improve model performance by optimizing data usage, rather than modifying the underlying model structure <cite class="ltx_cite ltx_citemacro_cite">Tarafdar etÂ al. (<a href="#bib.bib62" title="" class="ltx_ref">2019</a>); Mazumder etÂ al. (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>. These efforts often involve generating large quantities of synthetic data <cite class="ltx_cite ltx_citemacro_cite">Choi and Park (<a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, involving data manipulation measures like filtering <cite class="ltx_cite ltx_citemacro_cite">Koehn etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>, data augmentation <cite class="ltx_cite ltx_citemacro_cite">Shorten and Khoshgoftaar (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>); Li etÂ al. (<a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>, and noise injection <cite class="ltx_cite ltx_citemacro_cite">Izumi etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2003</a>)</cite>.
Such synthetic data has been widely used in various NLP tasks, such as grammatical error correction <cite class="ltx_cite ltx_citemacro_cite">IngÃ³lfsdÃ³ttir etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>, language identification <cite class="ltx_cite ltx_citemacro_cite">Ahmadi etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, question answering <cite class="ltx_cite ltx_citemacro_cite">Puri etÂ al. (<a href="#bib.bib49" title="" class="ltx_ref">2020</a>)</cite>, and named entity recognition <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">For the task of text denoising, the primary method for constructing synthetic data is noise injection <cite class="ltx_cite ltx_citemacro_cite">Izumi etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2003</a>)</cite>. This technique involves inserting errors into clean text to generate training data pairs. <cite class="ltx_cite ltx_citemacro_citet">Dâ€™hondt etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite> added artificial OCR errors into sentences using a random process, while <cite class="ltx_cite ltx_citemacro_citet">Jasonarson etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> focused on the low-resource Icelandic language for post-OCR tasks. The authors extracted OCR errors from real digitised documents and inserting them into clean text in similar proportions. <cite class="ltx_cite ltx_citemacro_citet">Grundkiewicz etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> analyzed real data to create replacement sets for each word. <cite class="ltx_cite ltx_citemacro_citet">Davydkin etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite> adopted a different approach, developing a system to generate handwritten image data which were then processed with OCR. The resulting OCR outputs and the original texts were subsequently used to train a T5 model <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> for correction purposes. <cite class="ltx_cite ltx_citemacro_citet">Ignat etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite> synthesized text image datasets by manipulating parameters, like font spacing and image saturation, then compare the original text with the OCR output text, to evaluate OCR systemsâ€™ performance on various low-resource languages, and they enhanced Machine Translation (MT) through backtranslation <cite class="ltx_cite ltx_citemacro_cite">Sennrich etÂ al. (<a href="#bib.bib55" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Some studies have explored improving post-OCR text correction by analyzing the visual forms of characters, known as glyphs. <cite class="ltx_cite ltx_citemacro_citet">Chen and Zhou (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite> attempting to use the CharBERT model <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> for post-OCR. Their method consists of two parallel CNN encoders and a transformer decoder, taking CharBERT and glyph embedding as inputs. <cite class="ltx_cite ltx_citemacro_citet">Amrhein and Clematide (<a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite>â€™s experiment included NMT models and glyph embedding, but it did not enhance model performance. Other research has focused on the detection of homoglyphs, with <cite class="ltx_cite ltx_citemacro_citet">Ginsberg and Yu (<a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite> employing a grid method to assess the similarity of glyphs by counting the number of overlapping grids between characters. The similarity of glyphs is actually based on visual features. In the field of computer vision, feature detection and matching algorithms, such as SIFT <cite class="ltx_cite ltx_citemacro_cite">Ng and Henikoff (<a href="#bib.bib47" title="" class="ltx_ref">2003</a>)</cite>, ORB <cite class="ltx_cite ltx_citemacro_cite">Rublee etÂ al. (<a href="#bib.bib54" title="" class="ltx_ref">2011</a>)</cite>, and AKAZE <cite class="ltx_cite ltx_citemacro_cite">Alcantarilla and Solutions (<a href="#bib.bib2" title="" class="ltx_ref">2011</a>)</cite> can extract feature points from an image and match them with those appearing in other images.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">We now describe three common methods for generating synthetic data in the post-OCR domain, before introducing a new method based on <span id="S3.p1.2.1" class="ltx_text ltx_font_italic">glyph similarity</span> in Section <a href="#S3.SS4" title="3.4 Method â‘£ Glyph Similarity â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>. Each method makes use of a clean corpus <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">A</annotation></semantics></math>. As a common preprocessing step, we segment <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">A</annotation></semantics></math> into multiple chunks by initially dividing sentences based on punctuation marks and then concatenating these sentences, ensuring that the total length of each chunk does not exceed a fixed limit of 230 characters, with the exception of Russian and Telugu, where the limits are 140 and 90 characters, respectively.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Method <math id="S3.SS1.1.m1.1" class="ltx_Math" alttext="â‘ " display="inline"><semantics id="S3.SS1.1.m1.1b"><mn id="S3.SS1.1.m1.1.1" xref="S3.SS1.1.m1.1.1.cmml">â‘ </mn><annotation-xml encoding="MathML-Content" id="S3.SS1.1.m1.1c"><cn type="float" id="S3.SS1.1.m1.1.1.cmml" xref="S3.SS1.1.m1.1.1">circled-1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.1.m1.1d">â‘ </annotation></semantics></math> Random Injection</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">The random injection method <cite class="ltx_cite ltx_citemacro_cite">Dâ€™hondt etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite> generates a synthetic OCR corpus <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mover accent="true" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">A</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><ci id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">^</ci><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\hat{A}</annotation></semantics></math> by randomly inserting errors into an existing clean corpus <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">A</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.6" class="ltx_p">First, we filter out infrequently occurring characters in <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">A</annotation></semantics></math>, as the corpus may inevitably contain some noise. The remaining characters are used for replacements and insertions.
Next, for each chunk from <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">A</annotation></semantics></math>, we randomly select a target error rate <math id="S3.SS1.p2.3.m3.2" class="ltx_Math" alttext="p\in[0,15]" display="inline"><semantics id="S3.SS1.p2.3.m3.2a"><mrow id="S3.SS1.p2.3.m3.2.3" xref="S3.SS1.p2.3.m3.2.3.cmml"><mi id="S3.SS1.p2.3.m3.2.3.2" xref="S3.SS1.p2.3.m3.2.3.2.cmml">p</mi><mo id="S3.SS1.p2.3.m3.2.3.1" xref="S3.SS1.p2.3.m3.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS1.p2.3.m3.2.3.3.2" xref="S3.SS1.p2.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.3.m3.2.3.3.2.1" xref="S3.SS1.p2.3.m3.2.3.3.1.cmml">[</mo><mn id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">0</mn><mo id="S3.SS1.p2.3.m3.2.3.3.2.2" xref="S3.SS1.p2.3.m3.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p2.3.m3.2.2" xref="S3.SS1.p2.3.m3.2.2.cmml">15</mn><mo stretchy="false" id="S3.SS1.p2.3.m3.2.3.3.2.3" xref="S3.SS1.p2.3.m3.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.2b"><apply id="S3.SS1.p2.3.m3.2.3.cmml" xref="S3.SS1.p2.3.m3.2.3"><in id="S3.SS1.p2.3.m3.2.3.1.cmml" xref="S3.SS1.p2.3.m3.2.3.1"></in><ci id="S3.SS1.p2.3.m3.2.3.2.cmml" xref="S3.SS1.p2.3.m3.2.3.2">ğ‘</ci><interval closure="closed" id="S3.SS1.p2.3.m3.2.3.3.1.cmml" xref="S3.SS1.p2.3.m3.2.3.3.2"><cn type="integer" id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">0</cn><cn type="integer" id="S3.SS1.p2.3.m3.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2">15</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.2c">p\in[0,15]</annotation></semantics></math>, which controls the level of noise to be introduced. According to the analysis by <cite class="ltx_cite ltx_citemacro_citet">Jatowt etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite>, the average rate of OCR errors involving substitution, insertion, and deletion is approximately 5:1:1. Therefore, in our implementation, each character has a probability of <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\frac{5}{7}\times p" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mfrac id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml"><mn id="S3.SS1.p2.4.m4.1.1.2.2" xref="S3.SS1.p2.4.m4.1.1.2.2.cmml">5</mn><mn id="S3.SS1.p2.4.m4.1.1.2.3" xref="S3.SS1.p2.4.m4.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">Ã—</mo><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><times id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></times><apply id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2"><divide id="S3.SS1.p2.4.m4.1.1.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2"></divide><cn type="integer" id="S3.SS1.p2.4.m4.1.1.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2.2">5</cn><cn type="integer" id="S3.SS1.p2.4.m4.1.1.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3">7</cn></apply><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\frac{5}{7}\times p</annotation></semantics></math> of being replaced by a random character and a probability of <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\frac{1}{7}\times p" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mfrac id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml"><mn id="S3.SS1.p2.5.m5.1.1.2.2" xref="S3.SS1.p2.5.m5.1.1.2.2.cmml">1</mn><mn id="S3.SS1.p2.5.m5.1.1.2.3" xref="S3.SS1.p2.5.m5.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">Ã—</mo><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><times id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></times><apply id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2"><divide id="S3.SS1.p2.5.m5.1.1.2.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2"></divide><cn type="integer" id="S3.SS1.p2.5.m5.1.1.2.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.2">1</cn><cn type="integer" id="S3.SS1.p2.5.m5.1.1.2.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3">7</cn></apply><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\frac{1}{7}\times p</annotation></semantics></math> of being deleted. Additionally, any two characters have a probability of <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="\frac{1}{7}\times p" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mfrac id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml"><mn id="S3.SS1.p2.6.m6.1.1.2.2" xref="S3.SS1.p2.6.m6.1.1.2.2.cmml">1</mn><mn id="S3.SS1.p2.6.m6.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml">Ã—</mo><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><times id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"></times><apply id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2"><divide id="S3.SS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1.2"></divide><cn type="integer" id="S3.SS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2">1</cn><cn type="integer" id="S3.SS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.3">7</cn></apply><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\frac{1}{7}\times p</annotation></semantics></math> of having a random character inserted between them.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Method <math id="S3.SS2.1.m1.1" class="ltx_Math" alttext="â‘¡" display="inline"><semantics id="S3.SS2.1.m1.1b"><mn id="S3.SS2.1.m1.1.1" xref="S3.SS2.1.m1.1.1.cmml">â‘¡</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.1.m1.1c"><cn type="float" id="S3.SS2.1.m1.1.1.cmml" xref="S3.SS2.1.m1.1.1">circled-2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.1.m1.1d">â‘¡</annotation></semantics></math> Image Creation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">Following some OCR-related studies that add noise to text images <cite class="ltx_cite ltx_citemacro_cite">Jaderberg etÂ al. (<a href="#bib.bib28" title="" class="ltx_ref">2014</a>); Krishna etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">2018</a>); Boros etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite>, we also investigate the simulation of real-world correction scenarios by creating synthetic text images. Specifically, each chunk from corpus <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">A</annotation></semantics></math> is used to create a separate image which is manipulated to add OCR-like noise. These images are then processed through a standard OCR system to obtain <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mover accent="true" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">A</mi><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><ci id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1">^</ci><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\hat{A}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p">The complete procedure is as follows. Initially, for every text chunk, a random font from the set <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">F</annotation></semantics></math>, which matches the language of corpus <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">A</annotation></semantics></math>, is chosen.
Then, the text from each chunk is converted into an image. These images are subjected to random rotations of <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\pm 5" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mo id="S3.SS2.p2.3.m3.1.1a" xref="S3.SS2.p2.3.m3.1.1.cmml">Â±</mo><mn id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">plus-or-minus</csymbol><cn type="integer" id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\pm 5</annotation></semantics></math> degrees, followed by the insertion of random noise pixels. Following this, the images undergo random dilation and erosion to simulate text variability, and their resolution are randomly reduced within a range of 0 to 50%. At the end of this process, the chosen OCR system is applied for text recognition, resulting in the output <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mover accent="true" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">A</mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><ci id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">^</ci><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\hat{A}</annotation></semantics></math>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2408.02253/assets/image/2.jpg" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="198" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples of synthetic OCR images in various languages, generated using the process in Section <a href="#S3.SS2" title="3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">Figure <a href="#S3.F1" title="Figure 1 â€£ 3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows sample synthesized images with noise generated using this process, for several different languages. Although synthetic images are used, this method simulates the OCR process under real-world conditions,
the output text is derived from the OCR system, hence we consider it to be representative of authentic OCR text.The corpora <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">A</annotation></semantics></math> and <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mover accent="true" id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">A</mi><mo id="S3.SS2.p3.2.m2.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><ci id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1">^</ci><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\hat{A}</annotation></semantics></math> can be used to construct test sets, training sets, or to extract distributions of OCR errors.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2408.02253/assets/image/3.jpg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Visualizations of feature matching using ORB for fonts from different character sets, where matched feature points connected by colored lines. For each pair of characters, two numbers are displayed: the upper number represents the Jaccard Index <math id="S3.F2.3.m1.1" class="ltx_Math" alttext="J" display="inline"><semantics id="S3.F2.3.m1.1b"><mi id="S3.F2.3.m1.1.1" xref="S3.F2.3.m1.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.F2.3.m1.1c"><ci id="S3.F2.3.m1.1.1.cmml" xref="S3.F2.3.m1.1.1">ğ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.3.m1.1d">J</annotation></semantics></math> of overlapping feature points, and the lower number indicates the average distance <math id="S3.F2.4.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.F2.4.m2.1b"><mi id="S3.F2.4.m2.1.1" xref="S3.F2.4.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.F2.4.m2.1c"><ci id="S3.F2.4.m2.1.1.cmml" xref="S3.F2.4.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m2.1d">D</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Method <math id="S3.SS3.1.m1.1" class="ltx_Math" alttext="â‘¢" display="inline"><semantics id="S3.SS3.1.m1.1b"><mn id="S3.SS3.1.m1.1.1" xref="S3.SS3.1.m1.1.1.cmml">â‘¢</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.1.m1.1c"><cn type="float" id="S3.SS3.1.m1.1.1.cmml" xref="S3.SS3.1.m1.1.1">circled-3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.1.m1.1d">â‘¢</annotation></semantics></math> Real-World Injection</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Several studies have considered the generation of synthetic data through the analysis of error distributions in existing datasets. The primary approach involves embedding OCR errors into the data at rates mirroring their occurrence in real-world settings <cite class="ltx_cite ltx_citemacro_citep">(Dâ€™hondt etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2017</a>; Grundkiewicz etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2019</a>; Jasonarson etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>. This strategy addresses the discrepancies between existing datasets and actual application domains, offering more control over the quality of the generated text.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.9" class="ltx_p">To obtain a realistic OCR error distribution, in this work we use additional clean corpus <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">C</annotation></semantics></math> coming from the same domain and apply the method described in Section <a href="#S3.SS2" title="3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> to obtain OCR-processed corpus <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="\hat{C}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mover accent="true" id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">C</mi><mo id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><ci id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1">^</ci><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\hat{C}</annotation></semantics></math>. Subsequently, the Recursive Text Alignment Scheme (RETAS) <cite class="ltx_cite ltx_citemacro_cite">Yalniz and Manmatha (<a href="#bib.bib67" title="" class="ltx_ref">2011</a>)</cite> is employed to perform the automatic alignment of the OCR text and the original clean text, allowing us to extract the probabilities for character substitution, deletion, and insertion. By adjusting the probability of these errors, we can control the CER of the synthetic data. For instance, if the CER between text <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">C</annotation></semantics></math> and its corresponding OCR version <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\hat{C}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mover accent="true" id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">C</mi><mo id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><ci id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1">^</ci><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">ğ¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\hat{C}</annotation></semantics></math> is <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">p</annotation></semantics></math>, then doubling all of the error probabilities would result in an expected CER of <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="2p" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mrow id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mn id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.1.1.1" xref="S3.SS3.p2.6.m6.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><times id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1"></times><cn type="integer" id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">2</cn><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">2p</annotation></semantics></math> for the newly generated synthetic text. In practice, we set the expected CER for each chunk in <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mi id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><ci id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">A</annotation></semantics></math> to a random value <math id="S3.SS3.p2.8.m8.2" class="ltx_Math" alttext="\in[0,15]" display="inline"><semantics id="S3.SS3.p2.8.m8.2a"><mrow id="S3.SS3.p2.8.m8.2.3" xref="S3.SS3.p2.8.m8.2.3.cmml"><mi id="S3.SS3.p2.8.m8.2.3.2" xref="S3.SS3.p2.8.m8.2.3.2.cmml"></mi><mo id="S3.SS3.p2.8.m8.2.3.1" xref="S3.SS3.p2.8.m8.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p2.8.m8.2.3.3.2" xref="S3.SS3.p2.8.m8.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.8.m8.2.3.3.2.1" xref="S3.SS3.p2.8.m8.2.3.3.1.cmml">[</mo><mn id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">0</mn><mo id="S3.SS3.p2.8.m8.2.3.3.2.2" xref="S3.SS3.p2.8.m8.2.3.3.1.cmml">,</mo><mn id="S3.SS3.p2.8.m8.2.2" xref="S3.SS3.p2.8.m8.2.2.cmml">15</mn><mo stretchy="false" id="S3.SS3.p2.8.m8.2.3.3.2.3" xref="S3.SS3.p2.8.m8.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.2b"><apply id="S3.SS3.p2.8.m8.2.3.cmml" xref="S3.SS3.p2.8.m8.2.3"><in id="S3.SS3.p2.8.m8.2.3.1.cmml" xref="S3.SS3.p2.8.m8.2.3.1"></in><csymbol cd="latexml" id="S3.SS3.p2.8.m8.2.3.2.cmml" xref="S3.SS3.p2.8.m8.2.3.2">absent</csymbol><interval closure="closed" id="S3.SS3.p2.8.m8.2.3.3.1.cmml" xref="S3.SS3.p2.8.m8.2.3.3.2"><cn type="integer" id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">0</cn><cn type="integer" id="S3.SS3.p2.8.m8.2.2.cmml" xref="S3.SS3.p2.8.m8.2.2">15</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.2c">\in[0,15]</annotation></semantics></math> to generate the synthetic data in <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><mover accent="true" id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2" xref="S3.SS3.p2.9.m9.1.1.2.cmml">A</mi><mo id="S3.SS3.p2.9.m9.1.1.1" xref="S3.SS3.p2.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><ci id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1.1">^</ci><ci id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">\hat{A}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Method <math id="S3.SS4.1.m1.1" class="ltx_Math" alttext="â‘£" display="inline"><semantics id="S3.SS4.1.m1.1b"><mn id="S3.SS4.1.m1.1.1" xref="S3.SS4.1.m1.1.1.cmml">â‘£</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.1.m1.1c"><cn type="float" id="S3.SS4.1.m1.1.1.cmml" xref="S3.SS4.1.m1.1.1">circled-4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.1.m1.1d">â‘£</annotation></semantics></math> Glyph Similarity</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.5" class="ltx_p">Given that OCR replacement errors frequently happen between characters with visually similar glyphs <cite class="ltx_cite ltx_citemacro_cite">Jatowt etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite>, we can also use the information from glyph similarities to construct synthetic data. Specifically, we apply the following procedure. Firstly, we filter infrequently appearing characters from the input corpus <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">A</annotation></semantics></math> to form a definitive character set. Based on the analysis of the ICDAR2017 <cite class="ltx_cite ltx_citemacro_cite">Chiron etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> and ICDAR2019 <cite class="ltx_cite ltx_citemacro_cite">Rigaud etÂ al. (<a href="#bib.bib53" title="" class="ltx_ref">2019</a>)</cite> datasets, 1:1 mapping errors, where a single character is incorrectly identified as another character, accounted for 87.9% of all 1:<math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">n</annotation></semantics></math> mapping errors. Here 1:<math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">n</annotation></semantics></math> mapping error refers to cases where a single character be incorrectly recognized as <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">n</annotation></semantics></math> characters. To enhance the computational efficiency of the implementation proposed in this paper, we focus solely on 1:1 errors. Note that simulations of 1:<math id="S3.SS4.p1.5.m5.1" class="ltx_Math" alttext="n\;(n&gt;1)" display="inline"><semantics id="S3.SS4.p1.5.m5.1a"><mrow id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml"><mi id="S3.SS4.p1.5.m5.1.1.3" xref="S3.SS4.p1.5.m5.1.1.3.cmml">n</mi><mo lspace="0.280em" rspace="0em" id="S3.SS4.p1.5.m5.1.1.2" xref="S3.SS4.p1.5.m5.1.1.2.cmml">â€‹</mo><mrow id="S3.SS4.p1.5.m5.1.1.1.1" xref="S3.SS4.p1.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.p1.5.m5.1.1.1.1.2" xref="S3.SS4.p1.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.p1.5.m5.1.1.1.1.1" xref="S3.SS4.p1.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.5.m5.1.1.1.1.1.2" xref="S3.SS4.p1.5.m5.1.1.1.1.1.2.cmml">n</mi><mo id="S3.SS4.p1.5.m5.1.1.1.1.1.1" xref="S3.SS4.p1.5.m5.1.1.1.1.1.1.cmml">&gt;</mo><mn id="S3.SS4.p1.5.m5.1.1.1.1.1.3" xref="S3.SS4.p1.5.m5.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS4.p1.5.m5.1.1.1.1.3" xref="S3.SS4.p1.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><apply id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1"><times id="S3.SS4.p1.5.m5.1.1.2.cmml" xref="S3.SS4.p1.5.m5.1.1.2"></times><ci id="S3.SS4.p1.5.m5.1.1.3.cmml" xref="S3.SS4.p1.5.m5.1.1.3">ğ‘›</ci><apply id="S3.SS4.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1.1.1"><gt id="S3.SS4.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1.1.1.1.1"></gt><ci id="S3.SS4.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.5.m5.1.1.1.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS4.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.5.m5.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">n\;(n&gt;1)</annotation></semantics></math> errors could be achieved through random insertion.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.7" class="ltx_p">For each language, we select a set of appropriate fonts <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mi id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">F</annotation></semantics></math>, which includes a variety of historical and modern fonts, and employ a set of vision feature detection algorithms <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mi id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">Q</annotation></semantics></math> to extract and match image features. In our experiments we consider ORB <cite class="ltx_cite ltx_citemacro_cite">Rublee etÂ al. (<a href="#bib.bib54" title="" class="ltx_ref">2011</a>)</cite>, AKAZE <cite class="ltx_cite ltx_citemacro_cite">Alcantarilla and Solutions (<a href="#bib.bib2" title="" class="ltx_ref">2011</a>)</cite> and SIFT <cite class="ltx_cite ltx_citemacro_cite">Ng and Henikoff (<a href="#bib.bib47" title="" class="ltx_ref">2003</a>)</cite>. For each character <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mi id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">i</annotation></semantics></math> in the character set, we calculate its glyph similarity with every other character <math id="S3.SS4.p2.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS4.p2.4.m4.1a"><mi id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><ci id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">j</annotation></semantics></math> by creating their images using fonts <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><mi id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><ci id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">f</annotation></semantics></math> from the font set <math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><mi id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><ci id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">F</annotation></semantics></math>. We then calculate their similarity under detector <math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><mi id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><ci id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">q</annotation></semantics></math> as:</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.12" class="ltx_Math" alttext="S(i,j,q)=\frac{1}{|F|}\sum_{f\in F}\frac{J(i,j,f,q)}{D(i,j,f,q)}" display="block"><semantics id="S3.Ex1.m1.12a"><mrow id="S3.Ex1.m1.12.13" xref="S3.Ex1.m1.12.13.cmml"><mrow id="S3.Ex1.m1.12.13.2" xref="S3.Ex1.m1.12.13.2.cmml"><mi id="S3.Ex1.m1.12.13.2.2" xref="S3.Ex1.m1.12.13.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.12.13.2.1" xref="S3.Ex1.m1.12.13.2.1.cmml">â€‹</mo><mrow id="S3.Ex1.m1.12.13.2.3.2" xref="S3.Ex1.m1.12.13.2.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.12.13.2.3.2.1" xref="S3.Ex1.m1.12.13.2.3.1.cmml">(</mo><mi id="S3.Ex1.m1.10.10" xref="S3.Ex1.m1.10.10.cmml">i</mi><mo id="S3.Ex1.m1.12.13.2.3.2.2" xref="S3.Ex1.m1.12.13.2.3.1.cmml">,</mo><mi id="S3.Ex1.m1.11.11" xref="S3.Ex1.m1.11.11.cmml">j</mi><mo id="S3.Ex1.m1.12.13.2.3.2.3" xref="S3.Ex1.m1.12.13.2.3.1.cmml">,</mo><mi id="S3.Ex1.m1.12.12" xref="S3.Ex1.m1.12.12.cmml">q</mi><mo stretchy="false" id="S3.Ex1.m1.12.13.2.3.2.4" xref="S3.Ex1.m1.12.13.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.12.13.1" xref="S3.Ex1.m1.12.13.1.cmml">=</mo><mrow id="S3.Ex1.m1.12.13.3" xref="S3.Ex1.m1.12.13.3.cmml"><mfrac id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><mn id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml">1</mn><mrow id="S3.Ex1.m1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.1.1.1.3.1" xref="S3.Ex1.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml">F</mi><mo stretchy="false" id="S3.Ex1.m1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.12.13.3.1" xref="S3.Ex1.m1.12.13.3.1.cmml">â€‹</mo><mrow id="S3.Ex1.m1.12.13.3.2" xref="S3.Ex1.m1.12.13.3.2.cmml"><munder id="S3.Ex1.m1.12.13.3.2.1" xref="S3.Ex1.m1.12.13.3.2.1.cmml"><mo movablelimits="false" id="S3.Ex1.m1.12.13.3.2.1.2" xref="S3.Ex1.m1.12.13.3.2.1.2.cmml">âˆ‘</mo><mrow id="S3.Ex1.m1.12.13.3.2.1.3" xref="S3.Ex1.m1.12.13.3.2.1.3.cmml"><mi id="S3.Ex1.m1.12.13.3.2.1.3.2" xref="S3.Ex1.m1.12.13.3.2.1.3.2.cmml">f</mi><mo id="S3.Ex1.m1.12.13.3.2.1.3.1" xref="S3.Ex1.m1.12.13.3.2.1.3.1.cmml">âˆˆ</mo><mi id="S3.Ex1.m1.12.13.3.2.1.3.3" xref="S3.Ex1.m1.12.13.3.2.1.3.3.cmml">F</mi></mrow></munder><mfrac id="S3.Ex1.m1.9.9" xref="S3.Ex1.m1.9.9.cmml"><mrow id="S3.Ex1.m1.5.5.4" xref="S3.Ex1.m1.5.5.4.cmml"><mi id="S3.Ex1.m1.5.5.4.6" xref="S3.Ex1.m1.5.5.4.6.cmml">J</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.5.5.4.5" xref="S3.Ex1.m1.5.5.4.5.cmml">â€‹</mo><mrow id="S3.Ex1.m1.5.5.4.7.2" xref="S3.Ex1.m1.5.5.4.7.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.5.5.4.7.2.1" xref="S3.Ex1.m1.5.5.4.7.1.cmml">(</mo><mi id="S3.Ex1.m1.2.2.1.1" xref="S3.Ex1.m1.2.2.1.1.cmml">i</mi><mo id="S3.Ex1.m1.5.5.4.7.2.2" xref="S3.Ex1.m1.5.5.4.7.1.cmml">,</mo><mi id="S3.Ex1.m1.3.3.2.2" xref="S3.Ex1.m1.3.3.2.2.cmml">j</mi><mo id="S3.Ex1.m1.5.5.4.7.2.3" xref="S3.Ex1.m1.5.5.4.7.1.cmml">,</mo><mi id="S3.Ex1.m1.4.4.3.3" xref="S3.Ex1.m1.4.4.3.3.cmml">f</mi><mo id="S3.Ex1.m1.5.5.4.7.2.4" xref="S3.Ex1.m1.5.5.4.7.1.cmml">,</mo><mi id="S3.Ex1.m1.5.5.4.4" xref="S3.Ex1.m1.5.5.4.4.cmml">q</mi><mo stretchy="false" id="S3.Ex1.m1.5.5.4.7.2.5" xref="S3.Ex1.m1.5.5.4.7.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.9.9.8" xref="S3.Ex1.m1.9.9.8.cmml"><mi id="S3.Ex1.m1.9.9.8.6" xref="S3.Ex1.m1.9.9.8.6.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.9.9.8.5" xref="S3.Ex1.m1.9.9.8.5.cmml">â€‹</mo><mrow id="S3.Ex1.m1.9.9.8.7.2" xref="S3.Ex1.m1.9.9.8.7.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.9.9.8.7.2.1" xref="S3.Ex1.m1.9.9.8.7.1.cmml">(</mo><mi id="S3.Ex1.m1.6.6.5.1" xref="S3.Ex1.m1.6.6.5.1.cmml">i</mi><mo id="S3.Ex1.m1.9.9.8.7.2.2" xref="S3.Ex1.m1.9.9.8.7.1.cmml">,</mo><mi id="S3.Ex1.m1.7.7.6.2" xref="S3.Ex1.m1.7.7.6.2.cmml">j</mi><mo id="S3.Ex1.m1.9.9.8.7.2.3" xref="S3.Ex1.m1.9.9.8.7.1.cmml">,</mo><mi id="S3.Ex1.m1.8.8.7.3" xref="S3.Ex1.m1.8.8.7.3.cmml">f</mi><mo id="S3.Ex1.m1.9.9.8.7.2.4" xref="S3.Ex1.m1.9.9.8.7.1.cmml">,</mo><mi id="S3.Ex1.m1.9.9.8.4" xref="S3.Ex1.m1.9.9.8.4.cmml">q</mi><mo stretchy="false" id="S3.Ex1.m1.9.9.8.7.2.5" xref="S3.Ex1.m1.9.9.8.7.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.12b"><apply id="S3.Ex1.m1.12.13.cmml" xref="S3.Ex1.m1.12.13"><eq id="S3.Ex1.m1.12.13.1.cmml" xref="S3.Ex1.m1.12.13.1"></eq><apply id="S3.Ex1.m1.12.13.2.cmml" xref="S3.Ex1.m1.12.13.2"><times id="S3.Ex1.m1.12.13.2.1.cmml" xref="S3.Ex1.m1.12.13.2.1"></times><ci id="S3.Ex1.m1.12.13.2.2.cmml" xref="S3.Ex1.m1.12.13.2.2">ğ‘†</ci><vector id="S3.Ex1.m1.12.13.2.3.1.cmml" xref="S3.Ex1.m1.12.13.2.3.2"><ci id="S3.Ex1.m1.10.10.cmml" xref="S3.Ex1.m1.10.10">ğ‘–</ci><ci id="S3.Ex1.m1.11.11.cmml" xref="S3.Ex1.m1.11.11">ğ‘—</ci><ci id="S3.Ex1.m1.12.12.cmml" xref="S3.Ex1.m1.12.12">ğ‘</ci></vector></apply><apply id="S3.Ex1.m1.12.13.3.cmml" xref="S3.Ex1.m1.12.13.3"><times id="S3.Ex1.m1.12.13.3.1.cmml" xref="S3.Ex1.m1.12.13.3.1"></times><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><divide id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1"></divide><cn type="integer" id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3">1</cn><apply id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.3"><abs id="S3.Ex1.m1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.3.1"></abs><ci id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1">ğ¹</ci></apply></apply><apply id="S3.Ex1.m1.12.13.3.2.cmml" xref="S3.Ex1.m1.12.13.3.2"><apply id="S3.Ex1.m1.12.13.3.2.1.cmml" xref="S3.Ex1.m1.12.13.3.2.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.12.13.3.2.1.1.cmml" xref="S3.Ex1.m1.12.13.3.2.1">subscript</csymbol><sum id="S3.Ex1.m1.12.13.3.2.1.2.cmml" xref="S3.Ex1.m1.12.13.3.2.1.2"></sum><apply id="S3.Ex1.m1.12.13.3.2.1.3.cmml" xref="S3.Ex1.m1.12.13.3.2.1.3"><in id="S3.Ex1.m1.12.13.3.2.1.3.1.cmml" xref="S3.Ex1.m1.12.13.3.2.1.3.1"></in><ci id="S3.Ex1.m1.12.13.3.2.1.3.2.cmml" xref="S3.Ex1.m1.12.13.3.2.1.3.2">ğ‘“</ci><ci id="S3.Ex1.m1.12.13.3.2.1.3.3.cmml" xref="S3.Ex1.m1.12.13.3.2.1.3.3">ğ¹</ci></apply></apply><apply id="S3.Ex1.m1.9.9.cmml" xref="S3.Ex1.m1.9.9"><divide id="S3.Ex1.m1.9.9.9.cmml" xref="S3.Ex1.m1.9.9"></divide><apply id="S3.Ex1.m1.5.5.4.cmml" xref="S3.Ex1.m1.5.5.4"><times id="S3.Ex1.m1.5.5.4.5.cmml" xref="S3.Ex1.m1.5.5.4.5"></times><ci id="S3.Ex1.m1.5.5.4.6.cmml" xref="S3.Ex1.m1.5.5.4.6">ğ½</ci><vector id="S3.Ex1.m1.5.5.4.7.1.cmml" xref="S3.Ex1.m1.5.5.4.7.2"><ci id="S3.Ex1.m1.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1">ğ‘–</ci><ci id="S3.Ex1.m1.3.3.2.2.cmml" xref="S3.Ex1.m1.3.3.2.2">ğ‘—</ci><ci id="S3.Ex1.m1.4.4.3.3.cmml" xref="S3.Ex1.m1.4.4.3.3">ğ‘“</ci><ci id="S3.Ex1.m1.5.5.4.4.cmml" xref="S3.Ex1.m1.5.5.4.4">ğ‘</ci></vector></apply><apply id="S3.Ex1.m1.9.9.8.cmml" xref="S3.Ex1.m1.9.9.8"><times id="S3.Ex1.m1.9.9.8.5.cmml" xref="S3.Ex1.m1.9.9.8.5"></times><ci id="S3.Ex1.m1.9.9.8.6.cmml" xref="S3.Ex1.m1.9.9.8.6">ğ·</ci><vector id="S3.Ex1.m1.9.9.8.7.1.cmml" xref="S3.Ex1.m1.9.9.8.7.2"><ci id="S3.Ex1.m1.6.6.5.1.cmml" xref="S3.Ex1.m1.6.6.5.1">ğ‘–</ci><ci id="S3.Ex1.m1.7.7.6.2.cmml" xref="S3.Ex1.m1.7.7.6.2">ğ‘—</ci><ci id="S3.Ex1.m1.8.8.7.3.cmml" xref="S3.Ex1.m1.8.8.7.3">ğ‘“</ci><ci id="S3.Ex1.m1.9.9.8.4.cmml" xref="S3.Ex1.m1.9.9.8.4">ğ‘</ci></vector></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.12c">S(i,j,q)=\frac{1}{|F|}\sum_{f\in F}\frac{J(i,j,f,q)}{D(i,j,f,q)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS4.p2.17" class="ltx_p">where <math id="S3.SS4.p2.8.m1.4" class="ltx_Math" alttext="D(i,j,f,q)" display="inline"><semantics id="S3.SS4.p2.8.m1.4a"><mrow id="S3.SS4.p2.8.m1.4.5" xref="S3.SS4.p2.8.m1.4.5.cmml"><mi id="S3.SS4.p2.8.m1.4.5.2" xref="S3.SS4.p2.8.m1.4.5.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.8.m1.4.5.1" xref="S3.SS4.p2.8.m1.4.5.1.cmml">â€‹</mo><mrow id="S3.SS4.p2.8.m1.4.5.3.2" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.8.m1.4.5.3.2.1" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml">(</mo><mi id="S3.SS4.p2.8.m1.1.1" xref="S3.SS4.p2.8.m1.1.1.cmml">i</mi><mo id="S3.SS4.p2.8.m1.4.5.3.2.2" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.8.m1.2.2" xref="S3.SS4.p2.8.m1.2.2.cmml">j</mi><mo id="S3.SS4.p2.8.m1.4.5.3.2.3" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.8.m1.3.3" xref="S3.SS4.p2.8.m1.3.3.cmml">f</mi><mo id="S3.SS4.p2.8.m1.4.5.3.2.4" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.8.m1.4.4" xref="S3.SS4.p2.8.m1.4.4.cmml">q</mi><mo stretchy="false" id="S3.SS4.p2.8.m1.4.5.3.2.5" xref="S3.SS4.p2.8.m1.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.8.m1.4b"><apply id="S3.SS4.p2.8.m1.4.5.cmml" xref="S3.SS4.p2.8.m1.4.5"><times id="S3.SS4.p2.8.m1.4.5.1.cmml" xref="S3.SS4.p2.8.m1.4.5.1"></times><ci id="S3.SS4.p2.8.m1.4.5.2.cmml" xref="S3.SS4.p2.8.m1.4.5.2">ğ·</ci><vector id="S3.SS4.p2.8.m1.4.5.3.1.cmml" xref="S3.SS4.p2.8.m1.4.5.3.2"><ci id="S3.SS4.p2.8.m1.1.1.cmml" xref="S3.SS4.p2.8.m1.1.1">ğ‘–</ci><ci id="S3.SS4.p2.8.m1.2.2.cmml" xref="S3.SS4.p2.8.m1.2.2">ğ‘—</ci><ci id="S3.SS4.p2.8.m1.3.3.cmml" xref="S3.SS4.p2.8.m1.3.3">ğ‘“</ci><ci id="S3.SS4.p2.8.m1.4.4.cmml" xref="S3.SS4.p2.8.m1.4.4">ğ‘</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.8.m1.4c">D(i,j,f,q)</annotation></semantics></math> is the average distance between matching point pairs for character <math id="S3.SS4.p2.9.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p2.9.m2.1a"><mi id="S3.SS4.p2.9.m2.1.1" xref="S3.SS4.p2.9.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.9.m2.1b"><ci id="S3.SS4.p2.9.m2.1.1.cmml" xref="S3.SS4.p2.9.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.9.m2.1c">i</annotation></semantics></math> and <math id="S3.SS4.p2.10.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS4.p2.10.m3.1a"><mi id="S3.SS4.p2.10.m3.1.1" xref="S3.SS4.p2.10.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.10.m3.1b"><ci id="S3.SS4.p2.10.m3.1.1.cmml" xref="S3.SS4.p2.10.m3.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.10.m3.1c">j</annotation></semantics></math>, using font <math id="S3.SS4.p2.11.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS4.p2.11.m4.1a"><mi id="S3.SS4.p2.11.m4.1.1" xref="S3.SS4.p2.11.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.11.m4.1b"><ci id="S3.SS4.p2.11.m4.1.1.cmml" xref="S3.SS4.p2.11.m4.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.11.m4.1c">f</annotation></semantics></math> and feature detector <math id="S3.SS4.p2.12.m5.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS4.p2.12.m5.1a"><mi id="S3.SS4.p2.12.m5.1.1" xref="S3.SS4.p2.12.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.12.m5.1b"><ci id="S3.SS4.p2.12.m5.1.1.cmml" xref="S3.SS4.p2.12.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.12.m5.1c">q</annotation></semantics></math>. The degree of overlap for feature matching points <math id="S3.SS4.p2.13.m6.4" class="ltx_Math" alttext="J(i,j,f,q)" display="inline"><semantics id="S3.SS4.p2.13.m6.4a"><mrow id="S3.SS4.p2.13.m6.4.5" xref="S3.SS4.p2.13.m6.4.5.cmml"><mi id="S3.SS4.p2.13.m6.4.5.2" xref="S3.SS4.p2.13.m6.4.5.2.cmml">J</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.13.m6.4.5.1" xref="S3.SS4.p2.13.m6.4.5.1.cmml">â€‹</mo><mrow id="S3.SS4.p2.13.m6.4.5.3.2" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.13.m6.4.5.3.2.1" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml">(</mo><mi id="S3.SS4.p2.13.m6.1.1" xref="S3.SS4.p2.13.m6.1.1.cmml">i</mi><mo id="S3.SS4.p2.13.m6.4.5.3.2.2" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.13.m6.2.2" xref="S3.SS4.p2.13.m6.2.2.cmml">j</mi><mo id="S3.SS4.p2.13.m6.4.5.3.2.3" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.13.m6.3.3" xref="S3.SS4.p2.13.m6.3.3.cmml">f</mi><mo id="S3.SS4.p2.13.m6.4.5.3.2.4" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml">,</mo><mi id="S3.SS4.p2.13.m6.4.4" xref="S3.SS4.p2.13.m6.4.4.cmml">q</mi><mo stretchy="false" id="S3.SS4.p2.13.m6.4.5.3.2.5" xref="S3.SS4.p2.13.m6.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.13.m6.4b"><apply id="S3.SS4.p2.13.m6.4.5.cmml" xref="S3.SS4.p2.13.m6.4.5"><times id="S3.SS4.p2.13.m6.4.5.1.cmml" xref="S3.SS4.p2.13.m6.4.5.1"></times><ci id="S3.SS4.p2.13.m6.4.5.2.cmml" xref="S3.SS4.p2.13.m6.4.5.2">ğ½</ci><vector id="S3.SS4.p2.13.m6.4.5.3.1.cmml" xref="S3.SS4.p2.13.m6.4.5.3.2"><ci id="S3.SS4.p2.13.m6.1.1.cmml" xref="S3.SS4.p2.13.m6.1.1">ğ‘–</ci><ci id="S3.SS4.p2.13.m6.2.2.cmml" xref="S3.SS4.p2.13.m6.2.2">ğ‘—</ci><ci id="S3.SS4.p2.13.m6.3.3.cmml" xref="S3.SS4.p2.13.m6.3.3">ğ‘“</ci><ci id="S3.SS4.p2.13.m6.4.4.cmml" xref="S3.SS4.p2.13.m6.4.4">ğ‘</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.13.m6.4c">J(i,j,f,q)</annotation></semantics></math> is calculated using the Jaccard Index <cite class="ltx_cite ltx_citemacro_citep">(Jaccard, <a href="#bib.bib27" title="" class="ltx_ref">1912</a>)</cite>. This is defined as the ratio of the number of matching points relative to the combined number of feature points in <math id="S3.SS4.p2.14.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p2.14.m7.1a"><mi id="S3.SS4.p2.14.m7.1.1" xref="S3.SS4.p2.14.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.14.m7.1b"><ci id="S3.SS4.p2.14.m7.1.1.cmml" xref="S3.SS4.p2.14.m7.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.14.m7.1c">i</annotation></semantics></math> and <math id="S3.SS4.p2.15.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS4.p2.15.m8.1a"><mi id="S3.SS4.p2.15.m8.1.1" xref="S3.SS4.p2.15.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.15.m8.1b"><ci id="S3.SS4.p2.15.m8.1.1.cmml" xref="S3.SS4.p2.15.m8.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.15.m8.1c">j</annotation></semantics></math> minus the number of matching points. A number of matching examples are shown in Figure <a href="#S3.F2" title="Figure 2 â€£ 3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We see that, as glyphs become more similar, <math id="S3.SS4.p2.16.m9.1" class="ltx_Math" alttext="J" display="inline"><semantics id="S3.SS4.p2.16.m9.1a"><mi id="S3.SS4.p2.16.m9.1.1" xref="S3.SS4.p2.16.m9.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.16.m9.1b"><ci id="S3.SS4.p2.16.m9.1.1.cmml" xref="S3.SS4.p2.16.m9.1.1">ğ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.16.m9.1c">J</annotation></semantics></math> increases and <math id="S3.SS4.p2.17.m10.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS4.p2.17.m10.1a"><mi id="S3.SS4.p2.17.m10.1.1" xref="S3.SS4.p2.17.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.17.m10.1b"><ci id="S3.SS4.p2.17.m10.1.1.cmml" xref="S3.SS4.p2.17.m10.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.17.m10.1c">D</annotation></semantics></math> decreases.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">Next, we perform min-max normalization for different mapping types and characters to obtain the normalized score <math id="S3.SS4.p3.1.m1.2" class="ltx_Math" alttext="\in[0,1]" display="inline"><semantics id="S3.SS4.p3.1.m1.2a"><mrow id="S3.SS4.p3.1.m1.2.3" xref="S3.SS4.p3.1.m1.2.3.cmml"><mi id="S3.SS4.p3.1.m1.2.3.2" xref="S3.SS4.p3.1.m1.2.3.2.cmml"></mi><mo id="S3.SS4.p3.1.m1.2.3.1" xref="S3.SS4.p3.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p3.1.m1.2.3.3.2" xref="S3.SS4.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p3.1.m1.2.3.3.2.1" xref="S3.SS4.p3.1.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.p3.1.m1.2.3.3.2.2" xref="S3.SS4.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p3.1.m1.2.2" xref="S3.SS4.p3.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p3.1.m1.2.3.3.2.3" xref="S3.SS4.p3.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.2b"><apply id="S3.SS4.p3.1.m1.2.3.cmml" xref="S3.SS4.p3.1.m1.2.3"><in id="S3.SS4.p3.1.m1.2.3.1.cmml" xref="S3.SS4.p3.1.m1.2.3.1"></in><csymbol cd="latexml" id="S3.SS4.p3.1.m1.2.3.2.cmml" xref="S3.SS4.p3.1.m1.2.3.2">absent</csymbol><interval closure="closed" id="S3.SS4.p3.1.m1.2.3.3.1.cmml" xref="S3.SS4.p3.1.m1.2.3.3.2"><cn type="integer" id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">0</cn><cn type="integer" id="S3.SS4.p3.1.m1.2.2.cmml" xref="S3.SS4.p3.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.2c">\in[0,1]</annotation></semantics></math></p>
<table id="S3.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex2.m1.12" class="ltx_Math" alttext="S_{\text{norm}}(i,j)=\frac{1}{|Q|}\sum_{q\in Q}\frac{S(i,j,q)-\min(S_{iq})}{\max(S_{iq})-\min(S_{iq})}" display="block"><semantics id="S3.Ex2.m1.12a"><mrow id="S3.Ex2.m1.12.13" xref="S3.Ex2.m1.12.13.cmml"><mrow id="S3.Ex2.m1.12.13.2" xref="S3.Ex2.m1.12.13.2.cmml"><msub id="S3.Ex2.m1.12.13.2.2" xref="S3.Ex2.m1.12.13.2.2.cmml"><mi id="S3.Ex2.m1.12.13.2.2.2" xref="S3.Ex2.m1.12.13.2.2.2.cmml">S</mi><mtext id="S3.Ex2.m1.12.13.2.2.3" xref="S3.Ex2.m1.12.13.2.2.3a.cmml">norm</mtext></msub><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.12.13.2.1" xref="S3.Ex2.m1.12.13.2.1.cmml">â€‹</mo><mrow id="S3.Ex2.m1.12.13.2.3.2" xref="S3.Ex2.m1.12.13.2.3.1.cmml"><mo stretchy="false" id="S3.Ex2.m1.12.13.2.3.2.1" xref="S3.Ex2.m1.12.13.2.3.1.cmml">(</mo><mi id="S3.Ex2.m1.11.11" xref="S3.Ex2.m1.11.11.cmml">i</mi><mo id="S3.Ex2.m1.12.13.2.3.2.2" xref="S3.Ex2.m1.12.13.2.3.1.cmml">,</mo><mi id="S3.Ex2.m1.12.12" xref="S3.Ex2.m1.12.12.cmml">j</mi><mo stretchy="false" id="S3.Ex2.m1.12.13.2.3.2.3" xref="S3.Ex2.m1.12.13.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m1.12.13.1" xref="S3.Ex2.m1.12.13.1.cmml">=</mo><mrow id="S3.Ex2.m1.12.13.3" xref="S3.Ex2.m1.12.13.3.cmml"><mfrac id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml"><mn id="S3.Ex2.m1.1.1.3" xref="S3.Ex2.m1.1.1.3.cmml">1</mn><mrow id="S3.Ex2.m1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.1.1.1.3.1" xref="S3.Ex2.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml">Q</mi><mo stretchy="false" id="S3.Ex2.m1.1.1.1.3.2" xref="S3.Ex2.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.12.13.3.1" xref="S3.Ex2.m1.12.13.3.1.cmml">â€‹</mo><mrow id="S3.Ex2.m1.12.13.3.2" xref="S3.Ex2.m1.12.13.3.2.cmml"><munder id="S3.Ex2.m1.12.13.3.2.1" xref="S3.Ex2.m1.12.13.3.2.1.cmml"><mo movablelimits="false" id="S3.Ex2.m1.12.13.3.2.1.2" xref="S3.Ex2.m1.12.13.3.2.1.2.cmml">âˆ‘</mo><mrow id="S3.Ex2.m1.12.13.3.2.1.3" xref="S3.Ex2.m1.12.13.3.2.1.3.cmml"><mi id="S3.Ex2.m1.12.13.3.2.1.3.2" xref="S3.Ex2.m1.12.13.3.2.1.3.2.cmml">q</mi><mo id="S3.Ex2.m1.12.13.3.2.1.3.1" xref="S3.Ex2.m1.12.13.3.2.1.3.1.cmml">âˆˆ</mo><mi id="S3.Ex2.m1.12.13.3.2.1.3.3" xref="S3.Ex2.m1.12.13.3.2.1.3.3.cmml">Q</mi></mrow></munder><mfrac id="S3.Ex2.m1.10.10" xref="S3.Ex2.m1.10.10.cmml"><mrow id="S3.Ex2.m1.6.6.5" xref="S3.Ex2.m1.6.6.5.cmml"><mrow id="S3.Ex2.m1.6.6.5.7" xref="S3.Ex2.m1.6.6.5.7.cmml"><mi id="S3.Ex2.m1.6.6.5.7.2" xref="S3.Ex2.m1.6.6.5.7.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.6.6.5.7.1" xref="S3.Ex2.m1.6.6.5.7.1.cmml">â€‹</mo><mrow id="S3.Ex2.m1.6.6.5.7.3.2" xref="S3.Ex2.m1.6.6.5.7.3.1.cmml"><mo stretchy="false" id="S3.Ex2.m1.6.6.5.7.3.2.1" xref="S3.Ex2.m1.6.6.5.7.3.1.cmml">(</mo><mi id="S3.Ex2.m1.2.2.1.1" xref="S3.Ex2.m1.2.2.1.1.cmml">i</mi><mo id="S3.Ex2.m1.6.6.5.7.3.2.2" xref="S3.Ex2.m1.6.6.5.7.3.1.cmml">,</mo><mi id="S3.Ex2.m1.3.3.2.2" xref="S3.Ex2.m1.3.3.2.2.cmml">j</mi><mo id="S3.Ex2.m1.6.6.5.7.3.2.3" xref="S3.Ex2.m1.6.6.5.7.3.1.cmml">,</mo><mi id="S3.Ex2.m1.4.4.3.3" xref="S3.Ex2.m1.4.4.3.3.cmml">q</mi><mo stretchy="false" id="S3.Ex2.m1.6.6.5.7.3.2.4" xref="S3.Ex2.m1.6.6.5.7.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m1.6.6.5.6" xref="S3.Ex2.m1.6.6.5.6.cmml">âˆ’</mo><mrow id="S3.Ex2.m1.6.6.5.5.1" xref="S3.Ex2.m1.6.6.5.5.2.cmml"><mi id="S3.Ex2.m1.5.5.4.4" xref="S3.Ex2.m1.5.5.4.4.cmml">min</mi><mo id="S3.Ex2.m1.6.6.5.5.1a" xref="S3.Ex2.m1.6.6.5.5.2.cmml">â¡</mo><mrow id="S3.Ex2.m1.6.6.5.5.1.1" xref="S3.Ex2.m1.6.6.5.5.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.6.6.5.5.1.1.2" xref="S3.Ex2.m1.6.6.5.5.2.cmml">(</mo><msub id="S3.Ex2.m1.6.6.5.5.1.1.1" xref="S3.Ex2.m1.6.6.5.5.1.1.1.cmml"><mi id="S3.Ex2.m1.6.6.5.5.1.1.1.2" xref="S3.Ex2.m1.6.6.5.5.1.1.1.2.cmml">S</mi><mrow id="S3.Ex2.m1.6.6.5.5.1.1.1.3" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.cmml"><mi id="S3.Ex2.m1.6.6.5.5.1.1.1.3.2" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.6.6.5.5.1.1.1.3.1" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.6.6.5.5.1.1.1.3.3" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.3.cmml">q</mi></mrow></msub><mo stretchy="false" id="S3.Ex2.m1.6.6.5.5.1.1.3" xref="S3.Ex2.m1.6.6.5.5.2.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.Ex2.m1.10.10.9" xref="S3.Ex2.m1.10.10.9.cmml"><mrow id="S3.Ex2.m1.9.9.8.3.1" xref="S3.Ex2.m1.9.9.8.3.2.cmml"><mi id="S3.Ex2.m1.7.7.6.1" xref="S3.Ex2.m1.7.7.6.1.cmml">max</mi><mo id="S3.Ex2.m1.9.9.8.3.1a" xref="S3.Ex2.m1.9.9.8.3.2.cmml">â¡</mo><mrow id="S3.Ex2.m1.9.9.8.3.1.1" xref="S3.Ex2.m1.9.9.8.3.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.9.9.8.3.1.1.2" xref="S3.Ex2.m1.9.9.8.3.2.cmml">(</mo><msub id="S3.Ex2.m1.9.9.8.3.1.1.1" xref="S3.Ex2.m1.9.9.8.3.1.1.1.cmml"><mi id="S3.Ex2.m1.9.9.8.3.1.1.1.2" xref="S3.Ex2.m1.9.9.8.3.1.1.1.2.cmml">S</mi><mrow id="S3.Ex2.m1.9.9.8.3.1.1.1.3" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.cmml"><mi id="S3.Ex2.m1.9.9.8.3.1.1.1.3.2" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.9.9.8.3.1.1.1.3.1" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.9.9.8.3.1.1.1.3.3" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.3.cmml">q</mi></mrow></msub><mo stretchy="false" id="S3.Ex2.m1.9.9.8.3.1.1.3" xref="S3.Ex2.m1.9.9.8.3.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m1.10.10.9.5" xref="S3.Ex2.m1.10.10.9.5.cmml">âˆ’</mo><mrow id="S3.Ex2.m1.10.10.9.4.1" xref="S3.Ex2.m1.10.10.9.4.2.cmml"><mi id="S3.Ex2.m1.8.8.7.2" xref="S3.Ex2.m1.8.8.7.2.cmml">min</mi><mo id="S3.Ex2.m1.10.10.9.4.1a" xref="S3.Ex2.m1.10.10.9.4.2.cmml">â¡</mo><mrow id="S3.Ex2.m1.10.10.9.4.1.1" xref="S3.Ex2.m1.10.10.9.4.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.10.10.9.4.1.1.2" xref="S3.Ex2.m1.10.10.9.4.2.cmml">(</mo><msub id="S3.Ex2.m1.10.10.9.4.1.1.1" xref="S3.Ex2.m1.10.10.9.4.1.1.1.cmml"><mi id="S3.Ex2.m1.10.10.9.4.1.1.1.2" xref="S3.Ex2.m1.10.10.9.4.1.1.1.2.cmml">S</mi><mrow id="S3.Ex2.m1.10.10.9.4.1.1.1.3" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.cmml"><mi id="S3.Ex2.m1.10.10.9.4.1.1.1.3.2" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.10.10.9.4.1.1.1.3.1" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.10.10.9.4.1.1.1.3.3" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.3.cmml">q</mi></mrow></msub><mo stretchy="false" id="S3.Ex2.m1.10.10.9.4.1.1.3" xref="S3.Ex2.m1.10.10.9.4.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.12b"><apply id="S3.Ex2.m1.12.13.cmml" xref="S3.Ex2.m1.12.13"><eq id="S3.Ex2.m1.12.13.1.cmml" xref="S3.Ex2.m1.12.13.1"></eq><apply id="S3.Ex2.m1.12.13.2.cmml" xref="S3.Ex2.m1.12.13.2"><times id="S3.Ex2.m1.12.13.2.1.cmml" xref="S3.Ex2.m1.12.13.2.1"></times><apply id="S3.Ex2.m1.12.13.2.2.cmml" xref="S3.Ex2.m1.12.13.2.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.12.13.2.2.1.cmml" xref="S3.Ex2.m1.12.13.2.2">subscript</csymbol><ci id="S3.Ex2.m1.12.13.2.2.2.cmml" xref="S3.Ex2.m1.12.13.2.2.2">ğ‘†</ci><ci id="S3.Ex2.m1.12.13.2.2.3a.cmml" xref="S3.Ex2.m1.12.13.2.2.3"><mtext mathsize="70%" id="S3.Ex2.m1.12.13.2.2.3.cmml" xref="S3.Ex2.m1.12.13.2.2.3">norm</mtext></ci></apply><interval closure="open" id="S3.Ex2.m1.12.13.2.3.1.cmml" xref="S3.Ex2.m1.12.13.2.3.2"><ci id="S3.Ex2.m1.11.11.cmml" xref="S3.Ex2.m1.11.11">ğ‘–</ci><ci id="S3.Ex2.m1.12.12.cmml" xref="S3.Ex2.m1.12.12">ğ‘—</ci></interval></apply><apply id="S3.Ex2.m1.12.13.3.cmml" xref="S3.Ex2.m1.12.13.3"><times id="S3.Ex2.m1.12.13.3.1.cmml" xref="S3.Ex2.m1.12.13.3.1"></times><apply id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1"><divide id="S3.Ex2.m1.1.1.2.cmml" xref="S3.Ex2.m1.1.1"></divide><cn type="integer" id="S3.Ex2.m1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.3">1</cn><apply id="S3.Ex2.m1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.3"><abs id="S3.Ex2.m1.1.1.1.2.1.cmml" xref="S3.Ex2.m1.1.1.1.3.1"></abs><ci id="S3.Ex2.m1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1">ğ‘„</ci></apply></apply><apply id="S3.Ex2.m1.12.13.3.2.cmml" xref="S3.Ex2.m1.12.13.3.2"><apply id="S3.Ex2.m1.12.13.3.2.1.cmml" xref="S3.Ex2.m1.12.13.3.2.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.12.13.3.2.1.1.cmml" xref="S3.Ex2.m1.12.13.3.2.1">subscript</csymbol><sum id="S3.Ex2.m1.12.13.3.2.1.2.cmml" xref="S3.Ex2.m1.12.13.3.2.1.2"></sum><apply id="S3.Ex2.m1.12.13.3.2.1.3.cmml" xref="S3.Ex2.m1.12.13.3.2.1.3"><in id="S3.Ex2.m1.12.13.3.2.1.3.1.cmml" xref="S3.Ex2.m1.12.13.3.2.1.3.1"></in><ci id="S3.Ex2.m1.12.13.3.2.1.3.2.cmml" xref="S3.Ex2.m1.12.13.3.2.1.3.2">ğ‘</ci><ci id="S3.Ex2.m1.12.13.3.2.1.3.3.cmml" xref="S3.Ex2.m1.12.13.3.2.1.3.3">ğ‘„</ci></apply></apply><apply id="S3.Ex2.m1.10.10.cmml" xref="S3.Ex2.m1.10.10"><divide id="S3.Ex2.m1.10.10.10.cmml" xref="S3.Ex2.m1.10.10"></divide><apply id="S3.Ex2.m1.6.6.5.cmml" xref="S3.Ex2.m1.6.6.5"><minus id="S3.Ex2.m1.6.6.5.6.cmml" xref="S3.Ex2.m1.6.6.5.6"></minus><apply id="S3.Ex2.m1.6.6.5.7.cmml" xref="S3.Ex2.m1.6.6.5.7"><times id="S3.Ex2.m1.6.6.5.7.1.cmml" xref="S3.Ex2.m1.6.6.5.7.1"></times><ci id="S3.Ex2.m1.6.6.5.7.2.cmml" xref="S3.Ex2.m1.6.6.5.7.2">ğ‘†</ci><vector id="S3.Ex2.m1.6.6.5.7.3.1.cmml" xref="S3.Ex2.m1.6.6.5.7.3.2"><ci id="S3.Ex2.m1.2.2.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1">ğ‘–</ci><ci id="S3.Ex2.m1.3.3.2.2.cmml" xref="S3.Ex2.m1.3.3.2.2">ğ‘—</ci><ci id="S3.Ex2.m1.4.4.3.3.cmml" xref="S3.Ex2.m1.4.4.3.3">ğ‘</ci></vector></apply><apply id="S3.Ex2.m1.6.6.5.5.2.cmml" xref="S3.Ex2.m1.6.6.5.5.1"><min id="S3.Ex2.m1.5.5.4.4.cmml" xref="S3.Ex2.m1.5.5.4.4"></min><apply id="S3.Ex2.m1.6.6.5.5.1.1.1.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.6.6.5.5.1.1.1.1.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.6.6.5.5.1.1.1.2.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1.2">ğ‘†</ci><apply id="S3.Ex2.m1.6.6.5.5.1.1.1.3.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3"><times id="S3.Ex2.m1.6.6.5.5.1.1.1.3.1.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.1"></times><ci id="S3.Ex2.m1.6.6.5.5.1.1.1.3.2.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.2">ğ‘–</ci><ci id="S3.Ex2.m1.6.6.5.5.1.1.1.3.3.cmml" xref="S3.Ex2.m1.6.6.5.5.1.1.1.3.3">ğ‘</ci></apply></apply></apply></apply><apply id="S3.Ex2.m1.10.10.9.cmml" xref="S3.Ex2.m1.10.10.9"><minus id="S3.Ex2.m1.10.10.9.5.cmml" xref="S3.Ex2.m1.10.10.9.5"></minus><apply id="S3.Ex2.m1.9.9.8.3.2.cmml" xref="S3.Ex2.m1.9.9.8.3.1"><max id="S3.Ex2.m1.7.7.6.1.cmml" xref="S3.Ex2.m1.7.7.6.1"></max><apply id="S3.Ex2.m1.9.9.8.3.1.1.1.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.9.9.8.3.1.1.1.1.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.9.9.8.3.1.1.1.2.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1.2">ğ‘†</ci><apply id="S3.Ex2.m1.9.9.8.3.1.1.1.3.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3"><times id="S3.Ex2.m1.9.9.8.3.1.1.1.3.1.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.1"></times><ci id="S3.Ex2.m1.9.9.8.3.1.1.1.3.2.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.2">ğ‘–</ci><ci id="S3.Ex2.m1.9.9.8.3.1.1.1.3.3.cmml" xref="S3.Ex2.m1.9.9.8.3.1.1.1.3.3">ğ‘</ci></apply></apply></apply><apply id="S3.Ex2.m1.10.10.9.4.2.cmml" xref="S3.Ex2.m1.10.10.9.4.1"><min id="S3.Ex2.m1.8.8.7.2.cmml" xref="S3.Ex2.m1.8.8.7.2"></min><apply id="S3.Ex2.m1.10.10.9.4.1.1.1.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.10.10.9.4.1.1.1.1.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.10.10.9.4.1.1.1.2.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1.2">ğ‘†</ci><apply id="S3.Ex2.m1.10.10.9.4.1.1.1.3.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3"><times id="S3.Ex2.m1.10.10.9.4.1.1.1.3.1.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.1"></times><ci id="S3.Ex2.m1.10.10.9.4.1.1.1.3.2.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.2">ğ‘–</ci><ci id="S3.Ex2.m1.10.10.9.4.1.1.1.3.3.cmml" xref="S3.Ex2.m1.10.10.9.4.1.1.1.3.3">ğ‘</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.12c">S_{\text{norm}}(i,j)=\frac{1}{|Q|}\sum_{q\in Q}\frac{S(i,j,q)-\min(S_{iq})}{\max(S_{iq})-\min(S_{iq})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS4.p3.5" class="ltx_p">where <math id="S3.SS4.p3.2.m1.1" class="ltx_Math" alttext="S_{iq}" display="inline"><semantics id="S3.SS4.p3.2.m1.1a"><msub id="S3.SS4.p3.2.m1.1.1" xref="S3.SS4.p3.2.m1.1.1.cmml"><mi id="S3.SS4.p3.2.m1.1.1.2" xref="S3.SS4.p3.2.m1.1.1.2.cmml">S</mi><mrow id="S3.SS4.p3.2.m1.1.1.3" xref="S3.SS4.p3.2.m1.1.1.3.cmml"><mi id="S3.SS4.p3.2.m1.1.1.3.2" xref="S3.SS4.p3.2.m1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m1.1.1.3.1" xref="S3.SS4.p3.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p3.2.m1.1.1.3.3" xref="S3.SS4.p3.2.m1.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m1.1b"><apply id="S3.SS4.p3.2.m1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m1.1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m1.1.1.2.cmml" xref="S3.SS4.p3.2.m1.1.1.2">ğ‘†</ci><apply id="S3.SS4.p3.2.m1.1.1.3.cmml" xref="S3.SS4.p3.2.m1.1.1.3"><times id="S3.SS4.p3.2.m1.1.1.3.1.cmml" xref="S3.SS4.p3.2.m1.1.1.3.1"></times><ci id="S3.SS4.p3.2.m1.1.1.3.2.cmml" xref="S3.SS4.p3.2.m1.1.1.3.2">ğ‘–</ci><ci id="S3.SS4.p3.2.m1.1.1.3.3.cmml" xref="S3.SS4.p3.2.m1.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m1.1c">S_{iq}</annotation></semantics></math> is the set of similarity scores between character <math id="S3.SS4.p3.3.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p3.3.m2.1a"><mi id="S3.SS4.p3.3.m2.1.1" xref="S3.SS4.p3.3.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m2.1b"><ci id="S3.SS4.p3.3.m2.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m2.1c">i</annotation></semantics></math> and other characters using feature detector <math id="S3.SS4.p3.4.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS4.p3.4.m3.1a"><mi id="S3.SS4.p3.4.m3.1.1" xref="S3.SS4.p3.4.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m3.1b"><ci id="S3.SS4.p3.4.m3.1.1.cmml" xref="S3.SS4.p3.4.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m3.1c">q</annotation></semantics></math>.
Figure <a href="#S3.F3" title="Figure 3 â€£ 3.4 Method â‘£ Glyph Similarity â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents an example of <math id="S3.SS4.p3.5.m4.2" class="ltx_Math" alttext="S_{\text{norm}}(i,j)" display="inline"><semantics id="S3.SS4.p3.5.m4.2a"><mrow id="S3.SS4.p3.5.m4.2.3" xref="S3.SS4.p3.5.m4.2.3.cmml"><msub id="S3.SS4.p3.5.m4.2.3.2" xref="S3.SS4.p3.5.m4.2.3.2.cmml"><mi id="S3.SS4.p3.5.m4.2.3.2.2" xref="S3.SS4.p3.5.m4.2.3.2.2.cmml">S</mi><mtext id="S3.SS4.p3.5.m4.2.3.2.3" xref="S3.SS4.p3.5.m4.2.3.2.3a.cmml">norm</mtext></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m4.2.3.1" xref="S3.SS4.p3.5.m4.2.3.1.cmml">â€‹</mo><mrow id="S3.SS4.p3.5.m4.2.3.3.2" xref="S3.SS4.p3.5.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p3.5.m4.2.3.3.2.1" xref="S3.SS4.p3.5.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS4.p3.5.m4.1.1" xref="S3.SS4.p3.5.m4.1.1.cmml">i</mi><mo id="S3.SS4.p3.5.m4.2.3.3.2.2" xref="S3.SS4.p3.5.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS4.p3.5.m4.2.2" xref="S3.SS4.p3.5.m4.2.2.cmml">j</mi><mo stretchy="false" id="S3.SS4.p3.5.m4.2.3.3.2.3" xref="S3.SS4.p3.5.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m4.2b"><apply id="S3.SS4.p3.5.m4.2.3.cmml" xref="S3.SS4.p3.5.m4.2.3"><times id="S3.SS4.p3.5.m4.2.3.1.cmml" xref="S3.SS4.p3.5.m4.2.3.1"></times><apply id="S3.SS4.p3.5.m4.2.3.2.cmml" xref="S3.SS4.p3.5.m4.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.p3.5.m4.2.3.2.1.cmml" xref="S3.SS4.p3.5.m4.2.3.2">subscript</csymbol><ci id="S3.SS4.p3.5.m4.2.3.2.2.cmml" xref="S3.SS4.p3.5.m4.2.3.2.2">ğ‘†</ci><ci id="S3.SS4.p3.5.m4.2.3.2.3a.cmml" xref="S3.SS4.p3.5.m4.2.3.2.3"><mtext mathsize="70%" id="S3.SS4.p3.5.m4.2.3.2.3.cmml" xref="S3.SS4.p3.5.m4.2.3.2.3">norm</mtext></ci></apply><interval closure="open" id="S3.SS4.p3.5.m4.2.3.3.1.cmml" xref="S3.SS4.p3.5.m4.2.3.3.2"><ci id="S3.SS4.p3.5.m4.1.1.cmml" xref="S3.SS4.p3.5.m4.1.1">ğ‘–</ci><ci id="S3.SS4.p3.5.m4.2.2.cmml" xref="S3.SS4.p3.5.m4.2.2">ğ‘—</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m4.2c">S_{\text{norm}}(i,j)</annotation></semantics></math> for English-language characters.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2408.02253/assets/image/1.jpg" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="228" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of a glyph similarity matrix for English-language characters (52 letters only). The saturation of each cell represents the value <math id="S3.F3.4.m1.2" class="ltx_Math" alttext="S_{\text{norm}}(i,j)" display="inline"><semantics id="S3.F3.4.m1.2b"><mrow id="S3.F3.4.m1.2.3" xref="S3.F3.4.m1.2.3.cmml"><msub id="S3.F3.4.m1.2.3.2" xref="S3.F3.4.m1.2.3.2.cmml"><mi id="S3.F3.4.m1.2.3.2.2" xref="S3.F3.4.m1.2.3.2.2.cmml">S</mi><mtext id="S3.F3.4.m1.2.3.2.3" xref="S3.F3.4.m1.2.3.2.3a.cmml">norm</mtext></msub><mo lspace="0em" rspace="0em" id="S3.F3.4.m1.2.3.1" xref="S3.F3.4.m1.2.3.1.cmml">â€‹</mo><mrow id="S3.F3.4.m1.2.3.3.2" xref="S3.F3.4.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.F3.4.m1.2.3.3.2.1" xref="S3.F3.4.m1.2.3.3.1.cmml">(</mo><mi id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml">i</mi><mo id="S3.F3.4.m1.2.3.3.2.2" xref="S3.F3.4.m1.2.3.3.1.cmml">,</mo><mi id="S3.F3.4.m1.2.2" xref="S3.F3.4.m1.2.2.cmml">j</mi><mo stretchy="false" id="S3.F3.4.m1.2.3.3.2.3" xref="S3.F3.4.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.2c"><apply id="S3.F3.4.m1.2.3.cmml" xref="S3.F3.4.m1.2.3"><times id="S3.F3.4.m1.2.3.1.cmml" xref="S3.F3.4.m1.2.3.1"></times><apply id="S3.F3.4.m1.2.3.2.cmml" xref="S3.F3.4.m1.2.3.2"><csymbol cd="ambiguous" id="S3.F3.4.m1.2.3.2.1.cmml" xref="S3.F3.4.m1.2.3.2">subscript</csymbol><ci id="S3.F3.4.m1.2.3.2.2.cmml" xref="S3.F3.4.m1.2.3.2.2">ğ‘†</ci><ci id="S3.F3.4.m1.2.3.2.3a.cmml" xref="S3.F3.4.m1.2.3.2.3"><mtext mathsize="70%" id="S3.F3.4.m1.2.3.2.3.cmml" xref="S3.F3.4.m1.2.3.2.3">norm</mtext></ci></apply><interval closure="open" id="S3.F3.4.m1.2.3.3.1.cmml" xref="S3.F3.4.m1.2.3.3.2"><ci id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1">ğ‘–</ci><ci id="S3.F3.4.m1.2.2.cmml" xref="S3.F3.4.m1.2.2">ğ‘—</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m1.2d">S_{\text{norm}}(i,j)</annotation></semantics></math> between each pair of characters <math id="S3.F3.5.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.F3.5.m2.1b"><mi id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c"><ci id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">i</annotation></semantics></math> and <math id="S3.F3.6.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.F3.6.m3.1b"><mi id="S3.F3.6.m3.1.1" xref="S3.F3.6.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.F3.6.m3.1c"><ci id="S3.F3.6.m3.1.1.cmml" xref="S3.F3.6.m3.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m3.1d">j</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.8" class="ltx_p">The technique of embedding OCR errors by exploiting glyph similarity shares some common aspects with the random injection method described previously. Firstly, we randomly select a target error rate <math id="S3.SS4.p4.1.m1.2" class="ltx_Math" alttext="p\in[0,15]" display="inline"><semantics id="S3.SS4.p4.1.m1.2a"><mrow id="S3.SS4.p4.1.m1.2.3" xref="S3.SS4.p4.1.m1.2.3.cmml"><mi id="S3.SS4.p4.1.m1.2.3.2" xref="S3.SS4.p4.1.m1.2.3.2.cmml">p</mi><mo id="S3.SS4.p4.1.m1.2.3.1" xref="S3.SS4.p4.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS4.p4.1.m1.2.3.3.2" xref="S3.SS4.p4.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p4.1.m1.2.3.3.2.1" xref="S3.SS4.p4.1.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.p4.1.m1.2.3.3.2.2" xref="S3.SS4.p4.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS4.p4.1.m1.2.2" xref="S3.SS4.p4.1.m1.2.2.cmml">15</mn><mo stretchy="false" id="S3.SS4.p4.1.m1.2.3.3.2.3" xref="S3.SS4.p4.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.2b"><apply id="S3.SS4.p4.1.m1.2.3.cmml" xref="S3.SS4.p4.1.m1.2.3"><in id="S3.SS4.p4.1.m1.2.3.1.cmml" xref="S3.SS4.p4.1.m1.2.3.1"></in><ci id="S3.SS4.p4.1.m1.2.3.2.cmml" xref="S3.SS4.p4.1.m1.2.3.2">ğ‘</ci><interval closure="closed" id="S3.SS4.p4.1.m1.2.3.3.1.cmml" xref="S3.SS4.p4.1.m1.2.3.3.2"><cn type="integer" id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1">0</cn><cn type="integer" id="S3.SS4.p4.1.m1.2.2.cmml" xref="S3.SS4.p4.1.m1.2.2">15</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.2c">p\in[0,15]</annotation></semantics></math> for each chunk from <math id="S3.SS4.p4.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS4.p4.2.m2.1a"><mi id="S3.SS4.p4.2.m2.1.1" xref="S3.SS4.p4.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.2.m2.1b"><ci id="S3.SS4.p4.2.m2.1.1.cmml" xref="S3.SS4.p4.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.2.m2.1c">A</annotation></semantics></math>, where each character <math id="S3.SS4.p4.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p4.3.m3.1a"><mi id="S3.SS4.p4.3.m3.1.1" xref="S3.SS4.p4.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.3.m3.1b"><ci id="S3.SS4.p4.3.m3.1.1.cmml" xref="S3.SS4.p4.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.3.m3.1c">i</annotation></semantics></math> in <math id="S3.SS4.p4.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS4.p4.4.m4.1a"><mi id="S3.SS4.p4.4.m4.1.1" xref="S3.SS4.p4.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.4.m4.1b"><ci id="S3.SS4.p4.4.m4.1.1.cmml" xref="S3.SS4.p4.4.m4.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.4.m4.1c">A</annotation></semantics></math> has a probability of <math id="S3.SS4.p4.5.m5.1" class="ltx_Math" alttext="\frac{5}{7}\times p" display="inline"><semantics id="S3.SS4.p4.5.m5.1a"><mrow id="S3.SS4.p4.5.m5.1.1" xref="S3.SS4.p4.5.m5.1.1.cmml"><mfrac id="S3.SS4.p4.5.m5.1.1.2" xref="S3.SS4.p4.5.m5.1.1.2.cmml"><mn id="S3.SS4.p4.5.m5.1.1.2.2" xref="S3.SS4.p4.5.m5.1.1.2.2.cmml">5</mn><mn id="S3.SS4.p4.5.m5.1.1.2.3" xref="S3.SS4.p4.5.m5.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p4.5.m5.1.1.1" xref="S3.SS4.p4.5.m5.1.1.1.cmml">Ã—</mo><mi id="S3.SS4.p4.5.m5.1.1.3" xref="S3.SS4.p4.5.m5.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.5.m5.1b"><apply id="S3.SS4.p4.5.m5.1.1.cmml" xref="S3.SS4.p4.5.m5.1.1"><times id="S3.SS4.p4.5.m5.1.1.1.cmml" xref="S3.SS4.p4.5.m5.1.1.1"></times><apply id="S3.SS4.p4.5.m5.1.1.2.cmml" xref="S3.SS4.p4.5.m5.1.1.2"><divide id="S3.SS4.p4.5.m5.1.1.2.1.cmml" xref="S3.SS4.p4.5.m5.1.1.2"></divide><cn type="integer" id="S3.SS4.p4.5.m5.1.1.2.2.cmml" xref="S3.SS4.p4.5.m5.1.1.2.2">5</cn><cn type="integer" id="S3.SS4.p4.5.m5.1.1.2.3.cmml" xref="S3.SS4.p4.5.m5.1.1.2.3">7</cn></apply><ci id="S3.SS4.p4.5.m5.1.1.3.cmml" xref="S3.SS4.p4.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.5.m5.1c">\frac{5}{7}\times p</annotation></semantics></math> to be replaced with another character. The choice of replacement is based on <math id="S3.SS4.p4.6.m6.2" class="ltx_Math" alttext="S_{\text{norm}}(i,j)" display="inline"><semantics id="S3.SS4.p4.6.m6.2a"><mrow id="S3.SS4.p4.6.m6.2.3" xref="S3.SS4.p4.6.m6.2.3.cmml"><msub id="S3.SS4.p4.6.m6.2.3.2" xref="S3.SS4.p4.6.m6.2.3.2.cmml"><mi id="S3.SS4.p4.6.m6.2.3.2.2" xref="S3.SS4.p4.6.m6.2.3.2.2.cmml">S</mi><mtext id="S3.SS4.p4.6.m6.2.3.2.3" xref="S3.SS4.p4.6.m6.2.3.2.3a.cmml">norm</mtext></msub><mo lspace="0em" rspace="0em" id="S3.SS4.p4.6.m6.2.3.1" xref="S3.SS4.p4.6.m6.2.3.1.cmml">â€‹</mo><mrow id="S3.SS4.p4.6.m6.2.3.3.2" xref="S3.SS4.p4.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p4.6.m6.2.3.3.2.1" xref="S3.SS4.p4.6.m6.2.3.3.1.cmml">(</mo><mi id="S3.SS4.p4.6.m6.1.1" xref="S3.SS4.p4.6.m6.1.1.cmml">i</mi><mo id="S3.SS4.p4.6.m6.2.3.3.2.2" xref="S3.SS4.p4.6.m6.2.3.3.1.cmml">,</mo><mi id="S3.SS4.p4.6.m6.2.2" xref="S3.SS4.p4.6.m6.2.2.cmml">j</mi><mo stretchy="false" id="S3.SS4.p4.6.m6.2.3.3.2.3" xref="S3.SS4.p4.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.6.m6.2b"><apply id="S3.SS4.p4.6.m6.2.3.cmml" xref="S3.SS4.p4.6.m6.2.3"><times id="S3.SS4.p4.6.m6.2.3.1.cmml" xref="S3.SS4.p4.6.m6.2.3.1"></times><apply id="S3.SS4.p4.6.m6.2.3.2.cmml" xref="S3.SS4.p4.6.m6.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.p4.6.m6.2.3.2.1.cmml" xref="S3.SS4.p4.6.m6.2.3.2">subscript</csymbol><ci id="S3.SS4.p4.6.m6.2.3.2.2.cmml" xref="S3.SS4.p4.6.m6.2.3.2.2">ğ‘†</ci><ci id="S3.SS4.p4.6.m6.2.3.2.3a.cmml" xref="S3.SS4.p4.6.m6.2.3.2.3"><mtext mathsize="70%" id="S3.SS4.p4.6.m6.2.3.2.3.cmml" xref="S3.SS4.p4.6.m6.2.3.2.3">norm</mtext></ci></apply><interval closure="open" id="S3.SS4.p4.6.m6.2.3.3.1.cmml" xref="S3.SS4.p4.6.m6.2.3.3.2"><ci id="S3.SS4.p4.6.m6.1.1.cmml" xref="S3.SS4.p4.6.m6.1.1">ğ‘–</ci><ci id="S3.SS4.p4.6.m6.2.2.cmml" xref="S3.SS4.p4.6.m6.2.2">ğ‘—</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.6.m6.2c">S_{\text{norm}}(i,j)</annotation></semantics></math>, with higher-weighted pairs being more likely to be chosen. After replacement, each character has a probability of <math id="S3.SS4.p4.7.m7.1" class="ltx_Math" alttext="\frac{1}{7}\times p" display="inline"><semantics id="S3.SS4.p4.7.m7.1a"><mrow id="S3.SS4.p4.7.m7.1.1" xref="S3.SS4.p4.7.m7.1.1.cmml"><mfrac id="S3.SS4.p4.7.m7.1.1.2" xref="S3.SS4.p4.7.m7.1.1.2.cmml"><mn id="S3.SS4.p4.7.m7.1.1.2.2" xref="S3.SS4.p4.7.m7.1.1.2.2.cmml">1</mn><mn id="S3.SS4.p4.7.m7.1.1.2.3" xref="S3.SS4.p4.7.m7.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p4.7.m7.1.1.1" xref="S3.SS4.p4.7.m7.1.1.1.cmml">Ã—</mo><mi id="S3.SS4.p4.7.m7.1.1.3" xref="S3.SS4.p4.7.m7.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.7.m7.1b"><apply id="S3.SS4.p4.7.m7.1.1.cmml" xref="S3.SS4.p4.7.m7.1.1"><times id="S3.SS4.p4.7.m7.1.1.1.cmml" xref="S3.SS4.p4.7.m7.1.1.1"></times><apply id="S3.SS4.p4.7.m7.1.1.2.cmml" xref="S3.SS4.p4.7.m7.1.1.2"><divide id="S3.SS4.p4.7.m7.1.1.2.1.cmml" xref="S3.SS4.p4.7.m7.1.1.2"></divide><cn type="integer" id="S3.SS4.p4.7.m7.1.1.2.2.cmml" xref="S3.SS4.p4.7.m7.1.1.2.2">1</cn><cn type="integer" id="S3.SS4.p4.7.m7.1.1.2.3.cmml" xref="S3.SS4.p4.7.m7.1.1.2.3">7</cn></apply><ci id="S3.SS4.p4.7.m7.1.1.3.cmml" xref="S3.SS4.p4.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.7.m7.1c">\frac{1}{7}\times p</annotation></semantics></math> to be deleted. Any two characters have a probability of <math id="S3.SS4.p4.8.m8.1" class="ltx_Math" alttext="\frac{1}{7}\times p" display="inline"><semantics id="S3.SS4.p4.8.m8.1a"><mrow id="S3.SS4.p4.8.m8.1.1" xref="S3.SS4.p4.8.m8.1.1.cmml"><mfrac id="S3.SS4.p4.8.m8.1.1.2" xref="S3.SS4.p4.8.m8.1.1.2.cmml"><mn id="S3.SS4.p4.8.m8.1.1.2.2" xref="S3.SS4.p4.8.m8.1.1.2.2.cmml">1</mn><mn id="S3.SS4.p4.8.m8.1.1.2.3" xref="S3.SS4.p4.8.m8.1.1.2.3.cmml">7</mn></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p4.8.m8.1.1.1" xref="S3.SS4.p4.8.m8.1.1.1.cmml">Ã—</mo><mi id="S3.SS4.p4.8.m8.1.1.3" xref="S3.SS4.p4.8.m8.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.8.m8.1b"><apply id="S3.SS4.p4.8.m8.1.1.cmml" xref="S3.SS4.p4.8.m8.1.1"><times id="S3.SS4.p4.8.m8.1.1.1.cmml" xref="S3.SS4.p4.8.m8.1.1.1"></times><apply id="S3.SS4.p4.8.m8.1.1.2.cmml" xref="S3.SS4.p4.8.m8.1.1.2"><divide id="S3.SS4.p4.8.m8.1.1.2.1.cmml" xref="S3.SS4.p4.8.m8.1.1.2"></divide><cn type="integer" id="S3.SS4.p4.8.m8.1.1.2.2.cmml" xref="S3.SS4.p4.8.m8.1.1.2.2">1</cn><cn type="integer" id="S3.SS4.p4.8.m8.1.1.2.3.cmml" xref="S3.SS4.p4.8.m8.1.1.2.3">7</cn></apply><ci id="S3.SS4.p4.8.m8.1.1.3.cmml" xref="S3.SS4.p4.8.m8.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.8.m8.1c">\frac{1}{7}\times p</annotation></semantics></math> of having a random character inserted between them.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Datasets</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we undertake post-OCR experiments involving English, Frisian, German, Icelandic, Irish, Russian, Spanish, and Telugu texts. Clean corpora <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">A</annotation></semantics></math> for these languages were obtained as follows: data for Icelandic, Irish, and Frisian were sourced from the CC-100 corpus <cite class="ltx_cite ltx_citemacro_cite">Conneau etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. Telugu<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.kaggle.com/datasets/sudalairajkumar/telugu-nlp" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/sudalairajkumar/telugu-nlp</a></span></span></span> and Russian<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.kaggle.com/datasets/d0rj3228/russian-literature/data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/d0rj3228/russian-literature/data</a></span></span></span> datasets were obtained from Kaggle, while English, Spanish, and German were sourced from Project Gutenberg. Summary statistics for the corpora are given in Table <a href="#S4.T1" title="Table 1 â€£ 4 Datasets â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The amount of data selected simulates the real-world rarity of these languages to some extent.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:160.4pt;height:147.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.9pt,7.3pt) scale(0.910352454507776,0.910352454507776) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Language</span></th>
<th id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Length</span></th>
<th id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Source</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.2.1" class="ltx_tr">
<td id="S4.T1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">English</td>
<td id="S4.T1.1.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">27,883,394</td>
<td id="S4.T1.1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Gutenberg</td>
</tr>
<tr id="S4.T1.1.1.3.2" class="ltx_tr">
<td id="S4.T1.1.1.3.2.1" class="ltx_td ltx_align_left">Frisian</td>
<td id="S4.T1.1.1.3.2.2" class="ltx_td ltx_align_right">3,426,499</td>
<td id="S4.T1.1.1.3.2.3" class="ltx_td ltx_align_left">CC100</td>
</tr>
<tr id="S4.T1.1.1.4.3" class="ltx_tr">
<td id="S4.T1.1.1.4.3.1" class="ltx_td ltx_align_left">German</td>
<td id="S4.T1.1.1.4.3.2" class="ltx_td ltx_align_right">3,758,352</td>
<td id="S4.T1.1.1.4.3.3" class="ltx_td ltx_align_left">Gutenberg</td>
</tr>
<tr id="S4.T1.1.1.5.4" class="ltx_tr">
<td id="S4.T1.1.1.5.4.1" class="ltx_td ltx_align_left">Icelandic</td>
<td id="S4.T1.1.1.5.4.2" class="ltx_td ltx_align_right">3,147,864</td>
<td id="S4.T1.1.1.5.4.3" class="ltx_td ltx_align_left">CC100</td>
</tr>
<tr id="S4.T1.1.1.6.5" class="ltx_tr">
<td id="S4.T1.1.1.6.5.1" class="ltx_td ltx_align_left">Irish</td>
<td id="S4.T1.1.1.6.5.2" class="ltx_td ltx_align_right">5,090,436</td>
<td id="S4.T1.1.1.6.5.3" class="ltx_td ltx_align_left">CC100</td>
</tr>
<tr id="S4.T1.1.1.7.6" class="ltx_tr">
<td id="S4.T1.1.1.7.6.1" class="ltx_td ltx_align_left">Russian</td>
<td id="S4.T1.1.1.7.6.2" class="ltx_td ltx_align_right">6,613,093</td>
<td id="S4.T1.1.1.7.6.3" class="ltx_td ltx_align_left">Kaggle</td>
</tr>
<tr id="S4.T1.1.1.8.7" class="ltx_tr">
<td id="S4.T1.1.1.8.7.1" class="ltx_td ltx_align_left">Spanish</td>
<td id="S4.T1.1.1.8.7.2" class="ltx_td ltx_align_right">7,813,245</td>
<td id="S4.T1.1.1.8.7.3" class="ltx_td ltx_align_left">Gutenberg</td>
</tr>
<tr id="S4.T1.1.1.9.8" class="ltx_tr">
<td id="S4.T1.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_bb">Telugu</td>
<td id="S4.T1.1.1.9.8.2" class="ltx_td ltx_align_right ltx_border_bb">5,777,551</td>
<td id="S4.T1.1.1.9.8.3" class="ltx_td ltx_align_left ltx_border_bb">Kaggle</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Corpus character counts and sources.</figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">All training, validation, and test datasets are generated from these clean corpora. The training data is created using the four different methods described in Section <a href="#S3" title="3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, with the aim of comparing the synthetic data generation techniques. To implement the method presented in Section <a href="#S3.SS3" title="3.3 Method â‘¢ Real-World Injection â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, 20% of the text from each language corpus is used as <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">C</annotation></semantics></math> for extracting OCR error distributions. The remaining 80% of the corpus is divided in a 8:1:1 ratio to generate training, validation, and test sets.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">The test datasets are generated using a method similar to that described in Section <a href="#S3.SS2" title="3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, employing the Tesseract OCR system <cite class="ltx_cite ltx_citemacro_cite">Smith (<a href="#bib.bib57" title="" class="ltx_ref">2007</a>)</cite> to convert synthetic images into OCR text. Since the methods described in Sections <a href="#S3.SS2" title="3.2 Method â‘¡ Image Creation â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> and <a href="#S3.SS3" title="3.3 Method â‘¢ Real-World Injection â€£ 3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> involve using an OCR system to either generate OCR text directly or to extract OCR errors, the Google Vision API OCR system <cite class="ltx_cite ltx_citemacro_cite">Fujii etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2017</a>)</cite> is used when creating training and validation datasets.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Models</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In our experiments, we compare the performance of various models which have been previously adopted for post-OCR tasks, including models that operate at the subword-level, character-level, and byte-level tokenizers. Additionally, we evaluate current SOTA models which is based on n-gram and majority voting. This comparison encompasses both pre-trained models and those trained from scratch. Training parameters are in Appendix <a href="#A1" title="Appendix A Training parameters â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>mT5</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The mT5 model <cite class="ltx_cite ltx_citemacro_cite">Xue etÂ al. (<a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite> is an extension of the T5 model <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>, which is pre-trained on a multilingual dataset. This model leverages the original T5â€™s text-to-text framework, where every natural language processing task is reframed as a text generation problem, allowing for consistent and flexible handling of a wide range of tasks across languages. The version we use in our experiments is mT5-base.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>mBART</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The mBART model <cite class="ltx_cite ltx_citemacro_cite">Tang etÂ al. (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite> is a multilingual extension of the BART architecture <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>. Developed by Facebook AI, its pre-training approach involves corrupting text with an arbitrary noising function and then learning to reconstruct the original text. mBART is also pre-trained on a large corpus of text in multiple languages, making it adept at both high-resource and low-resource language translation, as well as a variety of other language processing tasks. The version we use in our experiments is mBART-large-50.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>ByT5</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The ByT5 model <cite class="ltx_cite ltx_citemacro_cite">Xue etÂ al. (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite> is designed to address the limitations of traditional subword tokenization methods by working at the byte level. This approach allows ByT5 to handle any language or writing system with Unicode representation, making it naturally multilingual and adaptable for handling a wide variety of text data. By operating on bytes, ByT5 avoids the complexities and biases associated with subword vocabularies, enabling more equitable and accurate processing across languages. ByT5 was pre-trained on the same dataset as mT5. The model demonstrates robust performance across a wide range of tasks <cite class="ltx_cite ltx_citemacro_cite">StankeviÄius etÂ al. (<a href="#bib.bib59" title="" class="ltx_ref">2022</a>); Jentoft (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>. The version we use in our experiments is ByT5-base.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>CharBERT + Glyph Embedding</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">To verify the effectiveness of glyph embedding as proposed by <cite class="ltx_cite ltx_citemacro_citet">Chen and Zhou (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>, we also conducted some experiments using their model. CharBERT <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> is a char-level model. In the pre-training phase of CharBERT, one of the tasks involves text denoising which is closely aligns with the objectives of post-OCR correction tasks. Building on the original model, <cite class="ltx_cite ltx_citemacro_citet">Chen and Zhou (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite> introduced glyph embedding to CharBERT by using a ResNet50 model <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2016</a>)</cite>.
This supports the extraction of visual information from characters and serves as one of the inputs to the post-OCR correction model. The structure of this model is shown in Figure <a href="#S5.F4" title="Figure 4 â€£ 5.4 CharBERT + Glyph Embedding â€£ 5 Models â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. In our experiments we use the same structure and fine-tuning settings corresponding to the optimal configurations reported in the original work.
Since the CharBERT model was pre-trained on the English Wikipedia dataset <cite class="ltx_cite ltx_citemacro_cite">Foundation (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite>, we conduct experiments only in English with this model.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2408.02253/assets/image/4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="258" height="163" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The structure of the CharBERT post-OCR model incorporates glyph embeddings as inputs. It consists of two CNN encoders and one transformer decoder.</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Non-pre-trained Models</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">The method proposed by <cite class="ltx_cite ltx_citemacro_citet">Ramirez-Orta etÂ al. (<a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite> achieved SOTA results in 5 out of 9 languages on the ICDAR2019 dataset. In this study, we also compare this model with other models using the configuration: window type as n-grams, window size of 60, decoding method as beam, weighting as uniform. We refer to as the ENSEMBLE model.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">Additionally, we have defined a more conventional Seq2Seq model, referred to as SCRATCH. The SCRATCH model is designed with an embedding size of 512, feed-forward network embeddings of 2048, 4 attention heads, 5 encoder layers, 5 decoder layers, a SentencePiece tokenizer <cite class="ltx_cite ltx_citemacro_cite">Kudo and Richardson (<a href="#bib.bib37" title="" class="ltx_ref">2018</a>)</cite>, and a vocabulary size of 3000.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experiments</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The primary objective of our empirical analysis in this paper is to explore the key factors affecting the performance of models in post-OCR tasks, aiming to identify the most appropriate settings for such tasks. We conduct three different experiments:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Experiment 1:</span> We investigate how data volume impacts on model performance, aiming to identify a generally applicable data augmentation setting that balances performance and training time.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Experiment 2:</span> We seek identify the best method for constructing synthetic data and the best-performing model. Using the findings from Experiment 1, we apply augmentation and generate different datasets using the four methods from Section <a href="#S3" title="3 Methods â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, in combination with multiple post-OCR models.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Experiment 3:</span> We extend the best settings identified in the first two experiments to a wider set of languages for post-OCR tasks, verifying the applicability and effectiveness of these settings in a broader linguistic context.</p>
</div>
</li>
</ul>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Experiment 1</h3>

<figure id="S6.T2" class="ltx_table">
<div id="S6.T2.20" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:133pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-102.2pt,32.8pt) scale(0.668427293471499,0.668427293471499) ;">
<table id="S6.T2.20.20" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.20.20.21.1" class="ltx_tr">
<th id="S6.T2.20.20.21.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S6.T2.20.20.21.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S6.T2.20.20.21.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T2.20.20.21.1.3.1" class="ltx_text ltx_font_bold">English</span></th>
<th id="S6.T2.20.20.21.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T2.20.20.21.1.4.1" class="ltx_text ltx_font_bold">Icelandic</span></th>
<th id="S6.T2.20.20.21.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T2.20.20.21.1.5.1" class="ltx_text ltx_font_bold">Russian</span></th>
<th id="S6.T2.20.20.21.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T2.20.20.21.1.6.1" class="ltx_text ltx_font_bold">Telugu</span></th>
</tr>
<tr id="S6.T2.20.20.22.2" class="ltx_tr">
<th id="S6.T2.20.20.22.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T2.20.20.22.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">CER</th>
<th id="S6.T2.20.20.22.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">4.96</th>
<th id="S6.T2.20.20.22.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">10.09</th>
<th id="S6.T2.20.20.22.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">4.13</th>
<th id="S6.T2.20.20.22.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">34.12</th>
</tr>
<tr id="S6.T2.12.12.12" class="ltx_tr">
<th id="S6.T2.12.12.12.13" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Model</th>
<th id="S6.T2.12.12.12.14" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Data</th>
<th id="S6.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.T2.1.1.1.1.m1.1a"><mfrac id="S6.T2.1.1.1.1.m1.1.1" xref="S6.T2.1.1.1.1.m1.1.1.cmml"><mn id="S6.T2.1.1.1.1.m1.1.1.2" xref="S6.T2.1.1.1.1.m1.1.1.2.cmml">1</mn><mn id="S6.T2.1.1.1.1.m1.1.1.3" xref="S6.T2.1.1.1.1.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.1.1.1.1.m1.1b"><apply id="S6.T2.1.1.1.1.m1.1.1.cmml" xref="S6.T2.1.1.1.1.m1.1.1"><divide id="S6.T2.1.1.1.1.m1.1.1.1.cmml" xref="S6.T2.1.1.1.1.m1.1.1"></divide><cn type="integer" id="S6.T2.1.1.1.1.m1.1.1.2.cmml" xref="S6.T2.1.1.1.1.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.1.1.1.1.m1.1.1.3.cmml" xref="S6.T2.1.1.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.1.1.1.1.m1.1c">\frac{1}{6}</annotation></semantics></math></th>
<th id="S6.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.T2.2.2.2.2.m1.1a"><mfrac id="S6.T2.2.2.2.2.m1.1.1" xref="S6.T2.2.2.2.2.m1.1.1.cmml"><mn id="S6.T2.2.2.2.2.m1.1.1.2" xref="S6.T2.2.2.2.2.m1.1.1.2.cmml">1</mn><mn id="S6.T2.2.2.2.2.m1.1.1.3" xref="S6.T2.2.2.2.2.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.2.2.2.2.m1.1b"><apply id="S6.T2.2.2.2.2.m1.1.1.cmml" xref="S6.T2.2.2.2.2.m1.1.1"><divide id="S6.T2.2.2.2.2.m1.1.1.1.cmml" xref="S6.T2.2.2.2.2.m1.1.1"></divide><cn type="integer" id="S6.T2.2.2.2.2.m1.1.1.2.cmml" xref="S6.T2.2.2.2.2.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.2.2.2.2.m1.1.1.3.cmml" xref="S6.T2.2.2.2.2.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.2.2.2.2.m1.1c">\frac{1}{3}</annotation></semantics></math></th>
<th id="S6.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.T2.3.3.3.3.m1.1a"><mfrac id="S6.T2.3.3.3.3.m1.1.1" xref="S6.T2.3.3.3.3.m1.1.1.cmml"><mn id="S6.T2.3.3.3.3.m1.1.1.2" xref="S6.T2.3.3.3.3.m1.1.1.2.cmml">2</mn><mn id="S6.T2.3.3.3.3.m1.1.1.3" xref="S6.T2.3.3.3.3.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.3.3.3.3.m1.1b"><apply id="S6.T2.3.3.3.3.m1.1.1.cmml" xref="S6.T2.3.3.3.3.m1.1.1"><divide id="S6.T2.3.3.3.3.m1.1.1.1.cmml" xref="S6.T2.3.3.3.3.m1.1.1"></divide><cn type="integer" id="S6.T2.3.3.3.3.m1.1.1.2.cmml" xref="S6.T2.3.3.3.3.m1.1.1.2">2</cn><cn type="integer" id="S6.T2.3.3.3.3.m1.1.1.3.cmml" xref="S6.T2.3.3.3.3.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.3.3.3.m1.1c">\frac{2}{3}</annotation></semantics></math></th>
<th id="S6.T2.12.12.12.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1</th>
<th id="S6.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.T2.4.4.4.4.m1.1a"><mfrac id="S6.T2.4.4.4.4.m1.1.1" xref="S6.T2.4.4.4.4.m1.1.1.cmml"><mn id="S6.T2.4.4.4.4.m1.1.1.2" xref="S6.T2.4.4.4.4.m1.1.1.2.cmml">1</mn><mn id="S6.T2.4.4.4.4.m1.1.1.3" xref="S6.T2.4.4.4.4.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.4.4.4.4.m1.1b"><apply id="S6.T2.4.4.4.4.m1.1.1.cmml" xref="S6.T2.4.4.4.4.m1.1.1"><divide id="S6.T2.4.4.4.4.m1.1.1.1.cmml" xref="S6.T2.4.4.4.4.m1.1.1"></divide><cn type="integer" id="S6.T2.4.4.4.4.m1.1.1.2.cmml" xref="S6.T2.4.4.4.4.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.4.4.4.4.m1.1.1.3.cmml" xref="S6.T2.4.4.4.4.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.4.4.4.4.m1.1c">\frac{1}{6}</annotation></semantics></math></th>
<th id="S6.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.5.5.5.5.m1.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.T2.5.5.5.5.m1.1a"><mfrac id="S6.T2.5.5.5.5.m1.1.1" xref="S6.T2.5.5.5.5.m1.1.1.cmml"><mn id="S6.T2.5.5.5.5.m1.1.1.2" xref="S6.T2.5.5.5.5.m1.1.1.2.cmml">1</mn><mn id="S6.T2.5.5.5.5.m1.1.1.3" xref="S6.T2.5.5.5.5.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.5.5.5.5.m1.1b"><apply id="S6.T2.5.5.5.5.m1.1.1.cmml" xref="S6.T2.5.5.5.5.m1.1.1"><divide id="S6.T2.5.5.5.5.m1.1.1.1.cmml" xref="S6.T2.5.5.5.5.m1.1.1"></divide><cn type="integer" id="S6.T2.5.5.5.5.m1.1.1.2.cmml" xref="S6.T2.5.5.5.5.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.5.5.5.5.m1.1.1.3.cmml" xref="S6.T2.5.5.5.5.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.5.5.5.5.m1.1c">\frac{1}{3}</annotation></semantics></math></th>
<th id="S6.T2.6.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.6.6.6.6.m1.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.T2.6.6.6.6.m1.1a"><mfrac id="S6.T2.6.6.6.6.m1.1.1" xref="S6.T2.6.6.6.6.m1.1.1.cmml"><mn id="S6.T2.6.6.6.6.m1.1.1.2" xref="S6.T2.6.6.6.6.m1.1.1.2.cmml">2</mn><mn id="S6.T2.6.6.6.6.m1.1.1.3" xref="S6.T2.6.6.6.6.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.6.6.6.6.m1.1b"><apply id="S6.T2.6.6.6.6.m1.1.1.cmml" xref="S6.T2.6.6.6.6.m1.1.1"><divide id="S6.T2.6.6.6.6.m1.1.1.1.cmml" xref="S6.T2.6.6.6.6.m1.1.1"></divide><cn type="integer" id="S6.T2.6.6.6.6.m1.1.1.2.cmml" xref="S6.T2.6.6.6.6.m1.1.1.2">2</cn><cn type="integer" id="S6.T2.6.6.6.6.m1.1.1.3.cmml" xref="S6.T2.6.6.6.6.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.6.6.6.6.m1.1c">\frac{2}{3}</annotation></semantics></math></th>
<th id="S6.T2.12.12.12.16" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1</th>
<th id="S6.T2.7.7.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.7.7.7.7.m1.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.T2.7.7.7.7.m1.1a"><mfrac id="S6.T2.7.7.7.7.m1.1.1" xref="S6.T2.7.7.7.7.m1.1.1.cmml"><mn id="S6.T2.7.7.7.7.m1.1.1.2" xref="S6.T2.7.7.7.7.m1.1.1.2.cmml">1</mn><mn id="S6.T2.7.7.7.7.m1.1.1.3" xref="S6.T2.7.7.7.7.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.7.7.7.7.m1.1b"><apply id="S6.T2.7.7.7.7.m1.1.1.cmml" xref="S6.T2.7.7.7.7.m1.1.1"><divide id="S6.T2.7.7.7.7.m1.1.1.1.cmml" xref="S6.T2.7.7.7.7.m1.1.1"></divide><cn type="integer" id="S6.T2.7.7.7.7.m1.1.1.2.cmml" xref="S6.T2.7.7.7.7.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.7.7.7.7.m1.1.1.3.cmml" xref="S6.T2.7.7.7.7.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.7.7.7.7.m1.1c">\frac{1}{6}</annotation></semantics></math></th>
<th id="S6.T2.8.8.8.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.8.8.8.8.m1.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.T2.8.8.8.8.m1.1a"><mfrac id="S6.T2.8.8.8.8.m1.1.1" xref="S6.T2.8.8.8.8.m1.1.1.cmml"><mn id="S6.T2.8.8.8.8.m1.1.1.2" xref="S6.T2.8.8.8.8.m1.1.1.2.cmml">1</mn><mn id="S6.T2.8.8.8.8.m1.1.1.3" xref="S6.T2.8.8.8.8.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.8.8.8.8.m1.1b"><apply id="S6.T2.8.8.8.8.m1.1.1.cmml" xref="S6.T2.8.8.8.8.m1.1.1"><divide id="S6.T2.8.8.8.8.m1.1.1.1.cmml" xref="S6.T2.8.8.8.8.m1.1.1"></divide><cn type="integer" id="S6.T2.8.8.8.8.m1.1.1.2.cmml" xref="S6.T2.8.8.8.8.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.8.8.8.8.m1.1.1.3.cmml" xref="S6.T2.8.8.8.8.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.8.8.8.8.m1.1c">\frac{1}{3}</annotation></semantics></math></th>
<th id="S6.T2.9.9.9.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.9.9.9.9.m1.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.T2.9.9.9.9.m1.1a"><mfrac id="S6.T2.9.9.9.9.m1.1.1" xref="S6.T2.9.9.9.9.m1.1.1.cmml"><mn id="S6.T2.9.9.9.9.m1.1.1.2" xref="S6.T2.9.9.9.9.m1.1.1.2.cmml">2</mn><mn id="S6.T2.9.9.9.9.m1.1.1.3" xref="S6.T2.9.9.9.9.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.9.9.9.9.m1.1b"><apply id="S6.T2.9.9.9.9.m1.1.1.cmml" xref="S6.T2.9.9.9.9.m1.1.1"><divide id="S6.T2.9.9.9.9.m1.1.1.1.cmml" xref="S6.T2.9.9.9.9.m1.1.1"></divide><cn type="integer" id="S6.T2.9.9.9.9.m1.1.1.2.cmml" xref="S6.T2.9.9.9.9.m1.1.1.2">2</cn><cn type="integer" id="S6.T2.9.9.9.9.m1.1.1.3.cmml" xref="S6.T2.9.9.9.9.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.9.9.9.9.m1.1c">\frac{2}{3}</annotation></semantics></math></th>
<th id="S6.T2.12.12.12.17" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1</th>
<th id="S6.T2.10.10.10.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.10.10.10.10.m1.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.T2.10.10.10.10.m1.1a"><mfrac id="S6.T2.10.10.10.10.m1.1.1" xref="S6.T2.10.10.10.10.m1.1.1.cmml"><mn id="S6.T2.10.10.10.10.m1.1.1.2" xref="S6.T2.10.10.10.10.m1.1.1.2.cmml">1</mn><mn id="S6.T2.10.10.10.10.m1.1.1.3" xref="S6.T2.10.10.10.10.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.10.10.10.10.m1.1b"><apply id="S6.T2.10.10.10.10.m1.1.1.cmml" xref="S6.T2.10.10.10.10.m1.1.1"><divide id="S6.T2.10.10.10.10.m1.1.1.1.cmml" xref="S6.T2.10.10.10.10.m1.1.1"></divide><cn type="integer" id="S6.T2.10.10.10.10.m1.1.1.2.cmml" xref="S6.T2.10.10.10.10.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.10.10.10.10.m1.1.1.3.cmml" xref="S6.T2.10.10.10.10.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.10.10.10.10.m1.1c">\frac{1}{6}</annotation></semantics></math></th>
<th id="S6.T2.11.11.11.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.11.11.11.11.m1.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.T2.11.11.11.11.m1.1a"><mfrac id="S6.T2.11.11.11.11.m1.1.1" xref="S6.T2.11.11.11.11.m1.1.1.cmml"><mn id="S6.T2.11.11.11.11.m1.1.1.2" xref="S6.T2.11.11.11.11.m1.1.1.2.cmml">1</mn><mn id="S6.T2.11.11.11.11.m1.1.1.3" xref="S6.T2.11.11.11.11.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.11.11.11.11.m1.1b"><apply id="S6.T2.11.11.11.11.m1.1.1.cmml" xref="S6.T2.11.11.11.11.m1.1.1"><divide id="S6.T2.11.11.11.11.m1.1.1.1.cmml" xref="S6.T2.11.11.11.11.m1.1.1"></divide><cn type="integer" id="S6.T2.11.11.11.11.m1.1.1.2.cmml" xref="S6.T2.11.11.11.11.m1.1.1.2">1</cn><cn type="integer" id="S6.T2.11.11.11.11.m1.1.1.3.cmml" xref="S6.T2.11.11.11.11.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.11.11.11.11.m1.1c">\frac{1}{3}</annotation></semantics></math></th>
<th id="S6.T2.12.12.12.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S6.T2.12.12.12.12.m1.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.T2.12.12.12.12.m1.1a"><mfrac id="S6.T2.12.12.12.12.m1.1.1" xref="S6.T2.12.12.12.12.m1.1.1.cmml"><mn id="S6.T2.12.12.12.12.m1.1.1.2" xref="S6.T2.12.12.12.12.m1.1.1.2.cmml">2</mn><mn id="S6.T2.12.12.12.12.m1.1.1.3" xref="S6.T2.12.12.12.12.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.T2.12.12.12.12.m1.1b"><apply id="S6.T2.12.12.12.12.m1.1.1.cmml" xref="S6.T2.12.12.12.12.m1.1.1"><divide id="S6.T2.12.12.12.12.m1.1.1.1.cmml" xref="S6.T2.12.12.12.12.m1.1.1"></divide><cn type="integer" id="S6.T2.12.12.12.12.m1.1.1.2.cmml" xref="S6.T2.12.12.12.12.m1.1.1.2">2</cn><cn type="integer" id="S6.T2.12.12.12.12.m1.1.1.3.cmml" xref="S6.T2.12.12.12.12.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.12.12.12.12.m1.1c">\frac{2}{3}</annotation></semantics></math></th>
<th id="S6.T2.12.12.12.18" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.13.13.13" class="ltx_tr">
<th id="S6.T2.13.13.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T2.13.13.13.2.1" class="ltx_text">mT5</span></th>
<th id="S6.T2.13.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">1<math id="S6.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.13.13.13.1.m1.1a"><mo id="S6.T2.13.13.13.1.m1.1.1" xref="S6.T2.13.13.13.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.13.13.13.1.m1.1b"><times id="S6.T2.13.13.13.1.m1.1.1.cmml" xref="S6.T2.13.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.13.13.13.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.13.13.13.3" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
<td id="S6.T2.13.13.13.4" class="ltx_td ltx_align_center ltx_border_t">4.29</td>
<td id="S6.T2.13.13.13.5" class="ltx_td ltx_align_center ltx_border_t">3.77</td>
<td id="S6.T2.13.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.42</td>
<td id="S6.T2.13.13.13.7" class="ltx_td ltx_align_center ltx_border_t">9.68</td>
<td id="S6.T2.13.13.13.8" class="ltx_td ltx_align_center ltx_border_t">9.33</td>
<td id="S6.T2.13.13.13.9" class="ltx_td ltx_align_center ltx_border_t">9.02</td>
<td id="S6.T2.13.13.13.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.87</td>
<td id="S6.T2.13.13.13.11" class="ltx_td ltx_align_center ltx_border_t">3.78</td>
<td id="S6.T2.13.13.13.12" class="ltx_td ltx_align_center ltx_border_t">3.33</td>
<td id="S6.T2.13.13.13.13" class="ltx_td ltx_align_center ltx_border_t">2.99</td>
<td id="S6.T2.13.13.13.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.74</td>
<td id="S6.T2.13.13.13.15" class="ltx_td ltx_align_center ltx_border_t">31.44</td>
<td id="S6.T2.13.13.13.16" class="ltx_td ltx_align_center ltx_border_t">29.80</td>
<td id="S6.T2.13.13.13.17" class="ltx_td ltx_align_center ltx_border_t">28.35</td>
<td id="S6.T2.13.13.13.18" class="ltx_td ltx_align_center ltx_border_t">27.70</td>
</tr>
<tr id="S6.T2.14.14.14" class="ltx_tr">
<th id="S6.T2.14.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2<math id="S6.T2.14.14.14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.14.14.14.1.m1.1a"><mo id="S6.T2.14.14.14.1.m1.1.1" xref="S6.T2.14.14.14.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.14.14.14.1.m1.1b"><times id="S6.T2.14.14.14.1.m1.1.1.cmml" xref="S6.T2.14.14.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.14.14.14.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.14.14.14.2" class="ltx_td ltx_align_center">4.32</td>
<td id="S6.T2.14.14.14.3" class="ltx_td ltx_align_center">4.10</td>
<td id="S6.T2.14.14.14.4" class="ltx_td ltx_align_center">3.52</td>
<td id="S6.T2.14.14.14.5" class="ltx_td ltx_align_center ltx_border_r">3.24</td>
<td id="S6.T2.14.14.14.6" class="ltx_td ltx_align_center">9.44</td>
<td id="S6.T2.14.14.14.7" class="ltx_td ltx_align_center">9.12</td>
<td id="S6.T2.14.14.14.8" class="ltx_td ltx_align_center">8.83</td>
<td id="S6.T2.14.14.14.9" class="ltx_td ltx_align_center ltx_border_r">8.49</td>
<td id="S6.T2.14.14.14.10" class="ltx_td ltx_align_center">3.63</td>
<td id="S6.T2.14.14.14.11" class="ltx_td ltx_align_center">3.15</td>
<td id="S6.T2.14.14.14.12" class="ltx_td ltx_align_center">2.63</td>
<td id="S6.T2.14.14.14.13" class="ltx_td ltx_align_center ltx_border_r">2.51</td>
<td id="S6.T2.14.14.14.14" class="ltx_td ltx_align_center">29.83</td>
<td id="S6.T2.14.14.14.15" class="ltx_td ltx_align_center">28.69</td>
<td id="S6.T2.14.14.14.16" class="ltx_td ltx_align_center">27.83</td>
<td id="S6.T2.14.14.14.17" class="ltx_td ltx_align_center">26.89</td>
</tr>
<tr id="S6.T2.15.15.15" class="ltx_tr">
<th id="S6.T2.15.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">4<math id="S6.T2.15.15.15.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.15.15.15.1.m1.1a"><mo id="S6.T2.15.15.15.1.m1.1.1" xref="S6.T2.15.15.15.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.15.15.15.1.m1.1b"><times id="S6.T2.15.15.15.1.m1.1.1.cmml" xref="S6.T2.15.15.15.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.15.15.15.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.15.15.15.2" class="ltx_td ltx_align_center">4.24</td>
<td id="S6.T2.15.15.15.3" class="ltx_td ltx_align_center">3.71</td>
<td id="S6.T2.15.15.15.4" class="ltx_td ltx_align_center">3.13</td>
<td id="S6.T2.15.15.15.5" class="ltx_td ltx_align_center ltx_border_r">3.00</td>
<td id="S6.T2.15.15.15.6" class="ltx_td ltx_align_center">9.35</td>
<td id="S6.T2.15.15.15.7" class="ltx_td ltx_align_center">9.00</td>
<td id="S6.T2.15.15.15.8" class="ltx_td ltx_align_center">8.60</td>
<td id="S6.T2.15.15.15.9" class="ltx_td ltx_align_center ltx_border_r">8.31</td>
<td id="S6.T2.15.15.15.10" class="ltx_td ltx_align_center">3.54</td>
<td id="S6.T2.15.15.15.11" class="ltx_td ltx_align_center">3.05</td>
<td id="S6.T2.15.15.15.12" class="ltx_td ltx_align_center">2.40</td>
<td id="S6.T2.15.15.15.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.15.15.15.13.1" class="ltx_text ltx_font_bold">2.33</span></td>
<td id="S6.T2.15.15.15.14" class="ltx_td ltx_align_center">29.31</td>
<td id="S6.T2.15.15.15.15" class="ltx_td ltx_align_center">28.45</td>
<td id="S6.T2.15.15.15.16" class="ltx_td ltx_align_center">27.12</td>
<td id="S6.T2.15.15.15.17" class="ltx_td ltx_align_center"><span id="S6.T2.15.15.15.17.1" class="ltx_text ltx_font_bold">26.31</span></td>
</tr>
<tr id="S6.T2.16.16.16" class="ltx_tr">
<th id="S6.T2.16.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">8<math id="S6.T2.16.16.16.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.16.16.16.1.m1.1a"><mo id="S6.T2.16.16.16.1.m1.1.1" xref="S6.T2.16.16.16.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.16.16.16.1.m1.1b"><times id="S6.T2.16.16.16.1.m1.1.1.cmml" xref="S6.T2.16.16.16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.16.16.16.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.16.16.16.2" class="ltx_td ltx_align_center">4.24</td>
<td id="S6.T2.16.16.16.3" class="ltx_td ltx_align_center">3.68</td>
<td id="S6.T2.16.16.16.4" class="ltx_td ltx_align_center">3.05</td>
<td id="S6.T2.16.16.16.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.16.16.16.5.1" class="ltx_text ltx_font_bold">2.93</span></td>
<td id="S6.T2.16.16.16.6" class="ltx_td ltx_align_center">9.32</td>
<td id="S6.T2.16.16.16.7" class="ltx_td ltx_align_center">8.90</td>
<td id="S6.T2.16.16.16.8" class="ltx_td ltx_align_center">8.54</td>
<td id="S6.T2.16.16.16.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.16.16.16.9.1" class="ltx_text ltx_font_bold">8.29</span></td>
<td id="S6.T2.16.16.16.10" class="ltx_td ltx_align_center">3.55</td>
<td id="S6.T2.16.16.16.11" class="ltx_td ltx_align_center">3.02</td>
<td id="S6.T2.16.16.16.12" class="ltx_td ltx_align_center">2.39</td>
<td id="S6.T2.16.16.16.13" class="ltx_td ltx_align_center ltx_border_r">2.36</td>
<td id="S6.T2.16.16.16.14" class="ltx_td ltx_align_center">29.22</td>
<td id="S6.T2.16.16.16.15" class="ltx_td ltx_align_center">28.44</td>
<td id="S6.T2.16.16.16.16" class="ltx_td ltx_align_center">27.23</td>
<td id="S6.T2.16.16.16.17" class="ltx_td ltx_align_center">26.32</td>
</tr>
<tr id="S6.T2.17.17.17" class="ltx_tr">
<th id="S6.T2.17.17.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T2.17.17.17.2.1" class="ltx_text">ENSEMBLE</span></th>
<th id="S6.T2.17.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">1<math id="S6.T2.17.17.17.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.17.17.17.1.m1.1a"><mo id="S6.T2.17.17.17.1.m1.1.1" xref="S6.T2.17.17.17.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.17.17.17.1.m1.1b"><times id="S6.T2.17.17.17.1.m1.1.1.cmml" xref="S6.T2.17.17.17.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.17.17.17.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.17.17.17.3" class="ltx_td ltx_align_center ltx_border_t">4.84</td>
<td id="S6.T2.17.17.17.4" class="ltx_td ltx_align_center ltx_border_t">4.69</td>
<td id="S6.T2.17.17.17.5" class="ltx_td ltx_align_center ltx_border_t">4.51</td>
<td id="S6.T2.17.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.46</td>
<td id="S6.T2.17.17.17.7" class="ltx_td ltx_align_center ltx_border_t">10.18</td>
<td id="S6.T2.17.17.17.8" class="ltx_td ltx_align_center ltx_border_t">10.09</td>
<td id="S6.T2.17.17.17.9" class="ltx_td ltx_align_center ltx_border_t">10.00</td>
<td id="S6.T2.17.17.17.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.88</td>
<td id="S6.T2.17.17.17.11" class="ltx_td ltx_align_center ltx_border_t">4.09</td>
<td id="S6.T2.17.17.17.12" class="ltx_td ltx_align_center ltx_border_t">4.00</td>
<td id="S6.T2.17.17.17.13" class="ltx_td ltx_align_center ltx_border_t">3.90</td>
<td id="S6.T2.17.17.17.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.83</td>
<td id="S6.T2.17.17.17.15" class="ltx_td ltx_align_center ltx_border_t">40.23</td>
<td id="S6.T2.17.17.17.16" class="ltx_td ltx_align_center ltx_border_t">38.47</td>
<td id="S6.T2.17.17.17.17" class="ltx_td ltx_align_center ltx_border_t">38.02</td>
<td id="S6.T2.17.17.17.18" class="ltx_td ltx_align_center ltx_border_t">37.71</td>
</tr>
<tr id="S6.T2.18.18.18" class="ltx_tr">
<th id="S6.T2.18.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2<math id="S6.T2.18.18.18.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.18.18.18.1.m1.1a"><mo id="S6.T2.18.18.18.1.m1.1.1" xref="S6.T2.18.18.18.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.18.18.18.1.m1.1b"><times id="S6.T2.18.18.18.1.m1.1.1.cmml" xref="S6.T2.18.18.18.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.18.18.18.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.18.18.18.2" class="ltx_td ltx_align_center">4.80</td>
<td id="S6.T2.18.18.18.3" class="ltx_td ltx_align_center">4.63</td>
<td id="S6.T2.18.18.18.4" class="ltx_td ltx_align_center">4.44</td>
<td id="S6.T2.18.18.18.5" class="ltx_td ltx_align_center ltx_border_r">4.30</td>
<td id="S6.T2.18.18.18.6" class="ltx_td ltx_align_center">10.09</td>
<td id="S6.T2.18.18.18.7" class="ltx_td ltx_align_center">10.03</td>
<td id="S6.T2.18.18.18.8" class="ltx_td ltx_align_center">9.88</td>
<td id="S6.T2.18.18.18.9" class="ltx_td ltx_align_center ltx_border_r">9.74</td>
<td id="S6.T2.18.18.18.10" class="ltx_td ltx_align_center">4.06</td>
<td id="S6.T2.18.18.18.11" class="ltx_td ltx_align_center">3.85</td>
<td id="S6.T2.18.18.18.12" class="ltx_td ltx_align_center">3.80</td>
<td id="S6.T2.18.18.18.13" class="ltx_td ltx_align_center ltx_border_r">3.71</td>
<td id="S6.T2.18.18.18.14" class="ltx_td ltx_align_center">38.99</td>
<td id="S6.T2.18.18.18.15" class="ltx_td ltx_align_center">38.65</td>
<td id="S6.T2.18.18.18.16" class="ltx_td ltx_align_center">38.21</td>
<td id="S6.T2.18.18.18.17" class="ltx_td ltx_align_center">36.60</td>
</tr>
<tr id="S6.T2.19.19.19" class="ltx_tr">
<th id="S6.T2.19.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">4<math id="S6.T2.19.19.19.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.19.19.19.1.m1.1a"><mo id="S6.T2.19.19.19.1.m1.1.1" xref="S6.T2.19.19.19.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.19.19.19.1.m1.1b"><times id="S6.T2.19.19.19.1.m1.1.1.cmml" xref="S6.T2.19.19.19.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.19.19.19.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.19.19.19.2" class="ltx_td ltx_align_center">4.75</td>
<td id="S6.T2.19.19.19.3" class="ltx_td ltx_align_center">4.53</td>
<td id="S6.T2.19.19.19.4" class="ltx_td ltx_align_center">4.23</td>
<td id="S6.T2.19.19.19.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.19.19.19.5.1" class="ltx_text ltx_font_bold">4.19</span></td>
<td id="S6.T2.19.19.19.6" class="ltx_td ltx_align_center">10.14</td>
<td id="S6.T2.19.19.19.7" class="ltx_td ltx_align_center">9.94</td>
<td id="S6.T2.19.19.19.8" class="ltx_td ltx_align_center">9.83</td>
<td id="S6.T2.19.19.19.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.19.19.19.9.1" class="ltx_text ltx_font_bold">9.64</span></td>
<td id="S6.T2.19.19.19.10" class="ltx_td ltx_align_center">4.02</td>
<td id="S6.T2.19.19.19.11" class="ltx_td ltx_align_center">3.72</td>
<td id="S6.T2.19.19.19.12" class="ltx_td ltx_align_center">3.69</td>
<td id="S6.T2.19.19.19.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T2.19.19.19.13.1" class="ltx_text ltx_font_bold">3.52</span></td>
<td id="S6.T2.19.19.19.14" class="ltx_td ltx_align_center">38.78</td>
<td id="S6.T2.19.19.19.15" class="ltx_td ltx_align_center">38.17</td>
<td id="S6.T2.19.19.19.16" class="ltx_td ltx_align_center">37.43</td>
<td id="S6.T2.19.19.19.17" class="ltx_td ltx_align_center">35.66</td>
</tr>
<tr id="S6.T2.20.20.20" class="ltx_tr">
<th id="S6.T2.20.20.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">8<math id="S6.T2.20.20.20.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.20.20.20.1.m1.1a"><mo id="S6.T2.20.20.20.1.m1.1.1" xref="S6.T2.20.20.20.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.T2.20.20.20.1.m1.1b"><times id="S6.T2.20.20.20.1.m1.1.1.cmml" xref="S6.T2.20.20.20.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.20.20.20.1.m1.1c">\times</annotation></semantics></math>
</th>
<td id="S6.T2.20.20.20.2" class="ltx_td ltx_align_center ltx_border_bb">4.79</td>
<td id="S6.T2.20.20.20.3" class="ltx_td ltx_align_center ltx_border_bb">4.48</td>
<td id="S6.T2.20.20.20.4" class="ltx_td ltx_align_center ltx_border_bb">4.24</td>
<td id="S6.T2.20.20.20.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">4.22</td>
<td id="S6.T2.20.20.20.6" class="ltx_td ltx_align_center ltx_border_bb">10.11</td>
<td id="S6.T2.20.20.20.7" class="ltx_td ltx_align_center ltx_border_bb">9.97</td>
<td id="S6.T2.20.20.20.8" class="ltx_td ltx_align_center ltx_border_bb">9.80</td>
<td id="S6.T2.20.20.20.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">9.69</td>
<td id="S6.T2.20.20.20.10" class="ltx_td ltx_align_center ltx_border_bb">4.00</td>
<td id="S6.T2.20.20.20.11" class="ltx_td ltx_align_center ltx_border_bb">3.74</td>
<td id="S6.T2.20.20.20.12" class="ltx_td ltx_align_center ltx_border_bb">3.63</td>
<td id="S6.T2.20.20.20.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">3.60</td>
<td id="S6.T2.20.20.20.14" class="ltx_td ltx_align_center ltx_border_bb">38.65</td>
<td id="S6.T2.20.20.20.15" class="ltx_td ltx_align_center ltx_border_bb">37.75</td>
<td id="S6.T2.20.20.20.16" class="ltx_td ltx_align_center ltx_border_bb">36.54</td>
<td id="S6.T2.20.20.20.17" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T2.20.20.20.17.1" class="ltx_text ltx_font_bold">35.59</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results showing the effects of data volume and augmentation on mT5 and ENSEMBLE model CER on English, Icelandic, and Russian texts.</figcaption>
</figure>
<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">The process of generating OCR synthetic data is highly stochastic, so the same clean text can yield different synthetic text versions when OCR errors are inserted. This variability can potentially enrich the modelâ€™s learning process. In this experiment, we investigate the impact of data augmentation techniques (by replicating the clean text data multiple times to increase the volume of data) and the quantity of original clean text data used on model performance. We examine whether increasing the diversity of data via this method can enhance the modelâ€™s ability to correct OCR errors.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">The experiment is conducted on English, Icelandic, Russian and Telugu texts. These languages were chosen as they include both rich-resource and low-resource languages and belong to different language families, and have different grammatical structures and character sets. This diversity makes them representative for assessing different models and methods for generating synthetic data.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.12" class="ltx_p">To explore the impact of the original data volume, we experiment with datasets of different sizes: the full dataset size, <math id="S6.SS1.p3.1.m1.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.SS1.p3.1.m1.1a"><mfrac id="S6.SS1.p3.1.m1.1.1" xref="S6.SS1.p3.1.m1.1.1.cmml"><mn id="S6.SS1.p3.1.m1.1.1.2" xref="S6.SS1.p3.1.m1.1.1.2.cmml">2</mn><mn id="S6.SS1.p3.1.m1.1.1.3" xref="S6.SS1.p3.1.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.1.m1.1b"><apply id="S6.SS1.p3.1.m1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1"><divide id="S6.SS1.p3.1.m1.1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1"></divide><cn type="integer" id="S6.SS1.p3.1.m1.1.1.2.cmml" xref="S6.SS1.p3.1.m1.1.1.2">2</cn><cn type="integer" id="S6.SS1.p3.1.m1.1.1.3.cmml" xref="S6.SS1.p3.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.1.m1.1c">\frac{2}{3}</annotation></semantics></math> size, <math id="S6.SS1.p3.2.m2.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.SS1.p3.2.m2.1a"><mfrac id="S6.SS1.p3.2.m2.1.1" xref="S6.SS1.p3.2.m2.1.1.cmml"><mn id="S6.SS1.p3.2.m2.1.1.2" xref="S6.SS1.p3.2.m2.1.1.2.cmml">1</mn><mn id="S6.SS1.p3.2.m2.1.1.3" xref="S6.SS1.p3.2.m2.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.2.m2.1b"><apply id="S6.SS1.p3.2.m2.1.1.cmml" xref="S6.SS1.p3.2.m2.1.1"><divide id="S6.SS1.p3.2.m2.1.1.1.cmml" xref="S6.SS1.p3.2.m2.1.1"></divide><cn type="integer" id="S6.SS1.p3.2.m2.1.1.2.cmml" xref="S6.SS1.p3.2.m2.1.1.2">1</cn><cn type="integer" id="S6.SS1.p3.2.m2.1.1.3.cmml" xref="S6.SS1.p3.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.2.m2.1c">\frac{1}{3}</annotation></semantics></math> size, and <math id="S6.SS1.p3.3.m3.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.SS1.p3.3.m3.1a"><mfrac id="S6.SS1.p3.3.m3.1.1" xref="S6.SS1.p3.3.m3.1.1.cmml"><mn id="S6.SS1.p3.3.m3.1.1.2" xref="S6.SS1.p3.3.m3.1.1.2.cmml">1</mn><mn id="S6.SS1.p3.3.m3.1.1.3" xref="S6.SS1.p3.3.m3.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.3.m3.1b"><apply id="S6.SS1.p3.3.m3.1.1.cmml" xref="S6.SS1.p3.3.m3.1.1"><divide id="S6.SS1.p3.3.m3.1.1.1.cmml" xref="S6.SS1.p3.3.m3.1.1"></divide><cn type="integer" id="S6.SS1.p3.3.m3.1.1.2.cmml" xref="S6.SS1.p3.3.m3.1.1.2">1</cn><cn type="integer" id="S6.SS1.p3.3.m3.1.1.3.cmml" xref="S6.SS1.p3.3.m3.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.3.m3.1c">\frac{1}{6}</annotation></semantics></math> size, as in post-OCR correction tasks, the training data often need to be from the same domain as the text need to be fixed, so the settings of 1, <math id="S6.SS1.p3.4.m4.1" class="ltx_Math" alttext="\frac{2}{3}" display="inline"><semantics id="S6.SS1.p3.4.m4.1a"><mfrac id="S6.SS1.p3.4.m4.1.1" xref="S6.SS1.p3.4.m4.1.1.cmml"><mn id="S6.SS1.p3.4.m4.1.1.2" xref="S6.SS1.p3.4.m4.1.1.2.cmml">2</mn><mn id="S6.SS1.p3.4.m4.1.1.3" xref="S6.SS1.p3.4.m4.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.4.m4.1b"><apply id="S6.SS1.p3.4.m4.1.1.cmml" xref="S6.SS1.p3.4.m4.1.1"><divide id="S6.SS1.p3.4.m4.1.1.1.cmml" xref="S6.SS1.p3.4.m4.1.1"></divide><cn type="integer" id="S6.SS1.p3.4.m4.1.1.2.cmml" xref="S6.SS1.p3.4.m4.1.1.2">2</cn><cn type="integer" id="S6.SS1.p3.4.m4.1.1.3.cmml" xref="S6.SS1.p3.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.4.m4.1c">\frac{2}{3}</annotation></semantics></math>, <math id="S6.SS1.p3.5.m5.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S6.SS1.p3.5.m5.1a"><mfrac id="S6.SS1.p3.5.m5.1.1" xref="S6.SS1.p3.5.m5.1.1.cmml"><mn id="S6.SS1.p3.5.m5.1.1.2" xref="S6.SS1.p3.5.m5.1.1.2.cmml">1</mn><mn id="S6.SS1.p3.5.m5.1.1.3" xref="S6.SS1.p3.5.m5.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.5.m5.1b"><apply id="S6.SS1.p3.5.m5.1.1.cmml" xref="S6.SS1.p3.5.m5.1.1"><divide id="S6.SS1.p3.5.m5.1.1.1.cmml" xref="S6.SS1.p3.5.m5.1.1"></divide><cn type="integer" id="S6.SS1.p3.5.m5.1.1.2.cmml" xref="S6.SS1.p3.5.m5.1.1.2">1</cn><cn type="integer" id="S6.SS1.p3.5.m5.1.1.3.cmml" xref="S6.SS1.p3.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.5.m5.1c">\frac{1}{3}</annotation></semantics></math>, and <math id="S6.SS1.p3.6.m6.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="S6.SS1.p3.6.m6.1a"><mfrac id="S6.SS1.p3.6.m6.1.1" xref="S6.SS1.p3.6.m6.1.1.cmml"><mn id="S6.SS1.p3.6.m6.1.1.2" xref="S6.SS1.p3.6.m6.1.1.2.cmml">1</mn><mn id="S6.SS1.p3.6.m6.1.1.3" xref="S6.SS1.p3.6.m6.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.6.m6.1b"><apply id="S6.SS1.p3.6.m6.1.1.cmml" xref="S6.SS1.p3.6.m6.1.1"><divide id="S6.SS1.p3.6.m6.1.1.1.cmml" xref="S6.SS1.p3.6.m6.1.1"></divide><cn type="integer" id="S6.SS1.p3.6.m6.1.1.2.cmml" xref="S6.SS1.p3.6.m6.1.1.2">1</cn><cn type="integer" id="S6.SS1.p3.6.m6.1.1.3.cmml" xref="S6.SS1.p3.6.m6.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.6.m6.1c">\frac{1}{6}</annotation></semantics></math> were designed to simulate the scenarios within different domains under one language environment with varying amounts of clean texts.
And to examine the effect of data augmentation techniques, these will be further expanded to 1<math id="S6.SS1.p3.7.m7.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p3.7.m7.1a"><mo id="S6.SS1.p3.7.m7.1.1" xref="S6.SS1.p3.7.m7.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.7.m7.1b"><times id="S6.SS1.p3.7.m7.1.1.cmml" xref="S6.SS1.p3.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.7.m7.1c">\times</annotation></semantics></math>, 2<math id="S6.SS1.p3.8.m8.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p3.8.m8.1a"><mo id="S6.SS1.p3.8.m8.1.1" xref="S6.SS1.p3.8.m8.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.8.m8.1b"><times id="S6.SS1.p3.8.m8.1.1.cmml" xref="S6.SS1.p3.8.m8.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.8.m8.1c">\times</annotation></semantics></math>, 4<math id="S6.SS1.p3.9.m9.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p3.9.m9.1a"><mo id="S6.SS1.p3.9.m9.1.1" xref="S6.SS1.p3.9.m9.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.9.m9.1b"><times id="S6.SS1.p3.9.m9.1.1.cmml" xref="S6.SS1.p3.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.9.m9.1c">\times</annotation></semantics></math> and 8<math id="S6.SS1.p3.10.m10.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p3.10.m10.1a"><mo id="S6.SS1.p3.10.m10.1.1" xref="S6.SS1.p3.10.m10.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.10.m10.1b"><times id="S6.SS1.p3.10.m10.1.1.cmml" xref="S6.SS1.p3.10.m10.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.10.m10.1c">\times</annotation></semantics></math> their original sizes. This approach will yield multiple versions of dataset <math id="S6.SS1.p3.11.m11.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S6.SS1.p3.11.m11.1a"><mi id="S6.SS1.p3.11.m11.1.1" xref="S6.SS1.p3.11.m11.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.11.m11.1b"><ci id="S6.SS1.p3.11.m11.1.1.cmml" xref="S6.SS1.p3.11.m11.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.11.m11.1c">A</annotation></semantics></math>, and since Method <math id="S6.SS1.p3.12.m12.1" class="ltx_Math" alttext="â‘¢" display="inline"><semantics id="S6.SS1.p3.12.m12.1a"><mn id="S6.SS1.p3.12.m12.1.1" xref="S6.SS1.p3.12.m12.1.1.cmml">â‘¢</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.12.m12.1b"><cn type="float" id="S6.SS1.p3.12.m12.1.1.cmml" xref="S6.SS1.p3.12.m12.1.1">circled-3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.12.m12.1c">â‘¢</annotation></semantics></math> is the most commonly used, we will employ it to generate the training data for this experiment. The experiments are conducted using both the pre-trained mT5-base model and ENSEMBLE model.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.6" class="ltx_p">The results in Table <a href="#S6.T2" title="Table 2 â€£ 6.1 Experiment 1 â€£ 6 Experiments â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show that mT5 outperforms the ENSEMBLE model across the four languages. Data augmentation enhances model performance with diminishing returns â€“ augmenting from 1<math id="S6.SS1.p4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.1.m1.1a"><mo id="S6.SS1.p4.1.m1.1.1" xref="S6.SS1.p4.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.1.m1.1b"><times id="S6.SS1.p4.1.m1.1.1.cmml" xref="S6.SS1.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.1.m1.1c">\times</annotation></semantics></math> to 4<math id="S6.SS1.p4.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.2.m2.1a"><mo id="S6.SS1.p4.2.m2.1.1" xref="S6.SS1.p4.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.2.m2.1b"><times id="S6.SS1.p4.2.m2.1.1.cmml" xref="S6.SS1.p4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.2.m2.1c">\times</annotation></semantics></math> effectively lowers CER, but gains from 4<math id="S6.SS1.p4.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.3.m3.1a"><mo id="S6.SS1.p4.3.m3.1.1" xref="S6.SS1.p4.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.3.m3.1b"><times id="S6.SS1.p4.3.m3.1.1.cmml" xref="S6.SS1.p4.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.3.m3.1c">\times</annotation></semantics></math> to 8<math id="S6.SS1.p4.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.4.m4.1a"><mo id="S6.SS1.p4.4.m4.1.1" xref="S6.SS1.p4.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.4.m4.1b"><times id="S6.SS1.p4.4.m4.1.1.cmml" xref="S6.SS1.p4.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.4.m4.1c">\times</annotation></semantics></math> are marginal. In our experiment, training parameters for mT5 included a learning rate of 5e-4, warm-up steps of 250, batch size of 4, dropout rate of 0.2, and 6 epochs on fp32. Training times for 4<math id="S6.SS1.p4.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.5.m5.1a"><mo id="S6.SS1.p4.5.m5.1.1" xref="S6.SS1.p4.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.5.m5.1b"><times id="S6.SS1.p4.5.m5.1.1.cmml" xref="S6.SS1.p4.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.5.m5.1c">\times</annotation></semantics></math> augmented datasets on an RTX 4090 were approximately 35, 5, 10 and 8 hours for English, Icelandic, Russian and Telugu, respectively. Overall, the results suggest that 4<math id="S6.SS1.p4.6.m6.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.SS1.p4.6.m6.1a"><mo id="S6.SS1.p4.6.m6.1.1" xref="S6.SS1.p4.6.m6.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p4.6.m6.1b"><times id="S6.SS1.p4.6.m6.1.1.cmml" xref="S6.SS1.p4.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p4.6.m6.1c">\times</annotation></semantics></math> augmentation provides sufficient improvement.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Experiment 2</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Next, we explore how different methods of creating synthetic data impact on the performance of different language models. We conduct tests using several popular models: mT5-base <cite class="ltx_cite ltx_citemacro_cite">Xue etÂ al. (<a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite>, ByT5-base <cite class="ltx_cite ltx_citemacro_cite">Xue etÂ al. (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite>, mBART-large <cite class="ltx_cite ltx_citemacro_cite">Chipman etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>, SCRATCH, and ENSEMBLE. We also evaluate the approach of <cite class="ltx_cite ltx_citemacro_citet">Chen and Zhou (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>, which combines CharBERT <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> with glyph embedding, and compare these results to CharBERT without glyph embedding.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<div id="S6.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:124.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-92.9pt,28.0pt) scale(0.689145761910403,0.689145761910403) ;">
<table id="S6.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.1.1.1.1" class="ltx_tr">
<th id="S6.T3.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S6.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">English</span></th>
<th id="S6.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Icelandic</span></th>
<th id="S6.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Russian</span></th>
<th id="S6.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Telugu</span></th>
</tr>
<tr id="S6.T3.1.1.2.2" class="ltx_tr">
<th id="S6.T3.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">CER</th>
<th id="S6.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">4.96</th>
<th id="S6.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">10.09</th>
<th id="S6.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">4.13</th>
<th id="S6.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">34.12</th>
</tr>
<tr id="S6.T3.1.1.3.3" class="ltx_tr">
<th id="S6.T3.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Method</th>
<th id="S6.T3.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘ </th>
<th id="S6.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¡</th>
<th id="S6.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¢</th>
<th id="S6.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">â‘£</th>
<th id="S6.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘ </th>
<th id="S6.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¡</th>
<th id="S6.T3.1.1.3.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¢</th>
<th id="S6.T3.1.1.3.3.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">â‘£</th>
<th id="S6.T3.1.1.3.3.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘ </th>
<th id="S6.T3.1.1.3.3.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¡</th>
<th id="S6.T3.1.1.3.3.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¢</th>
<th id="S6.T3.1.1.3.3.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">â‘£</th>
<th id="S6.T3.1.1.3.3.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘ </th>
<th id="S6.T3.1.1.3.3.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¡</th>
<th id="S6.T3.1.1.3.3.16" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘¢</th>
<th id="S6.T3.1.1.3.3.17" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">â‘£</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.1.1.4.1" class="ltx_tr">
<th id="S6.T3.1.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">mT5</th>
<td id="S6.T3.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.2.1" class="ltx_text ltx_font_bold">3.98</span></td>
<td id="S6.T3.1.1.4.1.3" class="ltx_td ltx_align_center ltx_border_t">3.42</td>
<td id="S6.T3.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.4.1" class="ltx_text ltx_ulem_uline">3.00</span></td>
<td id="S6.T3.1.1.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.03</td>
<td id="S6.T3.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_t">9.48</td>
<td id="S6.T3.1.1.4.1.7" class="ltx_td ltx_align_center ltx_border_t">9.53</td>
<td id="S6.T3.1.1.4.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.8.1" class="ltx_text ltx_ulem_uline ltx_font_bold">8.31</span></td>
<td id="S6.T3.1.1.4.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.38</td>
<td id="S6.T3.1.1.4.1.10" class="ltx_td ltx_align_center ltx_border_t">3.36</td>
<td id="S6.T3.1.1.4.1.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.11.1" class="ltx_text ltx_font_bold">2.98</span></td>
<td id="S6.T3.1.1.4.1.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.12.1" class="ltx_text ltx_font_bold">2.33</span></td>
<td id="S6.T3.1.1.4.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T3.1.1.4.1.13.1" class="ltx_text ltx_ulem_uline">2.27</span></td>
<td id="S6.T3.1.1.4.1.14" class="ltx_td ltx_align_center ltx_border_t">30.35</td>
<td id="S6.T3.1.1.4.1.15" class="ltx_td ltx_align_center ltx_border_t">28.24</td>
<td id="S6.T3.1.1.4.1.16" class="ltx_td ltx_align_center ltx_border_t">26.31</td>
<td id="S6.T3.1.1.4.1.17" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1.17.1" class="ltx_text ltx_ulem_uline">25.85</span></td>
</tr>
<tr id="S6.T3.1.1.5.2" class="ltx_tr">
<th id="S6.T3.1.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ByT5</th>
<td id="S6.T3.1.1.5.2.2" class="ltx_td ltx_align_center">4.02</td>
<td id="S6.T3.1.1.5.2.3" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.3.1" class="ltx_text ltx_font_bold">3.36</span></td>
<td id="S6.T3.1.1.5.2.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.4.1" class="ltx_text ltx_ulem_uline ltx_font_bold">2.96</span></td>
<td id="S6.T3.1.1.5.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.5.2.5.1" class="ltx_text ltx_font_bold">3.00</span></td>
<td id="S6.T3.1.1.5.2.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.6.1" class="ltx_text ltx_font_bold">9.42</span></td>
<td id="S6.T3.1.1.5.2.7" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.7.1" class="ltx_text ltx_font_bold">9.45</span></td>
<td id="S6.T3.1.1.5.2.8" class="ltx_td ltx_align_center">8.39</td>
<td id="S6.T3.1.1.5.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.5.2.9.1" class="ltx_text ltx_ulem_uline ltx_font_bold">8.28</span></td>
<td id="S6.T3.1.1.5.2.10" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.10.1" class="ltx_text ltx_font_bold">3.34</span></td>
<td id="S6.T3.1.1.5.2.11" class="ltx_td ltx_align_center">3.13</td>
<td id="S6.T3.1.1.5.2.12" class="ltx_td ltx_align_center">2.34</td>
<td id="S6.T3.1.1.5.2.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.5.2.13.1" class="ltx_text ltx_ulem_uline ltx_font_bold">2.14</span></td>
<td id="S6.T3.1.1.5.2.14" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.14.1" class="ltx_text ltx_font_bold">30.21</span></td>
<td id="S6.T3.1.1.5.2.15" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.15.1" class="ltx_text ltx_font_bold">28.14</span></td>
<td id="S6.T3.1.1.5.2.16" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.16.1" class="ltx_text ltx_font_bold">25.98</span></td>
<td id="S6.T3.1.1.5.2.17" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.2.17.1" class="ltx_text ltx_ulem_uline ltx_font_bold">25.28</span></td>
</tr>
<tr id="S6.T3.1.1.6.3" class="ltx_tr">
<th id="S6.T3.1.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">mBART</th>
<td id="S6.T3.1.1.6.3.2" class="ltx_td ltx_align_center">4.19</td>
<td id="S6.T3.1.1.6.3.3" class="ltx_td ltx_align_center">4.23</td>
<td id="S6.T3.1.1.6.3.4" class="ltx_td ltx_align_center">3.63</td>
<td id="S6.T3.1.1.6.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.6.3.5.1" class="ltx_text ltx_ulem_uline">3.54</span></td>
<td id="S6.T3.1.1.6.3.6" class="ltx_td ltx_align_center">9.93</td>
<td id="S6.T3.1.1.6.3.7" class="ltx_td ltx_align_center">10.26</td>
<td id="S6.T3.1.1.6.3.8" class="ltx_td ltx_align_center">9.41</td>
<td id="S6.T3.1.1.6.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.6.3.9.1" class="ltx_text ltx_ulem_uline">9.30</span></td>
<td id="S6.T3.1.1.6.3.10" class="ltx_td ltx_align_center">3.41</td>
<td id="S6.T3.1.1.6.3.11" class="ltx_td ltx_align_center">3.33</td>
<td id="S6.T3.1.1.6.3.12" class="ltx_td ltx_align_center">2.82</td>
<td id="S6.T3.1.1.6.3.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.6.3.13.1" class="ltx_text ltx_ulem_uline">2.78</span></td>
<td id="S6.T3.1.1.6.3.14" class="ltx_td ltx_align_center">31.06</td>
<td id="S6.T3.1.1.6.3.15" class="ltx_td ltx_align_center">28.49</td>
<td id="S6.T3.1.1.6.3.16" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.6.3.16.1" class="ltx_text ltx_ulem_uline">25.66</span></td>
<td id="S6.T3.1.1.6.3.17" class="ltx_td ltx_align_center">26.00</td>
</tr>
<tr id="S6.T3.1.1.7.4" class="ltx_tr">
<th id="S6.T3.1.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CharBERT</th>
<td id="S6.T3.1.1.7.4.2" class="ltx_td ltx_align_center">4.12</td>
<td id="S6.T3.1.1.7.4.3" class="ltx_td ltx_align_center">3.60</td>
<td id="S6.T3.1.1.7.4.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.7.4.4.1" class="ltx_text ltx_ulem_uline">3.39</span></td>
<td id="S6.T3.1.1.7.4.5" class="ltx_td ltx_align_center ltx_border_r">3.57</td>
<td id="S6.T3.1.1.7.4.6" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.7" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.8" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T3.1.1.7.4.10" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.11" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.12" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.13" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T3.1.1.7.4.14" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.15" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.16" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.7.4.17" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S6.T3.1.1.8.5" class="ltx_tr">
<th id="S6.T3.1.1.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Â Â â€ƒ+Glyph</th>
<td id="S6.T3.1.1.8.5.2" class="ltx_td ltx_align_center">4.11</td>
<td id="S6.T3.1.1.8.5.3" class="ltx_td ltx_align_center">3.61</td>
<td id="S6.T3.1.1.8.5.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.8.5.4.1" class="ltx_text ltx_ulem_uline">3.42</span></td>
<td id="S6.T3.1.1.8.5.5" class="ltx_td ltx_align_center ltx_border_r">3.54</td>
<td id="S6.T3.1.1.8.5.6" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.7" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.8" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T3.1.1.8.5.10" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.11" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.12" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.13" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T3.1.1.8.5.14" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.15" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.16" class="ltx_td ltx_align_center">-</td>
<td id="S6.T3.1.1.8.5.17" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S6.T3.1.1.9.6" class="ltx_tr">
<th id="S6.T3.1.1.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ENSEMBLE</th>
<td id="S6.T3.1.1.9.6.2" class="ltx_td ltx_align_center">4.56</td>
<td id="S6.T3.1.1.9.6.3" class="ltx_td ltx_align_center">4.44</td>
<td id="S6.T3.1.1.9.6.4" class="ltx_td ltx_align_center">4.19</td>
<td id="S6.T3.1.1.9.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.9.6.5.1" class="ltx_text ltx_ulem_uline">4.00</span></td>
<td id="S6.T3.1.1.9.6.6" class="ltx_td ltx_align_center">10.32</td>
<td id="S6.T3.1.1.9.6.7" class="ltx_td ltx_align_center">10.65</td>
<td id="S6.T3.1.1.9.6.8" class="ltx_td ltx_align_center">9.64</td>
<td id="S6.T3.1.1.9.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.9.6.9.1" class="ltx_text ltx_ulem_uline">9.54</span></td>
<td id="S6.T3.1.1.9.6.10" class="ltx_td ltx_align_center">3.77</td>
<td id="S6.T3.1.1.9.6.11" class="ltx_td ltx_align_center">3.83</td>
<td id="S6.T3.1.1.9.6.12" class="ltx_td ltx_align_center">3.52</td>
<td id="S6.T3.1.1.9.6.13" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T3.1.1.9.6.13.1" class="ltx_text ltx_ulem_uline">3.34</span></td>
<td id="S6.T3.1.1.9.6.14" class="ltx_td ltx_align_center">37.12</td>
<td id="S6.T3.1.1.9.6.15" class="ltx_td ltx_align_center">34.23</td>
<td id="S6.T3.1.1.9.6.16" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.9.6.16.1" class="ltx_text ltx_ulem_uline">35.66</span></td>
<td id="S6.T3.1.1.9.6.17" class="ltx_td ltx_align_center">37.50</td>
</tr>
<tr id="S6.T3.1.1.10.7" class="ltx_tr">
<th id="S6.T3.1.1.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">SCRATCH</th>
<td id="S6.T3.1.1.10.7.2" class="ltx_td ltx_align_center ltx_border_bb">4.79</td>
<td id="S6.T3.1.1.10.7.3" class="ltx_td ltx_align_center ltx_border_bb">4.74</td>
<td id="S6.T3.1.1.10.7.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.10.7.4.1" class="ltx_text ltx_ulem_uline">4.52</span></td>
<td id="S6.T3.1.1.10.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">4.62</td>
<td id="S6.T3.1.1.10.7.6" class="ltx_td ltx_align_center ltx_border_bb">11.92</td>
<td id="S6.T3.1.1.10.7.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.10.7.7.1" class="ltx_text ltx_ulem_uline">9.82</span></td>
<td id="S6.T3.1.1.10.7.8" class="ltx_td ltx_align_center ltx_border_bb">10.43</td>
<td id="S6.T3.1.1.10.7.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">10.00</td>
<td id="S6.T3.1.1.10.7.10" class="ltx_td ltx_align_center ltx_border_bb">3.91</td>
<td id="S6.T3.1.1.10.7.11" class="ltx_td ltx_align_center ltx_border_bb">4.06</td>
<td id="S6.T3.1.1.10.7.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.10.7.12.1" class="ltx_text ltx_ulem_uline">3.62</span></td>
<td id="S6.T3.1.1.10.7.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">3.64</td>
<td id="S6.T3.1.1.10.7.14" class="ltx_td ltx_align_center ltx_border_bb">33.56</td>
<td id="S6.T3.1.1.10.7.15" class="ltx_td ltx_align_center ltx_border_bb">35.28</td>
<td id="S6.T3.1.1.10.7.16" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.10.7.16.1" class="ltx_text ltx_ulem_uline">34.52</span></td>
<td id="S6.T3.1.1.10.7.17" class="ltx_td ltx_align_center ltx_border_bb">34.92</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of CER results across various models and synthetic data generation methods in English, Icelandic, and Russian. The best-performing model for each dataset is highlighted in bold, and the best method for generating synthetic data for each model is underlined.</figcaption>
</figure>
<figure id="S6.T4" class="ltx_table">
<div id="S6.T4.1" class="ltx_inline-block ltx_transformed_outer" style="width:429.3pt;height:49.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-97.0pt,11.2pt) scale(0.688816329612557,0.688816329612557) ;">
<table id="S6.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.1.1.1.1" class="ltx_tr">
<th id="S6.T4.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"></th>
<th id="S6.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">English</span></th>
<th id="S6.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">German</span></th>
<th id="S6.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Irish</span></th>
<th id="S6.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Icelandic</span></th>
<th id="S6.T4.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Frisian</span></th>
<th id="S6.T4.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Russian</span></th>
<th id="S6.T4.1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.8.1" class="ltx_text ltx_font_bold">Spanish</span></th>
<th id="S6.T4.1.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S6.T4.1.1.1.1.9.1" class="ltx_text ltx_font_bold">Telugu</span></th>
</tr>
<tr id="S6.T4.1.1.2.2" class="ltx_tr">
<td id="S6.T4.1.1.2.2.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.1.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.2.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.3.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.4.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.5.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.6" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.6.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.7" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.7.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.8" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.8.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.9" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.9.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.10" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.10.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.11" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.11.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.12" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.12.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.13" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.13.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.14" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S6.T4.1.1.2.2.14.1" class="ltx_text ltx_font_bold">WER</span></td>
<td id="S6.T4.1.1.2.2.15" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.15.1" class="ltx_text ltx_font_bold">CER</span></td>
<td id="S6.T4.1.1.2.2.16" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T4.1.1.2.2.16.1" class="ltx_text ltx_font_bold">WER</span></td>
</tr>
<tr id="S6.T4.1.1.3.3" class="ltx_tr">
<th id="S6.T4.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">OCR</th>
<td id="S6.T4.1.1.3.3.2" class="ltx_td ltx_align_right ltx_border_t">4.96</td>
<td id="S6.T4.1.1.3.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">15.43</td>
<td id="S6.T4.1.1.3.3.4" class="ltx_td ltx_align_right ltx_border_t">5.79</td>
<td id="S6.T4.1.1.3.3.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">19.29</td>
<td id="S6.T4.1.1.3.3.6" class="ltx_td ltx_align_right ltx_border_t">12.57</td>
<td id="S6.T4.1.1.3.3.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">35.99</td>
<td id="S6.T4.1.1.3.3.8" class="ltx_td ltx_align_right ltx_border_t">10.09</td>
<td id="S6.T4.1.1.3.3.9" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">30.06</td>
<td id="S6.T4.1.1.3.3.10" class="ltx_td ltx_align_right ltx_border_t">5.15</td>
<td id="S6.T4.1.1.3.3.11" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">16.20</td>
<td id="S6.T4.1.1.3.3.12" class="ltx_td ltx_align_right ltx_border_t">4.13</td>
<td id="S6.T4.1.1.3.3.13" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">8.16</td>
<td id="S6.T4.1.1.3.3.14" class="ltx_td ltx_align_right ltx_border_t">6.00</td>
<td id="S6.T4.1.1.3.3.15" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">17.38</td>
<td id="S6.T4.1.1.3.3.16" class="ltx_td ltx_align_right ltx_border_t">34.12</td>
<td id="S6.T4.1.1.3.3.17" class="ltx_td ltx_align_right ltx_border_t">90.41</td>
</tr>
<tr id="S6.T4.1.1.4.4" class="ltx_tr">
<th id="S6.T4.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Post-OCR</th>
<td id="S6.T4.1.1.4.4.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">3.00</td>
<td id="S6.T4.1.1.4.4.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">7.74</td>
<td id="S6.T4.1.1.4.4.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">4.27</td>
<td id="S6.T4.1.1.4.4.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">11.07</td>
<td id="S6.T4.1.1.4.4.6" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">11.01</td>
<td id="S6.T4.1.1.4.4.7" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">29.97</td>
<td id="S6.T4.1.1.4.4.8" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">8.28</td>
<td id="S6.T4.1.1.4.4.9" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">24.57</td>
<td id="S6.T4.1.1.4.4.10" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">3.55</td>
<td id="S6.T4.1.1.4.4.11" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">11.03</td>
<td id="S6.T4.1.1.4.4.12" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">2.14</td>
<td id="S6.T4.1.1.4.4.13" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">5.88</td>
<td id="S6.T4.1.1.4.4.14" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">3.76</td>
<td id="S6.T4.1.1.4.4.15" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t">8.92</td>
<td id="S6.T4.1.1.4.4.16" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">25.28</td>
<td id="S6.T4.1.1.4.4.17" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">66.64</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of the ByT5 model in terms of Character Error Rate (CER) and Word Error Rate (WER) across multiple languages, before and after post-OCR correction.</figcaption>
</figure>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.7" class="ltx_p">The results of Experiment 2 are shown in Table <a href="#S6.T3" title="Table 3 â€£ 6.2 Experiment 2 â€£ 6 Experiments â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. It is observed that methods <math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="â‘¢" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mn id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml">â‘¢</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><cn type="float" id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1">circled-3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">â‘¢</annotation></semantics></math> and <math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="â‘£" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mn id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml">â‘£</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><cn type="float" id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1">circled-4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">â‘£</annotation></semantics></math> generally outperform <math id="S6.SS2.p2.3.m3.1" class="ltx_Math" alttext="â‘ " display="inline"><semantics id="S6.SS2.p2.3.m3.1a"><mn id="S6.SS2.p2.3.m3.1.1" xref="S6.SS2.p2.3.m3.1.1.cmml">â‘ </mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.3.m3.1b"><cn type="float" id="S6.SS2.p2.3.m3.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1">circled-1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.3.m3.1c">â‘ </annotation></semantics></math> and <math id="S6.SS2.p2.4.m4.1" class="ltx_Math" alttext="â‘¡" display="inline"><semantics id="S6.SS2.p2.4.m4.1a"><mn id="S6.SS2.p2.4.m4.1.1" xref="S6.SS2.p2.4.m4.1.1.cmml">â‘¡</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.4.m4.1b"><cn type="float" id="S6.SS2.p2.4.m4.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1">circled-2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.4.m4.1c">â‘¡</annotation></semantics></math>. Of the latter two, method <math id="S6.SS2.p2.5.m5.1" class="ltx_Math" alttext="â‘ " display="inline"><semantics id="S6.SS2.p2.5.m5.1a"><mn id="S6.SS2.p2.5.m5.1.1" xref="S6.SS2.p2.5.m5.1.1.cmml">â‘ </mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.5.m5.1b"><cn type="float" id="S6.SS2.p2.5.m5.1.1.cmml" xref="S6.SS2.p2.5.m5.1.1">circled-1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.5.m5.1c">â‘ </annotation></semantics></math>, which does not rely on additional data, yields slightly higher accuracy. While method <math id="S6.SS2.p2.6.m6.1" class="ltx_Math" alttext="â‘¡" display="inline"><semantics id="S6.SS2.p2.6.m6.1a"><mn id="S6.SS2.p2.6.m6.1.1" xref="S6.SS2.p2.6.m6.1.1.cmml">â‘¡</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.6.m6.1b"><cn type="float" id="S6.SS2.p2.6.m6.1.1.cmml" xref="S6.SS2.p2.6.m6.1.1">circled-2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.6.m6.1c">â‘¡</annotation></semantics></math> allows the model to learn from real OCR outputs, it fails to correct sentences with varying degrees of CER. In our experiments, the Google Vision API OCR system was used to generate training data, and Tesseract was used for test data. Since the Vision API OCR system generally has a higher accuracy than Tesseract, models only learn to correct sentences with low CER, which is reflected in the limitations of the method <math id="S6.SS2.p2.7.m7.1" class="ltx_Math" alttext="â‘¡" display="inline"><semantics id="S6.SS2.p2.7.m7.1a"><mn id="S6.SS2.p2.7.m7.1.1" xref="S6.SS2.p2.7.m7.1.1.cmml">â‘¡</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.7.m7.1b"><cn type="float" id="S6.SS2.p2.7.m7.1.1.cmml" xref="S6.SS2.p2.7.m7.1.1">circled-2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.7.m7.1c">â‘¡</annotation></semantics></math>.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.3" class="ltx_p">Method <math id="S6.SS2.p3.1.m1.1" class="ltx_Math" alttext="â‘¢" display="inline"><semantics id="S6.SS2.p3.1.m1.1a"><mn id="S6.SS2.p3.1.m1.1.1" xref="S6.SS2.p3.1.m1.1.1.cmml">â‘¢</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.1.m1.1b"><cn type="float" id="S6.SS2.p3.1.m1.1.1.cmml" xref="S6.SS2.p3.1.m1.1.1">circled-3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.1.m1.1c">â‘¢</annotation></semantics></math> proves more effective, extracting real OCR error distributions and generating training data with various CER values, but requires additional data.
With a sufficient volume of data (as in the English language experiments), models trained with this method performed best. Different OCR systems, due to their unique designs, can make various kinds of errors. With insufficient additional data, Method <math id="S6.SS2.p3.2.m2.1" class="ltx_Math" alttext="â‘¢" display="inline"><semantics id="S6.SS2.p3.2.m2.1a"><mn id="S6.SS2.p3.2.m2.1.1" xref="S6.SS2.p3.2.m2.1.1.cmml">â‘¢</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.2.m2.1b"><cn type="float" id="S6.SS2.p3.2.m2.1.1.cmml" xref="S6.SS2.p3.2.m2.1.1">circled-3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.2.m2.1c">â‘¢</annotation></semantics></math> can fail to extract a comprehensive set of OCR errors, leading to distributional shift in the data, which ultimately affects the performance of models that rely on it. In Experiment 2, Method <math id="S6.SS2.p3.3.m3.1" class="ltx_Math" alttext="â‘£" display="inline"><semantics id="S6.SS2.p3.3.m3.1a"><mn id="S6.SS2.p3.3.m3.1.1" xref="S6.SS2.p3.3.m3.1.1.cmml">â‘£</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.3.m3.1b"><cn type="float" id="S6.SS2.p3.3.m3.1.1.cmml" xref="S6.SS2.p3.3.m3.1.1">circled-4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.3.m3.1c">â‘£</annotation></semantics></math> achieved impressive results without relying on additional data. By generating its own training data with varying degrees of CER encoded through glyphs alone, it successfully trained models that perform well across diverse languages with different character sets.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">Overall, we observe that pre-trained models significantly outperformed smaller Seq2Seq models trained from scratch. mT5 and ByT5 showed similar performance, with ByT5 reducing CER values by 39.5%, 17.9%, 48.2% and 25.9% on English, Icelandic, Russian and Telugu datasets, respectively. CharBERT did not benefit from glyph embedding, consistent with the findings of <cite class="ltx_cite ltx_citemacro_citet">Amrhein and Clematide (<a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Experiment 3</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In our final experiment, we replicate the original clean text four times for augmentation. Based on our previous experiments, we select Method <math id="S6.SS3.p1.1.m1.1" class="ltx_Math" alttext="â‘£" display="inline"><semantics id="S6.SS3.p1.1.m1.1a"><mn id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">â‘£</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><cn type="float" id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">circled-4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">â‘£</annotation></semantics></math> to generate synthetic data and train the ByT5 model for post-OCR tasks on data from a wider set of languages, so that we can evaluate the chosen configuration in a broader linguistic context.</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2408.02253/assets/image/5.jpg" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="162" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparative analysis of CER changes after post-OCR across multiple languages. Each bar represents the distribution of CER changes categorized as Increased (red), Decreased (green), Equal (blue), and Zero (dotted green).</figcaption>
</figure>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">From the results in Table <a href="#S6.T4" title="Table 4 â€£ 6.2 Experiment 2 â€£ 6 Experiments â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we see that the model performs well on the English, Russian, and Spanish tasks, with CER reductions of 39.52%, 48.18%, and 37.33%, respectively. This approach also achieves a CER reduction of 31.07% on the low-resource language Frisian. The performance is poorest in the cases of Irish and Icelandic, with only 12.41% and 17.94% reductions in CER, respectively. We attribute this to two main reasons. Firstly, the data for Irish and Icelandic (sourced from the CC100 dataset of web-crawled data) contain numerous proper nouns. These are challenging for conventional NMT models to correct due to their inability to handle out-of-vocabulary words. Secondly, although the ByT5 model was trained on a multilingual dataset, the volume of data for low-resource languages is not substantial. This disparity in data availability can affect the modelsâ€™ performance on post-OCR tasks. Table <a href="#S6.T4" title="Table 4 â€£ 6.2 Experiment 2 â€£ 6 Experiments â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> also indicates that the Telugu test dataset has very high CER and WER, likely due to the complexity of Telugu glyphs <cite class="ltx_cite ltx_citemacro_citep">(Negi etÂ al., <a href="#bib.bib46" title="" class="ltx_ref">2001</a>)</cite>. When Telugu text becomes blurred, it can be difficult for OCR systems to recognize. Thus, post-OCR processing for Telugu results in a 25.91% reduction in CER.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">Figure <a href="#S6.F5" title="Figure 5 â€£ 6.3 Experiment 3 â€£ 6 Experiments â€£ Advancing Post-OCR Correction: A Comparative Study of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides a more detailed sentence-based view of CER across languages. Here we enumerate the following categories for CER changes after post-OCR processing: "Increased" indicates sentences where the CER has increased, "Decreased" indicates the CER has decreased, "Equal" means that CER remained unchanged, and "Zero" means the CER is zero after post-OCR processing (i.e., perfect matching with the ground truth). We observe that only a small number of sentences experienced an increase in CER after post-OCR processing. Specifically, 25.37% of sentences in Irish showed an increase in CER post-OCR, and only 8.66% of sentences in Russian. Notably, 59.52% of sentences in Russian had a CER of zero after post-OCR processing. For Telugu, which had the highest CER, we saw a reduction in CER for 76.18% of sentences after post-OCR processing.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Our experiments demonstrated that augmenting data by replicating clean text and constructing synthetic data based on glyph similarity significantly improves model performance for post-OCR correction. Furthermore, we proposed a novel approach to constructing post-OCR synthetic data based on glyph similarity, which outperforms traditional noise injection methods, especially in scenarios with limited data volume, as it does not require additional external data. In our experiments, pre-trained models demonstrated superior performance compared to those without pre-training, with the byte-level ByT5 model achieving the best performance. For rich-resource languages, this approach can reduce the CER by approximately 45%, while for low-resource languages the reduction varies between 12.41% and 31.07%.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">For the preferred Method â‘£, the time complexity of calculating the character similarity values is <math id="Sx1.p1.1.m1.1" class="ltx_Math" alttext="O(n^{2})" display="inline"><semantics id="Sx1.p1.1.m1.1a"><mrow id="Sx1.p1.1.m1.1.1" xref="Sx1.p1.1.m1.1.1.cmml"><mi id="Sx1.p1.1.m1.1.1.3" xref="Sx1.p1.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="Sx1.p1.1.m1.1.1.2" xref="Sx1.p1.1.m1.1.1.2.cmml">â€‹</mo><mrow id="Sx1.p1.1.m1.1.1.1.1" xref="Sx1.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="Sx1.p1.1.m1.1.1.1.1.2" xref="Sx1.p1.1.m1.1.1.1.1.1.cmml">(</mo><msup id="Sx1.p1.1.m1.1.1.1.1.1" xref="Sx1.p1.1.m1.1.1.1.1.1.cmml"><mi id="Sx1.p1.1.m1.1.1.1.1.1.2" xref="Sx1.p1.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="Sx1.p1.1.m1.1.1.1.1.1.3" xref="Sx1.p1.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="Sx1.p1.1.m1.1.1.1.1.3" xref="Sx1.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx1.p1.1.m1.1b"><apply id="Sx1.p1.1.m1.1.1.cmml" xref="Sx1.p1.1.m1.1.1"><times id="Sx1.p1.1.m1.1.1.2.cmml" xref="Sx1.p1.1.m1.1.1.2"></times><ci id="Sx1.p1.1.m1.1.1.3.cmml" xref="Sx1.p1.1.m1.1.1.3">ğ‘‚</ci><apply id="Sx1.p1.1.m1.1.1.1.1.1.cmml" xref="Sx1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="Sx1.p1.1.m1.1.1.1.1.1.1.cmml" xref="Sx1.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="Sx1.p1.1.m1.1.1.1.1.1.2.cmml" xref="Sx1.p1.1.m1.1.1.1.1.1.2">ğ‘›</ci><cn type="integer" id="Sx1.p1.1.m1.1.1.1.1.1.3.cmml" xref="Sx1.p1.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p1.1.m1.1c">O(n^{2})</annotation></semantics></math>. As a result, the calculation of character similarities in languages with a large array of characters, such as Chinese and Japanese, can be quite time consuming.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">This publication is part of a project that has received funding from (i) the European Research Council (ERC) under the Horizon 2020 research and innovation programme (Grant agreement No. 884951); (ii) Science Foundation Ireland (SFI) to the Insight Centre for Data Analytics under grant No 12/RC/2289 P2.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmadi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Sina Ahmadi, Milind Agarwal, and Antonios Anastasopoulos. 2023.

</span>
<span class="ltx_bibblock">Pali: A language identification benchmark for Perso-Arabic scripts.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01322</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alcantarilla and Solutions (2011)</span>
<span class="ltx_bibblock">
PabloÂ F Alcantarilla and TÂ Solutions. 2011.

</span>
<span class="ltx_bibblock">Fast explicit diffusion for accelerated features in nonlinear scale spaces.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Patt. Anal. Mach. Intell</em>, 34(7):1281â€“1298.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amrhein and Clematide (2018)</span>
<span class="ltx_bibblock">
Chantal Amrhein and Simon Clematide. 2018.

</span>
<span class="ltx_bibblock">Supervised OCR error detection and correction using statistical and neural machine translation methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Journal for Language Technology and Computational Linguistics</em>, 33(1):49â€“76.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bassil and Alwani (2012)</span>
<span class="ltx_bibblock">
Youssef Bassil and Mohammad Alwani. 2012.

</span>
<span class="ltx_bibblock">OCR post-processing error correction algorithm using google online spelling suggestion.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1204.0191</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bazzo etÂ al. (2020)</span>
<span class="ltx_bibblock">
GuilhermeÂ Torresan Bazzo, GustavoÂ Acauan Lorentz, Danny SuarezÂ Vargas, and VivianeÂ P Moreira. 2020.

</span>
<span class="ltx_bibblock">Assessing the impact of OCR errors in information retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Information Retrieval: 42nd European Conference on IR Research (ECIR 2020)</em>, pages 102â€“109. Springer.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boros etÂ al. (2022)</span>
<span class="ltx_bibblock">
Emanuela Boros, NhuÂ Khoa Nguyen, GaÃ«l Lejeune, and Antoine Doucet. 2022.

</span>
<span class="ltx_bibblock">Assessing the impact of ocr noise on multilingual event detection over digitised documents.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Journal on Digital Libraries</em>, 23(3):241â€“266.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck etÂ al. (2023)</span>
<span class="ltx_bibblock">
SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, YinÂ Tat Lee, Yuanzhi Li, Scott Lundberg, etÂ al. 2023.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with GPT-4.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>, (2303.12712).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Zhou (2023)</span>
<span class="ltx_bibblock">
Yung-Hsin Chen and Yuli Zhou. 2023.

</span>
<span class="ltx_bibblock">Enhancing ocr performance through Post-OCR models: Adopting glyph embedding for improved correction.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.15262</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chipman etÂ al. (2022)</span>
<span class="ltx_bibblock">
HughÂ A Chipman, EdwardÂ I George, RobertÂ E McCulloch, and ThomasÂ S Shively. 2022.

</span>
<span class="ltx_bibblock">mbart: multidimensional monotone bart.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Bayesian Analysis</em>, 17(2):515â€“544.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiron etÂ al. (2017)</span>
<span class="ltx_bibblock">
Guillaume Chiron, Antoine Doucet, MickaÃ«l Coustaty, and Jean-Philippe Moreux. 2017.

</span>
<span class="ltx_bibblock">ICDAR-2017 competition on post-OCR text correction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</em>, volumeÂ 1, pages 1423â€“1428. IEEE.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi and Park (2023)</span>
<span class="ltx_bibblock">
Eujeong Choi and Chanjun Park. 2023.

</span>
<span class="ltx_bibblock">Dmops: Data management operation and recipes.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.01228</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clematide etÂ al. (2016)</span>
<span class="ltx_bibblock">
Simon Clematide, Lenz Furrer, and Martin Volk. 2016.

</span>
<span class="ltx_bibblock">Crowdsourcing an OCR gold standard for a german and french heritage corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LRECâ€™16)</em>, pages 975â€“982.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau etÂ al. (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.02116</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davydkin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Evgenii Davydkin, Aleksandr Markelov, Egor Iuldashev, Anton Dudkin, and Ivan Krivorotov. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2311.15896" title="" class="ltx_ref ltx_href">Data generation for post-ocr correction of cyrillic handwriting</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>, (1810.04805).

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dâ€™hondt etÂ al. (2017)</span>
<span class="ltx_bibblock">
Eva Dâ€™hondt, Cyril Grouin, and Brigitte Grau. 2017.

</span>
<span class="ltx_bibblock">Generating a training corpus for OCR post-correction using encoder-decoder model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 8th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 1006â€“1014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Estrella and Paliza (2014)</span>
<span class="ltx_bibblock">
Paula Estrella and Pablo Paliza. 2014.

</span>
<span class="ltx_bibblock">Ocr correction of documents generated during argentinaâ€™s national reorganization process.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage</em>, pages 119â€“123.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Foundation (2024)</span>
<span class="ltx_bibblock">
Wikimedia Foundation. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://dumps.wikimedia.org" title="" class="ltx_ref ltx_href">Wikimedia downloads</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fujii etÂ al. (2017)</span>
<span class="ltx_bibblock">
Yasuhisa Fujii, Karel Driesen, Jonathan Baccash, Ash Hurst, and AshokÂ C Popat. 2017.

</span>
<span class="ltx_bibblock">Sequence-to-label script identification for multilingual OCR.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2017 14th IAPR international conference on document analysis and recognition (ICDAR)</em>, volumeÂ 1, pages 161â€“168. IEEE.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Furrer and Volk (2011)</span>
<span class="ltx_bibblock">
Lenz Furrer and Martin Volk. 2011.

</span>
<span class="ltx_bibblock">Reducing ocr errors in gothic-script documents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage</em>, pages 97â€“103.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginsberg and Yu (2018)</span>
<span class="ltx_bibblock">
Avi Ginsberg and Cui Yu. 2018.

</span>
<span class="ltx_bibblock">Rapid homoglyph prediction and detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proc. 1st International Conference on Data Intelligence and Security (ICDIS)</em>, pages 17â€“23. IEEE.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grundkiewicz etÂ al. (2019)</span>
<span class="ltx_bibblock">
Roman Grundkiewicz, Marcin Junczys-Dowmunt, and Kenneth Heafield. 2019.

</span>
<span class="ltx_bibblock">Neural grammatical error correction systems with unsupervised pre-training on synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 252â€“263.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 770â€“778.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ignat etÂ al. (2022)</span>
<span class="ltx_bibblock">
Oana Ignat, Jean Maillard, Vishrav Chaudhary, and Francisco GuzmÃ¡n. 2022.

</span>
<span class="ltx_bibblock">OCR improves machine translation for low-resource languages.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.13274</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IngÃ³lfsdÃ³ttir etÂ al. (2023)</span>
<span class="ltx_bibblock">
SvanhvÃ­tÂ Lilja IngÃ³lfsdÃ³ttir, PÃ©turÂ Orri Ragnarsson, HaukurÂ PÃ¡ll JÃ³nsson, HaukurÂ Barri SÃ­monarson, VilhjÃ¡lmur Ãorsteinsson, and VÃ©steinn SnÃ¦bjarnarson. 2023.

</span>
<span class="ltx_bibblock">Byte-level grammatical error correction using synthetic and curated corpora.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.17906</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izumi etÂ al. (2003)</span>
<span class="ltx_bibblock">
Emi Izumi, Kiyotaka Uchimoto, Toyomi Saiga, Thepchai Supnithi, and Hitoshi Isahara. 2003.

</span>
<span class="ltx_bibblock">Automatic error detection in the japanese learnersâ€™ english spoken data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics</em>, pages 145â€“148.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaccard (1912)</span>
<span class="ltx_bibblock">
Paul Jaccard. 1912.

</span>
<span class="ltx_bibblock">The distribution of flora in the alpine zone.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">New Phytologist</em>, 11(2):37â€“50.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaderberg etÂ al. (2014)</span>
<span class="ltx_bibblock">
Max Jaderberg, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014.

</span>
<span class="ltx_bibblock">Synthetic data and artificial neural networks for natural scene text recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1406.2227</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jarlbrink and Snickars (2017)</span>
<span class="ltx_bibblock">
Johan Jarlbrink and Pelle Snickars. 2017.

</span>
<span class="ltx_bibblock">Cultural heritage as digital noise: nineteenth century newspapers in the digital archive.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Journal of Documentation</em>, 73(6):1228â€“1243.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jasonarson etÂ al. (2023)</span>
<span class="ltx_bibblock">
Atli Jasonarson, SteinÃ¾Ã³r SteingrÃ­msson, EinarÂ Freyr SigurÃ°sson, ÃrniÂ DavÃ­Ã° MagnÃºsson, and FinnurÂ ÃgÃºst Ingimundarson. 2023.

</span>
<span class="ltx_bibblock">Generating Errors: OCR Post-Processing for Icelandic.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">24th Nordic Conference on Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jatowt etÂ al. (2019)</span>
<span class="ltx_bibblock">
Adam Jatowt, Mickael Coustaty, Nhu-Van Nguyen, Antoine Doucet, etÂ al. 2019.

</span>
<span class="ltx_bibblock">Deep statistical analysis of OCR errors for effective post-OCR processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</em>, pages 29â€“38. IEEE.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jentoft (2023)</span>
<span class="ltx_bibblock">
Matias Jentoft. 2023.

</span>
<span class="ltx_bibblock">Grammatical error correction with byte-level language models.

</span>
<span class="ltx_bibblock">Masterâ€™s thesis, University of Oslo.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kettunen (2016)</span>
<span class="ltx_bibblock">
Kimmo Kettunen. 2016.

</span>
<span class="ltx_bibblock">Keep, change or delete? setting up a low resource ocr post-correction framework for a digitized old finnish newspaper collection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Digital Libraries on the Move: 11th Italian Research Conference on Digital Libraries, IRCDL 2015, Bolzano, Italy, January 29-30, 2015, Revised Selected Papers 11</em>, pages 95â€“103. Springer.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn etÂ al. (2020)</span>
<span class="ltx_bibblock">
Philipp Koehn, Vishrav Chaudhary, Ahmed El-Kishky, Naman Goyal, Peng-Jen Chen, and Francisco GuzmÃ¡n. 2020.

</span>
<span class="ltx_bibblock">Findings of the wmt 2020 shared task on parallel corpus filtering and alignment.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth Conference on Machine Translation</em>, pages 726â€“742.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koudoro-Parfait etÂ al. (2021)</span>
<span class="ltx_bibblock">
Caroline Koudoro-Parfait, GaÃ«l Lejeune, and Glenn Roe. 2021.

</span>
<span class="ltx_bibblock">Spatial named entity recognition in literary texts: What is the influence of ocr noise?

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th ACM SIGSPATIAL International Workshop on Geospatial Humanities</em>, pages 13â€“21.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna etÂ al. (2018)</span>
<span class="ltx_bibblock">
Amrith Krishna, BodhisattwaÂ Prasad Majumder, RajeshÂ Shreedhar Bhat, and Pawan Goyal. 2018.

</span>
<span class="ltx_bibblock">Upcycle your ocr: Reusing ocrs for post-ocr text correction in romanised sanskrit.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.02147</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo and Richardson (2018)</span>
<span class="ltx_bibblock">
Taku Kudo and John Richardson. 2018.

</span>
<span class="ltx_bibblock">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>, (1808.06226).

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lam and Suen (1997)</span>
<span class="ltx_bibblock">
Louisa Lam and SYÂ Suen. 1997.

</span>
<span class="ltx_bibblock">Application of majority voting to pattern recognition: an analysis of its behavior and performance.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans</em>, 27(5):553â€“568.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2019)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.

</span>
<span class="ltx_bibblock">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.13461</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022)</span>
<span class="ltx_bibblock">
Bohan Li, Yutai Hou, and Wanxiang Che. 2022.

</span>
<span class="ltx_bibblock">Data augmentation approaches in natural language processing: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Ai Open</em>, 3:71â€“90.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LinharesÂ Pontes etÂ al. (2019)</span>
<span class="ltx_bibblock">
Elvys LinharesÂ Pontes, Ahmed Hamdi, Nicolas Sidere, and Antoine Doucet. 2019.

</span>
<span class="ltx_bibblock">Impact of ocr quality on named entity linking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Digital Libraries at the Crossroads of Digital Information for the Future: 21st International Conference on Asia-Pacific Digital Libraries, ICADL 2019, Kuala Lumpur, Malaysia, November 4â€“7, 2019, Proceedings 21</em>, pages 102â€“115. Springer.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Linlin Liu, Bosheng Ding, Lidong Bing, Shafiq Joty, Luo Si, and Chunyan Miao. 2021.

</span>
<span class="ltx_bibblock">MulDA: A multilingual data augmentation framework for low-resource cross-lingual NER.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 5834â€“5846.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2020)</span>
<span class="ltx_bibblock">
Wentao Ma, Yiming Cui, Chenglei Si, Ting Liu, Shijin Wang, and Guoping Hu. 2020.

</span>
<span class="ltx_bibblock">Charbert: character-aware pre-trained language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.01513</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maheshwari etÂ al. (2022)</span>
<span class="ltx_bibblock">
Ayush Maheshwari, Nikhil Singh, Amrith Krishna, and Ganesh Ramakrishnan. 2022.

</span>
<span class="ltx_bibblock">A benchmark and dataset for post-OCR text correction in Sanskrit.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.07980</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mazumder etÂ al. (2022)</span>
<span class="ltx_bibblock">
Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan KarlaÅ¡, WilliamÂ Gaviria Rojas, Sudnya Diamos, Greg Diamos, Lynn He, Alicia Parrish, HannahÂ Rose Kirk, etÂ al. 2022.

</span>
<span class="ltx_bibblock">Dataperf: Benchmarks for data-centric ai development.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.10062</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Negi etÂ al. (2001)</span>
<span class="ltx_bibblock">
Atul Negi, Chakravarthy Bhagvati, and BÂ Krishna. 2001.

</span>
<span class="ltx_bibblock">An OCR system for Telugu.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of 6th International Conference on Document Analysis and Recognition</em>, pages 1110â€“1114. IEEE.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng and Henikoff (2003)</span>
<span class="ltx_bibblock">
PaulineÂ C Ng and Steven Henikoff. 2003.

</span>
<span class="ltx_bibblock">Sift: Predicting amino acid changes that affect protein function.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Nucleic acids research</em>, 31(13):3812â€“3814.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen etÂ al. (2020)</span>
<span class="ltx_bibblock">
Thi TuyetÂ Hai Nguyen, Adam Jatowt, Nhu-Van Nguyen, Mickael Coustaty, and Antoine Doucet. 2020.

</span>
<span class="ltx_bibblock">Neural machine translation with BERT for post-OCR error detection and correction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM/IEEE joint conference on digital libraries</em>, pages 333â€“336.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puri etÂ al. (2020)</span>
<span class="ltx_bibblock">
Raul Puri, Ryan Spring, Mostofa Patwary, Mohammad Shoeybi, and Bryan Catanzaro. 2020.

</span>
<span class="ltx_bibblock">Training question answering models from synthetic data.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.09599</em>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, 21(1):5485â€“5551.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramirez-Orta etÂ al. (2022)</span>
<span class="ltx_bibblock">
JuanÂ Antonio Ramirez-Orta, Eduardo Xamena, Ana Maguitman, Evangelos Milios, and AxelÂ J Soto. 2022.

</span>
<span class="ltx_bibblock">Post-ocr document correction with large ensembles of character sequence-to-sequence models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volumeÂ 36, pages 11192â€“11199.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richter etÂ al. (2018)</span>
<span class="ltx_bibblock">
Caitlin Richter, Matthew Wickes, Deniz Beser, and Mitch Marcus. 2018.

</span>
<span class="ltx_bibblock">Low-resource post processing of noisy ocr output for historical corpus digitisation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</em>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rigaud etÂ al. (2019)</span>
<span class="ltx_bibblock">
Christophe Rigaud, Antoine Doucet, MickaÃ«l Coustaty, and Jean-Philippe Moreux. 2019.

</span>
<span class="ltx_bibblock">ICDAR-2019 competition on post-OCR text correction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 IAPR International Conference on Document Analysis and Recognition (ICDAR)</em>, pages 1588â€“1593. IEEE.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rublee etÂ al. (2011)</span>
<span class="ltx_bibblock">
Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. 2011.

</span>
<span class="ltx_bibblock">Orb: An efficient alternative to sift or surf.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">2011 International conference on computer vision</em>, pages 2564â€“2571. Ieee.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich etÂ al. (2015)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015.

</span>
<span class="ltx_bibblock">Improving neural machine translation models with monolingual data.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1511.06709</em>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten and Khoshgoftaar (2019)</span>
<span class="ltx_bibblock">
Connor Shorten and TaghiÂ M Khoshgoftaar. 2019.

</span>
<span class="ltx_bibblock">A survey on image data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Journal of big data</em>, 6(1):1â€“48.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith (2007)</span>
<span class="ltx_bibblock">
Ray Smith. 2007.

</span>
<span class="ltx_bibblock">An overview of the Tesseract OCR engine.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 9th International Conference on Document Analysis and Recognition (ICDAR)</em>, volumeÂ 2, pages 629â€“633. IEEE.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soper etÂ al. (2021)</span>
<span class="ltx_bibblock">
Elizabeth Soper, Stanley Fujimoto, and Yen-Yun Yu. 2021.

</span>
<span class="ltx_bibblock">Bart for post-correction of OCR newspaper text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</em>, pages 284â€“290.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">StankeviÄius etÂ al. (2022)</span>
<span class="ltx_bibblock">
Lukas StankeviÄius, Mantas LukoÅ¡eviÄius, Jurgita KapoÄiÅ«tÄ—-DzikienÄ—, Monika BriedienÄ—, and Tomas KrilaviÄius. 2022.

</span>
<span class="ltx_bibblock">Correcting diacritics and typos with a byt5 transformer model.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, 12(5):2636.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stubbs (1996)</span>
<span class="ltx_bibblock">
Michael Stubbs. 1996.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Text and corpus analysis: Computer-assisted studies of language and culture</em>.

</span>
<span class="ltx_bibblock">Blackwell Oxford.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, and Angela Fan. 2020.

</span>
<span class="ltx_bibblock">Multilingual translation with extensible multilingual pretraining and finetuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>, (2008.00401).

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tarafdar etÂ al. (2019)</span>
<span class="ltx_bibblock">
Monideepa Tarafdar, CynthiaÂ M Beath, and JeanneÂ W Ross. 2019.

</span>
<span class="ltx_bibblock">Using ai to enhance business operations.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">MIT Sloan Management Review</em>, 60(4).

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wemhoener etÂ al. (2013)</span>
<span class="ltx_bibblock">
David Wemhoener, IsmetÂ Zeki Yalniz, and RÂ Manmatha. 2013.

</span>
<span class="ltx_bibblock">Creating an improved version using noisy ocr from multiple editions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">2013 12th International Conference on Document Analysis and Recognition</em>, pages 160â€“164. IEEE.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue etÂ al. (2022)</span>
<span class="ltx_bibblock">
Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022.

</span>
<span class="ltx_bibblock">Byt5: Towards a token-free future with pre-trained byte-to-byte models.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 10:291â€“306.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue etÂ al. (2020)</span>
<span class="ltx_bibblock">
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2020.

</span>
<span class="ltx_bibblock">mt5: A massively multilingual pre-trained text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11934</em>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yalniz and Manmatha (2011)</span>
<span class="ltx_bibblock">
IsmetÂ Zeki Yalniz and Raghavan Manmatha. 2011.

</span>
<span class="ltx_bibblock">A fast alignment scheme for automatic OCR evaluation of books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">2011 International Conference on Document Analysis and Recognition</em>, pages 754â€“758. IEEE.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Training parameters</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Due to the numerous sub-experiments in this study, models were trained on both RTX 4090 24GB and A100 80GB GPUs, without selecting different training parameters for different languages.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">The mT5-base, ByT5-base, mBART-large, CharBERT, and ResNet50 models were all sourced from Hugging Face. Parameters for mT5-base, ByT5-base, and mBART-large were identical: dropout rate of 0.2, learning rate of 5e-4, batch size of 4, and 6 epochs. For CharBERT-related models, the dropout rate is 0.2, learning rate is 3e-5, batch size is 8, with 12 epochs. The ENSEMBLE and SCRATCH models have the same parameters: dropout rate of 0.1, learning rate of 1e-4, batch size of 32, and 30 epochs. All models use Adam optimizer and are trained in fp32 precision. The best models are selected based on dev loss.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.02252" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.02253" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.02253">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.02253" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.02254" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 15:17:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
