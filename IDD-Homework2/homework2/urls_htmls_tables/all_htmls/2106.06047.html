<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2106.06047] Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning</title><meta property="og:description" content="Federated learning is an emerging research paradigm enabling collaborative training of machine learning models among different organizations while keeping data private at each institution. Despite recent progress, ther…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2106.06047">

<!--Generated on Sat Mar  2 05:14:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Rethinking Architecture Design for Tackling Data Heterogeneity in 
<br class="ltx_break">Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liangqiong Qu<sup id="id13.13.id1" class="ltx_sup"><span id="id13.13.id1.1" class="ltx_text ltx_font_italic">1</span></sup>  Yuyin Zhou<sup id="id14.14.id2" class="ltx_sup"><span id="id14.14.id2.1" class="ltx_text ltx_font_italic">2∗</span></sup>  Paul Pu Liang<sup id="id15.15.id3" class="ltx_sup"><span id="id15.15.id3.1" class="ltx_text ltx_font_italic">3∗</span></sup>  Yingda Xia<sup id="id16.16.id4" class="ltx_sup">4</sup>  Feifei Wang<sup id="id17.17.id5" class="ltx_sup">1</sup>  
<br class="ltx_break">Ehsan Adeli<sup id="id18.18.id6" class="ltx_sup">1</sup>  Li Fei-Fei<sup id="id19.19.id7" class="ltx_sup">1</sup>  Daniel Rubin<sup id="id20.20.id8" class="ltx_sup">1</sup>

<br class="ltx_break"><sup id="id21.21.id9" class="ltx_sup">1</sup> Stanford University,<sup id="id22.22.id10" class="ltx_sup">2</sup> UC Santa Cruz, <sup id="id23.23.id11" class="ltx_sup">3</sup> Carnegie Mellon University, <sup id="id24.24.id12" class="ltx_sup">4</sup> Johns Hopkins University  
<br class="ltx_break"><span id="id25.25.id13" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{liangqiqu, zhouyuyiner, philyingdaxia}@gmail.com, pliang@cs.cmu.edu, </span> 
<br class="ltx_break"><span id="id26.26.id14" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{ffwang, eadeli, feifeili, rubin}@stanford.edu, </span> 
<br class="ltx_break">
</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id27.id1" class="ltx_p">Federated learning is an emerging research paradigm enabling collaborative training of machine learning models among different organizations while keeping data private at each institution. Despite recent progress, there remain fundamental challenges such as the lack of convergence and the potential for catastrophic forgetting across real-world heterogeneous devices. In this paper, we demonstrate that self-attention-based architectures (<em id="id27.id1.1" class="ltx_emph ltx_font_italic">e.g.</em>, Transformers) are more robust to distribution shifts and hence improve federated learning over heterogeneous data. Concretely, we conduct the first rigorous empirical investigation of different neural architectures across a range of federated algorithms, real-world benchmarks, and heterogeneous data splits. Our experiments show that simply replacing convolutional networks with Transformers can greatly reduce catastrophic forgetting of previous devices, accelerate convergence, and reach a better global model, especially when dealing with heterogeneous data. We release our code and pretrained models at <a target="_blank" href="https://github.com/Liangqiong/ViT-FL-main" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Liangqiong/ViT-FL-main</a> to encourage future exploration in robust architectures as an alternative to current research efforts on the optimization front.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure">
<table id="S1.F1.2" class="ltx_tabular ltx_align_middle">
<tr id="S1.F1.2.3" class="ltx_tr">
<td id="S1.F1.2.3.1" class="ltx_td ltx_align_center">CWT</td>
</tr>
<tr id="S1.F1.1.1" class="ltx_tr">
<td id="S1.F1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/performance_different_architecture_CWT.png" id="S1.F1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="323" alt="Refer to caption"></td>
</tr>
<tr id="S1.F1.2.4" class="ltx_tr">
<td id="S1.F1.2.4.1" class="ltx_td ltx_align_center">FedAVG</td>
</tr>
<tr id="S1.F1.2.2" class="ltx_tr">
<td id="S1.F1.2.2.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/performance_different_architecture_FedAVG.png" id="S1.F1.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="323" alt="Refer to caption"></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.6.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.1" class="ltx_text" style="font-size:90%;">Prediction test accuracy on highly heterogeneous data partitions (Split-3) of <span id="S1.F1.4.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="S1.F1.4.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S1.F1.4.1.1.m1.1b"><mn id="S1.F1.4.1.1.m1.1.1" xref="S1.F1.4.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S1.F1.4.1.1.m1.1c"><cn type="integer" id="S1.F1.4.1.1.m1.1.1.cmml" xref="S1.F1.4.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.1.1.m1.1d">10</annotation></semantics></math></span> dataset versus model size<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text" style="font-size:111%;">1</span></span>Mean and standard deviation are calculated across three runs.</span></span></span>. Vision Transformers (ViTs and Swin Transformers) significantly outperform CNNs (ResNets and EfficientNets) on highly heterogeneous data partitions.</span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) is an emerging research paradigm to train machine learning models on private data distributed over multiple heterogeneous devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. FL keeps data on each device private and aims to train a global model that is updated only via communicated parameters instead of the data itself. Therefore, it provides an opportunity for collaborative machine learning across multiple institutions without risking leakage of private data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. This has proved especially useful in domains such as healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, learning from mobile devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and communication networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, where preserving privacy is crucial. Despite the rich opportunities afforded by FL, there remain fundamental research problems to be tackled before FL can be readily applicable to real-world data distributions. Most current methods that aim to learn a single global model across non-IID devices encounter challenges such as non-guaranteed convergence and model weight divergence for parallel FL methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and severe catastrophic forgetting problems for serial FL methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<table id="S1.F2.1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.F2.1.1.1" class="ltx_tr">
<td id="S1.F2.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/framework_fedavg_cwt.png" id="S1.F2.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="180" alt="Refer to caption"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.14.6.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.11.5" class="ltx_text" style="font-size:90%;">Simplified schematic for a typical serial FL method CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and a parallel FL method FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> on non-IID data partitions of CIFAR-<math id="S1.F2.7.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S1.F2.7.1.m1.1b"><mn id="S1.F2.7.1.m1.1.1" xref="S1.F2.7.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S1.F2.7.1.m1.1c"><cn type="integer" id="S1.F2.7.1.m1.1.1.cmml" xref="S1.F2.7.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.7.1.m1.1d">10</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> with label distribution skewness. <math id="S1.F2.8.2.m2.2" class="ltx_Math" alttext="W_{t,i}" display="inline"><semantics id="S1.F2.8.2.m2.2b"><msub id="S1.F2.8.2.m2.2.3" xref="S1.F2.8.2.m2.2.3.cmml"><mi id="S1.F2.8.2.m2.2.3.2" xref="S1.F2.8.2.m2.2.3.2.cmml">W</mi><mrow id="S1.F2.8.2.m2.2.2.2.4" xref="S1.F2.8.2.m2.2.2.2.3.cmml"><mi id="S1.F2.8.2.m2.1.1.1.1" xref="S1.F2.8.2.m2.1.1.1.1.cmml">t</mi><mo id="S1.F2.8.2.m2.2.2.2.4.1" xref="S1.F2.8.2.m2.2.2.2.3.cmml">,</mo><mi id="S1.F2.8.2.m2.2.2.2.2" xref="S1.F2.8.2.m2.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.8.2.m2.2c"><apply id="S1.F2.8.2.m2.2.3.cmml" xref="S1.F2.8.2.m2.2.3"><csymbol cd="ambiguous" id="S1.F2.8.2.m2.2.3.1.cmml" xref="S1.F2.8.2.m2.2.3">subscript</csymbol><ci id="S1.F2.8.2.m2.2.3.2.cmml" xref="S1.F2.8.2.m2.2.3.2">𝑊</ci><list id="S1.F2.8.2.m2.2.2.2.3.cmml" xref="S1.F2.8.2.m2.2.2.2.4"><ci id="S1.F2.8.2.m2.1.1.1.1.cmml" xref="S1.F2.8.2.m2.1.1.1.1">𝑡</ci><ci id="S1.F2.8.2.m2.2.2.2.2.cmml" xref="S1.F2.8.2.m2.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.8.2.m2.2d">W_{t,i}</annotation></semantics></math> denotes the model weights during training at round <math id="S1.F2.9.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S1.F2.9.3.m3.1b"><mi id="S1.F2.9.3.m3.1.1" xref="S1.F2.9.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S1.F2.9.3.m3.1c"><ci id="S1.F2.9.3.m3.1.1.cmml" xref="S1.F2.9.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.9.3.m3.1d">t</annotation></semantics></math> on client <math id="S1.F2.10.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.F2.10.4.m4.1b"><mi id="S1.F2.10.4.m4.1.1" xref="S1.F2.10.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.F2.10.4.m4.1c"><ci id="S1.F2.10.4.m4.1.1.cmml" xref="S1.F2.10.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.10.4.m4.1d">i</annotation></semantics></math> (total <math id="S1.F2.11.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S1.F2.11.5.m5.1b"><mi id="S1.F2.11.5.m5.1.1" xref="S1.F2.11.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.F2.11.5.m5.1c"><ci id="S1.F2.11.5.m5.1.1.cmml" xref="S1.F2.11.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.11.5.m5.1d">K</annotation></semantics></math> clients are involved). On the right, we show feature embedding visualizations of ViT(S)-FedAVG and ResNet(50)-FedAVG using UMAP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. We find that the features learned by ViT(S)-FedAVG are more clearly separated than those learned by ResNet(50)-FedAVG. Our experiments (section <a href="#S4.SS2" title="4.2 Results ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) support the superiority of <span id="S1.F2.11.5.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> on heterogeneous data and we provide analysis explaining their effectiveness (section <a href="#S4.SS3" title="4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">While most research efforts focus on improving the optimization process in FL, our paper aims to provide a new perspective by rethinking the choice of architectures in federated models.
We hypothesize that Transformer architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> are especially suitable for heterogeneous data distributions due to their surprising robustness to distribution shifts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. This property has led to the prevalence of Transformers in self-supervised learning where heterogeneity is manifested via distribution shifts between unlabeled pretraining data and labeled test data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, as well as in multimodal learning over fundamentally heterogeneous input modalities such as image and text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.
To study this hypothesis, we conduct the first large-scale empirical benchmarking of several neural architectures across a suite of federated algorithms, real-world benchmarks, and heterogeneous data splits.
To represent Transformer networks, we use a standard implementation of Vision Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> on image tasks spanning image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> and medical image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Our results suggest that <span id="S1.p3.1.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> (Federated Learning with Vision Transformers) performs especially well in settings with most heterogeneous device splits, with the gap between <span id="S1.p3.1.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span> and FL with ResNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> increasing significantly as heterogeneity increases. To understand these results, we find that the main source of improvement lies in the increased robustness of Transformer models to heterogeneous data which reduces catastrophic forgetting of previous devices when trained on substantially different new ones. Together, Transformers converge faster and reach a better global model suitable for most devices. Through comparisons to FL methods designed specifically to combat heterogeneous data, we find that <span id="S1.p3.1.3" class="ltx_text ltx_font_smallcaps">ViT-FL</span> provides immediate improvements without using training heuristics, additional hyperparameter tuning, or additional training.
Moreover, it is noteworthy that our <span id="S1.p3.1.4" class="ltx_text ltx_font_smallcaps">ViT-FL</span> is orthogonal to existing optimization based FL methods, and can be easily applied to improve their performance.
To this end, we conclude that Transformers should be regarded as a natural starting point for FL problems in future research.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Federated Learning.</span>
Federated learning (FL) aims to train machine learning models on private data across massively distributed devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. To enable effective distributed training across heterogeneous devices, two categories of methods have emerged: (1) parallel FL methods involve training each local client in parallel either synchronously or asynchronously (such as the classic FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>), whereas (2) serial methods train each client in a serial and cyclical way (such as Cyclic Weight Transfer (CWT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and Split learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>). A schematic description of FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is illustrated in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. At its core, FL presents a challenge of data heterogeneity in the distributions of training data across clients, which causes non-guaranteed convergence and model weight divergence for parallel FL methods  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, and severe catastrophic forgetting problem for serial FL methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Among recent developments to the classic FedAVG algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> have included using server momentum (FedAVGM) to mitigate per-client distribution shift and imbalance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, globally sharing small subsets of data among all users (FedAVG-Share) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, using a proximal term to the local objective (FedProx) to reduce potential weight divergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, or using other optimization heuristics such as collaborative replay <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, unsupervised contrastive learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, matching feature layers of user models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, or model distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> to handle heterogeneity.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Concurrently, several recent efforts aim to alleviate catastrophic forgetting in continual and serial learning: constraining the updates on weights that are important to previously seen tasks or clients (elastic weight consolidation (EWC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>), applying Deep Generative Replay to mimic data from previous clients or tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2021handling</span>]</cite>, and applying cyclically weighted objectives to mitigate performance loss across label distribution skewness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, among others.
However, all of these approaches mainly focus on improving the optimization algorithm without studying the potential in architecture design to improve robustness to distribution shifts in data. In our work, we show that simple choices in architecture actually make a big difference and should be an active area of study in parallel to the optimization methods that have been the main focus of current work.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Transformers.</span>
The Transformer architecture was first proposed for sequence-to-sequence machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> and has subsequently established state-of-the-art performance across many NLP tasks, especially when trained in a self-supervised paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Recently, Transformers have also been found to be broadly applicable to tasks involving images and video.
For instance, Parmar <em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> applied self-attention to local neighborhoods of an image while the Vision Transformer (ViT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> achieved state-of-the-art on ImageNet classification by directly applying Transformers with global self-attention to full-sized images.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Its intriguing performance boosts relative to classical architectures for language (<em id="S2.p5.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, LSTMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>) and vision (<em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, CNNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>) have inspired recent interest towards understanding the reasons behind their effectiveness. Among several particularly relevant findings are that ViTs are highly robust to severe occlusions, perturbations, domain shifts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, as well as synthetic and natural adversarial examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. In addition, recent studies have suggested that Transformers are also suitable for heterogeneous and multimodal data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. Inspired by these findings, we hypothesize that ViTs will also be highly effective in adapting to data heterogeneity in FL, and provide detailed empirical analysis to test this hypothesis.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Transformers in Federated Learning</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we present background on Transformer architectures and federated learning methods.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Vision Architectures</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">CNN.</span>
For convolution-based architectures, we use the ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> model family (ResNet-50, ResNet-152, and ResNeXt-101 (32x8d)) and EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> model family (EfficientNet-B1, EfficientNet-B5, and EfficientNet-B7), which contains a sequence of convolution, ReLU, pooling, and batch normalization layers. ResNet and EfficientNet are among the most popular architectures for image classification and have been the standard architecture used in FL on image data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Transformers.</span> As a comparison, we employ Vision Transformers (ViT(S), ViT(T), ViT(B)) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> model family and Swin Transformer model family (Swin(T), Swin(S), and Swin(B))  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, which do not use conventional convolution layers. Instead, the image features are extracted with image sequentialization and patch embedding strategies. See Figure <a href="#footnotex2" title="Footnote 1 ‣ Figure 1 ‣ 1 Introduction ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text" style="font-size:111%;">1</span></span></a> for the number of parameters for each model.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Federated Learning Methods</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We apply one of the most popular parallel methods (FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>) and serial methods (CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>) as training algorithms (see schematic descriptions in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Federated Averaging.</span>
FedAVG combines local stochastic gradient descent (SGD) on each client with iterative model averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Specifically, a fraction of local clients are randomly sampled in each communication round, and the server sends the current global model to each of these clients. Each selected client then performs <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">E</annotation></semantics></math> epochs of local SGD on its local training data and sends the local gradients back to the central server for aggregation synchronously. The server then applies the averaged gradients to update its global model, and the process repeats.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Cyclic Weight Transfer.</span>
In contrast to FedAVG where each local client is trained in a synchronous and parallel way, the local clients in CWT are trained in a serial and cyclic manner. In each round of training, CWT trains a global model on one local client with its local data for a number of epochs <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">E</annotation></semantics></math>, and then transfers this global model to the next client for training, until all local clients have been trained on once <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. The training process then cycles through the clients repeatedly until the model converges or a predefined number of communication rounds is reached.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<table id="S3.F3.4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.F3.4.4.5" class="ltx_tr">
<td id="S3.F3.4.4.5.1" class="ltx_td ltx_align_center">
 <span id="S3.F3.4.4.5.1.1" class="ltx_text" style="font-size:70%;">(a) CWT</span>
</td>
<td id="S3.F3.4.4.5.2" class="ltx_td ltx_align_center"><span id="S3.F3.4.4.5.2.1" class="ltx_text" style="font-size:70%;">(b) FedAVG</span></td>
</tr>
<tr id="S3.F3.2.2.2" class="ltx_tr">
<td id="S3.F3.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/retina_performance_drop_rate-cwt.png" id="S3.F3.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="255" height="142" alt="Refer to caption"></td>
<td id="S3.F3.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_FedAVG_droprate.png" id="S3.F3.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="255" height="142" alt="Refer to caption"></td>
</tr>
<tr id="S3.F3.4.4.4" class="ltx_tr">
<td id="S3.F3.3.3.3.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/cifar-10-performance-drop-rate_CWT.png" id="S3.F3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="255" height="142" alt="Refer to caption"></td>
<td id="S3.F3.4.4.4.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/cifar-10-performance-drop-rate_FedAVG.png" id="S3.F3.4.4.4.2.g1" class="ltx_graphics ltx_img_landscape" width="255" height="142" alt="Refer to caption"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.8.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.6.1" class="ltx_text" style="font-size:90%;">Prediction accuracy (%) of both CWT and FedAVG with CNNs and Transformers as baseline networks on Retina dataset (first row) and <span id="S3.F3.6.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="S3.F3.6.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.F3.6.1.1.m1.1b"><mn id="S3.F3.6.1.1.m1.1.1" xref="S3.F3.6.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.F3.6.1.1.m1.1c"><cn type="integer" id="S3.F3.6.1.1.m1.1.1.cmml" xref="S3.F3.6.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.1.1.m1.1d">10</annotation></semantics></math></span> dataset (second row), respectively. Vision Transformers (both ViT and Swin) show consistently strong performance especially in non-IID data partitions.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our experiments are designed to answer the following research questions that are of importance to practical deployment of FL methods, while also aiding our understanding of (vision) Transformer architectures.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Are Transformers able to learn a better global model in FL settings as compared to CNNs which have been the de-facto approach on FL tasks (section <a href="#S4.SS2" title="4.2 Results ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>)?
</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Are Transformers especially capable of handling heterogeneous data partitions (section <a href="#S4.SS3.SSS1" title="4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>)?</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Do Transformers reduce communication costs as compared to CNNs (section <a href="#S4.SS3.SSS2" title="4.3.2 Transformers converge faster to better optimum ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.2</span></a>)?</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Can Transformers be applied to further improve existing optimization-based FL methods (section  <a href="#S4.SS4" title="4.4 In Conjunction with Existing Methods ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>)?</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">What are practical tips helpful for practitioners to deploy Transformers in FL (section <a href="#S4.SS5" title="4.5 Take-aways for Practical Usage ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a>)?</p>
</div>
</li>
</ul>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, we evaluate FL on the Kaggle Diabetic Retinopathy competition dataset (denoted as Retina) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, CIFAR-<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">10</annotation></semantics></math> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> with simulated data partitions, and a real-world CelebA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> in our study.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.12" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Retina and CIFAR-<math id="S4.SS1.p2.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.p2.1.1.m1.1a"><mn id="S4.SS1.p2.1.1.m1.1.1" xref="S4.SS1.p2.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.1.m1.1b"><cn type="integer" id="S4.SS1.p2.1.1.m1.1.1.cmml" xref="S4.SS1.p2.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.1.m1.1c">10</annotation></semantics></math>:</span> We binarize the labels in the Retina dataset to Healthy (positive) and Diseased (negative), randomly selecting <math id="S4.SS1.p2.2.m1.2" class="ltx_Math" alttext="6,000" display="inline"><semantics id="S4.SS1.p2.2.m1.2a"><mrow id="S4.SS1.p2.2.m1.2.3.2" xref="S4.SS1.p2.2.m1.2.3.1.cmml"><mn id="S4.SS1.p2.2.m1.1.1" xref="S4.SS1.p2.2.m1.1.1.cmml">6</mn><mo id="S4.SS1.p2.2.m1.2.3.2.1" xref="S4.SS1.p2.2.m1.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.2.m1.2.2" xref="S4.SS1.p2.2.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m1.2b"><list id="S4.SS1.p2.2.m1.2.3.1.cmml" xref="S4.SS1.p2.2.m1.2.3.2"><cn type="integer" id="S4.SS1.p2.2.m1.1.1.cmml" xref="S4.SS1.p2.2.m1.1.1">6</cn><cn type="integer" id="S4.SS1.p2.2.m1.2.2.cmml" xref="S4.SS1.p2.2.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m1.2c">6,000</annotation></semantics></math> balanced images for training, <math id="S4.SS1.p2.3.m2.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="S4.SS1.p2.3.m2.2a"><mrow id="S4.SS1.p2.3.m2.2.3.2" xref="S4.SS1.p2.3.m2.2.3.1.cmml"><mn id="S4.SS1.p2.3.m2.1.1" xref="S4.SS1.p2.3.m2.1.1.cmml">3</mn><mo id="S4.SS1.p2.3.m2.2.3.2.1" xref="S4.SS1.p2.3.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.3.m2.2.2" xref="S4.SS1.p2.3.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m2.2b"><list id="S4.SS1.p2.3.m2.2.3.1.cmml" xref="S4.SS1.p2.3.m2.2.3.2"><cn type="integer" id="S4.SS1.p2.3.m2.1.1.cmml" xref="S4.SS1.p2.3.m2.1.1">3</cn><cn type="integer" id="S4.SS1.p2.3.m2.2.2.cmml" xref="S4.SS1.p2.3.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m2.2c">3,000</annotation></semantics></math> images as the global validation dataset, and <math id="S4.SS1.p2.4.m3.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="S4.SS1.p2.4.m3.2a"><mrow id="S4.SS1.p2.4.m3.2.3.2" xref="S4.SS1.p2.4.m3.2.3.1.cmml"><mn id="S4.SS1.p2.4.m3.1.1" xref="S4.SS1.p2.4.m3.1.1.cmml">3</mn><mo id="S4.SS1.p2.4.m3.2.3.2.1" xref="S4.SS1.p2.4.m3.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.4.m3.2.2" xref="S4.SS1.p2.4.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m3.2b"><list id="S4.SS1.p2.4.m3.2.3.1.cmml" xref="S4.SS1.p2.4.m3.2.3.2"><cn type="integer" id="S4.SS1.p2.4.m3.1.1.cmml" xref="S4.SS1.p2.4.m3.1.1">3</cn><cn type="integer" id="S4.SS1.p2.4.m3.2.2.cmml" xref="S4.SS1.p2.4.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m3.2c">3,000</annotation></semantics></math> images as the global testing dataset following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We use the original test set in CIFAR-<math id="S4.SS1.p2.5.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.p2.5.m4.1a"><mn id="S4.SS1.p2.5.m4.1.1" xref="S4.SS1.p2.5.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m4.1b"><cn type="integer" id="S4.SS1.p2.5.m4.1.1.cmml" xref="S4.SS1.p2.5.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m4.1c">10</annotation></semantics></math> as the global test dataset, set aside <math id="S4.SS1.p2.6.m5.2" class="ltx_Math" alttext="5,000" display="inline"><semantics id="S4.SS1.p2.6.m5.2a"><mrow id="S4.SS1.p2.6.m5.2.3.2" xref="S4.SS1.p2.6.m5.2.3.1.cmml"><mn id="S4.SS1.p2.6.m5.1.1" xref="S4.SS1.p2.6.m5.1.1.cmml">5</mn><mo id="S4.SS1.p2.6.m5.2.3.2.1" xref="S4.SS1.p2.6.m5.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.6.m5.2.2" xref="S4.SS1.p2.6.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m5.2b"><list id="S4.SS1.p2.6.m5.2.3.1.cmml" xref="S4.SS1.p2.6.m5.2.3.2"><cn type="integer" id="S4.SS1.p2.6.m5.1.1.cmml" xref="S4.SS1.p2.6.m5.1.1">5</cn><cn type="integer" id="S4.SS1.p2.6.m5.2.2.cmml" xref="S4.SS1.p2.6.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m5.2c">5,000</annotation></semantics></math> images from the original training dataset as the global validation dataset, and use the remaining <math id="S4.SS1.p2.7.m6.2" class="ltx_Math" alttext="45,000" display="inline"><semantics id="S4.SS1.p2.7.m6.2a"><mrow id="S4.SS1.p2.7.m6.2.3.2" xref="S4.SS1.p2.7.m6.2.3.1.cmml"><mn id="S4.SS1.p2.7.m6.1.1" xref="S4.SS1.p2.7.m6.1.1.cmml">45</mn><mo id="S4.SS1.p2.7.m6.2.3.2.1" xref="S4.SS1.p2.7.m6.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.7.m6.2.2" xref="S4.SS1.p2.7.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m6.2b"><list id="S4.SS1.p2.7.m6.2.3.1.cmml" xref="S4.SS1.p2.7.m6.2.3.2"><cn type="integer" id="S4.SS1.p2.7.m6.1.1.cmml" xref="S4.SS1.p2.7.m6.1.1">45</cn><cn type="integer" id="S4.SS1.p2.7.m6.2.2.cmml" xref="S4.SS1.p2.7.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m6.2c">45,000</annotation></semantics></math> images as the training dataset. We simulate three sets of data partitions: one IID-data partition, and two non-IID data partitions with label distribution skew. Each data partition in Retina and CIFAR-<math id="S4.SS1.p2.8.m7.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.p2.8.m7.1a"><mn id="S4.SS1.p2.8.m7.1.1" xref="S4.SS1.p2.8.m7.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m7.1b"><cn type="integer" id="S4.SS1.p2.8.m7.1.1.cmml" xref="S4.SS1.p2.8.m7.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m7.1c">10</annotation></semantics></math> contains <math id="S4.SS1.p2.9.m8.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS1.p2.9.m8.1a"><mn id="S4.SS1.p2.9.m8.1.1" xref="S4.SS1.p2.9.m8.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m8.1b"><cn type="integer" id="S4.SS1.p2.9.m8.1.1.cmml" xref="S4.SS1.p2.9.m8.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m8.1c">4</annotation></semantics></math> and <math id="S4.SS1.p2.10.m9.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS1.p2.10.m9.1a"><mn id="S4.SS1.p2.10.m9.1.1" xref="S4.SS1.p2.10.m9.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m9.1b"><cn type="integer" id="S4.SS1.p2.10.m9.1.1.cmml" xref="S4.SS1.p2.10.m9.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m9.1c">5</annotation></semantics></math> simulated clients, respectively. We use the mean Kolmogorov-Smirnov (KS) statistic between every two clients to measure the degree of label distribution skewness. <math id="S4.SS1.p2.11.m10.1" class="ltx_Math" alttext="\textrm{KS}=0" display="inline"><semantics id="S4.SS1.p2.11.m10.1a"><mrow id="S4.SS1.p2.11.m10.1.1" xref="S4.SS1.p2.11.m10.1.1.cmml"><mtext id="S4.SS1.p2.11.m10.1.1.2" xref="S4.SS1.p2.11.m10.1.1.2a.cmml">KS</mtext><mo id="S4.SS1.p2.11.m10.1.1.1" xref="S4.SS1.p2.11.m10.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.11.m10.1.1.3" xref="S4.SS1.p2.11.m10.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.11.m10.1b"><apply id="S4.SS1.p2.11.m10.1.1.cmml" xref="S4.SS1.p2.11.m10.1.1"><eq id="S4.SS1.p2.11.m10.1.1.1.cmml" xref="S4.SS1.p2.11.m10.1.1.1"></eq><ci id="S4.SS1.p2.11.m10.1.1.2a.cmml" xref="S4.SS1.p2.11.m10.1.1.2"><mtext id="S4.SS1.p2.11.m10.1.1.2.cmml" xref="S4.SS1.p2.11.m10.1.1.2">KS</mtext></ci><cn type="integer" id="S4.SS1.p2.11.m10.1.1.3.cmml" xref="S4.SS1.p2.11.m10.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.11.m10.1c">\textrm{KS}=0</annotation></semantics></math> indicates IID data partitions, while <math id="S4.SS1.p2.12.m11.1" class="ltx_Math" alttext="\textrm{KS}=1" display="inline"><semantics id="S4.SS1.p2.12.m11.1a"><mrow id="S4.SS1.p2.12.m11.1.1" xref="S4.SS1.p2.12.m11.1.1.cmml"><mtext id="S4.SS1.p2.12.m11.1.1.2" xref="S4.SS1.p2.12.m11.1.1.2a.cmml">KS</mtext><mo id="S4.SS1.p2.12.m11.1.1.1" xref="S4.SS1.p2.12.m11.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.12.m11.1.1.3" xref="S4.SS1.p2.12.m11.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.12.m11.1b"><apply id="S4.SS1.p2.12.m11.1.1.cmml" xref="S4.SS1.p2.12.m11.1.1"><eq id="S4.SS1.p2.12.m11.1.1.1.cmml" xref="S4.SS1.p2.12.m11.1.1.1"></eq><ci id="S4.SS1.p2.12.m11.1.1.2a.cmml" xref="S4.SS1.p2.12.m11.1.1.2"><mtext id="S4.SS1.p2.12.m11.1.1.2.cmml" xref="S4.SS1.p2.12.m11.1.1.2">KS</mtext></ci><cn type="integer" id="S4.SS1.p2.12.m11.1.1.3.cmml" xref="S4.SS1.p2.12.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.12.m11.1c">\textrm{KS}=1</annotation></semantics></math> results in an extremely non-IID data partition, where each client holds totally different label distributions (see Appendix <a href="#A1.SS1" title="A.1 Detailed Image Pre-processing and Data Partitions ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> for detailed pre-processing and data partitions).</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.5" class="ltx_p"><span id="S4.SS1.p3.5.1" class="ltx_text ltx_font_bold">CelebA</span> is a large-scale face attributes dataset with more than <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mn id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><cn type="integer" id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">200</annotation></semantics></math>K celebrity images. We use the federated version of CelebA provided by the LEAF benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> which partitions into devices based on identity. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, we test on the binary classification task (presence of smile) and drop clients with larger than <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mn id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><cn type="integer" id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">8</annotation></semantics></math> samples to increase task difficulty. This results in a total of <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="227" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mn id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">227</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><cn type="integer" id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">227</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">227</annotation></semantics></math> clients each with an average of <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="5.34\pm 1.11" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mn id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">5.34</mn><mo id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml">±</mo><mn id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">1.11</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2">5.34</cn><cn type="float" id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">1.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">5.34\pm 1.11</annotation></semantics></math> samples and a total of <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="1213" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><mn id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml">1213</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><cn type="integer" id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">1213</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">1213</annotation></semantics></math> samples.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.5" class="ltx_p">We use linear learning rate warm-up and decay scheduler for <span id="S4.SS1.p4.5.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span>. The learning rate scheduler for FL with CNNs is selected from linear warm-up and decay or step decay. Gradient clipping (at global norm 1) is applied to stabilize training. We set the local training epoch <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">E</annotation></semantics></math> in all FL methods to <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mn id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><cn type="integer" id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">1</annotation></semantics></math> (unless otherwise stated), and the total communication rounds to <math id="S4.SS1.p4.3.m3.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS1.p4.3.m3.1a"><mn id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><cn type="integer" id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">100</annotation></semantics></math> for Retina and CIFAR-<math id="S4.SS1.p4.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.p4.4.m4.1a"><mn id="S4.SS1.p4.4.m4.1.1" xref="S4.SS1.p4.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.1b"><cn type="integer" id="S4.SS1.p4.4.m4.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.1c">10</annotation></semantics></math>, and <math id="S4.SS1.p4.5.m5.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS1.p4.5.m5.1a"><mn id="S4.SS1.p4.5.m5.1.1" xref="S4.SS1.p4.5.m5.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.5.m5.1b"><cn type="integer" id="S4.SS1.p4.5.m5.1.1.cmml" xref="S4.SS1.p4.5.m5.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.5.m5.1c">30</annotation></semantics></math> for CelebA. For fair comparison, all models used in this paper are pretrained on ImageNet-1K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. More implementation details are in Appendix <a href="#A1.SS2" title="A.2 Implementation Details and Hyperparameters ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Compute:</span> All experiments were conducted on either a TITAN V GPU or Tesla V100 GPU.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<table id="S4.F4.6.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.F4.3.3.3" class="ltx_tr">
<td id="S4.F4.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_all_split_1.png" id="S4.F4.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="162" height="128" alt="Refer to caption"></td>
<td id="S4.F4.2.2.2.2" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Retina_all_split_2.png" id="S4.F4.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="162" height="127" alt="Refer to caption">
</td>
<td id="S4.F4.3.3.3.3" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Retina_all_split_3.png" id="S4.F4.3.3.3.3.g1" class="ltx_graphics ltx_img_landscape" width="243" height="129" alt="Refer to caption">
</td>
</tr>
<tr id="S4.F4.6.6.6" class="ltx_tr">
<td id="S4.F4.4.4.4.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/CIFAR_all_split_1.png" id="S4.F4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="164" height="129" alt="Refer to caption"></td>
<td id="S4.F4.5.5.5.2" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/CIFAR_all_split_2.png" id="S4.F4.5.5.5.2.g1" class="ltx_graphics ltx_img_landscape" width="161" height="129" alt="Refer to caption">
</td>
<td id="S4.F4.6.6.6.3" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/CIFAR_all_split_3.png" id="S4.F4.6.6.6.3.g1" class="ltx_graphics ltx_img_landscape" width="243" height="129" alt="Refer to caption">
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.10.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.8.1" class="ltx_text" style="font-size:90%;">Test set accuracy versus communication rounds on Retina dataset (first row) and CIFAR-<math id="S4.F4.8.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F4.8.1.m1.1b"><mn id="S4.F4.8.1.m1.1.1" xref="S4.F4.8.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F4.8.1.m1.1c"><cn type="integer" id="S4.F4.8.1.m1.1.1.cmml" xref="S4.F4.8.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.1.m1.1d">10</annotation></semantics></math> dataset (second row) with different data partitions. The black dashed line shows the target performance (Target-ACC) used in Table <a href="#S4.T3" title="Table 3 ‣ 4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Vision Transformers converge faster with fewer communication rounds, which make them especially suitable for communication-efficient FL.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.4" class="ltx_p"><span id="S4.SS2.p1.4.1" class="ltx_text ltx_font_bold">Comparison of FL with different neural architectures and (ideal) centralized training:</span> Both CWT and FedAVG achieve comparable results to a model trained on centrally hosted data (denoted as Central) on the IID setting no matter which architecture is applied (Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Federated Learning Methods ‣ 3 Transformers in Federated Learning ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). However, we observe a significant reduction in test accuracy for CNNs on heterogeneous data partitions for both CWT and FedAVG, especially on extremely heterogeneous data partitions (Split 3, KS-1 of CIFAR-<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">10</annotation></semantics></math>) (Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Federated Learning Methods ‣ 3 Transformers in Federated Learning ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Figure <a href="#footnotex2" title="Footnote 1 ‣ Figure 1 ‣ 1 Introduction ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text" style="font-size:111%;">1</span></span></a>). By simply replacing CNNs with ViTs, both CWT and FedAVG successfully retain model accuracy even in highly heterogeneous non-IID settings. ViT(S)-CWT and ViT(S)-FedAVG improve the test accuracy relative to ResNet(50)-CWT and ResNet(50)-FedAVG by <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="77.70\%" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">77.70</mn><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">77.70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">77.70\%</annotation></semantics></math> and <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="37.34\%" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">37.34</mn><mo id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">37.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">37.34\%</annotation></semantics></math> on the highly heterogeneous Split-3, KS-1 of CIFAR-<math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><cn type="integer" id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">10</annotation></semantics></math> dataset. Therefore, <span id="S4.SS2.p1.4.2" class="ltx_text ltx_font_smallcaps">ViT</span> is particularly suitable for heterogeneous data.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.7" class="ltx_p"><span id="S4.SS2.p2.7.1" class="ltx_text ltx_font_bold">Comparison with existing FL methods:</span> We also compare <span id="S4.SS2.p2.7.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span> to two state-of-the-art optimization based FL methods: FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> on both Retina and CIFAR-<math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">10</annotation></semantics></math>. We use ResNet(50) as the backbone network for the other compared methods, and ViT(S) for our methods. We tune the best parameters (penalty constant <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\mu</annotation></semantics></math> in the proximal term of FedProx) on Split-2 dataset with grid search, and apply the same parameters to all the remaining data partitions.
We allow each client to share <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mn id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">5</mn><mo id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">5\%</annotation></semantics></math> percentage of their data among each other for FedAVG-Share. As shown in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, <span id="S4.SS2.p2.7.3" class="ltx_text ltx_font_smallcaps">ViT-FL</span> outperforms all the other FL methods in non-IID data partitions, especially on the highly heterogeneous non-IID settings. FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> suffers severe performance drops on highly heterogeneous data partitions despite carefully tuned optimization parameters. Similarly, FedAVG-Share also suffers from performance drops on highly heterogeneous data partition Split-3 even when <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mn id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">5</mn><mo id="S4.SS2.p2.4.m4.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">5\%</annotation></semantics></math> percentage of the local data is shared among all clients (<math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="94.4\%" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><mrow id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mn id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">94.4</mn><mo id="S4.SS2.p2.5.m5.1.1.1" xref="S4.SS2.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">94.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">94.4\%</annotation></semantics></math> of Split-3 on CIFAR-<math id="S4.SS2.p2.6.m6.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p2.6.m6.1a"><mn id="S4.SS2.p2.6.m6.1.1" xref="S4.SS2.p2.6.m6.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m6.1b"><cn type="integer" id="S4.SS2.p2.6.m6.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m6.1c">10</annotation></semantics></math> dataset compared to <math id="S4.SS2.p2.7.m7.1" class="ltx_Math" alttext="97\%" display="inline"><semantics id="S4.SS2.p2.7.m7.1a"><mrow id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml"><mn id="S4.SS2.p2.7.m7.1.1.2" xref="S4.SS2.p2.7.m7.1.1.2.cmml">97</mn><mo id="S4.SS2.p2.7.m7.1.1.1" xref="S4.SS2.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.1b"><apply id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1"><csymbol cd="latexml" id="S4.SS2.p2.7.m7.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.7.m7.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1.2">97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.1c">97\%</annotation></semantics></math> on Split-1). We conclude that simply using Transformers outperforms several recent methods designed for FL, which often require careful tuning of optimization parameters. Please note that the usage of <span id="S4.SS2.p2.7.4" class="ltx_text ltx_font_smallcaps">ViT</span>s is orthogonal to the existing optimization methods, and a combination of both can yield
stronger performance (see details in Section <a href="#S4.SS4" title="4.4 In Conjunction with Existing Methods ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.13.2.1" class="ltx_text" style="font-size:113%;">Table 1</span>: </span><span id="S4.T1.2.1" class="ltx_text" style="font-size:113%;">Prediction accuracy (<math id="S4.T1.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.2.1.m1.1b"><mo id="S4.T1.2.1.m1.1.1" xref="S4.T1.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.1.m1.1c"><csymbol cd="latexml" id="S4.T1.2.1.m1.1.1.cmml" xref="S4.T1.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.1.m1.1d">\%</annotation></semantics></math>) on CelebA dataset. Vision Transformers show superior performance to their ResNet(50) (R50 in Table) counterparts, and also outperform the optimization based FL methods (FedProx and FedAVG-Share) with ResNet(50) as backbone network.</span></figcaption>
<table id="S4.T1.8" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.8.7" class="ltx_tr">
<td id="S4.T1.8.7.1" class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T1.8.7.1.1" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S4.T1.8.7.2" class="ltx_td ltx_align_center"><span id="S4.T1.8.7.2.1" class="ltx_text" style="font-size:80%;">R50-CWT</span></td>
<td id="S4.T1.8.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.8.7.3.1" class="ltx_text" style="font-size:80%;">ViT(S)-CWT</span></td>
<td id="S4.T1.8.7.4" class="ltx_td ltx_align_center"><span id="S4.T1.8.7.4.1" class="ltx_text" style="font-size:80%;">R50-FedAVG</span></td>
<td id="S4.T1.8.7.5" class="ltx_td ltx_align_center"><span id="S4.T1.8.7.5.1" class="ltx_text" style="font-size:80%;">R50-FedProx</span></td>
<td id="S4.T1.8.7.6" class="ltx_td ltx_align_center"><span id="S4.T1.8.7.6.1" class="ltx_text" style="font-size:80%;">R50-FedAVG-Share</span></td>
<td id="S4.T1.8.7.7" class="ltx_td ltx_align_center"><span id="S4.T1.8.7.7.1" class="ltx_text" style="font-size:80%;">ViT(S)-FedAVG</span></td>
</tr>
<tr id="S4.T1.8.6" class="ltx_tr">
<td id="S4.T1.8.6.7" class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span><span id="S4.T1.8.6.7.1" class="ltx_text" style="font-size:80%;">
CelebA</span>
</td>
<td id="S4.T1.3.1.1" class="ltx_td ltx_align_center"><math id="S4.T1.3.1.1.m1.1" class="ltx_Math" alttext="85.35\pm 8.27" display="inline"><semantics id="S4.T1.3.1.1.m1.1a"><mrow id="S4.T1.3.1.1.m1.1.1" xref="S4.T1.3.1.1.m1.1.1.cmml"><mn mathsize="80%" id="S4.T1.3.1.1.m1.1.1.2" xref="S4.T1.3.1.1.m1.1.1.2.cmml">85.35</mn><mo mathsize="80%" id="S4.T1.3.1.1.m1.1.1.1" xref="S4.T1.3.1.1.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T1.3.1.1.m1.1.1.3" xref="S4.T1.3.1.1.m1.1.1.3.cmml">8.27</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.m1.1b"><apply id="S4.T1.3.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T1.3.1.1.m1.1.1.1.cmml" xref="S4.T1.3.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.3.1.1.m1.1.1.2.cmml" xref="S4.T1.3.1.1.m1.1.1.2">85.35</cn><cn type="float" id="S4.T1.3.1.1.m1.1.1.3.cmml" xref="S4.T1.3.1.1.m1.1.1.3">8.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.m1.1c">85.35\pm 8.27</annotation></semantics></math></td>
<td id="S4.T1.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T1.4.2.2.m1.1" class="ltx_Math" alttext="\textbf{88.09}\pm\textbf{5.15}" display="inline"><semantics id="S4.T1.4.2.2.m1.1a"><mrow id="S4.T1.4.2.2.m1.1.1" xref="S4.T1.4.2.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.4.2.2.m1.1.1.2" xref="S4.T1.4.2.2.m1.1.1.2a.cmml">88.09</mtext><mo mathsize="80%" id="S4.T1.4.2.2.m1.1.1.1" xref="S4.T1.4.2.2.m1.1.1.1.cmml">±</mo><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.4.2.2.m1.1.1.3" xref="S4.T1.4.2.2.m1.1.1.3a.cmml">5.15</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.2.m1.1b"><apply id="S4.T1.4.2.2.m1.1.1.cmml" xref="S4.T1.4.2.2.m1.1.1"><csymbol cd="latexml" id="S4.T1.4.2.2.m1.1.1.1.cmml" xref="S4.T1.4.2.2.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T1.4.2.2.m1.1.1.2a.cmml" xref="S4.T1.4.2.2.m1.1.1.2"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.4.2.2.m1.1.1.2.cmml" xref="S4.T1.4.2.2.m1.1.1.2">88.09</mtext></ci><ci id="S4.T1.4.2.2.m1.1.1.3a.cmml" xref="S4.T1.4.2.2.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.4.2.2.m1.1.1.3.cmml" xref="S4.T1.4.2.2.m1.1.1.3">5.15</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.2.m1.1c">\textbf{88.09}\pm\textbf{5.15}</annotation></semantics></math></td>
<td id="S4.T1.5.3.3" class="ltx_td ltx_align_center"><math id="S4.T1.5.3.3.m1.1" class="ltx_Math" alttext="84.08\pm 9.65" display="inline"><semantics id="S4.T1.5.3.3.m1.1a"><mrow id="S4.T1.5.3.3.m1.1.1" xref="S4.T1.5.3.3.m1.1.1.cmml"><mn mathsize="80%" id="S4.T1.5.3.3.m1.1.1.2" xref="S4.T1.5.3.3.m1.1.1.2.cmml">84.08</mn><mo mathsize="80%" id="S4.T1.5.3.3.m1.1.1.1" xref="S4.T1.5.3.3.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T1.5.3.3.m1.1.1.3" xref="S4.T1.5.3.3.m1.1.1.3.cmml">9.65</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.3.3.m1.1b"><apply id="S4.T1.5.3.3.m1.1.1.cmml" xref="S4.T1.5.3.3.m1.1.1"><csymbol cd="latexml" id="S4.T1.5.3.3.m1.1.1.1.cmml" xref="S4.T1.5.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.5.3.3.m1.1.1.2.cmml" xref="S4.T1.5.3.3.m1.1.1.2">84.08</cn><cn type="float" id="S4.T1.5.3.3.m1.1.1.3.cmml" xref="S4.T1.5.3.3.m1.1.1.3">9.65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.3.3.m1.1c">84.08\pm 9.65</annotation></semantics></math></td>
<td id="S4.T1.6.4.4" class="ltx_td ltx_align_center"><math id="S4.T1.6.4.4.m1.1" class="ltx_Math" alttext="84.27\pm 9.74" display="inline"><semantics id="S4.T1.6.4.4.m1.1a"><mrow id="S4.T1.6.4.4.m1.1.1" xref="S4.T1.6.4.4.m1.1.1.cmml"><mn mathsize="80%" id="S4.T1.6.4.4.m1.1.1.2" xref="S4.T1.6.4.4.m1.1.1.2.cmml">84.27</mn><mo mathsize="80%" id="S4.T1.6.4.4.m1.1.1.1" xref="S4.T1.6.4.4.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T1.6.4.4.m1.1.1.3" xref="S4.T1.6.4.4.m1.1.1.3.cmml">9.74</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.4.4.m1.1b"><apply id="S4.T1.6.4.4.m1.1.1.cmml" xref="S4.T1.6.4.4.m1.1.1"><csymbol cd="latexml" id="S4.T1.6.4.4.m1.1.1.1.cmml" xref="S4.T1.6.4.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.6.4.4.m1.1.1.2.cmml" xref="S4.T1.6.4.4.m1.1.1.2">84.27</cn><cn type="float" id="S4.T1.6.4.4.m1.1.1.3.cmml" xref="S4.T1.6.4.4.m1.1.1.3">9.74</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.4.4.m1.1c">84.27\pm 9.74</annotation></semantics></math></td>
<td id="S4.T1.7.5.5" class="ltx_td ltx_align_center"><math id="S4.T1.7.5.5.m1.1" class="ltx_Math" alttext="85.46\pm 3.75" display="inline"><semantics id="S4.T1.7.5.5.m1.1a"><mrow id="S4.T1.7.5.5.m1.1.1" xref="S4.T1.7.5.5.m1.1.1.cmml"><mn mathsize="80%" id="S4.T1.7.5.5.m1.1.1.2" xref="S4.T1.7.5.5.m1.1.1.2.cmml">85.46</mn><mo mathsize="80%" id="S4.T1.7.5.5.m1.1.1.1" xref="S4.T1.7.5.5.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T1.7.5.5.m1.1.1.3" xref="S4.T1.7.5.5.m1.1.1.3.cmml">3.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.5.5.m1.1b"><apply id="S4.T1.7.5.5.m1.1.1.cmml" xref="S4.T1.7.5.5.m1.1.1"><csymbol cd="latexml" id="S4.T1.7.5.5.m1.1.1.1.cmml" xref="S4.T1.7.5.5.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.7.5.5.m1.1.1.2.cmml" xref="S4.T1.7.5.5.m1.1.1.2">85.46</cn><cn type="float" id="S4.T1.7.5.5.m1.1.1.3.cmml" xref="S4.T1.7.5.5.m1.1.1.3">3.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.5.5.m1.1c">85.46\pm 3.75</annotation></semantics></math></td>
<td id="S4.T1.8.6.6" class="ltx_td ltx_align_center"><math id="S4.T1.8.6.6.m1.1" class="ltx_Math" alttext="\textbf{86.63}\pm\textbf{7.12}" display="inline"><semantics id="S4.T1.8.6.6.m1.1a"><mrow id="S4.T1.8.6.6.m1.1.1" xref="S4.T1.8.6.6.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.8.6.6.m1.1.1.2" xref="S4.T1.8.6.6.m1.1.1.2a.cmml">86.63</mtext><mo mathsize="80%" id="S4.T1.8.6.6.m1.1.1.1" xref="S4.T1.8.6.6.m1.1.1.1.cmml">±</mo><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.8.6.6.m1.1.1.3" xref="S4.T1.8.6.6.m1.1.1.3a.cmml">7.12</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.6.6.m1.1b"><apply id="S4.T1.8.6.6.m1.1.1.cmml" xref="S4.T1.8.6.6.m1.1.1"><csymbol cd="latexml" id="S4.T1.8.6.6.m1.1.1.1.cmml" xref="S4.T1.8.6.6.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T1.8.6.6.m1.1.1.2a.cmml" xref="S4.T1.8.6.6.m1.1.1.2"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.8.6.6.m1.1.1.2.cmml" xref="S4.T1.8.6.6.m1.1.1.2">86.63</mtext></ci><ci id="S4.T1.8.6.6.m1.1.1.3a.cmml" xref="S4.T1.8.6.6.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="80%" id="S4.T1.8.6.6.m1.1.1.3.cmml" xref="S4.T1.8.6.6.m1.1.1.3">7.12</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.6.6.m1.1c">\textbf{86.63}\pm\textbf{7.12}</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.8.8" class="ltx_tr">
<td id="S4.T1.8.8.1" class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="S4.T1.8.8.2" class="ltx_td"></td>
<td id="S4.T1.8.8.3" class="ltx_td"></td>
<td id="S4.T1.8.8.4" class="ltx_td"></td>
<td id="S4.T1.8.8.5" class="ltx_td"></td>
<td id="S4.T1.8.8.6" class="ltx_td"></td>
<td id="S4.T1.8.8.7" class="ltx_td"></td>
</tr>
</table>
</figure>
<figure id="S4.F5" class="ltx_figure">
<table id="S4.F5.2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.F5.2.2.2" class="ltx_tr">
<td id="S4.F5.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/EWC_Cifar.png" id="S4.F5.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="231" height="182" alt="Refer to caption"></td>
<td id="S4.F5.2.2.2.2" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/EWC_cifar_10_zoom.png" id="S4.F5.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="231" height="178" alt="Refer to caption">
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.6.2.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.1" class="ltx_text" style="font-size:90%;">Left: evolution of the prediction accuracy on the validation dataset of client 3 as more clients are involved in CWT learning. We use Split 3 of CIFAR-<math id="S4.F5.4.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F5.4.1.m1.1b"><mn id="S4.F5.4.1.m1.1.1" xref="S4.F5.4.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F5.4.1.m1.1c"><cn type="integer" id="S4.F5.4.1.m1.1.1.cmml" xref="S4.F5.4.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.4.1.m1.1d">10</annotation></semantics></math> dataset (most heterogeneous data split) and compare CWT trained with the ResNet(50) (R50 in Figure), ResNet(50)-EWC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, and ViT(S) models. Right: zoom in on the red rectangular in the left image. The training order of different clients is also shown. The sequential training strategy of ResNet(50)-CWT incurs catastrophic forgetting on previous clients under highly heterogeneous data distributions. ResNet(50)-EWC-CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> barely solves the catastrophic forgetting problem. ViT(S)-CWT helps alleviate this problem due to its strong generalization ability and robustness to heterogeneous data.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Analyzing the Effectiveness of Transformers</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Given these promising empirical results, we now perform a careful empirical analysis to uncover what exactly contributes to Transformers’ improved performance.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span><span id="S4.SS3.SSS1.1.1" class="ltx_text">Transformers generalize better in non-IID settings</span>
</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">The distributed nature of FL means that there can be substantial heterogeneity in data distributions across clients.
Prior research has shown that training FL models with FedAVG or CWT incurs issues such as weight divergence and catastrophic forgetting respectively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
We argue that the local convolutions used in CNNs, which have been shown to rely more on local high-frequency patterns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, might be particularly sensitive to heterogeneous devices.
This problem is particularly prevalent in FL over healthcare data since input images captured by different institutions may vary significantly in local patterns (intensity, contrast, <em id="S4.SS3.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">etc.</em>) due to different medical imaging protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, as well as in natural data splits due to user idiosyncrasies in speaking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, typing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and writing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
On the other hand, ViTs use self-attention to learn global interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and have been shown to be less biased towards local patterns as compared to CNNs.
This property may contribute to their surprising robustness to distribution shifts and adversarial perturbations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.
To further analyze the generalization capabilities of Transformers across heterogeneous data, we design the following experiments:</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.23.4.1" class="ltx_text" style="font-size:113%;">Table 2</span>: </span><span id="S4.T2.6.3" class="ltx_text" style="font-size:113%;">Prediction accuracy (%) on a large-scale edge case setting with thousands of clients involved in training (<math id="S4.T2.4.1.m1.2" class="ltx_Math" alttext="6,000" display="inline"><semantics id="S4.T2.4.1.m1.2b"><mrow id="S4.T2.4.1.m1.2.3.2" xref="S4.T2.4.1.m1.2.3.1.cmml"><mn id="S4.T2.4.1.m1.1.1" xref="S4.T2.4.1.m1.1.1.cmml">6</mn><mo id="S4.T2.4.1.m1.2.3.2.1" xref="S4.T2.4.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.4.1.m1.2.2" xref="S4.T2.4.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.1.m1.2c"><list id="S4.T2.4.1.m1.2.3.1.cmml" xref="S4.T2.4.1.m1.2.3.2"><cn type="integer" id="S4.T2.4.1.m1.1.1.cmml" xref="S4.T2.4.1.m1.1.1">6</cn><cn type="integer" id="S4.T2.4.1.m1.2.2.cmml" xref="S4.T2.4.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.1.m1.2d">6,000</annotation></semantics></math> and <math id="S4.T2.5.2.m2.2" class="ltx_Math" alttext="45,000" display="inline"><semantics id="S4.T2.5.2.m2.2b"><mrow id="S4.T2.5.2.m2.2.3.2" xref="S4.T2.5.2.m2.2.3.1.cmml"><mn id="S4.T2.5.2.m2.1.1" xref="S4.T2.5.2.m2.1.1.cmml">45</mn><mo id="S4.T2.5.2.m2.2.3.2.1" xref="S4.T2.5.2.m2.2.3.1.cmml">,</mo><mn id="S4.T2.5.2.m2.2.2" xref="S4.T2.5.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.2.m2.2c"><list id="S4.T2.5.2.m2.2.3.1.cmml" xref="S4.T2.5.2.m2.2.3.2"><cn type="integer" id="S4.T2.5.2.m2.1.1.cmml" xref="S4.T2.5.2.m2.1.1">45</cn><cn type="integer" id="S4.T2.5.2.m2.2.2.cmml" xref="S4.T2.5.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.2.m2.2d">45,000</annotation></semantics></math> clients for Retina and CIFAR-<math id="S4.T2.6.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T2.6.3.m3.1b"><mn id="S4.T2.6.3.m3.1.1" xref="S4.T2.6.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T2.6.3.m3.1c"><cn type="integer" id="S4.T2.6.3.m3.1.1.cmml" xref="S4.T2.6.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.3.m3.1d">10</annotation></semantics></math> respectively, with each client containing one data sample). Vision Transformers significantly outperform their ResNet counterparts in this edge case setting.</span></figcaption>
<table id="S4.T2.16" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.8.2" class="ltx_tr">
<td id="S4.T2.8.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T2.8.2.3.1" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S4.T2.7.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;" colspan="2"><span id="S4.T2.7.1.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Retina (#<math id="S4.T2.7.1.1.1.m1.2" class="ltx_Math" alttext="6,000" display="inline"><semantics id="S4.T2.7.1.1.1.m1.2a"><mrow id="S4.T2.7.1.1.1.m1.2.3.2" xref="S4.T2.7.1.1.1.m1.2.3.1.cmml"><mn id="S4.T2.7.1.1.1.m1.1.1" xref="S4.T2.7.1.1.1.m1.1.1.cmml">6</mn><mo id="S4.T2.7.1.1.1.m1.2.3.2.1" xref="S4.T2.7.1.1.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.7.1.1.1.m1.2.2" xref="S4.T2.7.1.1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.1.1.1.m1.2b"><list id="S4.T2.7.1.1.1.m1.2.3.1.cmml" xref="S4.T2.7.1.1.1.m1.2.3.2"><cn type="integer" id="S4.T2.7.1.1.1.m1.1.1.cmml" xref="S4.T2.7.1.1.1.m1.1.1">6</cn><cn type="integer" id="S4.T2.7.1.1.1.m1.2.2.cmml" xref="S4.T2.7.1.1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.1.1.1.m1.2c">6,000</annotation></semantics></math>)</span></td>
<td id="S4.T2.8.2.2" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;" colspan="2"><span id="S4.T2.8.2.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">CIFAR-10 (#<math id="S4.T2.8.2.2.1.m1.2" class="ltx_Math" alttext="45,000" display="inline"><semantics id="S4.T2.8.2.2.1.m1.2a"><mrow id="S4.T2.8.2.2.1.m1.2.3.2" xref="S4.T2.8.2.2.1.m1.2.3.1.cmml"><mn id="S4.T2.8.2.2.1.m1.1.1" xref="S4.T2.8.2.2.1.m1.1.1.cmml">45</mn><mo id="S4.T2.8.2.2.1.m1.2.3.2.1" xref="S4.T2.8.2.2.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.8.2.2.1.m1.2.2" xref="S4.T2.8.2.2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.2.2.1.m1.2b"><list id="S4.T2.8.2.2.1.m1.2.3.1.cmml" xref="S4.T2.8.2.2.1.m1.2.3.2"><cn type="integer" id="S4.T2.8.2.2.1.m1.1.1.cmml" xref="S4.T2.8.2.2.1.m1.1.1">45</cn><cn type="integer" id="S4.T2.8.2.2.1.m1.2.2.cmml" xref="S4.T2.8.2.2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.2.2.1.m1.2c">45,000</annotation></semantics></math>)</span></td>
</tr>
<tr id="S4.T2.16.11" class="ltx_tr">
<td id="S4.T2.16.11.1" class="ltx_td ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"></td>
<td id="S4.T2.16.11.2" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><span id="S4.T2.16.11.2.1" class="ltx_text" style="font-size:80%;">CWT</span></td>
<td id="S4.T2.16.11.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"><span id="S4.T2.16.11.3.1" class="ltx_text" style="font-size:80%;">FedAVG</span></td>
<td id="S4.T2.16.11.4" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><span id="S4.T2.16.11.4.1" class="ltx_text" style="font-size:80%;">CWT</span></td>
<td id="S4.T2.16.11.5" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><span id="S4.T2.16.11.5.1" class="ltx_text" style="font-size:80%;">FedAVG</span></td>
</tr>
<tr id="S4.T2.12.6" class="ltx_tr">
<td id="S4.T2.12.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T2.12.6.5.1" class="ltx_text" style="font-size:80%;">
ResNet(50)</span>
</td>
<td id="S4.T2.9.3.1" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.9.3.1.m1.1" class="ltx_Math" alttext="51.3\pm 1.3" display="inline"><semantics id="S4.T2.9.3.1.m1.1a"><mrow id="S4.T2.9.3.1.m1.1.1" xref="S4.T2.9.3.1.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.9.3.1.m1.1.1.2" xref="S4.T2.9.3.1.m1.1.1.2.cmml">51.3</mn><mo mathsize="80%" id="S4.T2.9.3.1.m1.1.1.1" xref="S4.T2.9.3.1.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.9.3.1.m1.1.1.3" xref="S4.T2.9.3.1.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.3.1.m1.1b"><apply id="S4.T2.9.3.1.m1.1.1.cmml" xref="S4.T2.9.3.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.9.3.1.m1.1.1.1.cmml" xref="S4.T2.9.3.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.9.3.1.m1.1.1.2.cmml" xref="S4.T2.9.3.1.m1.1.1.2">51.3</cn><cn type="float" id="S4.T2.9.3.1.m1.1.1.3.cmml" xref="S4.T2.9.3.1.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.3.1.m1.1c">51.3\pm 1.3</annotation></semantics></math></td>
<td id="S4.T2.10.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.10.4.2.m1.1" class="ltx_Math" alttext="55.0\pm 0.3" display="inline"><semantics id="S4.T2.10.4.2.m1.1a"><mrow id="S4.T2.10.4.2.m1.1.1" xref="S4.T2.10.4.2.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.10.4.2.m1.1.1.2" xref="S4.T2.10.4.2.m1.1.1.2.cmml">55.0</mn><mo mathsize="80%" id="S4.T2.10.4.2.m1.1.1.1" xref="S4.T2.10.4.2.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.10.4.2.m1.1.1.3" xref="S4.T2.10.4.2.m1.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.4.2.m1.1b"><apply id="S4.T2.10.4.2.m1.1.1.cmml" xref="S4.T2.10.4.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.10.4.2.m1.1.1.1.cmml" xref="S4.T2.10.4.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.10.4.2.m1.1.1.2.cmml" xref="S4.T2.10.4.2.m1.1.1.2">55.0</cn><cn type="float" id="S4.T2.10.4.2.m1.1.1.3.cmml" xref="S4.T2.10.4.2.m1.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.4.2.m1.1c">55.0\pm 0.3</annotation></semantics></math></td>
<td id="S4.T2.11.5.3" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.11.5.3.m1.1" class="ltx_Math" alttext="31.2\pm 12.2" display="inline"><semantics id="S4.T2.11.5.3.m1.1a"><mrow id="S4.T2.11.5.3.m1.1.1" xref="S4.T2.11.5.3.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.11.5.3.m1.1.1.2" xref="S4.T2.11.5.3.m1.1.1.2.cmml">31.2</mn><mo mathsize="80%" id="S4.T2.11.5.3.m1.1.1.1" xref="S4.T2.11.5.3.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.11.5.3.m1.1.1.3" xref="S4.T2.11.5.3.m1.1.1.3.cmml">12.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.5.3.m1.1b"><apply id="S4.T2.11.5.3.m1.1.1.cmml" xref="S4.T2.11.5.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.11.5.3.m1.1.1.1.cmml" xref="S4.T2.11.5.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.11.5.3.m1.1.1.2.cmml" xref="S4.T2.11.5.3.m1.1.1.2">31.2</cn><cn type="float" id="S4.T2.11.5.3.m1.1.1.3.cmml" xref="S4.T2.11.5.3.m1.1.1.3">12.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.5.3.m1.1c">31.2\pm 12.2</annotation></semantics></math></td>
<td id="S4.T2.12.6.4" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.12.6.4.m1.1" class="ltx_Math" alttext="37.5\pm 1.4" display="inline"><semantics id="S4.T2.12.6.4.m1.1a"><mrow id="S4.T2.12.6.4.m1.1.1" xref="S4.T2.12.6.4.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.12.6.4.m1.1.1.2" xref="S4.T2.12.6.4.m1.1.1.2.cmml">37.5</mn><mo mathsize="80%" id="S4.T2.12.6.4.m1.1.1.1" xref="S4.T2.12.6.4.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.12.6.4.m1.1.1.3" xref="S4.T2.12.6.4.m1.1.1.3.cmml">1.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.6.4.m1.1b"><apply id="S4.T2.12.6.4.m1.1.1.cmml" xref="S4.T2.12.6.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.12.6.4.m1.1.1.1.cmml" xref="S4.T2.12.6.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.12.6.4.m1.1.1.2.cmml" xref="S4.T2.12.6.4.m1.1.1.2">37.5</cn><cn type="float" id="S4.T2.12.6.4.m1.1.1.3.cmml" xref="S4.T2.12.6.4.m1.1.1.3">1.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.6.4.m1.1c">37.5\pm 1.4</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.16.10" class="ltx_tr">
<td id="S4.T2.16.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"><span id="S4.T2.16.10.5.1" class="ltx_text" style="font-size:80%;">ViT(S)</span></td>
<td id="S4.T2.13.7.1" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.13.7.1.m1.1" class="ltx_Math" alttext="80.0\pm 0.1" display="inline"><semantics id="S4.T2.13.7.1.m1.1a"><mrow id="S4.T2.13.7.1.m1.1.1" xref="S4.T2.13.7.1.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.13.7.1.m1.1.1.2" xref="S4.T2.13.7.1.m1.1.1.2.cmml">80.0</mn><mo mathsize="80%" id="S4.T2.13.7.1.m1.1.1.1" xref="S4.T2.13.7.1.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.13.7.1.m1.1.1.3" xref="S4.T2.13.7.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.13.7.1.m1.1b"><apply id="S4.T2.13.7.1.m1.1.1.cmml" xref="S4.T2.13.7.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.13.7.1.m1.1.1.1.cmml" xref="S4.T2.13.7.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.13.7.1.m1.1.1.2.cmml" xref="S4.T2.13.7.1.m1.1.1.2">80.0</cn><cn type="float" id="S4.T2.13.7.1.m1.1.1.3.cmml" xref="S4.T2.13.7.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.7.1.m1.1c">80.0\pm 0.1</annotation></semantics></math></td>
<td id="S4.T2.14.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.14.8.2.m1.1" class="ltx_Math" alttext="81.0\pm 0.1" display="inline"><semantics id="S4.T2.14.8.2.m1.1a"><mrow id="S4.T2.14.8.2.m1.1.1" xref="S4.T2.14.8.2.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.14.8.2.m1.1.1.2" xref="S4.T2.14.8.2.m1.1.1.2.cmml">81.0</mn><mo mathsize="80%" id="S4.T2.14.8.2.m1.1.1.1" xref="S4.T2.14.8.2.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.14.8.2.m1.1.1.3" xref="S4.T2.14.8.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.14.8.2.m1.1b"><apply id="S4.T2.14.8.2.m1.1.1.cmml" xref="S4.T2.14.8.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.14.8.2.m1.1.1.1.cmml" xref="S4.T2.14.8.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.14.8.2.m1.1.1.2.cmml" xref="S4.T2.14.8.2.m1.1.1.2">81.0</cn><cn type="float" id="S4.T2.14.8.2.m1.1.1.3.cmml" xref="S4.T2.14.8.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.8.2.m1.1c">81.0\pm 0.1</annotation></semantics></math></td>
<td id="S4.T2.15.9.3" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.15.9.3.m1.1" class="ltx_Math" alttext="97.5\pm 0.02" display="inline"><semantics id="S4.T2.15.9.3.m1.1a"><mrow id="S4.T2.15.9.3.m1.1.1" xref="S4.T2.15.9.3.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.15.9.3.m1.1.1.2" xref="S4.T2.15.9.3.m1.1.1.2.cmml">97.5</mn><mo mathsize="80%" id="S4.T2.15.9.3.m1.1.1.1" xref="S4.T2.15.9.3.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.15.9.3.m1.1.1.3" xref="S4.T2.15.9.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.15.9.3.m1.1b"><apply id="S4.T2.15.9.3.m1.1.1.cmml" xref="S4.T2.15.9.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.15.9.3.m1.1.1.1.cmml" xref="S4.T2.15.9.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.15.9.3.m1.1.1.2.cmml" xref="S4.T2.15.9.3.m1.1.1.2">97.5</cn><cn type="float" id="S4.T2.15.9.3.m1.1.1.3.cmml" xref="S4.T2.15.9.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.9.3.m1.1c">97.5\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.16.10.4" class="ltx_td ltx_align_center" style="padding-left:4.2pt;padding-right:4.2pt;"><math id="S4.T2.16.10.4.m1.1" class="ltx_Math" alttext="97.4\pm 0.03" display="inline"><semantics id="S4.T2.16.10.4.m1.1a"><mrow id="S4.T2.16.10.4.m1.1.1" xref="S4.T2.16.10.4.m1.1.1.cmml"><mn mathsize="80%" id="S4.T2.16.10.4.m1.1.1.2" xref="S4.T2.16.10.4.m1.1.1.2.cmml">97.4</mn><mo mathsize="80%" id="S4.T2.16.10.4.m1.1.1.1" xref="S4.T2.16.10.4.m1.1.1.1.cmml">±</mo><mn mathsize="80%" id="S4.T2.16.10.4.m1.1.1.3" xref="S4.T2.16.10.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.16.10.4.m1.1b"><apply id="S4.T2.16.10.4.m1.1.1.cmml" xref="S4.T2.16.10.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.16.10.4.m1.1.1.1.cmml" xref="S4.T2.16.10.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.16.10.4.m1.1.1.2.cmml" xref="S4.T2.16.10.4.m1.1.1.2">97.4</cn><cn type="float" id="S4.T2.16.10.4.m1.1.1.3.cmml" xref="S4.T2.16.10.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.10.4.m1.1c">97.4\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.16.12" class="ltx_tr">
<td id="S4.T2.16.12.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="S4.T2.16.12.2" class="ltx_td" style="padding-left:4.2pt;padding-right:4.2pt;"></td>
<td id="S4.T2.16.12.3" class="ltx_td" style="padding-left:4.2pt;padding-right:4.2pt;"></td>
<td id="S4.T2.16.12.4" class="ltx_td" style="padding-left:4.2pt;padding-right:4.2pt;"></td>
<td id="S4.T2.16.12.5" class="ltx_td" style="padding-left:4.2pt;padding-right:4.2pt;"></td>
</tr>
</table>
</figure>
<div id="S4.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p"><span id="S4.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_bold">1. Catastrophic forgetting across heterogeneous devices:</span>
CNNs often work worse on out-of-distribution data. This phenomenon is especially severe in the serial FL method CWT. Due to its sequential and serial training strategy, training CNNs in a CWT paradigm usually results in catastrophic forgetting on non-IID data partitions: the model’s performance on previous clients abruptly degrades after a few updates on a new client with a different data distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. This results in poorer and slower convergence which is undesirable in FL. Similar forgetting issues have also been found in the transfer learning literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.4" class="ltx_p">We evaluate CWT on Split-3 of the CIFAR-<math id="S4.SS3.SSS1.p3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS1.p3.1.m1.1a"><mn id="S4.SS3.SSS1.p3.1.m1.1.1" xref="S4.SS3.SSS1.p3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.1.m1.1b"><cn type="integer" id="S4.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.1.m1.1c">10</annotation></semantics></math> dataset to illustrate this catastrophic forgetting phenomenon. In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2 Results ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we plot the evolution of the prediction accuracy on the validation dataset of Client-3 (which shares the same data distribution as its training dataset) as more clients
are involved in CWT learning. When transferring a well-trained model on Client-3 to Client-4, the prediction accuracy on the previous Client-3 validation dataset degrades abruptly and dramatically (from <math id="S4.SS3.SSS1.p3.2.m2.1" class="ltx_Math" alttext="&gt;98\%" display="inline"><semantics id="S4.SS3.SSS1.p3.2.m2.1a"><mrow id="S4.SS3.SSS1.p3.2.m2.1.1" xref="S4.SS3.SSS1.p3.2.m2.1.1.cmml"><mi id="S4.SS3.SSS1.p3.2.m2.1.1.2" xref="S4.SS3.SSS1.p3.2.m2.1.1.2.cmml"></mi><mo id="S4.SS3.SSS1.p3.2.m2.1.1.1" xref="S4.SS3.SSS1.p3.2.m2.1.1.1.cmml">&gt;</mo><mrow id="S4.SS3.SSS1.p3.2.m2.1.1.3" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.cmml"><mn id="S4.SS3.SSS1.p3.2.m2.1.1.3.2" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.2.cmml">98</mn><mo id="S4.SS3.SSS1.p3.2.m2.1.1.3.1" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.2.m2.1b"><apply id="S4.SS3.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1"><gt id="S4.SS3.SSS1.p3.2.m2.1.1.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S4.SS3.SSS1.p3.2.m2.1.1.2.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.2">absent</csymbol><apply id="S4.SS3.SSS1.p3.2.m2.1.1.3.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p3.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.2">98</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.2.m2.1c">&gt;98\%</annotation></semantics></math> to <math id="S4.SS3.SSS1.p3.3.m3.1" class="ltx_Math" alttext="&lt;1\%" display="inline"><semantics id="S4.SS3.SSS1.p3.3.m3.1a"><mrow id="S4.SS3.SSS1.p3.3.m3.1.1" xref="S4.SS3.SSS1.p3.3.m3.1.1.cmml"><mi id="S4.SS3.SSS1.p3.3.m3.1.1.2" xref="S4.SS3.SSS1.p3.3.m3.1.1.2.cmml"></mi><mo id="S4.SS3.SSS1.p3.3.m3.1.1.1" xref="S4.SS3.SSS1.p3.3.m3.1.1.1.cmml">&lt;</mo><mrow id="S4.SS3.SSS1.p3.3.m3.1.1.3" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.cmml"><mn id="S4.SS3.SSS1.p3.3.m3.1.1.3.2" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.2.cmml">1</mn><mo id="S4.SS3.SSS1.p3.3.m3.1.1.3.1" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.3.m3.1b"><apply id="S4.SS3.SSS1.p3.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1"><lt id="S4.SS3.SSS1.p3.3.m3.1.1.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.1"></lt><csymbol cd="latexml" id="S4.SS3.SSS1.p3.3.m3.1.1.2.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.2">absent</csymbol><apply id="S4.SS3.SSS1.p3.3.m3.1.1.3.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p3.3.m3.1.1.3.2.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.3.m3.1c">&lt;1\%</annotation></semantics></math> accuracy).
However, the model trained with ViT as backbone (ViT(S)-CWT) is able to transfer knowledge from Client-3 to Client-4 while losing only small amounts of information on Client-3 (maintains accuracy at <math id="S4.SS3.SSS1.p3.4.m4.1" class="ltx_Math" alttext="98\%" display="inline"><semantics id="S4.SS3.SSS1.p3.4.m4.1a"><mrow id="S4.SS3.SSS1.p3.4.m4.1.1" xref="S4.SS3.SSS1.p3.4.m4.1.1.cmml"><mn id="S4.SS3.SSS1.p3.4.m4.1.1.2" xref="S4.SS3.SSS1.p3.4.m4.1.1.2.cmml">98</mn><mo id="S4.SS3.SSS1.p3.4.m4.1.1.1" xref="S4.SS3.SSS1.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.4.m4.1b"><apply id="S4.SS3.SSS1.p3.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.p3.4.m4.1.1.1.cmml" xref="S4.SS3.SSS1.p3.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p3.4.m4.1.1.2.cmml" xref="S4.SS3.SSS1.p3.4.m4.1.1.2">98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.4.m4.1c">98\%</annotation></semantics></math>). Therefore, ViTs generalize better to new data distributions without forgetting old ones.</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<p id="S4.SS3.SSS1.p4.1" class="ltx_p">We further compare ViT(S)-CWT with an optimization method specifically designed to alleviate catastrophic forgetting, EWC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> (using the implementation from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>). Serial training of CWT on Split-3 of CIFAR-<math id="S4.SS3.SSS1.p4.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS1.p4.1.m1.1a"><mn id="S4.SS3.SSS1.p4.1.m1.1.1" xref="S4.SS3.SSS1.p4.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.1.m1.1b"><cn type="integer" id="S4.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.1.m1.1c">10</annotation></semantics></math> can be considered as an incremental class learning task where each client contains an exclusive subset of classes in the dataset. Each client model shares the same classifier to a standardized union label space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. However, from Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2 Results ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, EWC barely solves the catastrophic forgetting problem on highly heterogeneous data partitions, which also matches the results reported in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. This experiment further demonstrates the effectiveness of ViT beyond optimization methods designed for FL.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.65.4.1" class="ltx_text" style="font-size:113%;">Table 3</span>: </span><span id="S4.T3.6.3" class="ltx_text" style="font-size:113%;"># transmitted message size ( # communication round <math id="S4.T3.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.4.1.m1.1b"><mo id="S4.T3.4.1.m1.1.1" xref="S4.T3.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.1.m1.1c"><times id="S4.T3.4.1.m1.1.1.cmml" xref="S4.T3.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.1.m1.1d">\times</annotation></semantics></math> # model parameters (M) ) required to reach target performance (<span id="S4.T3.6.3.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">best</span> and <span id="S4.T3.6.3.2" class="ltx_text ltx_font_bold" style="color:#0000FF;">second best</span>).
# model parameters of ViT(S) and ResNet(50) is <math id="S4.T3.5.2.m2.1" class="ltx_Math" alttext="21.7" display="inline"><semantics id="S4.T3.5.2.m2.1b"><mn id="S4.T3.5.2.m2.1.1" xref="S4.T3.5.2.m2.1.1.cmml">21.7</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.2.m2.1c"><cn type="float" id="S4.T3.5.2.m2.1.1.cmml" xref="S4.T3.5.2.m2.1.1">21.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.2.m2.1d">21.7</annotation></semantics></math>M and <math id="S4.T3.6.3.m3.1" class="ltx_Math" alttext="23.5" display="inline"><semantics id="S4.T3.6.3.m3.1b"><mn id="S4.T3.6.3.m3.1.1" xref="S4.T3.6.3.m3.1.1.cmml">23.5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.3.m3.1c"><cn type="float" id="S4.T3.6.3.m3.1.1.cmml" xref="S4.T3.6.3.m3.1.1">23.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.3.m3.1d">23.5</annotation></semantics></math>M, respectively.
ViTs converge faster especially on heterogeneous data splits, and can be combined with optimization-based methods (FedProx and FedAVG-Share) for even faster convergence.</span></figcaption>
<table id="S4.T3.54" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.54.49" class="ltx_tr">
<td id="S4.T3.54.49.1" class="ltx_td ltx_align_center">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T3.54.49.1.1" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S4.T3.54.49.2" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.54.49.3" class="ltx_td ltx_align_center ltx_border_r" colspan="2"><span id="S4.T3.54.49.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">CWT</span></td>
<td id="S4.T3.54.49.4" class="ltx_td ltx_align_center" colspan="6"><span id="S4.T3.54.49.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">FedAVG</span></td>
</tr>
<tr id="S4.T3.54.50" class="ltx_tr">
<td id="S4.T3.54.50.1" class="ltx_td"></td>
<td id="S4.T3.54.50.2" class="ltx_td ltx_border_r"></td>
<td id="S4.T3.54.50.3" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.3.1" class="ltx_text" style="font-size:80%;">R50</span></td>
<td id="S4.T3.54.50.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.54.50.4.1" class="ltx_text" style="font-size:80%;">ViT(S)</span></td>
<td id="S4.T3.54.50.5" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.5.1" class="ltx_text" style="font-size:80%;">R50</span></td>
<td id="S4.T3.54.50.6" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.6.1" class="ltx_text" style="font-size:80%;">R50-FedProx</span></td>
<td id="S4.T3.54.50.7" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.7.1" class="ltx_text" style="font-size:80%;">R50-Share</span></td>
<td id="S4.T3.54.50.8" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.8.1" class="ltx_text" style="font-size:80%;">ViT(S)</span></td>
<td id="S4.T3.54.50.9" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.9.1" class="ltx_text" style="font-size:80%;">ViT(S)-FedProx</span></td>
<td id="S4.T3.54.50.10" class="ltx_td ltx_align_center"><span id="S4.T3.54.50.10.1" class="ltx_text" style="font-size:80%;">ViT(S)-Share</span></td>
</tr>
<tr id="S4.T3.14.8" class="ltx_tr">
<td id="S4.T3.14.8.9" class="ltx_td ltx_align_center" rowspan="3">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T3.14.8.9.1" class="ltx_text" style="font-size:80%;">
</span><span id="S4.T3.14.8.9.2" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Retina</span>
</td>
<td id="S4.T3.14.8.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.14.8.10.1" class="ltx_text" style="font-size:80%;">Split-1</span></td>
<td id="S4.T3.7.1.1" class="ltx_td ltx_align_center"><span id="S4.T3.7.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">6 <math id="S4.T3.7.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.7.1.1.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.7.1.1.1.m1.1.1" xref="S4.T3.7.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.1.1.1.m1.1b"><times id="S4.T3.7.1.1.1.m1.1.1.cmml" xref="S4.T3.7.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.1.1.1.m1.1c">\times</annotation></semantics></math> 23.5</span></td>
<td id="S4.T3.8.2.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.8.2.2.1" class="ltx_text" style="font-size:80%;">9 </span><math id="S4.T3.8.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.8.2.2.m1.1a"><mo mathsize="80%" id="S4.T3.8.2.2.m1.1.1" xref="S4.T3.8.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.2.2.m1.1b"><times id="S4.T3.8.2.2.m1.1.1.cmml" xref="S4.T3.8.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.2.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.8.2.2.2" class="ltx_text" style="font-size:80%;"> 21.7</span>
</td>
<td id="S4.T3.9.3.3" class="ltx_td ltx_align_center">
<span id="S4.T3.9.3.3.1" class="ltx_text" style="font-size:80%;">12 </span><math id="S4.T3.9.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.9.3.3.m1.1a"><mo mathsize="80%" id="S4.T3.9.3.3.m1.1.1" xref="S4.T3.9.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.9.3.3.m1.1b"><times id="S4.T3.9.3.3.m1.1.1.cmml" xref="S4.T3.9.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.3.3.m1.1c">\times</annotation></semantics></math><span id="S4.T3.9.3.3.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.10.4.4" class="ltx_td ltx_align_center">
<span id="S4.T3.10.4.4.1" class="ltx_text" style="font-size:80%;">7 </span><math id="S4.T3.10.4.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.10.4.4.m1.1a"><mo mathsize="80%" id="S4.T3.10.4.4.m1.1.1" xref="S4.T3.10.4.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.10.4.4.m1.1b"><times id="S4.T3.10.4.4.m1.1.1.cmml" xref="S4.T3.10.4.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.4.4.m1.1c">\times</annotation></semantics></math><span id="S4.T3.10.4.4.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.11.5.5" class="ltx_td ltx_align_center">
<span id="S4.T3.11.5.5.1" class="ltx_text" style="font-size:80%;">11 </span><math id="S4.T3.11.5.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.11.5.5.m1.1a"><mo mathsize="80%" id="S4.T3.11.5.5.m1.1.1" xref="S4.T3.11.5.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.11.5.5.m1.1b"><times id="S4.T3.11.5.5.m1.1.1.cmml" xref="S4.T3.11.5.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.5.5.m1.1c">\times</annotation></semantics></math><span id="S4.T3.11.5.5.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.12.6.6" class="ltx_td ltx_align_center">
<span id="S4.T3.12.6.6.1" class="ltx_text" style="font-size:80%;">11 </span><math id="S4.T3.12.6.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.12.6.6.m1.1a"><mo mathsize="80%" id="S4.T3.12.6.6.m1.1.1" xref="S4.T3.12.6.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.12.6.6.m1.1b"><times id="S4.T3.12.6.6.m1.1.1.cmml" xref="S4.T3.12.6.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.6.6.m1.1c">\times</annotation></semantics></math><span id="S4.T3.12.6.6.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
<td id="S4.T3.13.7.7" class="ltx_td ltx_align_center"><span id="S4.T3.13.7.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">4 <math id="S4.T3.13.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.13.7.7.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.13.7.7.1.m1.1.1" xref="S4.T3.13.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.13.7.7.1.m1.1b"><times id="S4.T3.13.7.7.1.m1.1.1.cmml" xref="S4.T3.13.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.7.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.14.8.8" class="ltx_td ltx_align_center">
<span id="S4.T3.14.8.8.1" class="ltx_text" style="font-size:80%;">7 </span><math id="S4.T3.14.8.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.14.8.8.m1.1a"><mo mathsize="80%" id="S4.T3.14.8.8.m1.1.1" xref="S4.T3.14.8.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.14.8.8.m1.1b"><times id="S4.T3.14.8.8.m1.1.1.cmml" xref="S4.T3.14.8.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.8.8.m1.1c">\times</annotation></semantics></math><span id="S4.T3.14.8.8.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
</tr>
<tr id="S4.T3.21.15" class="ltx_tr">
<td id="S4.T3.21.15.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.21.15.8.1" class="ltx_text" style="font-size:80%;">Split-2</span></td>
<td id="S4.T3.15.9.1" class="ltx_td ltx_align_center">
<span id="S4.T3.15.9.1.1" class="ltx_text" style="font-size:80%;">72 </span><math id="S4.T3.15.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.15.9.1.m1.1a"><mo mathsize="80%" id="S4.T3.15.9.1.m1.1.1" xref="S4.T3.15.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.15.9.1.m1.1b"><times id="S4.T3.15.9.1.m1.1.1.cmml" xref="S4.T3.15.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.9.1.m1.1c">\times</annotation></semantics></math><span id="S4.T3.15.9.1.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.16.10.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.16.10.2.1" class="ltx_text" style="font-size:80%;">55 </span><math id="S4.T3.16.10.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.16.10.2.m1.1a"><mo mathsize="80%" id="S4.T3.16.10.2.m1.1.1" xref="S4.T3.16.10.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.16.10.2.m1.1b"><times id="S4.T3.16.10.2.m1.1.1.cmml" xref="S4.T3.16.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.10.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.16.10.2.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
<td id="S4.T3.17.11.3" class="ltx_td ltx_align_center"><math id="S4.T3.17.11.3.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.17.11.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.17.11.3.m1.1.1" xref="S4.T3.17.11.3.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.17.11.3.m1.1b"><infinity id="S4.T3.17.11.3.m1.1.1.cmml" xref="S4.T3.17.11.3.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.11.3.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.18.12.4" class="ltx_td ltx_align_center"><math id="S4.T3.18.12.4.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.18.12.4.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.18.12.4.m1.1.1" xref="S4.T3.18.12.4.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.18.12.4.m1.1b"><infinity id="S4.T3.18.12.4.m1.1.1.cmml" xref="S4.T3.18.12.4.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.12.4.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.21.15.9" class="ltx_td ltx_align_center"><span id="S4.T3.21.15.9.1" class="ltx_text" style="font-size:80%;">85</span></td>
<td id="S4.T3.19.13.5" class="ltx_td ltx_align_center">
<span id="S4.T3.19.13.5.1" class="ltx_text" style="font-size:80%;">15 </span><math id="S4.T3.19.13.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.19.13.5.m1.1a"><mo mathsize="80%" id="S4.T3.19.13.5.m1.1.1" xref="S4.T3.19.13.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.19.13.5.m1.1b"><times id="S4.T3.19.13.5.m1.1.1.cmml" xref="S4.T3.19.13.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.13.5.m1.1c">\times</annotation></semantics></math><span id="S4.T3.19.13.5.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
<td id="S4.T3.20.14.6" class="ltx_td ltx_align_center"><span id="S4.T3.20.14.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">12 <math id="S4.T3.20.14.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.20.14.6.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.20.14.6.1.m1.1.1" xref="S4.T3.20.14.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.20.14.6.1.m1.1b"><times id="S4.T3.20.14.6.1.m1.1.1.cmml" xref="S4.T3.20.14.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.14.6.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.21.15.7" class="ltx_td ltx_align_center"><span id="S4.T3.21.15.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">13 <math id="S4.T3.21.15.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.21.15.7.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.21.15.7.1.m1.1.1" xref="S4.T3.21.15.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.21.15.7.1.m1.1b"><times id="S4.T3.21.15.7.1.m1.1.1.cmml" xref="S4.T3.21.15.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.15.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
</tr>
<tr id="S4.T3.29.23" class="ltx_tr">
<td id="S4.T3.29.23.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.29.23.9.1" class="ltx_text" style="font-size:80%;">Split-3</span></td>
<td id="S4.T3.22.16.1" class="ltx_td ltx_align_center"><math id="S4.T3.22.16.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.22.16.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.22.16.1.m1.1.1" xref="S4.T3.22.16.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.22.16.1.m1.1b"><infinity id="S4.T3.22.16.1.m1.1.1.cmml" xref="S4.T3.22.16.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.16.1.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.23.17.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.23.17.2.1" class="ltx_text" style="font-size:80%;">58 </span><math id="S4.T3.23.17.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.23.17.2.m1.1a"><mo mathsize="80%" id="S4.T3.23.17.2.m1.1.1" xref="S4.T3.23.17.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.23.17.2.m1.1b"><times id="S4.T3.23.17.2.m1.1.1.cmml" xref="S4.T3.23.17.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.17.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.23.17.2.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
<td id="S4.T3.24.18.3" class="ltx_td ltx_align_center"><math id="S4.T3.24.18.3.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.24.18.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.24.18.3.m1.1.1" xref="S4.T3.24.18.3.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.24.18.3.m1.1b"><infinity id="S4.T3.24.18.3.m1.1.1.cmml" xref="S4.T3.24.18.3.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.24.18.3.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.25.19.4" class="ltx_td ltx_align_center"><math id="S4.T3.25.19.4.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.25.19.4.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.25.19.4.m1.1.1" xref="S4.T3.25.19.4.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.25.19.4.m1.1b"><infinity id="S4.T3.25.19.4.m1.1.1.cmml" xref="S4.T3.25.19.4.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.19.4.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.26.20.5" class="ltx_td ltx_align_center"><math id="S4.T3.26.20.5.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.26.20.5.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.26.20.5.m1.1.1" xref="S4.T3.26.20.5.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.26.20.5.m1.1b"><infinity id="S4.T3.26.20.5.m1.1.1.cmml" xref="S4.T3.26.20.5.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.26.20.5.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.27.21.6" class="ltx_td ltx_align_center"><span id="S4.T3.27.21.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">15 <math id="S4.T3.27.21.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.27.21.6.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.27.21.6.1.m1.1.1" xref="S4.T3.27.21.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.27.21.6.1.m1.1b"><times id="S4.T3.27.21.6.1.m1.1.1.cmml" xref="S4.T3.27.21.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.21.6.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.28.22.7" class="ltx_td ltx_align_center"><span id="S4.T3.28.22.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">12 <math id="S4.T3.28.22.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.28.22.7.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.28.22.7.1.m1.1.1" xref="S4.T3.28.22.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.28.22.7.1.m1.1b"><times id="S4.T3.28.22.7.1.m1.1.1.cmml" xref="S4.T3.28.22.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.22.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.29.23.8" class="ltx_td ltx_align_center">
<span id="S4.T3.29.23.8.1" class="ltx_text" style="font-size:80%;">16 </span><math id="S4.T3.29.23.8.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.29.23.8.m1.1a"><mo mathsize="80%" id="S4.T3.29.23.8.m1.1.1" xref="S4.T3.29.23.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.29.23.8.m1.1b"><times id="S4.T3.29.23.8.m1.1.1.cmml" xref="S4.T3.29.23.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.23.8.m1.1c">\times</annotation></semantics></math><span id="S4.T3.29.23.8.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
</tr>
<tr id="S4.T3.38.32" class="ltx_tr">
<td id="S4.T3.30.24.1" class="ltx_td ltx_align_center" rowspan="3">
<span class="ltx_rule" style="width:100%;height:0.4pt;background:black;display:inline-block;"> </span><span id="S4.T3.30.24.1.2" class="ltx_text" style="font-size:80%;">
</span><span id="S4.T3.30.24.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">CIFAR-<math id="S4.T3.30.24.1.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T3.30.24.1.1.1.m1.1a"><mn id="S4.T3.30.24.1.1.1.m1.1.1" xref="S4.T3.30.24.1.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.30.24.1.1.1.m1.1b"><cn type="integer" id="S4.T3.30.24.1.1.1.m1.1.1.cmml" xref="S4.T3.30.24.1.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.24.1.1.1.m1.1c">10</annotation></semantics></math></span>
</td>
<td id="S4.T3.38.32.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.38.32.10.1" class="ltx_text" style="font-size:80%;">Split-1</span></td>
<td id="S4.T3.31.25.2" class="ltx_td ltx_align_center">
<span id="S4.T3.31.25.2.1" class="ltx_text" style="font-size:80%;">2 </span><math id="S4.T3.31.25.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.31.25.2.m1.1a"><mo mathsize="80%" id="S4.T3.31.25.2.m1.1.1" xref="S4.T3.31.25.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.31.25.2.m1.1b"><times id="S4.T3.31.25.2.m1.1.1.cmml" xref="S4.T3.31.25.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.31.25.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.31.25.2.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.32.26.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.32.26.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.32.26.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.32.26.3.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.32.26.3.1.m1.1.1" xref="S4.T3.32.26.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.32.26.3.1.m1.1b"><times id="S4.T3.32.26.3.1.m1.1.1.cmml" xref="S4.T3.32.26.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.32.26.3.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.33.27.4" class="ltx_td ltx_align_center">
<span id="S4.T3.33.27.4.1" class="ltx_text" style="font-size:80%;">4</span><math id="S4.T3.33.27.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.33.27.4.m1.1a"><mo mathsize="80%" id="S4.T3.33.27.4.m1.1.1" xref="S4.T3.33.27.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.33.27.4.m1.1b"><times id="S4.T3.33.27.4.m1.1.1.cmml" xref="S4.T3.33.27.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.33.27.4.m1.1c">\times</annotation></semantics></math><span id="S4.T3.33.27.4.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.34.28.5" class="ltx_td ltx_align_center">
<span id="S4.T3.34.28.5.1" class="ltx_text" style="font-size:80%;">4 </span><math id="S4.T3.34.28.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.34.28.5.m1.1a"><mo mathsize="80%" id="S4.T3.34.28.5.m1.1.1" xref="S4.T3.34.28.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.34.28.5.m1.1b"><times id="S4.T3.34.28.5.m1.1.1.cmml" xref="S4.T3.34.28.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.34.28.5.m1.1c">\times</annotation></semantics></math><span id="S4.T3.34.28.5.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.35.29.6" class="ltx_td ltx_align_center">
<span id="S4.T3.35.29.6.1" class="ltx_text" style="font-size:80%;">5 </span><math id="S4.T3.35.29.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.35.29.6.m1.1a"><mo mathsize="80%" id="S4.T3.35.29.6.m1.1.1" xref="S4.T3.35.29.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.35.29.6.m1.1b"><times id="S4.T3.35.29.6.m1.1.1.cmml" xref="S4.T3.35.29.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.35.29.6.m1.1c">\times</annotation></semantics></math><span id="S4.T3.35.29.6.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.36.30.7" class="ltx_td ltx_align_center"><span id="S4.T3.36.30.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.36.30.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.36.30.7.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.36.30.7.1.m1.1.1" xref="S4.T3.36.30.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.36.30.7.1.m1.1b"><times id="S4.T3.36.30.7.1.m1.1.1.cmml" xref="S4.T3.36.30.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.36.30.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.37.31.8" class="ltx_td ltx_align_center"><span id="S4.T3.37.31.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.37.31.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.37.31.8.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.37.31.8.1.m1.1.1" xref="S4.T3.37.31.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.37.31.8.1.m1.1b"><times id="S4.T3.37.31.8.1.m1.1.1.cmml" xref="S4.T3.37.31.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.37.31.8.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.38.32.9" class="ltx_td ltx_align_center"><span id="S4.T3.38.32.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.38.32.9.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.38.32.9.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.38.32.9.1.m1.1.1" xref="S4.T3.38.32.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.38.32.9.1.m1.1b"><times id="S4.T3.38.32.9.1.m1.1.1.cmml" xref="S4.T3.38.32.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.38.32.9.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
</tr>
<tr id="S4.T3.46.40" class="ltx_tr">
<td id="S4.T3.46.40.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.46.40.9.1" class="ltx_text" style="font-size:80%;">Split-2</span></td>
<td id="S4.T3.39.33.1" class="ltx_td ltx_align_center"><math id="S4.T3.39.33.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.39.33.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.39.33.1.m1.1.1" xref="S4.T3.39.33.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.39.33.1.m1.1b"><infinity id="S4.T3.39.33.1.m1.1.1.cmml" xref="S4.T3.39.33.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.39.33.1.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.40.34.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.40.34.2.1" class="ltx_text" style="font-size:80%;">34 </span><math id="S4.T3.40.34.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.40.34.2.m1.1a"><mo mathsize="80%" id="S4.T3.40.34.2.m1.1.1" xref="S4.T3.40.34.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.40.34.2.m1.1b"><times id="S4.T3.40.34.2.m1.1.1.cmml" xref="S4.T3.40.34.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.40.34.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.40.34.2.2" class="ltx_text" style="font-size:80%;"> 21.7</span>
</td>
<td id="S4.T3.41.35.3" class="ltx_td ltx_align_center">
<span id="S4.T3.41.35.3.1" class="ltx_text" style="font-size:80%;">19 </span><math id="S4.T3.41.35.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.41.35.3.m1.1a"><mo mathsize="80%" id="S4.T3.41.35.3.m1.1.1" xref="S4.T3.41.35.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.41.35.3.m1.1b"><times id="S4.T3.41.35.3.m1.1.1.cmml" xref="S4.T3.41.35.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.41.35.3.m1.1c">\times</annotation></semantics></math><span id="S4.T3.41.35.3.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.42.36.4" class="ltx_td ltx_align_center">
<span id="S4.T3.42.36.4.1" class="ltx_text" style="font-size:80%;">17 </span><math id="S4.T3.42.36.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.42.36.4.m1.1a"><mo mathsize="80%" id="S4.T3.42.36.4.m1.1.1" xref="S4.T3.42.36.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.42.36.4.m1.1b"><times id="S4.T3.42.36.4.m1.1.1.cmml" xref="S4.T3.42.36.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.42.36.4.m1.1c">\times</annotation></semantics></math><span id="S4.T3.42.36.4.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.43.37.5" class="ltx_td ltx_align_center">
<span id="S4.T3.43.37.5.1" class="ltx_text" style="font-size:80%;">9 </span><math id="S4.T3.43.37.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.43.37.5.m1.1a"><mo mathsize="80%" id="S4.T3.43.37.5.m1.1.1" xref="S4.T3.43.37.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.43.37.5.m1.1b"><times id="S4.T3.43.37.5.m1.1.1.cmml" xref="S4.T3.43.37.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.43.37.5.m1.1c">\times</annotation></semantics></math><span id="S4.T3.43.37.5.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.44.38.6" class="ltx_td ltx_align_center"><span id="S4.T3.44.38.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">2 <math id="S4.T3.44.38.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.44.38.6.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.44.38.6.1.m1.1.1" xref="S4.T3.44.38.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.44.38.6.1.m1.1b"><times id="S4.T3.44.38.6.1.m1.1.1.cmml" xref="S4.T3.44.38.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.44.38.6.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.45.39.7" class="ltx_td ltx_align_center"><span id="S4.T3.45.39.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">2 <math id="S4.T3.45.39.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.45.39.7.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.45.39.7.1.m1.1.1" xref="S4.T3.45.39.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.45.39.7.1.m1.1b"><times id="S4.T3.45.39.7.1.m1.1.1.cmml" xref="S4.T3.45.39.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.45.39.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.46.40.8" class="ltx_td ltx_align_center"><span id="S4.T3.46.40.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.46.40.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.46.40.8.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.46.40.8.1.m1.1.1" xref="S4.T3.46.40.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.46.40.8.1.m1.1b"><times id="S4.T3.46.40.8.1.m1.1.1.cmml" xref="S4.T3.46.40.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.46.40.8.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
</tr>
<tr id="S4.T3.54.48" class="ltx_tr">
<td id="S4.T3.54.48.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.54.48.9.1" class="ltx_text" style="font-size:80%;">Split-3</span></td>
<td id="S4.T3.47.41.1" class="ltx_td ltx_align_center"><math id="S4.T3.47.41.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.47.41.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.47.41.1.m1.1.1" xref="S4.T3.47.41.1.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.47.41.1.m1.1b"><infinity id="S4.T3.47.41.1.m1.1.1.cmml" xref="S4.T3.47.41.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.47.41.1.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.48.42.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.48.42.2.1" class="ltx_text" style="font-size:80%;">85 </span><math id="S4.T3.48.42.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.48.42.2.m1.1a"><mo mathsize="80%" id="S4.T3.48.42.2.m1.1.1" xref="S4.T3.48.42.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.48.42.2.m1.1b"><times id="S4.T3.48.42.2.m1.1.1.cmml" xref="S4.T3.48.42.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.48.42.2.m1.1c">\times</annotation></semantics></math><span id="S4.T3.48.42.2.2" class="ltx_text" style="font-size:80%;"> 21.7</span>
</td>
<td id="S4.T3.49.43.3" class="ltx_td ltx_align_center"><math id="S4.T3.49.43.3.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.49.43.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.49.43.3.m1.1.1" xref="S4.T3.49.43.3.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.49.43.3.m1.1b"><infinity id="S4.T3.49.43.3.m1.1.1.cmml" xref="S4.T3.49.43.3.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.49.43.3.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.50.44.4" class="ltx_td ltx_align_center"><math id="S4.T3.50.44.4.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T3.50.44.4.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.50.44.4.m1.1.1" xref="S4.T3.50.44.4.m1.1.1.cmml">∞</mi><annotation-xml encoding="MathML-Content" id="S4.T3.50.44.4.m1.1b"><infinity id="S4.T3.50.44.4.m1.1.1.cmml" xref="S4.T3.50.44.4.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.50.44.4.m1.1c">\infty</annotation></semantics></math></td>
<td id="S4.T3.51.45.5" class="ltx_td ltx_align_center">
<span id="S4.T3.51.45.5.1" class="ltx_text" style="font-size:80%;">41 </span><math id="S4.T3.51.45.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.51.45.5.m1.1a"><mo mathsize="80%" id="S4.T3.51.45.5.m1.1.1" xref="S4.T3.51.45.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.51.45.5.m1.1b"><times id="S4.T3.51.45.5.m1.1.1.cmml" xref="S4.T3.51.45.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.51.45.5.m1.1c">\times</annotation></semantics></math><span id="S4.T3.51.45.5.2" class="ltx_text" style="font-size:80%;"> 23.5</span>
</td>
<td id="S4.T3.52.46.6" class="ltx_td ltx_align_center">
<span id="S4.T3.52.46.6.1" class="ltx_text" style="font-size:80%;">4 </span><math id="S4.T3.52.46.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.52.46.6.m1.1a"><mo mathsize="80%" id="S4.T3.52.46.6.m1.1.1" xref="S4.T3.52.46.6.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.52.46.6.m1.1b"><times id="S4.T3.52.46.6.m1.1.1.cmml" xref="S4.T3.52.46.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.52.46.6.m1.1c">\times</annotation></semantics></math><span id="S4.T3.52.46.6.2" class="ltx_text" style="font-size:80%;"> 21.4</span>
</td>
<td id="S4.T3.53.47.7" class="ltx_td ltx_align_center"><span id="S4.T3.53.47.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#0000FF;">3 <math id="S4.T3.53.47.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.53.47.7.1.m1.1a"><mo mathcolor="#0000FF" id="S4.T3.53.47.7.1.m1.1.1" xref="S4.T3.53.47.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.53.47.7.1.m1.1b"><times id="S4.T3.53.47.7.1.m1.1.1.cmml" xref="S4.T3.53.47.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.53.47.7.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
<td id="S4.T3.54.48.8" class="ltx_td ltx_align_center"><span id="S4.T3.54.48.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;color:#E62D2D;">1 <math id="S4.T3.54.48.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.54.48.8.1.m1.1a"><mo mathcolor="#E62D2D" id="S4.T3.54.48.8.1.m1.1.1" xref="S4.T3.54.48.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T3.54.48.8.1.m1.1b"><times id="S4.T3.54.48.8.1.m1.1.1.cmml" xref="S4.T3.54.48.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.54.48.8.1.m1.1c">\times</annotation></semantics></math> 21.4</span></td>
</tr>
<tr id="S4.T3.54.51" class="ltx_tr">
<td id="S4.T3.54.51.1" class="ltx_td ltx_align_center"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="S4.T3.54.51.2" class="ltx_td"></td>
<td id="S4.T3.54.51.3" class="ltx_td"></td>
<td id="S4.T3.54.51.4" class="ltx_td"></td>
<td id="S4.T3.54.51.5" class="ltx_td"></td>
<td id="S4.T3.54.51.6" class="ltx_td"></td>
<td id="S4.T3.54.51.7" class="ltx_td"></td>
<td id="S4.T3.54.51.8" class="ltx_td"></td>
<td id="S4.T3.54.51.9" class="ltx_td"></td>
<td id="S4.T3.54.51.10" class="ltx_td"></td>
</tr>
</table>
</figure>
<figure id="S4.F6" class="ltx_figure">
<table id="S4.F6.6.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.F6.2.2.2" class="ltx_tr">
<td id="S4.F6.2.2.2.3" class="ltx_td ltx_align_center">
  <span id="S4.F6.2.2.2.3.1" class="ltx_text" style="font-size:70%;">Split 2, KS-0.49 (Retina)</span>
</td>
<td id="S4.F6.2.2.2.4" class="ltx_td ltx_align_center"> <span id="S4.F6.2.2.2.4.1" class="ltx_text" style="font-size:70%;">Split 3, KS-0.57 (Retina)</span>
</td>
<td id="S4.F6.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.F6.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Split 3, KS-0.65 (CIFAR-<math id="S4.F6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F6.1.1.1.1.1.m1.1a"><mn id="S4.F6.1.1.1.1.1.m1.1.1" xref="S4.F6.1.1.1.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F6.1.1.1.1.1.m1.1b"><cn type="integer" id="S4.F6.1.1.1.1.1.m1.1.1.cmml" xref="S4.F6.1.1.1.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.1.1.1.1.1.m1.1c">10</annotation></semantics></math>)</span></td>
<td id="S4.F6.2.2.2.2" class="ltx_td ltx_align_center"><span id="S4.F6.2.2.2.2.1" class="ltx_text" style="font-size:70%;">Split 3, KS-1 (CIFAR-<math id="S4.F6.2.2.2.2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F6.2.2.2.2.1.m1.1a"><mn id="S4.F6.2.2.2.2.1.m1.1.1" xref="S4.F6.2.2.2.2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F6.2.2.2.2.1.m1.1b"><cn type="integer" id="S4.F6.2.2.2.2.1.m1.1.1.cmml" xref="S4.F6.2.2.2.2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.2.2.2.2.1.m1.1c">10</annotation></semantics></math>)</span></td>
</tr>
<tr id="S4.F6.6.6.6" class="ltx_tr">
<td id="S4.F6.3.3.3.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_Split_2_ViT_Comb.png" id="S4.F6.3.3.3.1.g1" class="ltx_graphics ltx_img_square" width="147" height="123" alt="Refer to caption"></td>
<td id="S4.F6.4.4.4.2" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Retina_Split_3_ViT_Comb.png" id="S4.F6.4.4.4.2.g1" class="ltx_graphics ltx_img_square" width="135" height="124" alt="Refer to caption">
</td>
<td id="S4.F6.5.5.5.3" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Cifar10_Split_2_ViT_Comb.png" id="S4.F6.5.5.5.3.g1" class="ltx_graphics ltx_img_square" width="135" height="119" alt="Refer to caption">
</td>
<td id="S4.F6.6.6.6.4" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Cifar10_Split_3_ViT_Comb.png" id="S4.F6.6.6.6.4.g1" class="ltx_graphics ltx_img_square" width="135" height="119" alt="Refer to caption">
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.8.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.9.2" class="ltx_text" style="font-size:90%;">Test set accuracy versus communication rounds on ViT(S)-FedAVG and their combination with existing FL methods FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. Vision Transformers can be used in conjunction with existing optimization based FL methods to further improve convergence speed and reach target performance with fewer communication rounds.</span></figcaption>
</figure>
<div id="S4.SS3.SSS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS3.SSS1.p5.1" class="ltx_p"><span id="S4.SS3.SSS1.p5.1.1" class="ltx_text ltx_font_bold">2. Generalization of <span id="S4.SS3.SSS1.p5.1.1.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> on real-world federated datasets:</span> A well-trained federated model should perform well on out-of-distribution test datasets of other unseen clients. To test the generalizability of Transformers, we apply it to a real-world federated CelebA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> and compare it to the ResNet counterparts, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. We report the test accuracies of models trained using different FL methods on the union of the test data from all local clients in Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Results ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Our <span id="S4.SS3.SSS1.p5.1.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span> approach outperforms state-of-the-art FL methods, and also reduces variance. This shows that Transformers learn a better global model than their CNNs counterparts.</p>
</div>
<div id="S4.SS3.SSS1.p6" class="ltx_para ltx_noindent">
<p id="S4.SS3.SSS1.p6.9" class="ltx_p"><span id="S4.SS3.SSS1.p6.9.1" class="ltx_text ltx_font_bold">3. Generalization of <span id="S4.SS3.SSS1.p6.9.1.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> on extreme large-scale setting:</span> To validate the effectiveness of <span id="S4.SS3.SSS1.p6.9.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span> on a more large-scale real-world distributed learning setting where thousands of clients are involved, we further apply different FL methods to an extreme edge case situation on both Retina and CIFAR-<math id="S4.SS3.SSS1.p6.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS1.p6.1.m1.1a"><mn id="S4.SS3.SSS1.p6.1.m1.1.1" xref="S4.SS3.SSS1.p6.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.1.m1.1b"><cn type="integer" id="S4.SS3.SSS1.p6.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p6.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.1.m1.1c">10</annotation></semantics></math> dataset. The edge case here is defined as one client holding <span id="S4.SS3.SSS1.p6.9.3" class="ltx_text ltx_font_italic">only one</span> data sample, which is quite common in healthcare where the patient holds only one data sample belonging to themselves. This results in an extremely large number of heterogeneous clients: <math id="S4.SS3.SSS1.p6.2.m2.2" class="ltx_Math" alttext="6,000" display="inline"><semantics id="S4.SS3.SSS1.p6.2.m2.2a"><mrow id="S4.SS3.SSS1.p6.2.m2.2.3.2" xref="S4.SS3.SSS1.p6.2.m2.2.3.1.cmml"><mn id="S4.SS3.SSS1.p6.2.m2.1.1" xref="S4.SS3.SSS1.p6.2.m2.1.1.cmml">6</mn><mo id="S4.SS3.SSS1.p6.2.m2.2.3.2.1" xref="S4.SS3.SSS1.p6.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS3.SSS1.p6.2.m2.2.2" xref="S4.SS3.SSS1.p6.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.2.m2.2b"><list id="S4.SS3.SSS1.p6.2.m2.2.3.1.cmml" xref="S4.SS3.SSS1.p6.2.m2.2.3.2"><cn type="integer" id="S4.SS3.SSS1.p6.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p6.2.m2.1.1">6</cn><cn type="integer" id="S4.SS3.SSS1.p6.2.m2.2.2.cmml" xref="S4.SS3.SSS1.p6.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.2.m2.2c">6,000</annotation></semantics></math> for Retina and <math id="S4.SS3.SSS1.p6.3.m3.2" class="ltx_Math" alttext="45,000" display="inline"><semantics id="S4.SS3.SSS1.p6.3.m3.2a"><mrow id="S4.SS3.SSS1.p6.3.m3.2.3.2" xref="S4.SS3.SSS1.p6.3.m3.2.3.1.cmml"><mn id="S4.SS3.SSS1.p6.3.m3.1.1" xref="S4.SS3.SSS1.p6.3.m3.1.1.cmml">45</mn><mo id="S4.SS3.SSS1.p6.3.m3.2.3.2.1" xref="S4.SS3.SSS1.p6.3.m3.2.3.1.cmml">,</mo><mn id="S4.SS3.SSS1.p6.3.m3.2.2" xref="S4.SS3.SSS1.p6.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.3.m3.2b"><list id="S4.SS3.SSS1.p6.3.m3.2.3.1.cmml" xref="S4.SS3.SSS1.p6.3.m3.2.3.2"><cn type="integer" id="S4.SS3.SSS1.p6.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p6.3.m3.1.1">45</cn><cn type="integer" id="S4.SS3.SSS1.p6.3.m3.2.2.cmml" xref="S4.SS3.SSS1.p6.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.3.m3.2c">45,000</annotation></semantics></math> for CIFAR-<math id="S4.SS3.SSS1.p6.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS1.p6.4.m4.1a"><mn id="S4.SS3.SSS1.p6.4.m4.1.1" xref="S4.SS3.SSS1.p6.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.4.m4.1b"><cn type="integer" id="S4.SS3.SSS1.p6.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p6.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.4.m4.1c">10</annotation></semantics></math>. From Table <a href="#S4.T2" title="Table 2 ‣ 4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, ViTs still learn a promising global model on this extremely heterogeneous edge case setting, significantly outperforming ResNet models (from <math id="S4.SS3.SSS1.p6.5.m5.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S4.SS3.SSS1.p6.5.m5.1a"><mrow id="S4.SS3.SSS1.p6.5.m5.1.1" xref="S4.SS3.SSS1.p6.5.m5.1.1.cmml"><mn id="S4.SS3.SSS1.p6.5.m5.1.1.2" xref="S4.SS3.SSS1.p6.5.m5.1.1.2.cmml">50</mn><mo id="S4.SS3.SSS1.p6.5.m5.1.1.1" xref="S4.SS3.SSS1.p6.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.5.m5.1b"><apply id="S4.SS3.SSS1.p6.5.m5.1.1.cmml" xref="S4.SS3.SSS1.p6.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.p6.5.m5.1.1.1.cmml" xref="S4.SS3.SSS1.p6.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p6.5.m5.1.1.2.cmml" xref="S4.SS3.SSS1.p6.5.m5.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.5.m5.1c">50\%</annotation></semantics></math> to <math id="S4.SS3.SSS1.p6.6.m6.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S4.SS3.SSS1.p6.6.m6.1a"><mrow id="S4.SS3.SSS1.p6.6.m6.1.1" xref="S4.SS3.SSS1.p6.6.m6.1.1.cmml"><mn id="S4.SS3.SSS1.p6.6.m6.1.1.2" xref="S4.SS3.SSS1.p6.6.m6.1.1.2.cmml">80</mn><mo id="S4.SS3.SSS1.p6.6.m6.1.1.1" xref="S4.SS3.SSS1.p6.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.6.m6.1b"><apply id="S4.SS3.SSS1.p6.6.m6.1.1.cmml" xref="S4.SS3.SSS1.p6.6.m6.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.p6.6.m6.1.1.1.cmml" xref="S4.SS3.SSS1.p6.6.m6.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p6.6.m6.1.1.2.cmml" xref="S4.SS3.SSS1.p6.6.m6.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.6.m6.1c">80\%</annotation></semantics></math> on Retina and from <math id="S4.SS3.SSS1.p6.7.m7.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.SS3.SSS1.p6.7.m7.1a"><mrow id="S4.SS3.SSS1.p6.7.m7.1.1" xref="S4.SS3.SSS1.p6.7.m7.1.1.cmml"><mn id="S4.SS3.SSS1.p6.7.m7.1.1.2" xref="S4.SS3.SSS1.p6.7.m7.1.1.2.cmml">30</mn><mo id="S4.SS3.SSS1.p6.7.m7.1.1.1" xref="S4.SS3.SSS1.p6.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.7.m7.1b"><apply id="S4.SS3.SSS1.p6.7.m7.1.1.cmml" xref="S4.SS3.SSS1.p6.7.m7.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.p6.7.m7.1.1.1.cmml" xref="S4.SS3.SSS1.p6.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p6.7.m7.1.1.2.cmml" xref="S4.SS3.SSS1.p6.7.m7.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.7.m7.1c">30\%</annotation></semantics></math> to <math id="S4.SS3.SSS1.p6.8.m8.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S4.SS3.SSS1.p6.8.m8.1a"><mrow id="S4.SS3.SSS1.p6.8.m8.1.1" xref="S4.SS3.SSS1.p6.8.m8.1.1.cmml"><mn id="S4.SS3.SSS1.p6.8.m8.1.1.2" xref="S4.SS3.SSS1.p6.8.m8.1.1.2.cmml">90</mn><mo id="S4.SS3.SSS1.p6.8.m8.1.1.1" xref="S4.SS3.SSS1.p6.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.8.m8.1b"><apply id="S4.SS3.SSS1.p6.8.m8.1.1.cmml" xref="S4.SS3.SSS1.p6.8.m8.1.1"><csymbol cd="latexml" id="S4.SS3.SSS1.p6.8.m8.1.1.1.cmml" xref="S4.SS3.SSS1.p6.8.m8.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS1.p6.8.m8.1.1.2.cmml" xref="S4.SS3.SSS1.p6.8.m8.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.8.m8.1c">90\%</annotation></semantics></math> on CIFAR-<math id="S4.SS3.SSS1.p6.9.m9.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS1.p6.9.m9.1a"><mn id="S4.SS3.SSS1.p6.9.m9.1.1" xref="S4.SS3.SSS1.p6.9.m9.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p6.9.m9.1b"><cn type="integer" id="S4.SS3.SSS1.p6.9.m9.1.1.cmml" xref="S4.SS3.SSS1.p6.9.m9.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p6.9.m9.1c">10</annotation></semantics></math>).</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Transformers converge faster to better optimum</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.4" class="ltx_p">A powerful FL method should not only perform robustly on both IID and non-IID data partitions but also have low communication costs to enable deployment over communicated-limited bandwidths.
Communication cost is determined by the number of rounds till convergence and the number of model parameter. We calculate the number of communication rounds needed to achieve a predefined target test set accuracy of <math id="S4.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="95\%" display="inline"><semantics id="S4.SS3.SSS2.p1.1.m1.1a"><mrow id="S4.SS3.SSS2.p1.1.m1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.cmml"><mn id="S4.SS3.SSS2.p1.1.m1.1.1.2" xref="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml">95</mn><mo id="S4.SS3.SSS2.p1.1.m1.1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.1.m1.1b"><apply id="S4.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.2">95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.1.m1.1c">95\%</annotation></semantics></math> of the prediction accuracy of a centrally trained ResNet(50). Specifically, we set the target accuracy of Retina and CIFAR-<math id="S4.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS2.p1.2.m2.1a"><mn id="S4.SS3.SSS2.p1.2.m2.1.1" xref="S4.SS3.SSS2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.2.m2.1b"><cn type="integer" id="S4.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.2.m2.1c">10</annotation></semantics></math> dataset to be <math id="S4.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="77.5\%" display="inline"><semantics id="S4.SS3.SSS2.p1.3.m3.1a"><mrow id="S4.SS3.SSS2.p1.3.m3.1.1" xref="S4.SS3.SSS2.p1.3.m3.1.1.cmml"><mn id="S4.SS3.SSS2.p1.3.m3.1.1.2" xref="S4.SS3.SSS2.p1.3.m3.1.1.2.cmml">77.5</mn><mo id="S4.SS3.SSS2.p1.3.m3.1.1.1" xref="S4.SS3.SSS2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.3.m3.1b"><apply id="S4.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS2.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS2.p1.3.m3.1.1.2">77.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.3.m3.1c">77.5\%</annotation></semantics></math> and <math id="S4.SS3.SSS2.p1.4.m4.1" class="ltx_Math" alttext="91.5\%" display="inline"><semantics id="S4.SS3.SSS2.p1.4.m4.1a"><mrow id="S4.SS3.SSS2.p1.4.m4.1.1" xref="S4.SS3.SSS2.p1.4.m4.1.1.cmml"><mn id="S4.SS3.SSS2.p1.4.m4.1.1.2" xref="S4.SS3.SSS2.p1.4.m4.1.1.2.cmml">91.5</mn><mo id="S4.SS3.SSS2.p1.4.m4.1.1.1" xref="S4.SS3.SSS2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.4.m4.1b"><apply id="S4.SS3.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS2.p1.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.SSS2.p1.4.m4.1.1.1.cmml" xref="S4.SS3.SSS2.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.SSS2.p1.4.m4.1.1.2.cmml" xref="S4.SS3.SSS2.p1.4.m4.1.1.2">91.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.4.m4.1c">91.5\%</annotation></semantics></math> respectively. We define one communication round on the serial CWT method as one complete training cycle across all federated local clients.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.3" class="ltx_p">From Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a href="#S4.T3" title="Table 3 ‣ 4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, all the evaluated FL methods converge to the target test performance quickly on homogeneous data partitions. However, the convergence speed of ResNet(50)-FedAVG and ResNet(50)-CWT decrease with increasing heterogeneity and even reach a plateau on highly heterogeneous data partitions (and never reach the target accuracy). In contrast, <span id="S4.SS3.SSS2.p2.3.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> still converges quickly on heterogeneous data. For example, ResNet(50)-CWT completely diverges due to severe catastrophic forgetting on heterogeneous data partitions Split-2 and Split-3 on CIFAR-<math id="S4.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS2.p2.1.m1.1a"><mn id="S4.SS3.SSS2.p2.1.m1.1.1" xref="S4.SS3.SSS2.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.1.m1.1b"><cn type="integer" id="S4.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.1.m1.1c">10</annotation></semantics></math>, whereas ViT(S)-CWT reaches the target performance after <math id="S4.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="34" display="inline"><semantics id="S4.SS3.SSS2.p2.2.m2.1a"><mn id="S4.SS3.SSS2.p2.2.m2.1.1" xref="S4.SS3.SSS2.p2.2.m2.1.1.cmml">34</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.2.m2.1b"><cn type="integer" id="S4.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS2.p2.2.m2.1.1">34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.2.m2.1c">34</annotation></semantics></math> and <math id="S4.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="85" display="inline"><semantics id="S4.SS3.SSS2.p2.3.m3.1a"><mn id="S4.SS3.SSS2.p2.3.m3.1.1" xref="S4.SS3.SSS2.p2.3.m3.1.1.cmml">85</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p2.3.m3.1b"><cn type="integer" id="S4.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS2.p2.3.m3.1.1">85</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p2.3.m3.1c">85</annotation></semantics></math> communication rounds.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<table id="S4.F7.4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.F7.1.1.1" class="ltx_tr">
<td id="S4.F7.1.1.1.2" class="ltx_td ltx_align_center">  <span id="S4.F7.1.1.1.2.1" class="ltx_text" style="font-size:70%;">Split 1, KS-0 (Retina)</span>
</td>
<td id="S4.F7.1.1.1.3" class="ltx_td ltx_align_center"><span id="S4.F7.1.1.1.3.1" class="ltx_text" style="font-size:70%;">Split 3, KS-0.57 (Retina)</span></td>
<td id="S4.F7.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.F7.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Split 3, KS-1 (CIFAR-<math id="S4.F7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F7.1.1.1.1.1.m1.1a"><mn id="S4.F7.1.1.1.1.1.m1.1.1" xref="S4.F7.1.1.1.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F7.1.1.1.1.1.m1.1b"><cn type="integer" id="S4.F7.1.1.1.1.1.m1.1.1.cmml" xref="S4.F7.1.1.1.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.1.1.1.1.1.m1.1c">10</annotation></semantics></math>)</span></td>
</tr>
<tr id="S4.F7.4.4.4" class="ltx_tr">
<td id="S4.F7.2.2.2.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_split1_diff_E.png" id="S4.F7.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="174" height="123" alt="Refer to caption"></td>
<td id="S4.F7.3.3.3.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_split3_diff_E.png" id="S4.F7.3.3.3.2.g1" class="ltx_graphics ltx_img_landscape" width="162" height="122" alt="Refer to caption"></td>
<td id="S4.F7.4.4.4.3" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Cifar10_split3_diff_E.png" id="S4.F7.4.4.4.3.g1" class="ltx_graphics ltx_img_landscape" width="162" height="122" alt="Refer to caption"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.12.4.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.10.3" class="ltx_text" style="font-size:90%;">The effect of training over different local epochs <math id="S4.F7.8.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.F7.8.1.m1.1b"><mi id="S4.F7.8.1.m1.1.1" xref="S4.F7.8.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.F7.8.1.m1.1c"><ci id="S4.F7.8.1.m1.1.1.cmml" xref="S4.F7.8.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.8.1.m1.1d">E</annotation></semantics></math> on each communication round for ViT(B)-CWT and ViT(B)-FedAVG models on Retina and CIFAR-<math id="S4.F7.9.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.F7.9.2.m2.1b"><mn id="S4.F7.9.2.m2.1.1" xref="S4.F7.9.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.F7.9.2.m2.1c"><cn type="integer" id="S4.F7.9.2.m2.1.1.cmml" xref="S4.F7.9.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.9.2.m2.1d">10</annotation></semantics></math> (the ViT(B) prefix of CWT and FedAVG in the legend labels is omitted for simplicity). Large <math id="S4.F7.10.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.F7.10.3.m3.1b"><mi id="S4.F7.10.3.m3.1.1" xref="S4.F7.10.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.F7.10.3.m3.1c"><ci id="S4.F7.10.3.m3.1.1.cmml" xref="S4.F7.10.3.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.10.3.m3.1d">E</annotation></semantics></math> leads to faster convergence in mild heterogeneous data partitions, but might lead to worse final performance in severely heterogeneous data partitions.</span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>In Conjunction with Existing Methods</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Since our investigation into architectural choices is largely orthogonal to existing optimization based FL methods, our findings can be easily used in conjunction with the latter. We combine Vision Transformers with optimization-based methods (FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>), and apply it to both Retina and CIFAR-<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><cn type="integer" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">10</annotation></semantics></math> datasets. From Table <a href="#S4.T3" title="Table 3 ‣ 4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3.1 Transformers generalize better in non-IID settings ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, when applying to existing FL optimization methods, <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_smallcaps">ViT</span> further boosts the performance for heterogeneous data clients.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Take-aways for Practical Usage</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.10" class="ltx_p"><span id="S4.SS5.p1.10.1" class="ltx_text ltx_font_bold">Local training epochs:</span> It is standard to use <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mi id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">E</annotation></semantics></math> to denote the number of rounds a local model passes over its local dataset. <math id="S4.SS5.p1.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.2.m2.1a"><mi id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><ci id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">E</annotation></semantics></math> is known to strongly affect the performance of FedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We conduct an experimental study on the impact of local training epochs <math id="S4.SS5.p1.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.3.m3.1a"><mi id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><ci id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">E</annotation></semantics></math> on <span id="S4.SS5.p1.10.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span>. We consider <math id="S4.SS5.p1.4.m4.3" class="ltx_Math" alttext="E\in\{1,5,10\}" display="inline"><semantics id="S4.SS5.p1.4.m4.3a"><mrow id="S4.SS5.p1.4.m4.3.4" xref="S4.SS5.p1.4.m4.3.4.cmml"><mi id="S4.SS5.p1.4.m4.3.4.2" xref="S4.SS5.p1.4.m4.3.4.2.cmml">E</mi><mo id="S4.SS5.p1.4.m4.3.4.1" xref="S4.SS5.p1.4.m4.3.4.1.cmml">∈</mo><mrow id="S4.SS5.p1.4.m4.3.4.3.2" xref="S4.SS5.p1.4.m4.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS5.p1.4.m4.3.4.3.2.1" xref="S4.SS5.p1.4.m4.3.4.3.1.cmml">{</mo><mn id="S4.SS5.p1.4.m4.1.1" xref="S4.SS5.p1.4.m4.1.1.cmml">1</mn><mo id="S4.SS5.p1.4.m4.3.4.3.2.2" xref="S4.SS5.p1.4.m4.3.4.3.1.cmml">,</mo><mn id="S4.SS5.p1.4.m4.2.2" xref="S4.SS5.p1.4.m4.2.2.cmml">5</mn><mo id="S4.SS5.p1.4.m4.3.4.3.2.3" xref="S4.SS5.p1.4.m4.3.4.3.1.cmml">,</mo><mn id="S4.SS5.p1.4.m4.3.3" xref="S4.SS5.p1.4.m4.3.3.cmml">10</mn><mo stretchy="false" id="S4.SS5.p1.4.m4.3.4.3.2.4" xref="S4.SS5.p1.4.m4.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.4.m4.3b"><apply id="S4.SS5.p1.4.m4.3.4.cmml" xref="S4.SS5.p1.4.m4.3.4"><in id="S4.SS5.p1.4.m4.3.4.1.cmml" xref="S4.SS5.p1.4.m4.3.4.1"></in><ci id="S4.SS5.p1.4.m4.3.4.2.cmml" xref="S4.SS5.p1.4.m4.3.4.2">𝐸</ci><set id="S4.SS5.p1.4.m4.3.4.3.1.cmml" xref="S4.SS5.p1.4.m4.3.4.3.2"><cn type="integer" id="S4.SS5.p1.4.m4.1.1.cmml" xref="S4.SS5.p1.4.m4.1.1">1</cn><cn type="integer" id="S4.SS5.p1.4.m4.2.2.cmml" xref="S4.SS5.p1.4.m4.2.2">5</cn><cn type="integer" id="S4.SS5.p1.4.m4.3.3.cmml" xref="S4.SS5.p1.4.m4.3.3">10</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.4.m4.3c">E\in\{1,5,10\}</annotation></semantics></math> for ViT(B)-FedAVG, and <math id="S4.SS5.p1.5.m5.2" class="ltx_Math" alttext="E\in\{1,5\}" display="inline"><semantics id="S4.SS5.p1.5.m5.2a"><mrow id="S4.SS5.p1.5.m5.2.3" xref="S4.SS5.p1.5.m5.2.3.cmml"><mi id="S4.SS5.p1.5.m5.2.3.2" xref="S4.SS5.p1.5.m5.2.3.2.cmml">E</mi><mo id="S4.SS5.p1.5.m5.2.3.1" xref="S4.SS5.p1.5.m5.2.3.1.cmml">∈</mo><mrow id="S4.SS5.p1.5.m5.2.3.3.2" xref="S4.SS5.p1.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS5.p1.5.m5.2.3.3.2.1" xref="S4.SS5.p1.5.m5.2.3.3.1.cmml">{</mo><mn id="S4.SS5.p1.5.m5.1.1" xref="S4.SS5.p1.5.m5.1.1.cmml">1</mn><mo id="S4.SS5.p1.5.m5.2.3.3.2.2" xref="S4.SS5.p1.5.m5.2.3.3.1.cmml">,</mo><mn id="S4.SS5.p1.5.m5.2.2" xref="S4.SS5.p1.5.m5.2.2.cmml">5</mn><mo stretchy="false" id="S4.SS5.p1.5.m5.2.3.3.2.3" xref="S4.SS5.p1.5.m5.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.5.m5.2b"><apply id="S4.SS5.p1.5.m5.2.3.cmml" xref="S4.SS5.p1.5.m5.2.3"><in id="S4.SS5.p1.5.m5.2.3.1.cmml" xref="S4.SS5.p1.5.m5.2.3.1"></in><ci id="S4.SS5.p1.5.m5.2.3.2.cmml" xref="S4.SS5.p1.5.m5.2.3.2">𝐸</ci><set id="S4.SS5.p1.5.m5.2.3.3.1.cmml" xref="S4.SS5.p1.5.m5.2.3.3.2"><cn type="integer" id="S4.SS5.p1.5.m5.1.1.cmml" xref="S4.SS5.p1.5.m5.1.1">1</cn><cn type="integer" id="S4.SS5.p1.5.m5.2.2.cmml" xref="S4.SS5.p1.5.m5.2.2">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.5.m5.2c">E\in\{1,5\}</annotation></semantics></math> for ViT(B)-CWT. From Figure <a href="#S4.F7" title="Figure 7 ‣ 4.3.2 Transformers converge faster to better optimum ‣ 4.3 Analyzing the Effectiveness of Transformers ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we find that ViT shows similar phenomena to their CNN counterparts, <em id="S4.SS5.p1.10.3" class="ltx_emph ltx_font_italic">i.e.</em>, larger <math id="S4.SS5.p1.6.m6.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.6.m6.1a"><mi id="S4.SS5.p1.6.m6.1.1" xref="S4.SS5.p1.6.m6.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.6.m6.1b"><ci id="S4.SS5.p1.6.m6.1.1.cmml" xref="S4.SS5.p1.6.m6.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.6.m6.1c">E</annotation></semantics></math> accelerates convergence of ViT(B)-FedAVG on homogeneous data partitions, but may lead to deterioration of final performance on heterogeneous data partitions.
Similarly, ViT(B)-CWT also favors frequent transfer rate between each client as ResNet(50)-CWT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> on non-IID data partitions. Therefore, we suggest users apply large <math id="S4.SS5.p1.7.m7.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.7.m7.1a"><mi id="S4.SS5.p1.7.m7.1.1" xref="S4.SS5.p1.7.m7.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.7.m7.1b"><ci id="S4.SS5.p1.7.m7.1.1.cmml" xref="S4.SS5.p1.7.m7.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.7.m7.1c">E</annotation></semantics></math> on homogeneous data to reduce communication, but a small <math id="S4.SS5.p1.8.m8.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS5.p1.8.m8.1a"><mi id="S4.SS5.p1.8.m8.1.1" xref="S4.SS5.p1.8.m8.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.8.m8.1b"><ci id="S4.SS5.p1.8.m8.1.1.cmml" xref="S4.SS5.p1.8.m8.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.8.m8.1c">E</annotation></semantics></math> (<math id="S4.SS5.p1.9.m9.1" class="ltx_Math" alttext="E\leq" display="inline"><semantics id="S4.SS5.p1.9.m9.1a"><mrow id="S4.SS5.p1.9.m9.1.1" xref="S4.SS5.p1.9.m9.1.1.cmml"><mi id="S4.SS5.p1.9.m9.1.1.2" xref="S4.SS5.p1.9.m9.1.1.2.cmml">E</mi><mo id="S4.SS5.p1.9.m9.1.1.1" xref="S4.SS5.p1.9.m9.1.1.1.cmml">≤</mo><mi id="S4.SS5.p1.9.m9.1.1.3" xref="S4.SS5.p1.9.m9.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.9.m9.1b"><apply id="S4.SS5.p1.9.m9.1.1.cmml" xref="S4.SS5.p1.9.m9.1.1"><leq id="S4.SS5.p1.9.m9.1.1.1.cmml" xref="S4.SS5.p1.9.m9.1.1.1"></leq><ci id="S4.SS5.p1.9.m9.1.1.2.cmml" xref="S4.SS5.p1.9.m9.1.1.2">𝐸</ci><csymbol cd="latexml" id="S4.SS5.p1.9.m9.1.1.3.cmml" xref="S4.SS5.p1.9.m9.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.9.m9.1c">E\leq</annotation></semantics></math> 5 for <span id="S4.SS5.p1.10.4" class="ltx_text ltx_font_smallcaps">ViT</span>-FedAVG and <math id="S4.SS5.p1.10.m10.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S4.SS5.p1.10.m10.1a"><mrow id="S4.SS5.p1.10.m10.1.1" xref="S4.SS5.p1.10.m10.1.1.cmml"><mi id="S4.SS5.p1.10.m10.1.1.2" xref="S4.SS5.p1.10.m10.1.1.2.cmml">E</mi><mo id="S4.SS5.p1.10.m10.1.1.1" xref="S4.SS5.p1.10.m10.1.1.1.cmml">=</mo><mn id="S4.SS5.p1.10.m10.1.1.3" xref="S4.SS5.p1.10.m10.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.10.m10.1b"><apply id="S4.SS5.p1.10.m10.1.1.cmml" xref="S4.SS5.p1.10.m10.1.1"><eq id="S4.SS5.p1.10.m10.1.1.1.cmml" xref="S4.SS5.p1.10.m10.1.1.1"></eq><ci id="S4.SS5.p1.10.m10.1.1.2.cmml" xref="S4.SS5.p1.10.m10.1.1.2">𝐸</ci><cn type="integer" id="S4.SS5.p1.10.m10.1.1.3.cmml" xref="S4.SS5.p1.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.10.m10.1c">E=1</annotation></semantics></math> for <span id="S4.SS5.p1.10.5" class="ltx_text ltx_font_smallcaps">ViT</span>-CWT) for highly heterogeneous cases.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.19.2.1" class="ltx_text" style="font-size:113%;">Table 4</span>: </span><span id="S4.T4.2.1" class="ltx_text" style="font-size:113%;">The influence of pretraining of Swin(T)-FedAVG on CIFAR-<math id="S4.T4.2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T4.2.1.m1.1b"><mn id="S4.T4.2.1.m1.1.1" xref="S4.T4.2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T4.2.1.m1.1c"><cn type="integer" id="S4.T4.2.1.m1.1.1.cmml" xref="S4.T4.2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.1.m1.1d">10</annotation></semantics></math>. Similar to the training of <span id="S4.T4.2.1.1" class="ltx_text ltx_font_smallcaps">ViT</span>, pretraining is important for the training of <span id="S4.T4.2.1.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span>.</span></figcaption>
<table id="S4.T4.10" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.10.9" class="ltx_tr">
<td id="S4.T4.10.9.1" class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T4.10.9.1.1" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S4.T4.10.9.2" class="ltx_td ltx_align_center"><span id="S4.T4.10.9.2.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Central</span></td>
<td id="S4.T4.10.9.3" class="ltx_td ltx_align_center"><span id="S4.T4.10.9.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Split-1</span></td>
<td id="S4.T4.10.9.4" class="ltx_td ltx_align_center"><span id="S4.T4.10.9.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Split-2</span></td>
<td id="S4.T4.10.9.5" class="ltx_td ltx_align_center"><span id="S4.T4.10.9.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Split-3</span></td>
</tr>
<tr id="S4.T4.6.4" class="ltx_tr">
<td id="S4.T4.6.4.5" class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="S4.T4.6.4.5.1" class="ltx_text" style="font-size:80%;">
Pretrain</span>
</td>
<td id="S4.T4.3.1.1" class="ltx_td ltx_align_center"><math id="S4.T4.3.1.1.m1.1" class="ltx_Math" alttext="97.91" display="inline"><semantics id="S4.T4.3.1.1.m1.1a"><mn mathsize="80%" id="S4.T4.3.1.1.m1.1.1" xref="S4.T4.3.1.1.m1.1.1.cmml">97.91</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.1.1.m1.1b"><cn type="float" id="S4.T4.3.1.1.m1.1.1.cmml" xref="S4.T4.3.1.1.m1.1.1">97.91</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.1.1.m1.1c">97.91</annotation></semantics></math></td>
<td id="S4.T4.4.2.2" class="ltx_td ltx_align_center"><math id="S4.T4.4.2.2.m1.1" class="ltx_Math" alttext="98.17" display="inline"><semantics id="S4.T4.4.2.2.m1.1a"><mn mathsize="80%" id="S4.T4.4.2.2.m1.1.1" xref="S4.T4.4.2.2.m1.1.1.cmml">98.17</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.2.2.m1.1b"><cn type="float" id="S4.T4.4.2.2.m1.1.1.cmml" xref="S4.T4.4.2.2.m1.1.1">98.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.2.2.m1.1c">98.17</annotation></semantics></math></td>
<td id="S4.T4.5.3.3" class="ltx_td ltx_align_center"><math id="S4.T4.5.3.3.m1.1" class="ltx_Math" alttext="97.78" display="inline"><semantics id="S4.T4.5.3.3.m1.1a"><mn mathsize="80%" id="S4.T4.5.3.3.m1.1.1" xref="S4.T4.5.3.3.m1.1.1.cmml">97.78</mn><annotation-xml encoding="MathML-Content" id="S4.T4.5.3.3.m1.1b"><cn type="float" id="S4.T4.5.3.3.m1.1.1.cmml" xref="S4.T4.5.3.3.m1.1.1">97.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.3.3.m1.1c">97.78</annotation></semantics></math></td>
<td id="S4.T4.6.4.4" class="ltx_td ltx_align_center"><math id="S4.T4.6.4.4.m1.1" class="ltx_Math" alttext="96.40" display="inline"><semantics id="S4.T4.6.4.4.m1.1a"><mn mathsize="80%" id="S4.T4.6.4.4.m1.1.1" xref="S4.T4.6.4.4.m1.1.1.cmml">96.40</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.4.4.m1.1b"><cn type="float" id="S4.T4.6.4.4.m1.1.1.cmml" xref="S4.T4.6.4.4.m1.1.1">96.40</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.4.4.m1.1c">96.40</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.10.8" class="ltx_tr">
<td id="S4.T4.10.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.10.8.5.1" class="ltx_text" style="font-size:80%;">From scratch</span></td>
<td id="S4.T4.7.5.1" class="ltx_td ltx_align_center"><math id="S4.T4.7.5.1.m1.1" class="ltx_Math" alttext="94.50" display="inline"><semantics id="S4.T4.7.5.1.m1.1a"><mn mathsize="80%" id="S4.T4.7.5.1.m1.1.1" xref="S4.T4.7.5.1.m1.1.1.cmml">94.50</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.5.1.m1.1b"><cn type="float" id="S4.T4.7.5.1.m1.1.1.cmml" xref="S4.T4.7.5.1.m1.1.1">94.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.5.1.m1.1c">94.50</annotation></semantics></math></td>
<td id="S4.T4.8.6.2" class="ltx_td ltx_align_center"><math id="S4.T4.8.6.2.m1.1" class="ltx_Math" alttext="86.91" display="inline"><semantics id="S4.T4.8.6.2.m1.1a"><mn mathsize="80%" id="S4.T4.8.6.2.m1.1.1" xref="S4.T4.8.6.2.m1.1.1.cmml">86.91</mn><annotation-xml encoding="MathML-Content" id="S4.T4.8.6.2.m1.1b"><cn type="float" id="S4.T4.8.6.2.m1.1.1.cmml" xref="S4.T4.8.6.2.m1.1.1">86.91</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.6.2.m1.1c">86.91</annotation></semantics></math></td>
<td id="S4.T4.9.7.3" class="ltx_td ltx_align_center"><math id="S4.T4.9.7.3.m1.1" class="ltx_Math" alttext="79.43" display="inline"><semantics id="S4.T4.9.7.3.m1.1a"><mn mathsize="80%" id="S4.T4.9.7.3.m1.1.1" xref="S4.T4.9.7.3.m1.1.1.cmml">79.43</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.7.3.m1.1b"><cn type="float" id="S4.T4.9.7.3.m1.1.1.cmml" xref="S4.T4.9.7.3.m1.1.1">79.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.7.3.m1.1c">79.43</annotation></semantics></math></td>
<td id="S4.T4.10.8.4" class="ltx_td ltx_align_center"><math id="S4.T4.10.8.4.m1.1" class="ltx_Math" alttext="64.50" display="inline"><semantics id="S4.T4.10.8.4.m1.1a"><mn mathsize="80%" id="S4.T4.10.8.4.m1.1.1" xref="S4.T4.10.8.4.m1.1.1.cmml">64.50</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.8.4.m1.1b"><cn type="float" id="S4.T4.10.8.4.m1.1.1.cmml" xref="S4.T4.10.8.4.m1.1.1">64.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.8.4.m1.1c">64.50</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.10.10" class="ltx_tr">
<td id="S4.T4.10.10.1" class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="S4.T4.10.10.2" class="ltx_td"></td>
<td id="S4.T4.10.10.3" class="ltx_td"></td>
<td id="S4.T4.10.10.4" class="ltx_td"></td>
<td id="S4.T4.10.10.5" class="ltx_td"></td>
</tr>
</table>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.4" class="ltx_p"><span id="S4.SS5.p2.4.1" class="ltx_text ltx_font_bold">The influence of pretraining on <span id="S4.SS5.p2.4.1.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span>:</span>
Evidence suggests that <span id="S4.SS5.p2.4.2" class="ltx_text ltx_font_smallcaps">ViT</span> generally require a larger amount of training data to perform better than CNNs when trained from scratch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. We conduct experiments to investigate the influence of pretraining on <span id="S4.SS5.p2.4.3" class="ltx_text ltx_font_smallcaps">ViT-FL</span>. We apply FedAVG as the training algorithm, use Swin(T) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> as the backbone network, and test on CIFAR-<math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><mn id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><cn type="integer" id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">10</annotation></semantics></math>. We apply the same augmentation and regularization strategies as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> during training and set the maximum communication rounds to <math id="S4.SS5.p2.2.m2.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS5.p2.2.m2.1a"><mn id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b"><cn type="integer" id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">300</annotation></semantics></math>. As shown in Table <a href="#S4.T4" title="Table 4 ‣ 4.5 Take-aways for Practical Usage ‣ 4 Experiments ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the performance of Swin(T) drops when trained from scratch for both the ideal centrally-hosted and FL settings. Despite this, its performance on highly-heterogeneous data partition Split-3 when trained from scratch (<math id="S4.SS5.p2.3.m3.1" class="ltx_Math" alttext="64.50\%" display="inline"><semantics id="S4.SS5.p2.3.m3.1a"><mrow id="S4.SS5.p2.3.m3.1.1" xref="S4.SS5.p2.3.m3.1.1.cmml"><mn id="S4.SS5.p2.3.m3.1.1.2" xref="S4.SS5.p2.3.m3.1.1.2.cmml">64.50</mn><mo id="S4.SS5.p2.3.m3.1.1.1" xref="S4.SS5.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m3.1b"><apply id="S4.SS5.p2.3.m3.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS5.p2.3.m3.1.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.3.m3.1.1.2.cmml" xref="S4.SS5.p2.3.m3.1.1.2">64.50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m3.1c">64.50\%</annotation></semantics></math>) is surprisingly better than ResNet(50)-FedAVG (<math id="S4.SS5.p2.4.m4.1" class="ltx_Math" alttext="59.68\%" display="inline"><semantics id="S4.SS5.p2.4.m4.1a"><mrow id="S4.SS5.p2.4.m4.1.1" xref="S4.SS5.p2.4.m4.1.1.cmml"><mn id="S4.SS5.p2.4.m4.1.1.2" xref="S4.SS5.p2.4.m4.1.1.2.cmml">59.68</mn><mo id="S4.SS5.p2.4.m4.1.1.1" xref="S4.SS5.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m4.1b"><apply id="S4.SS5.p2.4.m4.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS5.p2.4.m4.1.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.4.m4.1.1.2.cmml" xref="S4.SS5.p2.4.m4.1.1.2">59.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.4.m4.1c">59.68\%</annotation></semantics></math> on Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Federated Learning Methods ‣ 3 Transformers in Federated Learning ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) when pretrained with orders of magnitude more data. In real applications, users are recommended to apply <span id="S4.SS5.p2.4.4" class="ltx_text ltx_font_smallcaps">ViT</span> as their first option, since <span id="S4.SS5.p2.4.5" class="ltx_text ltx_font_smallcaps">ViT-FL</span> consistently outperform their CNNs counterparts when pretrained models are applied (Figure <a href="#footnotex2" title="Footnote 1 ‣ Figure 1 ‣ 1 Introduction ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text" style="font-size:111%;">1</span></span></a> and Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Federated Learning Methods ‣ 3 Transformers in Federated Learning ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). If large-scale pretraining datasets are not available, self-supervised pretraining <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> could be an alternative.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p"><span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_bold">Other training tips:</span> The training strategy of <span id="S4.SS5.p3.1.2" class="ltx_text ltx_font_smallcaps">ViT</span> in FL can be directly inherited from <span id="S4.SS5.p3.1.3" class="ltx_text ltx_font_smallcaps">ViT</span> training, such as using linear warm-up and learning rate decay, and gradient clipping. Relatively small learning rates and gradient norm clip are necessary to stabilize the training of <span id="S4.SS5.p3.1.4" class="ltx_text ltx_font_smallcaps">ViT</span> in CWT, especially in highly heterogeneous data partitions. Gradient norm clip also helps in the training of FL with CNNs across heterogeneous data since it has been shown to reduce weight divergence between local updates and the current global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Please refer to Appendix <a href="#A2.SS1" title="B.1 Take-aways for Practical Usage ‣ Appendix B Additional Results ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B.1</span></a> for more general tips and experimental analysis.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Despite the recent progress in FL, there remain challenges regarding convergence and forgetting when dealing with heterogeneous data.
Unlike previous methods on improving optimization, we provide a new perspective by rethinking architecture design in FL.
Using the robustness of Transformers to heterogeneous data and distribution shifts, we perform extensive analysis and demonstrate the advantages of Transformers in alleviating catastrophic forgetting, accelerating convergence, and reaching a better optimum for both parallel and serial FL methods. We release our code and models to encourage developments in robust architectures in parallel to efforts on the optimization front.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported in part by a grant from the NCI, U01CA242879.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav
Choudhary.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.00818</span>, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Niranjan Balachandar, Ken Chang, Jayashree Kalpathy-Cramer, and Daniel L Rubin.

</span>
<span class="ltx_bibblock">Accounting for data variability in multi-institutional distributed
deep learning for medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>,
27(5):700–708, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Srinadh Bhojanapalli, Ayan Chakrabarti, Daniel Glasner, Daliang Li, Thomas
Unterthiner, and Andreas Veit.

</span>
<span class="ltx_bibblock">Understanding robustness of transformers for image classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.14586</span>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Theodora S Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky, Ioannis Ch
Paschalidis, and Wei Shi.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from federated electronic
health records.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">International journal of medical informatics</span>, 112:59–67, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub
Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.01097</span>, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal,
Piotr Bojanowski, and Armand Joulin.

</span>
<span class="ltx_bibblock">Emerging properties in self-supervised vision transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.14294</span>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Ken Chang, Niranjan Balachandar, Carson Lam, Darvin Yi, James Brown, Andrew
Beers, Bruce Rosen, Daniel L Rubin, and Jayashree Kalpathy-Cramer.

</span>
<span class="ltx_bibblock">Distributed deep learning networks among institutions for medical
imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>,
25(8):945–954, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Xinyang Chen, Sinan Wang, Bo Fu, Mingsheng Long, and Jianmin Wang.

</span>
<span class="ltx_bibblock">Catastrophic forgetting meets negative transfer: Batch spectral
shrinkage for safe transfer learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Alexandra Chronopoulou, Christos Baziotis, and Alexandros Potamianos.

</span>
<span class="ltx_bibblock">An embarrassingly simple approach for transfer learning from
pretrained language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</span>, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.

</span>
<span class="ltx_bibblock">Imagenet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">2009 IEEE conference on computer vision and pattern
recognition</span>, pages 248–255. Ieee, 2009.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A
Wichmann, and Wieland Brendel.

</span>
<span class="ltx_bibblock">Imagenet-trained cnns are biased towards texture; increasing shape
bias improves accuracy and robustness.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Xuan Gong, Abhishek Sharma, Srikrishna Karanam, Ziyan Wu, Terrence Chen, David
Doermann, and Arun Innanje.

</span>
<span class="ltx_bibblock">Ensemble attention distillation for privacy-preserving federated
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span>, pages 15076–15086, October 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Pengfei Guo, Puyang Wang, Jinyuan Zhou, Shanshan Jiang, and Vishal M. Patel.

</span>
<span class="ltx_bibblock">Multi-institutional collaborations for improving deep learning-based
magnetic resonance image reconstruction using federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, pages 2423–2432, June 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Sharut Gupta, Praveer Singh, Ken Chang, Liangqiong Qu, Mehak Aggarwal, Nishanth
Arun, Ashwin Vaswani, Shruti Raghavan, Vibha Agarwal, Mishka Gidwani, et al.

</span>
<span class="ltx_bibblock">Addressing catastrophic forgetting for medical domain expansion.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.13511</span>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise
Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel
Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1811.03604</span>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross
Girshick.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.06377</span>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 770–778, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Neural Computation</span>, 9(8):1735–1780, 1997.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.

</span>
<span class="ltx_bibblock">The non-iid data quagmire of decentralized machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4387–4398. PMLR, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for
federated visual classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.06335</span>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira.

</span>
<span class="ltx_bibblock">Re-evaluating continual learning scenarios: A categorization and case
for strong baselines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">NeurIPS Continual learning Workshop</span>, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Ronghang Hu and Amanpreet Singh.

</span>
<span class="ltx_bibblock">Transformer is all you need: Multimodal multitask learning with a
unified transformer.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.10772</span>, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Ji Chu Jiang, Burak Kantarci, Sema Oktug, and Tolga Soyata.

</span>
<span class="ltx_bibblock">Federated learning in smart city sensing: Challenges and
opportunities.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 20(21):6230, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Jason Jo and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Measuring the tendency of cnns to learn surface statistical
regularities.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1711.11561</span>, 2017.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Kaggle.

</span>
<span class="ltx_bibblock">Diabetic retinopathy detection.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">https://www.kaggle.com/c/diabetic-retinopathy-detection</span>, 2017.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.04977</span>, 2019.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.6980</span>, 2014.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of the national academy of sciences</span>,
114(13):3521–3526, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Fan Lai, Yinwei Dai, Xiangfeng Zhu, Harsha V Madhyastha, and Mosharaf
Chowdhury.

</span>
<span class="ltx_bibblock">Fedscale: Benchmarking model and system performance of federated
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Proceedings of the First Workshop on Systems Challenges in
Reliable and Secure Federated Learning</span>, pages 1–3, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Siddique Latif, Sara Khalifa, Rajib Rana, and Raja Jurdak.

</span>
<span class="ltx_bibblock">Federated learning for speech emotion recognition applications.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">2020 19th ACM/IEEE International Conference on Information
Processing in Sensor Networks (IPSN)</span>, pages 341–342. IEEE, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 86(11):2278–2324, 1998.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He, and Dawn Song.

</span>
<span class="ltx_bibblock">Model-contrastive federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, pages 10713–10722, June 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Magazine</span>, 37(3):50–60, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.06127</span>, 2018.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B Allen, Randy P Auerbach,
David Brent, Ruslan Salakhutdinov, and Louis-Philippe Morency.

</span>
<span class="ltx_bibblock">Think locally, act globally: Federated learning with local and global
representations.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2001.01523</span>, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.07242</span>, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng.

</span>
<span class="ltx_bibblock">Feddg: Federated domain generalization on medical image segmentation
via episodic learning in continuous frequency space.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, pages 1013–1023, June 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo.

</span>
<span class="ltx_bibblock">Swin transformer: Hierarchical vision transformer using shifted
windows.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.14030</span>, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Deep learning face attributes in the wild.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</span>, pages 3730–3738, 2015.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Kevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch.

</span>
<span class="ltx_bibblock">Pretrained transformers as universal computation engines.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.05247</span>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Kaleel Mahmood, Rigel Mahmood, and Marten Van Dijk.

</span>
<span class="ltx_bibblock">On the robustness of vision transformers to adversarial examples.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.02610</span>, 2021.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Leland McInnes, John Healy, and James Melville.

</span>
<span class="ltx_bibblock">Umap: Uniform manifold approximation and projection for dimension
reduction.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1802.03426</span>, 2018.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y
Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span>, pages 1273–1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et al.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1602.05629</span>, 2016.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Munawar Hayat, Fahad Shahbaz
Khan, and Ming-Hsuan Yang.

</span>
<span class="ltx_bibblock">Intriguing properties of vision transformers, 2021.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Solmaz Niknam, Harpreet S Dhillon, and Jeffrey H Reed.

</span>
<span class="ltx_bibblock">Federated learning for wireless communications: Motivation,
opportunities, and challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">IEEE Communications Magazine</span>, 58(6):46–51, 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
Alexander Ku, and Dustin Tran.

</span>
<span class="ltx_bibblock">Image transformer.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4055–4064. PMLR, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Sayak Paul and Pin-Yu Chen.

</span>
<span class="ltx_bibblock">Vision transformers are robust learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2105.07581</span>, 2021.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Liangqiong Qu, Niranjan Balachandar, Miao Zhang, and Daniel Rubin.

</span>
<span class="ltx_bibblock">Handling data heterogeneity with generative replay in collaborative
learning for medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, page 102424, 2022.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya,
and Jonathon Shlens.

</span>
<span class="ltx_bibblock">Stand-alone self-attention in vision models.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2019.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi
Albarqouni, Spyridon Bakas, Mathieu N Galtier, Bennett A Landman, Klaus
Maier-Hein, et al.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">NPJ digital medicine</span>, 3(1):1–7, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Holger R Roth, Ken Chang, Praveer Singh, Nir Neumark, Wenqi Li, Vikash Gupta,
Sharut Gupta, Liangqiong Qu, Alvin Ihsani, Bernardo C Bizzo, et al.

</span>
<span class="ltx_bibblock">Federated learning for breast density classification: A real-world
implementation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Domain Adaptation and Representation Transfer, and
Distributed and Collaborative Learning</span>, pages 181–191. Springer, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting with hard attention to the task.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4548–4557. PMLR, 2018.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Micah J Sheller, Brandon Edwards, G Anthony Reina, Jason Martin, Sarthak Pati,
Aikaterini Kotrotsou, Mikhail Milchenko, Weilin Xu, Daniel Marcus, Rivka R
Colen, et al.

</span>
<span class="ltx_bibblock">Federated learning in medicine: facilitating multi-institutional
collaborations without sharing patient data.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Scientific reports</span>, 10(1):1–12, 2020.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim.

</span>
<span class="ltx_bibblock">Continual learning with deep generative replay.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1705.08690</span>, 2017.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Mingxing Tan and Quoc Le.

</span>
<span class="ltx_bibblock">Efficientnet: Rethinking model scaling for convolutional neural
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
6105–6114. PMLR, 2019.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang, J Zico Kolter, Louis-Philippe
Morency, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Multimodal transformer for unaligned multimodal language sequences.

</span>
<span class="ltx_bibblock">In <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics</span>, pages 6558–6569, 2019.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, pages
5998–6008, 2017.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar.

</span>
<span class="ltx_bibblock">Split learning for health: Distributed deep learning without sharing
raw patient data.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.00564</span>, 2018.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Haohan Wang, Songwei Ge, Eric P Xing, and Zachary C Lipton.

</span>
<span class="ltx_bibblock">Learning robust global representations by penalizing local predictive
power.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2019.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.06440</span>, 2020.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Lin Zhang, Yong Luo, Yan Bai, Bo Du, and Ling-Yu Duan.

</span>
<span class="ltx_bibblock">Federated learning for non-iid data via unified feature learning and
optimization objective alignment.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span>, pages 4420–4428, October 2021.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Miao Zhang, Liangqiong Qu, Praveer Singh, Jayashree Kalpathy-Cramer, and
Daniel L Rubin.

</span>
<span class="ltx_bibblock">Splitavg: A heterogeneity-aware federated deep learning method for
medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2107.02375</span>, 2021.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez.

</span>
<span class="ltx_bibblock">Personalized federated learning with first order model optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1806.00582</span>, 2018.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Weiming Zhuang, Xin Gan, Yonggang Wen, Shuai Zhang, and Shuai Yi.

</span>
<span class="ltx_bibblock">Collaborative unsupervised visual representation learning from
decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span>, pages 4912–4921, October 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Experimental Details</h2>

<figure id="A1.F8" class="ltx_figure">
<table id="A1.F8.2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.F8.2.2.3" class="ltx_tr">
<td id="A1.F8.2.2.3.1" class="ltx_td ltx_align_center">
 (a) Split 2, KS-0.49</td>
<td id="A1.F8.2.2.3.2" class="ltx_td ltx_align_center">(b) Split 3, KS-0.57</td>
</tr>
<tr id="A1.F8.2.2.2" class="ltx_tr">
<td id="A1.F8.1.1.1.1" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/Retina_Split2.png" id="A1.F8.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="240" height="186" alt="Refer to caption">
</td>
<td id="A1.F8.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_Split3.png" id="A1.F8.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="240" height="184" alt="Refer to caption"></td>
</tr>
<tr id="A1.F8.2.2.4" class="ltx_tr">
<td id="A1.F8.2.2.4.1" class="ltx_td ltx_align_center">Labels</td>
<td id="A1.F8.2.2.4.2" class="ltx_td ltx_align_center">Labels</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.5.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A1.F8.6.2" class="ltx_text" style="font-size:90%;">Detailed non-IID data partitions on <span id="A1.F8.6.2.1" class="ltx_text ltx_font_smallcaps">Retina</span> with label distribution skew. The value in each rectangle shows the fraction of data samples of a class over their total number.</span></figcaption>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">In this section, we provide additional details on the datasets used, preprocessing steps, and experimental methodology. We include code to reproduce our experiments at <a target="_blank" href="https://github.com/Liangqiong/ViT-FL-main" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Liangqiong/ViT-FL-main</a>.</p>
</div>
<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Detailed Image Pre-processing and Data Partitions</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.16" class="ltx_p"><span id="A1.SS1.p1.16.1" class="ltx_text ltx_font_bold">Kaggle Diabetic Retinopathy competition</span> (<span id="A1.SS1.p1.16.2" class="ltx_text ltx_font_smallcaps">Retina</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> contains a total of <math id="A1.SS1.p1.1.m1.2" class="ltx_Math" alttext="17,563" display="inline"><semantics id="A1.SS1.p1.1.m1.2a"><mrow id="A1.SS1.p1.1.m1.2.3.2" xref="A1.SS1.p1.1.m1.2.3.1.cmml"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">17</mn><mo id="A1.SS1.p1.1.m1.2.3.2.1" xref="A1.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.1.m1.2.2" xref="A1.SS1.p1.1.m1.2.2.cmml">563</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.2b"><list id="A1.SS1.p1.1.m1.2.3.1.cmml" xref="A1.SS1.p1.1.m1.2.3.2"><cn type="integer" id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">17</cn><cn type="integer" id="A1.SS1.p1.1.m1.2.2.cmml" xref="A1.SS1.p1.1.m1.2.2">563</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.2c">17,563</annotation></semantics></math> pairs of right and left color digital retinal fundus images. Each image is labeled on a scale of <math id="A1.SS1.p1.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn type="integer" id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">0</cn></annotation-xml></semantics></math> to <math id="A1.SS1.p1.3.m3.1" class="ltx_Math" alttext="4" display="inline"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn type="integer" id="A1.SS1.p1.3.m3.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">4</annotation></semantics></math> by a well-trained clinician, indicating no, mild, moderate, severe, and proliferative diabetic retinopathy respectively. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we exclude the samples with scale <math id="A1.SS1.p1.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.SS1.p1.4.m4.1a"><mn id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><cn type="integer" id="A1.SS1.p1.4.m4.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">1</annotation></semantics></math>, and then binarize the remaining labels to Healthy (scale <math id="A1.SS1.p1.5.m5.1" class="ltx_Math" alttext="0" display="inline"><semantics id="A1.SS1.p1.5.m5.1a"><mn id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><cn type="integer" id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1">0</cn></annotation-xml></semantics></math>) and Diseased (scale <math id="A1.SS1.p1.6.m6.2" class="ltx_Math" alttext="2,3" display="inline"><semantics id="A1.SS1.p1.6.m6.2a"><mrow id="A1.SS1.p1.6.m6.2.3.2" xref="A1.SS1.p1.6.m6.2.3.1.cmml"><mn id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml">2</mn><mo id="A1.SS1.p1.6.m6.2.3.2.1" xref="A1.SS1.p1.6.m6.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.6.m6.2.2" xref="A1.SS1.p1.6.m6.2.2.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.2b"><list id="A1.SS1.p1.6.m6.2.3.1.cmml" xref="A1.SS1.p1.6.m6.2.3.2"><cn type="integer" id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1">2</cn><cn type="integer" id="A1.SS1.p1.6.m6.2.2.cmml" xref="A1.SS1.p1.6.m6.2.2">3</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.2c">2,3</annotation></semantics></math> or <math id="A1.SS1.p1.7.m7.1" class="ltx_Math" alttext="4" display="inline"><semantics id="A1.SS1.p1.7.m7.1a"><mn id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.1b"><cn type="integer" id="A1.SS1.p1.7.m7.1.1.cmml" xref="A1.SS1.p1.7.m7.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.1c">4</annotation></semantics></math>). Furthermore, we only use the left images in our study to remove the confounding factor of different disease status of left and right eyes for the same patient. We randomly select <math id="A1.SS1.p1.8.m8.2" class="ltx_Math" alttext="6,000" display="inline"><semantics id="A1.SS1.p1.8.m8.2a"><mrow id="A1.SS1.p1.8.m8.2.3.2" xref="A1.SS1.p1.8.m8.2.3.1.cmml"><mn id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml">6</mn><mo id="A1.SS1.p1.8.m8.2.3.2.1" xref="A1.SS1.p1.8.m8.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.8.m8.2.2" xref="A1.SS1.p1.8.m8.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.2b"><list id="A1.SS1.p1.8.m8.2.3.1.cmml" xref="A1.SS1.p1.8.m8.2.3.2"><cn type="integer" id="A1.SS1.p1.8.m8.1.1.cmml" xref="A1.SS1.p1.8.m8.1.1">6</cn><cn type="integer" id="A1.SS1.p1.8.m8.2.2.cmml" xref="A1.SS1.p1.8.m8.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.2c">6,000</annotation></semantics></math> balanced (<math id="A1.SS1.p1.9.m9.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="A1.SS1.p1.9.m9.2a"><mrow id="A1.SS1.p1.9.m9.2.3.2" xref="A1.SS1.p1.9.m9.2.3.1.cmml"><mn id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml">3</mn><mo id="A1.SS1.p1.9.m9.2.3.2.1" xref="A1.SS1.p1.9.m9.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.9.m9.2.2" xref="A1.SS1.p1.9.m9.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.2b"><list id="A1.SS1.p1.9.m9.2.3.1.cmml" xref="A1.SS1.p1.9.m9.2.3.2"><cn type="integer" id="A1.SS1.p1.9.m9.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1">3</cn><cn type="integer" id="A1.SS1.p1.9.m9.2.2.cmml" xref="A1.SS1.p1.9.m9.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.2c">3,000</annotation></semantics></math> healthy and <math id="A1.SS1.p1.10.m10.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="A1.SS1.p1.10.m10.2a"><mrow id="A1.SS1.p1.10.m10.2.3.2" xref="A1.SS1.p1.10.m10.2.3.1.cmml"><mn id="A1.SS1.p1.10.m10.1.1" xref="A1.SS1.p1.10.m10.1.1.cmml">3</mn><mo id="A1.SS1.p1.10.m10.2.3.2.1" xref="A1.SS1.p1.10.m10.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.10.m10.2.2" xref="A1.SS1.p1.10.m10.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.10.m10.2b"><list id="A1.SS1.p1.10.m10.2.3.1.cmml" xref="A1.SS1.p1.10.m10.2.3.2"><cn type="integer" id="A1.SS1.p1.10.m10.1.1.cmml" xref="A1.SS1.p1.10.m10.1.1">3</cn><cn type="integer" id="A1.SS1.p1.10.m10.2.2.cmml" xref="A1.SS1.p1.10.m10.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.10.m10.2c">3,000</annotation></semantics></math> diseased) images for training, <math id="A1.SS1.p1.11.m11.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="A1.SS1.p1.11.m11.2a"><mrow id="A1.SS1.p1.11.m11.2.3.2" xref="A1.SS1.p1.11.m11.2.3.1.cmml"><mn id="A1.SS1.p1.11.m11.1.1" xref="A1.SS1.p1.11.m11.1.1.cmml">3</mn><mo id="A1.SS1.p1.11.m11.2.3.2.1" xref="A1.SS1.p1.11.m11.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.11.m11.2.2" xref="A1.SS1.p1.11.m11.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.11.m11.2b"><list id="A1.SS1.p1.11.m11.2.3.1.cmml" xref="A1.SS1.p1.11.m11.2.3.2"><cn type="integer" id="A1.SS1.p1.11.m11.1.1.cmml" xref="A1.SS1.p1.11.m11.1.1">3</cn><cn type="integer" id="A1.SS1.p1.11.m11.2.2.cmml" xref="A1.SS1.p1.11.m11.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.11.m11.2c">3,000</annotation></semantics></math> balanced images as the global validation dataset, and <math id="A1.SS1.p1.12.m12.2" class="ltx_Math" alttext="3,000" display="inline"><semantics id="A1.SS1.p1.12.m12.2a"><mrow id="A1.SS1.p1.12.m12.2.3.2" xref="A1.SS1.p1.12.m12.2.3.1.cmml"><mn id="A1.SS1.p1.12.m12.1.1" xref="A1.SS1.p1.12.m12.1.1.cmml">3</mn><mo id="A1.SS1.p1.12.m12.2.3.2.1" xref="A1.SS1.p1.12.m12.2.3.1.cmml">,</mo><mn id="A1.SS1.p1.12.m12.2.2" xref="A1.SS1.p1.12.m12.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.12.m12.2b"><list id="A1.SS1.p1.12.m12.2.3.1.cmml" xref="A1.SS1.p1.12.m12.2.3.2"><cn type="integer" id="A1.SS1.p1.12.m12.1.1.cmml" xref="A1.SS1.p1.12.m12.1.1">3</cn><cn type="integer" id="A1.SS1.p1.12.m12.2.2.cmml" xref="A1.SS1.p1.12.m12.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.12.m12.2c">3,000</annotation></semantics></math> balanced images as the global test dataset. Other image pre-processing steps include rescaling as a radius of <math id="A1.SS1.p1.13.m13.1" class="ltx_Math" alttext="300" display="inline"><semantics id="A1.SS1.p1.13.m13.1a"><mn id="A1.SS1.p1.13.m13.1.1" xref="A1.SS1.p1.13.m13.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.13.m13.1b"><cn type="integer" id="A1.SS1.p1.13.m13.1.1.cmml" xref="A1.SS1.p1.13.m13.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.13.m13.1c">300</annotation></semantics></math>, local color averaging and image clipping, resizing to <math id="A1.SS1.p1.14.m14.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="A1.SS1.p1.14.m14.1a"><mrow id="A1.SS1.p1.14.m14.1.1" xref="A1.SS1.p1.14.m14.1.1.cmml"><mn id="A1.SS1.p1.14.m14.1.1.2" xref="A1.SS1.p1.14.m14.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.14.m14.1.1.1" xref="A1.SS1.p1.14.m14.1.1.1.cmml">×</mo><mn id="A1.SS1.p1.14.m14.1.1.3" xref="A1.SS1.p1.14.m14.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.14.m14.1b"><apply id="A1.SS1.p1.14.m14.1.1.cmml" xref="A1.SS1.p1.14.m14.1.1"><times id="A1.SS1.p1.14.m14.1.1.1.cmml" xref="A1.SS1.p1.14.m14.1.1.1"></times><cn type="integer" id="A1.SS1.p1.14.m14.1.1.2.cmml" xref="A1.SS1.p1.14.m14.1.1.2">256</cn><cn type="integer" id="A1.SS1.p1.14.m14.1.1.3.cmml" xref="A1.SS1.p1.14.m14.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.14.m14.1c">256\times 256</annotation></semantics></math>, horizontal flipping, and randomly cropping to <math id="A1.SS1.p1.15.m15.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="A1.SS1.p1.15.m15.1a"><mrow id="A1.SS1.p1.15.m15.1.1" xref="A1.SS1.p1.15.m15.1.1.cmml"><mn id="A1.SS1.p1.15.m15.1.1.2" xref="A1.SS1.p1.15.m15.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.15.m15.1.1.1" xref="A1.SS1.p1.15.m15.1.1.1.cmml">×</mo><mn id="A1.SS1.p1.15.m15.1.1.3" xref="A1.SS1.p1.15.m15.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.15.m15.1b"><apply id="A1.SS1.p1.15.m15.1.1.cmml" xref="A1.SS1.p1.15.m15.1.1"><times id="A1.SS1.p1.15.m15.1.1.1.cmml" xref="A1.SS1.p1.15.m15.1.1.1"></times><cn type="integer" id="A1.SS1.p1.15.m15.1.1.2.cmml" xref="A1.SS1.p1.15.m15.1.1.2">224</cn><cn type="integer" id="A1.SS1.p1.15.m15.1.1.3.cmml" xref="A1.SS1.p1.15.m15.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.15.m15.1c">224\times 224</annotation></semantics></math>. We choose a final <math id="A1.SS1.p1.16.m16.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="A1.SS1.p1.16.m16.1a"><mrow id="A1.SS1.p1.16.m16.1.1" xref="A1.SS1.p1.16.m16.1.1.cmml"><mn id="A1.SS1.p1.16.m16.1.1.2" xref="A1.SS1.p1.16.m16.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.16.m16.1.1.1" xref="A1.SS1.p1.16.m16.1.1.1.cmml">×</mo><mn id="A1.SS1.p1.16.m16.1.1.3" xref="A1.SS1.p1.16.m16.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.16.m16.1b"><apply id="A1.SS1.p1.16.m16.1.1.cmml" xref="A1.SS1.p1.16.m16.1.1"><times id="A1.SS1.p1.16.m16.1.1.1.cmml" xref="A1.SS1.p1.16.m16.1.1.1"></times><cn type="integer" id="A1.SS1.p1.16.m16.1.1.2.cmml" xref="A1.SS1.p1.16.m16.1.1.2">224</cn><cn type="integer" id="A1.SS1.p1.16.m16.1.1.3.cmml" xref="A1.SS1.p1.16.m16.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.16.m16.1c">224\times 224</annotation></semantics></math> image dimension to be compatible with current work in both CNNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and Vision Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<figure id="A1.F9" class="ltx_figure">
<table id="A1.F9.2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.F9.2.2.3" class="ltx_tr">
<td id="A1.F9.2.2.3.1" class="ltx_td ltx_align_center">
 (a) Split 2, KS-0.65</td>
<td id="A1.F9.2.2.3.2" class="ltx_td ltx_align_center">(b) Split 3, KS-1</td>
</tr>
<tr id="A1.F9.2.2.2" class="ltx_tr">
<td id="A1.F9.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Cifar_Split2.png" id="A1.F9.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="252" height="163" alt="Refer to caption"></td>
<td id="A1.F9.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Cifar_Split3.png" id="A1.F9.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="252" height="165" alt="Refer to caption"></td>
</tr>
<tr id="A1.F9.2.2.4" class="ltx_tr">
<td id="A1.F9.2.2.4.1" class="ltx_td ltx_align_center">Labels</td>
<td id="A1.F9.2.2.4.2" class="ltx_td ltx_align_center">Labels</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.6.2.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A1.F9.4.1" class="ltx_text" style="font-size:90%;">Detailed non-IID data partitions on <span id="A1.F9.4.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.F9.4.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.F9.4.1.1.m1.1b"><mn id="A1.F9.4.1.1.m1.1.1" xref="A1.F9.4.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.F9.4.1.1.m1.1c"><cn type="integer" id="A1.F9.4.1.1.m1.1.1.cmml" xref="A1.F9.4.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.F9.4.1.1.m1.1d">10</annotation></semantics></math></span> with label distribution skew. The value in each rectangle shows the fraction of data samples in a class over their total number.</span></figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<table id="A1.F10.3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.F10.1.1.1" class="ltx_tr">
<td id="A1.F10.1.1.1.2" class="ltx_td ltx_align_center">  <span id="A1.F10.1.1.1.2.1" class="ltx_text" style="font-size:70%;">Split 3, KS-0.57 (Retina)</span>
</td>
<td id="A1.F10.1.1.1.1" class="ltx_td ltx_align_center"><span id="A1.F10.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Split 3, KS-1 (CIFAR-<math id="A1.F10.1.1.1.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.F10.1.1.1.1.1.m1.1a"><mn id="A1.F10.1.1.1.1.1.m1.1.1" xref="A1.F10.1.1.1.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.F10.1.1.1.1.1.m1.1b"><cn type="integer" id="A1.F10.1.1.1.1.1.m1.1.1.cmml" xref="A1.F10.1.1.1.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.F10.1.1.1.1.1.m1.1c">10</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="A1.F10.3.3.3" class="ltx_tr">
<td id="A1.F10.2.2.2.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Grid_clip_Retina.png" id="A1.F10.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="240" height="178" alt="Refer to caption"></td>
<td id="A1.F10.3.3.3.2" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Grid_clip_Cifar10.png" id="A1.F10.3.3.3.2.g1" class="ltx_graphics ltx_img_landscape" width="353" height="180" alt="Refer to caption"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.7.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A1.F10.8.2" class="ltx_text" style="font-size:90%;">Influence of gradient clip on different FL methods with ViT(B) and ResNet-50(R50) as the backbone networks, respectively. In the legend, <span id="A1.F10.8.2.1" class="ltx_text ltx_font_bold">-W</span> denotes with gradient clip and <span id="A1.F10.8.2.2" class="ltx_text ltx_font_bold">-Wo</span> denotes without gradient clip. We find that gradient clip stabilizes training and accelerates convergence speed on highly heterogeneous data splits.</span></figcaption>
</figure>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">We simulate three sets of data partitions for the <span id="A1.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">Retina</span> dataset with each data partition containing four simulated clients: one IID-data partition (Split 1, KS-0), and two non-IID data partitions with label distribution skew (Split 2, KS-0.49, and Split 3, KS-0.57). See Figure <a href="#A1.F8" title="Figure 8 ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> for the detailed non-IID data partitions.</p>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p id="A1.SS1.p3.11" class="ltx_p"><span id="A1.SS1.p3.11.1" class="ltx_text ltx_font_bold">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> consists of <math id="A1.SS1.p3.1.m1.2" class="ltx_Math" alttext="50,000" display="inline"><semantics id="A1.SS1.p3.1.m1.2a"><mrow id="A1.SS1.p3.1.m1.2.3.2" xref="A1.SS1.p3.1.m1.2.3.1.cmml"><mn id="A1.SS1.p3.1.m1.1.1" xref="A1.SS1.p3.1.m1.1.1.cmml">50</mn><mo id="A1.SS1.p3.1.m1.2.3.2.1" xref="A1.SS1.p3.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.1.m1.2.2" xref="A1.SS1.p3.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.1.m1.2b"><list id="A1.SS1.p3.1.m1.2.3.1.cmml" xref="A1.SS1.p3.1.m1.2.3.2"><cn type="integer" id="A1.SS1.p3.1.m1.1.1.cmml" xref="A1.SS1.p3.1.m1.1.1">50</cn><cn type="integer" id="A1.SS1.p3.1.m1.2.2.cmml" xref="A1.SS1.p3.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.1.m1.2c">50,000</annotation></semantics></math> training and <math id="A1.SS1.p3.2.m2.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="A1.SS1.p3.2.m2.2a"><mrow id="A1.SS1.p3.2.m2.2.3.2" xref="A1.SS1.p3.2.m2.2.3.1.cmml"><mn id="A1.SS1.p3.2.m2.1.1" xref="A1.SS1.p3.2.m2.1.1.cmml">10</mn><mo id="A1.SS1.p3.2.m2.2.3.2.1" xref="A1.SS1.p3.2.m2.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.2.m2.2.2" xref="A1.SS1.p3.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.2.m2.2b"><list id="A1.SS1.p3.2.m2.2.3.1.cmml" xref="A1.SS1.p3.2.m2.2.3.2"><cn type="integer" id="A1.SS1.p3.2.m2.1.1.cmml" xref="A1.SS1.p3.2.m2.1.1">10</cn><cn type="integer" id="A1.SS1.p3.2.m2.2.2.cmml" xref="A1.SS1.p3.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.2.m2.2c">10,000</annotation></semantics></math> testing <math id="A1.SS1.p3.3.m3.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="A1.SS1.p3.3.m3.1a"><mrow id="A1.SS1.p3.3.m3.1.1" xref="A1.SS1.p3.3.m3.1.1.cmml"><mn id="A1.SS1.p3.3.m3.1.1.2" xref="A1.SS1.p3.3.m3.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p3.3.m3.1.1.1" xref="A1.SS1.p3.3.m3.1.1.1.cmml">×</mo><mn id="A1.SS1.p3.3.m3.1.1.3" xref="A1.SS1.p3.3.m3.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.3.m3.1b"><apply id="A1.SS1.p3.3.m3.1.1.cmml" xref="A1.SS1.p3.3.m3.1.1"><times id="A1.SS1.p3.3.m3.1.1.1.cmml" xref="A1.SS1.p3.3.m3.1.1.1"></times><cn type="integer" id="A1.SS1.p3.3.m3.1.1.2.cmml" xref="A1.SS1.p3.3.m3.1.1.2">32</cn><cn type="integer" id="A1.SS1.p3.3.m3.1.1.3.cmml" xref="A1.SS1.p3.3.m3.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.3.m3.1c">32\times 32</annotation></semantics></math> images in <math id="A1.SS1.p3.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS1.p3.4.m4.1a"><mn id="A1.SS1.p3.4.m4.1.1" xref="A1.SS1.p3.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.4.m4.1b"><cn type="integer" id="A1.SS1.p3.4.m4.1.1.cmml" xref="A1.SS1.p3.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.4.m4.1c">10</annotation></semantics></math> classes, with <math id="A1.SS1.p3.5.m5.2" class="ltx_Math" alttext="5,000" display="inline"><semantics id="A1.SS1.p3.5.m5.2a"><mrow id="A1.SS1.p3.5.m5.2.3.2" xref="A1.SS1.p3.5.m5.2.3.1.cmml"><mn id="A1.SS1.p3.5.m5.1.1" xref="A1.SS1.p3.5.m5.1.1.cmml">5</mn><mo id="A1.SS1.p3.5.m5.2.3.2.1" xref="A1.SS1.p3.5.m5.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.5.m5.2.2" xref="A1.SS1.p3.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.5.m5.2b"><list id="A1.SS1.p3.5.m5.2.3.1.cmml" xref="A1.SS1.p3.5.m5.2.3.2"><cn type="integer" id="A1.SS1.p3.5.m5.1.1.cmml" xref="A1.SS1.p3.5.m5.1.1">5</cn><cn type="integer" id="A1.SS1.p3.5.m5.2.2.cmml" xref="A1.SS1.p3.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.5.m5.2c">5,000</annotation></semantics></math> and <math id="A1.SS1.p3.6.m6.2" class="ltx_Math" alttext="1,000" display="inline"><semantics id="A1.SS1.p3.6.m6.2a"><mrow id="A1.SS1.p3.6.m6.2.3.2" xref="A1.SS1.p3.6.m6.2.3.1.cmml"><mn id="A1.SS1.p3.6.m6.1.1" xref="A1.SS1.p3.6.m6.1.1.cmml">1</mn><mo id="A1.SS1.p3.6.m6.2.3.2.1" xref="A1.SS1.p3.6.m6.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.6.m6.2.2" xref="A1.SS1.p3.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.6.m6.2b"><list id="A1.SS1.p3.6.m6.2.3.1.cmml" xref="A1.SS1.p3.6.m6.2.3.2"><cn type="integer" id="A1.SS1.p3.6.m6.1.1.cmml" xref="A1.SS1.p3.6.m6.1.1">1</cn><cn type="integer" id="A1.SS1.p3.6.m6.2.2.cmml" xref="A1.SS1.p3.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.6.m6.2c">1,000</annotation></semantics></math> images per class in training and test dataset respectively. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, we apply the <math id="A1.SS1.p3.7.m7.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="A1.SS1.p3.7.m7.2a"><mrow id="A1.SS1.p3.7.m7.2.3.2" xref="A1.SS1.p3.7.m7.2.3.1.cmml"><mn id="A1.SS1.p3.7.m7.1.1" xref="A1.SS1.p3.7.m7.1.1.cmml">10</mn><mo id="A1.SS1.p3.7.m7.2.3.2.1" xref="A1.SS1.p3.7.m7.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.7.m7.2.2" xref="A1.SS1.p3.7.m7.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.7.m7.2b"><list id="A1.SS1.p3.7.m7.2.3.1.cmml" xref="A1.SS1.p3.7.m7.2.3.2"><cn type="integer" id="A1.SS1.p3.7.m7.1.1.cmml" xref="A1.SS1.p3.7.m7.1.1">10</cn><cn type="integer" id="A1.SS1.p3.7.m7.2.2.cmml" xref="A1.SS1.p3.7.m7.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.7.m7.2c">10,000</annotation></semantics></math> image test dataset as the global test dataset, set aside <math id="A1.SS1.p3.8.m8.2" class="ltx_Math" alttext="5,000" display="inline"><semantics id="A1.SS1.p3.8.m8.2a"><mrow id="A1.SS1.p3.8.m8.2.3.2" xref="A1.SS1.p3.8.m8.2.3.1.cmml"><mn id="A1.SS1.p3.8.m8.1.1" xref="A1.SS1.p3.8.m8.1.1.cmml">5</mn><mo id="A1.SS1.p3.8.m8.2.3.2.1" xref="A1.SS1.p3.8.m8.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.8.m8.2.2" xref="A1.SS1.p3.8.m8.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.8.m8.2b"><list id="A1.SS1.p3.8.m8.2.3.1.cmml" xref="A1.SS1.p3.8.m8.2.3.2"><cn type="integer" id="A1.SS1.p3.8.m8.1.1.cmml" xref="A1.SS1.p3.8.m8.1.1">5</cn><cn type="integer" id="A1.SS1.p3.8.m8.2.2.cmml" xref="A1.SS1.p3.8.m8.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.8.m8.2c">5,000</annotation></semantics></math> images from the training dataset as the global validation dataset, and the remaining <math id="A1.SS1.p3.9.m9.2" class="ltx_Math" alttext="45,000" display="inline"><semantics id="A1.SS1.p3.9.m9.2a"><mrow id="A1.SS1.p3.9.m9.2.3.2" xref="A1.SS1.p3.9.m9.2.3.1.cmml"><mn id="A1.SS1.p3.9.m9.1.1" xref="A1.SS1.p3.9.m9.1.1.cmml">45</mn><mo id="A1.SS1.p3.9.m9.2.3.2.1" xref="A1.SS1.p3.9.m9.2.3.1.cmml">,</mo><mn id="A1.SS1.p3.9.m9.2.2" xref="A1.SS1.p3.9.m9.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.9.m9.2b"><list id="A1.SS1.p3.9.m9.2.3.1.cmml" xref="A1.SS1.p3.9.m9.2.3.2"><cn type="integer" id="A1.SS1.p3.9.m9.1.1.cmml" xref="A1.SS1.p3.9.m9.1.1">45</cn><cn type="integer" id="A1.SS1.p3.9.m9.2.2.cmml" xref="A1.SS1.p3.9.m9.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.9.m9.2c">45,000</annotation></semantics></math> images as training dataset. We preprocess each image by resizing to <math id="A1.SS1.p3.10.m10.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="A1.SS1.p3.10.m10.1a"><mrow id="A1.SS1.p3.10.m10.1.1" xref="A1.SS1.p3.10.m10.1.1.cmml"><mn id="A1.SS1.p3.10.m10.1.1.2" xref="A1.SS1.p3.10.m10.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p3.10.m10.1.1.1" xref="A1.SS1.p3.10.m10.1.1.1.cmml">×</mo><mn id="A1.SS1.p3.10.m10.1.1.3" xref="A1.SS1.p3.10.m10.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.10.m10.1b"><apply id="A1.SS1.p3.10.m10.1.1.cmml" xref="A1.SS1.p3.10.m10.1.1"><times id="A1.SS1.p3.10.m10.1.1.1.cmml" xref="A1.SS1.p3.10.m10.1.1.1"></times><cn type="integer" id="A1.SS1.p3.10.m10.1.1.2.cmml" xref="A1.SS1.p3.10.m10.1.1.2">256</cn><cn type="integer" id="A1.SS1.p3.10.m10.1.1.3.cmml" xref="A1.SS1.p3.10.m10.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.10.m10.1c">256\times 256</annotation></semantics></math> and cropping to <math id="A1.SS1.p3.11.m11.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="A1.SS1.p3.11.m11.1a"><mrow id="A1.SS1.p3.11.m11.1.1" xref="A1.SS1.p3.11.m11.1.1.cmml"><mn id="A1.SS1.p3.11.m11.1.1.2" xref="A1.SS1.p3.11.m11.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p3.11.m11.1.1.1" xref="A1.SS1.p3.11.m11.1.1.1.cmml">×</mo><mn id="A1.SS1.p3.11.m11.1.1.3" xref="A1.SS1.p3.11.m11.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.11.m11.1b"><apply id="A1.SS1.p3.11.m11.1.1.cmml" xref="A1.SS1.p3.11.m11.1.1"><times id="A1.SS1.p3.11.m11.1.1.1.cmml" xref="A1.SS1.p3.11.m11.1.1.1"></times><cn type="integer" id="A1.SS1.p3.11.m11.1.1.2.cmml" xref="A1.SS1.p3.11.m11.1.1.2">224</cn><cn type="integer" id="A1.SS1.p3.11.m11.1.1.3.cmml" xref="A1.SS1.p3.11.m11.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.11.m11.1c">224\times 224</annotation></semantics></math>.</p>
</div>
<div id="A1.SS1.p4" class="ltx_para">
<p id="A1.SS1.p4.1" class="ltx_p">We simulate one IID-data partition (Split 1, KS-0), one heterogeneous data partition (Split 2, KS-0.65), and one heterogeneous data partition in the extreme case (Split 3, KS-1). Each data partitions contains five clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We randomly assign each client with images sampled via a uniform distribution over the <math id="A1.SS1.p4.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS1.p4.1.m1.1a"><mn id="A1.SS1.p4.1.m1.1.1" xref="A1.SS1.p4.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p4.1.m1.1b"><cn type="integer" id="A1.SS1.p4.1.m1.1.1.cmml" xref="A1.SS1.p4.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p4.1.m1.1c">10</annotation></semantics></math> classes for the IID data partition Split 1, KS-0. For Split 2, KS-0.65, one client receives images sampled from two classes, while the remaining four clients receive images sampled from four classes. Split 3, KS-1 is an extreme case where each client receives images sampled from only two classes. Please refer to Figure <a href="#A1.F9" title="Figure 9 ‣ A.1 Detailed Image Pre-processing and Data Partitions ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> for the detailed label distribution on each client for Split 2 and Split 3.</p>
</div>
<div id="A1.SS1.p5" class="ltx_para">
<p id="A1.SS1.p5.6" class="ltx_p"><span id="A1.SS1.p5.6.1" class="ltx_text ltx_font_bold">CelebA</span> is a large-scale face attributes dataset with more than <math id="A1.SS1.p5.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.SS1.p5.1.m1.1a"><mn id="A1.SS1.p5.1.m1.1.1" xref="A1.SS1.p5.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.1.m1.1b"><cn type="integer" id="A1.SS1.p5.1.m1.1.1.cmml" xref="A1.SS1.p5.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.1.m1.1c">200</annotation></semantics></math>K celebrity images. The images in CelebA cover large diversities, <em id="A1.SS1.p5.6.2" class="ltx_emph ltx_font_italic">i.e.</em>, large pose variations and background clutter. We use a specially designed federated version of CelebA provided by the LEAF benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> which partitions the dataset into devices based on the celebrity in the picture (<em id="A1.SS1.p5.6.3" class="ltx_emph ltx_font_italic">i.e.</em>, each device contains only images of celebrity). Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, we test on the binary classification task (presence of smile), drop clients with larger than 8 samples to increase the difficult. This results in a total of <math id="A1.SS1.p5.2.m2.1" class="ltx_Math" alttext="227" display="inline"><semantics id="A1.SS1.p5.2.m2.1a"><mn id="A1.SS1.p5.2.m2.1.1" xref="A1.SS1.p5.2.m2.1.1.cmml">227</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.2.m2.1b"><cn type="integer" id="A1.SS1.p5.2.m2.1.1.cmml" xref="A1.SS1.p5.2.m2.1.1">227</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.2.m2.1c">227</annotation></semantics></math> clients with an average of <math id="A1.SS1.p5.3.m3.1" class="ltx_Math" alttext="5.34\pm 1.11" display="inline"><semantics id="A1.SS1.p5.3.m3.1a"><mrow id="A1.SS1.p5.3.m3.1.1" xref="A1.SS1.p5.3.m3.1.1.cmml"><mn id="A1.SS1.p5.3.m3.1.1.2" xref="A1.SS1.p5.3.m3.1.1.2.cmml">5.34</mn><mo id="A1.SS1.p5.3.m3.1.1.1" xref="A1.SS1.p5.3.m3.1.1.1.cmml">±</mo><mn id="A1.SS1.p5.3.m3.1.1.3" xref="A1.SS1.p5.3.m3.1.1.3.cmml">1.11</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.3.m3.1b"><apply id="A1.SS1.p5.3.m3.1.1.cmml" xref="A1.SS1.p5.3.m3.1.1"><csymbol cd="latexml" id="A1.SS1.p5.3.m3.1.1.1.cmml" xref="A1.SS1.p5.3.m3.1.1.1">plus-or-minus</csymbol><cn type="float" id="A1.SS1.p5.3.m3.1.1.2.cmml" xref="A1.SS1.p5.3.m3.1.1.2">5.34</cn><cn type="float" id="A1.SS1.p5.3.m3.1.1.3.cmml" xref="A1.SS1.p5.3.m3.1.1.3">1.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.3.m3.1c">5.34\pm 1.11</annotation></semantics></math> samples and a total of <math id="A1.SS1.p5.4.m4.1" class="ltx_Math" alttext="1213" display="inline"><semantics id="A1.SS1.p5.4.m4.1a"><mn id="A1.SS1.p5.4.m4.1.1" xref="A1.SS1.p5.4.m4.1.1.cmml">1213</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.4.m4.1b"><cn type="integer" id="A1.SS1.p5.4.m4.1.1.cmml" xref="A1.SS1.p5.4.m4.1.1">1213</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.4.m4.1c">1213</annotation></semantics></math> samples. for the histogram of the number of training samples in each client. We preprocess each image by resizing to <math id="A1.SS1.p5.5.m5.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="A1.SS1.p5.5.m5.1a"><mrow id="A1.SS1.p5.5.m5.1.1" xref="A1.SS1.p5.5.m5.1.1.cmml"><mn id="A1.SS1.p5.5.m5.1.1.2" xref="A1.SS1.p5.5.m5.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p5.5.m5.1.1.1" xref="A1.SS1.p5.5.m5.1.1.1.cmml">×</mo><mn id="A1.SS1.p5.5.m5.1.1.3" xref="A1.SS1.p5.5.m5.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.5.m5.1b"><apply id="A1.SS1.p5.5.m5.1.1.cmml" xref="A1.SS1.p5.5.m5.1.1"><times id="A1.SS1.p5.5.m5.1.1.1.cmml" xref="A1.SS1.p5.5.m5.1.1.1"></times><cn type="integer" id="A1.SS1.p5.5.m5.1.1.2.cmml" xref="A1.SS1.p5.5.m5.1.1.2">256</cn><cn type="integer" id="A1.SS1.p5.5.m5.1.1.3.cmml" xref="A1.SS1.p5.5.m5.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.5.m5.1c">256\times 256</annotation></semantics></math> and cropping to <math id="A1.SS1.p5.6.m6.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="A1.SS1.p5.6.m6.1a"><mrow id="A1.SS1.p5.6.m6.1.1" xref="A1.SS1.p5.6.m6.1.1.cmml"><mn id="A1.SS1.p5.6.m6.1.1.2" xref="A1.SS1.p5.6.m6.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p5.6.m6.1.1.1" xref="A1.SS1.p5.6.m6.1.1.1.cmml">×</mo><mn id="A1.SS1.p5.6.m6.1.1.3" xref="A1.SS1.p5.6.m6.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p5.6.m6.1b"><apply id="A1.SS1.p5.6.m6.1.1.cmml" xref="A1.SS1.p5.6.m6.1.1"><times id="A1.SS1.p5.6.m6.1.1.1.cmml" xref="A1.SS1.p5.6.m6.1.1.1"></times><cn type="integer" id="A1.SS1.p5.6.m6.1.1.2.cmml" xref="A1.SS1.p5.6.m6.1.1.2">224</cn><cn type="integer" id="A1.SS1.p5.6.m6.1.1.3.cmml" xref="A1.SS1.p5.6.m6.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p5.6.m6.1c">224\times 224</annotation></semantics></math>.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Implementation Details and Hyperparameters</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.4" class="ltx_p"><span id="A1.SS2.p1.4.1" class="ltx_text ltx_font_bold">Implementation Details.</span> All the methods are implemented with Pytorch and optimized either with SGD (with momentum as <math id="A1.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="A1.SS2.p1.1.m1.1a"><mn id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><cn type="float" id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">0.9</annotation></semantics></math> and no weight decay) or AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> (with weight decay as 0.05). All experiments were conducted on either a TITAN V GPU or GeForce RTX 2080 GPU. For fair comparison, all the models used in this paper are pretrained from ImageNet’s ILSVRC-2012 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. We set local training epoch in all the FL methods to <math id="A1.SS2.p1.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.SS2.p1.2.m2.1a"><mn id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.1b"><cn type="integer" id="A1.SS2.p1.2.m2.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.1c">1</annotation></semantics></math>, and the total communication round to 100, unless otherwise stated. We set the local training batch size to <math id="A1.SS2.p1.3.m3.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A1.SS2.p1.3.m3.1a"><mn id="A1.SS2.p1.3.m3.1.1" xref="A1.SS2.p1.3.m3.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.3.m3.1b"><cn type="integer" id="A1.SS2.p1.3.m3.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.3.m3.1c">32</annotation></semantics></math>, and adopt a default input image resolution <math id="A1.SS2.p1.4.m4.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="A1.SS2.p1.4.m4.1a"><mrow id="A1.SS2.p1.4.m4.1.1" xref="A1.SS2.p1.4.m4.1.1.cmml"><mn id="A1.SS2.p1.4.m4.1.1.2" xref="A1.SS2.p1.4.m4.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS2.p1.4.m4.1.1.1" xref="A1.SS2.p1.4.m4.1.1.1.cmml">×</mo><mn id="A1.SS2.p1.4.m4.1.1.3" xref="A1.SS2.p1.4.m4.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.4.m4.1b"><apply id="A1.SS2.p1.4.m4.1.1.cmml" xref="A1.SS2.p1.4.m4.1.1"><times id="A1.SS2.p1.4.m4.1.1.1.cmml" xref="A1.SS2.p1.4.m4.1.1.1"></times><cn type="integer" id="A1.SS2.p1.4.m4.1.1.2.cmml" xref="A1.SS2.p1.4.m4.1.1.2">224</cn><cn type="integer" id="A1.SS2.p1.4.m4.1.1.3.cmml" xref="A1.SS2.p1.4.m4.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.4.m4.1c">224\times 224</annotation></semantics></math> for all methods. More implementation details are shown below.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<p id="A1.SS2.p2.2" class="ltx_p"><span id="A1.SS2.p2.2.1" class="ltx_text ltx_font_bold">Training hyperparameters:</span> Inherited from original Transformers training, the Swin-FL models are optimized with AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and the ViT-FL models are optimized with SGD. As a fair comparison, the optimizers for the compared CNNs are selected from either SGD and AdamW according to parameter searching. We use linear learning rate warm-up and decay scheduler for the Transformer models. Specifically, we set the warmup steps to <math id="A1.SS2.p2.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="A1.SS2.p2.1.m1.1a"><mn id="A1.SS2.p2.1.m1.1.1" xref="A1.SS2.p2.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.1.m1.1b"><cn type="integer" id="A1.SS2.p2.1.m1.1.1.cmml" xref="A1.SS2.p2.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.1.m1.1c">500</annotation></semantics></math>, and cosine learning rate decay to zero after the maximum round of FL training epochs is reached. The learning rate scheduler for FL with CNNs is selected from linear warm-up and decay or step decay (halved every <math id="A1.SS2.p2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS2.p2.2.m2.1a"><mn id="A1.SS2.p2.2.m2.1.1" xref="A1.SS2.p2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.2.m2.1b"><cn type="integer" id="A1.SS2.p2.2.m2.1.1.cmml" xref="A1.SS2.p2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.2.m2.1c">30</annotation></semantics></math> rounds of FL training). Gradient clipping (at global norm 1) is applied to stabilize the training.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para">
<p id="A1.SS2.p3.3" class="ltx_p"><span id="A1.SS2.p3.3.3" class="ltx_text ltx_font_bold">Hyperparameter selection:</span> We tune the best parameters (including learning rate scheduler, and penalty constant <math id="A1.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="A1.SS2.p3.1.m1.1a"><mi id="A1.SS2.p3.1.m1.1.1" xref="A1.SS2.p3.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.1.m1.1b"><ci id="A1.SS2.p3.1.m1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.1.m1.1c">\mu</annotation></semantics></math> in the proximal term of FedProx) for FL with CNNs on Split-2 of <span id="A1.SS2.p3.3.4" class="ltx_text ltx_font_smallcaps">Retina</span> and <span id="A1.SS2.p3.2.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.SS2.p3.2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p3.2.1.m1.1a"><mn id="A1.SS2.p3.2.1.m1.1.1" xref="A1.SS2.p3.2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.2.1.m1.1b"><cn type="integer" id="A1.SS2.p3.2.1.m1.1.1.cmml" xref="A1.SS2.p3.2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.2.1.m1.1c">10</annotation></semantics></math></span> dataset with grid search, and apply the same parameters to all the remaining data partitions, including the extreme large-scale edge case setting. The detailed hyperparameters of different models for <span id="A1.SS2.p3.3.5" class="ltx_text ltx_font_smallcaps">Retina</span> and <span id="A1.SS2.p3.3.2" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.SS2.p3.3.2.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p3.3.2.m1.1a"><mn id="A1.SS2.p3.3.2.m1.1.1" xref="A1.SS2.p3.3.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.3.2.m1.1b"><cn type="integer" id="A1.SS2.p3.3.2.m1.1.1.cmml" xref="A1.SS2.p3.3.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.3.2.m1.1c">10</annotation></semantics></math></span> are shown in Table <a href="#A1.T5" title="Table 5 ‣ A.2 Implementation Details and Hyperparameters ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="A1.SS2.p4" class="ltx_para">
<p id="A1.SS2.p4.14" class="ltx_p"><span id="A1.SS2.p4.14.3" class="ltx_text ltx_font_bold">FL hyperparameters:</span> For <span id="A1.SS2.p4.14.4" class="ltx_text ltx_font_smallcaps">Retina</span> and <span id="A1.SS2.p4.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.SS2.p4.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p4.1.1.m1.1a"><mn id="A1.SS2.p4.1.1.m1.1.1" xref="A1.SS2.p4.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.1.1.m1.1b"><cn type="integer" id="A1.SS2.p4.1.1.m1.1.1.cmml" xref="A1.SS2.p4.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.1.1.m1.1c">10</annotation></semantics></math></span>, we set the number of local training epochs <math id="A1.SS2.p4.2.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="A1.SS2.p4.2.m1.1a"><mi id="A1.SS2.p4.2.m1.1.1" xref="A1.SS2.p4.2.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.2.m1.1b"><ci id="A1.SS2.p4.2.m1.1.1.cmml" xref="A1.SS2.p4.2.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.2.m1.1c">E</annotation></semantics></math> on each client to <math id="A1.SS2.p4.3.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.SS2.p4.3.m2.1a"><mn id="A1.SS2.p4.3.m2.1.1" xref="A1.SS2.p4.3.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.3.m2.1b"><cn type="integer" id="A1.SS2.p4.3.m2.1.1.cmml" xref="A1.SS2.p4.3.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.3.m2.1c">1</annotation></semantics></math> (unless otherwise stated) and the total number of communication rounds to <math id="A1.SS2.p4.4.m3.1" class="ltx_Math" alttext="100" display="inline"><semantics id="A1.SS2.p4.4.m3.1a"><mn id="A1.SS2.p4.4.m3.1.1" xref="A1.SS2.p4.4.m3.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.4.m3.1b"><cn type="integer" id="A1.SS2.p4.4.m3.1.1.cmml" xref="A1.SS2.p4.4.m3.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.4.m3.1c">100</annotation></semantics></math>, with all local clients participating in FL training in each round. <math id="A1.SS2.p4.5.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.SS2.p4.5.m4.1a"><mi id="A1.SS2.p4.5.m4.1.1" xref="A1.SS2.p4.5.m4.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.5.m4.1b"><ci id="A1.SS2.p4.5.m4.1.1.cmml" xref="A1.SS2.p4.5.m4.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.5.m4.1c">\beta</annotation></semantics></math> is selected from <math id="A1.SS2.p4.6.m5.8" class="ltx_Math" alttext="\{0.1,0.3,0.5,0.7,0.9,0.97,0.99,0.997\}" display="inline"><semantics id="A1.SS2.p4.6.m5.8a"><mrow id="A1.SS2.p4.6.m5.8.9.2" xref="A1.SS2.p4.6.m5.8.9.1.cmml"><mo stretchy="false" id="A1.SS2.p4.6.m5.8.9.2.1" xref="A1.SS2.p4.6.m5.8.9.1.cmml">{</mo><mn id="A1.SS2.p4.6.m5.1.1" xref="A1.SS2.p4.6.m5.1.1.cmml">0.1</mn><mo id="A1.SS2.p4.6.m5.8.9.2.2" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.2.2" xref="A1.SS2.p4.6.m5.2.2.cmml">0.3</mn><mo id="A1.SS2.p4.6.m5.8.9.2.3" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.3.3" xref="A1.SS2.p4.6.m5.3.3.cmml">0.5</mn><mo id="A1.SS2.p4.6.m5.8.9.2.4" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.4.4" xref="A1.SS2.p4.6.m5.4.4.cmml">0.7</mn><mo id="A1.SS2.p4.6.m5.8.9.2.5" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.5.5" xref="A1.SS2.p4.6.m5.5.5.cmml">0.9</mn><mo id="A1.SS2.p4.6.m5.8.9.2.6" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.6.6" xref="A1.SS2.p4.6.m5.6.6.cmml">0.97</mn><mo id="A1.SS2.p4.6.m5.8.9.2.7" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.7.7" xref="A1.SS2.p4.6.m5.7.7.cmml">0.99</mn><mo id="A1.SS2.p4.6.m5.8.9.2.8" xref="A1.SS2.p4.6.m5.8.9.1.cmml">,</mo><mn id="A1.SS2.p4.6.m5.8.8" xref="A1.SS2.p4.6.m5.8.8.cmml">0.997</mn><mo stretchy="false" id="A1.SS2.p4.6.m5.8.9.2.9" xref="A1.SS2.p4.6.m5.8.9.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.6.m5.8b"><set id="A1.SS2.p4.6.m5.8.9.1.cmml" xref="A1.SS2.p4.6.m5.8.9.2"><cn type="float" id="A1.SS2.p4.6.m5.1.1.cmml" xref="A1.SS2.p4.6.m5.1.1">0.1</cn><cn type="float" id="A1.SS2.p4.6.m5.2.2.cmml" xref="A1.SS2.p4.6.m5.2.2">0.3</cn><cn type="float" id="A1.SS2.p4.6.m5.3.3.cmml" xref="A1.SS2.p4.6.m5.3.3">0.5</cn><cn type="float" id="A1.SS2.p4.6.m5.4.4.cmml" xref="A1.SS2.p4.6.m5.4.4">0.7</cn><cn type="float" id="A1.SS2.p4.6.m5.5.5.cmml" xref="A1.SS2.p4.6.m5.5.5">0.9</cn><cn type="float" id="A1.SS2.p4.6.m5.6.6.cmml" xref="A1.SS2.p4.6.m5.6.6">0.97</cn><cn type="float" id="A1.SS2.p4.6.m5.7.7.cmml" xref="A1.SS2.p4.6.m5.7.7">0.99</cn><cn type="float" id="A1.SS2.p4.6.m5.8.8.cmml" xref="A1.SS2.p4.6.m5.8.8">0.997</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.6.m5.8c">\{0.1,0.3,0.5,0.7,0.9,0.97,0.99,0.997\}</annotation></semantics></math> for FedAVGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, and is set to <math id="A1.SS2.p4.7.m6.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A1.SS2.p4.7.m6.1a"><mn id="A1.SS2.p4.7.m6.1.1" xref="A1.SS2.p4.7.m6.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.7.m6.1b"><cn type="float" id="A1.SS2.p4.7.m6.1.1.cmml" xref="A1.SS2.p4.7.m6.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.7.m6.1c">0.5</annotation></semantics></math> and <math id="A1.SS2.p4.8.m7.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="A1.SS2.p4.8.m7.1a"><mn id="A1.SS2.p4.8.m7.1.1" xref="A1.SS2.p4.8.m7.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.8.m7.1b"><cn type="float" id="A1.SS2.p4.8.m7.1.1.cmml" xref="A1.SS2.p4.8.m7.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.8.m7.1c">0.3</annotation></semantics></math> for Retina and CIFAR-<math id="A1.SS2.p4.9.m8.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p4.9.m8.1a"><mn id="A1.SS2.p4.9.m8.1.1" xref="A1.SS2.p4.9.m8.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.9.m8.1b"><cn type="integer" id="A1.SS2.p4.9.m8.1.1.cmml" xref="A1.SS2.p4.9.m8.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.9.m8.1c">10</annotation></semantics></math> dataset, respectively. In FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, <math id="A1.SS2.p4.10.m9.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="A1.SS2.p4.10.m9.1a"><mi id="A1.SS2.p4.10.m9.1.1" xref="A1.SS2.p4.10.m9.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.10.m9.1b"><ci id="A1.SS2.p4.10.m9.1.1.cmml" xref="A1.SS2.p4.10.m9.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.10.m9.1c">\mu</annotation></semantics></math> is set to <math id="A1.SS2.p4.11.m10.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.SS2.p4.11.m10.1a"><mn id="A1.SS2.p4.11.m10.1.1" xref="A1.SS2.p4.11.m10.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.11.m10.1b"><cn type="float" id="A1.SS2.p4.11.m10.1.1.cmml" xref="A1.SS2.p4.11.m10.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.11.m10.1c">0.001</annotation></semantics></math> for Retina dataset and <math id="A1.SS2.p4.12.m11.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.SS2.p4.12.m11.1a"><mn id="A1.SS2.p4.12.m11.1.1" xref="A1.SS2.p4.12.m11.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.12.m11.1b"><cn type="float" id="A1.SS2.p4.12.m11.1.1.cmml" xref="A1.SS2.p4.12.m11.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.12.m11.1c">0.1</annotation></semantics></math> for <span id="A1.SS2.p4.13.2" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.SS2.p4.13.2.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p4.13.2.m1.1a"><mn id="A1.SS2.p4.13.2.m1.1.1" xref="A1.SS2.p4.13.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.13.2.m1.1b"><cn type="integer" id="A1.SS2.p4.13.2.m1.1.1.cmml" xref="A1.SS2.p4.13.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.13.2.m1.1c">10</annotation></semantics></math></span> dataset by selecting from <math id="A1.SS2.p4.14.m12.4" class="ltx_Math" alttext="\{0.001,0.01,0.1,1\}" display="inline"><semantics id="A1.SS2.p4.14.m12.4a"><mrow id="A1.SS2.p4.14.m12.4.5.2" xref="A1.SS2.p4.14.m12.4.5.1.cmml"><mo stretchy="false" id="A1.SS2.p4.14.m12.4.5.2.1" xref="A1.SS2.p4.14.m12.4.5.1.cmml">{</mo><mn id="A1.SS2.p4.14.m12.1.1" xref="A1.SS2.p4.14.m12.1.1.cmml">0.001</mn><mo id="A1.SS2.p4.14.m12.4.5.2.2" xref="A1.SS2.p4.14.m12.4.5.1.cmml">,</mo><mn id="A1.SS2.p4.14.m12.2.2" xref="A1.SS2.p4.14.m12.2.2.cmml">0.01</mn><mo id="A1.SS2.p4.14.m12.4.5.2.3" xref="A1.SS2.p4.14.m12.4.5.1.cmml">,</mo><mn id="A1.SS2.p4.14.m12.3.3" xref="A1.SS2.p4.14.m12.3.3.cmml">0.1</mn><mo id="A1.SS2.p4.14.m12.4.5.2.4" xref="A1.SS2.p4.14.m12.4.5.1.cmml">,</mo><mn id="A1.SS2.p4.14.m12.4.4" xref="A1.SS2.p4.14.m12.4.4.cmml">1</mn><mo stretchy="false" id="A1.SS2.p4.14.m12.4.5.2.5" xref="A1.SS2.p4.14.m12.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.14.m12.4b"><set id="A1.SS2.p4.14.m12.4.5.1.cmml" xref="A1.SS2.p4.14.m12.4.5.2"><cn type="float" id="A1.SS2.p4.14.m12.1.1.cmml" xref="A1.SS2.p4.14.m12.1.1">0.001</cn><cn type="float" id="A1.SS2.p4.14.m12.2.2.cmml" xref="A1.SS2.p4.14.m12.2.2">0.01</cn><cn type="float" id="A1.SS2.p4.14.m12.3.3.cmml" xref="A1.SS2.p4.14.m12.3.3">0.1</cn><cn type="integer" id="A1.SS2.p4.14.m12.4.4.cmml" xref="A1.SS2.p4.14.m12.4.4">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.14.m12.4c">\{0.001,0.01,0.1,1\}</annotation></semantics></math>.</p>
</div>
<div id="A1.SS2.p5" class="ltx_para">
<p id="A1.SS2.p5.9" class="ltx_p">For the CelebA dataset, we randomly sample <math id="A1.SS2.p5.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p5.1.m1.1a"><mn id="A1.SS2.p5.1.m1.1.1" xref="A1.SS2.p5.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.1.m1.1b"><cn type="integer" id="A1.SS2.p5.1.m1.1.1.cmml" xref="A1.SS2.p5.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.1.m1.1c">10</annotation></semantics></math> clients in each round of FL learning for parallel FL methods. We set <math id="A1.SS2.p5.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="A1.SS2.p5.2.m2.1a"><mi id="A1.SS2.p5.2.m2.1.1" xref="A1.SS2.p5.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.2.m2.1b"><ci id="A1.SS2.p5.2.m2.1.1.cmml" xref="A1.SS2.p5.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.2.m2.1c">E</annotation></semantics></math> to <math id="A1.SS2.p5.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.SS2.p5.3.m3.1a"><mn id="A1.SS2.p5.3.m3.1.1" xref="A1.SS2.p5.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.3.m3.1b"><cn type="integer" id="A1.SS2.p5.3.m3.1.1.cmml" xref="A1.SS2.p5.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.3.m3.1c">1</annotation></semantics></math>, the maximum train round to <math id="A1.SS2.p5.4.m4.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS2.p5.4.m4.1a"><mn id="A1.SS2.p5.4.m4.1.1" xref="A1.SS2.p5.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.4.m4.1b"><cn type="integer" id="A1.SS2.p5.4.m4.1.1.cmml" xref="A1.SS2.p5.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.4.m4.1c">30</annotation></semantics></math> for CWT, and <math id="A1.SS2.p5.5.m5.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="A1.SS2.p5.5.m5.1a"><mn id="A1.SS2.p5.5.m5.1.1" xref="A1.SS2.p5.5.m5.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.5.m5.1b"><cn type="integer" id="A1.SS2.p5.5.m5.1.1.cmml" xref="A1.SS2.p5.5.m5.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.5.m5.1c">1000</annotation></semantics></math> for all the other parallel FL methods, to ensure each local client joins in FL training for around <math id="A1.SS2.p5.6.m6.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS2.p5.6.m6.1a"><mn id="A1.SS2.p5.6.m6.1.1" xref="A1.SS2.p5.6.m6.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.6.m6.1b"><cn type="integer" id="A1.SS2.p5.6.m6.1.1.cmml" xref="A1.SS2.p5.6.m6.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.6.m6.1c">30</annotation></semantics></math> rounds. <math id="A1.SS2.p5.7.m7.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="A1.SS2.p5.7.m7.1a"><mi id="A1.SS2.p5.7.m7.1.1" xref="A1.SS2.p5.7.m7.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.7.m7.1b"><ci id="A1.SS2.p5.7.m7.1.1.cmml" xref="A1.SS2.p5.7.m7.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.7.m7.1c">\mu</annotation></semantics></math> of FedProx is set to <math id="A1.SS2.p5.8.m8.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.SS2.p5.8.m8.1a"><mn id="A1.SS2.p5.8.m8.1.1" xref="A1.SS2.p5.8.m8.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.8.m8.1b"><cn type="float" id="A1.SS2.p5.8.m8.1.1.cmml" xref="A1.SS2.p5.8.m8.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.8.m8.1c">0.001</annotation></semantics></math> for CelebA dataset. We allow each client to share <math id="A1.SS2.p5.9.m9.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="A1.SS2.p5.9.m9.1a"><mrow id="A1.SS2.p5.9.m9.1.1" xref="A1.SS2.p5.9.m9.1.1.cmml"><mn id="A1.SS2.p5.9.m9.1.1.2" xref="A1.SS2.p5.9.m9.1.1.2.cmml">5</mn><mo id="A1.SS2.p5.9.m9.1.1.1" xref="A1.SS2.p5.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p5.9.m9.1b"><apply id="A1.SS2.p5.9.m9.1.1.cmml" xref="A1.SS2.p5.9.m9.1.1"><csymbol cd="latexml" id="A1.SS2.p5.9.m9.1.1.1.cmml" xref="A1.SS2.p5.9.m9.1.1.1">percent</csymbol><cn type="integer" id="A1.SS2.p5.9.m9.1.1.2.cmml" xref="A1.SS2.p5.9.m9.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p5.9.m9.1c">5\%</annotation></semantics></math> percentage of their data among each other for FedAVG-Share on all the compared datasets. The detailed hyperparameters are shown in Table <a href="#A1.T5" title="Table 5 ‣ A.2 Implementation Details and Hyperparameters ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a href="#A1.T6" title="Table 6 ‣ A.2 Implementation Details and Hyperparameters ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Please refer to our project page for an implementation to reproduce our results.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T5.14.4.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="A1.T5.6.3" class="ltx_text" style="font-size:90%;">Table of hyperparameters for experiments on <span id="A1.T5.6.3.2" class="ltx_text ltx_font_smallcaps">Retina</span> and <span id="A1.T5.4.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A1.T5.4.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.T5.4.1.1.m1.1b"><mn id="A1.T5.4.1.1.m1.1.1" xref="A1.T5.4.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.T5.4.1.1.m1.1c"><cn type="integer" id="A1.T5.4.1.1.m1.1.1.cmml" xref="A1.T5.4.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.4.1.1.m1.1d">10</annotation></semantics></math></span> with ResNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, EfficientNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, ViTs and Swins <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Gradient clip at global norm <math id="A1.T5.5.2.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.T5.5.2.m1.1b"><mn id="A1.T5.5.2.m1.1.1" xref="A1.T5.5.2.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.T5.5.2.m1.1c"><cn type="integer" id="A1.T5.5.2.m1.1.1.cmml" xref="A1.T5.5.2.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.5.2.m1.1d">1</annotation></semantics></math> are applied to all models to stabilize the training. The learning rate is halved every <math id="A1.T5.6.3.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.T5.6.3.m2.1b"><mn id="A1.T5.6.3.m2.1.1" xref="A1.T5.6.3.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.T5.6.3.m2.1c"><cn type="integer" id="A1.T5.6.3.m2.1.1.cmml" xref="A1.T5.6.3.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.6.3.m2.1d">30</annotation></semantics></math> epochs in the step decay scheduler.</span></figcaption>
<table id="A1.T5.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T5.11.6" class="ltx_tr">
<td id="A1.T5.11.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span>
Models</td>
<td id="A1.T5.11.6.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Dataset</td>
<td id="A1.T5.11.6.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Split type</td>
<td id="A1.T5.11.6.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Total Round</td>
<td id="A1.T5.11.6.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Optimizer type</td>
<td id="A1.T5.11.6.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Warm-steps</td>
<td id="A1.T5.11.6.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">LR decay</td>
<td id="A1.T5.11.6.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Base LR</td>
</tr>
<tr id="A1.T5.11.7" class="ltx_tr">
<td id="A1.T5.11.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span>
ResNets-CWT</td>
<td id="A1.T5.11.7.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.11.7.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.7.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.7.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.7.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.7.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.7.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.8" class="ltx_tr">
<td id="A1.T5.11.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">EfficientNets-CWT</td>
<td id="A1.T5.11.8.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina</td>
<td id="A1.T5.11.8.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.8.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.8.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">AdamW</td>
<td id="A1.T5.11.8.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.8.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.8.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.0005</td>
</tr>
<tr id="A1.T5.11.9" class="ltx_tr">
<td id="A1.T5.11.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">EfficietNets-CWT</td>
<td id="A1.T5.11.9.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">CIFAR-10</td>
<td id="A1.T5.11.9.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.9.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.9.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.9.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.9.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.9.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.10" class="ltx_tr">
<td id="A1.T5.11.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ViTs-CWT</td>
<td id="A1.T5.11.10.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.11.10.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.10.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.10.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.10.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.10.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.10.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.003</td>
</tr>
<tr id="A1.T5.7.1" class="ltx_tr">
<td id="A1.T5.7.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Swins-CWT</td>
<td id="A1.T5.7.1.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.7.1.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.7.1.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.7.1.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">AdamW</td>
<td id="A1.T5.7.1.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.7.1.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.7.1.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><math id="A1.T5.7.1.1.m1.1" class="ltx_Math" alttext="3.125\times 10^{-5}" display="inline"><semantics id="A1.T5.7.1.1.m1.1a"><mrow id="A1.T5.7.1.1.m1.1.1" xref="A1.T5.7.1.1.m1.1.1.cmml"><mn id="A1.T5.7.1.1.m1.1.1.2" xref="A1.T5.7.1.1.m1.1.1.2.cmml">3.125</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T5.7.1.1.m1.1.1.1" xref="A1.T5.7.1.1.m1.1.1.1.cmml">×</mo><msup id="A1.T5.7.1.1.m1.1.1.3" xref="A1.T5.7.1.1.m1.1.1.3.cmml"><mn id="A1.T5.7.1.1.m1.1.1.3.2" xref="A1.T5.7.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A1.T5.7.1.1.m1.1.1.3.3" xref="A1.T5.7.1.1.m1.1.1.3.3.cmml"><mo id="A1.T5.7.1.1.m1.1.1.3.3a" xref="A1.T5.7.1.1.m1.1.1.3.3.cmml">−</mo><mn id="A1.T5.7.1.1.m1.1.1.3.3.2" xref="A1.T5.7.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.7.1.1.m1.1b"><apply id="A1.T5.7.1.1.m1.1.1.cmml" xref="A1.T5.7.1.1.m1.1.1"><times id="A1.T5.7.1.1.m1.1.1.1.cmml" xref="A1.T5.7.1.1.m1.1.1.1"></times><cn type="float" id="A1.T5.7.1.1.m1.1.1.2.cmml" xref="A1.T5.7.1.1.m1.1.1.2">3.125</cn><apply id="A1.T5.7.1.1.m1.1.1.3.cmml" xref="A1.T5.7.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.T5.7.1.1.m1.1.1.3.1.cmml" xref="A1.T5.7.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="A1.T5.7.1.1.m1.1.1.3.2.cmml" xref="A1.T5.7.1.1.m1.1.1.3.2">10</cn><apply id="A1.T5.7.1.1.m1.1.1.3.3.cmml" xref="A1.T5.7.1.1.m1.1.1.3.3"><minus id="A1.T5.7.1.1.m1.1.1.3.3.1.cmml" xref="A1.T5.7.1.1.m1.1.1.3.3"></minus><cn type="integer" id="A1.T5.7.1.1.m1.1.1.3.3.2.cmml" xref="A1.T5.7.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.7.1.1.m1.1c">3.125\times 10^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A1.T5.11.11" class="ltx_tr">
<td id="A1.T5.11.11.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span>
ResNets-FedAVG</td>
<td id="A1.T5.11.11.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.11.11.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.11.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.11.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.11.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.11.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.11.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.12" class="ltx_tr">
<td id="A1.T5.11.12.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">EfficientNets-FedAVG</td>
<td id="A1.T5.11.12.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina</td>
<td id="A1.T5.11.12.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.12.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.12.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">AdamW</td>
<td id="A1.T5.11.12.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.12.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.12.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.0005</td>
</tr>
<tr id="A1.T5.11.13" class="ltx_tr">
<td id="A1.T5.11.13.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">EfficientNets-FedAVG</td>
<td id="A1.T5.11.13.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">CIFAR-10</td>
<td id="A1.T5.11.13.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.13.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.13.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.13.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.13.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.13.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.14" class="ltx_tr">
<td id="A1.T5.11.14.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ViTs-FedAVG</td>
<td id="A1.T5.11.14.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.11.14.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.14.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.14.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.14.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.14.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.14.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.8.2" class="ltx_tr">
<td id="A1.T5.8.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">Swins-FedAVG</td>
<td id="A1.T5.8.2.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-10</td>
<td id="A1.T5.8.2.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.8.2.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.8.2.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">AdamW</td>
<td id="A1.T5.8.2.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.8.2.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.8.2.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><math id="A1.T5.8.2.1.m1.1" class="ltx_Math" alttext="3.125\times 10^{-5}" display="inline"><semantics id="A1.T5.8.2.1.m1.1a"><mrow id="A1.T5.8.2.1.m1.1.1" xref="A1.T5.8.2.1.m1.1.1.cmml"><mn id="A1.T5.8.2.1.m1.1.1.2" xref="A1.T5.8.2.1.m1.1.1.2.cmml">3.125</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T5.8.2.1.m1.1.1.1" xref="A1.T5.8.2.1.m1.1.1.1.cmml">×</mo><msup id="A1.T5.8.2.1.m1.1.1.3" xref="A1.T5.8.2.1.m1.1.1.3.cmml"><mn id="A1.T5.8.2.1.m1.1.1.3.2" xref="A1.T5.8.2.1.m1.1.1.3.2.cmml">10</mn><mrow id="A1.T5.8.2.1.m1.1.1.3.3" xref="A1.T5.8.2.1.m1.1.1.3.3.cmml"><mo id="A1.T5.8.2.1.m1.1.1.3.3a" xref="A1.T5.8.2.1.m1.1.1.3.3.cmml">−</mo><mn id="A1.T5.8.2.1.m1.1.1.3.3.2" xref="A1.T5.8.2.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.8.2.1.m1.1b"><apply id="A1.T5.8.2.1.m1.1.1.cmml" xref="A1.T5.8.2.1.m1.1.1"><times id="A1.T5.8.2.1.m1.1.1.1.cmml" xref="A1.T5.8.2.1.m1.1.1.1"></times><cn type="float" id="A1.T5.8.2.1.m1.1.1.2.cmml" xref="A1.T5.8.2.1.m1.1.1.2">3.125</cn><apply id="A1.T5.8.2.1.m1.1.1.3.cmml" xref="A1.T5.8.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.T5.8.2.1.m1.1.1.3.1.cmml" xref="A1.T5.8.2.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="A1.T5.8.2.1.m1.1.1.3.2.cmml" xref="A1.T5.8.2.1.m1.1.1.3.2">10</cn><apply id="A1.T5.8.2.1.m1.1.1.3.3.cmml" xref="A1.T5.8.2.1.m1.1.1.3.3"><minus id="A1.T5.8.2.1.m1.1.1.3.3.1.cmml" xref="A1.T5.8.2.1.m1.1.1.3.3"></minus><cn type="integer" id="A1.T5.8.2.1.m1.1.1.3.3.2.cmml" xref="A1.T5.8.2.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.8.2.1.m1.1c">3.125\times 10^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A1.T5.11.15" class="ltx_tr">
<td id="A1.T5.11.15.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span>
ResNet(50)-FedAVGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="A1.T5.11.15.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina</td>
<td id="A1.T5.11.15.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.15.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.15.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.15.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0</td>
<td id="A1.T5.11.15.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">step</td>
<td id="A1.T5.11.15.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.9.3" class="ltx_tr">
<td id="A1.T5.9.3.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedAVGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="A1.T5.9.3.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">CIFAR-<math id="A1.T5.9.3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.T5.9.3.1.m1.1a"><mn id="A1.T5.9.3.1.m1.1.1" xref="A1.T5.9.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.T5.9.3.1.m1.1b"><cn type="integer" id="A1.T5.9.3.1.m1.1.1.cmml" xref="A1.T5.9.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.9.3.1.m1.1c">10</annotation></semantics></math>
</td>
<td id="A1.T5.9.3.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.9.3.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.9.3.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.9.3.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.9.3.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.9.3.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.16" class="ltx_tr">
<td id="A1.T5.11.16.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="A1.T5.11.16.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina</td>
<td id="A1.T5.11.16.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.16.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.16.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.16.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0</td>
<td id="A1.T5.11.16.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">step</td>
<td id="A1.T5.11.16.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.10.4" class="ltx_tr">
<td id="A1.T5.10.4.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="A1.T5.10.4.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">CIFAR-<math id="A1.T5.10.4.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.T5.10.4.1.m1.1a"><mn id="A1.T5.10.4.1.m1.1.1" xref="A1.T5.10.4.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.T5.10.4.1.m1.1b"><cn type="integer" id="A1.T5.10.4.1.m1.1.1.cmml" xref="A1.T5.10.4.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.10.4.1.m1.1c">10</annotation></semantics></math>
</td>
<td id="A1.T5.10.4.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.10.4.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.10.4.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.10.4.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.10.4.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.10.4.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.5" class="ltx_tr">
<td id="A1.T5.11.5.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>
</td>
<td id="A1.T5.11.5.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Retina &amp; CIFAR-<math id="A1.T5.11.5.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.T5.11.5.1.m1.1a"><mn id="A1.T5.11.5.1.m1.1.1" xref="A1.T5.11.5.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.T5.11.5.1.m1.1b"><cn type="integer" id="A1.T5.11.5.1.m1.1.1.cmml" xref="A1.T5.11.5.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.11.5.1.m1.1c">10</annotation></semantics></math>
</td>
<td id="A1.T5.11.5.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">All</td>
<td id="A1.T5.11.5.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">100</td>
<td id="A1.T5.11.5.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T5.11.5.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T5.11.5.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T5.11.5.8" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T5.11.17" class="ltx_tr">
<td id="A1.T5.11.17.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="A1.T5.11.17.2" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.3" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.4" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.5" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.6" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.7" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T5.11.17.8" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
</tr>
</table>
</figure>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T6.6.3.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="A1.T6.4.2" class="ltx_text" style="font-size:90%;">Table of hyperparameters for experiments on CelebA and OpenImage. All methods are optimized with SGD (momentum <math id="A1.T6.3.1.m1.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="A1.T6.3.1.m1.1b"><mn id="A1.T6.3.1.m1.1.1" xref="A1.T6.3.1.m1.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.T6.3.1.m1.1c"><cn type="float" id="A1.T6.3.1.m1.1.1.cmml" xref="A1.T6.3.1.m1.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.3.1.m1.1d">0.9</annotation></semantics></math> and no weight decay), and gradient clip at global norm <math id="A1.T6.4.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.T6.4.2.m2.1b"><mn id="A1.T6.4.2.m2.1.1" xref="A1.T6.4.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.T6.4.2.m2.1c"><cn type="integer" id="A1.T6.4.2.m2.1.1.cmml" xref="A1.T6.4.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.4.2.m2.1d">1</annotation></semantics></math>.</span></figcaption>
<table id="A1.T6.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T6.7.1" class="ltx_tr">
<td id="A1.T6.7.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span>
Models</td>
<td id="A1.T6.7.1.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Avg. Total Round</td>
<td id="A1.T6.7.1.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Warm-steps</td>
<td id="A1.T6.7.1.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Optimizer type</td>
<td id="A1.T6.7.1.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">LR decay</td>
<td id="A1.T6.7.1.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">Base LR</td>
</tr>
<tr id="A1.T6.7.2" class="ltx_tr">
<td id="A1.T6.7.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span>
ResNet(50)-CWT</td>
<td id="A1.T6.7.2.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.2.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.2.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.2.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.2.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T6.7.3" class="ltx_tr">
<td id="A1.T6.7.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedAVG</td>
<td id="A1.T6.7.3.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.3.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.3.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.3.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.3.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T6.7.4" class="ltx_tr">
<td id="A1.T6.7.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedProx</td>
<td id="A1.T6.7.4.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.4.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.4.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.4.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.4.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T6.7.5" class="ltx_tr">
<td id="A1.T6.7.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ResNet(50)-FedAVG-Share</td>
<td id="A1.T6.7.5.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.5.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.5.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.5.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.5.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T6.7.6" class="ltx_tr">
<td id="A1.T6.7.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ViT(S)-CWT</td>
<td id="A1.T6.7.6.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.6.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.6.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.6.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.6.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.003</td>
</tr>
<tr id="A1.T6.7.7" class="ltx_tr">
<td id="A1.T6.7.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">ViT(S)-FedAVG</td>
<td id="A1.T6.7.7.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">30</td>
<td id="A1.T6.7.7.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">500</td>
<td id="A1.T6.7.7.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">SGD</td>
<td id="A1.T6.7.7.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">cosine</td>
<td id="A1.T6.7.7.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">0.03</td>
</tr>
<tr id="A1.T6.7.8" class="ltx_tr">
<td id="A1.T6.7.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="A1.T6.7.8.2" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T6.7.8.3" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T6.7.8.4" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T6.7.8.5" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="A1.T6.7.8.6" class="ltx_td" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
</tr>
</table>
</figure>
<figure id="A1.F11" class="ltx_figure">
<table id="A1.F11.3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.F11.2.2.2" class="ltx_tr">
<td id="A1.F11.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2106.06047/assets/picture/Retina_comparison.jpg" id="A1.F11.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="295" height="168" alt="Refer to caption"></td>
<td id="A1.F11.2.2.2.2" class="ltx_td ltx_align_center">
<img src="/html/2106.06047/assets/picture/cifar10_comparison.jpg" id="A1.F11.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="299" height="171" alt="Refer to caption">
</td>
</tr>
<tr id="A1.F11.3.3.3" class="ltx_tr">
<td id="A1.F11.3.3.3.2" class="ltx_td ltx_align_center">Retina dataset</td>
<td id="A1.F11.3.3.3.1" class="ltx_td ltx_align_center">CIFAR-<math id="A1.F11.3.3.3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.F11.3.3.3.1.m1.1a"><mn id="A1.F11.3.3.3.1.m1.1.1" xref="A1.F11.3.3.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.F11.3.3.3.1.m1.1b"><cn type="integer" id="A1.F11.3.3.3.1.m1.1.1.cmml" xref="A1.F11.3.3.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.3.3.3.1.m1.1c">10</annotation></semantics></math> dataset</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.7.2.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A1.F11.5.1" class="ltx_text" style="font-size:90%;">Comparisons with state-of-the-art optimization based federated learning methods with ResNet-<math id="A1.F11.5.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="A1.F11.5.1.m1.1b"><mn id="A1.F11.5.1.m1.1.1" xref="A1.F11.5.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A1.F11.5.1.m1.1c"><cn type="integer" id="A1.F11.5.1.m1.1.1.cmml" xref="A1.F11.5.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.5.1.m1.1d">50</annotation></semantics></math> as backbone. Vision Transformer-based FL methods (ViT(S)-CWT and ViT(S)-FedAVG) outperform other methods in non-IID data partitions.</span></figcaption>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional Results</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Take-aways for Practical Usage</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">The training strategy of <span id="A2.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">ViT</span> in FL can be directly inherited from <span id="A2.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">ViT</span> training, such as using linear warm-up and learning rate decay, and gradient clip. We also notice that gradient clip stabilizes training for most FL methods on the highly heterogeneous data partition, and therefore can be applied as a general technique in FL applications (see Figure <a href="#A1.F10" title="Figure 10 ‣ A.1 Detailed Image Pre-processing and Data Partitions ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> of ViT(B)-FL and ResNet(50)-FedAVG with and without gradient clip). The training of <span id="A2.SS1.p1.1.3" class="ltx_text ltx_font_smallcaps">ViT</span>-CWT favors a relatively smaller learning rate on heterogeneous data partitions, whereas using a smaller learning rate for CNN counterparts leads to worse performance. In real-world applications, users can use a large learning rate for IID or mild-skewed data partitions for <span id="A2.SS1.p1.1.4" class="ltx_text ltx_font_smallcaps">ViT</span>-CWT, but a smaller learning rate is necessary to stabilize training for highly heterogeneous data partitions.</p>
</div>
<figure id="A2.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="A2.T7.12.2.1" class="ltx_text" style="font-size:113%;">Table 7</span>: </span><span id="A2.T7.2.1" class="ltx_text" style="font-size:113%;">Prediction accuracy (%) of CWT and FedAVG on <span id="A2.T7.2.1.2" class="ltx_text ltx_font_smallcaps">Retina</span> and <span id="A2.T7.2.1.1" class="ltx_text ltx_font_smallcaps">CIFAR-<math id="A2.T7.2.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.T7.2.1.1.m1.1b"><mn id="A2.T7.2.1.1.m1.1.1" xref="A2.T7.2.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.T7.2.1.1.m1.1c"><cn type="integer" id="A2.T7.2.1.1.m1.1.1.cmml" xref="A2.T7.2.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.2.1.1.m1.1d">10</annotation></semantics></math></span> when using ResNet50 and ResNet50(GN) as the backbone network. Replacing the batch normalization layer with group normalization in ResNet50 still suffers performance loss on highly heterogeneous data partitions, indicating that the promising performance of <span id="A2.T7.2.1.3" class="ltx_text ltx_font_smallcaps">ViT-FL</span> does not come purely from not using batch normalization.</span></figcaption>
<table id="A2.T7.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T7.3.1" class="ltx_tr">
<td id="A2.T7.3.1.2" class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="A2.T7.3.1.3" class="ltx_td ltx_align_center ltx_border_r" colspan="3"><span id="A2.T7.3.1.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">Retina</span></td>
<td id="A2.T7.3.1.1" class="ltx_td ltx_align_center" colspan="3"><span id="A2.T7.3.1.1.1" class="ltx_text ltx_font_smallcaps" style="font-size:80%;">CIFAR-<math id="A2.T7.3.1.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.T7.3.1.1.1.m1.1a"><mn id="A2.T7.3.1.1.1.m1.1.1" xref="A2.T7.3.1.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.T7.3.1.1.1.m1.1b"><cn type="integer" id="A2.T7.3.1.1.1.m1.1.1.cmml" xref="A2.T7.3.1.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.3.1.1.1.m1.1c">10</annotation></semantics></math></span></td>
</tr>
<tr id="A2.T7.3.2" class="ltx_tr">
<td id="A2.T7.3.2.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T7.3.2.2" class="ltx_td ltx_align_center"><span id="A2.T7.3.2.2.1" class="ltx_text" style="font-size:80%;">Split-1</span></td>
<td id="A2.T7.3.2.3" class="ltx_td ltx_align_center"><span id="A2.T7.3.2.3.1" class="ltx_text" style="font-size:80%;">Split-2</span></td>
<td id="A2.T7.3.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.2.4.1" class="ltx_text" style="font-size:80%;">Split-3</span></td>
<td id="A2.T7.3.2.5" class="ltx_td ltx_align_center"><span id="A2.T7.3.2.5.1" class="ltx_text" style="font-size:80%;">Split-1</span></td>
<td id="A2.T7.3.2.6" class="ltx_td ltx_align_center"><span id="A2.T7.3.2.6.1" class="ltx_text" style="font-size:80%;">Split-2</span></td>
<td id="A2.T7.3.2.7" class="ltx_td ltx_align_center"><span id="A2.T7.3.2.7.1" class="ltx_text" style="font-size:80%;">Split-3</span></td>
</tr>
<tr id="A2.T7.3.3" class="ltx_tr">
<td id="A2.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span><span id="A2.T7.3.3.1.1" class="ltx_text" style="font-size:80%;">
ResNet(50)-CWT</span>
</td>
<td id="A2.T7.3.3.2" class="ltx_td ltx_align_center"><span id="A2.T7.3.3.2.1" class="ltx_text" style="font-size:80%;">79.44</span></td>
<td id="A2.T7.3.3.3" class="ltx_td ltx_align_center"><span id="A2.T7.3.3.3.1" class="ltx_text" style="font-size:80%;">77.01</span></td>
<td id="A2.T7.3.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.3.4.1" class="ltx_text" style="font-size:80%;">71.30</span></td>
<td id="A2.T7.3.3.5" class="ltx_td ltx_align_center"><span id="A2.T7.3.3.5.1" class="ltx_text" style="font-size:80%;">96.08</span></td>
<td id="A2.T7.3.3.6" class="ltx_td ltx_align_center"><span id="A2.T7.3.3.6.1" class="ltx_text" style="font-size:80%;">56.46</span></td>
<td id="A2.T7.3.3.7" class="ltx_td ltx_align_center"><span id="A2.T7.3.3.7.1" class="ltx_text" style="font-size:80%;">19.92</span></td>
</tr>
<tr id="A2.T7.3.4" class="ltx_tr">
<td id="A2.T7.3.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.4.1.1" class="ltx_text" style="font-size:80%;">ResNet(50)(GN)-CWT</span></td>
<td id="A2.T7.3.4.2" class="ltx_td ltx_align_center"><span id="A2.T7.3.4.2.1" class="ltx_text" style="font-size:80%;">82.21</span></td>
<td id="A2.T7.3.4.3" class="ltx_td ltx_align_center"><span id="A2.T7.3.4.3.1" class="ltx_text" style="font-size:80%;">81.13</span></td>
<td id="A2.T7.3.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.4.4.1" class="ltx_text" style="font-size:80%;">77.05</span></td>
<td id="A2.T7.3.4.5" class="ltx_td ltx_align_center"><span id="A2.T7.3.4.5.1" class="ltx_text" style="font-size:80%;">95.10</span></td>
<td id="A2.T7.3.4.6" class="ltx_td ltx_align_center"><span id="A2.T7.3.4.6.1" class="ltx_text" style="font-size:80%;">93.87</span></td>
<td id="A2.T7.3.4.7" class="ltx_td ltx_align_center"><span id="A2.T7.3.4.7.1" class="ltx_text" style="font-size:80%;">87.70</span></td>
</tr>
<tr id="A2.T7.3.5" class="ltx_tr">
<td id="A2.T7.3.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.5.1.1" class="ltx_text" style="font-size:80%;">ResNet(50)-FedAVG</span></td>
<td id="A2.T7.3.5.2" class="ltx_td ltx_align_center"><span id="A2.T7.3.5.2.1" class="ltx_text" style="font-size:80%;">80.48</span></td>
<td id="A2.T7.3.5.3" class="ltx_td ltx_align_center"><span id="A2.T7.3.5.3.1" class="ltx_text" style="font-size:80%;">76.36</span></td>
<td id="A2.T7.3.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.5.4.1" class="ltx_text" style="font-size:80%;">75.99</span></td>
<td id="A2.T7.3.5.5" class="ltx_td ltx_align_center"><span id="A2.T7.3.5.5.1" class="ltx_text" style="font-size:80%;">96.51</span></td>
<td id="A2.T7.3.5.6" class="ltx_td ltx_align_center"><span id="A2.T7.3.5.6.1" class="ltx_text" style="font-size:80%;">93.14</span></td>
<td id="A2.T7.3.5.7" class="ltx_td ltx_align_center"><span id="A2.T7.3.5.7.1" class="ltx_text" style="font-size:80%;">59.68</span></td>
</tr>
<tr id="A2.T7.3.6" class="ltx_tr">
<td id="A2.T7.3.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.6.1.1" class="ltx_text" style="font-size:80%;">ResNet(50)(GN)-FedAVG</span></td>
<td id="A2.T7.3.6.2" class="ltx_td ltx_align_center"><span id="A2.T7.3.6.2.1" class="ltx_text" style="font-size:80%;">82.40</span></td>
<td id="A2.T7.3.6.3" class="ltx_td ltx_align_center"><span id="A2.T7.3.6.3.1" class="ltx_text" style="font-size:80%;">80.13</span></td>
<td id="A2.T7.3.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.3.6.4.1" class="ltx_text" style="font-size:80%;">80.57</span></td>
<td id="A2.T7.3.6.5" class="ltx_td ltx_align_center"><span id="A2.T7.3.6.5.1" class="ltx_text" style="font-size:80%;">96.39</span></td>
<td id="A2.T7.3.6.6" class="ltx_td ltx_align_center"><span id="A2.T7.3.6.6.1" class="ltx_text" style="font-size:80%;">95.12</span></td>
<td id="A2.T7.3.6.7" class="ltx_td ltx_align_center"><span id="A2.T7.3.6.7.1" class="ltx_text" style="font-size:80%;">86.20</span></td>
</tr>
<tr id="A2.T7.3.7" class="ltx_tr">
<td id="A2.T7.3.7.1" class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="A2.T7.3.7.2" class="ltx_td"></td>
<td id="A2.T7.3.7.3" class="ltx_td"></td>
<td id="A2.T7.3.7.4" class="ltx_td"></td>
<td id="A2.T7.3.7.5" class="ltx_td"></td>
<td id="A2.T7.3.7.6" class="ltx_td"></td>
<td id="A2.T7.3.7.7" class="ltx_td"></td>
</tr>
</table>
</figure>
<figure id="A2.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="A2.T8.10.1.1" class="ltx_text" style="font-size:113%;">Table 8</span>: </span><span id="A2.T8.11.2" class="ltx_text" style="font-size:113%;">Prediction accuracy (%) on a large-scale real world dataset OpenImage [Ref.A], covering 365 categories across 9,265 clients. <span id="A2.T8.11.2.1" class="ltx_text ltx_font_smallcaps">ViT</span>s significantly outperform their ResNet (R in Table) counterparts.</span></figcaption>
<div id="A2.T8.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:91.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(89.0pt,-18.8pt) scale(1.69610630008414,1.69610630008414) ;">
<table id="A2.T8.4.4" class="ltx_tabular ltx_align_middle">
<tr id="A2.T8.4.4.5" class="ltx_tr">
<td id="A2.T8.4.4.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span><span id="A2.T8.4.4.5.1.1" class="ltx_text" style="font-size:80%;">
R-CWT</span>
</td>
<td id="A2.T8.4.4.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.5.2.1" class="ltx_text" style="font-size:80%;">ViT-CWT</span></td>
<td id="A2.T8.4.4.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.5.3.1" class="ltx_text" style="font-size:80%;">R-FedAVG</span></td>
<td id="A2.T8.4.4.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.5.4.1" class="ltx_text" style="font-size:80%;">R-FedProx</span></td>
<td id="A2.T8.4.4.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.5.5.1" class="ltx_text" style="font-size:80%;">R-FedAVG-Share</span></td>
<td id="A2.T8.4.4.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.5.6.1" class="ltx_text" style="font-size:80%;">ViT-FedAVG</span></td>
</tr>
<tr id="A2.T8.4.4.4" class="ltx_tr">
<td id="A2.T8.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span class="ltx_rule" style="width:100%;height:0.2pt;background:black;display:inline-block;"> </span><span id="A2.T8.1.1.1.1.1" class="ltx_text" style="font-size:80%;">
</span><math id="A2.T8.1.1.1.1.m1.1" class="ltx_Math" alttext="41.62" display="inline"><semantics id="A2.T8.1.1.1.1.m1.1a"><mn mathsize="80%" id="A2.T8.1.1.1.1.m1.1.1" xref="A2.T8.1.1.1.1.m1.1.1.cmml">41.62</mn><annotation-xml encoding="MathML-Content" id="A2.T8.1.1.1.1.m1.1b"><cn type="float" id="A2.T8.1.1.1.1.m1.1.1.cmml" xref="A2.T8.1.1.1.1.m1.1.1">41.62</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.1.1.1.1.m1.1c">41.62</annotation></semantics></math>
</td>
<td id="A2.T8.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.2.2.2.2.1" class="ltx_text ltx_markedasmath ltx_font_bold" style="font-size:80%;">64.39</span></td>
<td id="A2.T8.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="A2.T8.3.3.3.3.m1.1" class="ltx_Math" alttext="50.92" display="inline"><semantics id="A2.T8.3.3.3.3.m1.1a"><mn mathsize="80%" id="A2.T8.3.3.3.3.m1.1.1" xref="A2.T8.3.3.3.3.m1.1.1.cmml">50.92</mn><annotation-xml encoding="MathML-Content" id="A2.T8.3.3.3.3.m1.1b"><cn type="float" id="A2.T8.3.3.3.3.m1.1.1.cmml" xref="A2.T8.3.3.3.3.m1.1.1">50.92</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T8.3.3.3.3.m1.1c">50.92</annotation></semantics></math></td>
<td id="A2.T8.4.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.4.5.1" class="ltx_text" style="font-size:80%;">51.39</span></td>
<td id="A2.T8.4.4.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.4.6.1" class="ltx_text" style="font-size:80%;">55.34</span></td>
<td id="A2.T8.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="A2.T8.4.4.4.4.1" class="ltx_text ltx_markedasmath ltx_font_bold" style="font-size:80%;">67.95</span></td>
</tr>
<tr id="A2.T8.4.4.6" class="ltx_tr">
<td id="A2.T8.4.4.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span class="ltx_rule" style="width:100%;height:1.2pt;background:black;display:inline-block;"> </span></td>
<td id="A2.T8.4.4.6.2" class="ltx_td" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="A2.T8.4.4.6.3" class="ltx_td" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="A2.T8.4.4.6.4" class="ltx_td" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="A2.T8.4.4.6.5" class="ltx_td" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="A2.T8.4.4.6.6" class="ltx_td" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Experiments on Real-World Federated Datasets</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">We further evaluate on a large-scale real-world dataset, OpenImage image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> collected from Flickr, containing 1.3M images spanning 600 categories across 14k clients. We select the categories with #samples per class between 20 and 800 from the dataset, resulting in 81,088 images spanning 365 categories across 9,265 clients. We use similar training parameters to CelebA for OpenImage, i.e., we randomly sample 10 clients in each round of FL learning for parallel FL methods. We set E to 1, the maximum train round to 30 for CWT, and 27,000 for all the other parallel FL methods, to ensure each
local client joins in FL training for around 30 rounds. From Table <a href="#A2.T8" title="Table 8 ‣ B.1 Take-aways for Practical Usage ‣ Appendix B Additional Results ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, <span id="A2.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">ViT</span> significantly outperforms ResNets on this heterogeneous large-scale real-world data partition, even outperforming ideal centrally-hosted models (60.56% for ResNet and 63.50% for <span id="A2.SS2.p1.1.2" class="ltx_text ltx_font_smallcaps">ViT</span> on centrally-hosted dataset)</p>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Investigating the Influence of Normalization Technique in <span id="A2.SS3.1.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span>
</h3>

<div id="A2.SS3.p1" class="ltx_para">
<p id="A2.SS3.p1.3" class="ltx_p">The batch normalization layer has been shown to be one of the major factors that deteriorate the performance of federated learning methods on non-IID data partitions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Hsieh <em id="A2.SS3.p1.3.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> demonstrate that group normalization (or layer normalization) can avoid the skew-induced accuracy loss of batch normalization on non-IID data. This may raise the question: does the promising performance of <span id="A2.SS3.p1.3.2" class="ltx_text ltx_font_smallcaps">ViT-FL</span> come purely from not using a batch normalization layer? To answer this question, we compare <span id="A2.SS3.p1.3.3" class="ltx_text ltx_font_smallcaps">ViT-FL</span> with FL-ResNet50 (GN) by replacing all batch normalization layers in ResNet(50) with group normalization. As shown in Table <a href="#A2.T7" title="Table 7 ‣ B.1 Take-aways for Practical Usage ‣ Appendix B Additional Results ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, group normalization indeed helps to obtain better performance for both CWT and FedAVG on mildly skewed data partitions than their batch normalization counterparts. For example, the performance on Split-2 of CIFAR-<math id="A2.SS3.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.SS3.p1.1.m1.1a"><mn id="A2.SS3.p1.1.m1.1.1" xref="A2.SS3.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.m1.1b"><cn type="integer" id="A2.SS3.p1.1.m1.1.1.cmml" xref="A2.SS3.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.m1.1c">10</annotation></semantics></math> is improved from original <math id="A2.SS3.p1.2.m2.1" class="ltx_Math" alttext="56.46\%" display="inline"><semantics id="A2.SS3.p1.2.m2.1a"><mrow id="A2.SS3.p1.2.m2.1.1" xref="A2.SS3.p1.2.m2.1.1.cmml"><mn id="A2.SS3.p1.2.m2.1.1.2" xref="A2.SS3.p1.2.m2.1.1.2.cmml">56.46</mn><mo id="A2.SS3.p1.2.m2.1.1.1" xref="A2.SS3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.2.m2.1b"><apply id="A2.SS3.p1.2.m2.1.1.cmml" xref="A2.SS3.p1.2.m2.1.1"><csymbol cd="latexml" id="A2.SS3.p1.2.m2.1.1.1.cmml" xref="A2.SS3.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="A2.SS3.p1.2.m2.1.1.2.cmml" xref="A2.SS3.p1.2.m2.1.1.2">56.46</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.2.m2.1c">56.46\%</annotation></semantics></math> to <math id="A2.SS3.p1.3.m3.1" class="ltx_Math" alttext="93.87\%" display="inline"><semantics id="A2.SS3.p1.3.m3.1a"><mrow id="A2.SS3.p1.3.m3.1.1" xref="A2.SS3.p1.3.m3.1.1.cmml"><mn id="A2.SS3.p1.3.m3.1.1.2" xref="A2.SS3.p1.3.m3.1.1.2.cmml">93.87</mn><mo id="A2.SS3.p1.3.m3.1.1.1" xref="A2.SS3.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.3.m3.1b"><apply id="A2.SS3.p1.3.m3.1.1.cmml" xref="A2.SS3.p1.3.m3.1.1"><csymbol cd="latexml" id="A2.SS3.p1.3.m3.1.1.1.cmml" xref="A2.SS3.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="A2.SS3.p1.3.m3.1.1.2.cmml" xref="A2.SS3.p1.3.m3.1.1.2">93.87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.3.m3.1c">93.87\%</annotation></semantics></math>. However, it still suffers performance loss on highly skewed data partitions. In contrast, <span id="A2.SS3.p1.3.4" class="ltx_text ltx_font_smallcaps">ViT-FL</span> consistently shows promising results on both mildly skewed and extremely highly skewed data partitions (see Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Federated Learning Methods ‣ 3 Transformers in Federated Learning ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> in main body paper for our results), indicating that the effectiveness <span id="A2.SS3.p1.3.5" class="ltx_text ltx_font_smallcaps">ViT-FL</span> does not arise purely from different normalization techniques.</p>
</div>
</section>
<section id="A2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Comparisons to Existing FL Methods</h3>

<div id="A2.SS4.p1" class="ltx_para">
<p id="A2.SS4.p1.3" class="ltx_p">We compare <span id="A2.SS4.p1.3.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> to several state-of-the-art optimization based FL methods: FedAVGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and FedAVG-Share <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.
We use ResNet-50 as the backbone network for all the compared FL methods. We tune the best parameters (including learning rate, momentum parameter <math id="A2.SS4.p1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A2.SS4.p1.1.m1.1a"><mi id="A2.SS4.p1.1.m1.1.1" xref="A2.SS4.p1.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A2.SS4.p1.1.m1.1b"><ci id="A2.SS4.p1.1.m1.1.1.cmml" xref="A2.SS4.p1.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p1.1.m1.1c">\beta</annotation></semantics></math> for FedAVGM, and penalty constant <math id="A2.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="A2.SS4.p1.2.m2.1a"><mi id="A2.SS4.p1.2.m2.1.1" xref="A2.SS4.p1.2.m2.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="A2.SS4.p1.2.m2.1b"><ci id="A2.SS4.p1.2.m2.1.1.cmml" xref="A2.SS4.p1.2.m2.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p1.2.m2.1c">\mu</annotation></semantics></math> in the proximal term of FedProx) on Split-2 dataset with grid search, and apply the same parameters to all the remaining data partitions. We allow each client to share <math id="A2.SS4.p1.3.m3.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="A2.SS4.p1.3.m3.1a"><mrow id="A2.SS4.p1.3.m3.1.1" xref="A2.SS4.p1.3.m3.1.1.cmml"><mn id="A2.SS4.p1.3.m3.1.1.2" xref="A2.SS4.p1.3.m3.1.1.2.cmml">5</mn><mo id="A2.SS4.p1.3.m3.1.1.1" xref="A2.SS4.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p1.3.m3.1b"><apply id="A2.SS4.p1.3.m3.1.1.cmml" xref="A2.SS4.p1.3.m3.1.1"><csymbol cd="latexml" id="A2.SS4.p1.3.m3.1.1.1.cmml" xref="A2.SS4.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="A2.SS4.p1.3.m3.1.1.2.cmml" xref="A2.SS4.p1.3.m3.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p1.3.m3.1c">5\%</annotation></semantics></math> percentage of their data among each other for FedAVG-Share.</p>
</div>
<div id="A2.SS4.p2" class="ltx_para">
<p id="A2.SS4.p2.4" class="ltx_p">As shown in Figure <a href="#A1.F11" title="Figure 11 ‣ A.2 Implementation Details and Hyperparameters ‣ Appendix A Experimental Details ‣ Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, <span id="A2.SS4.p2.4.1" class="ltx_text ltx_font_smallcaps">ViT-FL</span> outperforms all the other FL methods in non-IID data partitions. Both FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and FedAVGM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> suffer severe performance drops on highly heterogeneous data partitions despite carefully tuned optimization parameters. Similarly, FedAVG-Share also suffers from performance drops on highly heterogeneous data partition Split-3 even when <math id="A2.SS4.p2.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="A2.SS4.p2.1.m1.1a"><mrow id="A2.SS4.p2.1.m1.1.1" xref="A2.SS4.p2.1.m1.1.1.cmml"><mn id="A2.SS4.p2.1.m1.1.1.2" xref="A2.SS4.p2.1.m1.1.1.2.cmml">5</mn><mo id="A2.SS4.p2.1.m1.1.1.1" xref="A2.SS4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p2.1.m1.1b"><apply id="A2.SS4.p2.1.m1.1.1.cmml" xref="A2.SS4.p2.1.m1.1.1"><csymbol cd="latexml" id="A2.SS4.p2.1.m1.1.1.1.cmml" xref="A2.SS4.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.SS4.p2.1.m1.1.1.2.cmml" xref="A2.SS4.p2.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p2.1.m1.1c">5\%</annotation></semantics></math> percentage of the local data is shared among all clients (<math id="A2.SS4.p2.2.m2.1" class="ltx_Math" alttext="94.2\%" display="inline"><semantics id="A2.SS4.p2.2.m2.1a"><mrow id="A2.SS4.p2.2.m2.1.1" xref="A2.SS4.p2.2.m2.1.1.cmml"><mn id="A2.SS4.p2.2.m2.1.1.2" xref="A2.SS4.p2.2.m2.1.1.2.cmml">94.2</mn><mo id="A2.SS4.p2.2.m2.1.1.1" xref="A2.SS4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p2.2.m2.1b"><apply id="A2.SS4.p2.2.m2.1.1.cmml" xref="A2.SS4.p2.2.m2.1.1"><csymbol cd="latexml" id="A2.SS4.p2.2.m2.1.1.1.cmml" xref="A2.SS4.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="A2.SS4.p2.2.m2.1.1.2.cmml" xref="A2.SS4.p2.2.m2.1.1.2">94.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p2.2.m2.1c">94.2\%</annotation></semantics></math> of Split-3 on CIFAR-<math id="A2.SS4.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.SS4.p2.3.m3.1a"><mn id="A2.SS4.p2.3.m3.1.1" xref="A2.SS4.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.SS4.p2.3.m3.1b"><cn type="integer" id="A2.SS4.p2.3.m3.1.1.cmml" xref="A2.SS4.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p2.3.m3.1c">10</annotation></semantics></math> dataset compared to <math id="A2.SS4.p2.4.m4.1" class="ltx_Math" alttext="96\%" display="inline"><semantics id="A2.SS4.p2.4.m4.1a"><mrow id="A2.SS4.p2.4.m4.1.1" xref="A2.SS4.p2.4.m4.1.1.cmml"><mn id="A2.SS4.p2.4.m4.1.1.2" xref="A2.SS4.p2.4.m4.1.1.2.cmml">96</mn><mo id="A2.SS4.p2.4.m4.1.1.1" xref="A2.SS4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p2.4.m4.1b"><apply id="A2.SS4.p2.4.m4.1.1.cmml" xref="A2.SS4.p2.4.m4.1.1"><csymbol cd="latexml" id="A2.SS4.p2.4.m4.1.1.1.cmml" xref="A2.SS4.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="A2.SS4.p2.4.m4.1.1.2.cmml" xref="A2.SS4.p2.4.m4.1.1.2">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p2.4.m4.1c">96\%</annotation></semantics></math> on Split-1). We conclude that simply using Transformers achieve superior performance than several recent methods designed for federated optimization, which often require careful tuning of optimization parameters.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2106.06046" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2106.06047" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2106.06047">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2106.06047" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2106.06048" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 05:14:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
