<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Preference Distillation for Personalized Generative Recommendation</title>
<!--Generated on Sat Jul  6 09:51:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.05033v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S1" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S2" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S2.SS1" title="In 2 Related Works â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>LLMs for Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S2.SS2" title="In 2 Related Works â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Structural Prompt</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S3" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Preliminary</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S3.SS1" title="In 3 Preliminary â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Recommendation Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S3.SS2" title="In 3 Preliminary â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Prompt Distillation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>User-Personalized Prompt</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.SS1" title="In 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Query Function</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.SS2" title="In 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Prompt-Component Weighting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.SS3" title="In 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Prompt Composition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.SS4" title="In 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Orthogonal Initialization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.SS5" title="In 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Training and Generative Recommendation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.SS1" title="In 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.SS2" title="In 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.SS3" title="In 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.SS4" title="In 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Implementation Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6.SS1" title="In 6 Results â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Sequential Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6.SS2" title="In 6 Results â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Top-n Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6.SS3" title="In 6 Results â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Explanation Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6.SS4" title="In 6 Results â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Training without Task-Specific Prompts</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S7" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S8" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Limitations and Ethical Concerns</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS1" title="In Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Sequential Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS2" title="In Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Top-n Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS3" title="In Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Explanation Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A2" title="In Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Training without Task-Specific Prompts</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Preference Distillation for Personalized Generative Recommendation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jerome Ramos â€ƒBin Wu â€ƒAldo Lipani
<br class="ltx_break"/>University College London, London, UK 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{jerome.ramos.20, bin.wu.23, aldo.lipani}@ucl.ac.uk</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Recently, researchers have investigated the capabilities of Large Language Models (LLMs) for generative recommender systems. Existing LLM-based recommender models are trained by adding user and item IDs to a discrete prompt template. However, the disconnect between IDs and natural language makes it difficult for the LLM to learn the relationship between users. To address this issue, we propose a PErsonAlized PrOmpt Distillation (PeaPOD) approach, to distill user preferences as personalized soft prompts. Considering the complexities of user preferences in the real world, we maintain a shared set of learnable prompts that are dynamically weighted based on the userâ€™s interests to construct the user-personalized prompt in a compositional manner. Experimental results on three real-world datasets demonstrate the effectiveness of our PeaPOD model on sequential recommendation, top-n recommendation, and explanation generation tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Preference Distillation for Personalized Generative Recommendation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Jerome Ramos â€ƒBin Wu â€ƒAldo Lipani</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1">University College London, London, UK</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.3.1.1">{jerome.ramos.20, bin.wu.23, aldo.lipani}@ucl.ac.uk</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommender systems <cite class="ltx_cite ltx_citemacro_cite">Ge etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib3" title="">2022</a>)</cite> have emerged as pivotal tools in guiding users through vast amounts of items and tailoring personalized experiences across various tasks, including sequential recommendation, top-n recommendation and explanation generation. Recently, recommender systems trained using large language models (LLMs), known as generative recommender systems, have unlocked the ability to perform multiple tasks with a single model.
It has been shown to perform well in a zero- and few-shot settingÂ <cite class="ltx_cite ltx_citemacro_cite">Sanner etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib23" title="">2023</a>)</cite> and can be further fine-tuned on a specific domain to improve performance Â <cite class="ltx_cite ltx_citemacro_cite">Ramos etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib21" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">P5 Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite> formulates recommendation as a text-to-text sequence task and trains the model to perform generative recommendation based on discrete prompt templates. User and item IDs serve as important identifiers for discrete prompt templates, beyond the simple semantic meaning within their word embeddings. Thus, the disconnect between IDs and natural language and the inherent rigidity of discrete prompts makes it difficult for the LLM to learn the relationship between users, limiting the effectiveness of this approach. <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">Prompt Distillation</span> has been proposed to distill the knowledge in discrete prompts into continuous prompt vectors which do not map to any specific wordsÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>.
However, the existing work distills the knowledge into global-shared prompts, which is in conflict with the fact that usersâ€™ personalized preferences greatly differ across the entire user population. Given that each user has their own unique preferences <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib30" title="">2022</a>)</cite>, it is imperative to design a method to effectively distill preferences for personalized recommendation.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">One intuitive way to introduce distilled preferences is to create unique prompts per user based solely on their individual interaction history. However, there are two key issues: (1) Distilling separated prompts for each user is costly and difficult, where the number of prompts increases with the number of the user and in most cases, each userâ€™s interaction history is too sparse to effectively personalize the recommender;
and (2) This approach does not allow the model to match users with similar interests, which has been shown to increase performance for traditional recommender models in a warm-start settingÂ <cite class="ltx_cite ltx_citemacro_cite">Koren etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib10" title="">2009</a>); Mnih and Salakhutdinov (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib16" title="">2007</a>); Cheng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib1" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we propose <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">PErsonAlized PrOmpt Distillation (PeaPOD)</span>, a more flexible and effective framework to distill user preferences as personalized soft prompts.
Specifically, we construct a set of decomposed prompt components, which maintains a many-to-many mapping between user preferences and continuous prompts. This is due to the compositional nature of user preferences, meaning that users might share similar interests but maintain their distinction as well. By updating only a small set of prompt components, we can efficiently share prompts among users rather than maintaining a unique prompt per user.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Moreover, to construct the many-to-many mapping <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib29" title="">2023</a>)</cite> between users and the distilled prompt components, we propose a compositional strategy to dynamically weight the prompts based on user preference.
First, we use matrix factorizationÂ <cite class="ltx_cite ltx_citemacro_cite">Koren etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib10" title="">2009</a>)</cite> to generate a user embedding, which compresses a userâ€™s interaction history into a high-dimensional space. The user embeddings are used to identify user preferences, helping to create a weighted summation of the decomposed prompt components, called the <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">user-personalized prompt</span>.
Importantly, the construction of the user-personalized prompt are dynamic across users but only maintains a limited set of shared prompt components.
From experiments across three datasets, PeaPOD is able to achieve state-of-the-art performance in three recommendation tasks. We provide all data and code used at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jeromeramos70/peapod" title="">https://github.com/jeromeramos70/peapod</a>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In summary, our key contributions are:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We provide a novel architecture, namely <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">PErsonAlized PrOmpt Distillation
(PeaPOD)</span>, to distill complex user preferences into a limited set of learnable prompts.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a compositional strategy, dynamically weighting the decomposed prompt components to construct the user-specific prompt based on user preference.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We conduct extensive experiments, showing the effectiveness and superiority of our proposed PeaPOD model.
</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>LLMs for Recommendation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In recent years, researchers have explored the effectiveness of using LLMs for recommendation. The two main methods of LLMs for recommender systems are (1) using the LLMâ€™s pre-trained knowledge to recommend items in a zero-shot or few-shot setting and (2) fine-tuning the model for a given domain.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">One advantage of LLMs is that they are pre-trained with a large amount of data from various domains. Thus, Â <cite class="ltx_cite ltx_citemacro_citet">Sanner etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib23" title="">2023</a>)</cite> crowdsourced a dataset of natural language summaries of user preferences and showed that prompting a language model with these user summaries yielded competitive performance with traditional baselines in a near cold-start setting. Â <cite class="ltx_cite ltx_citemacro_citet">Ramos etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib21" title="">2024</a>)</cite> showed that a generative recommendation system trained solely on natural language user profiles are also competitive with traditional recommender systems in a warm-start setting, with the added benefit of transparency and scrutability. In addition, the zero-shot prompting of GPT-4 has also beaten SOTA models in a conversational recommender settingÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib6" title="">2023</a>)</cite>. Although prompting LLMs can lead to strong performance in recommender tasks, they are heavily reliant on better content knowledge rather than collaborative knowledgeÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib6" title="">2023</a>); Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib31" title="">2024</a>)</cite>. Thus, if the item metadata is not already learned in the pre-trained knowledge base or if the target dataset users interact differently than the users that the LLM was originally trained on, the performance of the recommender system will suffer.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">To mitigate these issues, the model can be further fine-tuned on target datasets in order to train the model based on the given user population and add or update its knowledge on the item dataset. P5Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite> is the first work that trains a T5-basedÂ <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib19" title="">2020</a>)</cite> foundational recommender model to unify various recommendation tasks in a shared
framework. VIP5Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite> extended P5 to a multi-modal foundational recommender system. PODÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite> builds upon the P5 model and appends a task-specific, continuous prompt to the input to improve performance. Although these models pass in the user_id as inputs, they still do not leverage the collaborative information contained from similar users. In particular, they do not implement a user-specific component to identify and share knowledge between users with similar preferences. Previous work in continual learning for image classification has shown that an attention-based mechanism based on the image input is able to learn similarities across similar images to achieve state-of-the-art performanceÂ <cite class="ltx_cite ltx_citemacro_cite">Smith etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib24" title="">2023</a>)</cite>. In this work, we focus on adding an attention-based mechanism to our model in order to leverage the shared collaborative knowledge between users to improve the recommendation performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Structural Prompt</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">One issue with generative approaches to recommendation is how to effectively encode user-item interactions to use with LLMs. Researchers have proposed numerous methods to bridge the gap between item IDs and natural language. One option is to add the userâ€™s name and item title to the input prompt. However, this data may be unavailable or non-unique, making it difficult to personalize recommendations. Another option is to directly insert the user and item IDs to the discrete prompt template. However, LLMs are trained on natural language text rather than IDs, which limits the effectiveness of this approach.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">To tackle these issues, many researchers have explored how to effectively encode item IDs with LLMs. For example,Â <cite class="ltx_cite ltx_citemacro_citet">Rajput etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib20" title="">2023</a>)</cite> proposed using RQ-VAE with item metadata to generate semantically meaningful tuples of tokens to serve as the Semantic ID for each item. GPTRec uses a novel SVD tokenization method to generate quantized item embeddings based on user-item interactionsÂ <cite class="ltx_cite ltx_citemacro_cite">Petrov and Macdonald (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib18" title="">2023</a>)</cite>. Â <cite class="ltx_cite ltx_citemacro_citet">Tan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib26" title="">2024</a>)</cite> proposed training a textual ID generator alongside the LLM-based recommender to convert item ids to meaningful text descriptions. Although these approaches have improved item IDs encoding for generative recommendations, the effective encoding of user information remains largely unexplored. In particular, existing works do not tackle the problem of how to encode both a userâ€™s personalized preferences and the shared knowledge between similar users to an LLM. Thus, our work focuses on how to develop user-personalized prompts to improve the performance of a generative recommender system.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminary</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Recommendation Tasks</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.2">Following the existing worksÂ <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>, we focus mainly on three important recommendation tasks: (1) Sequential Recommendation, (2) Top-n Recommendation, and (3) Explanation Generation. Let <math alttext="u\in U" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">u</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><in id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ‘¢</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">u\in U</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_u âˆˆ italic_U</annotation></semantics></math> denote a user in the user set and <math alttext="i\in I" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">i</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">I</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘–</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">i\in I</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_i âˆˆ italic_I</annotation></semantics></math> denote an item in the item set across all three tasks. We aim to train a unified model to complete the following tasks:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.4"><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.4.1">Sequential Recommendation:</span> given a user <math alttext="u" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">italic_u</annotation></semantics></math> and a list of historical interactions in chronological order <math alttext="i_{1},i_{2},...i_{n-1}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.3"><semantics id="S3.I1.i1.p1.2.m2.3a"><mrow id="S3.I1.i1.p1.2.m2.3.3.3" xref="S3.I1.i1.p1.2.m2.3.3.4.cmml"><msub id="S3.I1.i1.p1.2.m2.1.1.1.1" xref="S3.I1.i1.p1.2.m2.1.1.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.1.1.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.1.1.2.cmml">i</mi><mn id="S3.I1.i1.p1.2.m2.1.1.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.I1.i1.p1.2.m2.3.3.3.4" xref="S3.I1.i1.p1.2.m2.3.3.4.cmml">,</mo><msub id="S3.I1.i1.p1.2.m2.2.2.2.2" xref="S3.I1.i1.p1.2.m2.2.2.2.2.cmml"><mi id="S3.I1.i1.p1.2.m2.2.2.2.2.2" xref="S3.I1.i1.p1.2.m2.2.2.2.2.2.cmml">i</mi><mn id="S3.I1.i1.p1.2.m2.2.2.2.2.3" xref="S3.I1.i1.p1.2.m2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.I1.i1.p1.2.m2.3.3.3.5" xref="S3.I1.i1.p1.2.m2.3.3.4.cmml">,</mo><mrow id="S3.I1.i1.p1.2.m2.3.3.3.3" xref="S3.I1.i1.p1.2.m2.3.3.3.3.cmml"><mi id="S3.I1.i1.p1.2.m2.3.3.3.3.2" mathvariant="normal" xref="S3.I1.i1.p1.2.m2.3.3.3.3.2.cmml">â€¦</mi><mo id="S3.I1.i1.p1.2.m2.3.3.3.3.1" xref="S3.I1.i1.p1.2.m2.3.3.3.3.1.cmml">â¢</mo><msub id="S3.I1.i1.p1.2.m2.3.3.3.3.3" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.cmml"><mi id="S3.I1.i1.p1.2.m2.3.3.3.3.3.2" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.2.cmml">i</mi><mrow id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.cmml"><mi id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.2" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.2.cmml">n</mi><mo id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.1" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.1.cmml">âˆ’</mo><mn id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.3" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.3.cmml">1</mn></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.3b"><list id="S3.I1.i1.p1.2.m2.3.3.4.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3"><apply id="S3.I1.i1.p1.2.m2.1.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.2.m2.1.1.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.1.1.2">ğ‘–</ci><cn id="S3.I1.i1.p1.2.m2.1.1.1.1.3.cmml" type="integer" xref="S3.I1.i1.p1.2.m2.1.1.1.1.3">1</cn></apply><apply id="S3.I1.i1.p1.2.m2.2.2.2.2.cmml" xref="S3.I1.i1.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.2.2.2.2.1.cmml" xref="S3.I1.i1.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.I1.i1.p1.2.m2.2.2.2.2.2.cmml" xref="S3.I1.i1.p1.2.m2.2.2.2.2.2">ğ‘–</ci><cn id="S3.I1.i1.p1.2.m2.2.2.2.2.3.cmml" type="integer" xref="S3.I1.i1.p1.2.m2.2.2.2.2.3">2</cn></apply><apply id="S3.I1.i1.p1.2.m2.3.3.3.3.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3"><times id="S3.I1.i1.p1.2.m2.3.3.3.3.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.1"></times><ci id="S3.I1.i1.p1.2.m2.3.3.3.3.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.2">â€¦</ci><apply id="S3.I1.i1.p1.2.m2.3.3.3.3.3.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.3.3.3.3.3.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3">subscript</csymbol><ci id="S3.I1.i1.p1.2.m2.3.3.3.3.3.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.2">ğ‘–</ci><apply id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3"><minus id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.1"></minus><ci id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.2">ğ‘›</ci><cn id="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.3.cmml" type="integer" xref="S3.I1.i1.p1.2.m2.3.3.3.3.3.3.3">1</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.3c">i_{1},i_{2},...i_{n-1}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.3d">italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ italic_i start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT</annotation></semantics></math>, the task is to predict the next item <math alttext="i_{n}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.3.m3.1"><semantics id="S3.I1.i1.p1.3.m3.1a"><msub id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml"><mi id="S3.I1.i1.p1.3.m3.1.1.2" xref="S3.I1.i1.p1.3.m3.1.1.2.cmml">i</mi><mi id="S3.I1.i1.p1.3.m3.1.1.3" xref="S3.I1.i1.p1.3.m3.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><apply id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.2">ğ‘–</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">i_{n}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> that <math alttext="u" class="ltx_Math" display="inline" id="S3.I1.i1.p1.4.m4.1"><semantics id="S3.I1.i1.p1.4.m4.1a"><mi id="S3.I1.i1.p1.4.m4.1.1" xref="S3.I1.i1.p1.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.4.m4.1b"><ci id="S3.I1.i1.p1.4.m4.1.1.cmml" xref="S3.I1.i1.p1.4.m4.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.4.m4.1d">italic_u</annotation></semantics></math> will interact with.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.2"><span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.2.1">Top-n Recommendation:</span> given a pool of randomly sampled items from <math alttext="I" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mi id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">italic_I</annotation></semantics></math>, the model must select the top <math alttext="N" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">italic_N</annotation></semantics></math> items that the user wants to interact with.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.5"><span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.5.1">Explanation Generation:</span> given a user <math alttext="u" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mi id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><ci id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">italic_u</annotation></semantics></math> and item <math alttext="i" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.p1.2.m2.1a"><mi id="S3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">italic_i</annotation></semantics></math>, the model must generate an explanation <math alttext="E_{u,i}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.3.m3.2"><semantics id="S3.I1.i3.p1.3.m3.2a"><msub id="S3.I1.i3.p1.3.m3.2.3" xref="S3.I1.i3.p1.3.m3.2.3.cmml"><mi id="S3.I1.i3.p1.3.m3.2.3.2" xref="S3.I1.i3.p1.3.m3.2.3.2.cmml">E</mi><mrow id="S3.I1.i3.p1.3.m3.2.2.2.4" xref="S3.I1.i3.p1.3.m3.2.2.2.3.cmml"><mi id="S3.I1.i3.p1.3.m3.1.1.1.1" xref="S3.I1.i3.p1.3.m3.1.1.1.1.cmml">u</mi><mo id="S3.I1.i3.p1.3.m3.2.2.2.4.1" xref="S3.I1.i3.p1.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.I1.i3.p1.3.m3.2.2.2.2" xref="S3.I1.i3.p1.3.m3.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.3.m3.2b"><apply id="S3.I1.i3.p1.3.m3.2.3.cmml" xref="S3.I1.i3.p1.3.m3.2.3"><csymbol cd="ambiguous" id="S3.I1.i3.p1.3.m3.2.3.1.cmml" xref="S3.I1.i3.p1.3.m3.2.3">subscript</csymbol><ci id="S3.I1.i3.p1.3.m3.2.3.2.cmml" xref="S3.I1.i3.p1.3.m3.2.3.2">ğ¸</ci><list id="S3.I1.i3.p1.3.m3.2.2.2.3.cmml" xref="S3.I1.i3.p1.3.m3.2.2.2.4"><ci id="S3.I1.i3.p1.3.m3.1.1.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1.1">ğ‘¢</ci><ci id="S3.I1.i3.p1.3.m3.2.2.2.2.cmml" xref="S3.I1.i3.p1.3.m3.2.2.2.2">ğ‘–</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.3.m3.2c">E_{u,i}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.3.m3.2d">italic_E start_POSTSUBSCRIPT italic_u , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> that explains why <math alttext="u" class="ltx_Math" display="inline" id="S3.I1.i3.p1.4.m4.1"><semantics id="S3.I1.i3.p1.4.m4.1a"><mi id="S3.I1.i3.p1.4.m4.1.1" xref="S3.I1.i3.p1.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.4.m4.1b"><ci id="S3.I1.i3.p1.4.m4.1.1.cmml" xref="S3.I1.i3.p1.4.m4.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.4.m4.1d">italic_u</annotation></semantics></math> likes/dislikes <math alttext="i" class="ltx_Math" display="inline" id="S3.I1.i3.p1.5.m5.1"><semantics id="S3.I1.i3.p1.5.m5.1a"><mi id="S3.I1.i3.p1.5.m5.1.1" xref="S3.I1.i3.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.5.m5.1b"><ci id="S3.I1.i3.p1.5.m5.1.1.cmml" xref="S3.I1.i3.p1.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.5.m5.1d">italic_i</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Importantly, the scope of our study focuses only on user and item IDs for recommendation and excludes additional information such as item metadata or user profiles because this information may be sensitive or unavailable.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Prompt Distillation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In traditional recommender systems, user and item IDs are commonly used to identify unique users and items. However, since these IDs are unique to the dataset and are not natural language text, it is necessary to perform additional fine-tuning to allow the LLM to effectively understand these IDs. The most common methodology is to train the model with <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">discrete prompt templates</span>. For example, in the case of explanation generation, the discrete prompt could be â€œExplain why <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p1.1.2">user_1234</span> enjoys <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p1.1.3">item_5678</span>â€. When using IDs with discrete prompt templates, recent research proposes adding an additional embedding space, called whole-word embeddings, so that the model can recognize which tokens belong to the appropriate IDÂ <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>. In particular, each ID consists of the same whole-word embedding and all other tokens are tokenized as normal.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Although discrete prompts can lead to good performance, they are inflexible and require manually crafted prompts. Thus, the performance of the model may depend strongly on how well the instructions were written. On the other hand, continuous prompts are dynamically adjusted and fine-tuned through techniques like soft prompt tuning, which optimizes prompts by learning continuous embeddings. This approach allows the model to learn regardless of the the quality of the prompt template. <cite class="ltx_cite ltx_citemacro_citet">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite> introduced <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.1">Prompt Distillation</span>, which distills discrete prompts into continuous prompt vectors. The authors used prompt distillation to add task-specific continuous prompts per recommendation task globally shared across all users to improve the modelâ€™s performance. Since this method adds a shared continuous prompt per recommendation task, we will refer to these continuous prompts as <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">task-specific prompts</span>. Although task-specific prompts were shown to improve performance in our recommendation tasks, they cannot express personalization because each user uses the exact same prompts. Thus, it is imperative to construct a new method to distill each userâ€™s preferences into a personalized soft prompt.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>User-Personalized Prompt</h2>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="142" id="S4.F1.g1" src="extracted/5714243/images/CODA.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Method to create the user-personalized prompt. The user embedding from matrix factorization is used to weight the decomposed prompt components. The distillled user preferences are then compositionally combined into a single soft prompt that can be passed to the model as input.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="140" id="S4.F2.g1" src="extracted/5714243/images/architecture.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Full PeaPOD model architecture. PeaPOD prepends two continuous prompts to the discrete prompt template: (1) a user-personalized prompt based on the userâ€™s preferences and (2) a global task-specific prompt shared across all users. We add the additional whole-word embedding to distinguish tokens belonging to a given ID and train an encoder-decoder model.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The goal of the <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">user-personalized prompt</span> is to distill user preferences into a soft prompt that is able to represent the userâ€™s personal interests while also leveraging collaborative knowledge between similar users. We maintain a set of <span class="ltx_text ltx_font_italic" id="S4.p1.1.2">decomposed prompt components</span>, which represents a many-to-many mapping between user preferences and continuous prompt vectors. This allows us to efficiently maintain a limited group of prompts and share knowledge across similar users. The decomposed prompt vectors are then dynamically weighted and combined based on the userâ€™s interaction history to form a single continuous prompt. Using this methodology, user with similar preferences should have similar weight distributions. For example, if a decomposed prompt component contained information about action movies, then all users with an affinity to actions movies will contribute significant weight to this prompt component.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Query Function</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.8">Since we want to weight the decomposed prompt components based on each userâ€™s preferences, we introduce a query function <math alttext="q(x)" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.2" xref="S4.SS1.p1.1.m1.1.2.cmml"><mi id="S4.SS1.p1.1.m1.1.2.2" xref="S4.SS1.p1.1.m1.1.2.2.cmml">q</mi><mo id="S4.SS1.p1.1.m1.1.2.1" xref="S4.SS1.p1.1.m1.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.p1.1.m1.1.2.3.2" xref="S4.SS1.p1.1.m1.1.2.cmml"><mo id="S4.SS1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S4.SS1.p1.1.m1.1.2.cmml">(</mo><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">x</mi><mo id="S4.SS1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S4.SS1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.2"><times id="S4.SS1.p1.1.m1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.1.2.1"></times><ci id="S4.SS1.p1.1.m1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.1.2.2">ğ‘</ci><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">q(x)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_q ( italic_x )</annotation></semantics></math>. The purpose of <math alttext="q(x)" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.2" xref="S4.SS1.p1.2.m2.1.2.cmml"><mi id="S4.SS1.p1.2.m2.1.2.2" xref="S4.SS1.p1.2.m2.1.2.2.cmml">q</mi><mo id="S4.SS1.p1.2.m2.1.2.1" xref="S4.SS1.p1.2.m2.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.p1.2.m2.1.2.3.2" xref="S4.SS1.p1.2.m2.1.2.cmml"><mo id="S4.SS1.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S4.SS1.p1.2.m2.1.2.cmml">(</mo><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">x</mi><mo id="S4.SS1.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S4.SS1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.2.cmml" xref="S4.SS1.p1.2.m2.1.2"><times id="S4.SS1.p1.2.m2.1.2.1.cmml" xref="S4.SS1.p1.2.m2.1.2.1"></times><ci id="S4.SS1.p1.2.m2.1.2.2.cmml" xref="S4.SS1.p1.2.m2.1.2.2">ğ‘</ci><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">q(x)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_q ( italic_x )</annotation></semantics></math> is to obtain an embedding that effectively captures a userâ€™s personalized interests. In our case, we choose to use a user embedding generated from matrix factorizationÂ <cite class="ltx_cite ltx_citemacro_cite">Koren etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib10" title="">2009</a>)</cite> as the query function. In particular, given a user-item feedback matrix <math alttext="A\in\mathbb{R}^{|U|\times|I|}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.2"><semantics id="S4.SS1.p1.3.m3.2a"><mrow id="S4.SS1.p1.3.m3.2.3" xref="S4.SS1.p1.3.m3.2.3.cmml"><mi id="S4.SS1.p1.3.m3.2.3.2" xref="S4.SS1.p1.3.m3.2.3.2.cmml">A</mi><mo id="S4.SS1.p1.3.m3.2.3.1" xref="S4.SS1.p1.3.m3.2.3.1.cmml">âˆˆ</mo><msup id="S4.SS1.p1.3.m3.2.3.3" xref="S4.SS1.p1.3.m3.2.3.3.cmml"><mi id="S4.SS1.p1.3.m3.2.3.3.2" xref="S4.SS1.p1.3.m3.2.3.3.2.cmml">â„</mi><mrow id="S4.SS1.p1.3.m3.2.2.2" xref="S4.SS1.p1.3.m3.2.2.2.cmml"><mrow id="S4.SS1.p1.3.m3.2.2.2.4.2" xref="S4.SS1.p1.3.m3.2.2.2.4.1.cmml"><mo id="S4.SS1.p1.3.m3.2.2.2.4.2.1" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.2.4.1.1.cmml">|</mo><mi id="S4.SS1.p1.3.m3.1.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.1.cmml">U</mi><mo id="S4.SS1.p1.3.m3.2.2.2.4.2.2" rspace="0.055em" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.2.4.1.1.cmml">|</mo></mrow><mo id="S4.SS1.p1.3.m3.2.2.2.3" rspace="0.222em" xref="S4.SS1.p1.3.m3.2.2.2.3.cmml">Ã—</mo><mrow id="S4.SS1.p1.3.m3.2.2.2.5.2" xref="S4.SS1.p1.3.m3.2.2.2.5.1.cmml"><mo id="S4.SS1.p1.3.m3.2.2.2.5.2.1" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.2.5.1.1.cmml">|</mo><mi id="S4.SS1.p1.3.m3.2.2.2.2" xref="S4.SS1.p1.3.m3.2.2.2.2.cmml">I</mi><mo id="S4.SS1.p1.3.m3.2.2.2.5.2.2" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.2.5.1.1.cmml">|</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.2b"><apply id="S4.SS1.p1.3.m3.2.3.cmml" xref="S4.SS1.p1.3.m3.2.3"><in id="S4.SS1.p1.3.m3.2.3.1.cmml" xref="S4.SS1.p1.3.m3.2.3.1"></in><ci id="S4.SS1.p1.3.m3.2.3.2.cmml" xref="S4.SS1.p1.3.m3.2.3.2">ğ´</ci><apply id="S4.SS1.p1.3.m3.2.3.3.cmml" xref="S4.SS1.p1.3.m3.2.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.2.3.3.1.cmml" xref="S4.SS1.p1.3.m3.2.3.3">superscript</csymbol><ci id="S4.SS1.p1.3.m3.2.3.3.2.cmml" xref="S4.SS1.p1.3.m3.2.3.3.2">â„</ci><apply id="S4.SS1.p1.3.m3.2.2.2.cmml" xref="S4.SS1.p1.3.m3.2.2.2"><times id="S4.SS1.p1.3.m3.2.2.2.3.cmml" xref="S4.SS1.p1.3.m3.2.2.2.3"></times><apply id="S4.SS1.p1.3.m3.2.2.2.4.1.cmml" xref="S4.SS1.p1.3.m3.2.2.2.4.2"><abs id="S4.SS1.p1.3.m3.2.2.2.4.1.1.cmml" xref="S4.SS1.p1.3.m3.2.2.2.4.2.1"></abs><ci id="S4.SS1.p1.3.m3.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1">ğ‘ˆ</ci></apply><apply id="S4.SS1.p1.3.m3.2.2.2.5.1.cmml" xref="S4.SS1.p1.3.m3.2.2.2.5.2"><abs id="S4.SS1.p1.3.m3.2.2.2.5.1.1.cmml" xref="S4.SS1.p1.3.m3.2.2.2.5.2.1"></abs><ci id="S4.SS1.p1.3.m3.2.2.2.2.cmml" xref="S4.SS1.p1.3.m3.2.2.2.2">ğ¼</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.2c">A\in\mathbb{R}^{|U|\times|I|}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.2d">italic_A âˆˆ blackboard_R start_POSTSUPERSCRIPT | italic_U | Ã— | italic_I | end_POSTSUPERSCRIPT</annotation></semantics></math>, the model learns a user embedding <math alttext="U\in\mathbb{R}^{|U|\times D}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.2" xref="S4.SS1.p1.4.m4.1.2.cmml"><mi id="S4.SS1.p1.4.m4.1.2.2" xref="S4.SS1.p1.4.m4.1.2.2.cmml">U</mi><mo id="S4.SS1.p1.4.m4.1.2.1" xref="S4.SS1.p1.4.m4.1.2.1.cmml">âˆˆ</mo><msup id="S4.SS1.p1.4.m4.1.2.3" xref="S4.SS1.p1.4.m4.1.2.3.cmml"><mi id="S4.SS1.p1.4.m4.1.2.3.2" xref="S4.SS1.p1.4.m4.1.2.3.2.cmml">â„</mi><mrow id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml"><mrow id="S4.SS1.p1.4.m4.1.1.1.3.2" xref="S4.SS1.p1.4.m4.1.1.1.3.1.cmml"><mo id="S4.SS1.p1.4.m4.1.1.1.3.2.1" stretchy="false" xref="S4.SS1.p1.4.m4.1.1.1.3.1.1.cmml">|</mo><mi id="S4.SS1.p1.4.m4.1.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.1.cmml">U</mi><mo id="S4.SS1.p1.4.m4.1.1.1.3.2.2" rspace="0.055em" stretchy="false" xref="S4.SS1.p1.4.m4.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="S4.SS1.p1.4.m4.1.1.1.2" rspace="0.222em" xref="S4.SS1.p1.4.m4.1.1.1.2.cmml">Ã—</mo><mi id="S4.SS1.p1.4.m4.1.1.1.4" xref="S4.SS1.p1.4.m4.1.1.1.4.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.2.cmml" xref="S4.SS1.p1.4.m4.1.2"><in id="S4.SS1.p1.4.m4.1.2.1.cmml" xref="S4.SS1.p1.4.m4.1.2.1"></in><ci id="S4.SS1.p1.4.m4.1.2.2.cmml" xref="S4.SS1.p1.4.m4.1.2.2">ğ‘ˆ</ci><apply id="S4.SS1.p1.4.m4.1.2.3.cmml" xref="S4.SS1.p1.4.m4.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.2.3.1.cmml" xref="S4.SS1.p1.4.m4.1.2.3">superscript</csymbol><ci id="S4.SS1.p1.4.m4.1.2.3.2.cmml" xref="S4.SS1.p1.4.m4.1.2.3.2">â„</ci><apply id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"><times id="S4.SS1.p1.4.m4.1.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.1.2"></times><apply id="S4.SS1.p1.4.m4.1.1.1.3.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.3.2"><abs id="S4.SS1.p1.4.m4.1.1.1.3.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.3.2.1"></abs><ci id="S4.SS1.p1.4.m4.1.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1">ğ‘ˆ</ci></apply><ci id="S4.SS1.p1.4.m4.1.1.1.4.cmml" xref="S4.SS1.p1.4.m4.1.1.1.4">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">U\in\mathbb{R}^{|U|\times D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_U âˆˆ blackboard_R start_POSTSUPERSCRIPT | italic_U | Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> and item embedding <math alttext="U\in\mathbb{R}^{|I|\times D}" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.2" xref="S4.SS1.p1.5.m5.1.2.cmml"><mi id="S4.SS1.p1.5.m5.1.2.2" xref="S4.SS1.p1.5.m5.1.2.2.cmml">U</mi><mo id="S4.SS1.p1.5.m5.1.2.1" xref="S4.SS1.p1.5.m5.1.2.1.cmml">âˆˆ</mo><msup id="S4.SS1.p1.5.m5.1.2.3" xref="S4.SS1.p1.5.m5.1.2.3.cmml"><mi id="S4.SS1.p1.5.m5.1.2.3.2" xref="S4.SS1.p1.5.m5.1.2.3.2.cmml">â„</mi><mrow id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml"><mrow id="S4.SS1.p1.5.m5.1.1.1.3.2" xref="S4.SS1.p1.5.m5.1.1.1.3.1.cmml"><mo id="S4.SS1.p1.5.m5.1.1.1.3.2.1" stretchy="false" xref="S4.SS1.p1.5.m5.1.1.1.3.1.1.cmml">|</mo><mi id="S4.SS1.p1.5.m5.1.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.1.cmml">I</mi><mo id="S4.SS1.p1.5.m5.1.1.1.3.2.2" rspace="0.055em" stretchy="false" xref="S4.SS1.p1.5.m5.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="S4.SS1.p1.5.m5.1.1.1.2" rspace="0.222em" xref="S4.SS1.p1.5.m5.1.1.1.2.cmml">Ã—</mo><mi id="S4.SS1.p1.5.m5.1.1.1.4" xref="S4.SS1.p1.5.m5.1.1.1.4.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.2.cmml" xref="S4.SS1.p1.5.m5.1.2"><in id="S4.SS1.p1.5.m5.1.2.1.cmml" xref="S4.SS1.p1.5.m5.1.2.1"></in><ci id="S4.SS1.p1.5.m5.1.2.2.cmml" xref="S4.SS1.p1.5.m5.1.2.2">ğ‘ˆ</ci><apply id="S4.SS1.p1.5.m5.1.2.3.cmml" xref="S4.SS1.p1.5.m5.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.2.3.1.cmml" xref="S4.SS1.p1.5.m5.1.2.3">superscript</csymbol><ci id="S4.SS1.p1.5.m5.1.2.3.2.cmml" xref="S4.SS1.p1.5.m5.1.2.3.2">â„</ci><apply id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"><times id="S4.SS1.p1.5.m5.1.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.2"></times><apply id="S4.SS1.p1.5.m5.1.1.1.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.3.2"><abs id="S4.SS1.p1.5.m5.1.1.1.3.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.3.2.1"></abs><ci id="S4.SS1.p1.5.m5.1.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1">ğ¼</ci></apply><ci id="S4.SS1.p1.5.m5.1.1.1.4.cmml" xref="S4.SS1.p1.5.m5.1.1.1.4">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">U\in\mathbb{R}^{|I|\times D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_U âˆˆ blackboard_R start_POSTSUPERSCRIPT | italic_I | Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="D" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mi id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><ci id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">italic_D</annotation></semantics></math> is the dimension size and <math alttext="|U|" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><mrow id="S4.SS1.p1.7.m7.1.2.2" xref="S4.SS1.p1.7.m7.1.2.1.cmml"><mo id="S4.SS1.p1.7.m7.1.2.2.1" stretchy="false" xref="S4.SS1.p1.7.m7.1.2.1.1.cmml">|</mo><mi id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">U</mi><mo id="S4.SS1.p1.7.m7.1.2.2.2" stretchy="false" xref="S4.SS1.p1.7.m7.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.2.1.cmml" xref="S4.SS1.p1.7.m7.1.2.2"><abs id="S4.SS1.p1.7.m7.1.2.1.1.cmml" xref="S4.SS1.p1.7.m7.1.2.2.1"></abs><ci id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">|U|</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">| italic_U |</annotation></semantics></math> and <math alttext="|I|" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1"><semantics id="S4.SS1.p1.8.m8.1a"><mrow id="S4.SS1.p1.8.m8.1.2.2" xref="S4.SS1.p1.8.m8.1.2.1.cmml"><mo id="S4.SS1.p1.8.m8.1.2.2.1" stretchy="false" xref="S4.SS1.p1.8.m8.1.2.1.1.cmml">|</mo><mi id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">I</mi><mo id="S4.SS1.p1.8.m8.1.2.2.2" stretchy="false" xref="S4.SS1.p1.8.m8.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><apply id="S4.SS1.p1.8.m8.1.2.1.cmml" xref="S4.SS1.p1.8.m8.1.2.2"><abs id="S4.SS1.p1.8.m8.1.2.1.1.cmml" xref="S4.SS1.p1.8.m8.1.2.2.1"></abs><ci id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">|I|</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.1d">| italic_I |</annotation></semantics></math> are the number of users and items, respectively. By using a user embedding as the query function, we can effectively encode user preferences into the shared set of prompt components.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Prompt-Component Weighting</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.4">We use an attention-based architectureÂ <cite class="ltx_cite ltx_citemacro_cite">Vaswani etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib28" title="">2017</a>)</cite> to attend the prompt components based on the userâ€™s personalized preferences. Let <math alttext="A\in\mathbb{R}^{M\times D}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">A</mi><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.3.3.2.cmml">M</mi><mo id="S4.SS2.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS2.p1.1.m1.1.1.3.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><in id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></in><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ğ´</ci><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">â„</ci><apply id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"><times id="S4.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.1"></times><ci id="S4.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.2">ğ‘€</ci><ci id="S4.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">A\in\mathbb{R}^{M\times D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_A âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_M Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> be a learnable attention vector, where <math alttext="M" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_M</annotation></semantics></math> is the number of decomposed prompt components. We calculate the element-wise multiplication between q(x) and <math alttext="A" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">italic_A</annotation></semantics></math> to obtain the attended query, denoted as <math alttext="\lambda" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mi id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">italic_Î»</annotation></semantics></math>. The attended query allows the model to focus on the most important aspects of the userâ€™s interaction history. To obtain the attended query we calculate:</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\lambda=q(x)\odot A" class="ltx_Math" display="block" id="S4.E1.m1.1"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.2" xref="S4.E1.m1.1.2.cmml"><mi id="S4.E1.m1.1.2.2" xref="S4.E1.m1.1.2.2.cmml">Î»</mi><mo id="S4.E1.m1.1.2.1" xref="S4.E1.m1.1.2.1.cmml">=</mo><mrow id="S4.E1.m1.1.2.3" xref="S4.E1.m1.1.2.3.cmml"><mrow id="S4.E1.m1.1.2.3.2" xref="S4.E1.m1.1.2.3.2.cmml"><mi id="S4.E1.m1.1.2.3.2.2" xref="S4.E1.m1.1.2.3.2.2.cmml">q</mi><mo id="S4.E1.m1.1.2.3.2.1" xref="S4.E1.m1.1.2.3.2.1.cmml">â¢</mo><mrow id="S4.E1.m1.1.2.3.2.3.2" xref="S4.E1.m1.1.2.3.2.cmml"><mo id="S4.E1.m1.1.2.3.2.3.2.1" stretchy="false" xref="S4.E1.m1.1.2.3.2.cmml">(</mo><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">x</mi><mo id="S4.E1.m1.1.2.3.2.3.2.2" rspace="0.055em" stretchy="false" xref="S4.E1.m1.1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.2.3.1" rspace="0.222em" xref="S4.E1.m1.1.2.3.1.cmml">âŠ™</mo><mi id="S4.E1.m1.1.2.3.3" xref="S4.E1.m1.1.2.3.3.cmml">A</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.2.cmml" xref="S4.E1.m1.1.2"><eq id="S4.E1.m1.1.2.1.cmml" xref="S4.E1.m1.1.2.1"></eq><ci id="S4.E1.m1.1.2.2.cmml" xref="S4.E1.m1.1.2.2">ğœ†</ci><apply id="S4.E1.m1.1.2.3.cmml" xref="S4.E1.m1.1.2.3"><csymbol cd="latexml" id="S4.E1.m1.1.2.3.1.cmml" xref="S4.E1.m1.1.2.3.1">direct-product</csymbol><apply id="S4.E1.m1.1.2.3.2.cmml" xref="S4.E1.m1.1.2.3.2"><times id="S4.E1.m1.1.2.3.2.1.cmml" xref="S4.E1.m1.1.2.3.2.1"></times><ci id="S4.E1.m1.1.2.3.2.2.cmml" xref="S4.E1.m1.1.2.3.2.2">ğ‘</ci><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">ğ‘¥</ci></apply><ci id="S4.E1.m1.1.2.3.3.cmml" xref="S4.E1.m1.1.2.3.3">ğ´</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\lambda=q(x)\odot A</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.1d">italic_Î» = italic_q ( italic_x ) âŠ™ italic_A</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.9">where <math alttext="\odot" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><mo id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">âŠ™</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\odot</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">âŠ™</annotation></semantics></math> is the element-wise product. We then calculate the cosine similarity, denoted as <math alttext="\gamma" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">italic_Î³</annotation></semantics></math>, between <math alttext="\lambda" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">italic_Î»</annotation></semantics></math> and <math alttext="K\in\mathbb{R}^{M\times D}" class="ltx_Math" display="inline" id="S4.SS2.p3.4.m4.1"><semantics id="S4.SS2.p3.4.m4.1a"><mrow id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mi id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">K</mi><mo id="S4.SS2.p3.4.m4.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS2.p3.4.m4.1.1.3" xref="S4.SS2.p3.4.m4.1.1.3.cmml"><mi id="S4.SS2.p3.4.m4.1.1.3.2" xref="S4.SS2.p3.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S4.SS2.p3.4.m4.1.1.3.3" xref="S4.SS2.p3.4.m4.1.1.3.3.cmml"><mi id="S4.SS2.p3.4.m4.1.1.3.3.2" xref="S4.SS2.p3.4.m4.1.1.3.3.2.cmml">M</mi><mo id="S4.SS2.p3.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p3.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS2.p3.4.m4.1.1.3.3.3" xref="S4.SS2.p3.4.m4.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><in id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1.1"></in><ci id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">ğ¾</ci><apply id="S4.SS2.p3.4.m4.1.1.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.4.m4.1.1.3.1.cmml" xref="S4.SS2.p3.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.4.m4.1.1.3.2.cmml" xref="S4.SS2.p3.4.m4.1.1.3.2">â„</ci><apply id="S4.SS2.p3.4.m4.1.1.3.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3"><times id="S4.SS2.p3.4.m4.1.1.3.3.1.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3.1"></times><ci id="S4.SS2.p3.4.m4.1.1.3.3.2.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3.2">ğ‘€</ci><ci id="S4.SS2.p3.4.m4.1.1.3.3.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">K\in\mathbb{R}^{M\times D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.4.m4.1d">italic_K âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_M Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="k_{M}\in K" class="ltx_Math" display="inline" id="S4.SS2.p3.5.m5.1"><semantics id="S4.SS2.p3.5.m5.1a"><mrow id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml"><msub id="S4.SS2.p3.5.m5.1.1.2" xref="S4.SS2.p3.5.m5.1.1.2.cmml"><mi id="S4.SS2.p3.5.m5.1.1.2.2" xref="S4.SS2.p3.5.m5.1.1.2.2.cmml">k</mi><mi id="S4.SS2.p3.5.m5.1.1.2.3" xref="S4.SS2.p3.5.m5.1.1.2.3.cmml">M</mi></msub><mo id="S4.SS2.p3.5.m5.1.1.1" xref="S4.SS2.p3.5.m5.1.1.1.cmml">âˆˆ</mo><mi id="S4.SS2.p3.5.m5.1.1.3" xref="S4.SS2.p3.5.m5.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><apply id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1"><in id="S4.SS2.p3.5.m5.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1.1"></in><apply id="S4.SS2.p3.5.m5.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.1.1.2.1.cmml" xref="S4.SS2.p3.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS2.p3.5.m5.1.1.2.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2.2">ğ‘˜</ci><ci id="S4.SS2.p3.5.m5.1.1.2.3.cmml" xref="S4.SS2.p3.5.m5.1.1.2.3">ğ‘€</ci></apply><ci id="S4.SS2.p3.5.m5.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">k_{M}\in K</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.5.m5.1d">italic_k start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT âˆˆ italic_K</annotation></semantics></math> is a learnable key that has a corresponding attention vector <math alttext="A_{M}" class="ltx_Math" display="inline" id="S4.SS2.p3.6.m6.1"><semantics id="S4.SS2.p3.6.m6.1a"><msub id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml"><mi id="S4.SS2.p3.6.m6.1.1.2" xref="S4.SS2.p3.6.m6.1.1.2.cmml">A</mi><mi id="S4.SS2.p3.6.m6.1.1.3" xref="S4.SS2.p3.6.m6.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><apply id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.6.m6.1.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.p3.6.m6.1.1.2.cmml" xref="S4.SS2.p3.6.m6.1.1.2">ğ´</ci><ci id="S4.SS2.p3.6.m6.1.1.3.cmml" xref="S4.SS2.p3.6.m6.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">A_{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.6.m6.1d">italic_A start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math> and prompt component <math alttext="p_{M}" class="ltx_Math" display="inline" id="S4.SS2.p3.7.m7.1"><semantics id="S4.SS2.p3.7.m7.1a"><msub id="S4.SS2.p3.7.m7.1.1" xref="S4.SS2.p3.7.m7.1.1.cmml"><mi id="S4.SS2.p3.7.m7.1.1.2" xref="S4.SS2.p3.7.m7.1.1.2.cmml">p</mi><mi id="S4.SS2.p3.7.m7.1.1.3" xref="S4.SS2.p3.7.m7.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m7.1b"><apply id="S4.SS2.p3.7.m7.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.7.m7.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.p3.7.m7.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.2">ğ‘</ci><ci id="S4.SS2.p3.7.m7.1.1.3.cmml" xref="S4.SS2.p3.7.m7.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m7.1c">p_{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.7.m7.1d">italic_p start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math>. The cosine similarity between the attended query <math alttext="\lambda" class="ltx_Math" display="inline" id="S4.SS2.p3.8.m8.1"><semantics id="S4.SS2.p3.8.m8.1a"><mi id="S4.SS2.p3.8.m8.1.1" xref="S4.SS2.p3.8.m8.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.8.m8.1b"><ci id="S4.SS2.p3.8.m8.1.1.cmml" xref="S4.SS2.p3.8.m8.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.8.m8.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.8.m8.1d">italic_Î»</annotation></semantics></math> and <math alttext="K" class="ltx_Math" display="inline" id="S4.SS2.p3.9.m9.1"><semantics id="S4.SS2.p3.9.m9.1a"><mi id="S4.SS2.p3.9.m9.1.1" xref="S4.SS2.p3.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.9.m9.1b"><ci id="S4.SS2.p3.9.m9.1.1.cmml" xref="S4.SS2.p3.9.m9.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.9.m9.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.9.m9.1d">italic_K</annotation></semantics></math> is used to determine the magnitude that each prompt component should receive, which we define as:</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\alpha=\gamma(\lambda,K)" class="ltx_Math" display="block" id="S4.E2.m1.2"><semantics id="S4.E2.m1.2a"><mrow id="S4.E2.m1.2.3" xref="S4.E2.m1.2.3.cmml"><mi id="S4.E2.m1.2.3.2" xref="S4.E2.m1.2.3.2.cmml">Î±</mi><mo id="S4.E2.m1.2.3.1" xref="S4.E2.m1.2.3.1.cmml">=</mo><mrow id="S4.E2.m1.2.3.3" xref="S4.E2.m1.2.3.3.cmml"><mi id="S4.E2.m1.2.3.3.2" xref="S4.E2.m1.2.3.3.2.cmml">Î³</mi><mo id="S4.E2.m1.2.3.3.1" xref="S4.E2.m1.2.3.3.1.cmml">â¢</mo><mrow id="S4.E2.m1.2.3.3.3.2" xref="S4.E2.m1.2.3.3.3.1.cmml"><mo id="S4.E2.m1.2.3.3.3.2.1" stretchy="false" xref="S4.E2.m1.2.3.3.3.1.cmml">(</mo><mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">Î»</mi><mo id="S4.E2.m1.2.3.3.3.2.2" xref="S4.E2.m1.2.3.3.3.1.cmml">,</mo><mi id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">K</mi><mo id="S4.E2.m1.2.3.3.3.2.3" stretchy="false" xref="S4.E2.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.2b"><apply id="S4.E2.m1.2.3.cmml" xref="S4.E2.m1.2.3"><eq id="S4.E2.m1.2.3.1.cmml" xref="S4.E2.m1.2.3.1"></eq><ci id="S4.E2.m1.2.3.2.cmml" xref="S4.E2.m1.2.3.2">ğ›¼</ci><apply id="S4.E2.m1.2.3.3.cmml" xref="S4.E2.m1.2.3.3"><times id="S4.E2.m1.2.3.3.1.cmml" xref="S4.E2.m1.2.3.3.1"></times><ci id="S4.E2.m1.2.3.3.2.cmml" xref="S4.E2.m1.2.3.3.2">ğ›¾</ci><interval closure="open" id="S4.E2.m1.2.3.3.3.1.cmml" xref="S4.E2.m1.2.3.3.3.2"><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">ğœ†</ci><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">ğ¾</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.2c">\alpha=\gamma(\lambda,K)</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.2d">italic_Î± = italic_Î³ ( italic_Î» , italic_K )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.3">where <math alttext="\alpha\in\mathbb{R}^{M\times D}" class="ltx_Math" display="inline" id="S4.SS2.p5.1.m1.1"><semantics id="S4.SS2.p5.1.m1.1a"><mrow id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">Î±</mi><mo id="S4.SS2.p5.1.m1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml"><mi id="S4.SS2.p5.1.m1.1.1.3.2" xref="S4.SS2.p5.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S4.SS2.p5.1.m1.1.1.3.3" xref="S4.SS2.p5.1.m1.1.1.3.3.cmml"><mi id="S4.SS2.p5.1.m1.1.1.3.3.2" xref="S4.SS2.p5.1.m1.1.1.3.3.2.cmml">M</mi><mo id="S4.SS2.p5.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p5.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS2.p5.1.m1.1.1.3.3.3" xref="S4.SS2.p5.1.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><in id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1"></in><ci id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">ğ›¼</ci><apply id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p5.1.m1.1.1.3.1.cmml" xref="S4.SS2.p5.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p5.1.m1.1.1.3.2.cmml" xref="S4.SS2.p5.1.m1.1.1.3.2">â„</ci><apply id="S4.SS2.p5.1.m1.1.1.3.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3.3"><times id="S4.SS2.p5.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p5.1.m1.1.1.3.3.1"></times><ci id="S4.SS2.p5.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p5.1.m1.1.1.3.3.2">ğ‘€</ci><ci id="S4.SS2.p5.1.m1.1.1.3.3.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">\alpha\in\mathbb{R}^{M\times D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.1.m1.1d">italic_Î± âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_M Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> is a weighting vector. Since <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.p5.2.m2.1"><semantics id="S4.SS2.p5.2.m2.1a"><mi id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><ci id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.2.m2.1d">italic_Î±</annotation></semantics></math> is updated during training, the model is able to update its representation of the user embedding rather than fixing it to a single representation. <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.p5.3.m3.1"><semantics id="S4.SS2.p5.3.m3.1a"><mi id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.1b"><ci id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.3.m3.1d">italic_Î±</annotation></semantics></math> can then be used to weight the prompt components based on attended query function. Thus, we can determine how much each preference should contribute to the userâ€™s overall user-personalized prompt.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Prompt Composition</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Finally, we introduce the user-personalized prompt <math alttext="P" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_P</annotation></semantics></math>, which is calculated as a weighted summation over the set of decomposed prompt components:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P=\sum_{M}\alpha_{M}p_{M}" class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mi id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">P</mi><mo id="S4.E3.m1.1.1.1" rspace="0.111em" xref="S4.E3.m1.1.1.1.cmml">=</mo><mrow id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><munder id="S4.E3.m1.1.1.3.1" xref="S4.E3.m1.1.1.3.1.cmml"><mo id="S4.E3.m1.1.1.3.1.2" movablelimits="false" xref="S4.E3.m1.1.1.3.1.2.cmml">âˆ‘</mo><mi id="S4.E3.m1.1.1.3.1.3" xref="S4.E3.m1.1.1.3.1.3.cmml">M</mi></munder><mrow id="S4.E3.m1.1.1.3.2" xref="S4.E3.m1.1.1.3.2.cmml"><msub id="S4.E3.m1.1.1.3.2.2" xref="S4.E3.m1.1.1.3.2.2.cmml"><mi id="S4.E3.m1.1.1.3.2.2.2" xref="S4.E3.m1.1.1.3.2.2.2.cmml">Î±</mi><mi id="S4.E3.m1.1.1.3.2.2.3" xref="S4.E3.m1.1.1.3.2.2.3.cmml">M</mi></msub><mo id="S4.E3.m1.1.1.3.2.1" xref="S4.E3.m1.1.1.3.2.1.cmml">â¢</mo><msub id="S4.E3.m1.1.1.3.2.3" xref="S4.E3.m1.1.1.3.2.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.2" xref="S4.E3.m1.1.1.3.2.3.2.cmml">p</mi><mi id="S4.E3.m1.1.1.3.2.3.3" xref="S4.E3.m1.1.1.3.2.3.3.cmml">M</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"></eq><ci id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2">ğ‘ƒ</ci><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><apply id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.1.1.cmml" xref="S4.E3.m1.1.1.3.1">subscript</csymbol><sum id="S4.E3.m1.1.1.3.1.2.cmml" xref="S4.E3.m1.1.1.3.1.2"></sum><ci id="S4.E3.m1.1.1.3.1.3.cmml" xref="S4.E3.m1.1.1.3.1.3">ğ‘€</ci></apply><apply id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3.2"><times id="S4.E3.m1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.3.2.1"></times><apply id="S4.E3.m1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.2.1.cmml" xref="S4.E3.m1.1.1.3.2.2">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2.2">ğ›¼</ci><ci id="S4.E3.m1.1.1.3.2.2.3.cmml" xref="S4.E3.m1.1.1.3.2.2.3">ğ‘€</ci></apply><apply id="S4.E3.m1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.2">ğ‘</ci><ci id="S4.E3.m1.1.1.3.2.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.3">ğ‘€</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">P=\sum_{M}\alpha_{M}p_{M}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">italic_P = âˆ‘ start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT italic_Î± start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS3.p1.4">where <math alttext="p\in\mathbb{R}^{L\times D\times M}" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m1.1"><semantics id="S4.SS3.p1.2.m1.1a"><mrow id="S4.SS3.p1.2.m1.1.1" xref="S4.SS3.p1.2.m1.1.1.cmml"><mi id="S4.SS3.p1.2.m1.1.1.2" xref="S4.SS3.p1.2.m1.1.1.2.cmml">p</mi><mo id="S4.SS3.p1.2.m1.1.1.1" xref="S4.SS3.p1.2.m1.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS3.p1.2.m1.1.1.3" xref="S4.SS3.p1.2.m1.1.1.3.cmml"><mi id="S4.SS3.p1.2.m1.1.1.3.2" xref="S4.SS3.p1.2.m1.1.1.3.2.cmml">â„</mi><mrow id="S4.SS3.p1.2.m1.1.1.3.3" xref="S4.SS3.p1.2.m1.1.1.3.3.cmml"><mi id="S4.SS3.p1.2.m1.1.1.3.3.2" xref="S4.SS3.p1.2.m1.1.1.3.3.2.cmml">L</mi><mo id="S4.SS3.p1.2.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p1.2.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS3.p1.2.m1.1.1.3.3.3" xref="S4.SS3.p1.2.m1.1.1.3.3.3.cmml">D</mi><mo id="S4.SS3.p1.2.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p1.2.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS3.p1.2.m1.1.1.3.3.4" xref="S4.SS3.p1.2.m1.1.1.3.3.4.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m1.1b"><apply id="S4.SS3.p1.2.m1.1.1.cmml" xref="S4.SS3.p1.2.m1.1.1"><in id="S4.SS3.p1.2.m1.1.1.1.cmml" xref="S4.SS3.p1.2.m1.1.1.1"></in><ci id="S4.SS3.p1.2.m1.1.1.2.cmml" xref="S4.SS3.p1.2.m1.1.1.2">ğ‘</ci><apply id="S4.SS3.p1.2.m1.1.1.3.cmml" xref="S4.SS3.p1.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m1.1.1.3.1.cmml" xref="S4.SS3.p1.2.m1.1.1.3">superscript</csymbol><ci id="S4.SS3.p1.2.m1.1.1.3.2.cmml" xref="S4.SS3.p1.2.m1.1.1.3.2">â„</ci><apply id="S4.SS3.p1.2.m1.1.1.3.3.cmml" xref="S4.SS3.p1.2.m1.1.1.3.3"><times id="S4.SS3.p1.2.m1.1.1.3.3.1.cmml" xref="S4.SS3.p1.2.m1.1.1.3.3.1"></times><ci id="S4.SS3.p1.2.m1.1.1.3.3.2.cmml" xref="S4.SS3.p1.2.m1.1.1.3.3.2">ğ¿</ci><ci id="S4.SS3.p1.2.m1.1.1.3.3.3.cmml" xref="S4.SS3.p1.2.m1.1.1.3.3.3">ğ·</ci><ci id="S4.SS3.p1.2.m1.1.1.3.3.4.cmml" xref="S4.SS3.p1.2.m1.1.1.3.3.4">ğ‘€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m1.1c">p\in\mathbb{R}^{L\times D\times M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m1.1d">italic_p âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_L Ã— italic_D Ã— italic_M end_POSTSUPERSCRIPT</annotation></semantics></math> is a decomposed prompt component and <math alttext="L" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m2.1"><semantics id="S4.SS3.p1.3.m2.1a"><mi id="S4.SS3.p1.3.m2.1.1" xref="S4.SS3.p1.3.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m2.1b"><ci id="S4.SS3.p1.3.m2.1.1.cmml" xref="S4.SS3.p1.3.m2.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m2.1d">italic_L</annotation></semantics></math> is the length of each prompt component. Each decomposed prompt component is a soft prompt that represents information that can be collaboratively shared across similar users. We base this idea on the assumption that users may share similar interests and this shared collaborative knowledge can be used to improve personalization. Our many-to-many mapping between user preferences and soft prompts are dynamically weighted using <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m3.1"><semantics id="S4.SS3.p1.4.m3.1a"><mi id="S4.SS3.p1.4.m3.1.1" xref="S4.SS3.p1.4.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m3.1b"><ci id="S4.SS3.p1.4.m3.1.1.cmml" xref="S4.SS3.p1.4.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m3.1d">italic_Î±</annotation></semantics></math> based on each userâ€™s interactions, distilling user preferences to a user-personalized prompt in a compositional manner. Notably, our model can capture the complexities of a personalized user profile while maintaining a fixed number of prompts. Since the user-personalized prompt focuses on the most important parts of the user embedding, our method is similar high dimension clustering, meaning that users with similar preferences will have similar user-personalized prompts. We show how to obtain the user-personalized prompt in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.F1" title="Figure 1 â€£ 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Orthogonal Initialization</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.14">To reduce interference in knowledge between prompt components, we can initialize <math alttext="P" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">italic_P</annotation></semantics></math>, <math alttext="K" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">italic_K</annotation></semantics></math>, and <math alttext="A" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.1"><semantics id="S4.SS4.p1.3.m3.1a"><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.1d">italic_A</annotation></semantics></math> orthogonally using QR Decomposition. Namely, let <math alttext="Z\in\mathbb{R}^{R\times C}" class="ltx_Math" display="inline" id="S4.SS4.p1.4.m4.1"><semantics id="S4.SS4.p1.4.m4.1a"><mrow id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml"><mi id="S4.SS4.p1.4.m4.1.1.2" xref="S4.SS4.p1.4.m4.1.1.2.cmml">Z</mi><mo id="S4.SS4.p1.4.m4.1.1.1" xref="S4.SS4.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS4.p1.4.m4.1.1.3" xref="S4.SS4.p1.4.m4.1.1.3.cmml"><mi id="S4.SS4.p1.4.m4.1.1.3.2" xref="S4.SS4.p1.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S4.SS4.p1.4.m4.1.1.3.3" xref="S4.SS4.p1.4.m4.1.1.3.3.cmml"><mi id="S4.SS4.p1.4.m4.1.1.3.3.2" xref="S4.SS4.p1.4.m4.1.1.3.3.2.cmml">R</mi><mo id="S4.SS4.p1.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS4.p1.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS4.p1.4.m4.1.1.3.3.3" xref="S4.SS4.p1.4.m4.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><apply id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1"><in id="S4.SS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1.1"></in><ci id="S4.SS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.p1.4.m4.1.1.2">ğ‘</ci><apply id="S4.SS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.p1.4.m4.1.1.3.1.cmml" xref="S4.SS4.p1.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS4.p1.4.m4.1.1.3.2.cmml" xref="S4.SS4.p1.4.m4.1.1.3.2">â„</ci><apply id="S4.SS4.p1.4.m4.1.1.3.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3.3"><times id="S4.SS4.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS4.p1.4.m4.1.1.3.3.1"></times><ci id="S4.SS4.p1.4.m4.1.1.3.3.2.cmml" xref="S4.SS4.p1.4.m4.1.1.3.3.2">ğ‘…</ci><ci id="S4.SS4.p1.4.m4.1.1.3.3.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3.3.3">ğ¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">Z\in\mathbb{R}^{R\times C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.4.m4.1d">italic_Z âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_R Ã— italic_C end_POSTSUPERSCRIPT</annotation></semantics></math> be a real matrix with <math alttext="R" class="ltx_Math" display="inline" id="S4.SS4.p1.5.m5.1"><semantics id="S4.SS4.p1.5.m5.1a"><mi id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><ci id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.5.m5.1d">italic_R</annotation></semantics></math> rows and <math alttext="C" class="ltx_Math" display="inline" id="S4.SS4.p1.6.m6.1"><semantics id="S4.SS4.p1.6.m6.1a"><mi id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><ci id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">C</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.6.m6.1d">italic_C</annotation></semantics></math> columns. <math alttext="Z" class="ltx_Math" display="inline" id="S4.SS4.p1.7.m7.1"><semantics id="S4.SS4.p1.7.m7.1a"><mi id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><ci id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">Z</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.7.m7.1d">italic_Z</annotation></semantics></math> can be broken into an orthogonal matrix <math alttext="Q" class="ltx_Math" display="inline" id="S4.SS4.p1.8.m8.1"><semantics id="S4.SS4.p1.8.m8.1a"><mi id="S4.SS4.p1.8.m8.1.1" xref="S4.SS4.p1.8.m8.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.8.m8.1b"><ci id="S4.SS4.p1.8.m8.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.8.m8.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.8.m8.1d">italic_Q</annotation></semantics></math> and upper matrix <math alttext="R" class="ltx_Math" display="inline" id="S4.SS4.p1.9.m9.1"><semantics id="S4.SS4.p1.9.m9.1a"><mi id="S4.SS4.p1.9.m9.1.1" xref="S4.SS4.p1.9.m9.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.9.m9.1b"><ci id="S4.SS4.p1.9.m9.1.1.cmml" xref="S4.SS4.p1.9.m9.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.9.m9.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.9.m9.1d">italic_R</annotation></semantics></math>. The columns of <math alttext="Q" class="ltx_Math" display="inline" id="S4.SS4.p1.10.m10.1"><semantics id="S4.SS4.p1.10.m10.1a"><mi id="S4.SS4.p1.10.m10.1.1" xref="S4.SS4.p1.10.m10.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.10.m10.1b"><ci id="S4.SS4.p1.10.m10.1.1.cmml" xref="S4.SS4.p1.10.m10.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.10.m10.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.10.m10.1d">italic_Q</annotation></semantics></math> will thus be a set of <math alttext="C" class="ltx_Math" display="inline" id="S4.SS4.p1.11.m11.1"><semantics id="S4.SS4.p1.11.m11.1a"><mi id="S4.SS4.p1.11.m11.1.1" xref="S4.SS4.p1.11.m11.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.11.m11.1b"><ci id="S4.SS4.p1.11.m11.1.1.cmml" xref="S4.SS4.p1.11.m11.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.11.m11.1c">C</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.11.m11.1d">italic_C</annotation></semantics></math> orthogonal unit vectors which we can use as the initial vectors. We can repeat this initialization process for matrices <math alttext="P" class="ltx_Math" display="inline" id="S4.SS4.p1.12.m12.1"><semantics id="S4.SS4.p1.12.m12.1a"><mi id="S4.SS4.p1.12.m12.1.1" xref="S4.SS4.p1.12.m12.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.12.m12.1b"><ci id="S4.SS4.p1.12.m12.1.1.cmml" xref="S4.SS4.p1.12.m12.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.12.m12.1c">P</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.12.m12.1d">italic_P</annotation></semantics></math>, <math alttext="K" class="ltx_Math" display="inline" id="S4.SS4.p1.13.m13.1"><semantics id="S4.SS4.p1.13.m13.1a"><mi id="S4.SS4.p1.13.m13.1.1" xref="S4.SS4.p1.13.m13.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.13.m13.1b"><ci id="S4.SS4.p1.13.m13.1.1.cmml" xref="S4.SS4.p1.13.m13.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.13.m13.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.13.m13.1d">italic_K</annotation></semantics></math>, and <math alttext="A" class="ltx_Math" display="inline" id="S4.SS4.p1.14.m14.1"><semantics id="S4.SS4.p1.14.m14.1a"><mi id="S4.SS4.p1.14.m14.1.1" xref="S4.SS4.p1.14.m14.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.14.m14.1b"><ci id="S4.SS4.p1.14.m14.1.1.cmml" xref="S4.SS4.p1.14.m14.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.14.m14.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.14.m14.1d">italic_A</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Training and Generative Recommendation</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">Using the task-alternated training strategy proposed byÂ <cite class="ltx_cite ltx_citemacro_citet">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>, we alternate the task trained for each batch. This allows us to save time during training because the samples in the batch have the same data format and will therefore be a similar length to one another. Importantly, task-alternated training did not show any degradation in generative recommendation performance versus traditional random batching strategiesÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>. We combine user-personalized prompts, task-specific prompts, and discrete prompts as input during training. We also add whole-word embeddings to help the model identify which tokens belong to a particular ID. We show the whole mode architecture in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S4.F2" title="Figure 2 â€£ 4 User-Personalized Prompt â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">As all the generative recommendation tasks are posed as a sequence-to-sequence task, we use the Negative Log-Likelihood (NLL) loss to optimize the model parameters <math alttext="\Theta" class="ltx_Math" display="inline" id="S4.SS5.p2.1.m1.1"><semantics id="S4.SS5.p2.1.m1.1a"><mi id="S4.SS5.p2.1.m1.1.1" mathvariant="normal" xref="S4.SS5.p2.1.m1.1.1.cmml">Î˜</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><ci id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1">Î˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">\Theta</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p2.1.m1.1d">roman_Î˜</annotation></semantics></math>.</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\Theta}=\frac{1}{|\mathcal{D}|}\sum_{(X,Y)\in\mathcal{D}}\frac{1}%
{|Y|}\sum_{t=1}^{|Y|}-\log p(y_{t}|Y_{&lt;t},X)" class="ltx_Math" display="block" id="S4.E4.m1.7"><semantics id="S4.E4.m1.7a"><mrow id="S4.E4.m1.7.7" xref="S4.E4.m1.7.7.cmml"><msub id="S4.E4.m1.7.7.3" xref="S4.E4.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.7.7.3.2" xref="S4.E4.m1.7.7.3.2.cmml">â„’</mi><mi id="S4.E4.m1.7.7.3.3" mathvariant="normal" xref="S4.E4.m1.7.7.3.3.cmml">Î˜</mi></msub><mo id="S4.E4.m1.7.7.2" xref="S4.E4.m1.7.7.2.cmml">=</mo><mrow id="S4.E4.m1.7.7.1" xref="S4.E4.m1.7.7.1.cmml"><mrow id="S4.E4.m1.7.7.1.3" xref="S4.E4.m1.7.7.1.3.cmml"><mfrac id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mn id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml">1</mn><mrow id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.2.cmml"><mo id="S4.E4.m1.1.1.1.3.1" stretchy="false" xref="S4.E4.m1.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml">ğ’Ÿ</mi><mo id="S4.E4.m1.1.1.1.3.2" stretchy="false" xref="S4.E4.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S4.E4.m1.7.7.1.3.1" xref="S4.E4.m1.7.7.1.3.1.cmml">â¢</mo><mrow id="S4.E4.m1.7.7.1.3.2" xref="S4.E4.m1.7.7.1.3.2.cmml"><munder id="S4.E4.m1.7.7.1.3.2.1" xref="S4.E4.m1.7.7.1.3.2.1.cmml"><mo id="S4.E4.m1.7.7.1.3.2.1.2" movablelimits="false" xref="S4.E4.m1.7.7.1.3.2.1.2.cmml">âˆ‘</mo><mrow id="S4.E4.m1.3.3.2" xref="S4.E4.m1.3.3.2.cmml"><mrow id="S4.E4.m1.3.3.2.4.2" xref="S4.E4.m1.3.3.2.4.1.cmml"><mo id="S4.E4.m1.3.3.2.4.2.1" stretchy="false" xref="S4.E4.m1.3.3.2.4.1.cmml">(</mo><mi id="S4.E4.m1.2.2.1.1" xref="S4.E4.m1.2.2.1.1.cmml">X</mi><mo id="S4.E4.m1.3.3.2.4.2.2" xref="S4.E4.m1.3.3.2.4.1.cmml">,</mo><mi id="S4.E4.m1.3.3.2.2" xref="S4.E4.m1.3.3.2.2.cmml">Y</mi><mo id="S4.E4.m1.3.3.2.4.2.3" stretchy="false" xref="S4.E4.m1.3.3.2.4.1.cmml">)</mo></mrow><mo id="S4.E4.m1.3.3.2.3" xref="S4.E4.m1.3.3.2.3.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.3.3.2.5" xref="S4.E4.m1.3.3.2.5.cmml">ğ’Ÿ</mi></mrow></munder><mrow id="S4.E4.m1.7.7.1.3.2.2" xref="S4.E4.m1.7.7.1.3.2.2.cmml"><mfrac id="S4.E4.m1.4.4" xref="S4.E4.m1.4.4.cmml"><mn id="S4.E4.m1.4.4.3" xref="S4.E4.m1.4.4.3.cmml">1</mn><mrow id="S4.E4.m1.4.4.1.3" xref="S4.E4.m1.4.4.1.2.cmml"><mo id="S4.E4.m1.4.4.1.3.1" stretchy="false" xref="S4.E4.m1.4.4.1.2.1.cmml">|</mo><mi id="S4.E4.m1.4.4.1.1" xref="S4.E4.m1.4.4.1.1.cmml">Y</mi><mo id="S4.E4.m1.4.4.1.3.2" stretchy="false" xref="S4.E4.m1.4.4.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S4.E4.m1.7.7.1.3.2.2.1" xref="S4.E4.m1.7.7.1.3.2.2.1.cmml">â¢</mo><munderover id="S4.E4.m1.7.7.1.3.2.2.2" xref="S4.E4.m1.7.7.1.3.2.2.2.cmml"><mo id="S4.E4.m1.7.7.1.3.2.2.2.2.2" movablelimits="false" rspace="0em" xref="S4.E4.m1.7.7.1.3.2.2.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E4.m1.7.7.1.3.2.2.2.2.3" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.cmml"><mi id="S4.E4.m1.7.7.1.3.2.2.2.2.3.2" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.2.cmml">t</mi><mo id="S4.E4.m1.7.7.1.3.2.2.2.2.3.1" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.1.cmml">=</mo><mn id="S4.E4.m1.7.7.1.3.2.2.2.2.3.3" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S4.E4.m1.5.5.1.3" xref="S4.E4.m1.5.5.1.2.cmml"><mo id="S4.E4.m1.5.5.1.3.1" stretchy="false" xref="S4.E4.m1.5.5.1.2.1.cmml">|</mo><mi id="S4.E4.m1.5.5.1.1" xref="S4.E4.m1.5.5.1.1.cmml">Y</mi><mo id="S4.E4.m1.5.5.1.3.2" stretchy="false" xref="S4.E4.m1.5.5.1.2.1.cmml">|</mo></mrow></munderover></mrow></mrow></mrow><mo id="S4.E4.m1.7.7.1.2" lspace="0em" xref="S4.E4.m1.7.7.1.2.cmml">âˆ’</mo><mrow id="S4.E4.m1.7.7.1.1" xref="S4.E4.m1.7.7.1.1.cmml"><mrow id="S4.E4.m1.7.7.1.1.3" xref="S4.E4.m1.7.7.1.1.3.cmml"><mi id="S4.E4.m1.7.7.1.1.3.1" xref="S4.E4.m1.7.7.1.1.3.1.cmml">log</mi><mo id="S4.E4.m1.7.7.1.1.3a" lspace="0.167em" xref="S4.E4.m1.7.7.1.1.3.cmml">â¡</mo><mi id="S4.E4.m1.7.7.1.1.3.2" xref="S4.E4.m1.7.7.1.1.3.2.cmml">p</mi></mrow><mo id="S4.E4.m1.7.7.1.1.2" xref="S4.E4.m1.7.7.1.1.2.cmml">â¢</mo><mrow id="S4.E4.m1.7.7.1.1.1.1" xref="S4.E4.m1.7.7.1.1.1.1.1.cmml"><mo id="S4.E4.m1.7.7.1.1.1.1.2" stretchy="false" xref="S4.E4.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.7.7.1.1.1.1.1" xref="S4.E4.m1.7.7.1.1.1.1.1.cmml"><msub id="S4.E4.m1.7.7.1.1.1.1.1.3" xref="S4.E4.m1.7.7.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.7.7.1.1.1.1.1.3.2" xref="S4.E4.m1.7.7.1.1.1.1.1.3.2.cmml">y</mi><mi id="S4.E4.m1.7.7.1.1.1.1.1.3.3" xref="S4.E4.m1.7.7.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S4.E4.m1.7.7.1.1.1.1.1.2" xref="S4.E4.m1.7.7.1.1.1.1.1.2.cmml">|</mo><mrow id="S4.E4.m1.7.7.1.1.1.1.1.1.1" xref="S4.E4.m1.7.7.1.1.1.1.1.1.2.cmml"><msub id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">Y</mi><mrow id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.1" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></mrow></msub><mo id="S4.E4.m1.7.7.1.1.1.1.1.1.1.2" xref="S4.E4.m1.7.7.1.1.1.1.1.1.2.cmml">,</mo><mi id="S4.E4.m1.6.6" xref="S4.E4.m1.6.6.cmml">X</mi></mrow></mrow><mo id="S4.E4.m1.7.7.1.1.1.1.3" stretchy="false" xref="S4.E4.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.7b"><apply id="S4.E4.m1.7.7.cmml" xref="S4.E4.m1.7.7"><eq id="S4.E4.m1.7.7.2.cmml" xref="S4.E4.m1.7.7.2"></eq><apply id="S4.E4.m1.7.7.3.cmml" xref="S4.E4.m1.7.7.3"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.3.1.cmml" xref="S4.E4.m1.7.7.3">subscript</csymbol><ci id="S4.E4.m1.7.7.3.2.cmml" xref="S4.E4.m1.7.7.3.2">â„’</ci><ci id="S4.E4.m1.7.7.3.3.cmml" xref="S4.E4.m1.7.7.3.3">Î˜</ci></apply><apply id="S4.E4.m1.7.7.1.cmml" xref="S4.E4.m1.7.7.1"><minus id="S4.E4.m1.7.7.1.2.cmml" xref="S4.E4.m1.7.7.1.2"></minus><apply id="S4.E4.m1.7.7.1.3.cmml" xref="S4.E4.m1.7.7.1.3"><times id="S4.E4.m1.7.7.1.3.1.cmml" xref="S4.E4.m1.7.7.1.3.1"></times><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"><divide id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.1.1"></divide><cn id="S4.E4.m1.1.1.3.cmml" type="integer" xref="S4.E4.m1.1.1.3">1</cn><apply id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.3"><abs id="S4.E4.m1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.3.1"></abs><ci id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1">ğ’Ÿ</ci></apply></apply><apply id="S4.E4.m1.7.7.1.3.2.cmml" xref="S4.E4.m1.7.7.1.3.2"><apply id="S4.E4.m1.7.7.1.3.2.1.cmml" xref="S4.E4.m1.7.7.1.3.2.1"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.1.3.2.1.1.cmml" xref="S4.E4.m1.7.7.1.3.2.1">subscript</csymbol><sum id="S4.E4.m1.7.7.1.3.2.1.2.cmml" xref="S4.E4.m1.7.7.1.3.2.1.2"></sum><apply id="S4.E4.m1.3.3.2.cmml" xref="S4.E4.m1.3.3.2"><in id="S4.E4.m1.3.3.2.3.cmml" xref="S4.E4.m1.3.3.2.3"></in><interval closure="open" id="S4.E4.m1.3.3.2.4.1.cmml" xref="S4.E4.m1.3.3.2.4.2"><ci id="S4.E4.m1.2.2.1.1.cmml" xref="S4.E4.m1.2.2.1.1">ğ‘‹</ci><ci id="S4.E4.m1.3.3.2.2.cmml" xref="S4.E4.m1.3.3.2.2">ğ‘Œ</ci></interval><ci id="S4.E4.m1.3.3.2.5.cmml" xref="S4.E4.m1.3.3.2.5">ğ’Ÿ</ci></apply></apply><apply id="S4.E4.m1.7.7.1.3.2.2.cmml" xref="S4.E4.m1.7.7.1.3.2.2"><times id="S4.E4.m1.7.7.1.3.2.2.1.cmml" xref="S4.E4.m1.7.7.1.3.2.2.1"></times><apply id="S4.E4.m1.4.4.cmml" xref="S4.E4.m1.4.4"><divide id="S4.E4.m1.4.4.2.cmml" xref="S4.E4.m1.4.4"></divide><cn id="S4.E4.m1.4.4.3.cmml" type="integer" xref="S4.E4.m1.4.4.3">1</cn><apply id="S4.E4.m1.4.4.1.2.cmml" xref="S4.E4.m1.4.4.1.3"><abs id="S4.E4.m1.4.4.1.2.1.cmml" xref="S4.E4.m1.4.4.1.3.1"></abs><ci id="S4.E4.m1.4.4.1.1.cmml" xref="S4.E4.m1.4.4.1.1">ğ‘Œ</ci></apply></apply><apply id="S4.E4.m1.7.7.1.3.2.2.2.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.1.3.2.2.2.1.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2">superscript</csymbol><apply id="S4.E4.m1.7.7.1.3.2.2.2.2.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.1.3.2.2.2.2.1.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2">subscript</csymbol><sum id="S4.E4.m1.7.7.1.3.2.2.2.2.2.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2.2.2"></sum><apply id="S4.E4.m1.7.7.1.3.2.2.2.2.3.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3"><eq id="S4.E4.m1.7.7.1.3.2.2.2.2.3.1.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.1"></eq><ci id="S4.E4.m1.7.7.1.3.2.2.2.2.3.2.cmml" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.2">ğ‘¡</ci><cn id="S4.E4.m1.7.7.1.3.2.2.2.2.3.3.cmml" type="integer" xref="S4.E4.m1.7.7.1.3.2.2.2.2.3.3">1</cn></apply></apply><apply id="S4.E4.m1.5.5.1.2.cmml" xref="S4.E4.m1.5.5.1.3"><abs id="S4.E4.m1.5.5.1.2.1.cmml" xref="S4.E4.m1.5.5.1.3.1"></abs><ci id="S4.E4.m1.5.5.1.1.cmml" xref="S4.E4.m1.5.5.1.1">ğ‘Œ</ci></apply></apply></apply></apply></apply><apply id="S4.E4.m1.7.7.1.1.cmml" xref="S4.E4.m1.7.7.1.1"><times id="S4.E4.m1.7.7.1.1.2.cmml" xref="S4.E4.m1.7.7.1.1.2"></times><apply id="S4.E4.m1.7.7.1.1.3.cmml" xref="S4.E4.m1.7.7.1.1.3"><log id="S4.E4.m1.7.7.1.1.3.1.cmml" xref="S4.E4.m1.7.7.1.1.3.1"></log><ci id="S4.E4.m1.7.7.1.1.3.2.cmml" xref="S4.E4.m1.7.7.1.1.3.2">ğ‘</ci></apply><apply id="S4.E4.m1.7.7.1.1.1.1.1.cmml" xref="S4.E4.m1.7.7.1.1.1.1"><csymbol cd="latexml" id="S4.E4.m1.7.7.1.1.1.1.1.2.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.2">conditional</csymbol><apply id="S4.E4.m1.7.7.1.1.1.1.1.3.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.7.7.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S4.E4.m1.7.7.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.3.3">ğ‘¡</ci></apply><list id="S4.E4.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1"><apply id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.2">ğ‘Œ</ci><apply id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3"><lt id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.7.7.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply><ci id="S4.E4.m1.6.6.cmml" xref="S4.E4.m1.6.6">ğ‘‹</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.7c">\mathcal{L}_{\Theta}=\frac{1}{|\mathcal{D}|}\sum_{(X,Y)\in\mathcal{D}}\frac{1}%
{|Y|}\sum_{t=1}^{|Y|}-\log p(y_{t}|Y_{&lt;t},X)</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.7d">caligraphic_L start_POSTSUBSCRIPT roman_Î˜ end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG | caligraphic_D | end_ARG âˆ‘ start_POSTSUBSCRIPT ( italic_X , italic_Y ) âˆˆ caligraphic_D end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG | italic_Y | end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_Y | end_POSTSUPERSCRIPT - roman_log italic_p ( italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_Y start_POSTSUBSCRIPT &lt; italic_t end_POSTSUBSCRIPT , italic_X )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.4">where <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S4.SS5.p3.1.m1.1"><semantics id="S4.SS5.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS5.p3.1.m1.1.1" xref="S4.SS5.p3.1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.m1.1b"><ci id="S4.SS5.p3.1.m1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.m1.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p3.1.m1.1d">caligraphic_D</annotation></semantics></math> is the training set that consists of input output pairs (X,Y) and <math alttext="\log p(y_{t}|Y_{&lt;t})" class="ltx_Math" display="inline" id="S4.SS5.p3.2.m2.1"><semantics id="S4.SS5.p3.2.m2.1a"><mrow id="S4.SS5.p3.2.m2.1.1" xref="S4.SS5.p3.2.m2.1.1.cmml"><mrow id="S4.SS5.p3.2.m2.1.1.3" xref="S4.SS5.p3.2.m2.1.1.3.cmml"><mi id="S4.SS5.p3.2.m2.1.1.3.1" xref="S4.SS5.p3.2.m2.1.1.3.1.cmml">log</mi><mo id="S4.SS5.p3.2.m2.1.1.3a" lspace="0.167em" xref="S4.SS5.p3.2.m2.1.1.3.cmml">â¡</mo><mi id="S4.SS5.p3.2.m2.1.1.3.2" xref="S4.SS5.p3.2.m2.1.1.3.2.cmml">p</mi></mrow><mo id="S4.SS5.p3.2.m2.1.1.2" xref="S4.SS5.p3.2.m2.1.1.2.cmml">â¢</mo><mrow id="S4.SS5.p3.2.m2.1.1.1.1" xref="S4.SS5.p3.2.m2.1.1.1.1.1.cmml"><mo id="S4.SS5.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S4.SS5.p3.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS5.p3.2.m2.1.1.1.1.1" xref="S4.SS5.p3.2.m2.1.1.1.1.1.cmml"><msub id="S4.SS5.p3.2.m2.1.1.1.1.1.2" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2.cmml"><mi id="S4.SS5.p3.2.m2.1.1.1.1.1.2.2" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2.2.cmml">y</mi><mi id="S4.SS5.p3.2.m2.1.1.1.1.1.2.3" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S4.SS5.p3.2.m2.1.1.1.1.1.1" xref="S4.SS5.p3.2.m2.1.1.1.1.1.1.cmml">|</mo><msub id="S4.SS5.p3.2.m2.1.1.1.1.1.3" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.cmml"><mi id="S4.SS5.p3.2.m2.1.1.1.1.1.3.2" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.2.cmml">Y</mi><mrow id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.cmml"><mi id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.2" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.1" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.3" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo id="S4.SS5.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S4.SS5.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.2.m2.1b"><apply id="S4.SS5.p3.2.m2.1.1.cmml" xref="S4.SS5.p3.2.m2.1.1"><times id="S4.SS5.p3.2.m2.1.1.2.cmml" xref="S4.SS5.p3.2.m2.1.1.2"></times><apply id="S4.SS5.p3.2.m2.1.1.3.cmml" xref="S4.SS5.p3.2.m2.1.1.3"><log id="S4.SS5.p3.2.m2.1.1.3.1.cmml" xref="S4.SS5.p3.2.m2.1.1.3.1"></log><ci id="S4.SS5.p3.2.m2.1.1.3.2.cmml" xref="S4.SS5.p3.2.m2.1.1.3.2">ğ‘</ci></apply><apply id="S4.SS5.p3.2.m2.1.1.1.1.1.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1"><csymbol cd="latexml" id="S4.SS5.p3.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S4.SS5.p3.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS5.p3.2.m2.1.1.1.1.1.2.1.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS5.p3.2.m2.1.1.1.1.1.2.2.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2.2">ğ‘¦</ci><ci id="S4.SS5.p3.2.m2.1.1.1.1.1.2.3.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S4.SS5.p3.2.m2.1.1.1.1.1.3.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS5.p3.2.m2.1.1.1.1.1.3.1.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS5.p3.2.m2.1.1.1.1.1.3.2.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.2">ğ‘Œ</ci><apply id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3"><lt id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.1.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.2.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.3.cmml" xref="S4.SS5.p3.2.m2.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.2.m2.1c">\log p(y_{t}|Y_{&lt;t})</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p3.2.m2.1d">roman_log italic_p ( italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_Y start_POSTSUBSCRIPT &lt; italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> is the probability of generating token <math alttext="y_{t}" class="ltx_Math" display="inline" id="S4.SS5.p3.3.m3.1"><semantics id="S4.SS5.p3.3.m3.1a"><msub id="S4.SS5.p3.3.m3.1.1" xref="S4.SS5.p3.3.m3.1.1.cmml"><mi id="S4.SS5.p3.3.m3.1.1.2" xref="S4.SS5.p3.3.m3.1.1.2.cmml">y</mi><mi id="S4.SS5.p3.3.m3.1.1.3" xref="S4.SS5.p3.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.3.m3.1b"><apply id="S4.SS5.p3.3.m3.1.1.cmml" xref="S4.SS5.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS5.p3.3.m3.1.1.1.cmml" xref="S4.SS5.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS5.p3.3.m3.1.1.2.cmml" xref="S4.SS5.p3.3.m3.1.1.2">ğ‘¦</ci><ci id="S4.SS5.p3.3.m3.1.1.3.cmml" xref="S4.SS5.p3.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.3.m3.1c">y_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p3.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, given input sequence <math alttext="X" class="ltx_Math" display="inline" id="S4.SS5.p3.4.m4.1"><semantics id="S4.SS5.p3.4.m4.1a"><mi id="S4.SS5.p3.4.m4.1.1" xref="S4.SS5.p3.4.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.4.m4.1b"><ci id="S4.SS5.p3.4.m4.1.1.cmml" xref="S4.SS5.p3.4.m4.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.4.m4.1c">X</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p3.4.m4.1d">italic_X</annotation></semantics></math> and the tokens previously generated.</p>
</div>
<div class="ltx_para" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.7">In addtion, the model must output a sequence of text that forms an item ID (or a natural language text in the case of explanation generation). For this task, we choose beam search, which is commonly used for its effectiveness in sequence-to-sequence generation. Suppose we set the number of beams to <math alttext="b" class="ltx_Math" display="inline" id="S4.SS5.p4.1.m1.1"><semantics id="S4.SS5.p4.1.m1.1a"><mi id="S4.SS5.p4.1.m1.1.1" xref="S4.SS5.p4.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.1.m1.1b"><ci id="S4.SS5.p4.1.m1.1.1.cmml" xref="S4.SS5.p4.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.1.m1.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.1.m1.1d">italic_b</annotation></semantics></math>. At each time step, are <math alttext="b" class="ltx_Math" display="inline" id="S4.SS5.p4.2.m2.1"><semantics id="S4.SS5.p4.2.m2.1a"><mi id="S4.SS5.p4.2.m2.1.1" xref="S4.SS5.p4.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.2.m2.1b"><ci id="S4.SS5.p4.2.m2.1.1.cmml" xref="S4.SS5.p4.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.2.m2.1d">italic_b</annotation></semantics></math> candidate sequences. In the next step, any word in the vocabulary <math alttext="V" class="ltx_Math" display="inline" id="S4.SS5.p4.3.m3.1"><semantics id="S4.SS5.p4.3.m3.1a"><mi id="S4.SS5.p4.3.m3.1.1" xref="S4.SS5.p4.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.3.m3.1b"><ci id="S4.SS5.p4.3.m3.1.1.cmml" xref="S4.SS5.p4.3.m3.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.3.m3.1c">V</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.3.m3.1d">italic_V</annotation></semantics></math> are appended to the end of the candidate sequences, resulting in <math alttext="b\times V" class="ltx_Math" display="inline" id="S4.SS5.p4.4.m4.1"><semantics id="S4.SS5.p4.4.m4.1a"><mrow id="S4.SS5.p4.4.m4.1.1" xref="S4.SS5.p4.4.m4.1.1.cmml"><mi id="S4.SS5.p4.4.m4.1.1.2" xref="S4.SS5.p4.4.m4.1.1.2.cmml">b</mi><mo id="S4.SS5.p4.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS5.p4.4.m4.1.1.1.cmml">Ã—</mo><mi id="S4.SS5.p4.4.m4.1.1.3" xref="S4.SS5.p4.4.m4.1.1.3.cmml">V</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.4.m4.1b"><apply id="S4.SS5.p4.4.m4.1.1.cmml" xref="S4.SS5.p4.4.m4.1.1"><times id="S4.SS5.p4.4.m4.1.1.1.cmml" xref="S4.SS5.p4.4.m4.1.1.1"></times><ci id="S4.SS5.p4.4.m4.1.1.2.cmml" xref="S4.SS5.p4.4.m4.1.1.2">ğ‘</ci><ci id="S4.SS5.p4.4.m4.1.1.3.cmml" xref="S4.SS5.p4.4.m4.1.1.3">ğ‘‰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.4.m4.1c">b\times V</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.4.m4.1d">italic_b Ã— italic_V</annotation></semantics></math> combinations. We can then select <math alttext="b" class="ltx_Math" display="inline" id="S4.SS5.p4.5.m5.1"><semantics id="S4.SS5.p4.5.m5.1a"><mi id="S4.SS5.p4.5.m5.1.1" xref="S4.SS5.p4.5.m5.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.5.m5.1b"><ci id="S4.SS5.p4.5.m5.1.1.cmml" xref="S4.SS5.p4.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.5.m5.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.5.m5.1d">italic_b</annotation></semantics></math> sequences that have the maximum log-likelihood. The LLM can continue this process until the candidate sequences reach a predefined maximum length. For sequential recommendation and top-<math alttext="N" class="ltx_Math" display="inline" id="S4.SS5.p4.6.m6.1"><semantics id="S4.SS5.p4.6.m6.1a"><mi id="S4.SS5.p4.6.m6.1.1" xref="S4.SS5.p4.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.6.m6.1b"><ci id="S4.SS5.p4.6.m6.1.1.cmml" xref="S4.SS5.p4.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.6.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.6.m6.1d">italic_N</annotation></semantics></math> recommendation, the <math alttext="b" class="ltx_Math" display="inline" id="S4.SS5.p4.7.m7.1"><semantics id="S4.SS5.p4.7.m7.1a"><mi id="S4.SS5.p4.7.m7.1.1" xref="S4.SS5.p4.7.m7.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.7.m7.1b"><ci id="S4.SS5.p4.7.m7.1.1.cmml" xref="S4.SS5.p4.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.7.m7.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p4.7.m7.1d">italic_b</annotation></semantics></math> candidate sequences form the recommendation list. For explanation, we select the sequence with the largest log-likelihood from the candidates.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setup</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">For experimentation, we use the Sports, Beauty, and Toys &amp; Games Dataset from AmazonÂ <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://jmcauley.ucsd.edu/data/amazon/</span></span></span>. We reuse the preprocessing steps and the 8:1:1 train/validation/test splits created byÂ <cite class="ltx_cite ltx_citemacro_citet">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>. Each sample consists of a user ID, an item ID, a text review, a rating, and a time stamp. We provide the dataset statistics in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.T1" title="Table 1 â€£ 5.1 Datasets â€£ 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">1</span></a>. For explanation generation, the Sentires toolkitÂ <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib34" title="">2014</a>)</cite> was used to extract ground-truth explanations for a given (user, item) pair. For sequential recommendation, the last item in a userâ€™s history is part of the test set, the penultimate item is part of the validation set, and all other items are included in the train set. To prevent data leakage, the same training split used for sequential recommendation is used for top-n recommendation. For reproducibility, we provide all code used in the supplementary materials section of our submission and will release the code publicly upon publication.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.2.1">Sports</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.3.1">Beauty</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S5.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.4.1">Toys</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.1.2.1.1">#Users</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.2">35,598</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.3">22,363</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.4">19,412</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.1.3.2.1">#Items</th>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.2">18,357</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.3">12,101</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.4">11,924</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.1.4.3.1">#Reviews</th>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.2">296,337</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.3">198,502</td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.4">167,597</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S5.T1.1.5.4.1">#Sparsity (%)</th>
<td class="ltx_td ltx_align_right ltx_border_b" id="S5.T1.1.5.4.2">0.0453</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S5.T1.1.5.4.3">0.0734</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S5.T1.1.5.4.4">0.0724</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Statistics of the datasets.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Baselines</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">For sequential recommendation, we compare our model with the following baselines: <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Caser</span>Â <cite class="ltx_cite ltx_citemacro_cite">Tang and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib27" title="">2018</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">HGN</span>Â <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib15" title="">2019</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">GRU4Rec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Jannach and Ludewig (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib7" title="">2017</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.4">BERT4Rec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Sun etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib25" title="">2019</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.5">FDSA</span>Â <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib33" title="">2019</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.6">SASRec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib8" title="">2018</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.7">P5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.8">VIP5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite>, and <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.9">POD</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">For top-n recommendation, we compare our method with: <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">MF</span>Â <cite class="ltx_cite ltx_citemacro_cite">Koren etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib10" title="">2009</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.2">MLP</span>Â <cite class="ltx_cite ltx_citemacro_cite">Cheng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib1" title="">2016</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.3">P5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.4">VIP5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite>, and <span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.5">POD</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">Finally, for explanation generation, we use the following baselines: <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Att2Seq</span>Â <cite class="ltx_cite ltx_citemacro_cite">Dong etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib2" title="">2017</a>)</cite>:, <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.2">NRT</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib11" title="">2020</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.3">PETER</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib12" title="">2021</a>)</cite>, and <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.4">POD</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>. For a fair comparison, we exclude P5 and VIP5 because we are focused exclusively on models that only use user and item IDs rather than additional user or item metadata.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance comparison on sequential recommendation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:153.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-114.4pt,40.4pt) scale(0.6546295014601,0.6546295014601) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T2.1.1.2.1.1" rowspan="2"><span class="ltx_text" id="S5.T2.1.1.2.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.1.1.2.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.1.1.2.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.1.1.2.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.1">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.2">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.3">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.4">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.5">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.6">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.7">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.8">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.9">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.10">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.11">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.3.2.12">NDCG@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.4.1.1">Caser</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.2">0.0116</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.3">0.0072</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.4">0.0194</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.4.1.5">0.0097</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.6">0.0205</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.7">0.0131</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.8">0.0347</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.4.1.9">0.0176</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.10">0.0166</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.11">0.0107</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.12">0.0270</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4.1.13">0.0141</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.5.2.1">HGN</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.2">0.0189</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.3">0.0120</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.4">0.0313</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.5.2.5">0.0159</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.6">0.0325</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.7">0.0206</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.8">0.0512</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.5.2.9">0.0266</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.10">0.0321</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.11">0.0221</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.12">0.0497</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.2.13">0.0277</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.6.3.1">GRU4Rec</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.2">0.0129</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.3">0.0086</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.4">0.0204</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.6.3.5">0.0110</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.6">0.0137</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.7">0.0099</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.8">0.0283</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.6.3.9">0.0137</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.10">0.0097</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.11">0.0059</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.12">0.0176</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.3.13">0.0084</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.7.4.1">BERT4Rec</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.2">0.0115</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.3">0.0075</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.4">0.0191</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.7.4.5">0.0099</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.6">0.0203</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.7">0.0124</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.8">0.0347</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.7.4.9">0.0170</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.10">0.0116</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.11">0.0071</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.12">0.0203</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.4.13">0.0099</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.8.5.1">FDSA</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.2">0.0182</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.3">0.0122</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.4">0.0288</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.8.5.5">0.0156</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.6">0.0267</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.7">0.0163</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.8">0.0407</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.8.5.9">0.0208</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.10">0.0228</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.11">0.0140</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.12">0.0381</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.5.13">0.0189</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.9.6.1">SASRec</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.2">0.0233</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.3">0.0154</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.4">0.0350</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.9.6.5">0.0192</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.6">0.0387</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.7">0.0249</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.8">0.0605</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.9.6.9">0.0318</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.10">0.0463</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.11">0.0306</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.12">0.0675</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.6.13">0.0374</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.1.1">S<sup class="ltx_sup" id="S5.T2.1.1.1.1.1">3</sup>-Rec</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.2">0.0251</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.3">0.0161</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.4">0.0364</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.1.5">0.0204</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.6">0.0387</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.7">0.0247</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.8">0.0607</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.1.9">0.0327</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.10">0.0443</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.11">0.0294</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.12">0.0640</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1.13">0.0376</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.10.7.1">P5</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.2">0.0272</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.3">0.0169</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.4">0.0361</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.10.7.5">0.0198</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.6">0.0530</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.7">0.0370</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.8">0.0659</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.10.7.9">0.0421</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.10">0.0460</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.11">0.0567</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.12">0.0709</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.7.13">0.0587</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.11.8.1">VIP5</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.2">0.0412</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.3">0.0345</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.4">0.0475</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.11.8.5">0.0365</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.11.8.6.1">0.0556</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.11.8.7.1">0.0427</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.8">0.0677</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.11.8.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.11.8.9.1">0.0467</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.10">0.0662</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.11">0.0577</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.12"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.11.8.12.1">0.0749</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.11.8.13">0.0604</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.12.9.1">POD</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.2.1">0.0496</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.3.1">0.0396</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.4.1">0.0576</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.12.9.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.5.1">0.0419</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.6">0.0537</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.7">0.0395</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.8.1">0.0688</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.12.9.9">0.0443</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.12.9.10.1">0.0691</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.11"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.12.9.11.1">0.0599</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.12">0.0742</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.12.9.13"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.12.9.13.1">0.0610</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.2.1">0.0505</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.3.1">0.0400</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.4.1">0.0611</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.1.13.10.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.5.1">0.0432</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.6.1">0.0588</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.7"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.7.1">0.0445</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.8"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.8.1">0.0738</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.1.13.10.9"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.9.1">0.0493</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.10"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.10.1">0.0692</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.13.10.11.1">0.0583</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.12"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.13.10.12.1">0.0787</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T2.1.1.13.10.13"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.1.1.13.10.13.1">0.0609</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance comparison on top-n recommendation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1" style="width:433.6pt;height:81.6pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-168.7pt,31.5pt) scale(0.562391219676058,0.562391219676058) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T3.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T3.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="S5.T3.1.1.1.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="S5.T3.1.1.1.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="S5.T3.1.1.1.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.1">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.2">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.3">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.4">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.5">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.6">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.7">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.8">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.9">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.10">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.11">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.12">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.13">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.14">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.1.1.2.2.15">NDCG@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.3.1.1">MF</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.2">0.0314</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.3">0.1404</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.4">0.0848</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.5">0.2563</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.1.6">0.1220</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.7">0.0311</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.8">0.1426</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.9">0.0857</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.10">0.2573</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.1.11">0.1224</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.12">0.0233</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.13">0.1066</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.14">0.0641</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.15">0.2003</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3.1.16">0.0940</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.4.2.1">MLP</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.2">0.0351</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.3">0.1520</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.4">0.0927</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.5">0.2671</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.4.2.6">0.1296</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.7">0.0317</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.8">0.1392</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.9">0.0848</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.10">0.2542</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.4.2.11">0.1215</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.12">0.0252</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.13">0.1142</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.14">0.0688</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.15">0.2077</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.2.16">0.0988</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.5.3.1">P5</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.2">0.0567</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.3">0.1514</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.4">0.1049</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.5">0.2196</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.5.3.6">0.1269</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.7">0.0571</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.8">0.1566</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.9">0.1078</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.10">0.2317</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.5.3.11">0.1318</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.12">0.0451</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.13">0.1322</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.14">0.0889</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.15">0.2023</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.3.16">0.1114</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.6.4.1">VIP5</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.2">0.0699</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.3">0.1882</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.4">0.1304</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.5">0.2717</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.6.4.6">0.1572</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.7">0.0615</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.8">0.1655</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.9">0.1147</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.10">0.2407</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.6.4.11">0.1388</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.12">0.0433</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.13">0.1301</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.14">0.0875</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.15">0.2037</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6.4.16">0.1110</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.7.5.1">POD</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.2.1">0.0895</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.3.1">0.2086</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.4.1">0.1506</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.5.1">0.2873</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.7.5.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.6.1">0.1756</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.7.1">0.0829</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.8.1">0.1926</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.9.1">0.1391</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.10.1">0.2670</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.7.5.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.11.1">0.1629</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.12"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.12.1">0.0567</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.13"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.13.1">0.1433</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.14"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.14.1">0.1009</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.15"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.15.1">0.2082</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.5.16"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.1.1.7.5.16.1">0.1215</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.2.1">0.1212</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.3.1">0.2741</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.4.1">0.2007</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.5.1">0.3616</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.8.6.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.6.1">0.2286</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.7"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.7.1">0.1097</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.8"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.8.1">0.2441</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.9"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.9.1">0.1780</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.10"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.10.1">0.3260</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.8.6.11"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.11.1">0.2039</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.12"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.12.1">0.0728</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.13"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.13.1">0.1618</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.14"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.14.1">0.1190</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.15"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.15.1">0.2315</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.1.1.8.6.16"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.6.16.1">0.1411</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance comparison on explanation generation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.1" style="width:433.6pt;height:76.8pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-141.9pt,24.9pt) scale(0.604499762052186,0.604499762052186) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S5.T4.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T4.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T4.1.1.1.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T4.1.1.1.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T4.1.1.1.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.1">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.2">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.3">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T4.1.1.2.2.4">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.5">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.6">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.7">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T4.1.1.2.2.8">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.9">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.10">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.11">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T4.1.1.2.2.12">ROUGE-L</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.1.3.1.1">Att2Seq</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.2">0.5305</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.3">12.2800</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.4">1.2107</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.1.5">9.1312</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.6">0.7889</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.7">12.6590</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.8">1.6820</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.1.9">9.7481</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.10">1.6238</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.11">13.2245</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.12">2.9942</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.13">10.7398</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.4.2.1">NRT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.2">0.4793</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.3">11.0723</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.4">1.1304</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.4.2.5">7.6674</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.6">0.8295</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.7">12.7815</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.4.2.8.1">1.8543</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.4.2.9">9.9477</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.10">1.9084</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.11">13.5231</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.12">3.6708</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.2.13">11.1867</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.5.3.1">PETER</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.2">0.7112</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.5.3.3.1">12.8944</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.4">1.3283</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.5.3.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.5.3.5.1">9.8635</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.5.3.6.1">1.1541</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.5.3.7.1">14.8497</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.5.3.8.1">2.1413</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.5.3.9"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.5.3.9.1">11.4143</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.10">1.9861</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.11"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.5.3.11.1">14.2716</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.12">3.6718</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.3.13"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.5.3.13.1">11.7010</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.6.4.1">POD</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.6.4.2.1">1.0013</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.6.4.3.1">14.0168</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.6.4.4.1">2.0436</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.6.4.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.6.4.5.1">11.1236</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.6.4.6.1">1.0630</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.7"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.6.4.7.1">15.2517</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.8">1.5737</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.1.6.4.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.6.4.9.1">11.3283</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.6.4.10.1">2.3053</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.11">12.2889</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.12"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.6.4.12.1">3.8512</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.4.13">10.3923</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.7.5.2.1">0.9148</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.3">11.2685</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.7.5.4.1">1.7870</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.1.1.7.5.5">8.8078</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.6">1.0050</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.7">13.4532</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.8">1.5863</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.1.1.7.5.9">10.3238</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.10"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.7.5.10.1">2.4295</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.7.5.11.1">13.5537</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.12"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.7.5.12.1">3.9567</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.1.1.7.5.13"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T4.1.1.7.5.13.1">11.3863</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Metrics</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">For sequential and top-n recommendation, we evaluate models using two commonly used metrics, normalized Discounted Cumulative Gain (nDCG) and Hit Ratio (HR). nDCG is a metric used to evaluate the quality of ranked lists by considering the position of relevant items, while HR measures the fraction of relevant items that appear in the top-n positions of a ranked list. In particular, we measure HR@{5,10} and nDCG@{5,10} for sequential recommendation and HR@{1,5,10} and nDCG@{5,10} for top-n recommendation. For explanation generation, we evaluate models using BLEUÂ <cite class="ltx_cite ltx_citemacro_cite">Papineni etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib17" title="">2002</a>)</cite> and ROUGEÂ <cite class="ltx_cite ltx_citemacro_cite">Lin and Hovy (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib14" title="">2003</a>)</cite>. BLEU evaluates machine translation quality using n-gram precision against reference translations, while ROUGE assesses text summarization and translation by comparing n-gram overlaps with reference texts. We report the F1 scores for BLEU-4, ROUGE-1, ROUGE-2, and ROUGE-L. For all metrics, a greater score indicates better performance. In all tables, the best performing model for each metric is in <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">bold</span> and the second best model is <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS3.p1.1.2">underlined</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Implementation Details</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">To ensure a fair comparison, we compare PeaPOD with PODÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>, P5Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>, and VIP5Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite> using T5-small (60.5 M parameters)Â <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib19" title="">2020</a>)</cite> as the pre-trained LLM. On average, each experiment took 6 hours to run. Since the main focus of our study is not on formulating discrete prompts, we reuse the same discrete prompts asÂ <cite class="ltx_cite ltx_citemacro_citet">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>. We adapt task-alternated training, as proposed byÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>, to speed up training time by alternating each task per batch. Notably, both VIP5 and P5 both mention that fine-tuning with the T5-small pre-trained checkpoint often outperforms fine-tuning with T5-base.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">For all models, we train the model on an Nvidia RTX 3090 for 30 epochs, a batch size of 64, the AdamW optimizerÂ <cite class="ltx_cite ltx_citemacro_cite">Kingma and Ba (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib9" title="">2015</a>)</cite>, and a learning rate of 5e-3. We save the best performing model on the validation set. The length of the task-specific prompts and prompt components are both set to 3. We set the number of prompt components to 20. For our hyperparameter search, we tested prompt lengths of {3, 5, 8, 10} and the number of prompts of {10, 20, 30, 100}.To obtain the user embedding, we train a probabalistic matrix factorization modelÂ <cite class="ltx_cite ltx_citemacro_cite">Mnih and Salakhutdinov (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib16" title="">2007</a>)</cite>, a variant of matrix factorization, for 100 iterations with an embedding size of 512, learning rate of 1e-3, and a lambda regularization of 1e-3. During inference time, the number of beams is set to 20 and the inference batch size is set to 32 for all tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Sequential Recommendation</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.T2" title="Table 2 â€£ 5.2 Baselines â€£ 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">2</span></a>, we compare our models with our selected baseline models. Our results show that PeaPOD outperforms all baselines in the Sports and Beauty datasets and is either the first or second best model for all metrics in the Toys dataset. Notably, the only difference between our method and POD, which is the second best performing model, is the additional personalized-user prompt that is prepended to the input. Interestingly, even though the user embedding passed to the attention mechanism is trained on a top-n recommender model, the additional information still provides a performance boost to sequential recommendation. This performance gain may be attributed to the way the data was split. In particular, the sequential and top-n recommendation contains the same user-item interactions, meaning that information about the users can be shared to improve performance in both tasks.
</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Top-n Recommendation</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.T3" title="Table 3 â€£ 5.2 Baselines â€£ 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">3</span></a>, we report the performance of the top-n recommendation task. We note that PeaPOD performs the best in all metrics for all datasets, with a significant improvement in performance. We note that matrix factorization, which is used to generate the user embedding, is trained for top-n recommendation. Thus, the boost in performance may be more significant when compared to the other two tasks because of the user embedding selected as the query function. Nevertheless, we also find that PeaPOD outperforms matrix factorization itself, meaning that combining traditional collaborative filtering methods with LLMs leads to increased performance.</p>
</div>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="197" id="S6.F3.g1" src="extracted/5714243/images/plot.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Comparison between PeaPOD and an ablated version (PeaPOD-X) trained without the task-specific prompts on our three tasks.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Explanation Generation</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S5.T4" title="Table 4 â€£ 5.2 Baselines â€£ 5 Experimental Setup â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">4</span></a>, we report the performance of all models on the explanation generation task. Interestingly PeaPOD performs particularly well on both Sports and Toys datasets, but performs significantly worse in Beauty when compared to the top baseline models. Nevertheless, PeaPOD ranks first or second best on six out of the twelve evaluations, meaning that it is still competitive in explanation generation.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">Upon manual inspection across all models, we notice that there are a significant amount of duplicates across explanations, meaning that the same explanations are generated regardless of the (user, item) pair. Thus, we posit that limiting the explanation generation to exclusively user and item IDs hurts performance. Similar to how performance for sequential and top-n recommendation was improved by providing collaborative user embeddings, the performance of item explanations can be improved by providing additional item metadata to the model. Previous researchÂ <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>); Tan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib26" title="">2024</a>); Rajput etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib20" title="">2023</a>)</cite> has already explored how discrete item IDs can be transformed to provide more informative tokens to the model. However, we leave the additional experiments of combining enhanced item IDs with PeaPOD to future work.
</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Training without Task-Specific Prompts</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">To understand the effectiveness of user-personalized prompts versus globally shared prompts, we fine-tune the model with the same architecture and hyperparameters, but omit the task-specific prompts. We refer to the ablated model as â€˜PeaPOD-Xâ€™.</p>
</div>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">As shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#S6.F3" title="Figure 3 â€£ 6.2 Top-n Recommendation â€£ 6 Results â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">3</span></a>, we find that in all three datasets, the performance of the sequential recommendation marginally decreases, but the top-n recommendation performance improves. For explanation generation, the original model performs better for the Beauty dataset, but worse for Sports and Toys. We attribute the boost in top-n recommendation performance to the user embedding used for the query function. In particular, matrix factorization is a top-n recommendation model, meaning that the model is most likely to excel in this task. However, the lack of a task-specific prompt for sequential recommendation hinders the performance on this task. Nevertheless, we observe for the sequential recommendation task, the ablated model is still better than solely using the discrete prompt and has similar performance to POD. Thus, we show the effectiveness of a user-personalized prompt that utilizes preferences shared between similar users to improve recommendation performance. We report all metrics for this experiment in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A2" title="Appendix B Training without Task-Specific Prompts â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we propose PeaPOD, a novel recommender model that dynamically weights a set of decomposed prompt components to distill user preferences in a compositional manner. We maintain a many-to-many mapping between user preferences and continuous prompts to enable knowledge sharing among users with similar preferences. We utilize an attention-based mechanism to weight prompt components based on the userâ€™s interaction history, thus creating a user-personalized prompt that distills both the userâ€™s and similar usersâ€™ preferences into a learnable soft prompt. In our experiments, we show that our user-personalized prompt is effective in increasing the performance for three common recommendation tasks. Our model shows the effectiveness of preference distillation to improve personalized generative recommendation.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations and Ethical Concerns</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">One limitation to our approach is that we limit our study to exclusively use user and item IDs. Thus, we do not incorporate any additional metadata such as user profiles or item descriptions. We find that this may hinder performance on explanation generation, which relies on having a strong understanding of both the user and item to provide a personalized response. We predict that providing additional metadata to the model can improve performance, particularly if it is given in natural language text as the LLM is already pre-trained on such data. We plan to extend PeaPOD to utilize this information in future work.
</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">In addition, our model takes a two-step approach to generate user-personalized prompts. Namely, the user embedding is generated using matrix factorization, which is then passed to the model as the query function. However, the models are not connected end-to-end, which means that the user embedding cannot be continuously updated during training. For future work, we plan to combine these two models into a single end-to-end framework.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">Another concern is the issue of fairness in generative recommender systems. For example, prior research has shown that LLM-based recommenders skew towards popular items, which causes a disparity in recommendations and can lead to a bias-amplification loopÂ <cite class="ltx_cite ltx_citemacro_cite">Yoon etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib32" title="">2024</a>)</cite>. In addition, past research has investigated the issue of fairness in the LLM itselfÂ <cite class="ltx_cite ltx_citemacro_cite">Salutari etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib22" title="">2023</a>)</cite>. Thus, careful consideration must be made when deploying a generative recommender model to mitigate unfair recommendations.

</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng etÂ al. (2016)</span>
<span class="ltx_bibblock">
Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2988450.2988454" title="">Wide &amp; Deep Learning for Recommender Systems</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</em>, pages 7â€“10, Boston MA USA. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. (2017)</span>
<span class="ltx_bibblock">
LiÂ Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, and KeÂ Xu. 2017.

</span>
<span class="ltx_bibblock">Learning to Generate Product Reviews from Attributes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</em>, pages 623â€“632, Valencia, Spain. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yingqiang Ge, Shuchang Liu, Zuohui Fu, Juntao Tan, Zelong Li, Shuyuan Xu, Yunqi Li, Yikun Xian, and Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2207.12515" title="">A Survey on Trustworthy Recommender Systems</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arxiv:2207.12515.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng etÂ al. (2022)</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3523227.3546767" title="">Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 16th ACM Conference on Recommender Systems</em>, pages 299â€“315, Seattle WA USA. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shijie Geng, Juntao Tan, Shuchang Liu, Zuohui Fu, and Yongfeng Zhang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.644" title="">VIP5: Towards Multimodal Foundation Models for Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 9606â€“9620, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, BodhisattwaÂ Prasad Majumder, Nathan Kallus, and Julian Mcauley. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3583780.3614949" title="">Large Language Models as Zero-Shot Conversational Recommenders</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, pages 720â€“730, Birmingham United Kingdom. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jannach and Ludewig (2017)</span>
<span class="ltx_bibblock">
Dietmar Jannach and Malte Ludewig. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3109859.3109872" title="">When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the Eleventh ACM Conference on Recommender Systems</em>, pages 306â€“310, Como Italy. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">2018 IEEE international conference on data mining (ICDM)</em>, pages 197â€“206. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
DiederikÂ P. Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ICLR (Poster)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koren etÂ al. (2009)</span>
<span class="ltx_bibblock">
Yehuda Koren, Robert Bell, and Chris Volinsky. 2009.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/MC.2009.263" title="">Matrix Factorization Techniques for Recommender Systems</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Computer</em>, 42(8):30â€“37.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2020)</span>
<span class="ltx_bibblock">
Lei Li, Yongfeng Zhang, and LiÂ Chen. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3340531.3411992" title="">Generate Neural Template Explanations for Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>, pages 755â€“764, Virtual Event Ireland. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2021)</span>
<span class="ltx_bibblock">
Lei Li, Yongfeng Zhang, and LiÂ Chen. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.383" title="">Personalized Transformer for Explainable Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 4947â€“4957, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Lei Li, Yongfeng Zhang, and LiÂ Chen. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3583780.3615017" title="">Prompt Distillation for Efficient LLM-based Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, pages 1348â€“1357, Birmingham United Kingdom. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Hovy (2003)</span>
<span class="ltx_bibblock">
Chin-Yew Lin and Eduard Hovy. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073445.1073465" title="">Automatic evaluation of summaries using N-gram co-occurrence statistics</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - NAACL â€™03</em>, volumeÂ 1, pages 71â€“78, Edmonton, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2019)</span>
<span class="ltx_bibblock">
Chen Ma, Peng Kang, and Xue Liu. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3292500.3330984" title="">Hierarchical Gating Networks for Sequential Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 825â€“833, Anchorage AK USA. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mnih and Salakhutdinov (2007)</span>
<span class="ltx_bibblock">
Andriy Mnih and RussÂ R Salakhutdinov. 2007.

</span>
<span class="ltx_bibblock">Probabilistic Matrix Factorization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 20. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni etÂ al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">BLEU: A method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</em>, ACL â€™02, pages 311â€“318, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov and Macdonald (2023)</span>
<span class="ltx_bibblock">
AleksandrÂ V. Petrov and Craig Macdonald. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2306.11114" title="">Generative Sequential Recommendation with GPTRec</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arxiv:2306.11114.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J. Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">The Journal of Machine Learning Research</em>, 21(1):140:5485â€“140:5551.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajput etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan HulikalÂ Keshavan, Trung Vu, Lukasz Heldt, Lichan Hong, YiÂ Tay, Vinh Tran, Jonah Samost, Maciej Kula, EdÂ Chi, and Maheswaran Sathiamoorthy. 2023.

</span>
<span class="ltx_bibblock">Recommender Systems with Generative Retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in Neural Information Processing Systems</em>, 36:10299â€“10315.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramos etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jerome Ramos, HossenÂ A. Rahmani, XiÂ Wang, Xiao Fu, and Aldo Lipani. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.05810" title="">Natural Language User Profiles for Transparent and Scrutable Recommendations</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arxiv:2402.05810.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salutari etÂ al. (2023)</span>
<span class="ltx_bibblock">
Flavia Salutari, Jerome Ramos, HosseinÂ A Rahmani, Leonardo Linguaglossa, and Aldo Lipani. 2023.

</span>
<span class="ltx_bibblock">Quantifying the bias of transformer-based language models for african american english in masked language modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Pacific-Asia Conference on Knowledge Discovery and Data Mining</em>, pages 532â€“543. Springer Nature Switzerland Cham.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanner etÂ al. (2023)</span>
<span class="ltx_bibblock">
Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, and Lucas Dixon. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.14225" title="">Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Preprint</em>, arxiv:2307.14225.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith etÂ al. (2023)</span>
<span class="ltx_bibblock">
JamesÂ Seale Smith, Leonid Karlinsky, Vyshnavi Gutta, Paola Cascante-Bonilla, Donghyun Kim, Assaf Arbelle, Rameswar Panda, Rogerio Feris, and Zsolt Kira. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/CVPR52729.2023.01146" title="">CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 11909â€“11919, Vancouver, BC, Canada. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2019)</span>
<span class="ltx_bibblock">
Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3357384.3357895" title="">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>, pages 1441â€“1450, Beijing China. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan etÂ al. (2024)</span>
<span class="ltx_bibblock">
Juntao Tan, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Zelong Li, and Yongfeng Zhang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2403.19021" title="">IDGenRec: LLM-RecSys Alignment with Textual ID Learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">SIGIR</em>. arXiv.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang and Wang (2018)</span>
<span class="ltx_bibblock">
Jiaxi Tang and KeÂ Wang. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3159652.3159656" title="">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</em>, pages 565â€“573, Marina Del Rey CA USA. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, NoamÂ M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Neural Information Processing Systems</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Bin Wu, Jinyuan Fang, Xiangxiang Zeng, Shangsong Liang, and Qiang Zhang. 2023.

</span>
<span class="ltx_bibblock">Adaptive compositional continual meta-learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">International Conference on Machine Learning</em>, pages 37358â€“37378. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Bin Wu, Zaiqiao Meng, Qiang Zhang, and Shangsong Liang. 2022.

</span>
<span class="ltx_bibblock">Meta-learning helps personalized product search.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the ACM Web Conference 2022</em>, pages 2277â€“2287.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Bin Wu, Zhengyan Shi, HosseinÂ A Rahmani, Varsha Ramineni, and Emine Yilmaz. 2024.

</span>
<span class="ltx_bibblock">Understanding the role of user profile in the personalization of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2406.17803</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon etÂ al. (2024)</span>
<span class="ltx_bibblock">
Se-eun Yoon, Zhankui He, JessicaÂ Maria Echterhoff, and Julian McAuley. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2403.09738" title="">Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint</em>, arxiv:2403.09738.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tingting Zhang, Pengpeng Zhao, Yanchi Liu, VictorÂ S. Sheng, Jiajie Xu, Deqing Wang, Guanfeng Liu, and Xiaofang Zhou. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.24963/ijcai.2019/600" title="">Feature-level Deeper Self-Attention Network for Sequential Recommendation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</em>, pages 4320â€“4326, Macao, China. International Joint Conferences on Artificial Intelligence Organization.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2014)</span>
<span class="ltx_bibblock">
Yongfeng Zhang, Guokun Lai, Min Zhang, YiÂ Zhang, Yiqun Liu, and Shaoping Ma. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2600428.2609579" title="">Explicit factor models for explainable recommendation based on phrase-level sentiment analysis</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</em>, pages 83â€“92, Gold Coast Queensland Australia. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kun Zhou, Hui Wang, WayneÂ Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, and Ji-Rong Wen. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3340531.3411954" title="">S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>, pages 1893â€“1902, Virtual Event Ireland. ACM.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Baselines</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">For each of our three tasks, we compare our model with the following baselines.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Sequential Recommendation</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Sequential recommendation predicts a userâ€™s next preferred items based on their previous interactions, which are given in historical order.</p>
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">Caser</span>: <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.2">C</span>onvolution<span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.3">A</span>l <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.4">S</span>equence <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.5">E</span>mbedding <span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.6">R</span>ecommendationÂ <cite class="ltx_cite ltx_citemacro_cite">Tang and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib27" title="">2018</a>)</cite> uses a convolutional neural network to learn the sequential pattern of the user interaction history.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">HGN</span>Â <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib15" title="">2019</a>)</cite>: Hierarchical Gating Network uses two gating modules to model a userâ€™s short and long term interests.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i3.p1.1.1">GRU4Rec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Jannach and Ludewig (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib7" title="">2017</a>)</cite>: Gated Recurrent Unit (GRU) for Recommendation uses a GRU to process a userâ€™s recommender session.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i4.p1.1.1">BERT4Rec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Sun etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib25" title="">2019</a>)</cite>: Fine-tunes a bidirectional encoder representations from transformers model for sequential recommendation.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i5.p1.1.1">FDSA</span>Â <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib33" title="">2019</a>)</cite>: Feature-level Deeper Self-Attention network. Integrates item features as feature sequences, which are then combined with item sequences to generate recommendations.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i6.p1.1.1">SASRec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Kang and McAuley (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib8" title="">2018</a>)</cite>: Self-Attentive based Sequential Recommendation model. Uses self-attention mechanisms for short-term semantics and Recurrent Neural Networks for long-term semantics.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p" id="A1.I1.i7.p1.1"><math alttext="\mathbf{S^{3}}" class="ltx_Math" display="inline" id="A1.I1.i7.p1.1.m1.1"><semantics id="A1.I1.i7.p1.1.m1.1a"><msup id="A1.I1.i7.p1.1.m1.1.1" xref="A1.I1.i7.p1.1.m1.1.1.cmml"><mi id="A1.I1.i7.p1.1.m1.1.1.2" xref="A1.I1.i7.p1.1.m1.1.1.2.cmml">ğ’</mi><mn id="A1.I1.i7.p1.1.m1.1.1.3" xref="A1.I1.i7.p1.1.m1.1.1.3.cmml">ğŸ‘</mn></msup><annotation-xml encoding="MathML-Content" id="A1.I1.i7.p1.1.m1.1b"><apply id="A1.I1.i7.p1.1.m1.1.1.cmml" xref="A1.I1.i7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.I1.i7.p1.1.m1.1.1.1.cmml" xref="A1.I1.i7.p1.1.m1.1.1">superscript</csymbol><ci id="A1.I1.i7.p1.1.m1.1.1.2.cmml" xref="A1.I1.i7.p1.1.m1.1.1.2">ğ’</ci><cn id="A1.I1.i7.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.I1.i7.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i7.p1.1.m1.1c">\mathbf{S^{3}}</annotation><annotation encoding="application/x-llamapun" id="A1.I1.i7.p1.1.m1.1d">bold_S start_POSTSUPERSCRIPT bold_3 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="A1.I1.i7.p1.1.1">-Rec</span>Â <cite class="ltx_cite ltx_citemacro_cite">Zhou etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib35" title="">2020</a>)</cite>: Self-Supervised learning for Sequential Recommendation. Uses four self-supervised learning objectives to capture the correlations between items in sequential data.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p" id="A1.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i8.p1.1.1">P5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>: Pretrain, Personalized Prompt, and Predict Paradigm. Trains a model for multi-task generative recommendation using discrete prompt templates (e.g. â€œWhich item of the following to recommend for user_{}? item_list:{}â€</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p" id="A1.I1.i9.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i9.p1.1.1">VIP5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite>: An extension of P5 that trains on multimodal data.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I1.i10.p1">
<p class="ltx_p" id="A1.I1.i10.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i10.p1.1.1">POD</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>: An extension of P5 that uses a task-specific, distilled prompt as part of the input.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Top-n Recommendation</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">Top-n recommendation predicts a list of the top-n items based on the userâ€™s interaction history.</p>
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i1.p1.1.1">MF</span>Â <cite class="ltx_cite ltx_citemacro_cite">Koren etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib10" title="">2009</a>)</cite>: Matrix Factorization is a collaborative filtering technique that decomposes a user-item interaction matrix into latent user and item embeddings.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i2.p1.1.1">MLP</span>Â <cite class="ltx_cite ltx_citemacro_cite">Cheng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib1" title="">2016</a>)</cite>: Multi-Layer Perceptron is a neural network trained to learn captures non-linear interactions between users and items.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I2.i3.p1">
<p class="ltx_p" id="A1.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i3.p1.1.1">P5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib4" title="">2022</a>)</cite>: See definition in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS1" title="A.1 Sequential Recommendation â€£ Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I2.i4.p1">
<p class="ltx_p" id="A1.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i4.p1.1.1">VIP5</span>Â <cite class="ltx_cite ltx_citemacro_cite">Geng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib5" title="">2023</a>)</cite>: See definition in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS1" title="A.1 Sequential Recommendation â€£ Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I2.i5.p1">
<p class="ltx_p" id="A1.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i5.p1.1.1">POD</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib13" title="">2023</a>)</cite>: See definition in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#A1.SS1" title="A.1 Sequential Recommendation â€£ Appendix A Baselines â€£ Preference Distillation for Personalized Generative Recommendation"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Explanation Generation</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">Given a user ID and item ID, the model must return a natural language explanation describing why the user might like/dislike the target item. Notably, we exclude P5 and VIP5 because we are exclusively focused on models that exclusively use only user and item IDs rather than item titles or other item metadata.</p>
<ul class="ltx_itemize" id="A1.I3">
<li class="ltx_item" id="A1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I3.i1.p1">
<p class="ltx_p" id="A1.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I3.i1.p1.1.1">Att2Seq</span>Â <cite class="ltx_cite ltx_citemacro_cite">Dong etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib2" title="">2017</a>)</cite>: an attention based model that learns to generate product reviews from item attributes.</p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I3.i2.p1">
<p class="ltx_p" id="A1.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I3.i2.p1.1.1">NRT</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib11" title="">2020</a>)</cite>: Neural Ratings and Tips generation simultaneously returns a rating and a tip based on a neural network.</p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A1.I3.i3.p1">
<p class="ltx_p" id="A1.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I3.i3.p1.1.1">PETER</span>Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05033v1#bib.bib12" title="">2021</a>)</cite>: a transformer based model that performs rating prediction and explanation generation.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Training without Task-Specific Prompts</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">We report the original model including task-specific prompts (denoted as PeaPOD) versus training the model without them (denoted as PeaPOD-X). All inputs and hyperparameters are otherwise the same.</p>
</div>
<figure class="ltx_table" id="A2.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance comparison on sequential recommendation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T5.1" style="width:433.6pt;height:47.8pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-114.5pt,12.4pt) scale(0.654492241744612,0.654492241744612) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A2.T5.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="A2.T5.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T5.1.1.1.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T5.1.1.1.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T5.1.1.1.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.1">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.2">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.3">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T5.1.1.2.2.4">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.5">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.6">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.7">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T5.1.1.2.2.8">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.9">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.10">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.11">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.2.2.12">NDCG@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T5.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T5.1.1.3.1.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.2.1">0.0505</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.3"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.3.1">0.0400</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.4"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.4.1">0.0611</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T5.1.1.3.1.5"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.5.1">0.0432</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.6"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.6.1">0.0588</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.7"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.7.1">0.0445</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.8"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.8.1">0.0738</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T5.1.1.3.1.9"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.9.1">0.0493</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.10">0.0692</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.11"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.11.1">0.0583</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.12">0.0787</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.1.13"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.13.1">0.0609</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="A2.T5.1.1.4.2.1">PeaPOD-X</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.2">0.0480</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.3">0.0381</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.4">0.0581</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T5.1.1.4.2.5">0.0412</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.6">0.0565</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.7">0.0402</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.8">0.0732</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T5.1.1.4.2.9">0.0456</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.10"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.4.2.10.1">0.0705</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.11">0.0557</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.12"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.4.2.12.1">0.0835</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2.13">0.0594</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A2.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance comparison on top-n recommendation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T6.1" style="width:433.6pt;height:40.5pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-174.1pt,16.0pt) scale(0.554598829429359,0.554598829429359) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A2.T6.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="A2.T6.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="A2.T6.1.1.1.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="A2.T6.1.1.1.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5" id="A2.T6.1.1.1.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.1">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.2">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.3">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.4">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.2.2.5">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.6">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.7">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.8">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.9">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.2.2.10">NDCG@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.11">HR@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.12">HR@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.13">NDCG@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.14">HR@10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.2.2.15">NDCG@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T6.1.1.3.1.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.2">0.1212</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.3">0.2741</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.4">0.2007</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.5">0.3616</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.1.3.1.6">0.2286</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.7">0.1097</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.8">0.2441</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.9">0.1780</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.10">0.3260</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.1.3.1.11">0.2039</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.12">0.0728</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.13">0.1618</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.14">0.1190</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.15">0.2315</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.1.1.3.1.16">0.1411</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="A2.T6.1.1.4.2.1">PeaPOD-X</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.2"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.2.1">0.1232</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.3"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.3.1">0.2744</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.4"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.4.1">0.2017</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.5"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.5.1">0.3662</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T6.1.1.4.2.6"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.6.1">0.2309</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.7"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.7.1">0.1130</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.8"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.8.1">0.2480</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.9"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.9.1">0.1820</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.10"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.10.1">0.3304</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T6.1.1.4.2.11"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.11.1">0.2079</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.12"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.12.1">0.0790</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.13"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.13.1">0.1795</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.14"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.14.1">0.1308</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.15"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.15.1">0.2513</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.1.1.4.2.16"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.4.2.16.1">0.1536</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A2.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance comparison on explanation generation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T7.1" style="width:433.6pt;height:43.5pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-147.3pt,14.6pt) scale(0.595506120437427,0.595506120437427) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T7.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T7.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A2.T7.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="A2.T7.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T7.1.1.1.1.2">Sports</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T7.1.1.1.1.3">Beauty</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A2.T7.1.1.1.1.4">Toys</th>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.1">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.2">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.3">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.4">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.5">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.6">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.7">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.8">ROUGE-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.9">BLEU-4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.10">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.11">ROUGE-2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T7.1.1.2.2.12">ROUGE-L</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T7.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T7.1.1.3.1.1">PeaPOD</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.2">0.9148</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.3">11.2685</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.4"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1.4.1">1.7870</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.1.5">8.8078</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.6"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1.6.1">1.0050</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.7"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1.7.1">13.4532</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.8">1.5863</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.1.9"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1.9.1">10.3238</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.10">2.4295</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.11">13.5537</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.12"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.1.12.1">3.9567</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.1.13">11.3863</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="A2.T7.1.1.4.2.1">PeaPOD-X</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.2"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.2.1">0.9561</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.3"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.3.1">12.1112</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.4">1.7613</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T7.1.1.4.2.5"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.5.1">9.4255</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.6">0.9598</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.7">11.3673</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.8"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.8.1">1.7317</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.T7.1.1.4.2.9">8.8236</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.10"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.10.1">2.5306</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.11"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.11.1">15.3696</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.12">3.8183</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T7.1.1.4.2.13"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.2.13.1">12.6750</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Jul  6 09:51:25 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
