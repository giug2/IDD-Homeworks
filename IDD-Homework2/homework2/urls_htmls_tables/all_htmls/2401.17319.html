<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.17319] Decentralized Federated Learning: A Survey on Security and Privacy</title><meta property="og:description" content="Federated learning has been rapidly evolving and gaining popularity in recent years due to its privacy-preserving features, among other advantages. Nevertheless, the exchange of model updates and gradients in this arch‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Decentralized Federated Learning: A Survey on Security and Privacy">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Decentralized Federated Learning: A Survey on Security and Privacy">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.17319">

<!--Generated on Tue Feb 27 06:29:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  privacy-preserving,  security,  blockchain,  adversarial attacks,  decentralized federated learning,  verifiable federated learning.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Decentralized Federated Learning: A Survey on Security and Privacy</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ehsan¬†Hallaji,¬†
Roozbeh¬†Razavi-Far,¬†
Mehrdad¬†Saif,¬†
Boyu¬†Wang,¬†
Qiang¬†Yang,¬†





</span><span class="ltx_author_notes">This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).Ehsan Hallaji and Mehrdad Saif are with the Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada. E-mail: hallaji@uwindsor.ca, msaif@uwindsor.ca.Roozbeh Razavi-Far is with the Faculty of Computer Science, University of New Brunswick, Fredericton, NB E3B 5A3, Canada, and also with the Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada. E-mail: roozbeh.razavi-far@unb.ca.Boyu Wang is with the Department of Computer Science and the Brain Mind Institute, University of Western Ontario, London, ON N6A 5B7, Canada. E-mail: bwang@csd.uwo.ca.Qiang Yang is with the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong, and also with the Department of AI, WeBank, Gaungdong Province, China. E-mail: qyang@cse.ust.hk.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Federated learning has been rapidly evolving and gaining popularity in recent years due to its privacy-preserving features, among other advantages. Nevertheless, the exchange of model updates and gradients in this architecture provides new attack surfaces for malicious users of the network which may jeopardize the model performance and user and data privacy. For this reason, one of the main motivations for decentralized federated learning is to eliminate server-related threats by removing the server from the network and compensating for it through technologies such as blockchain. However, this advantage comes at the cost of challenging the system with new privacy threats. Thus, performing a thorough security analysis in this new paradigm is necessary. This survey studies possible variations of threats and adversaries in decentralized federated learning and overviews the potential defense mechanisms. Trustability and verifiability of decentralized federated learning are also considered in this study.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, privacy-preserving, security, blockchain, adversarial attacks, decentralized federated learning, verifiable federated learning.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With
the widespread use of machine learning over the recent years, new concerns have been raised regarding user and data privacy. The data-driven nature of these intelligent models necessitates gathering users‚Äô data to constantly improve and maintain the operating statistical model. This issue becomes more problematic in large-scale distributed systems with millions of users such as mobile networks.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Aside from privacy issues, in large-scale systems, communicating user data may pose an overhead to the network. This is while information technology and intelligent devices are evolving at a rapid pace, and in the wake of it, there is an explosion of data at the edge of the network. Given the potential benefits of this data collection process for improving their model, organizations tend to make the best use of it for knowledge extraction with minimal waste of data. Thus, modern intelligent systems struggle to find the optimal trade-off between user privacy and service quality.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Inspired by recent breakthroughs in distributed optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Federated Learning (FL) has proposed as a potential solution to resolve the aforementioned challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In contrast to distributed machine learning which is shown in Fig. <a href="#S1.F1" title="Figure 1 ‚Ä£ I Introduction ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a), FL proposes training local models at the edges of the network and then sharing the model parameters to a central server that aggregates the received information and then updates all the client models.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.8" class="ltx_p">Aside from its use in distributed training of Deep Learning (DL) models, FL offers additional advantages. Firstly, by communicating the local model parameters rather than the user‚Äôs data, the central model is trained on decentralized data, which no longer jeopardizes data privacy. Secondly, the communication is extensively reduced for large-scale systems, as the volume of model parameters is often smaller than the training data itself. The general scheme of FL workflow is illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‚Ä£ I Introduction ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b). As shown in this figure, for client <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.p4.1.m1.1a"><mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">i</annotation></semantics></math>, a model <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S1.p4.2.m2.1a"><msub id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">M</mi><mi id="S1.p4.2.m2.1.1.3" xref="S1.p4.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1">subscript</csymbol><ci id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">ùëÄ</ci><ci id="S1.p4.2.m2.1.1.3.cmml" xref="S1.p4.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">M_{i}</annotation></semantics></math> is constructed locally based on the local user data <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S1.p4.3.m3.1a"><msub id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml"><mi id="S1.p4.3.m3.1.1.2" xref="S1.p4.3.m3.1.1.2.cmml">D</mi><mi id="S1.p4.3.m3.1.1.3" xref="S1.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><apply id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S1.p4.3.m3.1.1.1.cmml" xref="S1.p4.3.m3.1.1">subscript</csymbol><ci id="S1.p4.3.m3.1.1.2.cmml" xref="S1.p4.3.m3.1.1.2">ùê∑</ci><ci id="S1.p4.3.m3.1.1.3.cmml" xref="S1.p4.3.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">D_{i}</annotation></semantics></math>. The model parameters <math id="S1.p4.4.m4.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S1.p4.4.m4.1a"><msub id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml"><mi id="S1.p4.4.m4.1.1.2" xref="S1.p4.4.m4.1.1.2.cmml">M</mi><mi id="S1.p4.4.m4.1.1.3" xref="S1.p4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><apply id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S1.p4.4.m4.1.1.1.cmml" xref="S1.p4.4.m4.1.1">subscript</csymbol><ci id="S1.p4.4.m4.1.1.2.cmml" xref="S1.p4.4.m4.1.1.2">ùëÄ</ci><ci id="S1.p4.4.m4.1.1.3.cmml" xref="S1.p4.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">M_{i}</annotation></semantics></math> are then sent to a server that aggregates all models in the form of <math id="S1.p4.5.m5.3" class="ltx_Math" alttext="\sum(M_{1},M_{2},M_{3})=u" display="inline"><semantics id="S1.p4.5.m5.3a"><mrow id="S1.p4.5.m5.3.3" xref="S1.p4.5.m5.3.3.cmml"><mrow id="S1.p4.5.m5.3.3.3" xref="S1.p4.5.m5.3.3.3.cmml"><mo rspace="0em" id="S1.p4.5.m5.3.3.3.4" xref="S1.p4.5.m5.3.3.3.4.cmml">‚àë</mo><mrow id="S1.p4.5.m5.3.3.3.3.3" xref="S1.p4.5.m5.3.3.3.3.4.cmml"><mo stretchy="false" id="S1.p4.5.m5.3.3.3.3.3.4" xref="S1.p4.5.m5.3.3.3.3.4.cmml">(</mo><msub id="S1.p4.5.m5.1.1.1.1.1.1" xref="S1.p4.5.m5.1.1.1.1.1.1.cmml"><mi id="S1.p4.5.m5.1.1.1.1.1.1.2" xref="S1.p4.5.m5.1.1.1.1.1.1.2.cmml">M</mi><mn id="S1.p4.5.m5.1.1.1.1.1.1.3" xref="S1.p4.5.m5.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S1.p4.5.m5.3.3.3.3.3.5" xref="S1.p4.5.m5.3.3.3.3.4.cmml">,</mo><msub id="S1.p4.5.m5.2.2.2.2.2.2" xref="S1.p4.5.m5.2.2.2.2.2.2.cmml"><mi id="S1.p4.5.m5.2.2.2.2.2.2.2" xref="S1.p4.5.m5.2.2.2.2.2.2.2.cmml">M</mi><mn id="S1.p4.5.m5.2.2.2.2.2.2.3" xref="S1.p4.5.m5.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S1.p4.5.m5.3.3.3.3.3.6" xref="S1.p4.5.m5.3.3.3.3.4.cmml">,</mo><msub id="S1.p4.5.m5.3.3.3.3.3.3" xref="S1.p4.5.m5.3.3.3.3.3.3.cmml"><mi id="S1.p4.5.m5.3.3.3.3.3.3.2" xref="S1.p4.5.m5.3.3.3.3.3.3.2.cmml">M</mi><mn id="S1.p4.5.m5.3.3.3.3.3.3.3" xref="S1.p4.5.m5.3.3.3.3.3.3.3.cmml">3</mn></msub><mo stretchy="false" id="S1.p4.5.m5.3.3.3.3.3.7" xref="S1.p4.5.m5.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S1.p4.5.m5.3.3.4" xref="S1.p4.5.m5.3.3.4.cmml">=</mo><mi id="S1.p4.5.m5.3.3.5" xref="S1.p4.5.m5.3.3.5.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.3b"><apply id="S1.p4.5.m5.3.3.cmml" xref="S1.p4.5.m5.3.3"><eq id="S1.p4.5.m5.3.3.4.cmml" xref="S1.p4.5.m5.3.3.4"></eq><apply id="S1.p4.5.m5.3.3.3.cmml" xref="S1.p4.5.m5.3.3.3"><sum id="S1.p4.5.m5.3.3.3.4.cmml" xref="S1.p4.5.m5.3.3.3.4"></sum><vector id="S1.p4.5.m5.3.3.3.3.4.cmml" xref="S1.p4.5.m5.3.3.3.3.3"><apply id="S1.p4.5.m5.1.1.1.1.1.1.cmml" xref="S1.p4.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S1.p4.5.m5.1.1.1.1.1.1.1.cmml" xref="S1.p4.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S1.p4.5.m5.1.1.1.1.1.1.2.cmml" xref="S1.p4.5.m5.1.1.1.1.1.1.2">ùëÄ</ci><cn type="integer" id="S1.p4.5.m5.1.1.1.1.1.1.3.cmml" xref="S1.p4.5.m5.1.1.1.1.1.1.3">1</cn></apply><apply id="S1.p4.5.m5.2.2.2.2.2.2.cmml" xref="S1.p4.5.m5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S1.p4.5.m5.2.2.2.2.2.2.1.cmml" xref="S1.p4.5.m5.2.2.2.2.2.2">subscript</csymbol><ci id="S1.p4.5.m5.2.2.2.2.2.2.2.cmml" xref="S1.p4.5.m5.2.2.2.2.2.2.2">ùëÄ</ci><cn type="integer" id="S1.p4.5.m5.2.2.2.2.2.2.3.cmml" xref="S1.p4.5.m5.2.2.2.2.2.2.3">2</cn></apply><apply id="S1.p4.5.m5.3.3.3.3.3.3.cmml" xref="S1.p4.5.m5.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S1.p4.5.m5.3.3.3.3.3.3.1.cmml" xref="S1.p4.5.m5.3.3.3.3.3.3">subscript</csymbol><ci id="S1.p4.5.m5.3.3.3.3.3.3.2.cmml" xref="S1.p4.5.m5.3.3.3.3.3.3.2">ùëÄ</ci><cn type="integer" id="S1.p4.5.m5.3.3.3.3.3.3.3.cmml" xref="S1.p4.5.m5.3.3.3.3.3.3.3">3</cn></apply></vector></apply><ci id="S1.p4.5.m5.3.3.5.cmml" xref="S1.p4.5.m5.3.3.5">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.3c">\sum(M_{1},M_{2},M_{3})=u</annotation></semantics></math>, where <math id="S1.p4.6.m6.1" class="ltx_Math" alttext="\sum(\cdot)" display="inline"><semantics id="S1.p4.6.m6.1a"><mrow id="S1.p4.6.m6.1.2" xref="S1.p4.6.m6.1.2.cmml"><mo rspace="0em" id="S1.p4.6.m6.1.2.1" xref="S1.p4.6.m6.1.2.1.cmml">‚àë</mo><mrow id="S1.p4.6.m6.1.2.2.2" xref="S1.p4.6.m6.1.2.cmml"><mo stretchy="false" id="S1.p4.6.m6.1.2.2.2.1" xref="S1.p4.6.m6.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S1.p4.6.m6.1.1" xref="S1.p4.6.m6.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S1.p4.6.m6.1.2.2.2.2" xref="S1.p4.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.6.m6.1b"><apply id="S1.p4.6.m6.1.2.cmml" xref="S1.p4.6.m6.1.2"><sum id="S1.p4.6.m6.1.2.1.cmml" xref="S1.p4.6.m6.1.2.1"></sum><ci id="S1.p4.6.m6.1.1.cmml" xref="S1.p4.6.m6.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.6.m6.1c">\sum(\cdot)</annotation></semantics></math> and <math id="S1.p4.7.m7.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S1.p4.7.m7.1a"><mi id="S1.p4.7.m7.1.1" xref="S1.p4.7.m7.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S1.p4.7.m7.1b"><ci id="S1.p4.7.m7.1.1.cmml" xref="S1.p4.7.m7.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.7.m7.1c">u</annotation></semantics></math> are the aggregation function and the generated update, respectively. Finally, <math id="S1.p4.8.m8.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S1.p4.8.m8.1a"><mi id="S1.p4.8.m8.1.1" xref="S1.p4.8.m8.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S1.p4.8.m8.1b"><ci id="S1.p4.8.m8.1.1.cmml" xref="S1.p4.8.m8.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.8.m8.1c">u</annotation></semantics></math> is sent back to the clients to update local models.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2401.17319/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="332" height="118" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Workflow of distributed training, FL, and DFL with three nodes. <math id="S1.F1.5.m1.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S1.F1.5.m1.1b"><msub id="S1.F1.5.m1.1.1" xref="S1.F1.5.m1.1.1.cmml"><mi id="S1.F1.5.m1.1.1.2" xref="S1.F1.5.m1.1.1.2.cmml">D</mi><mi id="S1.F1.5.m1.1.1.3" xref="S1.F1.5.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F1.5.m1.1c"><apply id="S1.F1.5.m1.1.1.cmml" xref="S1.F1.5.m1.1.1"><csymbol cd="ambiguous" id="S1.F1.5.m1.1.1.1.cmml" xref="S1.F1.5.m1.1.1">subscript</csymbol><ci id="S1.F1.5.m1.1.1.2.cmml" xref="S1.F1.5.m1.1.1.2">ùê∑</ci><ci id="S1.F1.5.m1.1.1.3.cmml" xref="S1.F1.5.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.m1.1d">D_{i}</annotation></semantics></math>, <math id="S1.F1.6.m2.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S1.F1.6.m2.1b"><msub id="S1.F1.6.m2.1.1" xref="S1.F1.6.m2.1.1.cmml"><mi id="S1.F1.6.m2.1.1.2" xref="S1.F1.6.m2.1.1.2.cmml">M</mi><mi id="S1.F1.6.m2.1.1.3" xref="S1.F1.6.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.m2.1c"><apply id="S1.F1.6.m2.1.1.cmml" xref="S1.F1.6.m2.1.1"><csymbol cd="ambiguous" id="S1.F1.6.m2.1.1.1.cmml" xref="S1.F1.6.m2.1.1">subscript</csymbol><ci id="S1.F1.6.m2.1.1.2.cmml" xref="S1.F1.6.m2.1.1.2">ùëÄ</ci><ci id="S1.F1.6.m2.1.1.3.cmml" xref="S1.F1.6.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m2.1d">M_{i}</annotation></semantics></math>, and <math id="S1.F1.7.m3.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S1.F1.7.m3.1b"><mi id="S1.F1.7.m3.1.1" xref="S1.F1.7.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S1.F1.7.m3.1c"><ci id="S1.F1.7.m3.1.1.cmml" xref="S1.F1.7.m3.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.m3.1d">u</annotation></semantics></math> denote client data, local model parameters, and the generated update by the server. In this example, three clients are shown in the picture (i.e., <math id="S1.F1.8.m4.1" class="ltx_Math" alttext="1\leq i\leq 3" display="inline"><semantics id="S1.F1.8.m4.1b"><mrow id="S1.F1.8.m4.1.1" xref="S1.F1.8.m4.1.1.cmml"><mn id="S1.F1.8.m4.1.1.2" xref="S1.F1.8.m4.1.1.2.cmml">1</mn><mo id="S1.F1.8.m4.1.1.3" xref="S1.F1.8.m4.1.1.3.cmml">‚â§</mo><mi id="S1.F1.8.m4.1.1.4" xref="S1.F1.8.m4.1.1.4.cmml">i</mi><mo id="S1.F1.8.m4.1.1.5" xref="S1.F1.8.m4.1.1.5.cmml">‚â§</mo><mn id="S1.F1.8.m4.1.1.6" xref="S1.F1.8.m4.1.1.6.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.8.m4.1c"><apply id="S1.F1.8.m4.1.1.cmml" xref="S1.F1.8.m4.1.1"><and id="S1.F1.8.m4.1.1a.cmml" xref="S1.F1.8.m4.1.1"></and><apply id="S1.F1.8.m4.1.1b.cmml" xref="S1.F1.8.m4.1.1"><leq id="S1.F1.8.m4.1.1.3.cmml" xref="S1.F1.8.m4.1.1.3"></leq><cn type="integer" id="S1.F1.8.m4.1.1.2.cmml" xref="S1.F1.8.m4.1.1.2">1</cn><ci id="S1.F1.8.m4.1.1.4.cmml" xref="S1.F1.8.m4.1.1.4">ùëñ</ci></apply><apply id="S1.F1.8.m4.1.1c.cmml" xref="S1.F1.8.m4.1.1"><leq id="S1.F1.8.m4.1.1.5.cmml" xref="S1.F1.8.m4.1.1.5"></leq><share href="#S1.F1.8.m4.1.1.4.cmml" id="S1.F1.8.m4.1.1d.cmml" xref="S1.F1.8.m4.1.1"></share><cn type="integer" id="S1.F1.8.m4.1.1.6.cmml" xref="S1.F1.8.m4.1.1.6">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.m4.1d">1\leq i\leq 3</annotation></semantics></math>).</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Despite the breakthrough made by FL, the proposed architecture was not flawless and demanded further research endeavors on the topic. To begin with, although the user data is not being shared in the network, communicating local parameters is still vulnerable to sniffing attacks which will lead to stealing model parameters for launching an inference attack to extract sensitive information from the local training data at the edges of the networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. In addition, the trustability of the central server is sometimes questionable in environments such as wireless networks. Moreover, having a Single Point of Failure (SPF) in the system is not ideal since a compromised server can affect the whole network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. While various works have been dedicated to designing defense mechanisms for FL, it was proposed that decentralizing the FL architecture will eliminate part of these security challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.3" class="ltx_p">Relying on Peer-to-Peer (P2P) communications, Decentralized Federated Learning (DFL) improves both the reliability and scalability of FL by eliminating SPF and enhancing the communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. The process of local update preparation is similar to that of FL; however, exchanging model parameters and model aggregation is mostly undertaken through P2P communication or blockchain technology. For instance, a generic diagram of a DFL workflow is shown in Fig. <a href="#S1.F1" title="Figure 1 ‚Ä£ I Introduction ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(c), where a client is assigned with the aggregator role in each round (i.e., shown with dotted lines) to apply the aggregating function <math id="S1.p6.1.m1.3" class="ltx_Math" alttext="\sum(M_{1},M_{2},M_{3})=u" display="inline"><semantics id="S1.p6.1.m1.3a"><mrow id="S1.p6.1.m1.3.3" xref="S1.p6.1.m1.3.3.cmml"><mrow id="S1.p6.1.m1.3.3.3" xref="S1.p6.1.m1.3.3.3.cmml"><mo rspace="0em" id="S1.p6.1.m1.3.3.3.4" xref="S1.p6.1.m1.3.3.3.4.cmml">‚àë</mo><mrow id="S1.p6.1.m1.3.3.3.3.3" xref="S1.p6.1.m1.3.3.3.3.4.cmml"><mo stretchy="false" id="S1.p6.1.m1.3.3.3.3.3.4" xref="S1.p6.1.m1.3.3.3.3.4.cmml">(</mo><msub id="S1.p6.1.m1.1.1.1.1.1.1" xref="S1.p6.1.m1.1.1.1.1.1.1.cmml"><mi id="S1.p6.1.m1.1.1.1.1.1.1.2" xref="S1.p6.1.m1.1.1.1.1.1.1.2.cmml">M</mi><mn id="S1.p6.1.m1.1.1.1.1.1.1.3" xref="S1.p6.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S1.p6.1.m1.3.3.3.3.3.5" xref="S1.p6.1.m1.3.3.3.3.4.cmml">,</mo><msub id="S1.p6.1.m1.2.2.2.2.2.2" xref="S1.p6.1.m1.2.2.2.2.2.2.cmml"><mi id="S1.p6.1.m1.2.2.2.2.2.2.2" xref="S1.p6.1.m1.2.2.2.2.2.2.2.cmml">M</mi><mn id="S1.p6.1.m1.2.2.2.2.2.2.3" xref="S1.p6.1.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S1.p6.1.m1.3.3.3.3.3.6" xref="S1.p6.1.m1.3.3.3.3.4.cmml">,</mo><msub id="S1.p6.1.m1.3.3.3.3.3.3" xref="S1.p6.1.m1.3.3.3.3.3.3.cmml"><mi id="S1.p6.1.m1.3.3.3.3.3.3.2" xref="S1.p6.1.m1.3.3.3.3.3.3.2.cmml">M</mi><mn id="S1.p6.1.m1.3.3.3.3.3.3.3" xref="S1.p6.1.m1.3.3.3.3.3.3.3.cmml">3</mn></msub><mo stretchy="false" id="S1.p6.1.m1.3.3.3.3.3.7" xref="S1.p6.1.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S1.p6.1.m1.3.3.4" xref="S1.p6.1.m1.3.3.4.cmml">=</mo><mi id="S1.p6.1.m1.3.3.5" xref="S1.p6.1.m1.3.3.5.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.3b"><apply id="S1.p6.1.m1.3.3.cmml" xref="S1.p6.1.m1.3.3"><eq id="S1.p6.1.m1.3.3.4.cmml" xref="S1.p6.1.m1.3.3.4"></eq><apply id="S1.p6.1.m1.3.3.3.cmml" xref="S1.p6.1.m1.3.3.3"><sum id="S1.p6.1.m1.3.3.3.4.cmml" xref="S1.p6.1.m1.3.3.3.4"></sum><vector id="S1.p6.1.m1.3.3.3.3.4.cmml" xref="S1.p6.1.m1.3.3.3.3.3"><apply id="S1.p6.1.m1.1.1.1.1.1.1.cmml" xref="S1.p6.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S1.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S1.p6.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S1.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S1.p6.1.m1.1.1.1.1.1.1.2">ùëÄ</ci><cn type="integer" id="S1.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S1.p6.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S1.p6.1.m1.2.2.2.2.2.2.cmml" xref="S1.p6.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S1.p6.1.m1.2.2.2.2.2.2.1.cmml" xref="S1.p6.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S1.p6.1.m1.2.2.2.2.2.2.2.cmml" xref="S1.p6.1.m1.2.2.2.2.2.2.2">ùëÄ</ci><cn type="integer" id="S1.p6.1.m1.2.2.2.2.2.2.3.cmml" xref="S1.p6.1.m1.2.2.2.2.2.2.3">2</cn></apply><apply id="S1.p6.1.m1.3.3.3.3.3.3.cmml" xref="S1.p6.1.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S1.p6.1.m1.3.3.3.3.3.3.1.cmml" xref="S1.p6.1.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S1.p6.1.m1.3.3.3.3.3.3.2.cmml" xref="S1.p6.1.m1.3.3.3.3.3.3.2">ùëÄ</ci><cn type="integer" id="S1.p6.1.m1.3.3.3.3.3.3.3.cmml" xref="S1.p6.1.m1.3.3.3.3.3.3.3">3</cn></apply></vector></apply><ci id="S1.p6.1.m1.3.3.5.cmml" xref="S1.p6.1.m1.3.3.5">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.3c">\sum(M_{1},M_{2},M_{3})=u</annotation></semantics></math> on the received parameters and update all nodes with <math id="S1.p6.2.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S1.p6.2.m2.1a"><mi id="S1.p6.2.m2.1.1" xref="S1.p6.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S1.p6.2.m2.1b"><ci id="S1.p6.2.m2.1.1.cmml" xref="S1.p6.2.m2.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.2.m2.1c">u</annotation></semantics></math>. The protocol for selecting the aggregating node and the <math id="S1.p6.3.m3.1" class="ltx_Math" alttext="\sum(\cdot)" display="inline"><semantics id="S1.p6.3.m3.1a"><mrow id="S1.p6.3.m3.1.2" xref="S1.p6.3.m3.1.2.cmml"><mo rspace="0em" id="S1.p6.3.m3.1.2.1" xref="S1.p6.3.m3.1.2.1.cmml">‚àë</mo><mrow id="S1.p6.3.m3.1.2.2.2" xref="S1.p6.3.m3.1.2.cmml"><mo stretchy="false" id="S1.p6.3.m3.1.2.2.2.1" xref="S1.p6.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S1.p6.3.m3.1.1" xref="S1.p6.3.m3.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S1.p6.3.m3.1.2.2.2.2" xref="S1.p6.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p6.3.m3.1b"><apply id="S1.p6.3.m3.1.2.cmml" xref="S1.p6.3.m3.1.2"><sum id="S1.p6.3.m3.1.2.1.cmml" xref="S1.p6.3.m3.1.2.1"></sum><ci id="S1.p6.3.m3.1.1.cmml" xref="S1.p6.3.m3.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.3.m3.1c">\sum(\cdot)</annotation></semantics></math> function varies among different DFL architectures. Integration with blockchain brings about additional advantages including traceability and immutability. Despite the security and efficiency features of DFL, this architecture is not flawless. For instance, incorporating blockchain into FL may come at the cost of making the system defenseless against blockchain-related security adversaries. The trustability of the DFL participants is another issue of concern that requires further research.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Abbreviations used in this article. The list is sorted alphabetically.</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.2.1" class="ltx_tr">
<th id="S1.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Abbreviation</th>
<th id="S1.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Definition</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.3.1" class="ltx_tr">
<td id="S1.T1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_t">BAFFLE</td>
<td id="S1.T1.1.3.1.2" class="ltx_td ltx_align_left ltx_border_t">Blockchain-based aggregator free FL</td>
</tr>
<tr id="S1.T1.1.4.2" class="ltx_tr">
<td id="S1.T1.1.4.2.1" class="ltx_td ltx_align_left">BEAS</td>
<td id="S1.T1.1.4.2.2" class="ltx_td ltx_align_left">Blockchain enabled asynchronous and secure FL</td>
</tr>
<tr id="S1.T1.1.5.3" class="ltx_tr">
<td id="S1.T1.1.5.3.1" class="ltx_td ltx_align_left">BFLC</td>
<td id="S1.T1.1.5.3.2" class="ltx_td ltx_align_left">Blockchain-based FL with committee consensus</td>
</tr>
<tr id="S1.T1.1.6.4" class="ltx_tr">
<td id="S1.T1.1.6.4.1" class="ltx_td ltx_align_left">BindaaS</td>
<td id="S1.T1.1.6.4.2" class="ltx_td ltx_align_left">Blockchain-based deep learning as-a-service</td>
</tr>
<tr id="S1.T1.1.7.5" class="ltx_tr">
<td id="S1.T1.1.7.5.1" class="ltx_td ltx_align_left">DDoS</td>
<td id="S1.T1.1.7.5.2" class="ltx_td ltx_align_left">Distributed denial of service</td>
</tr>
<tr id="S1.T1.1.8.6" class="ltx_tr">
<td id="S1.T1.1.8.6.1" class="ltx_td ltx_align_left">DFL</td>
<td id="S1.T1.1.8.6.2" class="ltx_td ltx_align_left">Decentralized federated learning</td>
</tr>
<tr id="S1.T1.1.9.7" class="ltx_tr">
<td id="S1.T1.1.9.7.1" class="ltx_td ltx_align_left">DL</td>
<td id="S1.T1.1.9.7.2" class="ltx_td ltx_align_left">Deep learning</td>
</tr>
<tr id="S1.T1.1.10.8" class="ltx_tr">
<td id="S1.T1.1.10.8.1" class="ltx_td ltx_align_left">DoS</td>
<td id="S1.T1.1.10.8.2" class="ltx_td ltx_align_left">Denial of service</td>
</tr>
<tr id="S1.T1.1.11.9" class="ltx_tr">
<td id="S1.T1.1.11.9.1" class="ltx_td ltx_align_left">DP</td>
<td id="S1.T1.1.11.9.2" class="ltx_td ltx_align_left">Differential privacy</td>
</tr>
<tr id="S1.T1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_left">
<math id="S1.T1.1.1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S1.T1.1.1.1.m1.1a"><mi id="S1.T1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.m1.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.m1.1c">f</annotation></semantics></math>-DP</td>
<td id="S1.T1.1.1.2" class="ltx_td ltx_align_left">Functional differential privacy</td>
</tr>
<tr id="S1.T1.1.12.10" class="ltx_tr">
<td id="S1.T1.1.12.10.1" class="ltx_td ltx_align_left">FL</td>
<td id="S1.T1.1.12.10.2" class="ltx_td ltx_align_left">Federated learning</td>
</tr>
<tr id="S1.T1.1.13.11" class="ltx_tr">
<td id="S1.T1.1.13.11.1" class="ltx_td ltx_align_left">FTL</td>
<td id="S1.T1.1.13.11.2" class="ltx_td ltx_align_left">Federated transfer learning</td>
</tr>
<tr id="S1.T1.1.14.12" class="ltx_tr">
<td id="S1.T1.1.14.12.1" class="ltx_td ltx_align_left">GAN</td>
<td id="S1.T1.1.14.12.2" class="ltx_td ltx_align_left">Generative adversarial network</td>
</tr>
<tr id="S1.T1.1.15.13" class="ltx_tr">
<td id="S1.T1.1.15.13.1" class="ltx_td ltx_align_left">HE</td>
<td id="S1.T1.1.15.13.2" class="ltx_td ltx_align_left">Homomorphic encryption</td>
</tr>
<tr id="S1.T1.1.16.14" class="ltx_tr">
<td id="S1.T1.1.16.14.1" class="ltx_td ltx_align_left">HFL</td>
<td id="S1.T1.1.16.14.2" class="ltx_td ltx_align_left">Horizontal federated learning</td>
</tr>
<tr id="S1.T1.1.17.15" class="ltx_tr">
<td id="S1.T1.1.17.15.1" class="ltx_td ltx_align_left">IoT</td>
<td id="S1.T1.1.17.15.2" class="ltx_td ltx_align_left">Internet of things</td>
</tr>
<tr id="S1.T1.1.18.16" class="ltx_tr">
<td id="S1.T1.1.18.16.1" class="ltx_td ltx_align_left">P2P</td>
<td id="S1.T1.1.18.16.2" class="ltx_td ltx_align_left">Peer-to-peer</td>
</tr>
<tr id="S1.T1.1.19.17" class="ltx_tr">
<td id="S1.T1.1.19.17.1" class="ltx_td ltx_align_left">PoS</td>
<td id="S1.T1.1.19.17.2" class="ltx_td ltx_align_left">Proof of state</td>
</tr>
<tr id="S1.T1.1.20.18" class="ltx_tr">
<td id="S1.T1.1.20.18.1" class="ltx_td ltx_align_left">PoW</td>
<td id="S1.T1.1.20.18.2" class="ltx_td ltx_align_left">Proof of work</td>
</tr>
<tr id="S1.T1.1.21.19" class="ltx_tr">
<td id="S1.T1.1.21.19.1" class="ltx_td ltx_align_left">TEE</td>
<td id="S1.T1.1.21.19.2" class="ltx_td ltx_align_left">Trusted Executive Environment</td>
</tr>
<tr id="S1.T1.1.22.20" class="ltx_tr">
<td id="S1.T1.1.22.20.1" class="ltx_td ltx_align_left">TL</td>
<td id="S1.T1.1.22.20.2" class="ltx_td ltx_align_left">Transfer learning</td>
</tr>
<tr id="S1.T1.1.23.21" class="ltx_tr">
<td id="S1.T1.1.23.21.1" class="ltx_td ltx_align_left">VFL</td>
<td id="S1.T1.1.23.21.2" class="ltx_td ltx_align_left">Vertical federated learning</td>
</tr>
<tr id="S1.T1.1.24.22" class="ltx_tr">
<td id="S1.T1.1.24.22.1" class="ltx_td ltx_align_left">SC</td>
<td id="S1.T1.1.24.22.2" class="ltx_td ltx_align_left">Smart contract</td>
</tr>
<tr id="S1.T1.1.25.23" class="ltx_tr">
<td id="S1.T1.1.25.23.1" class="ltx_td ltx_align_left">SGD</td>
<td id="S1.T1.1.25.23.2" class="ltx_td ltx_align_left">Stochastic gradient decent</td>
</tr>
<tr id="S1.T1.1.26.24" class="ltx_tr">
<td id="S1.T1.1.26.24.1" class="ltx_td ltx_align_left">SL</td>
<td id="S1.T1.1.26.24.2" class="ltx_td ltx_align_left">Swarm learning</td>
</tr>
<tr id="S1.T1.1.27.25" class="ltx_tr">
<td id="S1.T1.1.27.25.1" class="ltx_td ltx_align_left">SMC</td>
<td id="S1.T1.1.27.25.2" class="ltx_td ltx_align_left">Secure multiparty computation</td>
</tr>
<tr id="S1.T1.1.28.26" class="ltx_tr">
<td id="S1.T1.1.28.26.1" class="ltx_td ltx_align_left ltx_border_bb">SPF</td>
<td id="S1.T1.1.28.26.2" class="ltx_td ltx_align_left ltx_border_bb">Single point of failure</td>
</tr>
</tbody>
</table>
</figure>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Currently, the literature lacks a survey that primarily studies the security and privacy of DFL. Available reviews on DFL generally study trending approaches in DFL with an emphasis on the application in the Internet of Things (IoT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. On the other hand, surveys on security and privacy of centralized FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> do not discuss the applicability of their analysis and findings to DFL. Among the limited number of surveys on DFL, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> studies security issues in centralized FL that can be addressed through blockchain integration. However, the literature still lacks a thorough security analysis of threats in DFL and its potential defense mechanisms. Hence, it is worthwhile to perform a comprehensive survey on the new attack surface created on DFL, and defense mechanisms that can be directly used or adapted for DFL. Toward this goal, this survey makes the following contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">State-of-the-art DFL methods are reviewed in terms of security robustness and employed technologies.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Potential threats to DFL systems are identified and explained.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Defense mechanisms that can safeguard DFL systems against attacks are studied and analyzed.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">The effect of blockchain integration on the security and privacy of DFL is studied.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">The connection between verifiable FL and DFL is studied from a security standpoint.</p>
</div>
</li>
<li id="S1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i6.p1" class="ltx_para">
<p id="S1.I1.i6.p1.1" class="ltx_p">Undiscovered domains and demanding research directions in enhancing DFL security and privacy are identified and introduced.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Reviewed works in this survey are collected from Scopus and Google Scholar searches. The keywords used for the search are FL, DFL, security, privacy, attack, defense, and blockchain. After the initial search, irrelevant papers to the topic of this survey were excluded. Furthermore, the search was limited to works after 2015, and we consider published or in-press research works, as well as arXiv preprints.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">Towards this, we outline the background for this survey in Section 2. Preliminaries of DFL are reviewed in Section 3. Section 4 studies possible threats to DFL. Section 5 discusses the potential defense mechanisms in DFL. Section 6 elaborates on the verifiability of DFL. Future research directions are discussed in Section 7. Finally, the survey is concluded in Section 8. This survey contains several abbreviations to make discussions more concise, which are listed in Table <a href="#S1.T1" title="TABLE I ‚Ä£ I Introduction ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">DFL is a paradigm that often encompasses both FL and blockchain technologies, although it is important to note that DFL can exist independently of blockchain. To better comprehend the concept of DFL, it is crucial to have a clear understanding of the fundamentals of FL and blockchain. Thus, the following section provides a concise overview of these concepts.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">FL was proposed to reduce the risks of data ownership in collaborative training of DL models. Prior to the introduction of FL, collaborative training required immense loads of data exchange between participants of a distributed machine learning framework in which the clients constantly send local training data to a central server. The distributed model is then trained on the accumulated training data gathered from across the network. Nevertheless, communicating user data and overburdening the network with excessive communication load raised new concerns that motivated the invention of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In simple words, rather than sharing the training of the local data with the server, the client in FL locally trains a model of the same structure on the user data and sends the obtained model parameters to the server once convergence is achieved. The server aggregates these parameters (e.g., neural network weights) and updates all the client models with the aggregated parameters. As this cycle continues, in each round, clients initialize their local model parameters with the received update from the server before starting the local training and issuing an update to the server. It is worth mentioning that the collaboration schemes between clients at the edge of the network have been a topic of interest in the domain of multi-agent systems even before the birth of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. For instance, client-server collaboration in FL somehow resembles the umbrella system in which all agents communicate with a server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The aforementioned process in FL, however, assumes the homogeneity of data among all clients, which may not always be the case. This leads to the evolution of FL into a more advanced structure for dealing with heterogeneous data and comes with additional security perks. Specifically, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> categorizes techniques in this field into three groups: 1) Horizontal FL (HFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, 2) Vertical FL (VFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and 3) Federated Transfer Learning (FTL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. The difference between these groups is in the nature of the training data in the FL systems. HFL which is basically defined based on the initial FL model in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, assumes a diverse range of samples across all local training sets that all fall under a similar feature space. VFL on the other hand, considers a common sample space among participants who differ in the feature space. FTL addresses the minimal overlap between both sample and feature space by resorting to transfer learning for transferring knowledge between participants.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">It is worth mentioning that this categorization has primarily focused on centralized FL. Therefore, the focus of this survey is primarily on DFL which differs from the centralized FL. The central server in the FL systems is in charge of verifying the network clients, aggregating the local parameters, and broadcasting an update. With the absence of servers in the DFL structure, these tasks must be performed using the client networks. The current literature usually devises the concept of blockchain to carry out the mentioned tasks.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Even though the initial FL model was proposed on the basis of DL, decision tree models can also be employed and adapted to FL frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Threats and defense mechanisms that will be later reviewed in this work generally apply to both DL and tree-based models.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Blockchain</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Blockchain is designed primarily with the objective of making the data exchange immutable and traceable over a P2P network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Similar to FL, in a blockchain network data is decentralized, and each user will transfer data using a block. This consists of the data, a hash acting as a unique identifier for the block, and a previous hash pointing to the previous block in the chain. While these hashes make the data traceable in the chain, they also complicate tampering with data, as changing the data in an existing block will also alter the associated hash which creates a discrepancy in the chain.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2401.17319/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Generic process of blockchain-based DFL. SC can use any choice of aggregation mechanism such as selecting the update with the highest score or averaging all received model parameters. <math id="S2.F2.3.m1.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S2.F2.3.m1.1b"><msub id="S2.F2.3.m1.1.1" xref="S2.F2.3.m1.1.1.cmml"><mi id="S2.F2.3.m1.1.1.2" xref="S2.F2.3.m1.1.1.2.cmml">S</mi><mi id="S2.F2.3.m1.1.1.3" xref="S2.F2.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.3.m1.1c"><apply id="S2.F2.3.m1.1.1.cmml" xref="S2.F2.3.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.3.m1.1.1.1.cmml" xref="S2.F2.3.m1.1.1">subscript</csymbol><ci id="S2.F2.3.m1.1.1.2.cmml" xref="S2.F2.3.m1.1.1.2">ùëÜ</ci><ci id="S2.F2.3.m1.1.1.3.cmml" xref="S2.F2.3.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.3.m1.1d">S_{i}</annotation></semantics></math> indicates the calculated score for the estimated model parameters for client <math id="S2.F2.4.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.F2.4.m2.1b"><mi id="S2.F2.4.m2.1.1" xref="S2.F2.4.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.F2.4.m2.1c"><ci id="S2.F2.4.m2.1.1.cmml" xref="S2.F2.4.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m2.1d">i</annotation></semantics></math>.</figcaption>
</figure>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">A key idea behind the blockchain is to prevent a certain participant from controlling the network and provide all network members with an equal chance to verify and control the transactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Nonetheless, finding the optimal solution to ensure fairness in assigning the evaluators is still an open problem and as a result, many consensus mechanisms have been proposed over time. Perhaps, the most common consensus mechanisms are Proof of Work (PoW) and Proof of State (PoS), albeit they are not necessarily the best. In PoW, the participants (also called miners) need to solve a time-consuming problem and anyone who achieves the answer quicker will get a chance to contribute to the chain. As an alternative to PoW, PoS randomly selects the evaluators with the aim of improving the scalability.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Based on the current literature, Blockchain approaches can fall into four major categories, namely 1) public, 2) private, 3) consortium, and 4) hybrid blockchain (i.e., we refer to this as DFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. These variations are briefly explained in the following.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Public:</span> Blockchain is built in a permissionless network that allows anyone to join the network and participate in the consensus process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Private:</span> Participants can join the network through a received authorization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. While permissions are granted in a centralized manner, the consensus mechanisms are decentralized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Consortium:</span> Blockchain is semi-decentralized and the network access is managed by more than one entity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Hybrid:</span> Block construction is carried out within a private network and the storage is done through a public network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Decentralized Federated Learning</span>
</h2>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2401.17319/assets/FIG3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="334" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Advances in decentralized federated learning in time. The order of the methods is set based on the first version that became available online (e.g., pre-prints).</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">As mentioned, the main flaw with the centralized FL is the dependency of the entire federation on a central server whose privacy and performance directly affect all the clients in the system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. In other words, a compromised server will jeopardize the whole federated learning system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. To eliminate the dependency of the whole network on a single node and also enhance the communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, DFL resorts to P2P communications to bypass the need for a central server. To do so, model aggregation and participant verification should be carried out in a serverless fashion.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">As explained in Section <a href="#S2" title="II Background ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, DFL often uses blockchain to facilitate inter-node communications. While this combination is non-absolute, blockchain can effectively facilitate communication by treating model updates as data within a block and sharing the block with respect to a consensus mechanism. In this process, local model construction is similar to that of FL, and prepared updates will be in the form of a data block. The prepared block will be then shared with the rest of the nodes for consensus and addition to the blockchain. The aggregation mechanisms of DFL work on the basis of decentralized Stochastic Gradient Decent (SGD), which makes use of gossip averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.8" class="ltx_p">DFL models that use blockchain have distinct architectures. For instance, the block structure, information included in the headers, aggregation, and consensus mechanisms can all be different in each architecture. However, a generic scheme is shown in Fig. <a href="#S2.F2" title="Figure 2 ‚Ä£ II-B Blockchain ‚Ä£ II Background ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> that resembles the most common practices in designing a blockchain-based DFL. In this example, the blockchain is initialized using a single block containing the starting global model. Each update is added as a new block that is linked to the previous block in the chain using a header. On the client‚Äôs side, the local model is initialized using the global model <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="u_{t}" display="inline"><semantics id="S3.p3.1.m1.1a"><msub id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">u</mi><mi id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">ùë¢</ci><ci id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">u_{t}</annotation></semantics></math> and trained on the <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p3.2.m2.1a"><mi id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">i</annotation></semantics></math>-th client data <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p3.3.m3.1a"><msub id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mi id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">D</mi><mi id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">ùê∑</ci><ci id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">D_{i}</annotation></semantics></math>. Once the trained model <math id="S3.p3.4.m4.1" class="ltx_Math" alttext="M_{i}" display="inline"><semantics id="S3.p3.4.m4.1a"><msub id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml"><mi id="S3.p3.4.m4.1.1.2" xref="S3.p3.4.m4.1.1.2.cmml">M</mi><mi id="S3.p3.4.m4.1.1.3" xref="S3.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.1b"><apply id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p3.4.m4.1.1.1.cmml" xref="S3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.p3.4.m4.1.1.2.cmml" xref="S3.p3.4.m4.1.1.2">ùëÄ</ci><ci id="S3.p3.4.m4.1.1.3.cmml" xref="S3.p3.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.1c">M_{i}</annotation></semantics></math> is obtained, a score <math id="S3.p3.5.m5.1" class="ltx_Math" alttext="S_{i}" display="inline"><semantics id="S3.p3.5.m5.1a"><msub id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml"><mi id="S3.p3.5.m5.1.1.2" xref="S3.p3.5.m5.1.1.2.cmml">S</mi><mi id="S3.p3.5.m5.1.1.3" xref="S3.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b"><apply id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p3.5.m5.1.1.1.cmml" xref="S3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.p3.5.m5.1.1.2.cmml" xref="S3.p3.5.m5.1.1.2">ùëÜ</ci><ci id="S3.p3.5.m5.1.1.3.cmml" xref="S3.p3.5.m5.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">S_{i}</annotation></semantics></math> is estimated w.r.t. the difference between the global model and the estimated local model. Nevertheless, not all blockchain-based DFL models necessarily use a scoring system. The client then uploads data to the blockchain by creating a block containing a header, trained model, estimated score, and the uploader identifier (ID). In some architectures, clients are directly communicating with a set of miners to obtain the Merkle root of the data before uploading the block. It is also worthwhile to mention that the block size is often limited to a fixed size. If the model size is larger than the block size, the uploader has to upload a set of serialized blocks to the blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. The SC on this blockchain uses a set of rules to determine when the global model should be updated. For instance, a minimum number of unique clients <math id="S3.p3.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p3.6.m6.1a"><mi id="S3.p3.6.m6.1.1" xref="S3.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p3.6.m6.1b"><ci id="S3.p3.6.m6.1.1.cmml" xref="S3.p3.6.m6.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m6.1c">k</annotation></semantics></math> are required to participate in updating <math id="S3.p3.7.m7.1" class="ltx_Math" alttext="u_{t}" display="inline"><semantics id="S3.p3.7.m7.1a"><msub id="S3.p3.7.m7.1.1" xref="S3.p3.7.m7.1.1.cmml"><mi id="S3.p3.7.m7.1.1.2" xref="S3.p3.7.m7.1.1.2.cmml">u</mi><mi id="S3.p3.7.m7.1.1.3" xref="S3.p3.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.7.m7.1b"><apply id="S3.p3.7.m7.1.1.cmml" xref="S3.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p3.7.m7.1.1.1.cmml" xref="S3.p3.7.m7.1.1">subscript</csymbol><ci id="S3.p3.7.m7.1.1.2.cmml" xref="S3.p3.7.m7.1.1.2">ùë¢</ci><ci id="S3.p3.7.m7.1.1.3.cmml" xref="S3.p3.7.m7.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m7.1c">u_{t}</annotation></semantics></math>. Furthermore, considering that each client is allowed to serialize its updates into multiple blocks, a limit is set to define the maximum number of contributions by each client in each round. The aggregation mechanism varies in different DFL architectures. While the majority of DFL models use an averaging function <math id="S3.p3.8.m8.1" class="ltx_Math" alttext="\sum(\cdot)" display="inline"><semantics id="S3.p3.8.m8.1a"><mrow id="S3.p3.8.m8.1.2" xref="S3.p3.8.m8.1.2.cmml"><mo rspace="0em" id="S3.p3.8.m8.1.2.1" xref="S3.p3.8.m8.1.2.1.cmml">‚àë</mo><mrow id="S3.p3.8.m8.1.2.2.2" xref="S3.p3.8.m8.1.2.cmml"><mo stretchy="false" id="S3.p3.8.m8.1.2.2.2.1" xref="S3.p3.8.m8.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.p3.8.m8.1.1" xref="S3.p3.8.m8.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.p3.8.m8.1.2.2.2.2" xref="S3.p3.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.8.m8.1b"><apply id="S3.p3.8.m8.1.2.cmml" xref="S3.p3.8.m8.1.2"><sum id="S3.p3.8.m8.1.2.1.cmml" xref="S3.p3.8.m8.1.2.1"></sum><ci id="S3.p3.8.m8.1.1.cmml" xref="S3.p3.8.m8.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.8.m8.1c">\sum(\cdot)</annotation></semantics></math> similar to that of federated averaging (FedAVG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, other frameworks use different approaches such as selecting the update with the highest score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">While the initial DFL model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> was proposed with the aim of security enhancement and failure robustness of FL using Bayesian beliefs of one-hop neighbors, several research studies extend their work by improving the overall efficiency and security. Fig. <a href="#S3.F3" title="Figure 3 ‚Ä£ III Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the historical evolution of DFL since it was first proposed in 2018. BAFFLE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> makes use of Smart Contracts (SC) to facilitate storing the FL model and clients‚Äô states. Model updates and aggregation is also carried out by resorting to SC. BAFFLE takes the computational states into account in order to preserve fairness among clients. Another approach, Blade-FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, uses clients for both mining and training via gossip learning. A novel consensus mechanism was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> to enhance the efficiency and privacy of the system. The DFL framework proposed based on this committee consensus mechanism is called BFLC. The Biscotti technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> integrates DFL with Differential Privacy (DP) to safeguard DFL against a range of attacks. Focused on healthcare applications, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> introduces the BindaaS method, which integrates DL as a service and lattices-based cryptography. This enables BinDaaS to employ an authentication phase that enhances DFL attack resilience. Another DP-based DFL approach called LearningChain is proposed with the aim of combating Byzantine attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. To do this, LearningChain utilizes a new aggregation mechanism for decentralized SGD. Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> designs the PIRATE framework based on the sharding approach in blockchain which helps in securing the aggregation process. BEAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> employs DP, gradient pruning, and anomaly detection to protect DFL against poisoning attacks. BEAS is also adapted for heterogeneous data to ensure proper convergence of the global model. BrainTorrent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> is a DFL method that employs version control and arbitrarily assigns a participant to act as the server. A reputation management scheme is used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> to select updates from reliable workers in the blockchain which reduces the probability of successful poisoning attacks in the DFL system. BlockFLA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, uses smart contracts to detect and penalize malicious nodes by means of monetary penalty. BlockFLA requires uploading hashed updates into separate private and public blockchains. Smart contracts is used for aggregating gradients whereas hashed updates are used for evaluating the updates through recovering the parameters to detect any mismatch. DFedForest is a tree-based DFL framework that uses bagging for tree construction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. This method devises a private test dataset for evaluating the uploaded parameters as malicious updates are expected to result in anomalous outputs on this data. Bift, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, designs a Proof of FL by combining PoW with FederatedAVG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and FederatedSGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> aggregation schemes to reach secure DFL with low communication overhead. A verifiable version of DFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> incorporates private key sharing and gradient masking into the consensus mechanism to defend against malicious miners and dropouts. Swarm Learning (SL) also integrates FL and blockchain to distributively train a model for diagnosing a number of diseases while safeguarding the patient‚Äôs data privacy and security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Security and privacy features of SL are limited to those of blockchain and the P2P DFL design. However, there is an extension of SL that couples it with HE is also presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> to secure SL communications against privacy attacks. Various aspects of SL such as fault tolerance, scalability, and fairness are studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, and the results indicate an overall improvement over centralized FL.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Despite the security advantages of blockchain integration with DFL, communication delay and resource consumption issues often become problematic in this domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. As mentioned in Section <a href="#S2" title="II Background ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, the process of model aggregation and achieving a consensus often requires sufficient computational power at the edge of the network which may not always be practical (e.g., mobile networks). This becomes more critical for consensus mechanisms such as PoW. As a result, the model aggregation process may be usually delayed due to the potential computational constraints.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Threats to Decentralized Federated Learning</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As shown in Fig. <a href="#S4.F4" title="Figure 4 ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the security and performance of DFL are directly related to those of FL and blockchain. Generally, threats to DFL target privacy or the performance of the global model. In centralized FL, all the possible threats involve the server at some point as the server is the core of the system for aggregation, communication, and validation. As a result, the trustworthiness of the server is of great importance in FL as a malicious server can easily attack all clients. On the other hand, attacking the server and causing a malfunction can also disable the entire system. Table <a href="#S4.T2" title="TABLE II ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> lists sources of threats for common attacks on FL. However, in DFL, all possible threats will be traced back to the clients or miners. Table <a href="#S4.T5" title="TABLE V ‚Ä£ IV-C3 Defensibility ‚Ä£ IV-C Analyzing the Viability of Attacks ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> indicates attack models that are considered in the design of the aforementioned DFL techniques.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Identification of sources of attacks in FL systems.</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Attacks</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">Source of Attack</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<td id="S4.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Data poisoning</td>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<td id="S4.T2.1.3.2.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Gradient manipulation</td>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<td id="S4.T2.1.4.3.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Backdoor attack</td>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client and malicious server</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<td id="S4.T2.1.5.4.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Evasion attack</td>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client and model deployment</td>
</tr>
<tr id="S4.T2.1.6.5" class="ltx_tr">
<td id="S4.T2.1.6.5.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Non-robust aggregation</td>
<td id="S4.T2.1.6.5.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Aggregation algorithm</td>
</tr>
<tr id="S4.T2.1.7.6" class="ltx_tr">
<td id="S4.T2.1.7.6.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Training rule manipulation</td>
<td id="S4.T2.1.7.6.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client</td>
</tr>
<tr id="S4.T2.1.8.7" class="ltx_tr">
<td id="S4.T2.1.8.7.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Inference attacks</td>
<td id="S4.T2.1.8.7.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious server and communication</td>
</tr>
<tr id="S4.T2.1.9.8" class="ltx_tr">
<td id="S4.T2.1.9.8.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">GAN reconstruction</td>
<td id="S4.T2.1.9.8.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious server and communication</td>
</tr>
<tr id="S4.T2.1.10.9" class="ltx_tr">
<td id="S4.T2.1.10.9.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Free-riding attack</td>
<td id="S4.T2.1.10.9.2" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">Malicious client</td>
</tr>
<tr id="S4.T2.1.11.10" class="ltx_tr">
<td id="S4.T2.1.11.10.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">Man-in-the-middle attack</td>
<td id="S4.T2.1.11.10.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">Communication</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2401.17319/assets/x3.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="332" height="170" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Overview of security and privacy threats on decentralized federated learning. Threats are generally related to privacy, model robustness, or blockchain bottleneck of DFL.</figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Malicious clients can follow different attack models to jeopardize the performance or privacy of the system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. For instance, an adversary can be either semi-honest or aggressive. In the semi-honest model, the objective is to infer confidential information while complying with the DFL protocol. This phase can be also used as a reconnaissance step prior to launching an aggressive attack where the aim is to degrade the system‚Äôs performance. Using this combination, one can first learn the global model parameters using a semi-honest approach and then actively forge malicious updates in order to insert a backdoor in the global model. Due to the immutability of blockchain, hackers cannot directly manipulate the training data in a block. Nevertheless, they can reach their objective by sending the gradients that lead to incorrect predictions. To do so, gradients can be forged targeted or untargeted. As the name implies, the latter aims at degrading the performance of all classes in general whereas the targeted scheme only attacks a certain class without tampering with the rest of the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Attacks on Performance</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The performance of the DFL model is mostly targeted by means of poisoning attacks. In addition, there are certain blockchain-based attacks that also apply to DFL. An overview of these attacks for DFL is given in the following.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.5.1.1" class="ltx_text">IV-A</span>1 </span>Data Poisoning</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Data poisoning techniques in FL and DFL could be somewhat different. In centralized FL, data poisoning is referred to as the process of corrupting the local training data via backdoor injection or introducing label noise which in turn produces deviating gradients and misleads the FL model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. In this setting, usually, the intruder disguises as a member of the federation and uses its artificially made data. As an example, reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> studies different variations of label poisoning in federated learning systems and mitigates these attacks by reformulating the problem as a label noise classification task.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">Aside from the aforementioned mechanisms for data poisoning, the following attacks can be planned to take advantage of the blockchain backbone that most DFL methods rely on:</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p"><span id="S4.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Disrupting Communications:</span>
Blockchain is robust by nature against Denial of Service (DoS) attacks as there is no possible SPF that can be targeted. Nevertheless, Distributed DoS (DDoS) attacks can still slow down inter-node communications in the DFL system. DDoS agents continuously generate fake transactions and send them to the chain to fill up the blockchain buffer with spam data once the blockchain capacity is reached. This significantly postpones the inclusion of valid data into the upcoming blocks which puts the functionality of the blockchain under question. This is besides the permanent effect DDoS leaves on the DFL due to the data immutability of the blockchain.</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<p id="S4.SS1.SSS1.p4.3" class="ltx_p"><span id="S4.SS1.SSS1.p4.3.1" class="ltx_text ltx_font_bold">Degrading Detection Performance:</span> Using a targeted attack model, an intruder can inject certain triggers into the local model and obtain gradients in a way that the rest of the model remains intact <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. This backdoor attack results in sharing the poisoned parameters with the rest of the DFL participants and introducing the backdoor into their model as well. For instance, backdoors are injected into the DFL network in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> with two different mechanisms, namely label flipping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> and pixel patch backdoor <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. The number of malicious nodes is restricted to prevent intruders from controlling the consensus (i.e., <math id="S4.SS1.SSS1.p4.1.m1.1" class="ltx_Math" alttext="2N_{corrupted}+2&lt;N" display="inline"><semantics id="S4.SS1.SSS1.p4.1.m1.1a"><mrow id="S4.SS1.SSS1.p4.1.m1.1.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.cmml"><mrow id="S4.SS1.SSS1.p4.1.m1.1.1.2" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.cmml"><mrow id="S4.SS1.SSS1.p4.1.m1.1.1.2.2" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.cmml"><mn id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.2" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.1.cmml">‚Äã</mo><msub id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.cmml"><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.2" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.2.cmml">N</mi><mrow id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.cmml"><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.2" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.3" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1a" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.4" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1b" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.5" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1c" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.6" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1d" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.7" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1e" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.8" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1f" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.9" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1g" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.10" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.10.cmml">d</mi></mrow></msub></mrow><mo id="S4.SS1.SSS1.p4.1.m1.1.1.2.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.1.cmml">+</mo><mn id="S4.SS1.SSS1.p4.1.m1.1.1.2.3" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.3.cmml">2</mn></mrow><mo id="S4.SS1.SSS1.p4.1.m1.1.1.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.1.cmml">&lt;</mo><mi id="S4.SS1.SSS1.p4.1.m1.1.1.3" xref="S4.SS1.SSS1.p4.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.1.m1.1b"><apply id="S4.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1"><lt id="S4.SS1.SSS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.1"></lt><apply id="S4.SS1.SSS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2"><plus id="S4.SS1.SSS1.p4.1.m1.1.1.2.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.1"></plus><apply id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2"><times id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.1"></times><cn type="integer" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.2.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.2">2</cn><apply id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3">subscript</csymbol><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.2.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.2">ùëÅ</ci><apply id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3"><times id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.1"></times><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.2.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.2">ùëê</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.3.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.3">ùëú</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.4.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.4">ùëü</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.5.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.5">ùëü</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.6.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.6">ùë¢</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.7.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.7">ùëù</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.8.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.8">ùë°</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.9.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.9">ùëí</ci><ci id="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.10.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.2.3.3.10">ùëë</ci></apply></apply></apply><cn type="integer" id="S4.SS1.SSS1.p4.1.m1.1.1.2.3.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.2.3">2</cn></apply><ci id="S4.SS1.SSS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1.3">ùëÅ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.1.m1.1c">2N_{corrupted}+2&lt;N</annotation></semantics></math>, where <math id="S4.SS1.SSS1.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.SSS1.p4.2.m2.1a"><mi id="S4.SS1.SSS1.p4.2.m2.1.1" xref="S4.SS1.SSS1.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.2.m2.1b"><ci id="S4.SS1.SSS1.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p4.2.m2.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.2.m2.1c">N</annotation></semantics></math> and <math id="S4.SS1.SSS1.p4.3.m3.1" class="ltx_Math" alttext="N_{corrupted}" display="inline"><semantics id="S4.SS1.SSS1.p4.3.m3.1a"><msub id="S4.SS1.SSS1.p4.3.m3.1.1" xref="S4.SS1.SSS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.SSS1.p4.3.m3.1.1.2" xref="S4.SS1.SSS1.p4.3.m3.1.1.2.cmml">N</mi><mrow id="S4.SS1.SSS1.p4.3.m3.1.1.3" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.cmml"><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.2" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.3" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1a" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.4" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1b" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.5" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1c" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.6" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1d" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.7" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.7.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1e" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.8" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1f" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.9" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS1.p4.3.m3.1.1.3.1g" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.SSS1.p4.3.m3.1.1.3.10" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.10.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.3.m3.1b"><apply id="S4.SS1.SSS1.p4.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.2">ùëÅ</ci><apply id="S4.SS1.SSS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3"><times id="S4.SS1.SSS1.p4.3.m3.1.1.3.1.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.1"></times><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.2.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.2">ùëê</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.3.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.3">ùëú</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.4.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.4">ùëü</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.5.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.5">ùëü</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.6.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.6">ùë¢</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.7.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.7">ùëù</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.8.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.8">ùë°</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.9.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.9">ùëí</ci><ci id="S4.SS1.SSS1.p4.3.m3.1.1.3.10.cmml" xref="S4.SS1.SSS1.p4.3.m3.1.1.3.10">ùëë</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.3.m3.1c">N_{corrupted}</annotation></semantics></math> indicate the number of all nodes and corrupted ones, respectively). A pixel pattern backdoor is also simulated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> for DFL with smart contract. The untargeted scheme of this attack which is also known as the Crashing DoS attack, follows the same process with the exception of degrading the performance of the entire model rather than for a specific class. While the untargeted version is easier to implement, it is also easier to detect. Note that the literature usually defines DoS differently for blockchain and FL. DoS in blockchain renders the global model inaccessible, whereas in FL, it makes the global model unusable. Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> presents an example of a data poisoning attack in DFL which is simulated with the aim of corrupting the global model performance. In this scenario, 30 percent of nodes are considered malicious, with the assumption that the number of malicious nodes does not change in time. Another case is tested in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> by generating forged gradients drawn from a Gaussian distribution by several Byzantine data holders (i.e., trusted nodes went rouge in the DFL network). Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> simulates this attack by filliping the class labels randomly on the training data. In contrast to poisoning attacks that primarily corrupt the training process, evasion or exploratory attacks occur during the inference phase after the model has been trained. Their goal is typically not to change the trained model, but rather to generate incorrect predictions or gather information about the model‚Äôs characteristics.</p>
</div>
<div id="S4.SS1.SSS1.p5" class="ltx_para">
<p id="S4.SS1.SSS1.p5.1" class="ltx_p"><span id="S4.SS1.SSS1.p5.1.1" class="ltx_text ltx_font_bold">Causing Legal Problems:</span> By law, the inclusion of personal data is prohibited in some regions of the world. European general data protection regulation can be mentioned as a good example of this legal constraint. A malicious user, however, can poison the blockchain by inserting personal data into a data block and adding it to the chain which makes the DFL system non-compliant with the existing legal bounds. We call these adversaries privacy poisoning attacks. Despite its importance, not many research studies considering this type of attack in a DFL paradigm have been reported.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Characteristics and description of attacks in DFL. The ease of implementation, effectiveness, and defense feasibility for each attack is evaluated.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Attacks</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Target</th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Implementation</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Effectiveness</th>
<th id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Defensibility</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Backdoor</th>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Performance</td>
<td id="S4.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†DoS/DDoS</th>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Performance</td>
<td id="S4.T3.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<th id="S4.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Gradient manipulation</th>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Performance</td>
<td id="S4.T3.1.4.3.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.4.3.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.4.3.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<th id="S4.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Training objective manipulation</th>
<td id="S4.T3.1.5.4.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Performance</td>
<td id="S4.T3.1.5.4.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.5.4.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.5.4.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.6.5" class="ltx_tr">
<th id="S4.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Evasion attacks</th>
<td id="S4.T3.1.6.5.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Performance</td>
<td id="S4.T3.1.6.5.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.6.5.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.6.5.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
</tr>
<tr id="S4.T3.1.7.6" class="ltx_tr">
<th id="S4.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Model inversion</th>
<td id="S4.T3.1.7.6.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Privacy</td>
<td id="S4.T3.1.7.6.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.7.6.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Low</td>
<td id="S4.T3.1.7.6.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
</tr>
<tr id="S4.T3.1.8.7" class="ltx_tr">
<th id="S4.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Feature inference</th>
<td id="S4.T3.1.8.7.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Privacy</td>
<td id="S4.T3.1.8.7.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.8.7.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.8.7.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
</tr>
<tr id="S4.T3.1.9.8" class="ltx_tr">
<th id="S4.T3.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Membership inference</th>
<td id="S4.T3.1.9.8.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Privacy</td>
<td id="S4.T3.1.9.8.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.9.8.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.9.8.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.10.9" class="ltx_tr">
<th id="S4.T3.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Hijacking private key</th>
<td id="S4.T3.1.10.9.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.10.9.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.10.9.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.10.9.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.11.10" class="ltx_tr">
<th id="S4.T3.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†51% attack</th>
<td id="S4.T3.1.11.10.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.11.10.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.11.10.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.11.10.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.12.11" class="ltx_tr">
<th id="S4.T3.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Sybil attacks</th>
<td id="S4.T3.1.12.11.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.12.11.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.12.11.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.12.11.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.13.12" class="ltx_tr">
<th id="S4.T3.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Double spending</th>
<td id="S4.T3.1.13.12.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.13.12.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.13.12.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.13.12.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.14.13" class="ltx_tr">
<th id="S4.T3.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Routing attacks</th>
<td id="S4.T3.1.14.13.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.14.13.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Simple</td>
<td id="S4.T3.1.14.13.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.14.13.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
</tr>
<tr id="S4.T3.1.15.14" class="ltx_tr">
<th id="S4.T3.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Privacy poisoning</th>
<td id="S4.T3.1.15.14.2" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain/Privacy</td>
<td id="S4.T3.1.15.14.3" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.15.14.4" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
<td id="S4.T3.1.15.14.5" class="ltx_td ltx_align_center" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
</tr>
<tr id="S4.T3.1.16.15" class="ltx_tr">
<th id="S4.T3.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Attacks on SC</th>
<td id="S4.T3.1.16.15.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Blockchain</td>
<td id="S4.T3.1.16.15.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Challenging</td>
<td id="S4.T3.1.16.15.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†High</td>
<td id="S4.T3.1.16.15.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:17.0pt;padding-right:17.0pt;">¬†¬†¬†¬†¬†¬†Moderate</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.5.1.1" class="ltx_text">IV-A</span>2 </span>Model Poisoning</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Model poisoning is the process of maliciously controlling global model training. While data poisoning can be also used as a tool to cause model poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, model poisoning without data manipulation is also possible. As an example, one can simply change the objective of the local model to obtain poisoned gradients using valid data on the same model structure as the rest of the network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. For instance, an additional term can be added to the objective to penalize sensitivity to malicious data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. The same approach can be followed to deteriorate the overall performance in an untargeted manner (e.g., gradient manipulation). This case is also studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> where a set of Byzantine nodes are considered to generate and inject deviating gradients into the blockchain in order to degrade the shared DFL model via an outsider attack. A similar approach is used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> to corrupt gradients using pointwise Gaussian noise.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS3.5.1.1" class="ltx_text">IV-A</span>3 </span>Routing Attacks</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Reliable network infrastructure is of paramount importance for DFL due to its integration with blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. This is while some of the utilized network protocols used by current internet service providers, such as the border gateway protocol, come with security flaws. Blockchain has no control over the network layer as it mostly works in the application layer. Thus, if the service provider network is breached, the routing of packets can be tampered with to either discard the transferring data blocks or change the blockchain structure. An example of a routing attack is a hack that took place in 2014 in which the intruder used the hijacked blocks to provide PoW and steal the associated rewards.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS4.5.1.1" class="ltx_text">IV-A</span>4 </span>Consensus Attacks</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">The objective of these attacks is to obtain the majority of approvals in order to control the consensus mechanism in the DFL system. Depending on the number of agents or nodes involved in these attacks, they will be called 51% or Sybil attacks. Sybil attacks indicate the scenario in which an intruder creates multiple fake nodes and claims to be more than one entity to impose a greater influence on the consensus. If intruders manage to take control of 51 percent of the nodes, the consensus mechanism is fully controllable. At this scale, the attack is known as 51% attack in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. It is worth mentioning that consensus attacks are most effective when the blockchain associated with the DFL is at its early stage when the number of participants is still limited. PoW and PoS can drastically complicate consensus attacks for hackers.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Attacks on Privacy</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Despite the decentralization of data in DFL, gradient and parameter information can be visible to system clients. Previously, we studied the effect of such information leakage on the performance of the DFL model. Here, we elaborate on the privacy risks associated with DFL networks.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Model Inversion Attacks</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Model inversion can be used to approximate and reconstruct the private data of clients merely based on the classification model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. An example of this attack is reported in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> where gradient leakage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> of a global DFL model is used for reconstructing the user‚Äôs local data. This process is often carried out using a DL-based generator. For instance, Generative Adversarial Networks (GAN) can be employed to perform model inversion by using the target model as the discriminator and training a generator network to minimize a cost that eventually converges and produces data samples similar to that of the targeted client.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Membership Inference Attacks</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">Membership inference attacks are focused on revealing sensitive information associated with certain samples. Membership inference can disclose the membership of a sample to a certain class, or elicit attribute information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. An example of this attack can be found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, where an inference attack by observing the clients‚Äô updates in a DFL network and using the leaked gradients to infer record-level information of local datasets.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.5.1.1" class="ltx_text">IV-B</span>3 </span>Hijacking Private Key</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">Securing private keys and public key using cryptography is one of the most critical aspects of blockchain which is the backbone of DFL. If there is any imperfection in the key signing mechanism, hackers can hijack a client‚Äôs private key using their public key. Taking over a client‚Äôs private key enables the hacker to gain full access to the corresponding data in the blockchain.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS4.5.1.1" class="ltx_text">IV-B</span>4 </span>Vulnerability of Smart Contracts</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">Smart contracts, which are coded agreements utilizing blockchain technology for record-keeping, can be susceptible to security flaws. While they eliminate the need for intermediaries and provide immutable contracts, there is a risk associated with poorly coded smart contracts. These coding vulnerabilities create opportunities for attackers to identify flaws in the code and exploit them. By exploiting these weaknesses, attackers can potentially manipulate or extract unauthorized access to the contract‚Äôs contents or associated assets. It is crucial to ensure thorough code review and rigorous testing to identify and address these security flaws to safeguard the integrity and trustworthiness of smart contracts.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Analyzing the Viability of Attacks</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Table <a href="#S4.T3" title="TABLE III ‚Ä£ IV-A1 Data Poisoning ‚Ä£ IV-A Attacks on Performance ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> provides an overview of the analyzed attacks, highlighting their key characteristics. When evaluating these attacks, it is crucial to assess their feasibility and effectiveness to design effective defense mechanisms and allocate appropriate resources to secure DFL systems.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.5.1.1" class="ltx_text">IV-C</span>1 </span>Ease of implementation</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Implementing a backdoor attack is considered to be difficult because it requires extensive knowledge of the target DFL system, access to training data, and the ability to modify model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Backdoor attacks often involve sophisticated techniques and may require compromising multiple clients or insiders with privileged access <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. Conversely, carrying out a DoS or DDoS attack is relatively less complicated. These attacks overwhelm the system with a high volume of requests or malicious traffic, and readily available tools and techniques can be used to execute them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">Gradient manipulation necessitates a deep understanding of the DFL system‚Äôs architecture, algorithms, and access to the communication channels. Tampering with gradients exchanged between clients and the server is a challenging task that requires careful execution to avoid detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. Similarly, manipulating the training objective, such as modifying the loss function or optimization process, is also categorized as hard. It demands an in-depth understanding of the system‚Äôs algorithms, access to the training process, and the ability to modify the objective without disrupting the overall learning process.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">On the other hand, attacks such as evasion attacks and model inversion are easier to implement. These attacks can be implemented using existing knowledge and techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. Other attacks, including feature inference and Sybil attacks, are also categorized as easy to implement. In contrast, attacks such as membership inference, hijacking private keys, 51% attacks, consensus attacks, and double spending are challenging attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. These attacks require advanced knowledge, sophisticated attacks, and access to specific components or mechanisms of the DFL system. Implementing them successfully is a complex and resource-intensive task. Furthermore, privacy poisoning attacks are not overly complex or technically challenging, leading to a medium level of ease of implementation. The process may involve tampering with the data blocks and ensuring the inclusion of personal information, but it does not require advanced technical skills or extensive resources. Moreover, finding security holes in SC is a complex task as these protocols are usually well-tested before release, and sophisticated technical skills are required to hack SC under this condition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.5.1.1" class="ltx_text">IV-C</span>2 </span>Effectiveness of Attacks</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">In terms of attack effectiveness, the backdoor attack is classified as high. This attack has the potential to significantly impact the model‚Äôs predictions, compromising the integrity and reliability of the DFL system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. On the other hand, DoS/DDoS attacks are considered to have a moderate level of effectiveness. While they can disrupt the normal functioning of the system and cause temporary delays, their impact on the actual model parameters or the accuracy of the aggregated model may vary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">Gradient manipulation and training objective manipulation attacks are both considered to have a moderate level of effectiveness. Tampering with gradients or modifying the training objective can potentially influence the learning process and impact the accuracy of the aggregated model. However, their success depends on the robustness of the DFL system and the defense mechanisms in place <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">Evasion attacks and model inversion attacks are also considered to have a moderate level of effectiveness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. Their impact on the overall model performance may be limited depending on the effectiveness of the defense mechanisms. Membership inference attacks, on the other hand, are classified as having a high level of effectiveness. Successfully inferring membership information about specific individuals participating in the DFL system can have severe privacy implications.</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<p id="S4.SS3.SSS2.p4.1" class="ltx_p">Attacks targeting the blockchain aspect of DFL, such as hijacking private keys, 51% attacks, consensus attacks, Sybil attacks, double spending, and routing attacks, are generally considered to have a high level of effectiveness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. These attacks have the potential to compromise the security, integrity, and trust of the DFL system, depending on the specific vulnerabilities and defense mechanisms in place. Moreover, privacy poisoning attacks can have a moderate impact on compromising the privacy of participants in the DFL system. While the effectiveness of privacy poisoning attacks is not as high as some other attacks, it still poses a significant risk to the privacy of participants and the overall integrity of the system. In addition, exploiting the vulnerabilities of SC can lead to losing digital trust and massive financial loss. For instance, reports indicate that crypto investors nearly lost four billion dollars to hackers in 2022.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS3.5.1.1" class="ltx_text">IV-C</span>3 </span>Defensibility</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">Backdoor attacks involve inserting malicious behavior into the training data or model, making it challenging to detect and defend against. Detecting and mitigating backdoor attacks often require advanced techniques and rigorous model verification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p">DoS/DDoS attacks are classified as moderately defensible. While it may be challenging to completely prevent DoS/DDoS attacks, there are various mitigation strategies available, including anomaly detection. Such methods can reduce the impact of DoS/DDoS attacks and keep the system operational <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS3.p3" class="ltx_para">
<p id="S4.SS3.SSS3.p3.1" class="ltx_p">Defending against gradient manipulation and training objective manipulation attacks is also categorized as moderately defensible. Implementing techniques like DP, robust aggregation algorithms, and secure communication protocols can enhance the system‚Äôs resilience against these attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. However, the effectiveness of the defense mechanisms may vary based on the sophistication of the attack and the quality of the defense techniques.</p>
</div>
<div id="S4.SS3.SSS3.p4" class="ltx_para">
<p id="S4.SS3.SSS3.p4.1" class="ltx_p">Evasion attacks and model inversion attacks are considered moderately defensible. Privacy-preserving techniques, such as DP or SMC, can help protect against these attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>. However, achieving strong defenses requires careful design and implementation, considering factors like attack vectors and data sensitivity.</p>
</div>
<div id="S4.SS3.SSS3.p5" class="ltx_para">
<p id="S4.SS3.SSS3.p5.1" class="ltx_p">Defending against membership inference attacks is classified as challenging due to the difficulty of protecting individual privacy in the FL setting. Advanced privacy protection techniques, such as privacy amplification and enhanced model aggregation protocols, are needed to effectively mitigate the risk of membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS3.p6" class="ltx_para">
<p id="S4.SS3.SSS3.p6.1" class="ltx_p">Regarding attacks on the blockchain aspect of DFL, the defensibility levels vary depending on the specific attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. Hijacking private keys, 51% attacks, and double spending attacks are challenging to defend against due to the vulnerabilities they exploit in the blockchain infrastructure. Implementing robust consensus mechanisms, multi-factor authentication, and encryption can enhance the defensibility against these attacks. Defending against consensus attacks, Sybil attacks, and routing attacks requires strong identity management systems, network monitoring, and reputation-based mechanisms. Defending against privacy poisoning attacks requires a combination of technical, legal, and regulatory measures, making it of medium difficulty in terms of defensibility. In addition, ensuring the security and integrity of SC has a moderate level of difficulty since it requires sophisticated code review and rigorous testing to identify and eliminate potential security holes and flaws.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Characteristics and applicability of defense mechanisms. The final column denotes the specific types of attacks for which each defense mechanism is suitable.</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Defense mechanism</td>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt">Description</td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt">Weakness</td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_align_left ltx_border_tt">Used against</td>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<td id="S4.T4.1.2.2.1" class="ltx_td ltx_align_left ltx_border_tt">Homomorphic Encryption</td>
<td id="S4.T4.1.2.2.2" class="ltx_td ltx_align_left ltx_border_tt">Encrypts parameters</td>
<td id="S4.T4.1.2.2.3" class="ltx_td ltx_align_left ltx_border_tt">Computational overhead</td>
<td id="S4.T4.1.2.2.4" class="ltx_td ltx_align_left ltx_border_tt">Attacks on privacy</td>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<td id="S4.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">SMC</td>
<td id="S4.T4.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">Protects data with multiparty computation</td>
<td id="S4.T4.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">Communication overhead</td>
<td id="S4.T4.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">Attacks on privacy</td>
</tr>
<tr id="S4.T4.1.4.4" class="ltx_tr">
<td id="S4.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_border_t">Differential Privacy</td>
<td id="S4.T4.1.4.4.2" class="ltx_td ltx_align_left ltx_border_t">Perturbs parameters with noise</td>
<td id="S4.T4.1.4.4.3" class="ltx_td ltx_align_left ltx_border_t">Accuracy loss</td>
<td id="S4.T4.1.4.4.4" class="ltx_td ltx_align_left ltx_border_t">Attacks on privacy</td>
</tr>
<tr id="S4.T4.1.5.5" class="ltx_tr">
<td id="S4.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_border_t">Anomaly Detection</td>
<td id="S4.T4.1.5.5.2" class="ltx_td ltx_align_left ltx_border_t">Monitors updates to detect abnormalities</td>
<td id="S4.T4.1.5.5.3" class="ltx_td ltx_align_left ltx_border_t">Backdoors can bypass it</td>
<td id="S4.T4.1.5.5.4" class="ltx_td ltx_align_left ltx_border_t">Untargeted poisoning</td>
</tr>
<tr id="S4.T4.1.6.6" class="ltx_tr">
<td id="S4.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_border_t">Robust Aggregation</td>
<td id="S4.T4.1.6.6.2" class="ltx_td ltx_align_left ltx_border_t">Safeguards global aggregation against adversaries</td>
<td id="S4.T4.1.6.6.3" class="ltx_td ltx_align_left ltx_border_t">Limiting assumptions</td>
<td id="S4.T4.1.6.6.4" class="ltx_td ltx_align_left ltx_border_t">Poisoning attacks</td>
</tr>
<tr id="S4.T4.1.7.7" class="ltx_tr">
<td id="S4.T4.1.7.7.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.7.7.1.1" class="ltx_text">Pruning</span></td>
<td id="S4.T4.1.7.7.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.7.7.2.1" class="ltx_text">Randomly drops neurons from global model</span></td>
<td id="S4.T4.1.7.7.3" class="ltx_td ltx_align_left ltx_border_t">Computational overhead</td>
<td id="S4.T4.1.7.7.4" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.7.7.4.1" class="ltx_text">Backdoor attacks</span></td>
</tr>
<tr id="S4.T4.1.8.8" class="ltx_tr">
<td id="S4.T4.1.8.8.1" class="ltx_td ltx_align_left">Performance loss</td>
</tr>
<tr id="S4.T4.1.9.9" class="ltx_tr">
<td id="S4.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_border_t">TEE</td>
<td id="S4.T4.1.9.9.2" class="ltx_td ltx_align_left ltx_border_t">A secure ecosystem for maintaining digital trust</td>
<td id="S4.T4.1.9.9.3" class="ltx_td ltx_align_left ltx_border_t">Limited memory size</td>
<td id="S4.T4.1.9.9.4" class="ltx_td ltx_align_left ltx_border_t">White box attacks</td>
</tr>
<tr id="S4.T4.1.10.10" class="ltx_tr">
<td id="S4.T4.1.10.10.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T4.1.10.10.1.1" class="ltx_text">Zero-Knowledge Proofs</span></td>
<td id="S4.T4.1.10.10.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T4.1.10.10.2.1" class="ltx_text">Uses unconnected bits of information to hide data</span></td>
<td id="S4.T4.1.10.10.3" class="ltx_td ltx_align_left ltx_border_t">Computational overhead</td>
<td id="S4.T4.1.10.10.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.1.10.10.4.1" class="ltx_text">Privacy attacks</span></td>
</tr>
<tr id="S4.T4.1.11.11" class="ltx_tr">
<td id="S4.T4.1.11.11.1" class="ltx_td ltx_align_left">Communication overhead</td>
<td id="S4.T4.1.11.11.2" class="ltx_td ltx_align_left" rowspan="2"><span id="S4.T4.1.11.11.2.1" class="ltx_text">Poisoning attacks</span></td>
</tr>
<tr id="S4.T4.1.12.12" class="ltx_tr">
<td id="S4.T4.1.12.12.1" class="ltx_td ltx_align_left">Complex implementation</td>
</tr>
<tr id="S4.T4.1.13.13" class="ltx_tr">
<td id="S4.T4.1.13.13.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.13.13.1.1" class="ltx_text">Knowledge Distillation</span></td>
<td id="S4.T4.1.13.13.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.13.13.2.1" class="ltx_text">Performs TL to indirectly train a smaller model</span></td>
<td id="S4.T4.1.13.13.3" class="ltx_td ltx_align_left ltx_border_t">Computational overhead</td>
<td id="S4.T4.1.13.13.4" class="ltx_td ltx_align_left ltx_border_t">Privacy attacks</td>
</tr>
<tr id="S4.T4.1.14.14" class="ltx_tr">
<td id="S4.T4.1.14.14.1" class="ltx_td ltx_align_left">Not a stand-alone defense</td>
<td id="S4.T4.1.14.14.2" class="ltx_td ltx_align_left">Poisoning attacks</td>
</tr>
<tr id="S4.T4.1.15.15" class="ltx_tr">
<td id="S4.T4.1.15.15.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.15.15.1.1" class="ltx_text">Regularization</span></td>
<td id="S4.T4.1.15.15.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T4.1.15.15.2.1" class="ltx_text">Prevents global model from overfitting</span></td>
<td id="S4.T4.1.15.15.3" class="ltx_td ltx_align_left ltx_border_t">Sensitivity to hyperparameters</td>
<td id="S4.T4.1.15.15.4" class="ltx_td ltx_align_left ltx_border_t">Privacy attacks</td>
</tr>
<tr id="S4.T4.1.16.16" class="ltx_tr">
<td id="S4.T4.1.16.16.1" class="ltx_td ltx_align_left">Computational overhead</td>
<td id="S4.T4.1.16.16.2" class="ltx_td ltx_align_left">Poisoning attacks</td>
</tr>
<tr id="S4.T4.1.17.17" class="ltx_tr">
<td id="S4.T4.1.17.17.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T4.1.17.17.1.1" class="ltx_text">Blockchain</span></td>
<td id="S4.T4.1.17.17.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T4.1.17.17.2.1" class="ltx_text">Secures DFL communications</span></td>
<td id="S4.T4.1.17.17.3" class="ltx_td ltx_align_left ltx_border_t">Computational overhead</td>
<td id="S4.T4.1.17.17.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T4.1.17.17.4.1" class="ltx_text">Poisoning attacks</span></td>
</tr>
<tr id="S4.T4.1.18.18" class="ltx_tr">
<td id="S4.T4.1.18.18.1" class="ltx_td ltx_align_left ltx_border_bb">Blockchain security issues</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Security analysis of state-of-the-art DFL methods. All models are robust against SPF. ‚óã, ‚óê, and ‚óè¬†denote not robust, partially robust, and robust, respectively. ‚úìand <math id="S4.T5.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.2.m1.1b"><mo id="S4.T5.2.m1.1.1" xref="S4.T5.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.m1.1c"><times id="S4.T5.2.m1.1.1.cmml" xref="S4.T5.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.m1.1d">\times</annotation></semantics></math> indicate whether the specified technology is used or not. Attacks or technologies that are not included in this table are not studied in the listed methods.</figcaption>
<table id="S4.T5.18" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.18.17.1" class="ltx_tr">
<th id="S4.T5.18.17.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Methods</th>
<th id="S4.T5.18.17.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">References</th>
<th id="S4.T5.18.17.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Blockchain</th>
<th id="S4.T5.18.17.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Encryption</th>
<th id="S4.T5.18.17.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Clients</th>
<th id="S4.T5.18.17.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Data poisoning</th>
<th id="S4.T5.18.17.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Model poisoning</th>
<th id="S4.T5.18.17.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Inference</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.3.1" class="ltx_tr">
<th id="S4.T5.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">BindaaS</th>
<th id="S4.T5.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></th>
<td id="S4.T5.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.3.1.1.m1.1a"><mo id="S4.T5.3.1.1.m1.1.1" xref="S4.T5.3.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.1.1.m1.1b"><times id="S4.T5.3.1.1.m1.1.1.cmml" xref="S4.T5.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.3.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">Honest</td>
<td id="S4.T5.3.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.3.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.3.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.4.2" class="ltx_tr">
<th id="S4.T5.4.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">PIRATE</th>
<th id="S4.T5.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite></th>
<td id="S4.T5.4.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.4.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.4.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.4.2.1.m1.1a"><mo id="S4.T5.4.2.1.m1.1.1" xref="S4.T5.4.2.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.2.1.m1.1b"><times id="S4.T5.4.2.1.m1.1.1.cmml" xref="S4.T5.4.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.2.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.4.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Semi-honest</td>
<td id="S4.T5.4.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.4.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.4.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
</tr>
<tr id="S4.T5.5.3" class="ltx_tr">
<th id="S4.T5.5.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">BAFFLE</th>
<th id="S4.T5.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite></th>
<td id="S4.T5.5.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.5.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.5.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.5.3.1.m1.1a"><mo id="S4.T5.5.3.1.m1.1.1" xref="S4.T5.5.3.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.3.1.m1.1b"><times id="S4.T5.5.3.1.m1.1.1.cmml" xref="S4.T5.5.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.5.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.5.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.5.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.5.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.6.4" class="ltx_tr">
<th id="S4.T5.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">BFLC</th>
<th id="S4.T5.6.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite></th>
<td id="S4.T5.6.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.6.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.6.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.6.4.1.m1.1a"><mo id="S4.T5.6.4.1.m1.1.1" xref="S4.T5.6.4.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.4.1.m1.1b"><times id="S4.T5.6.4.1.m1.1.1.cmml" xref="S4.T5.6.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.6.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Semi-honest</td>
<td id="S4.T5.6.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.6.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.6.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.18.18.1" class="ltx_tr">
<th id="S4.T5.18.18.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">LearningChain</th>
<th id="S4.T5.18.18.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite></th>
<td id="S4.T5.18.18.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.18.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DP</td>
<td id="S4.T5.18.18.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.18.18.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.18.18.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.18.18.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.18.19.2" class="ltx_tr">
<th id="S4.T5.18.19.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Biscotti</th>
<th id="S4.T5.18.19.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite></th>
<td id="S4.T5.18.19.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.19.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DP</td>
<td id="S4.T5.18.19.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.18.19.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.18.19.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.18.19.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.18.20.3" class="ltx_tr">
<th id="S4.T5.18.20.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Blade-FL</th>
<th id="S4.T5.18.20.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite></th>
<td id="S4.T5.18.20.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.20.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DP</td>
<td id="S4.T5.18.20.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Honest</td>
<td id="S4.T5.18.20.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.20.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.20.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
</tr>
<tr id="S4.T5.18.21.4" class="ltx_tr">
<th id="S4.T5.18.21.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">BEAS</th>
<th id="S4.T5.18.21.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite></th>
<td id="S4.T5.18.21.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.21.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DP</td>
<td id="S4.T5.18.21.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.18.21.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.18.21.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
<td id="S4.T5.18.21.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.7.5" class="ltx_tr">
<th id="S4.T5.7.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Swarm Learning</th>
<th id="S4.T5.7.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></th>
<td id="S4.T5.7.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.7.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.7.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.7.5.1.m1.1a"><mo id="S4.T5.7.5.1.m1.1.1" xref="S4.T5.7.5.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.5.1.m1.1b"><times id="S4.T5.7.5.1.m1.1.1.cmml" xref="S4.T5.7.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.7.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.7.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.7.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.7.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.18.22.5" class="ltx_tr">
<th id="S4.T5.18.22.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">SL+HE</th>
<th id="S4.T5.18.22.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite></th>
<td id="S4.T5.18.22.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.22.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">HE</td>
<td id="S4.T5.18.22.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.18.22.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.22.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.22.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.9.7" class="ltx_tr">
<th id="S4.T5.9.7.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">BrainTorrent</th>
<th id="S4.T5.9.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite></th>
<td id="S4.T5.8.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.8.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.8.6.1.m1.1a"><mo id="S4.T5.8.6.1.m1.1.1" xref="S4.T5.8.6.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.6.1.m1.1b"><times id="S4.T5.8.6.1.m1.1.1.cmml" xref="S4.T5.8.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.9.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.9.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.9.7.2.m1.1a"><mo id="S4.T5.9.7.2.m1.1.1" xref="S4.T5.9.7.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.7.2.m1.1b"><times id="S4.T5.9.7.2.m1.1.1.cmml" xref="S4.T5.9.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.7.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.9.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Honest</td>
<td id="S4.T5.9.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.9.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.9.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.11.9" class="ltx_tr">
<th id="S4.T5.11.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">P2P-FL</th>
<th id="S4.T5.11.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite></th>
<td id="S4.T5.10.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.10.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.10.8.1.m1.1a"><mo id="S4.T5.10.8.1.m1.1.1" xref="S4.T5.10.8.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.10.8.1.m1.1b"><times id="S4.T5.10.8.1.m1.1.1.cmml" xref="S4.T5.10.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.8.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.11.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.11.9.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.11.9.2.m1.1a"><mo id="S4.T5.11.9.2.m1.1.1" xref="S4.T5.11.9.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.11.9.2.m1.1b"><times id="S4.T5.11.9.2.m1.1.1.cmml" xref="S4.T5.11.9.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.9.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.11.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Honest</td>
<td id="S4.T5.11.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.11.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.11.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.12.10" class="ltx_tr">
<th id="S4.T5.12.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">ReputationDFL</th>
<th id="S4.T5.12.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite></th>
<td id="S4.T5.12.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.12.10.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.12.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.12.10.1.m1.1a"><mo id="S4.T5.12.10.1.m1.1.1" xref="S4.T5.12.10.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.12.10.1.m1.1b"><times id="S4.T5.12.10.1.m1.1.1.cmml" xref="S4.T5.12.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.12.10.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.12.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.12.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.12.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.12.10.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.13.11" class="ltx_tr">
<th id="S4.T5.13.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">BlockFLA</th>
<th id="S4.T5.13.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite></th>
<td id="S4.T5.13.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.13.11.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.13.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.13.11.1.m1.1a"><mo id="S4.T5.13.11.1.m1.1.1" xref="S4.T5.13.11.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.13.11.1.m1.1b"><times id="S4.T5.13.11.1.m1.1.1.cmml" xref="S4.T5.13.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.13.11.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.13.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.13.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.13.11.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.13.11.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.14.12" class="ltx_tr">
<th id="S4.T5.14.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DFedForest</th>
<th id="S4.T5.14.12.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite></th>
<td id="S4.T5.14.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.14.12.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.14.12.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.14.12.1.m1.1a"><mo id="S4.T5.14.12.1.m1.1.1" xref="S4.T5.14.12.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.14.12.1.m1.1b"><times id="S4.T5.14.12.1.m1.1.1.cmml" xref="S4.T5.14.12.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.14.12.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.14.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.14.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.14.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.14.12.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.15.13" class="ltx_tr">
<th id="S4.T5.15.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Bift</th>
<th id="S4.T5.15.13.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite></th>
<td id="S4.T5.15.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.15.13.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.15.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.15.13.1.m1.1a"><mo id="S4.T5.15.13.1.m1.1.1" xref="S4.T5.15.13.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.15.13.1.m1.1b"><times id="S4.T5.15.13.1.m1.1.1.cmml" xref="S4.T5.15.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.15.13.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.15.13.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Dishonest</td>
<td id="S4.T5.15.13.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.15.13.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
<td id="S4.T5.15.13.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.16.14" class="ltx_tr">
<th id="S4.T5.16.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Verifiable DFL</th>
<th id="S4.T5.16.14.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite></th>
<td id="S4.T5.16.14.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.16.14.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.16.14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.16.14.1.m1.1a"><mo id="S4.T5.16.14.1.m1.1.1" xref="S4.T5.16.14.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.16.14.1.m1.1b"><times id="S4.T5.16.14.1.m1.1.1.cmml" xref="S4.T5.16.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.16.14.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.16.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Semi-honest</td>
<td id="S4.T5.16.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.16.14.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.16.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.18.23.6" class="ltx_tr">
<th id="S4.T5.18.23.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DFL for Healthcare</th>
<th id="S4.T5.18.23.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite></th>
<td id="S4.T5.18.23.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.23.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">DP, SMC</td>
<td id="S4.T5.18.23.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Semi-honest</td>
<td id="S4.T5.18.23.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.23.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.23.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óè</td>
</tr>
<tr id="S4.T5.17.15" class="ltx_tr">
<th id="S4.T5.17.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">FLChain</th>
<th id="S4.T5.17.15.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite></th>
<td id="S4.T5.17.15.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.17.15.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.17.15.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.17.15.1.m1.1a"><mo id="S4.T5.17.15.1.m1.1.1" xref="S4.T5.17.15.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.17.15.1.m1.1b"><times id="S4.T5.17.15.1.m1.1.1.cmml" xref="S4.T5.17.15.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.17.15.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.17.15.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Honest</td>
<td id="S4.T5.17.15.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.17.15.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.17.15.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
</tr>
<tr id="S4.T5.18.16" class="ltx_tr">
<th id="S4.T5.18.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">VFChain</th>
<th id="S4.T5.18.16.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite></th>
<td id="S4.T5.18.16.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚úì</td>
<td id="S4.T5.18.16.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><math id="S4.T5.18.16.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.18.16.1.m1.1a"><mo id="S4.T5.18.16.1.m1.1.1" xref="S4.T5.18.16.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T5.18.16.1.m1.1b"><times id="S4.T5.18.16.1.m1.1.1.cmml" xref="S4.T5.18.16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.18.16.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.18.16.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">Semi-honest</td>
<td id="S4.T5.18.16.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.16.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óã</td>
<td id="S4.T5.18.16.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">‚óê</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Defense Mechanisms</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Various defense mechanisms are proposed to fortify DFL against privacy and performance-related threats. While this section reviews the literature on DFL defense mechanisms, their characteristics are summarized in Table <a href="#S4.T4" title="TABLE IV ‚Ä£ IV-C3 Defensibility ‚Ä£ IV-C Analyzing the Viability of Attacks ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. In addition, Table <a href="#S4.T5" title="TABLE V ‚Ä£ IV-C3 Defensibility ‚Ä£ IV-C Analyzing the Viability of Attacks ‚Ä£ IV Threats to Decentralized Federated Learning ‚Ä£ Decentralized Federated Learning: A Survey on Security and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> specifies mechanisms that each reviewed DFL method employs.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Privacy Preserving</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Despite the wide diversity of previous efforts on safeguarding FL and blockchain privacy, suggested methods typically fall into one of these three categories: 1) Homomorphic Encryption (HE), 2) Secure Multiparty Computation (SMC), and 3) DP. The following discussion goes through each of these groups.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS1.5.1.1" class="ltx_text">V-A</span>1 </span>Homomorphic Encryption</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">By processing on cyphertext, HE is commonly used to secure the learning process. Clients can use HE to perform arithmetic operations on encrypted data (i.e., ciphertext) without having to decode it. HE has three major variations that differ in arithmetic complexity and flexibility, namely full, partial, and substantial HE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p">Fully HE is capable of doing arbitrary calculations on the encrypted data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>. This is while partially HE can only execute one operation (e.g., addition or multiplication), and substantially HE can do several operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. The latter, on the other hand, has a restricted amount of additions and multiplications. While full HE offers greater flexibility, it is inefficient when compared to other forms of HE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>. As an example, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> shows that swarm learning updates are encrypted using partial HE to defend DFL against inference attacks.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p">Despite the benefits of HE, executing arithmetic on the encrypted integers increases the memory and processing time costs. Moreover, non-linear estimations in statistical models demand approximating polynomials which make it important to find a balance between utility and privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>, for instance, additively HE is used to secure distributed learning by securing model changes and maintaining gradient privacy. Another example is <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, which uses an additively homomorphic architecture to defeat honest-but-curious adversaries using federated logistic regression on the encrypted vertical FL data. However, the overburdening of the system with additional computational costs is a typical downside of such systems.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS2.5.1.1" class="ltx_text">V-A</span>2 </span>Secure Multiparty Computation</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Secure Multiparty Computation (SMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>, is a distributed cryptography technique in which several entities participate in the estimation of a function. The distinct feature of SMC is securing each participant‚Äôs data by creating a set of random values that are not equal to the participant‚Äôs data, and sending them to the rest of the parties for local calculation of the function. The outputs of these functions then will be averaged to obtain the desired estimation. In this scheme, the data on the participant‚Äôs side is meaningless, and the function estimations are only usable once they are averaged. For instance, SMC was used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> for private model training. It is worth mentioning that SMC is followed by excessive communication and computational cost. It has been also mentioned that SMC is best to be coupled with DP to secure the communications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">In conclusion, SMC usage in large-scale DFL could be inefficient due to the dramatic rise in communication and processing costs. Secondly, encryption-based solutions corresponding to these functions must be properly defined and implemented <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. Finally, all cryptography-based protocols preclude an audition phase of the received updates by the shared model, hence, leaving holes for rogue users to exploit.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS3.5.1.1" class="ltx_text">V-A</span>3 </span>Differential Privacy</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">The idea of DP is to inject random noise into the generating updates so that the data interpretation becomes infeasible for malicious entities. DP is primarily used to safeguard DFL communications against privacy attacks (e.g., inference attacks); however, the literature also shows that DP can be also beneficial against data poisoning attacks as these attacks are usually designed based on the communicated gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>. Biscotti <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> couples DP with a secure aggregation technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> to safeguard DFL systems against poisoning and inference attacks. Another report shows the effectiveness of pruning-based DP in safeguarding horizontal DFL systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. DP in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> is implemented through perturbing local gradients using the exponential mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> and a predefined probability density function before uploading them into the blockchain and broadcasting them across the DFL network. Similarly, Blade-FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> adds noise to the gradients prior to the encapsulation phase, albeit using a Gaussian distribution.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">In contrast to HE and SMC whose main disadvantage was communication overhead, DP has a lower computational cost and does not overburden the system in this sense. Instead, DP comes at the cost of deteriorating the model quality. This is mainly because the injected noise can potentially add up to the noise within the constructed model. Another issue of concern in conventional DP is the cumulative privacy loss resulting from iterative training processes that utilize local data from multiple individuals or sources. These iterations are crucial for enhancing the accuracy and performance of trained models. However, with each iteration, a certain degree of privacy loss is introduced, and this loss accumulates over time, potentially reaching a significant level. Researchers have dedicated efforts to address this problem by exploring various approaches, including subsampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> and privacy amplification by iteration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. These techniques aim to mitigate cumulative privacy loss and improve the overall privacy guarantees of DP schemes. Since these methods derive a tight upper bound of cumulative privacy loss, they can also be applied to preserve model utility even in cases where the gradients are perturbed by noise. Moreover, DP provides resistance to poisoning attempts due to its group privacy trait. As a result, as the number of attackers increases, this defense will reduce significantly. As mentioned before, all privacy-preserving methods have a set of advantages and disadvantages, and thus, there is no perfect alternative for DP. In other words, DP, HE, and SMC each result in a different privacy-utility trade-off. As a solution, hybrid approaches can be implemented to build privacy protocols that are more robust than using only one of these methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. As an example, SMC is combined with DP to balance the trade-off between them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. This combination offsets excessive noise injection when the number of clients is growing while preserving the desired rate of trust.</p>
</div>
<div id="S5.SS1.SSS3.p3" class="ltx_para">
<p id="S5.SS1.SSS3.p3.4" class="ltx_p">Gaussian DP is a specific case within the functional DP (<math id="S5.SS1.SSS3.p3.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.SSS3.p3.1.m1.1a"><mi id="S5.SS1.SSS3.p3.1.m1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.1.m1.1b"><ci id="S5.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.1.m1.1c">f</annotation></semantics></math>-DP) framework, which characterizes privacy through hypothesis testing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>. In <math id="S5.SS1.SSS3.p3.2.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.SSS3.p3.2.m2.1a"><mi id="S5.SS1.SSS3.p3.2.m2.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.2.m2.1b"><ci id="S5.SS1.SSS3.p3.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.2.m2.1c">f</annotation></semantics></math>-DP, a randomized algorithm is considered to satisfy privacy if the difficulty of distinguishing between two neighboring datasets (quantified by a trade-off function) is element-wise larger than a convex and non-increasing function <math id="S5.SS1.SSS3.p3.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.SSS3.p3.3.m3.1a"><mi id="S5.SS1.SSS3.p3.3.m3.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.3.m3.1b"><ci id="S5.SS1.SSS3.p3.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.3.m3.1c">f</annotation></semantics></math>. When this function f is constructed using two Gaussian distributions, the resulting form of <math id="S5.SS1.SSS3.p3.4.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.SSS3.p3.4.m4.1a"><mi id="S5.SS1.SSS3.p3.4.m4.1.1" xref="S5.SS1.SSS3.p3.4.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.4.m4.1b"><ci id="S5.SS1.SSS3.p3.4.m4.1.1.cmml" xref="S5.SS1.SSS3.p3.4.m4.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.4.m4.1c">f</annotation></semantics></math>-DP is termed Gaussian Differential Privacy. In other words, Gaussian DP defines privacy guarantees by examining the distinguishability of neighboring datasets through a hypothesis testing approach, with the specific choice of a trade-off function derived from Gaussian distributions. This provides a mathematical and analytical framework for evaluating privacy in the context of private data analysis. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> applies Gaussian DP in an FL system to provide record-level privacy guarantees for each client. Building upon the ability of this approach to handle composition and subsampling, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> extends the work to apply DP to SGD and Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> optimizers.</p>
</div>
<div id="S5.SS1.SSS3.p4" class="ltx_para">
<p id="S5.SS1.SSS3.p4.1" class="ltx_p">In the context of applying DP to FL, two privacy notations, namely user level and instance level privacy, can be found in the literature. User-level privacy in DP ensures that clients‚Äô data remains private and the privacy of the global model remains intact, even if an adversary removes a client or its data from the aggregation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>. Additionally, adversaries are unable to determine whether a client has participated in the training. On the other hand, employing DP at the record level offers privacy guarantees for each individual record within a client‚Äôs data, protecting them against potential adversaries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>. Instance-level DP is often perceived as offering a relatively weaker privacy guarantee, as adversaries may potentially determine whether a user participated in the training or not. However, there are cases where discerning user participation is not crucial, and the primary concern is maintaining data privacy. Considering the trade-off between privacy and utility in differential privacy, it is prudent to adopt instance-level privacy in such scenarios to achieve improved performance while avoiding overly stringent privacy constraints.</p>
</div>
<div id="S5.SS1.SSS3.p5" class="ltx_para">
<p id="S5.SS1.SSS3.p5.1" class="ltx_p">DP can be centralized, local, or distributed. In centralized DP, the noise addition is performed via a server, which makes it impractical in DFL. On the other hand, local <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> and distributed DP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> both assume that the aggregator is not trusted which perfectly complies with the DFL paradigm. In the local variant, participants inject noise in their estimated gradients before sharing them over the blockchain. However, research on local DP indicates its inability to provide a privacy guarantee on large-scale and heterogeneous models with numerous parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>. In DFL, the injected noise should be calibrated to ensure successful DP. Despite the appealing security qualities of local DP, its practicality becomes questionable when dealing with an immense number of users.</p>
</div>
<div id="S5.SS1.SSS3.p6" class="ltx_para">
<p id="S5.SS1.SSS3.p6.1" class="ltx_p">Distributed DP combines cryptographic techniques to provide the benefits of both local and centralized DP without compromising the clients‚Äô privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>, <a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>. As a result, it avoids putting faith in any server and is more effective in that sense. Decentralized DP, in theory, has the same benefit as the centralized variant because the overall quantity of noise is similar for them. The concept of distributed DP alludes to the notion that the required amount of noise is derived from several individuals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Model Robustness</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Defenses are classified into two types: proactive and reactive. Proactive defense is a low-cost method of anticipating attacks and associated consequences. The reactive defense operates by detecting an invasion and taking preventative steps. In the production environment, reactive defense is often deployed as a patch-up. DFL presents multiple additional attack surfaces throughout training, resulting in complicated and unique countermeasures. In this part, we will look at some of the most common types of DFL defensive tactics and investigate their usefulness and limits.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS1.5.1.1" class="ltx_text">V-B</span>1 </span>Anomaly Detection</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Anomaly detection methods have a long history in real-time identification of data attacks in intelligent systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>. In centralized FL, anomaly detection is often performed on the server to identify malicious updates that can lead to model or data poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>. It is worthwhile to mention that this approach usually works best against untargeted attacks. In the DFL paradigm, however, anomalies can take place either due to fraudulent transactions or changes in blockchain networks such as network division and blockchain fork. Each of these issues is separately studied in the literature and there is no anomaly detection framework designed to handle both. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> proposes a fast-paced detection scheme for monitoring transactions using a subgraph-based approach. The designed detection method is optimized for parallel processing GPU acceleration. On the other hand, another work, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>, designs a distributed anomaly detection scheme, called BAD, to combat eclipse attacks in blockchain networks by re-connecting unauthorized forks to the P2P network.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">The majority of the anomaly detection methods for FL security are proposed with respect to the centralized architecture of the FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib129" title="" class="ltx_ref">129</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>, and anomaly detection in DFL is only studied in a limited number of works. As an example, BEAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> employs two anomaly detection protocols, namely Multi-KRUM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> and FoolsGold <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> to detect poisoning attacks and identifying Sybil groups (i.e., group of malicious nodes coordinating a cyber-attack), respectively. The former monitors change in variance or performance of generated gradients with respect to the majority of updates. The latter, on the other hand, detects Sybil groups based on the correlation between the generated updates, as it is expected for malicious nodes to generate highly similar gradients. Anomaly detection in high-dimensional space poses challenges, leading some detectors to suggest using dimensionality reduction to make monitoring easier. However, reducing the dimensionality size may result in information loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, even with advanced techniques preserving data characteristics.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS2.5.1.1" class="ltx_text">V-B</span>2 </span>Robust Aggregation</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">The aggregation algorithm used in an FL system should tolerate communications disturbances, client dropout, and incorrect model updates on top of hostile participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite>. Extensive research has been dedicated to advancing robust aggregation in centralized FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>, <a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>. Similarly, in DFL networks, the security of the aggregation phase is of paramount importance. Under a DFL paradigm, the aggregation phase is mainly secured by employing the same techniques used in FL in combination with the consensus mechanism of the utilized blockchain scheme <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. These protocols (e.g., PoW, PoS, SC) control which nodes can participate in the model aggregation phase for both generating updates and aggregating parameters. On the downside, many of the advanced Byzantine-robust aggregations rely on assumptions that are either unrealistic or incompatible within the context of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS3.5.1.1" class="ltx_text">V-B</span>3 </span>Pruning</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">Even though pruning is not specific to DFL and can be applied to any neural network structure, it can help in eliminating backdoors. The idea of pruning is to drop some neurons in order to enhance the efficiency and accuracy of the network. However, this feature makes the parameter usage somewhat unpredictable for attackers which complicates injecting backdoors into a neural network since inactive neurons will be removed eventually in the network. While pruning has been mainly studied for FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, current literature on pruning under a DFL paradigm is very limited <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. In particular, BEAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> makes use of gradient pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> in DFL to facilitate DP and complicating model poisoning for attackers in the system. Nevertheless, since these techniques are mainly used at the edge of the network, most pruning approaches should be adaptable to DFL as well.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">Pruning comes with a set of drawbacks. One drawback is the potential loss of model capacity, resulting from the removal of connections or components. Another concern is the sensitivity of pruning to initialization and training, necessitating careful fine-tuning and experimentation for optimal outcomes. Moreover, the pruned model may struggle to generalize effectively to new data, limiting its real-world applicability. Lastly, the computational overhead increases due to the additional resources and time required during the pruning and retraining stages. Considering these factors is vital when assessing the viability of pruning as a defense mechanism against backdoors.</p>
</div>
</section>
<section id="S5.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS4.5.1.1" class="ltx_text">V-B</span>4 </span>Trusted Execution Environment</h4>

<div id="S5.SS2.SSS4.p1" class="ltx_para">
<p id="S5.SS2.SSS4.p1.1" class="ltx_p">The blockchain backbone of DFL requires the data to be replicated on each node which makes it challenging to keep smart contracts confidential. TEE (Trusted Execution Environment), on the other hand, is a tamper-resistant ecosystem that can be used to maintain digital trust between nodes of a distributed network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. TEE is often referred to as a secure and isolated part of the processor that requires all codes and data signatures to be verified with respect to the designer‚Äôs expectations. The validity of a participating device in a TEE Authentication should be checked by the connected service with which it is attempting to enroll. Until the matching party provides a message, the status of code execution stays hidden. The execution route of the code cannot be changed until it takes explicit input or a validated interruption. Data stored on and processed by participants is safe, and interactions between various parties are carried out in a secure manner. The TEE is in charge of all data access privileges. Cryptographic technologies are used to secure TEE communications. Only the TEE secure environment stores, maintains, and uses private and public encryption keys. The TEE can show a remote client what code is presently being executed as well as the starting state. TEE can aid in resolving a key challenge for FL security since it is becoming progressively important in securing the central server and clients against hackers and preventing data theft.</p>
</div>
<div id="S5.SS2.SSS4.p2" class="ltx_para">
<p id="S5.SS2.SSS4.p2.1" class="ltx_p">TEE is coupled with FL to safeguard against algorithmic attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>. TEE can hide model parameters on local devices so that the model is not accessible to the attacker. Under this condition, the attacker is only able to launch black box attacks on the system. Nevertheless, TEE often suffers from a limited memory size, that is only a limited part of the model can be secured with this approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>. It has been also suggested that TEE can secure smart contract data in a blockchain which is the main vulnerability of this architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>. Theoretically, the same concept can be applied to DFL. However, current literature lacks an experimental study on the integration of DFL and TEE.</p>
</div>
</section>
<section id="S5.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS5.5.1.1" class="ltx_text">V-B</span>5 </span>Zero-Knowledge Proofs</h4>

<div id="S5.SS2.SSS5.p1" class="ltx_para">
<p id="S5.SS2.SSS5.p1.1" class="ltx_p">The origin of zero-knowledge proofs goes back to the mid-1980s <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>. This cryptographic approach allows a verification process that does not involve data exchange between parties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>. This process often involves using unconnected bits of information to keep data private during the verification.</p>
</div>
<div id="S5.SS2.SSS5.p2" class="ltx_para">
<p id="S5.SS2.SSS5.p2.1" class="ltx_p">As an example, zero-knowledge proofs have the potential to be utilized in DFL to verify the authenticity of the features used by clients for training and generating updates. While zero-knowledge proofs offer a promising avenue for enhancing secure update monitoring, additional research is necessary to identify challenges in constructing and implementing their modules. Notably, zero-knowledge proof protocols generally maintain their performance regardless of the data volume.</p>
</div>
<div id="S5.SS2.SSS5.p3" class="ltx_para">
<p id="S5.SS2.SSS5.p3.1" class="ltx_p">Zero-knowledge proofs offer advantages for enhancing secure update monitoring in DFL. However, their adoption also entails certain drawbacks. These include computational overhead due to resource-intensive operations, the complexity of implementation requiring meticulous attention to cryptographic techniques, potential scalability issues in large-scale DFL systems due to communication complexity, and the trust assumption associated with the setup phase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS2.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS6.5.1.1" class="ltx_text">V-B</span>6 </span>Knowledge Distillation</h4>

<div id="S5.SS2.SSS6.p1" class="ltx_para">
<p id="S5.SS2.SSS6.p1.9" class="ltx_p">Knowledge distillation is a fundamental algorithm in federated distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>. The goal of knowledge distillation is to perform TL from a large teacher model (<math id="S5.SS2.SSS6.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S5.SS2.SSS6.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.1.m1.1.1" xref="S5.SS2.SSS6.p1.1.m1.1.1.cmml">ùíØ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.1.m1.1b"><ci id="S5.SS2.SSS6.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS6.p1.1.m1.1.1">ùíØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.1.m1.1c">\mathcal{T}</annotation></semantics></math>) to a compact student model (<math id="S5.SS2.SSS6.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S5.SS2.SSS6.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.2.m2.1.1" xref="S5.SS2.SSS6.p1.2.m2.1.1.cmml">ùíÆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.2.m2.1b"><ci id="S5.SS2.SSS6.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS6.p1.2.m2.1.1">ùíÆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.2.m2.1c">\mathcal{S}</annotation></semantics></math>) without sacrificing performance significantly. Smaller models have fewer parameters and are less susceptible to overfitting, making them more resilient against attacks. This increased resistance makes it more challenging for attackers to reverse-engineer or manipulate the model. Nonetheless, for certain threats such as backdoor attacks, knowledge distillation alone may not be directly effective, as these attacks typically involve modifying the training data or model parameters to embed a hidden trigger. However, knowledge distillation can be used as part of a broader defense strategy to mitigate the impact of backdoor attacks. For instance, reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> mitigates backdoor attacks by utilizing knowledge distillation in deep neural networks. This approach independently fine-tunes <math id="S5.SS2.SSS6.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S5.SS2.SSS6.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.3.m3.1.1" xref="S5.SS2.SSS6.p1.3.m3.1.1.cmml">ùíØ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.3.m3.1b"><ci id="S5.SS2.SSS6.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS6.p1.3.m3.1.1">ùíØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.3.m3.1c">\mathcal{T}</annotation></semantics></math> on a clean subset and uses it to clean backdoored <math id="S5.SS2.SSS6.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S5.SS2.SSS6.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.4.m4.1.1" xref="S5.SS2.SSS6.p1.4.m4.1.1.cmml">ùíÆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.4.m4.1b"><ci id="S5.SS2.SSS6.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS6.p1.4.m4.1.1">ùíÆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.4.m4.1c">\mathcal{S}</annotation></semantics></math>. To do so, this method tries to align intermediate-layer attention in <math id="S5.SS2.SSS6.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S5.SS2.SSS6.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.5.m5.1.1" xref="S5.SS2.SSS6.p1.5.m5.1.1.cmml">ùíÆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.5.m5.1b"><ci id="S5.SS2.SSS6.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS6.p1.5.m5.1.1">ùíÆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.5.m5.1c">\mathcal{S}</annotation></semantics></math> with that of <math id="S5.SS2.SSS6.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S5.SS2.SSS6.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.6.m6.1.1" xref="S5.SS2.SSS6.p1.6.m6.1.1.cmml">ùíØ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.6.m6.1b"><ci id="S5.SS2.SSS6.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS6.p1.6.m6.1.1">ùíØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.6.m6.1c">\mathcal{T}</annotation></semantics></math>. Another example trains a <math id="S5.SS2.SSS6.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S5.SS2.SSS6.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.7.m7.1.1" xref="S5.SS2.SSS6.p1.7.m7.1.1.cmml">ùíØ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.7.m7.1b"><ci id="S5.SS2.SSS6.p1.7.m7.1.1.cmml" xref="S5.SS2.SSS6.p1.7.m7.1.1">ùíØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.7.m7.1c">\mathcal{T}</annotation></semantics></math> ensemble on disjoint training subsets and trains <math id="S5.SS2.SSS6.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S5.SS2.SSS6.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.8.m8.1.1" xref="S5.SS2.SSS6.p1.8.m8.1.1.cmml">ùíÆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.8.m8.1b"><ci id="S5.SS2.SSS6.p1.8.m8.1.1.cmml" xref="S5.SS2.SSS6.p1.8.m8.1.1">ùíÆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.8.m8.1c">\mathcal{S}</annotation></semantics></math> based on aggregated noisy voting among <math id="S5.SS2.SSS6.p1.9.m9.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S5.SS2.SSS6.p1.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS6.p1.9.m9.1.1" xref="S5.SS2.SSS6.p1.9.m9.1.1.cmml">ùíØ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS6.p1.9.m9.1b"><ci id="S5.SS2.SSS6.p1.9.m9.1.1.cmml" xref="S5.SS2.SSS6.p1.9.m9.1.1">ùíØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS6.p1.9.m9.1c">\mathcal{T}</annotation></semantics></math> models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>. The goal of this approach is to provide a privacy guarantee for training data. In DFL, this idea translates into sharing the knowledge of a model rather than the parameters which improves FL‚Äôs robustness against both poisoning and privacy attacks. In addition to the mentioned security advantages, knowledge distillation also results in communication and computation efficiency in DFL. Exchanging model parameters becomes burdensome when communication resources are limited, especially for contemporary big deep neural networks. In this sense, federated distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> is an appealing FL option since it only transmits model outputs which are often considerably less in size than the model sizes.</p>
</div>
</section>
<section id="S5.SS2.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS7.5.1.1" class="ltx_text">V-B</span>7 </span>Regularization</h4>

<div id="S5.SS2.SSS7.p1" class="ltx_para">
<p id="S5.SS2.SSS7.p1.1" class="ltx_p">In DFL, the computational model that is being distributively updated is most likely a DL structure. One approach to mislead this model is to make it overfit by introducing malicious samples which may in turn lead to membership inference. Regularization techniques such as <math id="S5.SS2.SSS7.p1.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S5.SS2.SSS7.p1.1.m1.1a"><msub id="S5.SS2.SSS7.p1.1.m1.1.1" xref="S5.SS2.SSS7.p1.1.m1.1.1.cmml"><mi id="S5.SS2.SSS7.p1.1.m1.1.1.2" xref="S5.SS2.SSS7.p1.1.m1.1.1.2.cmml">L</mi><mn id="S5.SS2.SSS7.p1.1.m1.1.1.3" xref="S5.SS2.SSS7.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS7.p1.1.m1.1b"><apply id="S5.SS2.SSS7.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS7.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS7.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS7.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS7.p1.1.m1.1.1.2">ùêø</ci><cn type="integer" id="S5.SS2.SSS7.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS7.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS7.p1.1.m1.1c">L_{2}</annotation></semantics></math> regularizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> and dropout <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> can eliminate the effect of such malicious samples to a great extent. Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> designs a semidefinite relaxation method that generates a differentiable certificate for network robustness and optimizes it alongside network parameters to encourage robustness against all attacks. Furthermore, determining suitable hyperparameters, such as regularization strength, for regularization techniques can be a difficult task, and incorrect choices may yield undesirable results. Moreover, the use of certain regularization methods with intricate terms or penalties can introduce considerable computational complexity, especially in scenarios involving extensive datasets or intricate models, resulting in prolonged training durations.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Verifiable DFL</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Defense mechanisms reviewed in the previous section mainly combat an adversary after a malicious attack is launched by an intruder. Nevertheless, another approach to combat these threats is to prevent malicious parties to take part in the training process. A DFL system that can verify the trustworthiness of its clients is called verifiable.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">A DFL system is considered verifiable if clients of a network can prove to each other that the given task has been carried out without compromising privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite>.
Security, transparency, and automation of blockchain can enhance the verifiability of DFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> which in turn prevent malicious activities. In this structure, some nodes are in charge of generating updates and training the model (i.e., trainers) and groups of participants verify the generated updates (i.e., workers) with respect to consensus protocol. If the update is verified, the worker who completes this task first will create a new block. Then, if the majority of the workers approve the content of the created block, it will be appended to the chain. At this point, DFL clients can update their models using this new block of information. This process is repeated periodically to keep the DFL model up to date.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Trustable DFL Trainers</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">A vulnerability of DFL systems is that dishonest trainers can upload maliciously crafted updates to the blockchain. For instance, BlockFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> verifies the submitted updates through a random selection of workers before letting the update take effect. In BlockFL, each client is associated with a random worker who is rewarded when evaluating the updates prior to the aggregation. The evaluation criteria are designed based on the relationship between the data size and the elapsed time for generating the update.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Another approach for verifying trainers is to use proof of correctness. Examples of this are presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>, where produced parameters are paired with their proof of correctness which is used by registered workers for determining the approved updates. This approach uses verifiable random functions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite> or reliability ranking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite> to select a worker whose aggregation results will be appended to the blockchain. The trainer‚Äôs reliability, which is an indicator of its performance, will affect its chance to take part in the training process thereafter.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">Trustable DFL Workers</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Assuming that all trainers are trustworthy, the aggregated model could still be compromised if the responsible worker for the model aggregation is unreliable, that is, it does not follow the defined protocol. VFChain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> addresses this issue by using trainer signatures that are appended to the uploaded block by the trainer. To verify the aggregated model by the responsible worker, a committee is randomly selected among other workers to evaluate the aggregated model with respect to the verifying contract. The members of this committee are continuously updated in each training round. The blockchain preserves signatures and their corresponding aggregated models of each training round which makes all records tamper-resistant and transparent to all network members. It is worth mentioning that this structure is only compatible with semi-honest trainers.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Future Research Directions</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Despite the advancements of DFL in the past five years, this paradigm is fairly new and still has a lot of potential to be improved. From a security standpoint, many of the available countermeasures in the literature are either studied for FL or blockchain, and their effectiveness in DFL remains unclear. Here, we outline future development requirements that we believe will be promising for DFL in this sense.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.5.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.6.2" class="ltx_text ltx_font_italic">Weakness of Privacy-Preserving Techniques</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">As mentioned before, privacy-preserving techniques often trade excessive computational burden for enhancing privacy (e.g., HE, SMC). Furthermore, the implementation of cryptographic techniques such as SMC is sensitive and can imperil privacy if not defined properly. DP, on the other hand, can affect the accuracy of the aggregated model since the utilized noise can leak into the model. These issues are beside the fact that the audition phase in these techniques can lead to security holes. Hence, despite the history of privacy-preserving techniques, they all have imperfections that require further research and adaptation to the DFL paradigm.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">Addressing these challenges requires ongoing research and adaptation of privacy-preserving techniques to suit the specific requirements of DFL. Developing optimized implementations of cryptographic methods, such as SMC, can help alleviate the computational overhead and address sensitivity concerns. Paying attention to secure parameter configurations and robust cryptographic protocols is essential to minimize privacy risks. Exploring advanced noise reduction techniques within DP can strike a balance between preserving privacy and maintaining the accuracy of the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>. Robust auditing mechanisms need to be established to ensure the security of privacy-preserving techniques and safeguard against potential vulnerabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. Moreover, investigating hybrid approaches that integrate multiple privacy-preserving techniques can offer a compromise between privacy and computational efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">Continued exploration and refinement of privacy-preserving techniques in the DFL domain will enhance privacy and security while minimizing the impact on computational performance. This ongoing research and innovation will pave the way for more effective and privacy-aware DFL systems.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.5.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.6.2" class="ltx_text ltx_font_italic">Optimizing Defense Mechanism Deployment</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Devising defense mechanisms in DFL presents specific challenges that need to be addressed. One key challenge is the requirement for additional computational power, which may not always be feasible, particularly in resource-constrained environments like mobile networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite>. The limited computational resources available can pose limitations on the implementation of defense mechanisms.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">Another challenge is the diverse nature of threats in DFL. Different threats often require different countermeasures. Designing a comprehensive defense mechanism that addresses a wide range of threats can be complex and challenging. It requires analyzing various threat models, understanding their unique characteristics, and developing tailored defense strategies accordingly.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">When considering DFL deployed on blockchain, resource and computational constraints specific to blockchain systems must also be taken into account <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>. The scalability of defense mechanisms becomes a critical aspect to consider. Strategies that optimize smart contract execution or leverage off-chain computations can help ensure efficient operation within the resource constraints of blockchain platforms.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">Continuous evaluation, benchmarking, and improvement of existing defense mechanisms are vital. The field of defense mechanisms in DFL is dynamic, with emerging threats and advancements in technology. Regular evaluation and improvement are necessary to keep up with evolving challenges and maintain effective protection.</p>
</div>
<div id="S7.SS2.p5" class="ltx_para">
<p id="S7.SS2.p5.1" class="ltx_p">Overall, addressing the challenges of additional computational power, diverse threats, resource constraints in blockchain, and the optimal deployment of defense mechanisms are critical areas for further research and development in the field of DFL. By tackling these challenges and exploring the proposed solutions, researchers can advance the field and enhance the security and resilience of DFL systems.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS3.5.1.1" class="ltx_text">VII-C</span> </span><span id="S7.SS3.6.2" class="ltx_text ltx_font_italic">Blockchain-Related Security Issues</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">The decentralization and traceability offered by DFL introduce unique challenges related to blockchain-related threats. These threats specifically exploit the structure of the blockchain, posing risks to the overall security of DFL systems. Consequently, there is a need for research and development aiming at creating more secure blockchain structures that can enhance the resilience of DFL ecosystems against these attacks.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">One key challenge is the susceptibility of DFL to cyber-attacks that target the underlying blockchain infrastructure. Adversaries may attempt to manipulate or tamper with the blockchain, compromising the integrity and reliability of the system. This poses a significant risk to the confidentiality and privacy of participants‚Äô data in DFL. To address these challenges, research efforts should focus on the development of more secure blockchain structures tailored to the specific requirements of DFL. This involves exploring techniques such as improved consensus mechanisms, advanced cryptographic protocols, and enhanced smart contract design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>. These solutions aim to bolster the security of the blockchain layer, mitigating the vulnerabilities that can be exploited by malicious actors. Additionally, advancements in blockchain technology, such as the integration of privacy-preserving techniques and zero-knowledge proofs, can contribute to building a more attack-resilient DFL ecosystem. By leveraging techniques that enhance data privacy and confidentiality, DFL systems can better withstand attacks and protect sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. Furthermore, the development of robust monitoring and auditing mechanisms is crucial for detecting and mitigating blockchain-related threats in DFL. Implementing effective monitoring systems can help identify suspicious activities and ensure the integrity of the blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. Auditing mechanisms can verify the correctness and security of the system, providing transparency and accountability in DFL deployments.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS4.5.1.1" class="ltx_text">VII-D</span> </span><span id="S7.SS4.6.2" class="ltx_text ltx_font_italic">Heterogeneity of Decentralized Federated Learning</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">DFL convergence in a distributed ecosystem (e.g., blockchain) is not guaranteed when various clients have diverse computation power (i.e., heterogeneous users). Limited processing power and poor connectivity can delay the training and communication of some nodes, delaying the global aggregation. Disregarding this heterogeneity results deteriorates the overall efficiency of DFL training.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p">The heterogeneity of clients in DFL not only poses challenges to convergence and efficiency but also gives rise to security issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite>. In an asynchronous DFL setting, where clients operate with different computation power and connectivity, ensuring secure aggregation becomes challenging. Asynchronous DFL is not compatible with secure aggregation protocols because all clients need to be incorporated in the aggregation step when using secure aggregation. This also limits the ability to perform centralized or distributed DP. Consequently, the use of local DP techniques becomes the viable option in asynchronous DFL scenarios, potentially compromising the level of privacy protection and increasing the risk of information leakage during the aggregation process. These security concerns highlight the need for innovative approaches that strike a balance between achieving privacy-preserving aggregation and accommodating the heterogeneity of clients in DFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>. By exploring novel cryptographic techniques, adaptive privacy mechanisms, and secure communication protocols, it is possible to address the security challenges that arise from the heterogeneity of DFL and ensure the confidentiality, integrity, and privacy of the FL process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>, <a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite>.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS5.5.1.1" class="ltx_text">VII-E</span> </span><span id="S7.SS5.6.2" class="ltx_text ltx_font_italic">Challenges in Verifiable Decentralized Federated Learning</span>
</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p id="S7.SS5.p1.1" class="ltx_p">Joining a DFL network requires a set of verifiers to evaluate the trustworthiness of the joining party. Since the joining party will not disclose their information for privacy reasons, the evaluation process often involves monitoring the performance of the joining party in the training process. Nevertheless, this evaluation scheme is not efficient as it exhausts computational and communication resources. Another challenge in this domain is to gain insight into the misbehavior of clients based on the history of their behavior. It is important to discover how the verification results can be employed to facilitate this task.</p>
</div>
<div id="S7.SS5.p2" class="ltx_para">
<p id="S7.SS5.p2.1" class="ltx_p">One possible solution is to employ privacy-preserving techniques during the trust evaluation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Techniques such as SMC or HE can enable verifiers to evaluate the performance and trustworthiness of the joining party without directly accessing their sensitive information. This way, privacy is maintained while still obtaining the necessary insights for trust evaluation. Furthermore, optimizing the evaluation process can enhance its efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. Implementing techniques that reduce the computational and communication overhead, such as lightweight monitoring mechanisms or selective data aggregation, can help alleviate the resource exhaustion issues associated with the evaluation scheme. By carefully designing evaluation protocols and employing efficient algorithms, the overall efficiency of the process can be improved without compromising the evaluation‚Äôs effectiveness.</p>
</div>
<div id="S7.SS5.p3" class="ltx_para">
<p id="S7.SS5.p3.1" class="ltx_p">In terms of addressing misbehavior based on historical behavior, leveraging machine learning techniques and anomaly detection algorithms can be beneficial. By analyzing the behavior patterns and performance metrics of clients over time, it is possible to identify potential anomalies or deviations that may indicate misbehavior. Establishing a comprehensive system for tracking and monitoring client behavior, coupled with intelligent analysis and detection mechanisms, can aid in detecting and addressing misbehavior in a timely manner. Moreover, incorporating reputation systems within the DFL network can provide additional insights into the trustworthiness of participating clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. Verifiers can leverage the verification results and feedback from previous collaborations to build reputation scores for each client. These scores can serve as indicators of past behavior and can be used as a basis for decision-making during the trust evaluation process.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">The integration of FL and blockchain technologies has alleviated the need for a server in the network. This is followed by a number of advantages such as efficient communication and the elimination of a single point of failure in the federation. While there are a limited number of surveys on the security analysis of FL, since the previous studies were all based on centralized architectures, further analysis is required to study the new paradigm of DFL from a security perspective. This work first reviewed common trends and preliminaries of FL and blockchain. It then performed a security analysis on DFL by identifying possible threats and defense mechanisms in such systems.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J.¬†Koneƒçn√Ω, H.¬†B. McMahan, D.¬†Ramage, and P.¬†Richt√°rik,
‚ÄúFederated optimization: Distributed machine learning for on-device
intelligence,‚Äù 2016, arXiv:1610.02527.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B.¬†McMahan, E.¬†Moore, D.¬†Ramage, S.¬†Hampson, and B.¬†A.¬†y. Arcas,
‚ÄúCommunication-Efficient Learning of Deep Networks from Decentralized
Data,‚Äù in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics</em>, vol.¬†54, 2017, pp. 1273‚Äì1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
C.¬†Ma, J.¬†Li, M.¬†Ding, H.¬†H. Yang, F.¬†Shu, T.¬†Q.¬†S. Quek, and H.¬†V. Poor, ‚ÄúOn
safeguarding privacy and security in the framework of federated learning,‚Äù
<em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol.¬†34, no.¬†4, pp. 242‚Äì248, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Y.¬†Qu, L.¬†Gao, T.¬†H. Luan, Y.¬†Xiang, S.¬†Yu, B.¬†Li, and G.¬†Zheng,
‚ÄúDecentralized privacy using blockchain-enabled federated learning in fog
computing,‚Äù <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol.¬†7, no.¬†6, pp.
5171‚Äì5183, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
M.¬†Shayan, C.¬†Fung, C.¬†J.¬†M. Yoon, and I.¬†Beschastnikh, ‚ÄúBiscotti: A
blockchain system for private and secure federated learning,‚Äù <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Parallel and Distributed Systems</em>, vol.¬†32, no.¬†7, pp.
1513‚Äì1525, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T.¬†Li, A.¬†K. Sahu, A.¬†Talwalkar, and V.¬†Smith, ‚ÄúFederated learning:
Challenges, methods, and future directions,‚Äù <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol.¬†37, no.¬†3, pp. 50‚Äì60, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P.¬†Kairouz <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúAdvances and open problems in federated learning,‚Äù
2019, arXiv:1912.04977.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
D.¬†C. Nguyen, M.¬†Ding, Q.-V. Pham, P.¬†N. Pathirana, L.¬†B. Le, A.¬†Seneviratne,
J.¬†Li, D.¬†Niyato, and H.¬†V. Poor, ‚ÄúFederated learning meets blockchain in
edge computing: Opportunities and challenges,‚Äù <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Journal</em>, vol.¬†8, no.¬†16, pp. 12‚Äâ806‚Äì12‚Äâ825, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D.¬†Li, D.¬†Han, T.-H. Weng, Z.¬†Zheng, H.¬†Li, H.¬†Liu, A.¬†Castiglione, and K.-C.
Li, ‚ÄúBlockchain for federated learning toward secure distributed machine
learning systems: a systemic survey,‚Äù <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Soft Computing</em>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D.¬†Hou, J.¬†Zhang, K.¬†L. Man, J.¬†Ma, and Z.¬†Peng, ‚ÄúA systematic literature
review of blockchain-based federated learning: Architectures, applications
and issues,‚Äù in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">2nd Information Communication Technologies
Conference</em>, 2021, pp. 302‚Äì307.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C.¬†Li, Y.¬†Yuan, and F.-Y. Wang, ‚ÄúBlockchain-enabled federated learning: A
survey,‚Äù in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE 1st International Conference on Digital Twins and
Parallel Intelligence</em>, 2021, pp. 286‚Äì289.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Z.¬†Wang and Q.¬†Hu, ‚ÄúBlockchain-based federated learning: A comprehensive
survey,‚Äù 2021, arXiv:2110.02182.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M.¬†Ali, H.¬†Karimipour, and M.¬†Tariq, ‚ÄúIntegration of blockchain and federated
learning for internet of things: Recent advances and future challenges,‚Äù
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>, vol. 108, p. 102355, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L.¬†Lyu, H.¬†Yu, and Q.¬†Yang, ‚ÄúThreats to federated learning: A survey,‚Äù
2020, arXiv:2003.02133.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M.¬†S. Jere, T.¬†Farnan, and F.¬†Koushanfar, ‚ÄúA taxonomy of attacks on federated
learning,‚Äù <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Security Privacy</em>, vol.¬†19, no.¬†2, pp. 20‚Äì28, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
L.¬†Lyu, H.¬†Yu, X.¬†Ma, L.¬†Sun, J.¬†Zhao, Q.¬†Yang, and P.¬†S. Yu, ‚ÄúPrivacy and
robustness in federated learning: Attacks and defenses,‚Äù 2020,
arXiv:2012.06337.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
N.¬†Bouacida and P.¬†Mohapatra, ‚ÄúVulnerabilities in federated learning,‚Äù
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol.¬†9, pp. 63‚Äâ229‚Äì63‚Äâ249, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
V.¬†Mothukuri, R.¬†M. Parizi, S.¬†Pouriyeh, Y.¬†Huang, A.¬†Dehghantanha, and
G.¬†Srivastava, ‚ÄúA survey on security and privacy of federated learning,‚Äù
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 115, pp. 619‚Äì640, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
P.¬†Liu, X.¬†Xu, and W.¬†Wang, ‚ÄúThreats, attacks and defenses to federated
learning: issues, taxonomy and perspectives,‚Äù <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Cybersecurity</em>, vol.¬†5,
no.¬†1, p.¬†4, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A.¬†Qammar, A.¬†Karim, H.¬†Ning, and J.¬†Ding, ‚ÄúSecuring federated learning with
blockchain: a systematic literature review,‚Äù <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence
Review</em>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M.¬†Kolp, P.¬†Giorgini, and J.¬†Mylopoulos, ‚ÄúA goal-based organizational
perspective on multi-agent architectures,‚Äù in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Intelligent Agents
VIII</em>.¬†¬†¬†Berlin, Heidelberg: Springer
Berlin Heidelberg, 2002, pp. 128‚Äì140.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
S.¬†C. Hayden, C.¬†Carrick, and Q.¬†Yang, ‚ÄúArchitectural design patterns for
multiagent coordination,‚Äù in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International
Conference on Agent Systems</em>, vol.¬†99, 1999.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Q.¬†Yang, Y.¬†Liu, T.¬†Chen, and Y.¬†Tong, ‚ÄúFederated machine learning: Concept
and applications,‚Äù <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology</em>, vol.¬†10, no.¬†2, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
M.¬†Kantarcioglu and C.¬†Clifton, ‚ÄúPrivacy-preserving distributed mining of
association rules on horizontally partitioned data,‚Äù <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Knowledge and Data Engineering</em>, vol.¬†16, no.¬†9, pp. 1026‚Äì1037, 2004.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S.¬†Hardy, W.¬†Henecka, H.¬†Ivey-Law, R.¬†Nock, G.¬†Patrini, G.¬†Smith, and
B.¬†Thorne, ‚ÄúPrivate federated learning on vertically partitioned data via
entity resolution and additively homomorphic encryption,‚Äù 2017,
arXiv:1711.10677.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y.¬†Liu, Y.¬†Kang, C.¬†Xing, T.¬†Chen, and Q.¬†Yang, ‚ÄúA secure federated transfer
learning framework,‚Äù <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, vol.¬†35, no.¬†4, pp.
70‚Äì82, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Y.¬†Wu, S.¬†Cai, X.¬†Xiao, G.¬†Chen, and B.¬†C. Ooi, ‚ÄúPrivacy preserving vertical
federated learning for tree-based models,‚Äù <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em>,
vol.¬†13, no.¬†12, p. 2090‚Äì2103, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
K.¬†Cheng, T.¬†Fan, Y.¬†Jin, Y.¬†Liu, T.¬†Chen, D.¬†Papadopoulos, and Q.¬†Yang,
‚ÄúSecureboost: A lossless federated learning framework,‚Äù <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE
Intelligent Systems</em>, vol.¬†36, no.¬†6, pp. 87‚Äì98, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Q.¬†Li, Z.¬†Wen, and B.¬†He, ‚ÄúPractical federated gradient boosting decision
trees,‚Äù <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, vol.¬†34, no.¬†04, pp. 4642‚Äì4649, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S.¬†Nakamoto, ‚ÄúBitcoin: A peer-to-peer electronic cash system,‚Äù
<em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Decentralized business review</em>, p. 21260, 2008.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
D.¬†C. Nguyen, P.¬†N. Pathirana, M.¬†Ding, and A.¬†Seneviratne, ‚ÄúBlockchain for 5g
and beyond networks: A state of the art survey,‚Äù <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Journal of Network
and Computer Applications</em>, vol. 166, p. 102693, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
W.¬†Wang, D.¬†T. Hoang, P.¬†Hu, Z.¬†Xiong, D.¬†Niyato, P.¬†Wang, Y.¬†Wen, and D.¬†I.
Kim, ‚ÄúA survey on consensus mechanisms and mining strategy management in
blockchain networks,‚Äù <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol.¬†7, pp. 22‚Äâ328‚Äì22‚Äâ370,
2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
X.¬†Wang, X.¬†Zha, W.¬†Ni, R.¬†P. Liu, Y.¬†J. Guo, X.¬†Niu, and K.¬†Zheng, ‚ÄúSurvey on
blockchain for internet of things,‚Äù <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Computer Communications</em>, vol.
136, pp. 10‚Äì29, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
‚ÄúEthereum.‚Äù [Online]. Available: <a target="_blank" href="http://ethereum.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://ethereum.org</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
‚ÄúHyperledger.‚Äù [Online]. Available: <a target="_blank" href="https://www.hyperledger.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.hyperledger.org/</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
V.¬†Buterin, ‚ÄúEthereum: A next generation smart contract &amp; decentralized
application platform,‚Äù 2014. [Online]. Available:
<a target="_blank" href="https://ethereum.org/669c9e2e2027310b6b3cdce6e1c52962/Ethereum_Whitepaper_-_Buterin_2014.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ethereum.org/669c9e2e2027310b6b3cdce6e1c52962/Ethereum_Whitepaper_-_Buterin_2014.pdf</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
E.¬†Androulaki, A.¬†Barger, V.¬†Bortnikov, C.¬†Cachin, K.¬†Christidis, A.¬†De¬†Caro,
D.¬†Enyeart, C.¬†Ferris, G.¬†Laventman, Y.¬†Manevich, S.¬†Muralidharan, C.¬†Murthy,
B.¬†Nguyen, M.¬†Sethi, G.¬†Singh, K.¬†Smith, A.¬†Sorniotti, C.¬†Stathakopoulou,
M.¬†Vukoliƒá, S.¬†W. Cocco, and J.¬†Yellick, ‚ÄúHyperledger fabric: A
distributed operating system for permissioned blockchains,‚Äù in
<em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirteenth EuroSys Conference</em>, 2018.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J.¬†Kang, R.¬†Yu, X.¬†Huang, S.¬†Maharjan, Y.¬†Zhang, and E.¬†Hossain, ‚ÄúEnabling
localized peer-to-peer electricity trading among plug-in hybrid electric
vehicles using consortium blockchains,‚Äù <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Industrial Informatics</em>, vol.¬†13, no.¬†6, pp. 3154‚Äì3164, 2017.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Z.¬†Li, J.¬†Kang, R.¬†Yu, D.¬†Ye, Q.¬†Deng, and Y.¬†Zhang, ‚ÄúConsortium blockchain
for secure energy trading in industrial internet of things,‚Äù <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, vol.¬†14, no.¬†8, pp. 3690‚Äì3700,
2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
H.¬†Watanabe, S.¬†Fujimura, A.¬†Nakadaira, Y.¬†Miyazaki, A.¬†Akutsu, and
J.¬†Kishigami, ‚ÄúBlockchain contract: Securing a blockchain applied to smart
contracts,‚Äù in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Consumer Electronics</em>,
2016, pp. 467‚Äì468.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Z.¬†Cui, F.¬†XUE, S.¬†Zhang, X.¬†Cai, Y.¬†Cao, W.¬†Zhang, and J.¬†Chen, ‚ÄúA hybrid
blockchain-based identity authentication scheme for multi-wsn,‚Äù <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Services Computing</em>, vol.¬†13, no.¬†2, pp. 241‚Äì251, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
P.¬†Vanhaesebrouck, A.¬†Bellet, and M.¬†Tommasi, ‚ÄúDecentralized Collaborative
Learning of Personalized Models over Networks,‚Äù in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
20th International Conference on Artificial Intelligence and Statistics</em>,
vol.¬†54.¬†¬†¬†PMLR, 2017, pp. 509‚Äì517.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
W.¬†Liu, L.¬†Chen, and W.¬†Zhang, ‚ÄúDecentralized federated learning: Balancing
communication and computing costs,‚Äù 2021, arXiv:2107.12048.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
X.¬†Lian, C.¬†Zhang, H.¬†Zhang, C.-J. Hsieh, W.¬†Zhang, and J.¬†Liu, ‚ÄúCan
decentralized algorithms outperform centralized algorithms? a case study for
decentralized parallel stochastic gradient descent,‚Äù in <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems</em>, vol.¬†30, 2017.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Q.¬†Yang, ‚ÄúToward responsible ai: An overview of federated learning for
user-centered privacy-preserving computing,‚Äù <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Interact.
Intell. Syst.</em>, vol.¬†11, no. 3‚Äì4, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
C.¬†Hu, J.¬†Jiang, and Z.¬†Wang, ‚ÄúDecentralized federated learning: A segmented
gossip approach,‚Äù 2019, arXiv:1908.07782.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Z.¬†Jiang, A.¬†Balu, C.¬†Hegde, and S.¬†Sarkar, ‚ÄúCollaborative deep learning in
fixed topology networks,‚Äù in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, vol.¬†30, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
P.¬†Ramanan and K.¬†Nakayama, ‚ÄúBaffle : Blockchain based aggregator free
federated learning,‚Äù in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Blockchain</em>,
2020, pp. 72‚Äì81.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
A.¬†Lalitha, S.¬†Shekhar, T.¬†Javidi, and F.¬†Koushanfar, ‚ÄúFully decentralized
federated learning,‚Äù in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Third workshop on Bayesian Deep Learning
(NeurIPS)</em>, 2018.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A.¬†Lalitha, O.¬†C. Kilinc, T.¬†Javidi, and F.¬†Koushanfar, ‚ÄúPeer-to-peer
federated learning on graphs,‚Äù 2019, arXiv:1901.11173.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
J.¬†Li, Y.¬†Shao, K.¬†Wei, M.¬†Ding, C.¬†Ma, L.¬†Shi, Z.¬†Han, and H.¬†Poor,
‚ÄúBlockchain assisted decentralized federated learning (blade-fl):
Performance analysis and resource allocation,‚Äù <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Parallel and Distributed Systems</em>, vol.¬†33, no.¬†10, pp. 2401‚Äì2415, 2022.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Y.¬†Li, C.¬†Chen, N.¬†Liu, H.¬†Huang, Z.¬†Zheng, and Q.¬†Yan, ‚ÄúA blockchain-based
decentralized federated learning framework with committee consensus,‚Äù
<em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol.¬†35, no.¬†1, pp. 234‚Äì241, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
P.¬†Bhattacharya, S.¬†Tanwar, U.¬†Bodkhe, S.¬†Tyagi, and N.¬†Kumar, ‚ÄúBindaas:
Blockchain-based deep-learning as-a-service in healthcare 4.0 applications,‚Äù
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and Engineering</em>, vol.¬†8, no.¬†2,
pp. 1242‚Äì1255, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
X.¬†Chen, J.¬†Ji, C.¬†Luo, W.¬†Liao, and P.¬†Li, ‚ÄúWhen machine learning meets
blockchain: A decentralized, privacy-preserving and secure design,‚Äù in
<em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Big Data</em>, 2018, pp. 1178‚Äì1187.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
S.¬†Zhou, H.¬†Huang, W.¬†Chen, P.¬†Zhou, Z.¬†Zheng, and S.¬†Guo, ‚ÄúPirate: A
blockchain-based secure framework of distributed machine learning in 5g
networks,‚Äù <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol.¬†34, no.¬†6, pp. 84‚Äì91, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
A.¬†Mondal, H.¬†Virk, and D.¬†Gupta, ‚ÄúBEAS: blockchain enabled asynchronous
&amp; secure federated machine learning,‚Äù 2022, arXiv:2202.02817.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
A.¬†G. Roy, S.¬†Siddiqui, S.¬†P√∂lsterl, N.¬†Navab, and C.¬†Wachinger,
‚ÄúBraintorrent: A peer-to-peer environment for decentralized federated
learning,‚Äù 2019, arXiv:1905.06731.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
J.¬†Kang, Z.¬†Xiong, D.¬†Niyato, Y.¬†Zou, Y.¬†Zhang, and M.¬†Guizani, ‚ÄúReliable
federated learning for mobile networks,‚Äù <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol.¬†27, no.¬†2, pp. 72‚Äì80, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
H.¬†B. Desai, M.¬†S. Ozdayi, and M.¬†Kantarcioglu, ‚ÄúBlockfla: Accountable
federated learning via hybrid blockchain architecture,‚Äù in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the Eleventh ACM Conference on Data and Application Security and Privacy</em>,
2021, p. 101‚Äì112.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
L.¬†A.¬†C. de¬†Souza, G.¬†Antonio F.¬†Rebello, G.¬†F. Camilo, L.¬†C.¬†B. Guimar√£es,
and O.¬†C. M.¬†B. Duarte, ‚ÄúDfedforest: Decentralized federated forest,‚Äù in
<em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Blockchain</em>, 2020, pp. 90‚Äì97.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Y.¬†He, K.¬†Huang, G.¬†Zhang, F.¬†R. Yu, J.¬†Chen, and J.¬†Li, ‚ÄúBift: A
blockchain-based federated learning system for connected and autonomous
vehicles,‚Äù <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol.¬†9, no.¬†14, pp.
12‚Äâ311‚Äì12‚Äâ322, 2022.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
J.¬†Chen, R.¬†Monga, S.¬†Bengio, and R.¬†Jozefowicz, ‚ÄúRevisiting distributed
synchronous sgd,‚Äù in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations Workshop Track</em>, 2016, arXiv:1604.00981.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
C.¬†Fang, Y.¬†Guo, J.¬†Ma, H.¬†Xie, and Y.¬†Wang, ‚ÄúA privacy-preserving and
verifiable federated learning method based on blockchain,‚Äù <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Computer
Communications</em>, vol. 186, pp. 1‚Äì11, 2022.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Warnat-Herresthal <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúSwarm Learning for decentralized and
confidential clinical machine learning,‚Äù <em id="bib.bib64.2.2" class="ltx_emph ltx_font_italic">Nature</em>, vol. 594, no. 7862,
pp. 265‚Äì270, 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
L.¬†Chen, S.¬†Fu, L.¬†Lin, Y.¬†Luo, and W.¬†Zhao, ‚ÄúPrivacy-preserving swarm
learning based on¬†homomorphic encryption,‚Äù in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Algorithms and
Architectures for Parallel Processing</em>.¬†¬†¬†Cham: Springer International Publishing, 2022, pp. 509‚Äì523.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
J.¬†Han, Y.¬†Ma, and Y.¬†Han, ‚ÄúDemystifying swarm learning: A new paradigm of
blockchain-based decentralized federated learning,‚Äù 2022, arXiv:2201.05286.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
E.¬†Hallaji, R.¬†Razavi-Far, and M.¬†Saif, <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Federated and Transfer Learning:
A Survey on Adversaries and Defense Mechanisms</em>.¬†¬†¬†Cham: Springer International Publishing, 2023, pp. 29‚Äì55.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
E.¬†Hallaji, R.¬†Razavi-Far, M.¬†Saif, and E.¬†Herrera-Viedma, ‚ÄúLabel noise
analysis meets adversarial training: A defense against label poisoning in
federated learning,‚Äù <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 266, p. 110384,
2023.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
E.¬†Rosenfeld, E.¬†Winston, P.¬†Ravikumar, and Z.¬†Kolter, ‚ÄúCertified robustness
to label-flipping attacks via randomized smoothing,‚Äù in <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 37th International Conference on Machine Learning</em>, vol. 119, 2020, pp.
8230‚Äì8241.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
E.¬†Bagdasaryan, A.¬†Veit, Y.¬†Hua, D.¬†Estrin, and V.¬†Shmatikov, ‚ÄúHow to backdoor
federated learning,‚Äù in <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty Third International
Conference on Artificial Intelligence and Statistics</em>, vol. 108, 2020, pp.
2938‚Äì2948.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
A.¬†N. Bhagoji, S.¬†Chakraborty, P.¬†Mittal, and S.¬†Calo, ‚ÄúAnalyzing federated
learning through an adversarial lens,‚Äù in <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th
International Conference on Machine Learning</em>, vol.¬†97, 2019, pp. 634‚Äì643.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
X.¬†Li, P.¬†Jiang, T.¬†Chen, X.¬†Luo, and Q.¬†Wen, ‚ÄúA survey on the security of
blockchain systems,‚Äù <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 107,
pp. 841‚Äì853, 2020.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
M.¬†A. Khan and K.¬†Salah, ‚ÄúIot security: Review, blockchain solutions, and open
challenges,‚Äù <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol.¬†82, pp.
395‚Äì411, 2018.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
L.¬†Zhu, Z.¬†Liu, and S.¬†Han, ‚ÄúDeep leakage from gradients,‚Äù in <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Advances
in Neural Information Processing Systems</em>, vol.¬†32, 2019.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
L.¬†Melis, C.¬†Song, E.¬†De¬†Cristofaro, and V.¬†Shmatikov, ‚ÄúExploiting unintended
feature leakage in collaborative learning,‚Äù in <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on
Security and Privacy</em>, 2019, pp. 691‚Äì706.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
B.¬†Hitaj, G.¬†Ateniese, and F.¬†Perez-Cruz, ‚ÄúDeep models under the gan:
Information leakage from collaborative deep learning,‚Äù in <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the ACM SIGSAC Conference on Computer and Communications Security</em>, 2017,
pp. 603‚Äì618.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
H.¬†Wang, K.¬†Sreenivasan, S.¬†Rajput, H.¬†Vishwakarma, S.¬†Agarwal, J.-y. Sohn,
K.¬†Lee, and D.¬†Papailiopoulos, ‚ÄúAttack of the tails: Yes, you really can
backdoor federated learning,‚Äù in <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, vol.¬†33, 2020, pp. 16‚Äâ070‚Äì16‚Äâ084.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
C.¬†Xie, K.¬†Huang, P.-Y. Chen, and B.¬†Li, ‚ÄúDba: Distributed backdoor attacks
against federated learning,‚Äù in <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>, 2020.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Z.¬†A.¬†E. Houda, A.¬†S. Hafid, and L.¬†Khoukhi, ‚ÄúMitfed: A privacy preserving
collaborative network attack mitigation framework based on federated learning
using sdn and blockchain,‚Äù <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and
Engineering</em>, vol.¬†10, no.¬†4, pp. 1985‚Äì2001, 2023.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
J.¬†Xu, S.¬†Huang, L.¬†Song, and T.¬†Lan, ‚ÄúByzantine-robust federated learning
through collaborative malicious gradient filtering,‚Äù in <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">IEEE 42nd
International Conference on Distributed Computing Systems</em>, 2022, pp.
1223‚Äì1235.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
M.¬†Fredrikson, S.¬†Jha, and T.¬†Ristenpart, ‚ÄúModel inversion attacks that
exploit confidence information and basic countermeasures,‚Äù in
<em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security</em>, 2015, pp. 1322‚Äì1333.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Y.¬†Chen, H.¬†Chen, Y.¬†Zhang, M.¬†Han, M.¬†Siddula, and Z.¬†Cai, ‚ÄúA survey on
blockchain systems: Attacks, defenses, and privacy preservation,‚Äù
<em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">High-Confidence Computing</em>, vol.¬†2, no.¬†2, p. 100048, 2022.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
H.¬†Chu, P.¬†Zhang, H.¬†Dong, Y.¬†Xiao, S.¬†Ji, and W.¬†Li, ‚ÄúA survey on smart
contract vulnerabilities: Data sources, detection and repair,‚Äù
<em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Information and Software Technology</em>, vol. 159, p. 107221, 2023.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
B.¬†Wang, Y.¬†Yao, S.¬†Shan, H.¬†Li, B.¬†Viswanath, H.¬†Zheng, and B.¬†Y. Zhao,
‚ÄúNeural cleanse: Identifying and mitigating backdoor attacks in neural
networks,‚Äù in <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>, 2019, pp.
707‚Äì723.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Y.¬†Li, X.¬†Lyu, N.¬†Koren, L.¬†Lyu, B.¬†Li, and X.¬†Ma, ‚ÄúNeural attention
distillation: Erasing backdoor triggers from deep neural networks,‚Äù in
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021. [Online].
Available: <a target="_blank" href="https://openreview.net/forum?id=9l0K4OM-oXE" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=9l0K4OM-oXE</a>

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
R.¬†Doriguzzi-Corin and D.¬†Siracusa, ‚ÄúFlad: Adaptive federated learning for
ddos attack detection,‚Äù <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>, vol. 137, p. 103597,
2024.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
P.¬†Blanchard, E.¬†M. El¬†Mhamdi, R.¬†Guerraoui, and J.¬†Stainer, ‚ÄúMachine learning
with adversaries: Byzantine tolerant gradient descent,‚Äù in <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems</em>, vol.¬†30, 2017.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
S.¬†Shen, S.¬†Tople, and P.¬†Saxena, ‚ÄúAuror: Defending against poisoning attacks
in collaborative deep learning systems,‚Äù in <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd
Annual Conference on Computer Security Applications</em>, 2016, pp. 508‚Äì519.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
V.¬†Rastogi and S.¬†Nath, ‚ÄúDifferentially private aggregation of distributed
time-series with transformation and encryption,‚Äù in <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
CM SIGMOD International Conference on Management of Data</em>, 2010, pp.
735‚Äì746.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
G.¬†√Åcs and C.¬†Castelluccia, ‚ÄúI have a dream! (differentially private smart
metering),‚Äù in <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Information Hiding</em>.¬†¬†¬†Berlin, Heidelberg: Springer Berlin Heidelberg, 2011, pp.
118‚Äì132.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
B.¬†Balle, G.¬†Barthe, and M.¬†Gaboardi, ‚ÄúPrivacy amplification by subsampling:
Tight analyses via couplings and divergences,‚Äù in <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, vol.¬†31, 2018.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
V.¬†Feldman, I.¬†Mironov, K.¬†Talwar, and A.¬†Thakurta, ‚ÄúPrivacy amplification by
iteration,‚Äù in <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">IEEE 59th Annual Symposium on Foundations of Computer
Science</em>, Los Alamitos, CA, USA, 2018, pp. 521‚Äì532.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
H.¬†Kasyap and S.¬†Tripathy, ‚ÄúPrivacy-preserving decentralized learning
framework for healthcare system,‚Äù <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Multimedia Comput.
Commun. Appl.</em>, vol.¬†17, no.¬†2s, 2021.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
X.¬†Bao, C.¬†Su, Y.¬†Xiong, W.¬†Huang, and Y.¬†Hu, ‚ÄúFlchain: A blockchain for
auditable federated learning with trust and incentive,‚Äù in <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">5th
International Conference on Big Data Computing and Communications</em>, 2019, pp.
151‚Äì159.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Z.¬†Peng, J.¬†Xu, X.¬†Chu, S.¬†Gao, Y.¬†Yao, R.¬†Gu, and Y.¬†Tang, ‚ÄúVfchain: Enabling
verifiable and auditable federated learning via blockchain systems,‚Äù
<em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and Engineering</em>, vol.¬†9, no.¬†1,
pp. 173‚Äì186, 2022.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
M.¬†Ogburn, C.¬†Turner, and P.¬†Dahal, ‚ÄúHomomorphic encryption,‚Äù <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">Procedia
Computer Science</em>, vol.¬†20, pp. 502‚Äì509, 2013, complex Adaptive Systems.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
C.¬†Gentry, ‚ÄúFully homomorphic encryption using ideal lattices,‚Äù in
<em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Forty-First Annual ACM Symposium on Theory of
Computing</em>, 2009, pp. 169‚Äì178.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
I.¬†Damg√•rd, V.¬†Pastro, N.¬†Smart, and S.¬†Zakarias, ‚ÄúMultiparty computation
from somewhat homomorphic encryption,‚Äù in <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Advances in
Cryptology</em>.¬†¬†¬†Berlin, Heidelberg:
Springer Berlin Heidelberg, 2012, pp. 643‚Äì662.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
R.¬†L. Rivest, A.¬†Shamir, and L.¬†Adleman, ‚ÄúA method for obtaining digital
signatures and public-key cryptosystems,‚Äù <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol.¬†21,
no.¬†2, pp. 120‚Äì126, 1978.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
P.¬†Paillier, ‚ÄúPublic-key cryptosystems based on composite degree residuosity
classes,‚Äù in <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Advances in Cryptology</em>.¬†¬†¬†Berlin, Heidelberg: Springer Berlin Heidelberg, 1999, pp.
223‚Äì238.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Y.¬†Aono, T.¬†Hayashi, L.¬†Trieu¬†Phong, and L.¬†Wang, ‚ÄúScalable and secure
logistic regression via homomorphic encryption,‚Äù in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Sixth ACM Conference on Data and Application Security and Privacy</em>, 2016, pp.
142‚Äì144.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
M.¬†Kim, Y.¬†Song, S.¬†Wang, Y.¬†Xia, and X.¬†Jiang, ‚ÄúSecure logistic regression
based on homomorphic encryption: Design and evaluation,‚Äù <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">JMIR Med
Inform</em>, vol.¬†6, no.¬†2, p. e19, 2018.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
L.¬†T. Phong, Y.¬†Aono, T.¬†Hayashi, L.¬†Wang, and S.¬†Moriai, ‚ÄúPrivacy-preserving
deep learning via additively homomorphic encryption,‚Äù <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Information Forensics and Security</em>, vol.¬†13, no.¬†5, pp.
1333‚Äì1345, 2018.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
A.¬†C. Yao, ‚ÄúProtocols for secure computations,‚Äù in <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">23rd Annual
Symposium on Foundations of Computer Science</em>, 1982, pp. 160‚Äì164.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
P.¬†Mohassel and Y.¬†Zhang, ‚ÄúSecureml: A system for scalable privacy-preserving
machine learning,‚Äù in <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>, 2017,
pp. 19‚Äì38.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
P.¬†Mohassel and P.¬†Rindal, ‚ÄúABY 3 : A mixed protocol framework for machine
learning,‚Äù in <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGSAC Conference on Computer and
Communications Security</em>, 2018, pp. 35‚Äì52.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
V.¬†Chen, V.¬†Pastro, and M.¬†Raykova, ‚ÄúSecure computation for machine learning
with SPDZ,‚Äù 2019, arXiv:1901.00329.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Y.¬†Ma, X.¬†Zhu, and J.¬†Hsu, ‚ÄúData poisoning against differentially-private
learners: Attacks and defenses,‚Äù in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th
International Joint Conference on Artificial Intelligence</em>, Macao, China,
2019, pp. 4732‚Äì4738.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
M.¬†Abadi, A.¬†Chu, I.¬†Goodfellow, H.¬†B. McMahan, I.¬†Mironov, K.¬†Talwar, and
L.¬†Zhang, ‚ÄúDeep learning with differential privacy,‚Äù in <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the ACM SIGSAC Conference on Computer and Communications Security</em>, 2016,
pp. 308‚Äì318.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
R.¬†C. Geyer, T.¬†Klein, and M.¬†Nabi, ‚ÄúDifferentially private federated
learning: A client level perspective,‚Äù 2017, arXiv:1712.07557.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
A.¬†Shamir, ‚ÄúHow to share a secret,‚Äù <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol.¬†22, no.¬†11, p.
612‚Äì613, 1979.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
C.¬†Dwork, ‚ÄúDifferential privacy: A survey of results,‚Äù in <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Theory and
Applications of Models of Computation</em>.¬†¬†¬†Berlin, Heidelberg: Springer Berlin Heidelberg, 2008, pp. 1‚Äì19.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
R.¬†Xu, N.¬†Baracaldo, Y.¬†Zhou, A.¬†Anwar, and H.¬†Ludwig, ‚ÄúHybridalpha: An
efficient approach for privacy-preserving federated learning,‚Äù in
<em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM Workshop on Artificial Intelligence and
Security</em>, 2019, p. 13‚Äì23.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
S.¬†Truex, N.¬†Baracaldo, A.¬†Anwar, T.¬†Steinke, H.¬†Ludwig, R.¬†Zhang, and Y.¬†Zhou,
‚ÄúA hybrid approach to privacy-preserving federated learning,‚Äù in
<em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM Workshop on Artificial Intelligence and
Security</em>, 2019, p. 1‚Äì11.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
J.¬†Dong, A.¬†Roth, and W.¬†J. Su, ‚ÄúGaussian Differential Privacy,‚Äù
<em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Journal of the Royal Statistical Society Series B: Statistical
Methodology</em>, vol.¬†84, no.¬†1, pp. 3‚Äì37, 2022.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Q.¬†Zheng, S.¬†Chen, Q.¬†Long, and W.¬†Su, ‚ÄúFederated f-differential privacy,‚Äù in
<em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Proceedings of The 24th International Conference on Artificial
Intelligence and Statistics</em>, vol. 130, 2021, pp. 2251‚Äì2259.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Z.¬†Bu, J.¬†Dong, Q.¬†Long, and W.¬†Su, ‚ÄúDeep Learning With Gaussian
Differential Privacy,‚Äù <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">Harvard Data Science Review</em>, vol.¬†2,
no.¬†3, 2020. [Online]. Available:
<a target="_blank" href="https://hdsr.mitpress.mit.edu/pub/u24wj42y" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://hdsr.mitpress.mit.edu/pub/u24wj42y</a>

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
D.¬†P. Kingma and J.¬†Ba, ‚ÄúAdam: A method for stochastic optimization,‚Äù in
<em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on Learning Representations</em>, 2015,
arXiv:1412.6980.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
H.¬†B. McMahan, D.¬†Ramage, K.¬†Talwar, and L.¬†Zhang, ‚ÄúLearning differentially
private recurrent language models,‚Äù in <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">International Conference on
Learning Representations</em>, 2018. [Online]. Available:
<a target="_blank" href="https://openreview.net/forum?id=BJ0hF1Z0b" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=BJ0hF1Z0b</a>

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
J.¬†C. Duchi, M.¬†I. Jordan, and M.¬†J. Wainwright, ‚ÄúLocal privacy and
statistical minimax rates,‚Äù in <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">1st Annual Allerton Conference on
Communication, Control, and Computing</em>, 2013, pp. 1592‚Äì1592.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
F.¬†Benhamouda, M.¬†Joye, and B.¬†Libert, ‚ÄúA new framework for privacy-preserving
aggregation of time-series data,‚Äù <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Inf. Syst. Secur.</em>,
vol.¬†18, no.¬†3, 2016.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
C.¬†Dwork, K.¬†Kenthapadi, F.¬†McSherry, I.¬†Mironov, and M.¬†Naor, ‚ÄúOur data,
ourselves: Privacy via distributed noise generation,‚Äù in <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Advances in
Cryptology</em>, vol. 4004, 2006, pp. 486‚Äì503.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
L.¬†Sun and L.¬†Lyu, ‚ÄúFederated model distillation with noise-free differential
privacy,‚Äù 2020, arXiv:2009.05537.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
N.¬†Papernot, M.¬†Abadi, √ö.¬†Erlingsson, I.¬†Goodfellow, and K.¬†Talwar,
‚ÄúSemi-supervised knowledge transfer for deep learning from private training
data,‚Äù 2017, arXiv:1610.05755.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
N.¬†Agarwal, A.¬†T. Suresh, F.¬†Yu, S.¬†Kumar, and H.¬†B. McMahan, ‚ÄúCpSGD:
Communication-efficient and differentially-private distributed SGD,‚Äù in
<em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd International Conference on Neural Information
Processing Systems</em>, 2018, pp. 7575‚Äì7586.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
E.¬†Hallaji, R.¬†Razavi-Far, M.¬†Wang, M.¬†Saif, and B.¬†Fardanesh, ‚ÄúA stream
learning approach for real-time identification of false data injection
attacks in cyber-physical power systems,‚Äù <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol.¬†17, pp. 3934‚Äì3945, 2022.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
S.¬†Morishima, ‚ÄúScalable anomaly detection in blockchain using graphics
processing unit,‚Äù <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Electrical Engineering</em>, vol.¬†92, p.
107087, 2021.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
M.¬†Signorini, M.¬†Pontecorvi, W.¬†Kanoun, and R.¬†Di¬†Pietro, ‚ÄúBad: A blockchain
anomaly detection solution,‚Äù <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol.¬†8, pp.
173‚Äâ481‚Äì173‚Äâ490, 2020.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
B.¬†Nelson, M.¬†Barreno, F.¬†J. Chi, A.¬†D. Joseph, B.¬†I.¬†P. Rubinstein, U.¬†Saini,
C.¬†Sutton, J.¬†D. Tygar, and K.¬†Xia, ‚ÄúExploiting machine learning to subvert
your spam filter,‚Äù in <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st USENIX Workshop on
Large-Scale Exploits and Emergent Threats</em>, 2008.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
M.¬†Jagielski, A.¬†Oprea, B.¬†Biggio, C.¬†Liu, C.¬†Nita-Rotaru, and B.¬†Li,
‚ÄúManipulating machine learning: Poisoning attacks and countermeasures for
regression learning,‚Äù in <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>,
2018, pp. 19‚Äì35.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
S.¬†Li, Y.¬†Cheng, W.¬†Wang, Y.¬†Liu, and T.¬†Chen, ‚ÄúLearning to detect malicious
clients for robust federated learning,‚Äù 2020, arXiv:2002.00211.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
T.¬†Id√©, ‚ÄúCollaborative anomaly detection on blockchain from noisy sensor
data,‚Äù in <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Data Mining Workshops</em>,
2018, pp. 120‚Äì127.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
E.¬†Hallaji, M.¬†Farajzadeh-Zanjani, R.¬†Razavi-Far, V.¬†Palade, and M.¬†Saif,
‚ÄúConstrained generative adversarial learning for dimensionality reduction,‚Äù
<em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, vol.¬†35, no.¬†3,
pp. 2394‚Äì2405, 2023.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
F.¬†Ang, L.¬†Chen, N.¬†Zhao, Y.¬†Chen, W.¬†Wang, and F.¬†R. Yu, ‚ÄúRobust federated
learning with noisy communication,‚Äù <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Communications</em>, vol.¬†68, no.¬†6, pp. 3452‚Äì3464, 2020.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
K.¬†Pillutla, S.¬†M. Kakade, and Z.¬†Harchaoui, ‚ÄúRobust aggregation for federated
learning,‚Äù 2019, arXiv:1912.13445.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
M.¬†Grama, M.¬†Musat, L.¬†Mu√±oz-Gonz√°lez, J.¬†Passerat-Palmbach,
D.¬†Rueckert, and A.¬†Alansary, ‚ÄúRobust aggregation for adaptive privacy
preserving federated learning in healthcare,‚Äù 2020, arXiv:2009.08294.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
S.¬†Caldas, J.¬†Koneƒçn√Ω, H.¬†B. McMahan, and A.¬†Talwalkar, ‚ÄúExpanding
the reach of federated learning by reducing client resource requirements,‚Äù
2018, arXiv:1812.07210.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
Y.¬†Jiang, S.¬†Wang, B.¬†Ko, W.¬†Lee, and L.¬†Tassiulas, ‚ÄúModel pruning enables
efficient federated learning on edge devices,‚Äù 2019, arXiv:1909.12326.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
Y.¬†Chen, F.¬†Luo, T.¬†Li, T.¬†Xiang, Z.¬†Liu, and J.¬†Li, ‚ÄúA training-integrity
privacy-preserving federated learning scheme with trusted execution
environment,‚Äù <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em>, vol. 522, pp. 69‚Äì79, 2020.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
F.¬†Mo, H.¬†Haddadi, K.¬†Katevas, E.¬†Marin, D.¬†Perino, and N.¬†Kourtellis,
‚ÄúPPFL: Privacy-preserving federated learning with trusted execution
environments,‚Äù in <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th Annual International
Conference on Mobile Systems, Applications, and Services</em>, 2021, pp. 94‚Äì108.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
M.¬†Brandenburger, C.¬†Cachin, R.¬†Kapitza, and A.¬†Sorniotti, ‚ÄúBlockchain and
trusted computing: Problems, pitfalls, and a solution for hyperledger
fabric,‚Äù 2018.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
S.¬†Goldwasser, S.¬†Micali, and C.¬†Rackoff, ‚ÄúThe knowledge complexity of
interactive proof systems,‚Äù <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">SIAM Journal on Computing</em>, vol.¬†18,
no.¬†1, pp. 186‚Äì208, 1989.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
B.¬†Parno, J.¬†Howell, C.¬†Gentry, and M.¬†Raykova, ‚ÄúPinocchio: Nearly practical
verifiable computation,‚Äù in <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">EEE Symposium on Security and Privacy</em>,
2013, pp. 238‚Äì252.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
C.¬†Weng, K.¬†Yang, X.¬†Xie, J.¬†Katz, and X.¬†Wang, ‚ÄúMystique: Efficient
conversions for zero-knowledge proofs with applications to machine
learning,‚Äù in <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">USENIX Security</em>, 2021, pp. 501‚Äì518.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
D.¬†Li and J.¬†Wang, ‚ÄúFedmd: Heterogenous federated learning via model
distillation,‚Äù 2019, arXiv:1910.03581.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
R.¬†Shokri, M.¬†Stronati, C.¬†Song, and V.¬†Shmatikov, ‚ÄúMembership inference
attacks against machine learning models,‚Äù in <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on
Security and Privacy</em>, 2017, pp. 3‚Äì18.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
A.¬†Salem, Y.¬†Zhang, M.¬†Humbert, M.¬†Fritz, and M.¬†Backes, ‚ÄúML-Leaks: Model
and data independent membership inference attacks and defenses on machine
learning models,‚Äù 2018, arXiv:1806.01246.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
A.¬†Raghunathan, J.¬†Steinhardt, and P.¬†Liang, ‚ÄúCertified defenses against
adversarial examples,‚Äù in <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>, 2018. [Online]. Available:
<a target="_blank" href="https://openreview.net/forum?id=Bys4ob-Rb" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bys4ob-Rb</a>

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
Y.¬†Zhang and H.¬†Yu, ‚ÄúTowards verifiable federated learning,‚Äù in
<em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-First International Joint Conference on
Artificial Intelligence, IJCAI-22</em>, 2022, pp. 5686‚Äì5693, survey Track.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
H.¬†Kim, J.¬†Park, M.¬†Bennis, and S.-L. Kim, ‚ÄúBlockchained on-device federated
learning,‚Äù <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol.¬†24, no.¬†6, pp.
1279‚Äì1283, 2020.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
Y.¬†Zhao, J.¬†Zhao, L.¬†Jiang, R.¬†Tan, and D.¬†Niyato, ‚ÄúMobile edge computing,
blockchain and reputation-based crowdsourcing iot federated learning: A
secure, decentralized and privacy-preserving system,‚Äù 2019,
arXiv:1906.10893.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
S.¬†Baghersalimi, T.¬†Teijeiro, A.¬†Aminifar, and D.¬†Atienza, ‚ÄúDecentralized
federated learning for epileptic seizures detection in low-power wearable
systems,‚Äù <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>, pp. 1‚Äì16, 2023.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
M.¬†Aloqaily, I.¬†A. Ridhawi, and M.¬†Guizani, ‚ÄúEnergy-aware blockchain and
federated learning-supported vehicular networks,‚Äù <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Intelligent Transportation Systems</em>, vol.¬†23, no.¬†11, pp. 22‚Äâ641‚Äì22‚Äâ652,
2022.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
S.¬†H. Alsamhi, F.¬†A. Almalki, F.¬†Afghah, A.¬†Hawbani, A.¬†V. Shvetsov, B.¬†Lee,
and H.¬†Song, ‚ÄúDrones‚Äô edge intelligence over smart environments in b5g:
Blockchain and federated learning synergy,‚Äù <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Green
Communications and Networking</em>, vol.¬†6, no.¬†1, pp. 295‚Äì312, 2022.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
X.¬†Qu, S.¬†Wang, Q.¬†Hu, and X.¬†Cheng, ‚ÄúProof of federated learning: A novel
energy-recycling consensus algorithm,‚Äù <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel
and Distributed Systems</em>, vol.¬†32, no.¬†08, pp. 2074‚Äì2085, 2021.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
T.¬†Li, A.¬†K. Sahu, M.¬†Zaheer, M.¬†Sanjabi, A.¬†Talwalkar, and V.¬†Smith,
‚ÄúFederated optimization in heterogeneous networks,‚Äù 2020.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
D.¬†Gao, Y.¬†Liu, A.¬†Huang, C.¬†Ju, H.¬†Yu, and Q.¬†Yang, ‚ÄúPrivacy-preserving
heterogeneous federated transfer learning,‚Äù in <em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">IEEE International
Conference on Big Data</em>, 2019, pp. 2552‚Äì2559.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
Q.¬†Wang, Y.¬†Guo, X.¬†Wang, T.¬†Ji, L.¬†Yu, and P.¬†Li, ‚ÄúAi at the edge:
Blockchain-empowered secure multiparty learning with heterogeneous models,‚Äù
<em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol.¬†7, no.¬†10, pp. 9600‚Äì9610, 2020.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
X.-Z. Wu, S.¬†Liu, and Z.-H. Zhou, ‚ÄúHeterogeneous model reuse via optimizing
multiparty multiclass margin,‚Äù in <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th
International Conference on Machine Learning</em>, vol.¬†97, 2019, pp. 6840‚Äì6849.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
J.¬†Kang, Z.¬†Xiong, D.¬†Niyato, S.¬†Xie, and J.¬†Zhang, ‚ÄúIncentive mechanism for
reliable federated learning: A joint optimization approach to combining
reputation and contract theory,‚Äù <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
vol.¬†6, no.¬†6, pp. 10‚Äâ700‚Äì10‚Äâ714, 2019.

</span>
</li>
</ul>
</section>
<figure id="id1" class="ltx_float biography">
<table id="id1.1" class="ltx_tabular">
<tr id="id1.1.1" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td"><img src="/html/2401.17319/assets/Ehsan_Hallaji.jpg" id="id1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id1.1.1.2" class="ltx_td">
<span id="id1.1.1.2.1" class="ltx_inline-block">
<span id="id1.1.1.2.1.1" class="ltx_p"><span id="id1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Ehsan Hallaji</span> 
(Graduate Student Member, IEEE) received the B.Sc. degree in software engineering from Shahid Rajaee University, Tehran, Iran, in 2015, and the M.A.Sc. degree in electrical and computer engineering from the University of Windsor, Windsor, ON, Canada, in 2018, where he is currently pursuing a Ph.D. degree with the Department of Electrical and Computer Engineering. His current research interests include machine learning, data mining, federated learning, and cybersecurity. He is a reviewer for several journals and conferences in his area of research. He also served as the Vice-Chair of the IEEE SMC Society, Windsor Section, from 2019 to 2022.
<br class="ltx_break"></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id2" class="ltx_float biography">
<table id="id2.1" class="ltx_tabular">
<tr id="id2.1.1" class="ltx_tr">
<td id="id2.1.1.1" class="ltx_td"><img src="/html/2401.17319/assets/Roozbeh_Razavi-Far.jpg" id="id2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id2.1.1.2" class="ltx_td">
<span id="id2.1.1.2.1" class="ltx_inline-block">
<span id="id2.1.1.2.1.1" class="ltx_p"><span id="id2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Roozbeh Razavi-Far</span> 
(Senior Member, IEEE) is an Assistant Professor at the Faculty of Computer Science and Canadian Institute for Cybersecurity, at the University of New Brunswick. His research focuses on machine learning, big data analytics, computational intelligence, and cybersecurity of cyber-physical systems. He has authored or co-authored more than 150 papers in scholarly journals and international conferences. Stanford lists his name among the top two percent most cited researchers for 2022. He is the recipient of several awards and grants including NSERC-DG, NSERC-ECR, NBIF, USRG and NSERC-PDF. He is an Associate Editor at several journals, including <span id="id2.1.1.2.1.1.2" class="ltx_text ltx_font_italic">Neurocomputing</span>, <span id="id2.1.1.2.1.1.3" class="ltx_text ltx_font_italic">Machine Learning with Applications</span>, <span id="id2.1.1.2.1.1.4" class="ltx_text ltx_font_italic">Discover Artificial Intelligence</span>, and <span id="id2.1.1.2.1.1.5" class="ltx_text ltx_font_smallcaps">IEEE Transactions on Industrial Cyber-Physical Systems</span>. He served as a Guest Editor and Chair for several journals and peer-reviewed conferences, and the Chapter Chair of IEEE Computational Intelligence, and Systems, Man and Cybernetics Societies at Windsor Section.
<br class="ltx_break"></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id3" class="ltx_float biography">
<table id="id3.1" class="ltx_tabular">
<tr id="id3.1.1" class="ltx_tr">
<td id="id3.1.1.1" class="ltx_td"><img src="/html/2401.17319/assets/Mehrdad_Saif.jpg" id="id3.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id3.1.1.2" class="ltx_td">
<span id="id3.1.1.2.1" class="ltx_inline-block">
<span id="id3.1.1.2.1.1" class="ltx_p"><span id="id3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Mehrdad Saif</span> (Fellow, IEEE) is a distinguished figure in the field of systems and control, with a career spanning nearly four decades. He received the B.S., M.S., and D.Eng. degrees in electrical engineering from Cleveland State University, OH, USA, in 1982, 1984, and 1987, respectively. Throughout his graduate studies, he was involved in research sponsored by NASA Lewis (now Glenn) Research Center and the Cleveland Advanced Manufacturing Program (CAMP). In 1987, Dr. Saif joined Simon Fraser University‚Äôs School of Engineering Science as an Assistant Professor. He rose through the ranks, becoming a Full Professor in 1997. From 2002 to 2011, he took on the role of Director of the School, spearheading its significant expansion during his tenure. Subsequently, he served as the Dean of the Faculty of Engineering at the University of Windsor from July 2011 until September 2021. There, he initiated major developments, including substantial enrollment growth and the addition of new programs in aerospace engineering, engineering management, B.Eng. technology, mechatronics, among others. Under his leadership, the Faculty of Engineering at University of Windsor also saw an increase in both faculty/staff numbers and research output. Dr. Saif‚Äôs research contributions are both vast and impactful, specializing in systems and control, estimation, observer theory, and AI/ML-based approaches to fault diagnostics and condition monitoring. His work has applications in a range of sectors, including automotive, power, and autonomous systems. To date, he has published over 400 refereed journal and conference papers and edited a book in these subject areas. He has garnered over 10,000 citations and holds a Google h-index of 50. Moreover, Dr. Saif is listed in Stanford University‚Äôs database of the top 100,000 career scientists from 1965 to the present. In his own area of expertise, the same database ranks him in the top 0.7%. Research.com also places him at 2681 worldwide and 139Th nationally among all electrical and electronics engineers. Dr. Saif expertise has been sought after by notable organizations such as GM, NASA, B.C. Hydro, and Canadian Space Agency (CSA). He has also significantly contributed to the IEEE Control Systems Society as the Chair of its Vancouver Section and serves on the Editorial Board of several esteemed IEEE journals such as the <span id="id3.1.1.2.1.1.2" class="ltx_text ltx_font_smallcaps">IEEE Access</span>, <span id="id3.1.1.2.1.1.3" class="ltx_text ltx_font_smallcaps">IEEE SMC Magazine</span>, <span id="id3.1.1.2.1.1.4" class="ltx_text ltx_font_smallcaps">IEEE Industrial Informatics</span>, <span id="id3.1.1.2.1.1.5" class="ltx_text ltx_font_smallcaps">IEEE Transactions on Industrial and Cyber-physical Systems</span>, among others. Dr. Saif is a Registered Professional Engineer in Ontario, Canada, and has been honored with Fellowships in several prestigious organizations, including IEEE, the Canadian Academy of Engineering (CAE), the Engineering Institute of Canada (EIC), the Institution of Engineering and Technology (IET), and Asia-Pacific Artificial Intelligence Association (AAIA). His IEEE fellowship is particularly noteworthy, earned <span id="id3.1.1.2.1.1.6" class="ltx_text ltx_font_italic">‚Äúfor contributions to monitoring, diagnosis and prognosis in cyber-physical health systems‚Äù</span>.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id4" class="ltx_float biography">
<table id="id4.1" class="ltx_tabular">
<tr id="id4.1.1" class="ltx_tr">
<td id="id4.1.1.1" class="ltx_td"><img src="/html/2401.17319/assets/Boyu_Wang.jpg" id="id4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id4.1.1.2" class="ltx_td">
<span id="id4.1.1.2.1" class="ltx_inline-block">
<span id="id4.1.1.2.1.1" class="ltx_p"><span id="id4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Boyu Wang</span>  (Member, IEEE)
received his B.Eng. degree in Electronic Information Engineering from Tianjin University, Tianjin, China, M.Sc. degree in Electrical and Computer Engineering from University of Macau, Macau, China, and Ph.D. in Computer Science from McGill University, Montreal, QC, Canada. He is currently an Assistant Professor with the Department of Computer Science, University of Western Ontario, London, ON, Canada. He is also affiliated with the Brain and Mind Institute and the Vector Institute. He was a Post-Doctoral Research Fellow at the University of Pennsylvania and Princeton University. His research interests include machine learning theory, algorithms, and applications.
<br class="ltx_break"></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id5" class="ltx_float biography">
<table id="id5.1" class="ltx_tabular">
<tr id="id5.1.1" class="ltx_tr">
<td id="id5.1.1.1" class="ltx_td"><img src="/html/2401.17319/assets/Qiang_Yang.jpg" id="id5.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id5.1.1.2" class="ltx_td">
<span id="id5.1.1.2.1" class="ltx_inline-block">
<span id="id5.1.1.2.1.1" class="ltx_p"><span id="id5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Qiang Yang</span> 
(Fellow, IEEE) received the B.Sc. degree in astrophysics from Peking University, Beijing, China, in 1982, and the M.Sc. degree in astrophysics and the Ph.D. degree in computer science from the University of Maryland, College Park, MD, USA, in 1985 and 1989, respectively. He was a Faculty Member with the University of Waterloo, Waterloo, ON, Canada, from 1989 to 1995, and Simon Fraser University, Burnaby, BC, Canada, from 1995 to 2001. He was the Founding Director of Huawei‚Äôs Noah‚Äôs Ark Lab, Hong Kong, from 2012 to 2014 and a Co-Founder of 4Paradigm Corporation, Beijing, an artificial intelligence (AI) platform company. He is currently the Head of the AI Department and the Chief AI Officer of WeBank, Shenzhen, China. Dr. Yang has been a Professor Emeritus with the Computer Science and Engineering Department, Hong Kong University of Science and Technology (HKUST), Hong Kong, since 2023, where he was previously a Chair Professor, and a former Head of the CSE Department and the Founding Director of the Big Data Institute from 2015 to 2018. He is the author of several books, including <span id="id5.1.1.2.1.1.2" class="ltx_text ltx_font_italic">Intelligent Planning</span> (Springer), <span id="id5.1.1.2.1.1.3" class="ltx_text ltx_font_italic">Crafting Your Research Future</span> (Morgan &amp; Claypool), and <span id="id5.1.1.2.1.1.4" class="ltx_text ltx_font_italic">Constraint-Based Design Recovery for Software Engineering</span> (Springer). His research interests include AI, machine learning, and data mining, especially in transfer learning, automated planning, federated learning, and case-based reasoning. Dr. Yang has served as an Executive Council Member of the Advancement of AI (AAAI) from 2016 to 2020. He is a fellow of several international societies, including ACM, AAAI, IEEE, IAPR, and AAAS. He was a recipient of several awards, including the 2004/2005 ACM KDDCUP Championship, the ACM SIGKDD Distinguished Service Award in 2017, and the AAAI Innovative AI Applications Awards in 2018 and 2020. He was the Founding Editorin-Chief of the <span id="id5.1.1.2.1.1.5" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</span> and <span id="id5.1.1.2.1.1.6" class="ltx_text ltx_font_smallcaps">IEEE Transactions on Big Data</span>. He has served as the President of the International Joint Conference on AI (IJCAI) from 2017 to 2019.
<br class="ltx_break"></span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.17318" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.17319" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.17319">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.17319" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.17321" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 06:29:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
