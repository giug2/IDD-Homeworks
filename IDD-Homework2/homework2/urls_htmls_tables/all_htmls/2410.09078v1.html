<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs</title>
<!--Generated on Fri Oct  4 18:21:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.09078v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S1" title="In Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S2" title="In Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Requirements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3" title="In Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Functional Architecture and Workflow</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3.SS1" title="In 3 Functional Architecture and Workflow ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3.SS2" title="In 3 Functional Architecture and Workflow ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Workflow</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S4" title="In Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion and Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tomas Bueno Momcilovic
</span><span class="ltx_author_notes">Corresponding Author. Email: momcilovic@fortiss.org 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id1.1.id1">Accepted Manuscript.</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dian Balta
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Beat Buesser
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giulio Zizzo
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mark Purcell
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">fortiss Research Institute of the Free State of Bavaria, Munich, Germany
</span>
<span class="ltx_contact ltx_role_address">IBM Research Europe, Zurich, Switzerland
</span>
<span class="ltx_contact ltx_role_address">IBM Research Europe, Dublin, Ireland
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">The EU AI Act (EUAIA) introduces requirements for AI systems which intersect with the processes required to establish adversarial robustness. However, given the ambiguous language of regulation and the dynamicity of adversarial attacks, developers of systems with highly complex models such as LLMs may find their effort to be duplicated without the assurance of having achieved either compliance or robustness. This paper presents a functional architecture that focuses on bridging the two properties, by introducing components with clear reference to their source. Taking the detection layer recommended by the literature, and the reporting layer required by the law, we aim to support developers and auditors with a reasoning layer based on knowledge augmentation (rules, assurance cases, contextual mappings). Our findings demonstrate a novel direction for ensuring LLMs deployed in the EU are both compliant and adversarially robust, which underpin trustworthiness.</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\paperid</span>
<p class="ltx_p" id="p1.2">1</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The European Union (EU) bases trustworthiness of artificial intelligence systems (AIS) on three properties: lawful, ethical, and robust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib7" title="">7</a>]</cite>. The EU AI Act (EUAIA, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite>) is an upcoming regulation that sets obligations on the lawful design and implementation of AIS in the EU. Its content outlines the high-level requirements for improving the auditability of the AIS, whose generic descriptions are interepretable across contexts.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, for properties such as adversarial robustness, providers of AIS with large language model-based (LLM) components are facing a difficult and highly dynamic challenge whose boundaries are not yet known. Providers in the EU who would like to ensure both compliance and robustness, are doubly burdened. First there is the need to constantly readapt their defenses against novel adversarial attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib5" title="">5</a>]</cite>, and second is the overhead for correctly interpreting "compliant robustness" with auditable evidence.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This paper presents a novel approach of knowledge augmentation for aligning adversarial robustness of LLMs with EUAIA compliance. By integrating detection, reasoning and reporting layers alongside the layer for interacting with users, we propose a comprehensive functional architecture as a reference for ensuring the AIS is dynamically protected and auditable. The research provides a framework for combining robustness and compliance activities while retaining the provenance to the requirements.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Our roadmap centers on solution-oriented requirements engineering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib12" title="">12</a>]</cite> and knowledge augmentation (i.e., knowledge representation and reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib9" title="">9</a>]</cite>) to develop the architecture of our prototype. This process of creating a blueprint of a compliant LLM defense against adversarial attacks involves three steps.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">First, we extract the legal duties and relevant stakeholders from the EUAIA (<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib14" title="">14</a>]</cite>; cf. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib2" title="">2</a>]</cite> for the expanded list), and structure them into draft requirements in the next section. This approach takes inspiration from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib4" title="">4</a>]</cite>. Second, concepts and relations surrounding LLMs are represented in a simple ontology <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib10" title="">10</a>]</cite>. State-of-the-art attacks and defenses in the context of natural language tasks are recovered from preprints <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib5" title="">5</a>]</cite>. The third step is a representation of the knowledge in a cyclical process model of actions between stakeholders and components, and the corresponding sources.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Requirements</h2>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Requirements related to adversarial robustness and their sources</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt" id="S2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1">id</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.2.1.1.1">Requirement</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.3.1.1" style="width:95.4pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.3.1.1.1">Source</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S2.T1.1.2.1.1">R0</th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.2.1">
<span class="ltx_p" id="S2.T1.1.2.1.2.1.1">Include the following stakeholders: user; (malicious) third party; GPAI provider; AIS provider; 
<br class="ltx_break"/>GPAI or AIS deployer; national competent authority; market surveillance authority; AI office.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S2.T1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.2.1.3.1">
<span class="ltx_p" id="S2.T1.1.2.1.3.1.1" style="width:95.4pt;">Art. 3 &amp; Rec. 76 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite>; cf. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib2" title="">2</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.3.2.1">R1</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.2.2.1">
<span class="ltx_p" id="S2.T1.1.3.2.2.1.1">Include the following roles: user; developer (i.e., system or LLM engineer, researcher, scientist); auditor.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.3.2.3.1">
<span class="ltx_p" id="S2.T1.1.3.2.3.1.1" style="width:95.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib13" title="">13</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.4.3.1">R2</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.3.2.1">
<span class="ltx_p" id="S2.T1.1.4.3.2.1.1">Identify, evaluate and mitigate <span class="ltx_text ltx_font_italic" id="S2.T1.1.4.3.2.1.1.1">reasonably foreseeable</span> risks of the system.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.4.3.3.1">
<span class="ltx_p" id="S2.T1.1.4.3.3.1.1" style="width:95.4pt;">Art. 9 Para. 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.5.4.1">R3</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.4.2.1">
<span class="ltx_p" id="S2.T1.1.5.4.2.1.1">Ensure appropriate and adequate risk management measures.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.5.4.3.1">
<span class="ltx_p" id="S2.T1.1.5.4.3.1.1" style="width:95.4pt;">Art. 9 Para. 5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.6.5.1">R4</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.5.2.1">
<span class="ltx_p" id="S2.T1.1.6.5.2.1.1">Detect automated attacks such as prompts with randomized perturbations.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.6.5.3.1">
<span class="ltx_p" id="S2.T1.1.6.5.3.1.1" style="width:95.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib16" title="">16</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.7.6.1">R5</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.6.2.1">
<span class="ltx_p" id="S2.T1.1.7.6.2.1.1">Detect semi-automated attacks such as heuristic-based exploitation of the undertrained aspects of the model.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.7.6.3.1">
<span class="ltx_p" id="S2.T1.1.7.6.3.1.1" style="width:95.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib5" title="">5</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.8.7">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.8.7.1">R6</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.7.2.1">
<span class="ltx_p" id="S2.T1.1.8.7.2.1.1">Establish cybersecurity measures against adversarial and poisoning attacks.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.8.7.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.8.7.3.1">
<span class="ltx_p" id="S2.T1.1.8.7.3.1.1" style="width:95.4pt;">Art. 15 Para. 5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.9.8">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.9.8.1">R7</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.8.2.1">
<span class="ltx_p" id="S2.T1.1.9.8.2.1.1">Achieve sustained coverage of detected and prevented attacks above a predefined threshold.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.9.8.3.1">
<span class="ltx_p" id="S2.T1.1.9.8.3.1.1" style="width:95.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib1" title="">1</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.10.9">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.10.9.1">R8</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.9.2.1">
<span class="ltx_p" id="S2.T1.1.10.9.2.1.1">Establish an appropriate level of robustness and cybersecurity.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.10.9.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.10.9.3.1">
<span class="ltx_p" id="S2.T1.1.10.9.3.1.1" style="width:95.4pt;">Art. 15 Para. 1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.11.10">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.11.10.1">R9</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.11.10.2.1">
<span class="ltx_p" id="S2.T1.1.11.10.2.1.1">Provide information about robustness and cybersecurity (e.g., metrics) and their limitations in 
<br class="ltx_break"/>instructions for use.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.11.10.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.11.10.3.1">
<span class="ltx_p" id="S2.T1.1.11.10.3.1.1" style="width:95.4pt;">Art. 13 Para. 3 &amp; Annex IV <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.12.11">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.12.11.1">R10</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.12.11.2.1">
<span class="ltx_p" id="S2.T1.1.12.11.2.1.1">Design system for effective human oversight regarding safety monitoring and prevention/minimization of reasonably foreseeable misuse.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.12.11.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.12.11.3.1">
<span class="ltx_p" id="S2.T1.1.12.11.3.1.1" style="width:95.4pt;">Art. 14 Para. 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.13.12">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.13.12.1">R11</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.13.12.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.13.12.2.1">
<span class="ltx_p" id="S2.T1.1.13.12.2.1.1">Design appropriate functionalities for human overseers to monitor for "anomalies, dysfunctions and 
<br class="ltx_break"/>unexpected performance."</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.13.12.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.13.12.3.1">
<span class="ltx_p" id="S2.T1.1.13.12.3.1.1" style="width:95.4pt;">Art. 14 Para. 4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.14.13">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.14.13.1">R12</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.14.13.2.1">
<span class="ltx_p" id="S2.T1.1.14.13.2.1.1">Report on measures and tests used for adversarial testing, model alignment, and fine-tuning.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.14.13.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.14.13.3.1">
<span class="ltx_p" id="S2.T1.1.14.13.3.1.1" style="width:95.4pt;">Art. 53 Para. 1 &amp; Annex XI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite>; Art. 11 &amp; Annex IV <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.15.14">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.15.14.1">R13</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.15.14.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.15.14.2.1">
<span class="ltx_p" id="S2.T1.1.15.14.2.1.1">Supply information on testing, safeguards and risk mitigation measures at the request of the AI Office.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.15.14.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.15.14.3.1">
<span class="ltx_p" id="S2.T1.1.15.14.3.1.1" style="width:95.4pt;">Art. 92 Para. 5 &amp; 7 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.16.15">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.16.15.1">R14</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.16.15.2.1">
<span class="ltx_p" id="S2.T1.1.16.15.2.1.1">Establish and report on the definite, reasonably likely or suspected causal link between the system and 
<br class="ltx_break"/>a serious incident.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.16.15.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.16.15.3.1">
<span class="ltx_p" id="S2.T1.1.16.15.3.1.1" style="width:95.4pt;">Art. 73 Para. 2-6 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.17.16">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S2.T1.1.17.16.1">R15</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S2.T1.1.17.16.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.17.16.2.1">
<span class="ltx_p" id="S2.T1.1.17.16.2.1.1">Detect manual attacks based on patterns of persuasion (i.e., "jailbreaking").</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S2.T1.1.17.16.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.17.16.3.1">
<span class="ltx_p" id="S2.T1.1.17.16.3.1.1" style="width:95.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib15" title="">15</a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.18.17">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r" id="S2.T1.1.18.17.1">R16</th>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r" id="S2.T1.1.18.17.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.18.17.2.1">
<span class="ltx_p" id="S2.T1.1.18.17.2.1.1">Notify supervising stakeholder of a serious incident.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r" id="S2.T1.1.18.17.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.18.17.3.1">
<span class="ltx_p" id="S2.T1.1.18.17.3.1.1" style="width:95.4pt;">Art. 73 Para. 1, 7-8 &amp; 11 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The EUAIA places AI systems that are deployed in particular products or domains under categories of risk, where high-risk AI systems play a central role <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite>. The regulation which has been adopted in 2024 places duties on stakeholders at design and runtime. Before standards are expected in the following years, these duties provide a basis for safety- and security-oriented requirements.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">General-purpose AI models (GPAI, Art. 3, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib3" title="">3</a>]</cite>) such as LLMs are not inherently high-risk. However, their broad capabilities and wide attack surface have over time crystallized similar requirements with respect to adversarial robustness. In examples provided by an ever-increasing body of work (cf. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib16" title="">16</a>]</cite>), adversaries of an LLM can include third parties with malicious intentions, curious users who test the boundaries, and even completely benign users whose prompts elicit harmful or otherwise unintended output.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Based on an analysis of requirements in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S2.T1" title="Table 1 ‣ 2 Requirements ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>, EUAIA compliance and adversarial robustness are complementary properties, despite the difference in details. On the one hand, the requirements that are derived from the regulation (cf. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib2" title="">2</a>]</cite> for expanded list) provide a generic description of stakeholders (R0), risk management (R3) and cybersecurity measures, and the need for human oversight (R10) and reporting (R12). On the other hand, the state-of-the-art literature introduces specific roles (R1), the detection of automated (R4), semi-automated (R5), and manual attacks (R15), and sustained coverage of these threats (R7). However, aside from the direct references to the term in EUAIA (R6, R12), the two sources emphasize different facets of a larger system - i.e., components for assuring the quality of adversarial robustness beyond the purely functional components of an LLM-supported application. In the next section, we introduce one approach to satisfying both facets.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Functional Architecture and Workflow</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architecture</h3>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="S3.F1.g1" src="extracted/5902640/llm_dfd_layered.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Reference functional architecture for compliant adversarial robustness of LLM-based AI systems.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The functional architecture depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3.F1" title="Figure 1 ‣ 3.1 Architecture ‣ 3 Functional Architecture and Workflow ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_tag">1</span></a> is composed of a cyclical workflow linking four stakeholders and four layers of components. Stakeholders and components are connected with arrows denoting action IDs (A#), as described in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3.T2" title="Table 2 ‣ 3.2 Workflow ‣ 3 Functional Architecture and Workflow ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>, whereby each non-functional element of the architecture has a corresponding requirement ID (R#) identified in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S2.T1" title="Table 1 ‣ 2 Requirements ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The stakeholders include users, LLM developers, AIS developers and auditors, who represent the various roles involved in the design and implementation of AIS, with the corresponding EUAIA-defined role in parentheses. Auditors and users are external temporary roles, whereby a user can be benign, curious or malicious. Developers are internal and lasting roles, whose responsibilities depend on the access to the internal workings of an LLM and the system deploying it.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The layers involve the interaction layer which fulfils the functional requirements of an AIS, and detection, reasoning and reporting layers which fulfill the quality requirements underlying robustness. In other words, the first layer is enough to establish a fully working AIS, without special consideration for other properties. Interaction has a simple structure inspired by practice <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib11" title="">11</a>]</cite>, containing the user-facing application (i.e., the interface between the user and the AIS) and the LLM.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Workflow</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Actions and their descriptions.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">id</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.1.2.1">
<span class="ltx_p" id="S3.T2.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1.1.1">Action</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.2.1.1">A0</th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S3.T2.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.1.2.1">
<span class="ltx_p" id="S3.T2.1.2.1.2.1.1">Displays relevant information about the LLM, disclaimers, and limitations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.3.2.1">A1</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.3.2.2.1">
<span class="ltx_p" id="S3.T2.1.3.2.2.1.1">Enters a prompt.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.4.3.1">A2</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.4.3.2.1">
<span class="ltx_p" id="S3.T2.1.4.3.2.1.1">Forwards the prompt and the metadata.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.5.4.1">A3</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.5.4.2.1">
<span class="ltx_p" id="S3.T2.1.5.4.2.1.1">Provides the first batch of classification using the deployed detectors.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.6.5.1">A4</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.6.5.2.1">
<span class="ltx_p" id="S3.T2.1.6.5.2.1.1">Provides the evaluation with the prompt (if benign) or warning (if malicious).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.7.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.7.6.1">A5</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.7.6.2.1">
<span class="ltx_p" id="S3.T2.1.7.6.2.1.1">Provides the generated result according to the evaluation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.8.7">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.8.7.1">A6</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.8.7.2.1">
<span class="ltx_p" id="S3.T2.1.8.7.2.1.1">Displays the generated result.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.9.8">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.9.8.1">A7</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.9.8.2.1">
<span class="ltx_p" id="S3.T2.1.9.8.2.1.1">Provides data on the metrics and thresholds used for detectors.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.10.9">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.10.9.1">A8</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.10.9.2.1">
<span class="ltx_p" id="S3.T2.1.10.9.2.1.1">Displays the metrics and relevant data.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.11.10">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.11.10.1">A9</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.11.10.2.1">
<span class="ltx_p" id="S3.T2.1.11.10.2.1.1">Provides the second batch of classification using all relevant detectors and their combinations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.12.11">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.12.11.1">A10</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.12.11.2.1">
<span class="ltx_p" id="S3.T2.1.12.11.2.1.1">Provides a counterfactual assessment comparing the coverage and accuracy of deployed and non-deployed detector combinations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.13.12">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.13.12.1">A11</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.13.12.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.13.12.2.1">
<span class="ltx_p" id="S3.T2.1.13.12.2.1.1">Displays the counterfactual assessment.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.14.13">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.14.13.1">A12</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.14.13.2.1">
<span class="ltx_p" id="S3.T2.1.14.13.2.1.1">Reconfigures the detector combinations and their threshold values.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.15.14">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.15.14.1">A13</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.15.14.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.15.14.2.1">
<span class="ltx_p" id="S3.T2.1.15.14.2.1.1">Provides flagged LLM output (i.e., anomaly or incident) and the corresponding input prompt.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.16.15">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.16.15.1">A14</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.16.15.2.1">
<span class="ltx_p" id="S3.T2.1.16.15.2.1.1">Provides the data on the detected anomalies.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.17.16">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.17.16.1">A15</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.17.16.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.17.16.2.1">
<span class="ltx_p" id="S3.T2.1.17.16.2.1.1">Displays information about the individual or group of anomalies.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.18.17">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.18.17.1">A16</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.18.17.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.18.17.2.1">
<span class="ltx_p" id="S3.T2.1.18.17.2.1.1">Makes adjustments to the LLM based on the provided data.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.19.18">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S3.T2.1.19.18.1">A17</th>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S3.T2.1.19.18.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.19.18.2.1">
<span class="ltx_p" id="S3.T2.1.19.18.2.1.1">Provides data about the anomalies flagged as incidents.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.20.19">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r" id="S3.T2.1.20.19.1">A18</th>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r" id="S3.T2.1.20.19.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.20.19.2.1">
<span class="ltx_p" id="S3.T2.1.20.19.2.1.1">Displays information about the (serious) incidents.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Detection is based on input and output classification, following the current paradigm of dealing with adversarial attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib1" title="">1</a>]</cite>. Input detectors have thresholds based on some combination of single and n-pairs of metrics. Metrics denote ways of measuring particular properties of input prompts, examples including perplexity (pp; i.e., the extent to which the model is "surprised" by a prompt), context length (cl) and character set size (cs). Output detectors attempt to detect unexpected LLM results which may be results of undetected attacks. They can be implemented similar as for inputs, but also using flags for harmful keywords to provide an early warning to the developer.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Reasoning serves as the middleware between other layers by decoupling the logic from detection, interaction and reporting activities. The layer provides a set of rules derived using deductive or inductive reasoning, which are behind decisions to classify an input as an attack, an output as an incident, or detector performance as a trigger for change. The library with assurance cases is a set of graphs connecting claims about satisfied requirements relating to compliance and robustness, with the evidence from chosen strategies. Given the adaptability of LLMs and the context-specific properties, context-aware mappings provide the needed metadata to separate the rules and assurance case elements to what they are appropriate. In addition, these mappings enable the variables in reports to be linked with actual values.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Finally, the reporting layer is primarily based on the EUAIA need for human oversight. Instructions for use and technical documentation are factsheets for users and auditors respectively. However, given the relevance of figures and test results to the monitoring of adversarial robustness, these components are useful to developers for AIS debugging and improvement as well. In addition, assessments based on counterfactuals and anomaly data allow the developers to monitor detectors with respect to needed changes. Incident reports are triggered by an event of a potentially successful attack; although primarily an EUAIA requirement for mandatory auditing of serious incidents, less critical but problematic anomalies provide an opportunity to developers to perform forensic analyses.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">The Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#S3.F2" title="Figure 2 ‣ 3.2 Workflow ‣ 3 Functional Architecture and Workflow ‣ Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs"><span class="ltx_text ltx_ref_tag">2</span></a> depicts three main cyclic processes. The primary cycle is the simplest: a user enters a prompt into the application (A1), which is then forwarded to the input detectors (A2). The detectors’ results are provided as input (A3) to a rule that classifies the prompt as safe or unsafe, passing on the prompt or the warning respectively to the LLM (A4). The LLM then generates instead elicits a warning to the user (A4, A5, A6). Relying only on this cycle would be a naive approach to handling adversarial attacks, whereby the developer would expect the detectors to perform well over time and prompts.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="420" id="S3.F2.g1" src="extracted/5902640/llm_dfd_l1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Primary cycle with interaction and basic attack detection.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">The secondary cycle introduces the required auditability for EUAIA compliance. The information about the deployed detectors is structured in assurance cases, which feed into the documentation (A7). This documentation provides an interface to the user to understand the model and its limitations before use (A0), and an interface to the auditor (A8) to establish a clear picture about the AIS.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1">This cycle also provides the basis for required dynamicity for adversarial robustness. Assurance cases are intended to provide the logic needed to evaluate detector performance. Given a number of prompts or some other triggering rule (A9), prompts would be processed through non-deployed detector combinations. This would provide the basis for counterfactually assessing the sustained robustness of the detectors (A10). This evaluation is initially be the responsibility of the AIS developer (A11), whose understanding of the context-sensitive performance and coverage would be needed to reconfigure the detectors (A12).</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="436" id="S3.F3.g1" src="extracted/5902640/llm_dfd_l2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Secondary cycle with assurance, monitoring and reporting.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">The tertiary cycle introduces mechanisms for handling failure systematically. An evaluation of the LLM output (A5), whether in real-time or delayed intervals, allows some successful attacks (i.e., incidents; A13) to be automatically detected. Here is context-specific information necessary to operationalize ambiguous EUAIA language: which risks or anomalies are "reasonably foreseeable" (A14) and worth exploring; which incidents are "serious" enough (A17) to demand contact with the auditor (A18); and when is a given risk management procedure not "suitable" anymore (A12). This cycle also proposes providing relevant information to the LLM developer, who may not be associated with the AIS directly, but nonetheless benefits from adversarially retraining the LLM, thereby making it more secure in the AIS as well.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="423" id="S3.F4.g1" src="extracted/5902640/llm_dfd_l3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Tertiary cycle for advanced handling of failures.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This paper introduces a knowledge-augmented framework designed to align the adversarial robustness of large language models with the EU AI Act compliance. By using a combination of detection, reasoning and reporting layers, we address the critical need for compliance and robustness in AI systems.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The functional architecture is meant as a reference for implementing physical components. For example, our early prototype implements simple detectors in Python, including n-pair detectors based on logistic regression classifiers pretrained on Hugging Face jailbreak data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09078v1#bib.bib8" title="">8</a>]</cite>. The reasoner is based on a combination of an assurance case and an ontology, stored in the graph database, where evaluations are performed through queries. Additionally, graphical visualizations and textual data is generated in Jupyter Notebooks to provide clear and informative reporting. The interaction layer uses the streamlit package to provide a user-facing application, while GPT-2, accessed via the Hugging Face package, serves as the foundational LLM.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Our findings highlight a promising direction for developing resilient AI technologies capable of withstanding adversarial attacks while meeting regulatory standards. Future work will focus on the following aspects: (1) defining new detectors and combinations thereof, such as classifiers trained on larger samples of malicious and benign prompts; (2) expanding the reasoning based on the wider context, including computer language tasks (e.g., code translation); (3) evaluating the components of the architecture with respect to helping developers assure robustness and auditors determine compliance of the LLM-based systems.</p>
</div>
<div class="ltx_para" id="S4.p4">
<span class="ltx_ERROR undefined" id="S4.p4.1">{ack}</span>
<p class="ltx_p" id="S4.p4.2">This work was partially supported by financial and other means by the following research projects: DUCA (EU grant agreement 101086308), FLA (supported by the Bavarian Ministry of Economic Affairs, Regional Development and Energy), the DiProLeA (German Federal Ministry of Education and Research, grant 02J19B120 ff), as well as our industrial partners in the FinComp project. We thank the reviewers for their valuable comments.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alon and Kamfonas [2023]</span>
<span class="ltx_bibblock">
G. Alon and M. Kamfonas.

</span>
<span class="ltx_bibblock">Detecting language model attacks with perplexity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2308.14132</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bueno Momcilovic et al. [2024]</span>
<span class="ltx_bibblock">
T. Bueno Momcilovic, B. Buesser, G. Zizzo, M. Purcell, and D. Balta.

</span>
<span class="ltx_bibblock">Towards assuring eu ai act compliance and adversarial robustness of llms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">AI Act Workshop, 19. Internationale Tagung Wirtschaftsinformatik, 16. – 19. September (upcoming publication).</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">European Parliament and Council of the European Union [2024]</span>
<span class="ltx_bibblock">
European Parliament and Council of the European Union.

</span>
<span class="ltx_bibblock">Corrigendum to the position of the European Parliament adopted at first reading on 13 March 2024 with a view to the adoption of Regulation (EU) 2024/……) of the European Parliament and of the Council laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act), 2024.

</span>
<span class="ltx_bibblock">URL <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138-FNL-COR01_EN.pdf</span>.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-15.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Floridi et al. [2022]</span>
<span class="ltx_bibblock">
L. Floridi, M. Holweg, M. Taddeo, J. Amaya, J. Mökander, and Y. Wen.

</span>
<span class="ltx_bibblock">capai - a procedure for conducting conformity assessment of ai systems in line with the eu artificial intelligence act.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">SSRN</em>, March 23 2022.

</span>
<span class="ltx_bibblock">Available at SSRN: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://ssrn.com/abstract=4064091</span> or <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://dx.doi.org/10.2139/ssrn.4064091</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping et al. [2024]</span>
<span class="ltx_bibblock">
J. Geiping, A. Stein, M. Shu, K. Saifullah, Y. Wen, and T. Goldstein.

</span>
<span class="ltx_bibblock">Coercing llms to do and reveal (almost) anything.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2402.14020</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hohfeld et al. [2001]</span>
<span class="ltx_bibblock">
W. N. Hohfeld, D. Campbell, and P. A. Thomas.

</span>
<span class="ltx_bibblock">Some fundamental legal conceptions as applied in judicial reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Yale Law Journal</em>, 2001.

</span>
<span class="ltx_bibblock">URL <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://lawcat.berkeley.edu/record/1178561</span>.

</span>
<span class="ltx_bibblock">First published 2001 by Ashgate Publishing.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">INTELLIGENCE [2019]</span>
<span class="ltx_bibblock">
H.-L. E. G. O. A. INTELLIGENCE.

</span>
<span class="ltx_bibblock">Ethics guidelines for trustworthy AI.

</span>
<span class="ltx_bibblock">European Commission, 2019.

</span>
<span class="ltx_bibblock">URL <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60419</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaramillo [2023]</span>
<span class="ltx_bibblock">
R. D. Jaramillo.

</span>
<span class="ltx_bibblock">Chatgpt jailbreak prompts, 2023.

</span>
<span class="ltx_bibblock">URL <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/datasets/rubend18/ChatGPT-Jailbreak-Prompts</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Keet [2023]</span>
<span class="ltx_bibblock">
C. M. Keet.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">The What and How of Modelling Information and Knowledge: From Mind Maps to Ontologies</em>.

</span>
<span class="ltx_bibblock">Springer, Berlin, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ontotext [2023]</span>
<span class="ltx_bibblock">
Ontotext.

</span>
<span class="ltx_bibblock">What is GraphDB?

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://graphdb.ontotext.com/documentation/10.6/</span>, 2023.

</span>
<span class="ltx_bibblock">Accessed: 2024/03/14.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2022]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing ChatGPT.

</span>
<span class="ltx_bibblock"><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://openai.com/index/chatgpt</span>, 2022.

</span>
<span class="ltx_bibblock">Accessed: 2024/02/25.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pohl [2010]</span>
<span class="ltx_bibblock">
K. Pohl.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Requirements Engineering: Fundamentals, Principles, and Techniques</em>.

</span>
<span class="ltx_bibblock">Springer, Berlin, Heidelberg, 2010.

</span>
<span class="ltx_bibblock">ISBN 9783642125775.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suresh et al. [2021]</span>
<span class="ltx_bibblock">
H. Suresh, S. R. Gomez, K. K. Nam, and A. Satyanarayan.

</span>
<span class="ltx_bibblock">Beyond expertise and roles: A framework to characterize the stakeholders of interpretable machine learning and their needs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 2021. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van Engers and van Doesburg [2015]</span>
<span class="ltx_bibblock">
T. van Engers and R. van Doesburg.

</span>
<span class="ltx_bibblock">First steps towards a formal analysis of law.

</span>
<span class="ltx_bibblock">In D. Malzahn and G. Granja, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">eKNOW 2015: The Seventh International Conference on Information, Process, and Knowledge Management: February 22-27, 2015, Lisbon, Portugal</em>, pages 36–42, Wilmington, DE, 2015. IARIA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. [2024]</span>
<span class="ltx_bibblock">
Y. Zeng, H. Lin, J. Zhang, D. Yang, R. Jia, and W. Shi.

</span>
<span class="ltx_bibblock">How johnny can persuade LLMs to jailbreak them: Rethinking persuasion to challenge AI safety by humanizing LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">CoRR</em>, abs/2401.06373, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et al. [2023]</span>
<span class="ltx_bibblock">
A. Zou, Z. Wang, J. Z. Kolter, and M. Fredrikson.

</span>
<span class="ltx_bibblock">Universal and transferable adversarial attacks on aligned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">CoRR</em>, abs/2307.15043, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct  4 18:21:54 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
