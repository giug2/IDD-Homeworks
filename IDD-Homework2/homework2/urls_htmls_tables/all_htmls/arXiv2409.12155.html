<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT</title>
<!--Generated on Wed Sep 18 17:15:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Semantic Segmentation PET/CT nnU-Net Autopet III Award Category 1" lang="en" name="keywords"/>
<base href="/html/2409.12155v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S1" title="In Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2" title="In Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS1" title="In 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Pipeline overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS2" title="In 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>MIP-based tracer classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS3" title="In 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Anatomy-guided lesion segmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3" title="In Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experimental setup and evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS1" title="In 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS2" title="In 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evaluation protocol and metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS2.SSS0.Px1" title="In 3.2 Evaluation protocol and metrics ‚Ä£ 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title">Tracer classification.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS2.SSS0.Px2" title="In 3.2 Evaluation protocol and metrics ‚Ä£ 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title">Lesion segmentation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS3" title="In 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Preprocessing and implementation details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS3.SSS0.Px1" title="In 3.3 Preprocessing and implementation details ‚Ä£ 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title">Tracer classification.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS3.SSS0.Px2" title="In 3.3 Preprocessing and implementation details ‚Ä£ 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title">Lesion segmentation.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4" title="In Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS1" title="In 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Baseline models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS2" title="In 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Tracer classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS3" title="In 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Anatomy-guided lesion segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS4" title="In 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Postprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS5" title="In 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Final submissions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S5" title="In Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Institute for AI in Medicine (IKIM), University Hospital Essen (A√∂R), Essen, Germany </span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Department of Nuclear Medicine, University Hospital Essen (A√∂R), Essen, Germany
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Cancer Research Center Cologne Essen (CCCE), West German Cancer Center Essen University Hospital Essen (A√∂R), Essen, Germany
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>German Cancer Consortium (DKTK, Partner site Essen), Heidelberg, Germany
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>Department of Physics, TU Dortmund, Dortmund, Germany
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id5.1"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">email: </span>{firstname.lastname}@uk-essen.de</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamza Kalisch 
</span><span class="ltx_author_notes">1122</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabian H√∂rst
</span><span class="ltx_author_notes">113355</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ken Herrmann
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jens Kleesiek
</span><span class="ltx_author_notes">11334455</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Constantin Seibold
</span><span class="ltx_author_notes">1122</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Lesion segmentation in PET/CT imaging is essential for precise tumor characterization, which supports personalized treatment planning and enhances diagnostic precision in oncology. However, accurate manual segmentation of lesions is time-consuming and prone to inter-observer variability.
Given the rising demand and clinical use of PET/CT, automated segmentation methods, particularly deep-learning-based approaches, have become increasingly more relevant. The autoPET III Challenge focuses on advancing automated segmentation of tumor lesions in PET/CT images in a multitracer multicenter setting, addressing the clinical need for quantitative, robust, and generalizable solutions.
Building on previous challenges, the third iteration of the autoPET challenge introduces a more diverse dataset featuring two different tracers (FDG and PSMA) from two clinical centers.
To this extent, we developed a classifier that identifies the tracer of the given PET/CT based on the Maximum Intensity Projection of the PET scan. We trained two individual nnUNet-ensembles for each tracer where anatomical labels are included as a multi-label task to enhance the model‚Äôs performance. Our final submission achieves cross-validation Dice scores of 76.90% and 61.33% for the publicly available FDG and PSMA datasets, respectively. The code is available at <a class="ltx_ref ltx_href" href="https://github.com/hakal104/autoPETIII/" title="">https://github.com/hakal104/autoPETIII/</a></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Semantic Segmentation PET/CT nnU-Net Autopet III Award Category 1
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Positron Emission Tomography (PET) combined with Computed Tomography (CT) imaging is an essential tool in oncology, providing detailed information about tumors and helping to personalize treatment plans <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib15" title="">15</a>]</cite>. While the CT scan offers detailed anatomical information, PET imaging complements it by highlighting the metabolic activity of different cancers through the use of different tracers such as 18F-Fluorodeoxyglucose (FDG) and Prostate-Specific Membrane Antigen (PSMA). FDG is valued for its ability to detect metabolic activity in various cancers, while PSMA is particularly useful for targeting prostate cancer due to its specific binding to prostate tumor cells <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Lesion segmentation in PET/CT imaging is essential for detailed tumor analysis and boosting diagnostic precision. However, manual lesion segmentation in PET/CT scans is still time-consuming and prone to inconsistencies, making automated methods increasingly important for improving diagnostic precision and efficiency in clinical settings.
The task is however subject to differences in patient physiology, tracer-specific uptake patterns, and diverse imaging protocols, making it challenging to distinguish between physiological and pathological uptake.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The autoPET III challenge addresses the need for robust and generalizable segmentation solutions by focusing on automated lesion segmentation in PET/CT scans across multiple tracers and clinical settings. It builds on past efforts by adding a new PSMA dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib11" title="">11</a>]</cite> of 597 whole-body PET/CT studies alongside the FDG dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib5" title="">5</a>]</cite> of 1,014 studies, which was used in the previous two autoPET challenges. The FDG dataset was acquired at the University Hospital T√ºbingen (UKT), while the PSMA dataset was obtained from the LMU Hospital in Munich.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Previous challenge results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib8" title="">8</a>]</cite> have extensively shown the effectiveness of the nnU-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib4" title="">4</a>]</cite> for the task of lesion segmentation in FDG PET/CTs. However, the distinct uptake distributions of FDG and PSMA tracers present additional challenges, complicating the differentiation between physiological and pathological uptake. To address this, we trained a classifier to distinguish between FDG and PSMA tracers and enhanced the model‚Äôs accuracy by integrating anatomical knowledge through a multilabel approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib10" title="">10</a>]</cite>. This involves training two separate nnUNet ensembles on the FDG and PSMA datasets, where anatomical masks are included alongside lesion labels in a multi-class classification task.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Pipeline overview</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.F1" title="Figure 1 ‚Ä£ 2.1 Pipeline overview ‚Ä£ 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the workflow of our final submission. Given a PET/CT scan, the PET volume is first input into a classification module that identifies the tracer. In the next step, both the PET and the CT are concatenated and processed through a tracer-specific nnUNet-ensemble, which generates the initial segmentation mask. After applying post-processing steps, the final segmentation mask is produced. In the following, the classification module is described in detail.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">Pipeline of our final submission. In the first step, the PET volume from a given PET/CT scan is input into a classification module that determines the tracer type. PET and CT volumes are then concatenated and fed into a nnU-Net ensemble that was trained on the dataset of the classified tracer. The final binary lesion mask is output after postprocessing.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>MIP-based tracer classification</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Due to the distinct mechanisms of FDG and PSMA as PET tracers, their uptake distributions exhibit notable differences. The most notable difference is observed in the brain, where FDG demonstrates significantly higher SUV values than PSMA. Additionally, FDG PET scans generally show lower average uptake in the kidneys and liver, whereas PSMA demonstrates significant uptake in the submandibular and parotid glands. To capture these uptake distributions while simplifying image complexity, we utilize Maximum Intensity Projections (MIP) of the PET scans in the coronal and sagittal plane as input to our classification model. This approach significantly reduces inference time by minimizing the complexity of the input data compared to using the full 3D volume. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.F2" title="Figure 2 ‚Ä£ 2.2 MIP-based tracer classification ‚Ä£ 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the distinct uptake patterns between healthy FDG and PSMA scans as observed in the MIPs. The differences in uptake patterns between tracers also vary with pathological conditions. Since PSMA scans are used in the context of prostate cancer, its bone metastases are more commonly observed in PSMA scans, while they may be less visible in FDG scans.</p>
</div>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="366" id="S2.F2.sf1.g1" src="extracted/5861275/mip_fdg.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S2.F2.sf1.3.2" style="font-size:90%;">FDG</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="365" id="S2.F2.sf2.g1" src="extracted/5861275/mip_psma.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S2.F2.sf2.3.2" style="font-size:90%;">PSMA</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.3.2" style="font-size:90%;">Exemplary coronal and sagittal MIPs for PET scans of two healthy patients using the FDG tracer and PSMA tracer. Whiter regions represent higher SUV values. In both views, the FDG MIP highlights clear higher uptake patterns for the brain and urinary bladder, whereas the latter reveals higher uptake in the kidneys, submandibular glands, and parotid glands.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">We first train two separate ResNet18 models on coronal and sagittal MIPs. Next, a multilayer perceptron (MLP) is trained on top of the concatenated features from the frozen backbones of both models. The MLP outputs a binary classification indicating whether the used tracer in the given PET/CT scan is FDG or PSMA.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Anatomy-guided lesion segmentation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">For the segmentation of the lesions, we use the nnU-Net framework. To better distinguish between physiological and pathological uptake, we guide the network to learn organ-specific uptake patterns by incorporating anatomical knowledge.
To this extent, we explore how anatomical structures can further improve the initial results. 117 different anatomical labels are extracted using TotalSegmentator <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib16" title="">16</a>]</cite> for each CT volume of the datasets. Besides using all anatomical structures, we also take different subsets depending on the dataset which are described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S3.SS3" title="3.3 Preprocessing and implementation details ‚Ä£ 3 Experimental setup and evaluation ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">3.3</span></a>. We train and evaluate models for each dataset using the following three approaches:</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Multilabel classification</span>: Anatomical structures are used as additional label input alongside the lesion labels. Additionally, we introduce a weighting factor <math alttext="\lambda" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.1"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">Œª</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">ùúÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.1d">italic_Œª</annotation></semantics></math> to adjust the relative importance of lesion labels compared to anatomical labels within the Dice Cross-Entropy loss function.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Channel concatenation</span>: Anatomical labels are added as an additional channel to the PET/CT data, resulting in a three-channel input for the model.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Pretraining</span>: We finetune the STU-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib7" title="">7</a>]</cite> architecture, which has been pretrained on the TotalSegmentator dataset, on only lesion labels as well as the mentioned subsets of additional anatomical labels.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental setup and evaluation</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Experiments were conducted on two datasets, which we will simply refer to as the FDG dataset and the PSMA dataset. The FDG dataset consists of 1,014 whole-body PET/CT studies from 900 patients, acquired at the University Hospital T√ºbingen using a Siemens Biograph mCT scanner. It includes 501 studies from patients diagnosed with malignant melanoma, lymphoma, or lung cancer, along with 513 studies from negative control patients.
The PSMA dataset includes 597 whole-body PET/CT studies of male patients with prostate carcinoma, comprising 537 studies with PSMA-avid tumor lesions and 60 studies without. The studies were acquired from the LMU Hospital in Munich using three different PET/CT scanners (Siemens Biograph 64-4R TruePoint, Siemens Biograph mCT Flow 20, and GE Discovery 690). It should be noted that for the segmentation experiments in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS1" title="4.1 Baseline models ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">4.1</span></a> and Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS3" title="4.3 Anatomy-guided lesion segmentation ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">4.3</span></a> redacted samples were utilized.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation protocol and metrics</h3>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Tracer classification.</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">We merged the FDG and PSMA datasets and performed an 80/20 train-test split. To evaluate model robustness, we conducted 5-fold cross-validation on the training set. Classification accuracy is reported across both the cross-validation folds and the independent test set.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Lesion segmentation.</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">For each dataset, five samples were excluded and used as an additional internal test set. We then conducted 5-fold cross-validation using nnUNet, following the training strategies outlined in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS3" title="2.3 Anatomy-guided lesion segmentation ‚Ä£ 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">2.3</span></a> and report results based on three different metrics. In addition to the Dice score, the evaluation metrics of the autoPET challenge include false positive and false negative lesion volumes. The false positive volume (FPV) refers to the volume of predicted connected components that do not overlap with any ground truth components, while the false negative volume (FNV) measures the ground truth connected components that are missed by the predicted segmentation mask.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Preprocessing and implementation details</h3>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Tracer classification.</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">The coronal and sagittal MIPs were resized to a size of 224 x 224 and given to the ResNet18 as inputs. During training, we applied various data augmentations such as horizontal flipping, random rotation, Gaussian blurring, and cropping. The ResNets are trained for 50 epochs with a learning rate and weight decay of 0.0005 using ADAM as an optimizer, while the MLP is trained for 20 epochs with a learning rate of 0.0001.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Lesion segmentation.</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">For both the PET and the CT, global dataset percentile clipping as well as normalization based on the mean and standard deviation of the dataset were performed. Notably, for the final submission, we applied z-score normalization specifically to the PET scans.
We trained standard 3D full-resolution U-Net models, using the default configurations and data augmentations from nnUNet. This includes a range of augmentations such as Gaussian noise, random rotation, cropping, Gaussian blur, down-sampling, and gamma correction. We trained for 1000 epochs with a batch size of 2 and an initial learning rate of 0.01. For fine-tuning the STU-Net model and concatenating the labels as a third channel, we adjusted the learning rate to 0.001.
For approaches that utilize anatomical labels, we mainly considered organs from healthy patients that show a mean SUV uptake of higher than 2. For FDG, these labels are given by brain, urinary bladder, spleen, liver, heart, kidneys, duodenum, prostate, small bowel, and esophagus. Besides the colon and pancreas, we also added the lungs to this subset, since including them has shown a performance boost. For the PSMA models, we included the gallbladder and excluded the brain, lungs, and colon.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Baseline models</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Before presenting the results for tracer classification and evaluating different lesion segmentation algorithms, we first compare the performance of a simple baseline nnU-Net model trained on a combined FDG and PSMA dataset with models trained individually on each dataset. As shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T1" title="Table 1 ‚Ä£ 4.1 Baseline models ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">1</span></a>, the results indicate that the Dice score and FNV for the FDG dataset are slightly better with the separate training approach, while the FPV is worse. In contrast, the model trained individually on the PSMA dataset significantly outperforms the combined model in both Dice score and FPV, with similar performance in FNV.
These findings highlight the benefits of training separate models for each dataset, thereby justifying the development of a dedicated tracer classification module.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.1.1.1.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.2.1.1.3.1" style="font-size:90%;">FDG Dataset</span></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.1.1.4"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.2.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.1.1.5.1" style="font-size:90%;">PSMA Dataset</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.2.2.1">
<td class="ltx_td" id="S4.T1.2.2.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T1.2.2.1.2"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.3.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.4.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.5.1" style="font-size:90%;">FNV</span></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.6"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.7"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.7.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T1.2.2.1.8"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.8.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T1.2.2.1.9"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.1.9.1" style="font-size:90%;">FNV</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.2.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.2.1.1" style="font-size:90%;">Combined training</span></td>
<td class="ltx_td ltx_border_t" id="S4.T1.2.3.2.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.3"><span class="ltx_text" id="S4.T1.2.3.2.3.1" style="font-size:90%;">0.6483</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.2.4.1" style="font-size:90%;">18.93</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.5"><span class="ltx_text" id="S4.T1.2.3.2.5.1" style="font-size:90%;">12.18</span></td>
<td class="ltx_td ltx_border_t" id="S4.T1.2.3.2.6"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.7"><span class="ltx_text" id="S4.T1.2.3.2.7.1" style="font-size:90%;">0.5258</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.8"><span class="ltx_text" id="S4.T1.2.3.2.8.1" style="font-size:90%;">16.33</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.2.9"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.2.9.1" style="font-size:90%;">19.46</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.2.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.4.3.1.1" style="font-size:90%;">Individual training</span></td>
<td class="ltx_td ltx_border_bb" id="S4.T1.2.4.3.2"></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T1.2.4.3.3.1" style="font-size:90%;">0.6538</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.4"><span class="ltx_text" id="S4.T1.2.4.3.4.1" style="font-size:90%;">25.34</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.4.3.5.1" style="font-size:90%;">9.72</span></td>
<td class="ltx_td ltx_border_bb" id="S4.T1.2.4.3.6"></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.7"><span class="ltx_text ltx_font_bold" id="S4.T1.2.4.3.7.1" style="font-size:90%;">0.6014</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.8"><span class="ltx_text ltx_font_bold" id="S4.T1.2.4.3.8.1" style="font-size:90%;">12.17</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.4.3.9"><span class="ltx_text" id="S4.T1.2.4.3.9.1" style="font-size:90%;">20.49</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Averaged 5-fold cross-validation results for the combined and individual training approach on the FDG and PSMA dataset.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Tracer classification</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T2" title="Table 2 ‚Ä£ 4.2 Tracer classification ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">2</span></a> shows the final results for tracer classification using the fusion approach described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS2" title="2.2 MIP-based tracer classification ‚Ä£ 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">2.2</span></a> . We compare this approach with two models trained separately on coronal and sagittal MIPs. All methods demonstrate high effectiveness, achieving accuracies of at least 99%. This high performance suggests that the classification task is relatively simple due to the clear distinction between tracer distributions. Although all methods attain perfect accuracy on the test set, the fusion approach outperforms the individual MIP-based models for cross-validation. This approach benefits from integrating complementary information from both MIPs, leading to more reliable and accurate classification results. Given that the additional computational cost of including both MIPs is minimal compared to the lesion segmentation model, its use is well-justified.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.2.1.1.1.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.2.1.1.2.1" style="font-size:90%;">5-Fold CV</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.2.1.1.3.1" style="font-size:90%;">Test Dataset</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.2.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.2.2.1.1.1" style="font-size:90%;">Coronal</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.1.2"><span class="ltx_text" id="S4.T2.2.2.1.2.1" style="font-size:90%;">0.9977</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.1.3"><span class="ltx_text" id="S4.T2.2.2.1.3.1" style="font-size:90%;">1.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.2.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.2.3.2.1.1" style="font-size:90%;">Sagittal</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.2.3.2.2"><span class="ltx_text" id="S4.T2.2.3.2.2.1" style="font-size:90%;">0.9977</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.3.2.3"><span class="ltx_text" id="S4.T2.2.3.2.3.1" style="font-size:90%;">1.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.2.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.2.4.3.1.1" style="font-size:90%;">Fusion</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.4.3.2"><span class="ltx_text" id="S4.T2.2.4.3.2.1" style="font-size:90%;">0.9992</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.2.4.3.3"><span class="ltx_text" id="S4.T2.2.4.3.3.1" style="font-size:90%;">1.0000</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Classification accuracies for the 5-Fold Cross-Validation and test dataset using ResNets trained separately on coronal MIPs, sagittal MIPs, and the fusion approach. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Anatomy-guided lesion segmentation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The cross-validation results on the FDG and PSMA datasets using the various lesion segmentation approaches described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S2.SS3" title="2.3 Anatomy-guided lesion segmentation ‚Ä£ 2 Method ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">2.3</span></a> are shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T3" title="Table 3 ‚Ä£ 4.3 Anatomy-guided lesion segmentation ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">3</span></a>. The baseline models refer to the nnU-Net models that are trained individually on the FDG and PSMA datasets. Compared to the baseline every approach shows improvements for every metric except the multilabel classification model that is trained on all anatomical labels. We suggest that the Dice is even slightly lower than the baseline because the model places less emphasis on the lesion class during training. By taking a relevant subset of organs and therefore also fewer organs the Dice score improves dramatically. Using the weighted approach further increases the Dice score.
The weighted multilabel approach is also the best-performing method on the PSMA dataset while keeping FPV and FNV comparable to other methods.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">For the finetuning of the pretrained STU-Net model using the multilabel approach, we surprisingly find lower performance in the Dice score. It should be noted that this might be attributed to the use of a lower learning rate. Specifically, when training on the PSMA dataset using the multilabel approach with a learning rate of 0.001, we also observe a similar decrease in performance.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.1.1" style="font-size:90%;">Method</span></td>
<td class="ltx_td ltx_border_tt" id="S4.T3.1.2.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.3.1" style="font-size:90%;">FDG Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.4.1" style="font-size:90%;">PSMA Dataset</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td" id="S4.T3.1.3.2.1"></td>
<td class="ltx_td" id="S4.T3.1.3.2.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.3.1" style="font-size:90%;">DICE</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.4.1" style="font-size:90%;">FPV</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.5.1" style="font-size:90%;">FNV</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.6.1" style="font-size:90%;">DICE</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.7.1" style="font-size:90%;">FPV</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.3.2.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.8.1" style="font-size:90%;">FNV</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.3.1.1" style="font-size:90%;">Baseline</span></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.4.3.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.3"><span class="ltx_text" id="S4.T3.1.4.3.3.1" style="font-size:90%;">0.6583</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.4"><span class="ltx_text" id="S4.T3.1.4.3.4.1" style="font-size:90%;">25.34</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.5"><span class="ltx_text" id="S4.T3.1.4.3.5.1" style="font-size:90%;">9.72</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.6"><span class="ltx_text" id="S4.T3.1.4.3.6.1" style="font-size:90%;">0.6014</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.7"><span class="ltx_text" id="S4.T3.1.4.3.7.1" style="font-size:90%;">12.17</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.4.3.8"><span class="ltx_text" id="S4.T3.1.4.3.8.1" style="font-size:90%;">20.49</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.4.1.1" style="font-size:90%;">Multilabel Classification</span></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.2"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.3"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.4"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.5"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.6"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.7"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.5.4.8"></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.5.1"><span class="ltx_text" id="S4.T3.1.6.5.1.1" style="font-size:90%;">¬†¬†‚ÄÉAll labels</span></td>
<td class="ltx_td" id="S4.T3.1.6.5.2"></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.3"><span class="ltx_text" id="S4.T3.1.6.5.3.1" style="font-size:90%;">0.6530</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.4"><span class="ltx_text" id="S4.T3.1.6.5.4.1" style="font-size:90%;">9.64</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.5"><span class="ltx_text" id="S4.T3.1.6.5.5.1" style="font-size:90%;">7.96</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.6"><span class="ltx_text" id="S4.T3.1.6.5.6.1" style="font-size:90%;">0.5343</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.7.1" style="font-size:90%;">9.82</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.6.5.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.8.1" style="font-size:90%;">10.55</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.6">
<td class="ltx_td ltx_align_left" id="S4.T3.1.7.6.1"><span class="ltx_text" id="S4.T3.1.7.6.1.1" style="font-size:90%;">¬†¬†‚ÄÉSubset of Labels</span></td>
<td class="ltx_td" id="S4.T3.1.7.6.2"></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.3"><span class="ltx_text" id="S4.T3.1.7.6.3.1" style="font-size:90%;">0.7346</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.4"><span class="ltx_text" id="S4.T3.1.7.6.4.1" style="font-size:90%;">7.36</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.5"><span class="ltx_text" id="S4.T3.1.7.6.5.1" style="font-size:90%;">6.39</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.6"><span class="ltx_text" id="S4.T3.1.7.6.6.1" style="font-size:90%;">0.5968</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.7"><span class="ltx_text" id="S4.T3.1.7.6.7.1" style="font-size:90%;">10.64</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.7.6.8"><span class="ltx_text" id="S4.T3.1.7.6.8.1" style="font-size:90%;">12.68</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1">
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.1">
<span class="ltx_text" id="S4.T3.1.1.1.1" style="font-size:90%;">¬†¬†‚ÄÉWeighted Approach (</span><math alttext="\lambda=3" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.m1.1.1.2" mathsize="90%" xref="S4.T3.1.1.1.m1.1.1.2.cmml">Œª</mi><mo id="S4.T3.1.1.1.m1.1.1.1" mathsize="90%" xref="S4.T3.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T3.1.1.1.m1.1.1.3" mathsize="90%" xref="S4.T3.1.1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><eq id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1.1"></eq><ci id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">ùúÜ</ci><cn id="S4.T3.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T3.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\lambda=3</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">italic_Œª = 3</annotation></semantics></math><span class="ltx_text" id="S4.T3.1.1.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td" id="S4.T3.1.1.2"></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1" style="font-size:90%;">0.7493</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.4"><span class="ltx_text" id="S4.T3.1.1.4.1" style="font-size:90%;">7.69</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.5"><span class="ltx_text" id="S4.T3.1.1.5.1" style="font-size:90%;">5.90</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.6.1" style="font-size:90%;">0.6133</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.7"><span class="ltx_text" id="S4.T3.1.1.7.1" style="font-size:90%;">12.97</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.1.8"><span class="ltx_text" id="S4.T3.1.1.8.1" style="font-size:90%;">11.23</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.8.7.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.7.1.1" style="font-size:90%;">Channel Concatenation</span></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.2"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.3"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.4"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.5"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.6"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.7"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.8.7.8"></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9.8">
<td class="ltx_td ltx_align_left" id="S4.T3.1.9.8.1"><span class="ltx_text" id="S4.T3.1.9.8.1.1" style="font-size:90%;">¬†¬†‚ÄÉAll labels</span></td>
<td class="ltx_td" id="S4.T3.1.9.8.2"></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.3"><span class="ltx_text" id="S4.T3.1.9.8.3.1" style="font-size:90%;">0.7193</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.4"><span class="ltx_text" id="S4.T3.1.9.8.4.1" style="font-size:90%;">9.19</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.5"><span class="ltx_text" id="S4.T3.1.9.8.5.1" style="font-size:90%;">7.79</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.6"><span class="ltx_text" id="S4.T3.1.9.8.6.1" style="font-size:90%;">0.5930</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.7"><span class="ltx_text" id="S4.T3.1.9.8.7.1" style="font-size:90%;">11.04</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.9.8.8"><span class="ltx_text" id="S4.T3.1.9.8.8.1" style="font-size:90%;">12.79</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.10.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.10.9.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.10.9.1.1" style="font-size:90%;">Pretraining</span></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.2"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.3"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.4"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.5"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.6"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.7"></td>
<td class="ltx_td ltx_border_t" id="S4.T3.1.10.9.8"></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.11.10">
<td class="ltx_td ltx_align_left" id="S4.T3.1.11.10.1"><span class="ltx_text" id="S4.T3.1.11.10.1.1" style="font-size:90%;">¬†¬†‚ÄÉSingle label</span></td>
<td class="ltx_td" id="S4.T3.1.11.10.2"></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.3"><span class="ltx_text" id="S4.T3.1.11.10.3.1" style="font-size:90%;">0.7442</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.4"><span class="ltx_text" id="S4.T3.1.11.10.4.1" style="font-size:90%;">8.52</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.11.10.5.1" style="font-size:90%;">5.66</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.6"><span class="ltx_text" id="S4.T3.1.11.10.6.1" style="font-size:90%;">0.5909</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.7"><span class="ltx_text" id="S4.T3.1.11.10.7.1" style="font-size:90%;">11.73</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.1.11.10.8"><span class="ltx_text" id="S4.T3.1.11.10.8.1" style="font-size:90%;">17.44</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.12.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.12.11.1"><span class="ltx_text" id="S4.T3.1.12.11.1.1" style="font-size:90%;">¬†¬†‚ÄÉMultilabel</span></td>
<td class="ltx_td ltx_border_bb" id="S4.T3.1.12.11.2"></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.3"><span class="ltx_text" id="S4.T3.1.12.11.3.1" style="font-size:90%;">0.7244</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.12.11.4.1" style="font-size:90%;">6.50</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.5"><span class="ltx_text" id="S4.T3.1.12.11.5.1" style="font-size:90%;">7.40</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.6"><span class="ltx_text" id="S4.T3.1.12.11.6.1" style="font-size:90%;">0.5784</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.7"><span class="ltx_text" id="S4.T3.1.12.11.7.1" style="font-size:90%;">10.95</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.1.12.11.8"><span class="ltx_text" id="S4.T3.1.12.11.8.1" style="font-size:90%;">12.54</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Cross-validation results for various lesion segmentation approaches using anatomical information on the FDG and PSMA dataset.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Postprocessing</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">For postprocessing, we evaluate the impact of thresholding methods on the segmentation performance for two scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T4" title="Table 4 ‚Ä£ 4.4 Postprocessing ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">4</span></a> examines the effect of removing connected components smaller than a specified threshold on the performance metrics for both datasets. The predicted segmentation masks from the cross-validation results of the final submission models (see Sec. 4.5) are used for evaluation. Based on the result that this method even leads to significant increases in FNV for a threshold of 1, we don‚Äôt use this method in our final submission.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">Additionally, we assess how varying SUV thresholds impact the model‚Äôs performance (refer to Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T5" title="Table 5 ‚Ä£ 4.4 Postprocessing ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">5</span></a>). This involves setting the predicted segmentation masks to 0 for PET values that fall below a designated threshold. According to our findings, we adopt SUV thresholds of 1.5 for the FDG model and 1 for the PSMA model.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T4.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.1.1" style="font-size:90%;">CC threshold</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T4.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.2.1" style="font-size:90%;">FDG Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T4.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.1.1.3.1" style="font-size:90%;">PSMA Dataset</span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.2.2.2.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.2.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.3.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.4.1" style="font-size:90%;">FNV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.5.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.6.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.7.1" style="font-size:90%;">FNV</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.2.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.3.1.1.1" style="font-size:90%;">1</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.2"><span class="ltx_text" id="S4.T4.2.3.1.2.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.3"><span class="ltx_text" id="S4.T4.2.3.1.3.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.4"><span class="ltx_text" id="S4.T4.2.3.1.4.1" style="font-size:90%;">0.1059</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.5"><span class="ltx_text" id="S4.T4.2.3.1.5.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.6"><span class="ltx_text" id="S4.T4.2.3.1.6.1" style="font-size:90%;">-0.0271</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.2.3.1.7"><span class="ltx_text" id="S4.T4.2.3.1.7.1" style="font-size:90%;">0.2028</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.2.4.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.4.2.1.1" style="font-size:90%;">2</span></th>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.2"><span class="ltx_text" id="S4.T4.2.4.2.2.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.3"><span class="ltx_text" id="S4.T4.2.4.2.3.1" style="font-size:90%;">-0.0123</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.4"><span class="ltx_text" id="S4.T4.2.4.2.4.1" style="font-size:90%;">0.1708</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.5"><span class="ltx_text" id="S4.T4.2.4.2.5.1" style="font-size:90%;">-0.0005</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.6"><span class="ltx_text" id="S4.T4.2.4.2.6.1" style="font-size:90%;">-0.0629</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.4.2.7"><span class="ltx_text" id="S4.T4.2.4.2.7.1" style="font-size:90%;">0.4956</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.2.5.3.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.5.3.1.1" style="font-size:90%;">3</span></th>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.2"><span class="ltx_text" id="S4.T4.2.5.3.2.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.3"><span class="ltx_text" id="S4.T4.2.5.3.3.1" style="font-size:90%;">-0.0196</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.4"><span class="ltx_text" id="S4.T4.2.5.3.4.1" style="font-size:90%;">0.1994</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.5"><span class="ltx_text" id="S4.T4.2.5.3.5.1" style="font-size:90%;">-0.0007</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.6"><span class="ltx_text" id="S4.T4.2.5.3.6.1" style="font-size:90%;">-0.1024</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.5.3.7"><span class="ltx_text" id="S4.T4.2.5.3.7.1" style="font-size:90%;">0.8054</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.2.6.4.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.6.4.1.1" style="font-size:90%;">5</span></th>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.2"><span class="ltx_text" id="S4.T4.2.6.4.2.1" style="font-size:90%;">0.0001</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.3"><span class="ltx_text" id="S4.T4.2.6.4.3.1" style="font-size:90%;">-0.0354</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.4"><span class="ltx_text" id="S4.T4.2.6.4.4.1" style="font-size:90%;">0.2467</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.5"><span class="ltx_text" id="S4.T4.2.6.4.5.1" style="font-size:90%;">-0.0019</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.6"><span class="ltx_text" id="S4.T4.2.6.4.6.1" style="font-size:90%;">-0.1852</span></td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.6.4.7"><span class="ltx_text" id="S4.T4.2.6.4.7.1" style="font-size:90%;">1.2753</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T4.2.7.5.1"><span class="ltx_text ltx_font_bold" id="S4.T4.2.7.5.1.1" style="font-size:90%;">10</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.2"><span class="ltx_text" id="S4.T4.2.7.5.2.1" style="font-size:90%;">-0.0007</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.3"><span class="ltx_text" id="S4.T4.2.7.5.3.1" style="font-size:90%;">-0.0739</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.4"><span class="ltx_text" id="S4.T4.2.7.5.4.1" style="font-size:90%;">0.3834</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.5"><span class="ltx_text" id="S4.T4.2.7.5.5.1" style="font-size:90%;">-0.0074</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.6"><span class="ltx_text" id="S4.T4.2.7.5.6.1" style="font-size:90%;">-0.4350</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.2.7.5.7"><span class="ltx_text" id="S4.T4.2.7.5.7.1" style="font-size:90%;">3.1680</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Absolute differences for the validation results of the FDG and PSMA models when all connected components in the predicted segmentation mask with a length smaller than a specified threshold are set to zero.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T5.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.1.1.1.1" style="font-size:90%;">SUV threshold</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T5.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.1.1.2.1" style="font-size:90%;">FDG Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T5.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.1.1.3.1" style="font-size:90%;">PSMA Dataset</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T5.2.2.2.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.2.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.3.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.4.1" style="font-size:90%;">FNV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.5.1" style="font-size:90%;">DICE</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.6.1" style="font-size:90%;">FPV</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T5.2.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.7.1" style="font-size:90%;">FNV</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.2.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.3.1.1.1" style="font-size:90%;">0.50</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.2"><span class="ltx_text" id="S4.T5.2.3.1.2.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.3"><span class="ltx_text" id="S4.T5.2.3.1.3.1" style="font-size:90%;">-0.0001</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.4"><span class="ltx_text" id="S4.T5.2.3.1.4.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.5"><span class="ltx_text" id="S4.T5.2.3.1.5.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.6"><span class="ltx_text" id="S4.T5.2.3.1.6.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.2.3.1.7"><span class="ltx_text" id="S4.T5.2.3.1.7.1" style="font-size:90%;">0.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.2.4.2.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.4.2.1.1" style="font-size:90%;">0.75</span></th>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.2"><span class="ltx_text" id="S4.T5.2.4.2.2.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.3"><span class="ltx_text" id="S4.T5.2.4.2.3.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.4"><span class="ltx_text" id="S4.T5.2.4.2.4.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.5"><span class="ltx_text" id="S4.T5.2.4.2.5.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.6"><span class="ltx_text" id="S4.T5.2.4.2.6.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.4.2.7"><span class="ltx_text" id="S4.T5.2.4.2.7.1" style="font-size:90%;">0.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.2.5.3.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.5.3.1.1" style="font-size:90%;">1.00</span></th>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.2"><span class="ltx_text" id="S4.T5.2.5.3.2.1" style="font-size:90%;">0.0001</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.3"><span class="ltx_text" id="S4.T5.2.5.3.3.1" style="font-size:90%;">-0.0008</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.4"><span class="ltx_text" id="S4.T5.2.5.3.4.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.5"><span class="ltx_text" id="S4.T5.2.5.3.5.1" style="font-size:90%;">-0.0001</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.6"><span class="ltx_text" id="S4.T5.2.5.3.6.1" style="font-size:90%;">-0.0007</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.5.3.7"><span class="ltx_text" id="S4.T5.2.5.3.7.1" style="font-size:90%;">0.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.2.6.4.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.6.4.1.1" style="font-size:90%;">1.25</span></th>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.2"><span class="ltx_text" id="S4.T5.2.6.4.2.1" style="font-size:90%;">0.0002</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.3"><span class="ltx_text" id="S4.T5.2.6.4.3.1" style="font-size:90%;">-0.0060</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.4"><span class="ltx_text" id="S4.T5.2.6.4.4.1" style="font-size:90%;">0.0000</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.5"><span class="ltx_text" id="S4.T5.2.6.4.5.1" style="font-size:90%;">-0.0003</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.6"><span class="ltx_text" id="S4.T5.2.6.4.6.1" style="font-size:90%;">-0.0125</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.6.4.7"><span class="ltx_text" id="S4.T5.2.6.4.7.1" style="font-size:90%;">0.0000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.2.7.5.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.7.5.1.1" style="font-size:90%;">1.50</span></th>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.2"><span class="ltx_text" id="S4.T5.2.7.5.2.1" style="font-size:90%;">0.0003</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.3"><span class="ltx_text" id="S4.T5.2.7.5.3.1" style="font-size:90%;">-0.0233</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.4"><span class="ltx_text" id="S4.T5.2.7.5.4.1" style="font-size:90%;">0.0005</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.5"><span class="ltx_text" id="S4.T5.2.7.5.5.1" style="font-size:90%;">-0.0009</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.6"><span class="ltx_text" id="S4.T5.2.7.5.6.1" style="font-size:90%;">-0.0467</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.2.7.5.7"><span class="ltx_text" id="S4.T5.2.7.5.7.1" style="font-size:90%;">0.0001</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T5.2.8.6.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.8.6.1.1" style="font-size:90%;">1.75</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.2"><span class="ltx_text" id="S4.T5.2.8.6.2.1" style="font-size:90%;">-0.0015</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.3"><span class="ltx_text" id="S4.T5.2.8.6.3.1" style="font-size:90%;">-0.0594</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.4"><span class="ltx_text" id="S4.T5.2.8.6.4.1" style="font-size:90%;">0.0014</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.5"><span class="ltx_text" id="S4.T5.2.8.6.5.1" style="font-size:90%;">-0.0016</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.6"><span class="ltx_text" id="S4.T5.2.8.6.6.1" style="font-size:90%;">-0.1227</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.2.8.6.7"><span class="ltx_text" id="S4.T5.2.8.6.7.1" style="font-size:90%;">0.0080</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Absolute differences for the validation results of the FDG and PSMA models when all values in the predicted segmentation mask are set to zero where the PET values are below the specified threshold.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Final submissions</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">The results of Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.SS3" title="4.3 Anatomy-guided lesion segmentation ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">4.3</span></a> have shown that a weighted multilabel approach has yielded the best performance in our cross-validation.
Therefore, for the final model submission, we train two separate nnU-Net models using this approach on the FDG and PSMA datasets respectively. Given the demonstrated performance improvements with nnU-Net using residual encoders as reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib9" title="">9</a>]</cite>, we adopt this architecture (ResEnc-M) in our work to leverage these benefits for our segmentation tasks. The FDG and PSMA models are trained for 1500 and 1000 epochs respectively. In contrast to the FDG model, longer training has not led to higher performance for the PSMA one. After manual examination of samples with high false positive volumes across different models from Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T3" title="Table 3 ‚Ä£ 4.3 Anatomy-guided lesion segmentation ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">3</span></a>, we exclude one sample from the FDG and nine samples from the PSMA dataset. These samples either present certain special cases (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#bib.bib1" title="">1</a>]</cite>) or may lack annotations. We assess that these samples are not essential for the model‚Äôs performance.
The final results of this submission can be seen in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T6" title="Table 6 ‚Ä£ 4.5 Final submissions ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">6</span></a>. The FDG model has an increase of almost 2 %, while the PSMA model has a slightly lower Dice score. Since we excluded multiple samples with high false-positive volumes, the FPV values are significantly lower in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T6" title="Table 6 ‚Ä£ 4.5 Final submissions ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">6</span></a>. In comparison, the models using the weighted multilabel approach from Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T6" title="Table 6 ‚Ä£ 4.5 Final submissions ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">6</span></a> achieve higher FPV values of 8.15 for the FDG and PSMA datasets with excluded samples, respectively.
Since the PSMA model from Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T3" title="Table 3 ‚Ä£ 4.3 Anatomy-guided lesion segmentation ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">3</span></a> achieved the highest Dice score, we also submitted a variant that includes it and the FDG model from Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.12155v1#S4.T6" title="Table 6 ‚Ä£ 4.5 Final submissions ‚Ä£ 4 Results ‚Ä£ Autopet III challenge: Incorporating anatomical knowledge into nnUNet for lesion segmentation in PET/CT"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T6.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T6.2.1.1.1.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T6.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.2.1.1.2.1" style="font-size:90%;">FDG Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T6.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.2.1.1.3.1" style="font-size:90%;">PSMA Dataset</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.2.2.1">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T6.2.2.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.2.1" style="font-size:90%;">DICE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.3.1" style="font-size:90%;">FPV</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.4.1" style="font-size:90%;">FNV</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.5.1" style="font-size:90%;">DICE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.6"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.6.1" style="font-size:90%;">FPV</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.1.7"><span class="ltx_text ltx_font_bold" id="S4.T6.2.2.1.7.1" style="font-size:90%;">FNV</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T6.2.3.2.1.1" style="font-size:90%;">Multilabel</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.2"><span class="ltx_text" id="S4.T6.2.3.2.2.1" style="font-size:90%;">0.7690</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.3"><span class="ltx_text" id="S4.T6.2.3.2.3.1" style="font-size:90%;">3.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.4"><span class="ltx_text" id="S4.T6.2.3.2.4.1" style="font-size:90%;">6.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.5"><span class="ltx_text" id="S4.T6.2.3.2.5.1" style="font-size:90%;">0.6071</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.6"><span class="ltx_text" id="S4.T6.2.3.2.6.1" style="font-size:90%;">6.355</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.2.3.2.7"><span class="ltx_text" id="S4.T6.2.3.2.7.1" style="font-size:90%;">13.78</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Cross-validation results for the final submission.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we addressed the task of automated lesion segmentation in PET/CT imaging within the context of the autoPET III challenge. Our approach involved developing a classifier to identify the tracer type based on the PET scan‚Äôs Maximum Intensity Projection (MIP). We then trained separate nnU-Net ensembles for each tracer, integrating anatomical labels as a weighted multi-label classification task to enhance segmentation performance.
Our methodology tackled the inherent difficulties of distinguishing between physiological and pathological uptake patterns, given the distinct tracer-specific uptake characteristics and varied imaging protocols.
Our final models achieved Dice scores of 76.90% for the FDG dataset and 61.33% for the PSMA dataset, representing a significant improvement over a baseline nnU-Net model trained on both datasets. Additionally, our approach maintained lower volumes of false negatives and false positives, underscoring the effectiveness of incorporating tracer-specific classification and anatomical knowledge into the segmentation process. A drawback of employing two separate models in the context of the challenge is that the effectiveness of this approach depends heavily on the tracer classifier‚Äôs accuracy. However, in a clinical setting, the tracer type is known at inference time, so this issue is mitigated.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work received funding from ‚ÄòKITE‚Äô (Plattform f√ºr KI-Translation Essen) from the REACT-EU initiative (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kite.ikim.nrw/" title="">https://kite.ikim.nrw/</a>, EFRE-0801977) and the Cancer Research Center Cologne Essen (CCCE).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M.¬†S. Alam, L.¬†Fu, Y.¬†Y. Ren, H.¬†B. Wu, Q.¬†S. Wang, Y.¬†J. Han, W.¬†L. Zhou, H.¬†S. Li, and Z.¬†Wang.

</span>
<span class="ltx_bibblock">18f-fdg super bone marrow uptake: A highly potent indicator for the malignant infiltration.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Medicine (Baltimore)</span>, 95(52):e5579, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A.¬†Almuhaideb, N.¬†Papathanasiou, and J.¬†Bomanji.

</span>
<span class="ltx_bibblock">18f-fdg pet/ct imaging in oncology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Annals of Saudi Medicine</span>, 31(1):3‚Äì13, January-February 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M.¬†D. Farwell, D.¬†A. Pryma, and D.¬†A. Mankoff.

</span>
<span class="ltx_bibblock">Pet/ct imaging in cancer: Current applications and future directions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Cancer</span>, 120(22):3433‚Äì3445, November 2014.

</span>
<span class="ltx_bibblock">Epub 2014 Jun 19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Sergios Gatidis, Marcel Fr√ºh, Matthias Fabritius, Sijing Gu, Konstantin Nikolaou, Christian La¬†Foug√®re, Jin Ye, Junjun He, Yige Peng, Lei Bi, et¬†al.

</span>
<span class="ltx_bibblock">The autopet challenge: towards fully automated lesion segmentation in oncologic pet/ct imaging.

</span>
<span class="ltx_bibblock">2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Stefanie Gatidis and Thomas Kuestner.

</span>
<span class="ltx_bibblock">A whole-body fdg-pet/ct dataset with manually annotated tumor lesions (fdg-pet-ct-lesions) [dataset].

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.7937/gkr0-xv29" title="">https://doi.org/10.7937/gkr0-xv29</a>, 2022.

</span>
<span class="ltx_bibblock">The Cancer Imaging Archive.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
H.¬†Gr√ºnig, A.¬†Maurer, Y.¬†Thali, Z.¬†Kovacs, K.¬†Strobel, I.¬†A. Burger, and J.¬†M√ºller.

</span>
<span class="ltx_bibblock">Focal unspecific bone uptake on [18f]-psma-1007 pet: a multicenter retrospective evaluation of the distribution, frequency, and quantitative parameters of a potential pitfall in prostate cancer imaging.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">European Journal of Nuclear Medicine and Molecular Imaging</span>, 48(13):4483‚Äì4494, December 2021.

</span>
<span class="ltx_bibblock">Epub 2021 Jun 13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Ziyan Huang, Haoyu Wang, Zhongying Deng, Jin Ye, Yanzhou Su, Hui Sun, Junjun He, Yun Gu, Lixu Gu, Shaoting Zhang, et¬†al.

</span>
<span class="ltx_bibblock">Stu-net: Scalable and transferable medical image segmentation models empowered by large-scale supervised pre-training.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2304.06716</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Fabian Isensee, Paul¬†F Jaeger, Simon¬†AA Kohl, Jens Petersen, and Klaus¬†H Maier-Hein.

</span>
<span class="ltx_bibblock">nnu-net: a self-configuring method for deep learning-based biomedical image segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Nature methods</span>, 18(2):203‚Äì211, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Fabian Isensee, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus Maier-Hein, and Paul¬†F Jaeger.

</span>
<span class="ltx_bibblock">nnu-net revisited: A call for rigorous validation in 3d medical image segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2404.09556</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Alexander Jaus, Constantin Seibold, Simon Rei√ü, Lukas Heine, Anton Schily, Moon Kim, Fin¬†Hendrik Bahnsen, Ken Herrmann, Rainer Stiefelhagen, and Jens Kleesiek.

</span>
<span class="ltx_bibblock">Anatomy-guided pathology segmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2407.05844</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Konstantin Jeblick et¬†al.

</span>
<span class="ltx_bibblock">A whole-body psma-pet/ct dataset with manually annotated tumor lesions (psma-pet-ct-lesions) (version 1) [dataset].

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.7937/r7ep-3x37" title="">https://doi.org/10.7937/r7ep-3x37</a>, 2024.

</span>
<span class="ltx_bibblock">The Cancer Imaging Archive.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Mads¬†Ry√∏ Jochumsen and Kirsten Bouchelouche.

</span>
<span class="ltx_bibblock">Psma pet/ct for primary staging of prostate cancer-an updated overview.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Seminars in Nuclear Medicine</span>, volume¬†54, pages 39‚Äì45. Elsevier, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Gowtham¬†Krishnan Murugesan, Eric Brunner, Rahul Soni, Diana McCrumb, Jithendra Kumar, Vasily Grigorash, Jeff Van¬†Oss, Stephen Moore, Anderson Peck, Kevin Maupin, et¬†al.

</span>
<span class="ltx_bibblock">Evaluating the effect of multilabel and single label models on prostate cancer lesion segmentation in ga-68 psma-11 pet/ct, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Gowtham¬†Krishnan Murugesan, Diana McCrumb, Eric Brunner, Jithendra Kumar, Rahul Soni, Vasily Grigorash, Stephen Moore, and Jeff Van¬†Oss.

</span>
<span class="ltx_bibblock">Improving lesion segmentation in fdg-18 whole-body pet/ct scans using multilabel approach: Autopet ii challenge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2311.01574</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J.¬†Schwenck, D.¬†Sonanini, J.¬†M. Cotton, H.¬†G. Rammensee, C.¬†la¬†Foug√®re, L.¬†Zender, and B.¬†J. Pichler.

</span>
<span class="ltx_bibblock">Advances in pet imaging of cancer.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Nature Reviews Cancer</span>, 23(7):474‚Äì490, July 2023.

</span>
<span class="ltx_bibblock">Epub 2023 May 31.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jakob Wasserthal, Hanns-Christian Breit, Manfred¬†T Meyer, Maurice Pradella, Daniel Hinck, Alexander¬†W Sauter, Tobias Heye, Daniel¬†T Boll, Joshy Cyriac, Shan Yang, et¬†al.

</span>
<span class="ltx_bibblock">Totalsegmentator: robust segmentation of 104 anatomic structures in ct images.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Radiology: Artificial Intelligence</span>, 5(5), 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 18 17:15:21 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
