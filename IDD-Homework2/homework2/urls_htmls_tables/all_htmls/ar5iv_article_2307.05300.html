<article class="ltx_document">
 <h1 class="ltx_title ltx_title_document">
  Unleashing the Emergent Cognitive Synergy in Large Language Models:
  <br class="ltx_break"/>
  A Task-Solving Agent through Multi-Persona Self-Collaboration
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Zhenhailong Wang
    <sup class="ltx_sup" id="id1.1.id1">
     1
    </sup>
    ,
Shaoguang Mao
    <sup class="ltx_sup" id="id2.2.id2">
     2
    </sup>
    ,
Wenshan Wu
    <sup class="ltx_sup" id="id3.3.id3">
     2
    </sup>
    ,
Tao Ge
    <sup class="ltx_sup" id="id4.4.id4">
     2
    </sup>
    ,
Furu Wei
    <sup class="ltx_sup" id="id5.5.id5">
     2
    </sup>
    ,
Heng Ji
    <sup class="ltx_sup" id="id6.6.id6">
     1
    </sup>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id7.7.id7">
     1
    </sup>
    University of Illinois Urbana-Champaign,
    <sup class="ltx_sup" id="id8.8.id8">
     2
    </sup>
    Microsoft Research Asia
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id9.9.id9">
     {wangz3,hengji}@illinois.edu
     <br class="ltx_break"/>
     {shaoguang.mao,wenshan.wu,tage,fuwei}@microsoft.com
    </span>
   </span>
   <span class="ltx_author_notes">
    Work was done when interning at Microsoft Research Asia.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id10.id1">
   Human intelligence thrives on cognitive synergy, where collaboration among different minds yield superior outcomes compared to isolated individuals.
In this work, we propose
   <span class="ltx_text ltx_font_bold" id="id10.id1.1">
    Solo Performance Prompting (
    <span class="ltx_text" id="id10.id1.1.1">
     SPP
    </span>
    )
   </span>
   , which transforms a single LLM into a
   <span class="ltx_text ltx_font_bold" id="id10.id1.2">
    cognitive synergist
   </span>
   by engaging in multi-turn self-collaboration with multiple personas.
A cognitive synergist is an intelligent agent that collaboratively combines multiple minds’ strengths and knowledge to enhance problem-solving in complex tasks.
By dynamically identifying and simulating different personas based on task inputs,
   <span class="ltx_text" id="id10.id1.3">
    SPP
   </span>
   unleashes the potential of cognitive synergy in LLMs.
Our in-depth analysis shows that assigning multiple fine-grained personas in LLMs improves problem-solving abilities compared to using a single or fixed number of personas.
We evaluate
   <span class="ltx_text" id="id10.id1.4">
    SPP
   </span>
   on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both
   <span class="ltx_text ltx_font_bold" id="id10.id1.5">
    knowledge-intensive
   </span>
   and
   <span class="ltx_text ltx_font_bold" id="id10.id1.6">
    reasoning-intensive
   </span>
   types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, experimental results demonstrate that
   <span class="ltx_text" id="id10.id1.7">
    SPP
   </span>
   effectively reduces factual hallucination, and maintains strong reasoning capabilities. Additionally, comparative experiments show that cognitive synergy only
   <span class="ltx_text ltx_font_bold" id="id10.id1.8">
    emerges
   </span>
   in GPT-4 and does not appear in less capable models, such as GPT-3.5-turbo and Llama2-13b-chat, which draws an interesting analogy to human development.
Code, data, and prompts can be found at:
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git" target="_blank" title="">
    https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git
   </a>
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p1">
  <div class="ltx_block ltx_align_bottom" id="p1.1">
   <p class="ltx_p" id="p1.1.1">
    <span class="ltx_text ltx_font_bold" id="p1.1.1.1">
     Unleashing the Emergent Cognitive Synergy in Large Language Models:
     <br class="ltx_break"/>
     A Task-Solving Agent through Multi-Persona Self-Collaboration
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
   <p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;">
    <span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
     <span class="ltx_tabular ltx_guessed_headers ltx_align_top" id="p1.1.2.1.1">
      <span class="ltx_thead">
       <span class="ltx_tr" id="p1.1.2.1.1.1.1">
        <span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.1.2.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
          Zhenhailong Wang
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.1.1">
            1
            <span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.1.1.1.1.1.1.1">
             <sup class="ltx_note_mark">
              †
             </sup>
             <span class="ltx_note_outer">
              <span class="ltx_note_content">
               <sup class="ltx_note_mark">
                †
               </sup>
               <span class="ltx_note_type">
                thanks:
               </span>
               <span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1.1.1.1.1">
                Work was done when interning at Microsoft Research Asia.
               </span>
              </span>
             </span>
            </span>
           </span>
          </sup>
          ,
Shaoguang Mao
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.2.1">
            2
           </span>
          </sup>
          ,
Wenshan Wu
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.3.1">
            2
           </span>
          </sup>
          ,
Tao Ge
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.4.1">
            2
           </span>
          </sup>
          ,
Furu Wei
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.5">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.5.1">
            2
           </span>
          </sup>
          ,
Heng Ji
          <sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.6">
           <span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.6.1">
            1
           </span>
          </sup>
         </span>
        </span>
       </span>
       <span class="ltx_tr" id="p1.1.2.1.1.2.2">
        <span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.1.2.1.1.2.2.1">
         <sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1">
          1
         </sup>
         University of Illinois Urbana-Champaign,
         <sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.2">
          2
         </sup>
         Microsoft Research Asia
        </span>
       </span>
      </span>
      <span class="ltx_tbody">
       <span class="ltx_tr" id="p1.1.2.1.1.3.1">
        <span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.1.1">
         <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.1.1.1">
          {wangz3,hengji}@illinois.edu
         </span>
        </span>
       </span>
       <span class="ltx_tr" id="p1.1.2.1.1.4.2">
        <span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.2.1">
         <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.2.1.1">
          {shaoguang.mao,wenshan.wu,tage,fuwei}@microsoft.com
         </span>
        </span>
       </span>
      </span>
     </span>
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
  </div>
 </div>
 <figure class="ltx_figure" id="S0.F1">
  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="198" id="S0.F1.g1" src="/html/2307.05300/assets/x1.png" width="207"/>
  <figcaption class="ltx_caption ltx_centering">
   <span class="ltx_tag ltx_tag_figure">
    Figure 1:
   </span>
   Schematic illustration of Solo Performance Prompting (
   <span class="ltx_text" id="S0.F1.2.1">
    SPP
   </span>
   ) and the difference compared to previous prompting methods.
  </figcaption>
 </figure>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <figure class="ltx_figure" id="S1.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="291" id="S1.F2.g1" src="/html/2307.05300/assets/x2.png" width="424"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    Task-solving example of Solo Performance Prompting (
    <span class="ltx_text" id="S1.F2.3.1">
     SPP
    </span>
    ) with GPT-4. The personas of the participants are automatically identified by GPT-4 based on the task input. This example shows that Standard Prompting suffers from factual errors, whereas
    <span class="ltx_text" id="S1.F2.4.2">
     SPP
    </span>
    provides accurate information and a coherent answer. Note that, in real-world applications, the domains can vary not only within entertainment but also encompass history, science, education, healthcare, etc.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Although large language models (LLMs) have demonstrated impressive performance as general task-solving agents, they still encounter challenges
    <cite class="ltx_cite ltx_citemacro_citep">
     (Qin et al.,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023
     </a>
     ; Bang et al.,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2023
     </a>
     ; OpenAI,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023b
     </a>
     ; Bubeck et al.,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2023
     </a>
     )
    </cite>
    in various knowledge-intensive and reasoning-intensive tasks due to factual hallucination
    <cite class="ltx_cite ltx_citemacro_citep">
     (Maynez et al.,
     <a class="ltx_ref" href="#bib.bib22" title="">
      2020
     </a>
     )
    </cite>
    and a lack of slow-thinking
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sloman,
     <a class="ltx_ref" href="#bib.bib33" title="">
      1996
     </a>
     )
    </cite>
    capabilities.
Unlike humans, who can leverage the power of collaboration and information integration among different cognitive processes and individuals (referred to as
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">
     cognitive synergy
    </span>
    <cite class="ltx_cite ltx_citemacro_citep">
     (Curşeu et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2015
     </a>
     ; Goertzel,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2009
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2017
     </a>
     )
    </cite>
    ), current LLMs are akin to "jack-of-all-trades" with a vast mixture of knowledge and characteristics.
Recent advancements, such as Chain-of-Thought (CoT) prompting
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     ; Kojima et al.,
     <a class="ltx_ref" href="#bib.bib19" title="">
      2022
     </a>
     )
    </cite>
    and Self-refinement
    <cite class="ltx_cite ltx_citemacro_citep">
     (Madaan et al.,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2023
     </a>
     ; Shinn et al.,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2023
     </a>
     )
    </cite>
    , have successfully enhanced the reasoning abilities of LLMs by simulating slow-thinking through the generation of intermediate steps or iterative revision. However, factual hallucination remains a major challenge for LLMs on knowledge-intensive tasks.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    A cognitive synergist is an intelligent agent that collaborates with multiple minds to enhance problem-solving and efficacy in complex tasks.
In this work, we aim to
    <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">
     create a cognitive synergist based on a single LLM
    </span>
    that can
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">
     "split into" multiple personas and engage in self-collaboration to solve both knowledge-intensive and reasoning-intensive tasks
    </span>
    .
This idea is heavily inspired by the role of pretend play
    <cite class="ltx_cite ltx_citemacro_citep">
     (Piaget,
     <a class="ltx_ref" href="#bib.bib28" title="">
      1954
     </a>
     ; Pellegrini,
     <a class="ltx_ref" href="#bib.bib27" title="">
      2009
     </a>
     )
    </cite>
    in cognitive development and recent findings that assigning personas
    <cite class="ltx_cite ltx_citemacro_citep">
     (Deshpande et al.,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     ; Xu et al.,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     )
    </cite>
    to LLMs can elicit specific behaviors, improve answer quality, and potentially build an AI society
    <cite class="ltx_cite ltx_citemacro_cite">
     Park et al. (
     <a class="ltx_ref" href="#bib.bib26" title="">
      2023
     </a>
     ); Schick et al. (
     <a class="ltx_ref" href="#bib.bib30" title="">
      2022
     </a>
     ); Li et al. (
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023
     </a>
     ); Cai et al. (
     <a class="ltx_ref" href="#bib.bib6" title="">
      2023
     </a>
     )
    </cite>
    with collaborative LLM agents. However, as shown in Table
    <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , previous works have limitations such as fixed or task-specific personas, the need for additional fine-tuning, and increased inference costs due to multiple LLM instances.
   </p>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.69" style="width:411.9pt;height:121.7pt;vertical-align:-0.5pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-201.0pt,59.1pt) scale(0.506105340710864,0.506105340710864) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.69.69">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S1.T1.69.69.70.1">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S1.T1.69.69.70.1.1">
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.2">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.2.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.2.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.2.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.2.1.1.1.1">
             General task
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.2.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.2.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.2.1.2.1.1">
             solving?
            </span>
           </td>
          </tr>
         </table>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.3">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.3.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.3.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.3.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.3.1.1.1.1">
             Pure zero-shot
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.3.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.3.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.3.1.2.1.1">
             prompting?
            </span>
           </td>
          </tr>
         </table>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.4">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.4.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.4.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.4.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.4.1.1.1.1">
             Has multiple
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.4.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.4.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.4.1.2.1.1">
             personas?
            </span>
           </td>
          </tr>
         </table>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.5">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.5.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.5.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.5.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.5.1.1.1.1">
             Personas dynamically
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.5.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.5.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.5.1.2.1.1">
             identified?
            </span>
           </td>
          </tr>
         </table>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.6">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.6.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.6.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.6.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.6.1.1.1.1">
             Has iterative
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.6.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.6.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.6.1.2.1.1">
             refinement?
            </span>
           </td>
          </tr>
         </table>
        </th>
        <th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.69.69.70.1.7">
         <table class="ltx_tabular ltx_align_middle" id="S1.T1.69.69.70.1.7.1">
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.7.1.1">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.7.1.1.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.7.1.1.1.1">
             Need only a
            </span>
           </td>
          </tr>
          <tr class="ltx_tr" id="S1.T1.69.69.70.1.7.1.2">
           <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.69.69.70.1.7.1.2.1">
            <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.70.1.7.1.2.1.1">
             single LLM?
            </span>
           </td>
          </tr>
         </table>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S1.T1.7.7.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.1.1.1">
         <math alttext="\dagger" class="ltx_Math" display="inline" id="S1.T1.1.1.1.1.m1.1">
          <semantics id="S1.T1.1.1.1.1.m1.1a">
           <mo id="S1.T1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.m1.1.1.cmml">
            †
           </mo>
           <annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.m1.1b">
            <ci id="S1.T1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.m1.1.1">
             †
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.m1.1c">
            \dagger
           </annotation>
          </semantics>
         </math>
         Standard Prompting
         <cite class="ltx_cite ltx_citemacro_cite">
          Brown et al. (
          <a class="ltx_ref" href="#bib.bib4" title="">
           2020
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.2.2.2.2">
         <span class="ltx_text" id="S1.T1.2.2.2.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.2.2.2.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.3.3">
         <span class="ltx_text" id="S1.T1.3.3.3.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.3.3.3.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.4.4.4">
         <span class="ltx_text" id="S1.T1.4.4.4.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.4.4.4.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.5.5.5">
         <span class="ltx_text" id="S1.T1.5.5.5.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.5.5.5.5.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.6.6.6.6">
         <span class="ltx_text" id="S1.T1.6.6.6.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.6.6.6.6.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S1.T1.7.7.7.7">
         <span class="ltx_text" id="S1.T1.7.7.7.7.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.7.7.7.7.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.14.14.14">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.8.8.8.1">
         <math alttext="\dagger" class="ltx_Math" display="inline" id="S1.T1.8.8.8.1.m1.1">
          <semantics id="S1.T1.8.8.8.1.m1.1a">
           <mo id="S1.T1.8.8.8.1.m1.1.1" xref="S1.T1.8.8.8.1.m1.1.1.cmml">
            †
           </mo>
           <annotation-xml encoding="MathML-Content" id="S1.T1.8.8.8.1.m1.1b">
            <ci id="S1.T1.8.8.8.1.m1.1.1.cmml" xref="S1.T1.8.8.8.1.m1.1.1">
             †
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S1.T1.8.8.8.1.m1.1c">
            \dagger
           </annotation>
          </semantics>
         </math>
         Chain-of-Thought
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wei et al.,
          <a class="ltx_ref" href="#bib.bib37" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.9.9.9.2">
         <span class="ltx_text" id="S1.T1.9.9.9.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.9.9.9.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.10.10.10.3">
         <span class="ltx_text" id="S1.T1.10.10.10.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.10.10.10.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.11.11.11.4">
         <span class="ltx_text" id="S1.T1.11.11.11.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.11.11.11.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.12.12.12.5">
         <span class="ltx_text" id="S1.T1.12.12.12.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.12.12.12.5.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.13.13.13.6">
         <span class="ltx_text" id="S1.T1.13.13.13.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.13.13.13.6.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.14.14.14.7">
         <span class="ltx_text" id="S1.T1.14.14.14.7.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.14.14.14.7.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.20.20.20">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.20.20.20.7">
         Inner Monologue
         <cite class="ltx_cite ltx_citemacro_citep">
          (Huang et al.,
          <a class="ltx_ref" href="#bib.bib15" title="">
           2022
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.15.15.15.1">
         <span class="ltx_text" id="S1.T1.15.15.15.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.15.15.15.1.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.16.16.16.2">
         <span class="ltx_text" id="S1.T1.16.16.16.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.16.16.16.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.17.17.17.3">
         <span class="ltx_text" id="S1.T1.17.17.17.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.17.17.17.3.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.18.18.18.4">
         <span class="ltx_text" id="S1.T1.18.18.18.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.18.18.18.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.19.19.19.5">
         <span class="ltx_text" id="S1.T1.19.19.19.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.19.19.19.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.20.20.20.6">
         <span class="ltx_text" id="S1.T1.20.20.20.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.20.20.20.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.26.26.26">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.26.26.26.7">
         ReAct
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yao et al.,
          <a class="ltx_ref" href="#bib.bib41" title="">
           2022
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.21.21.21.1">
         <span class="ltx_text" id="S1.T1.21.21.21.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.21.21.21.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.22.22.22.2">
         <span class="ltx_text" id="S1.T1.22.22.22.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.22.22.22.2.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.23.23.23.3">
         <span class="ltx_text" id="S1.T1.23.23.23.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.23.23.23.3.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.24.24.24.4">
         <span class="ltx_text" id="S1.T1.24.24.24.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.24.24.24.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.25.25.25.5">
         <span class="ltx_text" id="S1.T1.25.25.25.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.25.25.25.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.26.26.26.6">
         <span class="ltx_text" id="S1.T1.26.26.26.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.26.26.26.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.32.32.32">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.32.32.32.7">
         Reflexion
         <cite class="ltx_cite ltx_citemacro_citep">
          (Shinn et al.,
          <a class="ltx_ref" href="#bib.bib31" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.27.27.27.1">
         <span class="ltx_text" id="S1.T1.27.27.27.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.27.27.27.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.28.28.28.2">
         <span class="ltx_text" id="S1.T1.28.28.28.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.28.28.28.2.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.29.29.29.3">
         <span class="ltx_text" id="S1.T1.29.29.29.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.29.29.29.3.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.30.30.30.4">
         <span class="ltx_text" id="S1.T1.30.30.30.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.30.30.30.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.31.31.31.5">
         <span class="ltx_text" id="S1.T1.31.31.31.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.31.31.31.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.32.32.32.6">
         <span class="ltx_text" id="S1.T1.32.32.32.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.32.32.32.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.39.39.39">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.33.33.33.1">
         <math alttext="\dagger" class="ltx_Math" display="inline" id="S1.T1.33.33.33.1.m1.1">
          <semantics id="S1.T1.33.33.33.1.m1.1a">
           <mo id="S1.T1.33.33.33.1.m1.1.1" xref="S1.T1.33.33.33.1.m1.1.1.cmml">
            †
           </mo>
           <annotation-xml encoding="MathML-Content" id="S1.T1.33.33.33.1.m1.1b">
            <ci id="S1.T1.33.33.33.1.m1.1.1.cmml" xref="S1.T1.33.33.33.1.m1.1.1">
             †
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S1.T1.33.33.33.1.m1.1c">
            \dagger
           </annotation>
          </semantics>
         </math>
         Self-Refine
         <cite class="ltx_cite ltx_citemacro_citep">
          (Madaan et al.,
          <a class="ltx_ref" href="#bib.bib21" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.34.34.34.2">
         <span class="ltx_text" id="S1.T1.34.34.34.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.34.34.34.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.35.35.35.3">
         <span class="ltx_text" id="S1.T1.35.35.35.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.35.35.35.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.36.36.36.4">
         <span class="ltx_text" id="S1.T1.36.36.36.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.36.36.36.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.37.37.37.5">
         <span class="ltx_text" id="S1.T1.37.37.37.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.37.37.37.5.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.38.38.38.6">
         <span class="ltx_text" id="S1.T1.38.38.38.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.38.38.38.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.39.39.39.7">
         <span class="ltx_text" id="S1.T1.39.39.39.7.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.39.39.39.7.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.45.45.45">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.45.45.45.7">
         Tree-of-thought
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yao et al.,
          <a class="ltx_ref" href="#bib.bib40" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.40.40.40.1">
         <span class="ltx_text" id="S1.T1.40.40.40.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.40.40.40.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.41.41.41.2">
         <span class="ltx_text" id="S1.T1.41.41.41.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.41.41.41.2.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.42.42.42.3">
         <span class="ltx_text" id="S1.T1.42.42.42.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.42.42.42.3.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.43.43.43.4">
         <span class="ltx_text" id="S1.T1.43.43.43.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.43.43.43.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.44.44.44.5">
         <span class="ltx_text" id="S1.T1.44.44.44.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.44.44.44.5.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.45.45.45.6">
         <span class="ltx_text" id="S1.T1.45.45.45.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.45.45.45.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.51.51.51">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.51.51.51.7">
         GPT-Bargaining
         <cite class="ltx_cite ltx_citemacro_citep">
          (Fu et al.,
          <a class="ltx_ref" href="#bib.bib10" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.46.46.46.1">
         <span class="ltx_text" id="S1.T1.46.46.46.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.46.46.46.1.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.47.47.47.2">
         <span class="ltx_text" id="S1.T1.47.47.47.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.47.47.47.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.48.48.48.3">
         <span class="ltx_text" id="S1.T1.48.48.48.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.48.48.48.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
         (fixed to 3)
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.49.49.49.4">
         <span class="ltx_text" id="S1.T1.49.49.49.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.49.49.49.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.50.50.50.5">
         <span class="ltx_text" id="S1.T1.50.50.50.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.50.50.50.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.51.51.51.6">
         <span class="ltx_text" id="S1.T1.51.51.51.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.51.51.51.6.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.57.57.57">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.57.57.57.7">
         Camel
         <cite class="ltx_cite ltx_citemacro_citep">
          (Li et al.,
          <a class="ltx_ref" href="#bib.bib20" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.52.52.52.1">
         <span class="ltx_text" id="S1.T1.52.52.52.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.52.52.52.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.53.53.53.2">
         <span class="ltx_text" id="S1.T1.53.53.53.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.53.53.53.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.54.54.54.3">
         <span class="ltx_text" id="S1.T1.54.54.54.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.54.54.54.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
         (fixed to 2)
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.55.55.55.4">
         <span class="ltx_text" id="S1.T1.55.55.55.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.55.55.55.4.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.56.56.56.5">
         <span class="ltx_text" id="S1.T1.56.56.56.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.56.56.56.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.57.57.57.6">
         <span class="ltx_text" id="S1.T1.57.57.57.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.57.57.57.6.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.63.63.63">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.63.63.63.7">
         ExpertPrompting
         <cite class="ltx_cite ltx_citemacro_citep">
          (Xu et al.,
          <a class="ltx_ref" href="#bib.bib38" title="">
           2023
          </a>
          )
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.58.58.58.1">
         <span class="ltx_text" id="S1.T1.58.58.58.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.58.58.58.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.59.59.59.2">
         <span class="ltx_text" id="S1.T1.59.59.59.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.59.59.59.2.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.60.60.60.3">
         <span class="ltx_text" id="S1.T1.60.60.60.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.60.60.60.3.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.61.61.61.4">
         <span class="ltx_text" id="S1.T1.61.61.61.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.61.61.61.4.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.62.62.62.5">
         <span class="ltx_text" id="S1.T1.62.62.62.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.62.62.62.5.1.g1" src="/html/2307.05300/assets/images/emojis/cross.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.63.63.63.6">
         <span class="ltx_text" id="S1.T1.63.63.63.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.63.63.63.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.69.69.69">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S1.T1.69.69.69.7">
         <span class="ltx_text ltx_font_bold" id="S1.T1.69.69.69.7.1">
          Solo Performance Prompting (ours)
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.64.64.64.1">
         <span class="ltx_text" id="S1.T1.64.64.64.1.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.64.64.64.1.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.65.65.65.2">
         <span class="ltx_text" id="S1.T1.65.65.65.2.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.65.65.65.2.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.66.66.66.3">
         <span class="ltx_text" id="S1.T1.66.66.66.3.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.66.66.66.3.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
         (varied)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.67.67.67.4">
         <span class="ltx_text" id="S1.T1.67.67.67.4.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.67.67.67.4.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.68.68.68.5">
         <span class="ltx_text" id="S1.T1.68.68.68.5.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.68.68.68.5.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
        <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S1.T1.69.69.69.6">
         <span class="ltx_text" id="S1.T1.69.69.69.6.1" style="position:relative; bottom:-0.2pt;">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="17" id="S1.T1.69.69.69.6.1.g1" src="/html/2307.05300/assets/images/emojis/check.png" width="17"/>
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    High-level comparison with various prompting-based methods. Methods directly comparable to ours are denoted by
    <math alttext="\dagger" class="ltx_Math" display="inline" id="S1.T1.71.m1.1">
     <semantics id="S1.T1.71.m1.1b">
      <mo id="S1.T1.71.m1.1.1" xref="S1.T1.71.m1.1.1.cmml">
       †
      </mo>
      <annotation-xml encoding="MathML-Content" id="S1.T1.71.m1.1c">
       <ci id="S1.T1.71.m1.1.1.cmml" xref="S1.T1.71.m1.1.1">
        †
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.T1.71.m1.1d">
       \dagger
      </annotation>
     </semantics>
    </math>
    . Results for the comparison can be found in Section
    <a class="ltx_ref" href="#S3" title="3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    . In Section
    <a class="ltx_ref" href="#S4" title="4 Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    , we further design and compare with two variants of Solo Performance Prompting: one adopting fixed personas, as in Camel
    <cite class="ltx_cite ltx_citemacro_citep">
     (Li et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023
     </a>
     )
    </cite>
    , and another with additional persona profiles, as proposed in ExpertPrompting
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xu et al.,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     )
    </cite>
    .
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    To unleash the potential of cognitive synergy for general task-solving, we propose
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">
     Solo Performance Prompting
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">
     (
     <span class="ltx_text" id="S1.p3.1.2.1">
      SPP
     </span>
     )
    </span>
    , which
    <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">
     prompts a single LLM to identify, simulate, and collaborate with multiple personas
    </span>
    . Figure
    <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    provides a high-level overview of
    <span class="ltx_text" id="S1.p3.1.4">
     SPP
    </span>
    .
Here, a persona can represent either a domain expert, such as a movie enthusiast, or a target audience, such as a ten-year-old child.
Through the dynamic identification of various personas, we empower a single LLM to acquire diverse domain knowledge accurately without additional retrieval systems.
By facilitating multi-turn self-collaboration, we enable self-revision and self-feedback from various perspectives without requiring additional agents.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    In real-world scenarios, such as those in creative industries, there is often a need to incorporate diverse information from different domains. Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    presents a concrete example of how
    <span class="ltx_text" id="S1.p4.1.1">
     SPP
    </span>
    operates on a challenging task that requires creative integration of information from various domains, such as the Legend of Zelda game, Harry Potter movies, and Jay Chou’s albums.
Standard prompting fails to generate satisfactory output due to missing essential information and factual errors. In contrast,
    <span class="ltx_text" id="S1.p4.1.2">
     SPP
    </span>
    produces informative and coherent answers by automatically identifying expert personas and engaging in a multi-turn self-collaboration. In this process, the AI Assistant persona iteratively writes drafts of the story, solicits feedback from other participants, and revises accordingly.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    To explore the prevalence of cognitive synergy in different LLMs, we apply
    <span class="ltx_text" id="S1.p5.1.1">
     SPP
    </span>
    to LLMs with varying scales and capabilities, including GPT-4, GPT-3.5-turbo, and Llama-13b-chat. Comparative results show that cognitive synergy only emerges in GPT-4 and not in less capable models. This draws an interesting analogy to human development, as children typically start engaging in role-playing at the age of 2 to 3
    <cite class="ltx_cite ltx_citemacro_cite">
     Piaget (
     <a class="ltx_ref" href="#bib.bib28" title="">
      1954
     </a>
     )
    </cite>
    , but not earlier.
In summary, the key contributions of this paper are as follows:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We investigate whether LLMs can leveraging cognitive synergy for general task-solving. We introduce
       <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">
        Solo Performance Prompting (
        <span class="ltx_text" id="S1.I1.i1.p1.1.1.1">
         SPP
        </span>
        )
       </span>
       , which simulates multi-agent, multi-persona collaboration in a pure zero-shot manner.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We evaluate
       <span class="ltx_text" id="S1.I1.i2.p1.1.1">
        SPP
       </span>
       across
       <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.2">
        three challenging tasks
       </span>
       : Trivia Creative Writing, Codenames Collaborative and Logic Grid Puzzle, spanning both knowledge- and reasoning-intensive domains. To our knowledge,
       <span class="ltx_text" id="S1.I1.i2.p1.1.3">
        SPP
       </span>
       is the first zero-shot prompting method that can enhance both knowledge and reasoning abilities on GPT-4.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       We present an intriguing finding regarding the emergent nature of cognitive synergy ability in LLMs, which
       <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">
        only emerges in GPT-4
       </span>
       and not in less powerful models.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i4.p1">
      <p class="ltx_p" id="S1.I1.i4.p1.1">
       We conduct in-depth analyses of the impact of the identified personas and
       <span class="ltx_text" id="S1.I1.i4.p1.1.1">
        SPP
       </span>
       prompt design, providing insights into why
       <span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.2">
        dynamic, fine-grained personas
       </span>
       are necessary, as opposed to fixed, coarse-grained personas.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Solo Performance Prompting
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    To unleash the power of synergizing different personas to tackle complex problems, we propose Solo Performance Prompting (
    <span class="ltx_text" id="S2.p1.1.1">
     SPP
    </span>
    ) which instructs a LLM to perform the following the procedure for general task-solving:
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">
     (1) Persona Identification
    </span>
    : Identify multiple participants with special personas (including a leader persona: AI Assistant) that are essential for solving the particular task.
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.3">
     (2) Brainstorming
    </span>
    : The participants share knowledge and provide suggestions on how to approach the task based on their own expertise.
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.4">
     (3) Multi-Persona Iterative Collaboration
    </span>
    : The leader persona, AI Assistant, proposes initial solutions, consults the other participants for feedback, and revise the answer iteratively. Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    shows a walking example of
    <span class="ltx_text" id="S2.p1.1.5">
     SPP
    </span>
    during inference. Next, we formally describe the
    <span class="ltx_text" id="S2.p1.1.6">
     SPP
    </span>
    procedure in detail.
   </p>
  </div>
  <div class="ltx_para" id="S2.p2">
   <p class="ltx_p" id="S2.p2.6">
    Given an input sequence
    <math alttext="x" class="ltx_Math" display="inline" id="S2.p2.1.m1.1">
     <semantics id="S2.p2.1.m1.1a">
      <mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">
       x
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b">
       <ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">
        𝑥
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">
       x
      </annotation>
     </semantics>
    </math>
    and a model
    <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p2.2.m2.1">
     <semantics id="S2.p2.2.m2.1a">
      <mi class="ltx_font_mathcaligraphic" id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">
       ℳ
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b">
       <ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">
        ℳ
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">
       \mathcal{M}
      </annotation>
     </semantics>
    </math>
    , let a prompt (including demonstration examples) prepended to the input to be
    <math alttext="p" class="ltx_Math" display="inline" id="S2.p2.3.m3.1">
     <semantics id="S2.p2.3.m3.1a">
      <mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">
       p
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b">
       <ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">
        𝑝
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">
       p
      </annotation>
     </semantics>
    </math>
    and the final output to be
    <math alttext="y" class="ltx_Math" display="inline" id="S2.p2.4.m4.1">
     <semantics id="S2.p2.4.m4.1a">
      <mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">
       y
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b">
       <ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">
        𝑦
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">
       y
      </annotation>
     </semantics>
    </math>
    . Denote an intermediate generation before generating the final
    <math alttext="y" class="ltx_Math" display="inline" id="S2.p2.5.m5.1">
     <semantics id="S2.p2.5.m5.1a">
      <mi id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">
       y
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b">
       <ci id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">
        𝑦
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">
       y
      </annotation>
     </semantics>
    </math>
    as
    <math alttext="z" class="ltx_Math" display="inline" id="S2.p2.6.m6.1">
     <semantics id="S2.p2.6.m6.1a">
      <mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">
       z
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b">
       <ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">
        𝑧
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">
       z
      </annotation>
     </semantics>
    </math>
    . Under this formulation, Standard Prompting and Chain-of-Thought (CoT) Prompting can be described as:
   </p>
   <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A7.EGx1">
    <tbody id="S2.E1">
     <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
      <td class="ltx_eqn_cell ltx_eqn_center_padleft">
      </td>
      <td class="ltx_eqn_cell ltx_align_center">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_center_padright">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0">
       <span class="ltx_tag ltx_tag_equation ltx_align_right">
        (1)
       </span>
      </td>
     </tr>
    </tbody>
    <tbody id="S2.E2">
     <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
      <td class="ltx_eqn_cell ltx_eqn_center_padleft">
      </td>
      <td class="ltx_eqn_cell ltx_align_center">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_center_padright">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0">
       <span class="ltx_tag ltx_tag_equation ltx_align_right">
        (2)
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="ltx_p" id="S2.p2.8">
    where
    <math alttext="p_{cot}" class="ltx_Math" display="inline" id="S2.p2.7.m1.1">
     <semantics id="S2.p2.7.m1.1a">
      <msub id="S2.p2.7.m1.1.1" xref="S2.p2.7.m1.1.1.cmml">
       <mi id="S2.p2.7.m1.1.1.2" xref="S2.p2.7.m1.1.1.2.cmml">
        p
       </mi>
       <mrow id="S2.p2.7.m1.1.1.3" xref="S2.p2.7.m1.1.1.3.cmml">
        <mi id="S2.p2.7.m1.1.1.3.2" xref="S2.p2.7.m1.1.1.3.2.cmml">
         c
        </mi>
        <mo id="S2.p2.7.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S2.p2.7.m1.1.1.3.1.cmml">
         ​
        </mo>
        <mi id="S2.p2.7.m1.1.1.3.3" xref="S2.p2.7.m1.1.1.3.3.cmml">
         o
        </mi>
        <mo id="S2.p2.7.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S2.p2.7.m1.1.1.3.1.cmml">
         ​
        </mo>
        <mi id="S2.p2.7.m1.1.1.3.4" xref="S2.p2.7.m1.1.1.3.4.cmml">
         t
        </mi>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.7.m1.1b">
       <apply id="S2.p2.7.m1.1.1.cmml" xref="S2.p2.7.m1.1.1">
        <csymbol cd="ambiguous" id="S2.p2.7.m1.1.1.1.cmml" xref="S2.p2.7.m1.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.7.m1.1.1.2.cmml" xref="S2.p2.7.m1.1.1.2">
         𝑝
        </ci>
        <apply id="S2.p2.7.m1.1.1.3.cmml" xref="S2.p2.7.m1.1.1.3">
         <times id="S2.p2.7.m1.1.1.3.1.cmml" xref="S2.p2.7.m1.1.1.3.1">
         </times>
         <ci id="S2.p2.7.m1.1.1.3.2.cmml" xref="S2.p2.7.m1.1.1.3.2">
          𝑐
         </ci>
         <ci id="S2.p2.7.m1.1.1.3.3.cmml" xref="S2.p2.7.m1.1.1.3.3">
          𝑜
         </ci>
         <ci id="S2.p2.7.m1.1.1.3.4.cmml" xref="S2.p2.7.m1.1.1.3.4">
          𝑡
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.7.m1.1c">
       p_{cot}
      </annotation>
     </semantics>
    </math>
    is the CoT prompt, e.g.,
    <span class="ltx_text ltx_font_typewriter" id="S2.p2.8.1">
     "Solve the task step-by-step"
    </span>
    and
    <math alttext="\{z_{1},z_{2}...,z_{n}\}" class="ltx_Math" display="inline" id="S2.p2.8.m2.3">
     <semantics id="S2.p2.8.m2.3a">
      <mrow id="S2.p2.8.m2.3.3.3" xref="S2.p2.8.m2.3.3.4.cmml">
       <mo id="S2.p2.8.m2.3.3.3.4" stretchy="false" xref="S2.p2.8.m2.3.3.4.cmml">
        {
       </mo>
       <msub id="S2.p2.8.m2.1.1.1.1" xref="S2.p2.8.m2.1.1.1.1.cmml">
        <mi id="S2.p2.8.m2.1.1.1.1.2" xref="S2.p2.8.m2.1.1.1.1.2.cmml">
         z
        </mi>
        <mn id="S2.p2.8.m2.1.1.1.1.3" xref="S2.p2.8.m2.1.1.1.1.3.cmml">
         1
        </mn>
       </msub>
       <mo id="S2.p2.8.m2.3.3.3.5" xref="S2.p2.8.m2.3.3.4.cmml">
        ,
       </mo>
       <mrow id="S2.p2.8.m2.2.2.2.2" xref="S2.p2.8.m2.2.2.2.2.cmml">
        <msub id="S2.p2.8.m2.2.2.2.2.2" xref="S2.p2.8.m2.2.2.2.2.2.cmml">
         <mi id="S2.p2.8.m2.2.2.2.2.2.2" xref="S2.p2.8.m2.2.2.2.2.2.2.cmml">
          z
         </mi>
         <mn id="S2.p2.8.m2.2.2.2.2.2.3" xref="S2.p2.8.m2.2.2.2.2.2.3.cmml">
          2
         </mn>
        </msub>
        <mo id="S2.p2.8.m2.2.2.2.2.1" lspace="0em" rspace="0em" xref="S2.p2.8.m2.2.2.2.2.1.cmml">
         ​
        </mo>
        <mi id="S2.p2.8.m2.2.2.2.2.3" mathvariant="normal" xref="S2.p2.8.m2.2.2.2.2.3.cmml">
         …
        </mi>
       </mrow>
       <mo id="S2.p2.8.m2.3.3.3.6" xref="S2.p2.8.m2.3.3.4.cmml">
        ,
       </mo>
       <msub id="S2.p2.8.m2.3.3.3.3" xref="S2.p2.8.m2.3.3.3.3.cmml">
        <mi id="S2.p2.8.m2.3.3.3.3.2" xref="S2.p2.8.m2.3.3.3.3.2.cmml">
         z
        </mi>
        <mi id="S2.p2.8.m2.3.3.3.3.3" xref="S2.p2.8.m2.3.3.3.3.3.cmml">
         n
        </mi>
       </msub>
       <mo id="S2.p2.8.m2.3.3.3.7" stretchy="false" xref="S2.p2.8.m2.3.3.4.cmml">
        }
       </mo>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S2.p2.8.m2.3b">
       <set id="S2.p2.8.m2.3.3.4.cmml" xref="S2.p2.8.m2.3.3.3">
        <apply id="S2.p2.8.m2.1.1.1.1.cmml" xref="S2.p2.8.m2.1.1.1.1">
         <csymbol cd="ambiguous" id="S2.p2.8.m2.1.1.1.1.1.cmml" xref="S2.p2.8.m2.1.1.1.1">
          subscript
         </csymbol>
         <ci id="S2.p2.8.m2.1.1.1.1.2.cmml" xref="S2.p2.8.m2.1.1.1.1.2">
          𝑧
         </ci>
         <cn id="S2.p2.8.m2.1.1.1.1.3.cmml" type="integer" xref="S2.p2.8.m2.1.1.1.1.3">
          1
         </cn>
        </apply>
        <apply id="S2.p2.8.m2.2.2.2.2.cmml" xref="S2.p2.8.m2.2.2.2.2">
         <times id="S2.p2.8.m2.2.2.2.2.1.cmml" xref="S2.p2.8.m2.2.2.2.2.1">
         </times>
         <apply id="S2.p2.8.m2.2.2.2.2.2.cmml" xref="S2.p2.8.m2.2.2.2.2.2">
          <csymbol cd="ambiguous" id="S2.p2.8.m2.2.2.2.2.2.1.cmml" xref="S2.p2.8.m2.2.2.2.2.2">
           subscript
          </csymbol>
          <ci id="S2.p2.8.m2.2.2.2.2.2.2.cmml" xref="S2.p2.8.m2.2.2.2.2.2.2">
           𝑧
          </ci>
          <cn id="S2.p2.8.m2.2.2.2.2.2.3.cmml" type="integer" xref="S2.p2.8.m2.2.2.2.2.2.3">
           2
          </cn>
         </apply>
         <ci id="S2.p2.8.m2.2.2.2.2.3.cmml" xref="S2.p2.8.m2.2.2.2.2.3">
          …
         </ci>
        </apply>
        <apply id="S2.p2.8.m2.3.3.3.3.cmml" xref="S2.p2.8.m2.3.3.3.3">
         <csymbol cd="ambiguous" id="S2.p2.8.m2.3.3.3.3.1.cmml" xref="S2.p2.8.m2.3.3.3.3">
          subscript
         </csymbol>
         <ci id="S2.p2.8.m2.3.3.3.3.2.cmml" xref="S2.p2.8.m2.3.3.3.3.2">
          𝑧
         </ci>
         <ci id="S2.p2.8.m2.3.3.3.3.3.cmml" xref="S2.p2.8.m2.3.3.3.3.3">
          𝑛
         </ci>
        </apply>
       </set>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.8.m2.3c">
       \{z_{1},z_{2}...,z_{n}\}
      </annotation>
     </semantics>
    </math>
    are the intermediate steps. In contrast, our proposed Solo Performance Prompting can be described as follows:
   </p>
   <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A7.EGx2">
    <tbody id="S2.Ex1">
     <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
      <td class="ltx_eqn_cell ltx_eqn_center_padleft">
      </td>
      <td class="ltx_eqn_cell ltx_align_center">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_center_padright">
      </td>
     </tr>
    </tbody>
    <tbody id="S2.E3">
     <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
      <td class="ltx_eqn_cell ltx_eqn_center_padleft">
      </td>
      <td class="ltx_eqn_cell ltx_align_center">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_center_padright">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0">
       <span class="ltx_tag ltx_tag_equation ltx_align_right">
        (3)
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="ltx_p" id="S2.p2.10">
    where the
    <span class="ltx_text" id="S2.p2.10.1">
     SPP
    </span>
    prompt (
    <math alttext="p_{spp}" class="ltx_Math" display="inline" id="S2.p2.9.m1.1">
     <semantics id="S2.p2.9.m1.1a">
      <msub id="S2.p2.9.m1.1.1" xref="S2.p2.9.m1.1.1.cmml">
       <mi id="S2.p2.9.m1.1.1.2" xref="S2.p2.9.m1.1.1.2.cmml">
        p
       </mi>
       <mrow id="S2.p2.9.m1.1.1.3" xref="S2.p2.9.m1.1.1.3.cmml">
        <mi id="S2.p2.9.m1.1.1.3.2" xref="S2.p2.9.m1.1.1.3.2.cmml">
         s
        </mi>
        <mo id="S2.p2.9.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S2.p2.9.m1.1.1.3.1.cmml">
         ​
        </mo>
        <mi id="S2.p2.9.m1.1.1.3.3" xref="S2.p2.9.m1.1.1.3.3.cmml">
         p
        </mi>
        <mo id="S2.p2.9.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S2.p2.9.m1.1.1.3.1.cmml">
         ​
        </mo>
        <mi id="S2.p2.9.m1.1.1.3.4" xref="S2.p2.9.m1.1.1.3.4.cmml">
         p
        </mi>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.9.m1.1b">
       <apply id="S2.p2.9.m1.1.1.cmml" xref="S2.p2.9.m1.1.1">
        <csymbol cd="ambiguous" id="S2.p2.9.m1.1.1.1.cmml" xref="S2.p2.9.m1.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.9.m1.1.1.2.cmml" xref="S2.p2.9.m1.1.1.2">
         𝑝
        </ci>
        <apply id="S2.p2.9.m1.1.1.3.cmml" xref="S2.p2.9.m1.1.1.3">
         <times id="S2.p2.9.m1.1.1.3.1.cmml" xref="S2.p2.9.m1.1.1.3.1">
         </times>
         <ci id="S2.p2.9.m1.1.1.3.2.cmml" xref="S2.p2.9.m1.1.1.3.2">
          𝑠
         </ci>
         <ci id="S2.p2.9.m1.1.1.3.3.cmml" xref="S2.p2.9.m1.1.1.3.3">
          𝑝
         </ci>
         <ci id="S2.p2.9.m1.1.1.3.4.cmml" xref="S2.p2.9.m1.1.1.3.4">
          𝑝
         </ci>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.9.m1.1c">
       p_{spp}
      </annotation>
     </semantics>
    </math>
    ) includes a high-level instruction and two carefully crafted demonstration examples
    <span class="ltx_note ltx_role_footnote" id="footnote1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       The tasks we use in the demonstration examples do not overlap with the evaluation tasks.
      </span>
     </span>
    </span>
    that showcase the expected task-solving procedure of
    <span class="ltx_text" id="S2.p2.10.2">
     SPP
    </span>
    . We describe the design details of the prompt in
    <span class="ltx_text ltx_font_bold" id="S2.p2.10.3">
     §
     <a class="ltx_ref" href="#A1.SS1" title="A.1 SPP Prompt Design ‣ Appendix A Prompts ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       A.1
      </span>
     </a>
    </span>
    .
The corresponding intermediate generations (
    <math alttext="z" class="ltx_Math" display="inline" id="S2.p2.10.m2.1">
     <semantics id="S2.p2.10.m2.1a">
      <mi id="S2.p2.10.m2.1.1" xref="S2.p2.10.m2.1.1.cmml">
       z
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.10.m2.1b">
       <ci id="S2.p2.10.m2.1.1.cmml" xref="S2.p2.10.m2.1.1">
        𝑧
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.10.m2.1c">
       z
      </annotation>
     </semantics>
    </math>
    ) of
    <span class="ltx_text" id="S2.p2.10.4">
     SPP
    </span>
    are detailed below.
   </p>
  </div>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    Persona Identification (
    <math alttext="z_{p}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.1.m1.1">
     <semantics id="S2.SS0.SSS0.Px1.1.m1.1b">
      <msub id="S2.SS0.SSS0.Px1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.1.m1.1.1.cmml">
       <mi id="S2.SS0.SSS0.Px1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.1.m1.1.1.2.cmml">
        z
       </mi>
       <mi id="S2.SS0.SSS0.Px1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.1.m1.1.1.3.cmml">
        p
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.1.m1.1c">
       <apply id="S2.SS0.SSS0.Px1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.1.m1.1.1">
        <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.1.m1.1.1">
         subscript
        </csymbol>
        <ci id="S2.SS0.SSS0.Px1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.1.m1.1.1.2">
         𝑧
        </ci>
        <ci id="S2.SS0.SSS0.Px1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.1.m1.1.1.3">
         𝑝
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.1.m1.1d">
       z_{p}
      </annotation>
     </semantics>
    </math>
    ).
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">
     Given an input task,
     <span class="ltx_text" id="S2.SS0.SSS0.Px1.p1.1.1">
      SPP
     </span>
     first generates a list of participants with different personas.
For example in Figure
     <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , the model identified a
     <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.2">
      Jay Chou Fan
     </span>
     persona to help answer "the last song in the second album by Jay Chou".
We let the language model identify the personas dynamically instead of manually defining them. Given only two demonstration examples (detailed in §
     <a class="ltx_ref" href="#A1" title="Appendix A Prompts ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       A
      </span>
     </a>
     ), we observe that a state-of-the-art large language model, e.g., GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023b
      </a>
      )
     </cite>
     , can identify accurate and meaningful personas for diverse tasks. We denote this part of intermediate generation as
     <math alttext="z_{p}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.1.m1.1">
      <semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a">
       <msub id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">
        <mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">
         z
        </mi>
        <mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">
         p
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b">
        <apply id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.2">
          𝑧
         </ci>
         <ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.3">
          𝑝
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">
        z_{p}
       </annotation>
      </semantics>
     </math>
     in Equation
     <a class="ltx_ref" href="#S2.E3" title="In 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    Brainstorming (
    <math alttext="z^{i}_{b}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.1.m1.1">
     <semantics id="S2.SS0.SSS0.Px2.1.m1.1b">
      <msubsup id="S2.SS0.SSS0.Px2.1.m1.1.1" xref="S2.SS0.SSS0.Px2.1.m1.1.1.cmml">
       <mi id="S2.SS0.SSS0.Px2.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px2.1.m1.1.1.2.2.cmml">
        z
       </mi>
       <mi id="S2.SS0.SSS0.Px2.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.1.m1.1.1.3.cmml">
        b
       </mi>
       <mi id="S2.SS0.SSS0.Px2.1.m1.1.1.2.3" xref="S2.SS0.SSS0.Px2.1.m1.1.1.2.3.cmml">
        i
       </mi>
      </msubsup>
      <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.1.m1.1c">
       <apply id="S2.SS0.SSS0.Px2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1">
        <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1">
         subscript
        </csymbol>
        <apply id="S2.SS0.SSS0.Px2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S2.SS0.SSS0.Px2.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1.2.2">
          𝑧
         </ci>
         <ci id="S2.SS0.SSS0.Px2.1.m1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1.2.3">
          𝑖
         </ci>
        </apply>
        <ci id="S2.SS0.SSS0.Px2.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.1.m1.1.1.3">
         𝑏
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.1.m1.1d">
       z^{i}_{b}
      </annotation>
     </semantics>
    </math>
    ).
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.3">
     Among the identified participants, "AI Assistant (you)" is treated as a leader persona that initiates the collaboration and generates initial solutions. Before generating the initial answer, the personas brainstorm on how to approach the task from their own perspectives. For example, the
     <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.3.1">
      Jay Chou Fan
     </span>
     points out that the last song in Jay Chou’s second album is "An Jing" ("Silence").
We find that the brainstorming phase effectively improves the quality of the initial solution.
In Equation
     <a class="ltx_ref" href="#S2.E3" title="In 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , the superscript
     <math alttext="i=0" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.1.m1.1">
      <semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a">
       <mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">
        <mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">
         i
        </mi>
        <mo id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">
         =
        </mo>
        <mn id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">
         0
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b">
        <apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">
         <eq id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1">
         </eq>
         <ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2">
          𝑖
         </ci>
         <cn id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3">
          0
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">
        i=0
       </annotation>
      </semantics>
     </math>
     is used to denote the "AI Assistant" persona, while
     <math alttext="i\geq 1" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.2.m2.1">
      <semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a">
       <mrow id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">
        <mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">
         i
        </mi>
        <mo id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">
         ≥
        </mo>
        <mn id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml">
         1
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b">
        <apply id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">
         <geq id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1">
         </geq>
         <ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2">
          𝑖
         </ci>
         <cn id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">
        i\geq 1
       </annotation>
      </semantics>
     </math>
     represents other dynamically identified personas. The intermediate generations of the brainstorming step are denoted as
     <math alttext="\{z^{1}_{b},z^{2}_{b},...,z^{m}_{b}\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.3.m3.4">
      <semantics id="S2.SS0.SSS0.Px2.p1.3.m3.4a">
       <mrow id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
        <mo id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.4" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
         {
        </mo>
        <msubsup id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.cmml">
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.2.cmml">
          z
         </mi>
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.3.cmml">
          b
         </mi>
         <mn id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.3.cmml">
          1
         </mn>
        </msubsup>
        <mo id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.5" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
         ,
        </mo>
        <msubsup id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.cmml">
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.cmml">
          z
         </mi>
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.3.cmml">
          b
         </mi>
         <mn id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml">
          2
         </mn>
        </msubsup>
        <mo id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.6" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
         ,
        </mo>
        <mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" mathvariant="normal" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">
         …
        </mi>
        <mo id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.7" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
         ,
        </mo>
        <msubsup id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.cmml">
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.2.cmml">
          z
         </mi>
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.3.cmml">
          b
         </mi>
         <mi id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.3.cmml">
          m
         </mi>
        </msubsup>
        <mo id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.8" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.4b">
        <set id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.4.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3">
         <apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1">
          <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1">
           subscript
          </csymbol>
          <apply id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1">
            superscript
           </csymbol>
           <ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.2">
            𝑧
           </ci>
           <cn id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.2.3">
            1
           </cn>
          </apply>
          <ci id="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.3">
           𝑏
          </ci>
         </apply>
         <apply id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2">
          <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2">
           subscript
          </csymbol>
          <apply id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2">
            superscript
           </csymbol>
           <ci id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2">
            𝑧
           </ci>
           <cn id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3">
            2
           </cn>
          </apply>
          <ci id="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.3">
           𝑏
          </ci>
         </apply>
         <ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1">
          …
         </ci>
         <apply id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3">
          <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3">
           subscript
          </csymbol>
          <apply id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3">
            superscript
           </csymbol>
           <ci id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.2">
            𝑧
           </ci>
           <ci id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.2.3">
            𝑚
           </ci>
          </apply>
          <ci id="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.4.4.3.3.3">
           𝑏
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.4c">
        \{z^{1}_{b},z^{2}_{b},...,z^{m}_{b}\}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    Multi-Persona Iterative Collaboration (
    <math alttext="z^{0}_{s}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.1.m1.1">
     <semantics id="S2.SS0.SSS0.Px3.1.m1.1b">
      <msubsup id="S2.SS0.SSS0.Px3.1.m1.1.1" xref="S2.SS0.SSS0.Px3.1.m1.1.1.cmml">
       <mi id="S2.SS0.SSS0.Px3.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px3.1.m1.1.1.2.2.cmml">
        z
       </mi>
       <mi id="S2.SS0.SSS0.Px3.1.m1.1.1.3" xref="S2.SS0.SSS0.Px3.1.m1.1.1.3.cmml">
        s
       </mi>
       <mn id="S2.SS0.SSS0.Px3.1.m1.1.1.2.3" xref="S2.SS0.SSS0.Px3.1.m1.1.1.2.3.cmml">
        0
       </mn>
      </msubsup>
      <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.1.m1.1c">
       <apply id="S2.SS0.SSS0.Px3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1">
        <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1">
         subscript
        </csymbol>
        <apply id="S2.SS0.SSS0.Px3.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1">
          superscript
         </csymbol>
         <ci id="S2.SS0.SSS0.Px3.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1.2.2">
          𝑧
         </ci>
         <cn id="S2.SS0.SSS0.Px3.1.m1.1.1.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px3.1.m1.1.1.2.3">
          0
         </cn>
        </apply>
        <ci id="S2.SS0.SSS0.Px3.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.1.m1.1.1.3">
         𝑠
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.1.m1.1d">
       z^{0}_{s}
      </annotation>
     </semantics>
    </math>
    ,
    <math alttext="z^{i}_{f}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.2.m2.1">
     <semantics id="S2.SS0.SSS0.Px3.2.m2.1b">
      <msubsup id="S2.SS0.SSS0.Px3.2.m2.1.1" xref="S2.SS0.SSS0.Px3.2.m2.1.1.cmml">
       <mi id="S2.SS0.SSS0.Px3.2.m2.1.1.2.2" xref="S2.SS0.SSS0.Px3.2.m2.1.1.2.2.cmml">
        z
       </mi>
       <mi id="S2.SS0.SSS0.Px3.2.m2.1.1.3" xref="S2.SS0.SSS0.Px3.2.m2.1.1.3.cmml">
        f
       </mi>
       <mi id="S2.SS0.SSS0.Px3.2.m2.1.1.2.3" xref="S2.SS0.SSS0.Px3.2.m2.1.1.2.3.cmml">
        i
       </mi>
      </msubsup>
      <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.2.m2.1c">
       <apply id="S2.SS0.SSS0.Px3.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1">
        <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1">
         subscript
        </csymbol>
        <apply id="S2.SS0.SSS0.Px3.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.2.m2.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1">
          superscript
         </csymbol>
         <ci id="S2.SS0.SSS0.Px3.2.m2.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1.2.2">
          𝑧
         </ci>
         <ci id="S2.SS0.SSS0.Px3.2.m2.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1.2.3">
          𝑖
         </ci>
        </apply>
        <ci id="S2.SS0.SSS0.Px3.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.2.m2.1.1.3">
         𝑓
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.2.m2.1d">
       z^{i}_{f}
      </annotation>
     </semantics>
    </math>
    ).
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.4">
     Based on the brainstorming remarks, the AI Assistant persona generates an initial solution
     <math alttext="z^{0}_{s}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p1.1.m1.1">
      <semantics id="S2.SS0.SSS0.Px3.p1.1.m1.1a">
       <msubsup id="S2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">
        <mi id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.2.cmml">
         z
        </mi>
        <mi id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml">
         s
        </mi>
        <mn id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.3.cmml">
         0
        </mn>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.m1.1b">
        <apply id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">
          subscript
         </csymbol>
         <apply id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">
           superscript
          </csymbol>
          <ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.2">
           𝑧
          </ci>
          <cn id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.3">
           0
          </cn>
         </apply>
         <ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3">
          𝑠
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.m1.1c">
        z^{0}_{s}
       </annotation>
      </semantics>
     </math>
     , then it consults each of the other participants for feedback
     <math alttext="\{z^{i}_{f}\}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p1.2.m2.1">
      <semantics id="S2.SS0.SSS0.Px3.p1.2.m2.1a">
       <mrow id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">
        <mo id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">
         {
        </mo>
        <msubsup id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.cmml">
         <mi id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.2" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.2.cmml">
          z
         </mi>
         <mi id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.3.cmml">
          f
         </mi>
         <mi id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.3" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.3.cmml">
          i
         </mi>
        </msubsup>
        <mo id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.2.m2.1b">
        <set id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1">
         <apply id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1">
          <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1">
           subscript
          </csymbol>
          <apply id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1">
            superscript
           </csymbol>
           <ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.2">
            𝑧
           </ci>
           <ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.2.3">
            𝑖
           </ci>
          </apply>
          <ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.1.3">
           𝑓
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.2.m2.1c">
        \{z^{i}_{f}\}
       </annotation>
      </semantics>
     </math>
     . The participants are encouraged to critique the current generation and give revision suggestions. For example, the Jay Chou Fan persona checks whether the song "An Jing" ("Silence") is correctly included in the story.
This process can be repeated for multiple times until every participant is satisfied with the current solution.
In Equation
     <a class="ltx_ref" href="#S2.E3" title="In 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , we denote the intermediate generations of the multi-turn dialogue as
     <math alttext="\{z^{0}_{s},z^{1}_{f},...,z^{m}_{f}\}_{j=1...n}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p1.3.m3.4">
      <semantics id="S2.SS0.SSS0.Px3.p1.3.m3.4a">
       <msub id="S2.SS0.SSS0.Px3.p1.3.m3.4.4" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.cmml">
        <mrow id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.4" stretchy="false" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
          {
         </mo>
         <msubsup id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml">
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.2.cmml">
           z
          </mi>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml">
           s
          </mi>
          <mn id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.3.cmml">
           0
          </mn>
         </msubsup>
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.5" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msubsup id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.cmml">
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.2.cmml">
           z
          </mi>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.3.cmml">
           f
          </mi>
          <mn id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.3.cmml">
           1
          </mn>
         </msubsup>
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.6" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S2.SS0.SSS0.Px3.p1.3.m3.1.1" mathvariant="normal" xref="S2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">
          …
         </mi>
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.7" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
          ,
         </mo>
         <msubsup id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.cmml">
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.2.cmml">
           z
          </mi>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.3.cmml">
           f
          </mi>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.3.cmml">
           m
          </mi>
         </msubsup>
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.8" stretchy="false" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml">
          }
         </mo>
        </mrow>
        <mrow id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.cmml">
         <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.2.cmml">
          j
         </mi>
         <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.1" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.1.cmml">
          =
         </mo>
         <mrow id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.cmml">
          <mn id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.2" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.2.cmml">
           1
          </mn>
          <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1" lspace="0em" rspace="0em" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1.cmml">
           ​
          </mo>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.3" mathvariant="normal" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.3.cmml">
           …
          </mi>
          <mo id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1a" lspace="0em" rspace="0em" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1.cmml">
           ​
          </mo>
          <mi id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.4" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.4.cmml">
           n
          </mi>
         </mrow>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.3.m3.4b">
        <apply id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4">
         <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.4.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4">
          subscript
         </csymbol>
         <set id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.4.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3">
          <apply id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1">
            subscript
           </csymbol>
           <apply id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1">
            <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1">
             superscript
            </csymbol>
            <ci id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.2">
             𝑧
            </ci>
            <cn id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.3">
             0
            </cn>
           </apply>
           <ci id="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.2.2.1.1.1.3">
            𝑠
           </ci>
          </apply>
          <apply id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2">
            subscript
           </csymbol>
           <apply id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2">
            <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2">
             superscript
            </csymbol>
            <ci id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.2">
             𝑧
            </ci>
            <cn id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.3.cmml" type="integer" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.3">
             1
            </cn>
           </apply>
           <ci id="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.3.3.2.2.2.3">
            𝑓
           </ci>
          </apply>
          <ci id="S2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.1.1">
           …
          </ci>
          <apply id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3">
            subscript
           </csymbol>
           <apply id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3">
            <csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3">
             superscript
            </csymbol>
            <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.2">
             𝑧
            </ci>
            <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.2.3">
             𝑚
            </ci>
           </apply>
           <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.3.3.3.3">
            𝑓
           </ci>
          </apply>
         </set>
         <apply id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5">
          <eq id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.1">
          </eq>
          <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.2.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.2">
           𝑗
          </ci>
          <apply id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3">
           <times id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.1">
           </times>
           <cn id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.2.cmml" type="integer" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.2">
            1
           </cn>
           <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.3">
            …
           </ci>
           <ci id="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.4.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.4.4.5.3.4">
            𝑛
           </ci>
          </apply>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.3.m3.4c">
        \{z^{0}_{s},z^{1}_{f},...,z^{m}_{f}\}_{j=1...n}
       </annotation>
      </semantics>
     </math>
     where
     <math alttext="n" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p1.4.m4.1">
      <semantics id="S2.SS0.SSS0.Px3.p1.4.m4.1a">
       <mi id="S2.SS0.SSS0.Px3.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml">
        n
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.4.m4.1b">
        <ci id="S2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.4.m4.1.1">
         𝑛
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.4.m4.1c">
        n
       </annotation>
      </semantics>
     </math>
     is the number of iterations before reaching the final answer. The final answer can be directly read out following user-specified output format.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
    <p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">
     In summary,
     <span class="ltx_text" id="S2.SS0.SSS0.Px3.p2.1.1">
      SPP
     </span>
     instructs an LLM to solve general tasks via multi-persona self-collaboration in a pure zero-shot manner. In contrast, as detailed in Table
     <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     , previous prompting-based methods are either task-specific or require additional mechanism, e.g., searching
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yao et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     , external tools
     <cite class="ltx_cite ltx_citemacro_cite">
      Yao et al. (
      <a class="ltx_ref" href="#bib.bib41" title="">
       2022
      </a>
      )
     </cite>
     , memory component
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shinn et al.,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2023
      </a>
      )
     </cite>
     , and fine-tuning
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al.,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <figure class="ltx_table" id="S2.T2">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T2.16" style="width:433.6pt;height:112.3pt;vertical-align:-0.9pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-28.4pt,7.3pt) scale(0.884035174730568,0.884035174730568) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.16.16">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S2.T2.16.16.17.1">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S2.T2.16.16.17.1.1" rowspan="2">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.17.1.1.1">
           Methods
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S2.T2.16.16.17.1.2">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.17.1.2.1">
           Trivia.C.W (N=5)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="2" id="S2.T2.16.16.17.1.3">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.17.1.3.1">
           Trivia.C.W (N=10)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="2" id="S2.T2.16.16.17.1.4">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.17.1.4.1">
           Codenames.C
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S2.T2.16.16.17.1.5">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.17.1.5.1">
           Logic.G.Puzzle
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.4.4.4">
         <td class="ltx_td ltx_align_center" id="S2.T2.4.4.4.5">
          Score (%)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.1.1.1.1">
          <math alttext="\Delta" class="ltx_Math" display="inline" id="S2.T2.1.1.1.1.m1.1">
           <semantics id="S2.T2.1.1.1.1.m1.1a">
            <mi id="S2.T2.1.1.1.1.m1.1.1" mathvariant="normal" xref="S2.T2.1.1.1.1.m1.1.1.cmml">
             Δ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.m1.1b">
             <ci id="S2.T2.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.m1.1.1">
              Δ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.m1.1c">
             \Delta
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.4.4.4.6">
          Score (%)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.2.2.2.2">
          <math alttext="\Delta" class="ltx_Math" display="inline" id="S2.T2.2.2.2.2.m1.1">
           <semantics id="S2.T2.2.2.2.2.m1.1a">
            <mi id="S2.T2.2.2.2.2.m1.1.1" mathvariant="normal" xref="S2.T2.2.2.2.2.m1.1.1.cmml">
             Δ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.2.m1.1b">
             <ci id="S2.T2.2.2.2.2.m1.1.1.cmml" xref="S2.T2.2.2.2.2.m1.1.1">
              Δ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.2.2.2.2.m1.1c">
             \Delta
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.4.4.4.7">
          Score (%)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.3.3.3.3">
          <math alttext="\Delta" class="ltx_Math" display="inline" id="S2.T2.3.3.3.3.m1.1">
           <semantics id="S2.T2.3.3.3.3.m1.1a">
            <mi id="S2.T2.3.3.3.3.m1.1.1" mathvariant="normal" xref="S2.T2.3.3.3.3.m1.1.1.cmml">
             Δ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.3.m1.1b">
             <ci id="S2.T2.3.3.3.3.m1.1.1.cmml" xref="S2.T2.3.3.3.3.m1.1.1">
              Δ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.3.3.3.3.m1.1c">
             \Delta
            </annotation>
           </semantics>
          </math>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.4.4.4.8">
          Score (%)
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.4.4.4.4">
          <math alttext="\Delta" class="ltx_Math" display="inline" id="S2.T2.4.4.4.4.m1.1">
           <semantics id="S2.T2.4.4.4.4.m1.1a">
            <mi id="S2.T2.4.4.4.4.m1.1.1" mathvariant="normal" xref="S2.T2.4.4.4.4.m1.1.1.cmml">
             Δ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S2.T2.4.4.4.4.m1.1b">
             <ci id="S2.T2.4.4.4.4.m1.1.1.cmml" xref="S2.T2.4.4.4.4.m1.1.1">
              Δ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.4.4.4.4.m1.1c">
             \Delta
            </annotation>
           </semantics>
          </math>
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.16.16.18.2">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.16.16.18.2.1">
          Standard
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.18.2.2">
          74.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T2.16.16.18.2.3">
          0.0%
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.18.2.4">
          77.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S2.T2.16.16.18.2.5">
          0.0%
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.18.2.6">
          75.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S2.T2.16.16.18.2.7">
          0.0%
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.18.2.8">
          57.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.18.2.9">
          0.0%
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.8.8.8">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T2.8.8.8.5">
          CoT
         </th>
         <td class="ltx_td ltx_align_center" id="S2.T2.8.8.8.6">
          67.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.5.5.5.1">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.5.5.5.1.m1.1">
           <semantics id="S2.T2.5.5.5.1.m1.1a">
            <mo id="S2.T2.5.5.5.1.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.5.5.5.1.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.5.5.5.1.m1.1b">
             <ci id="S2.T2.5.5.5.1.m1.1.1.cmml" xref="S2.T2.5.5.5.1.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.5.5.5.1.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.5.5.5.1.1" style="color:#FF0000;">
           10.0%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.8.8.8.7">
          68.5
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.6.6.6.2">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.6.6.6.2.m1.1">
           <semantics id="S2.T2.6.6.6.2.m1.1a">
            <mo id="S2.T2.6.6.6.2.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.6.6.6.2.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.6.6.6.2.m1.1b">
             <ci id="S2.T2.6.6.6.2.m1.1.1.cmml" xref="S2.T2.6.6.6.2.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.6.6.6.2.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.6.6.6.2.1" style="color:#FF0000;">
           11.1%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.8.8.8.8">
          72.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.7.7.7.3">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.7.7.7.3.m1.1">
           <semantics id="S2.T2.7.7.7.3.m1.1a">
            <mo id="S2.T2.7.7.7.3.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.7.7.7.3.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.7.7.7.3.m1.1b">
             <ci id="S2.T2.7.7.7.3.m1.1.1.cmml" xref="S2.T2.7.7.7.3.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.7.7.7.3.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.7.7.7.3.1" style="color:#FF0000;">
           3.6%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.8.8.8.9">
          65.8
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.8.8.8.4">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.8.8.8.4.m1.1">
           <semantics id="S2.T2.8.8.8.4.m1.1a">
            <mo id="S2.T2.8.8.8.4.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.8.8.8.4.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.8.8.8.4.m1.1b">
             <ci id="S2.T2.8.8.8.4.m1.1.1.cmml" xref="S2.T2.8.8.8.4.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.8.8.8.4.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.8.8.8.4.1" style="color:#009900;">
           14.1%
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.16.16.19.3">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T2.16.16.19.3.1">
          Self-Refine [iter=0]
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.19.3.2">
          73.8
         </td>
         <td class="ltx_td ltx_border_r ltx_border_t" id="S2.T2.16.16.19.3.3">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.19.3.4">
          76.3
         </td>
         <td class="ltx_td ltx_border_rr ltx_border_t" id="S2.T2.16.16.19.3.5">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.19.3.6">
          75.2
         </td>
         <td class="ltx_td ltx_border_rr ltx_border_t" id="S2.T2.16.16.19.3.7">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S2.T2.16.16.19.3.8">
          58.8
         </td>
         <td class="ltx_td ltx_border_t" id="S2.T2.16.16.19.3.9">
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.12.12.12">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T2.12.12.12.5">
          Self-Refine [iter=1]
         </th>
         <td class="ltx_td ltx_align_center" id="S2.T2.12.12.12.6">
          73.9
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r" id="S2.T2.9.9.9.1">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.9.9.9.1.m1.1">
           <semantics id="S2.T2.9.9.9.1.m1.1a">
            <mo id="S2.T2.9.9.9.1.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.9.9.9.1.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.9.9.9.1.m1.1b">
             <ci id="S2.T2.9.9.9.1.m1.1.1.cmml" xref="S2.T2.9.9.9.1.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.9.9.9.1.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.9.9.9.1.1" style="color:#FF0000;">
           1.0%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.12.12.12.7">
          76.9
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.10.10.10.2">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.10.10.10.2.m1.1">
           <semantics id="S2.T2.10.10.10.2.m1.1a">
            <mo id="S2.T2.10.10.10.2.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.10.10.10.2.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.10.10.10.2.m1.1b">
             <ci id="S2.T2.10.10.10.2.m1.1.1.cmml" xref="S2.T2.10.10.10.2.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.10.10.10.2.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.10.10.10.2.1" style="color:#FF0000;">
           0.1%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.12.12.12.8">
          64.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_rr" id="S2.T2.11.11.11.3">
          <math alttext="\downarrow" class="ltx_Math" display="inline" id="S2.T2.11.11.11.3.m1.1">
           <semantics id="S2.T2.11.11.11.3.m1.1a">
            <mo id="S2.T2.11.11.11.3.m1.1.1" mathcolor="#FF0000" stretchy="false" xref="S2.T2.11.11.11.3.m1.1.1.cmml">
             ↓
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.11.11.11.3.m1.1b">
             <ci id="S2.T2.11.11.11.3.m1.1.1.cmml" xref="S2.T2.11.11.11.3.m1.1.1">
              ↓
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.11.11.11.3.m1.1c">
             \downarrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.11.11.11.3.1" style="color:#FF0000;">
           14.6%
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.12.12.12.9">
          60.0
         </td>
         <td class="ltx_td ltx_align_center" id="S2.T2.12.12.12.4">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.12.12.12.4.m1.1">
           <semantics id="S2.T2.12.12.12.4.m1.1a">
            <mo id="S2.T2.12.12.12.4.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.12.12.12.4.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.12.12.12.4.m1.1b">
             <ci id="S2.T2.12.12.12.4.m1.1.1.cmml" xref="S2.T2.12.12.12.4.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.12.12.12.4.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S2.T2.12.12.12.4.1" style="color:#009900;">
           4.0%
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T2.16.16.16">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.16.16.16.5">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.5.1">
           SPP (ours)
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T2.16.16.16.6">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.6.1">
           79.9
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.13.13.13.1">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.13.13.13.1.m1.1">
           <semantics id="S2.T2.13.13.13.1.m1.1a">
            <mo id="S2.T2.13.13.13.1.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.13.13.13.1.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.13.13.13.1.m1.1b">
             <ci id="S2.T2.13.13.13.1.m1.1.1.cmml" xref="S2.T2.13.13.13.1.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.13.13.13.1.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text ltx_font_bold" id="S2.T2.13.13.13.1.1" style="color:#009900;">
           7.1%
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T2.16.16.16.7">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.7.1">
           84.7
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t" id="S2.T2.14.14.14.2">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.14.14.14.2.m1.1">
           <semantics id="S2.T2.14.14.14.2.m1.1a">
            <mo id="S2.T2.14.14.14.2.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.14.14.14.2.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.14.14.14.2.m1.1b">
             <ci id="S2.T2.14.14.14.2.m1.1.1.cmml" xref="S2.T2.14.14.14.2.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.14.14.14.2.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text ltx_font_bold" id="S2.T2.14.14.14.2.1" style="color:#009900;">
           10.0%
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T2.16.16.16.8">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.8.1">
           79.0
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t" id="S2.T2.15.15.15.3">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.15.15.15.3.m1.1">
           <semantics id="S2.T2.15.15.15.3.m1.1a">
            <mo id="S2.T2.15.15.15.3.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.15.15.15.3.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.15.15.15.3.m1.1b">
             <ci id="S2.T2.15.15.15.3.m1.1.1.cmml" xref="S2.T2.15.15.15.3.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.15.15.15.3.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text ltx_font_bold" id="S2.T2.15.15.15.3.1" style="color:#009900;">
           4.8%
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T2.16.16.16.9">
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.9.1">
           68.3
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T2.16.16.16.4">
          <math alttext="\uparrow" class="ltx_Math" display="inline" id="S2.T2.16.16.16.4.m1.1">
           <semantics id="S2.T2.16.16.16.4.m1.1a">
            <mo id="S2.T2.16.16.16.4.m1.1.1" mathcolor="#009900" stretchy="false" xref="S2.T2.16.16.16.4.m1.1.1.cmml">
             ↑
            </mo>
            <annotation-xml encoding="MathML-Content" id="S2.T2.16.16.16.4.m1.1b">
             <ci id="S2.T2.16.16.16.4.m1.1.1.cmml" xref="S2.T2.16.16.16.4.m1.1.1">
              ↑
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T2.16.16.16.4.m1.1c">
             \uparrow
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text ltx_font_bold" id="S2.T2.16.16.16.4.1" style="color:#009900;">
           18.5%
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     GPT-4 results on Trivia Creative Writing (Trivia.C.W), Codenames Collaborative (Codenames.C) and Logic Grid Puzzle (Logic.G.Puzzle).
     <math alttext="\Delta" class="ltx_Math" display="inline" id="S2.T2.18.m1.1">
      <semantics id="S2.T2.18.m1.1b">
       <mi id="S2.T2.18.m1.1.1" mathvariant="normal" xref="S2.T2.18.m1.1.1.cmml">
        Δ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.T2.18.m1.1c">
        <ci id="S2.T2.18.m1.1.1.cmml" xref="S2.T2.18.m1.1.1">
         Δ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.T2.18.m1.1d">
        \Delta
       </annotation>
      </semantics>
     </math>
     indicates the relative gain/loss compared with Standard Prompting (first row). We report the average scores across two individual runs with/without a system message (detailed in Appendix
     <a class="ltx_ref" href="#A3" title="Appendix C Inference Configurations ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       C
      </span>
     </a>
     ).
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Experiments
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    To explore the effectiveness of Solo Performance Prompting (
    <span class="ltx_text" id="S3.p1.1.1">
     SPP
    </span>
    ), we adopt an evaluation methodology similar to that of previous work
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     )
    </cite>
    . We carefully design new tasks and select tasks from existing benchmarks
    <cite class="ltx_cite ltx_citemacro_cite">
     Srivastava et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2022
     </a>
     )
    </cite>
    that are challenging even for the most capable LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023b
     </a>
     )
    </cite>
    .
The evaluation aims to cover diverse types of tasks encompassing both
    <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">
     knowledge-intensive
    </span>
    and
    <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">
     reasoning-intensive
    </span>
    domains.
   </p>
  </div>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    Tasks.
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">
     We invent the
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.1">
      Trivia Creative Writing
     </span>
     task (§
     <a class="ltx_ref" href="#S3.SS1" title="3.1 Trivia Creative Writing: A Knowledge-Intensive Task ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3.1
      </span>
     </a>
     ), which requires the model to internally acquire and integrate diverse information from various fields.
We observe that even GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023b
      </a>
      )
     </cite>
     frequently exhibit hallucination and factuality errors in the Trivia Creative Writing task.
We also propose the
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.2">
      Codenames Collaborative
     </span>
     task (§
     <a class="ltx_ref" href="#S3.SS2" title="3.2 Codenames Collaborative: A Knowledge+Reasoning Task ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3.2
      </span>
     </a>
     ), an extension of the Codenames task from the BigBench
     <cite class="ltx_cite ltx_citemacro_citep">
      (Srivastava et al.,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2022
      </a>
      )
     </cite>
     that features a two-role collaboration setup.
Codenames Collaborative demands creative reasoning across a broad range of related knowledge and challenges the model’s theory of mind skills.
Lastly, we include a challenging pure-reasoning task,
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.3">
      Logic Grid Puzzle
     </span>
     (§
     <a class="ltx_ref" href="#S3.SS3" title="3.3 Logic Grid Puzzle: A Reasoning-Intensive Task ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3.3
      </span>
     </a>
     ), from the BigBench
     <cite class="ltx_cite ltx_citemacro_citep">
      (Srivastava et al.,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2022
      </a>
      )
     </cite>
     which necessitates complex multi-step reasoning.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    Baselines.
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">
     We compare our approach with
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.1">
      Standard Prompting
     </span>
     ,
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.2">
      Chain-of-Thought (CoT)
     </span>
     prompting methods (outlined in §
     <a class="ltx_ref" href="#S2" title="2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     ) and
     <span class="ltx_text ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.3">
      Self-Refine
     </span>
     <cite class="ltx_cite ltx_citemacro_citep">
      (Madaan et al.,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2023
      </a>
      )
     </cite>
     .
For CoT, a similar prompt design to
     <cite class="ltx_cite ltx_citemacro_cite">
      Yao et al. (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     is employed, where the model is prompted to generate a plan or a series of steps before producing the final output.
For Self-Refine, we follow
     <cite class="ltx_cite ltx_citemacro_cite">
      Madaan et al. (
      <a class="ltx_ref" href="#bib.bib21" title="">
       2023
      </a>
      )
     </cite>
     to design
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.1.4">
      feedback
     </span>
     and
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.1.5">
      refine
     </span>
     prompts. We perform one self-refine iteration which requires three times more inferences than
     <span class="ltx_text" id="S3.SS0.SSS0.Px2.p1.1.6">
      SPP
     </span>
     .
Full prompts for the methods can be found in Appendix
     <a class="ltx_ref" href="#A1.SS2" title="A.2 Full Prompts ‣ Appendix A Prompts ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       A.2
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    Models.
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">
     The default model we use is GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023b
      </a>
      )
     </cite>
     .
Detailed inference configurations, API versions, and full results can be found in Appendices
     <a class="ltx_ref" href="#A3" title="Appendix C Inference Configurations ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       C
      </span>
     </a>
     and
     <a class="ltx_ref" href="#A6" title="Appendix F Full Results ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       F
      </span>
     </a>
     .
In §
     <a class="ltx_ref" href="#S3.SS4" title="3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3.4
      </span>
     </a>
     , we further investigate the prevalence of cognitive synergy in LLMs with different scales and capabilities, including GPT-3.5-turbo
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023a
      </a>
      )
     </cite>
     and Llama2-13b-chat
     <cite class="ltx_cite ltx_citemacro_citep">
      (Touvron et al.,
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="190" id="S3.F3.g1" src="/html/2307.05300/assets/x3.png" width="415"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Trivia Creative Writing task example.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S3.F4.g1" src="/html/2307.05300/assets/x4.png" width="415"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Codenames Collaborative task example.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="226" id="S3.F5.g1" src="/html/2307.05300/assets/x5.png" width="415"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Logic Grid Puzzle task example.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Trivia Creative Writing: A Knowledge-Intensive Task
   </h3>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Task Description.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.5">
      As illustrated in Figure
      <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      , Trivia Creative Writing asks a model to write a coherent story while incorporating the answers to
      <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1">
       <semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a">
        <mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">
         N
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b">
         <ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">
          𝑁
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">
         N
        </annotation>
       </semantics>
      </math>
      trivia questions. Our preliminary experiments (Figure
      <a class="ltx_ref" href="#A2.F10" title="Figure 10 ‣ Appendix B Task Details ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        10
       </span>
      </a>
      ) show that a sufficiently large
      <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.2.m2.1">
       <semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a">
        <mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">
         N
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b">
         <ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">
          𝑁
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">
         N
        </annotation>
       </semantics>
      </math>
      can effectively challenge GPT-4 to demonstrate factual knowledge across diverse domains. Thus, we mainly consider two evaluation settings,
      <math alttext="N=5" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.3.m3.1">
       <semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a">
        <mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">
         <mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">
          N
         </mi>
         <mo id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml">
          =
         </mo>
         <mn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml">
          5
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b">
         <apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">
          <eq id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1">
          </eq>
          <ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2">
           𝑁
          </ci>
          <cn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3">
           5
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">
         N=5
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="N=10" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.1">
       <semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a">
        <mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">
         <mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">
          N
         </mi>
         <mo id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml">
          =
         </mo>
         <mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">
          10
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b">
         <apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">
          <eq id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1">
          </eq>
          <ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">
           𝑁
          </ci>
          <cn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">
           10
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">
         N=10
        </annotation>
       </semantics>
      </math>
      .
We built a benchmark with 100 instances for each
      <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.1">
       <semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a">
        <mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml">
         N
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b">
         <ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">
          𝑁
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">
         N
        </annotation>
       </semantics>
      </math>
      , covering a total of 1000 trivia questions
      <span class="ltx_note ltx_role_footnote" id="footnote2">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          2
         </sup>
         <span class="ltx_tag ltx_tag_note">
          2
         </span>
         To select difficult question instances that can pose challenges to GPT-4, we use a smaller open-source LLM,
         <span class="ltx_text ltx_font_italic" id="footnote2.1">
          fastchat_t5_3b
         </span>
         <cite class="ltx_cite ltx_citemacro_citep">
          (Zheng et al.,
          <a class="ltx_ref" href="#bib.bib43" title="">
           2023
          </a>
          )
         </cite>
         , to obtain preliminary performance on the validation set, and then choose the failure cases as our question selection.
        </span>
       </span>
      </span>
      extracted from the TriviaQA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Joshi et al.,
       <a class="ltx_ref" href="#bib.bib17" title="">
        2017
       </a>
       )
      </cite>
      dataset.
More details can be found in Appendix
      <a class="ltx_ref" href="#A2.SS1" title="B.1 Trivia Creative Writing ‣ Appendix B Task Details ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        B.1
       </span>
      </a>
      .
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Evaluation Metrics.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">
      Evaluating GPT-4 level generation results can be challenging. Our preliminary experiments indicate that, even for humans, it is very difficult to identify which generation is better in terms of overall "quality" of the story from different prompting methods. Thus, instead of focusing on evaluating the coherence of the generation, which can be highly subjective, we employ an automatic metric which focuses on detecting factual hallucinations.
As shown in Figure
      <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      , we perform string matching with the ground truth target answers for each question on the output generation.
For each question, a match to any of the answer aliases provided by the TriviaQA dataset is considered a correct mention.
The metric score is computed as:
      <math alttext="\frac{\text{\# correct answer mentions}}{\text{\# trivia questions}}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.1.m1.1">
       <semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a">
        <mfrac id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">
         <mtext id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml">
          # correct answer mentions
         </mtext>
         <mtext id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3a.cmml">
          # trivia questions
         </mtext>
        </mfrac>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b">
         <apply id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">
          <divide id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">
          </divide>
          <ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2">
           <mtext id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" mathsize="70%" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2">
            # correct answer mentions
           </mtext>
          </ci>
          <ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3">
           <mtext id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3">
            # trivia questions
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">
         \frac{\text{\# correct answer mentions}}{\text{\# trivia questions}}
        </annotation>
       </semantics>
      </math>
      .
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Results.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.2">
      Table
      <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ Multi-Persona Iterative Collaboration (𝑧⁰_𝑠, 𝑧^𝑖_𝑓). ‣ 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      presents the results of the Trivia Creative Writing task. The key observations are as follows: (1) Chain-of-Thought (CoT) does not outperform Standard prompting, indicating that CoT is ineffective in eliciting an LLM’s knowledge abilities. Qualitative examples in Figure
      <a class="ltx_ref" href="#S4.F8" title="Figure 8 ‣ LLMs can effectively identify useful personas in a zero-shot manner. ‣ 4 Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      and
      <a class="ltx_ref" href="#A4.F11" title="Figure 11 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        11
       </span>
      </a>
      illustrate that although CoT generates reasonable plans for task resolution, the final generation still contains factual errors and hallucinations. (2) Self-Refine only brings marginal improvements over iterations. (3)
      <span class="ltx_text" id="S3.SS1.SSS0.Px3.p1.2.1">
       SPP
      </span>
      outperforms all baselines significantly. The improvement is more pronounced in the
      <math alttext="N=10" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.1.m1.1">
       <semantics id="S3.SS1.SSS0.Px3.p1.1.m1.1a">
        <mrow id="S3.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">
         <mi id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">
          N
         </mi>
         <mo id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml">
          =
         </mo>
         <mn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml">
          10
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.1.m1.1b">
         <apply id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1">
          <eq id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1">
          </eq>
          <ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2">
           𝑁
          </ci>
          <cn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3">
           10
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.1.m1.1c">
         N=10
        </annotation>
       </semantics>
      </math>
      setting compared to
      <math alttext="N=5" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.2.m2.1">
       <semantics id="S3.SS1.SSS0.Px3.p1.2.m2.1a">
        <mrow id="S3.SS1.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.cmml">
         <mi id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml">
          N
         </mi>
         <mo id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.cmml">
          =
         </mo>
         <mn id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.3.cmml">
          5
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.2.m2.1b">
         <apply id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1">
          <eq id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1">
          </eq>
          <ci id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.2">
           𝑁
          </ci>
          <cn id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.3">
           5
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.2.m2.1c">
         N=5
        </annotation>
       </semantics>
      </math>
      (10% vs. 7%), suggesting that Solo Performance Prompting is particularly beneficial when the task requires incorporating knowledge from numerous domains.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Codenames Collaborative: A Knowledge+Reasoning Task
   </h3>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Task Description.
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">
      As illustrated in
      <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      , Codenames Collaborative is a collaborative task that challenges a model’s knowledge, reasoning, and theory of mind abilities by assigning two player roles: the
      <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS0.Px1.p1.1.1">
       Spymaster
      </span>
      and the
      <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS0.Px1.p1.1.2">
       Guesser
      </span>
      . The Spymaster’s role is to provide a hint word related to the target words, excluding some other distractor words, while the Guesser’s role is to identify the target words based on the given hint and the full list of words.
The same LLM (GPT-4
      <cite class="ltx_cite ltx_citemacro_citep">
       (OpenAI,
       <a class="ltx_ref" href="#bib.bib25" title="">
        2023b
       </a>
       )
      </cite>
      ) is used for both roles sequentially, and a dataset with 50 instances is constructed based on BigBench’s
      <cite class="ltx_cite ltx_citemacro_citep">
       (Srivastava et al.,
       <a class="ltx_ref" href="#bib.bib34" title="">
        2022
       </a>
       )
      </cite>
      Codenames task data.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Evaluation Metrics.
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">
      The original Codenames task in the BigBench dataset has limitations due to its focus on the Guesser role and subjectivity in hint words. Our new task, Codenames Collaborative, resolves this by creating a self-contained evaluation setting that accurately measures the model’s capability without human annotation. As illustrated in Figure
      <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      , we compute the overlapping ratio between the predicted words from the Guesser and the target words as the metric.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Results.
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px3.p1.1">
      Table
      <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ Multi-Persona Iterative Collaboration (𝑧⁰_𝑠, 𝑧^𝑖_𝑓). ‣ 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      shows the results on the Codenames Collaborative task. Similar to the Trivia Creative Writing task, we find that CoT does not bring positive gains compared with the Standard prompting.
Interestingly, iterative self-refinement brings negative impact on this task, due to a high tendency changing the initial response even if it is already good.
In contrast,
      <span class="ltx_text" id="S3.SS2.SSS0.Px3.p1.1.1">
       SPP
      </span>
      brings significant improvements (~5%), which indicates its effectiveness on collaborative tasks that require knowledge, reasoning, and theory of mind skills.
Figure
      <a class="ltx_ref" href="#A4.F12" title="Figure 12 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        12
       </span>
      </a>
      provides further qualitative examples illustrating that
      <span class="ltx_text" id="S3.SS2.SSS0.Px3.p1.1.2">
       SPP
      </span>
      generates
      <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS0.Px3.p1.1.3">
       detailed
      </span>
      and
      <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS0.Px3.p1.1.4">
       interpretable
      </span>
      intermediate dialogues.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Logic Grid Puzzle: A Reasoning-Intensive Task
   </h3>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Task Description and Evaluation Metrics
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">
      We utilize the Logic Grid Puzzle task from the Bigbench
      <cite class="ltx_cite ltx_citemacro_citep">
       (Srivastava et al.,
       <a class="ltx_ref" href="#bib.bib34" title="">
        2022
       </a>
       )
      </cite>
      dataset, which comprises 200 instances. Each instance describes a logic puzzle typically involving 2 to 5 houses, with each house inhabited by a person with specific characteristics, such as playing the piano. The objective is to answer questions about house numbers based on given clues, which requires multi-step reasoning and the selection of relevant information. An example input and output of the Logic Grid Puzzle task are illustrated in Figure
      <a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      . For evaluation metrics, we calculate the accuracy of the predicted house numbers by comparing them with the ground truth targets provided by the dataset.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Results.
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">
      Table
      <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ Multi-Persona Iterative Collaboration (𝑧⁰_𝑠, 𝑧^𝑖_𝑓). ‣ 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      presents the results on Logic Grid Puzzle. In contrast to the previous two tasks, we find that CoT brings significant improvements compared to Standard prompting, verifying the observation from previous work that CoT elicits better reasoning abilities. Furthermore, we discover that
      <span class="ltx_text" id="S3.SS3.SSS0.Px2.p1.1.1">
       SPP
      </span>
      also achieves strong performance on this reasoning-intensive task.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F6">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S3.F6.g1" src="/html/2307.05300/assets/x6.png" width="415"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 6:
      </span>
      <span class="ltx_text" id="S3.F6.2.1">
       SPP
      </span>
      achieves superior performance only with the most powerful LLM (GPT-4), but not with GPT-3.5 and Llama2-13b. This indicates that cognitive synergy abilities only emerge in LLMs with GPT-4 level capabilities.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    The Emergence of Cognitive Synergy
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     We further discover that
     <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.1">
      cognitive synergy can only be fully unleashed in LLMs with a certain level of instruction-following capabilities, akin to that of GPT-4.
     </span>
     This can be intriguingly compared to human development, where children usually begin to participate in role-playing around the ages of 2 to 3
     <cite class="ltx_cite ltx_citemacro_cite">
      Piaget (
      <a class="ltx_ref" href="#bib.bib28" title="">
       1954
      </a>
      )
     </cite>
     , but not before that age.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p2">
    <p class="ltx_p" id="S3.SS4.p2.1">
     As shown in Figure
     <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ Results. ‣ 3.3 Logic Grid Puzzle: A Reasoning-Intensive Task ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     , the effectiveness of
     <span class="ltx_text" id="S3.SS4.p2.1.1">
      SPP
     </span>
     is not seen in smaller and less capable models like GPT-3.5 and Llama2.
Additionally, on Llama2, we identify a unique problem which we refer to as
     <span class="ltx_text ltx_font_italic" id="S3.SS4.p2.1.2">
      early-termination
     </span>
     , where the model stops generating after identifying the participants, resulting in exceptionally low performance with
     <span class="ltx_text" id="S3.SS4.p2.1.3">
      SPP
     </span>
     .
The model behaves as if it were waiting for input from a user instead of following the demonstration examples to generate responses on its own. Detailed discussions and examples on the early-termination problem can be found in Appendix
     <a class="ltx_ref" href="#A5" title="Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       E
      </span>
     </a>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F7">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F7.sf1">
       <p class="ltx_p" id="S3.F7.sf1.1">
        <span class="ltx_text" id="S3.F7.sf1.1.1" style="position:relative; bottom:0.0pt;">
         <span class="ltx_inline-block ltx_transformed_outer" id="S3.F7.sf1.1.1.1.1.1" style="width:435.5pt;height:836.9pt;vertical-align:-0.0pt;">
          <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
           <span class="ltx_p" id="S3.F7.sf1.1.1.1.1.1.1">
            <span class="ltx_text" id="S3.F7.sf1.1.1.1.1.1.1.1">
             <img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1158" id="S3.F7.sf1.1.1.1.1.1.1.1.g1" src="/html/2307.05300/assets/images/persona_cloud_vertical.png" width="598"/>
            </span>
           </span>
          </span>
         </span>
        </span>
       </p>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         (a)
        </span>
        Visualization of the
        <span class="ltx_text" id="S3.F7.sf1.3.1">
         SPP
        </span>
        -identified personas. The personas show a high correlation with the nature of the tasks.
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F7.sf2">
       <p class="ltx_p" id="S3.F7.sf2.1">
        <span class="ltx_text" id="S3.F7.sf2.1.1" style="position:relative; bottom:0.0pt;">
         <span class="ltx_inline-block ltx_transformed_outer" id="S3.F7.sf2.1.1.1.1.1" style="width:435.5pt;height:247.2pt;vertical-align:-0.0pt;">
          <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
           <span class="ltx_p" id="S3.F7.sf2.1.1.1.1.1.1">
            <span class="ltx_text" id="S3.F7.sf2.1.1.1.1.1.1.1">
             <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="342" id="S3.F7.sf2.1.1.1.1.1.1.1.g1" src="/html/2307.05300/assets/images/barchart_spp_variants_7x4.png" width="598"/>
            </span>
           </span>
          </span>
         </span>
        </span>
       </p>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         (b)
        </span>
        Comparison between
        <span class="ltx_text" id="S3.F7.sf2.9.1">
         SPP
        </span>
        ,
        <span class="ltx_text" id="S3.F7.sf2.10.2">
         SPP-Fixed-Persona
        </span>
        (with two fixed personas) and
        <span class="ltx_text" id="S3.F7.sf2.11.3">
         SPP-Profile
        </span>
        (additionally generating persona profiles).
        <span class="ltx_text" id="S3.F7.sf2.12.4">
         SPP
        </span>
        significantly outperforms
        <span class="ltx_text" id="S3.F7.sf2.13.5">
         SPP-Fixed-Persona
        </span>
        , highlighting the importance of automatically identifying dynamic, fine-grained personas.
        <span class="ltx_text" id="S3.F7.sf2.14.6">
         SPP
        </span>
        slightly outperforms
        <span class="ltx_text" id="S3.F7.sf2.15.7">
         SPP-Profile
        </span>
        , indicating that the persona names (without detailed description of the expertise) are probably already sufficient for eliciting cognitive synergy.
       </figcaption>
      </figure>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 7:
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.F7.4.1">
      (a)
     </span>
     Qualitative analysis on the identified personas;
     <span class="ltx_text ltx_font_bold" id="S3.F7.5.2">
      (b)
     </span>
     Quantitative analysis on two
     <span class="ltx_text" id="S3.F7.6.3">
      SPP
     </span>
     variants.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Analysis
  </h2>
  <section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    <span class="ltx_text" id="S4.SS0.SSS0.Px1.1.1">
     SPP
    </span>
    effectively improves both knowledge and reasoning abilities in LLMs.
   </h4>
   <div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">
     As demonstrated by the results in §
     <a class="ltx_ref" href="#S3" title="3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , Solo Performance Prompting (
     <span class="ltx_text" id="S4.SS0.SSS0.Px1.p1.1.1">
      SPP
     </span>
     ) not only brings significant improvements to knowledge-intensive tasks such as Trivia Creative Writing and Codenames Collaborative without relying on external knowledge bases, but also achieves strong performance on reasoning-intensive tasks like Logic Grid Puzzle. To our knowledge,
     <span class="ltx_text" id="S4.SS0.SSS0.Px1.p1.1.2">
      SPP
     </span>
     is the first zero-shot prompting method that can enhance both knowledge and reasoning abilities on GPT-4.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    LLMs can effectively identify useful personas in a zero-shot manner.
   </h4>
   <div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">
     We are interested in investigating whether the identified personas are highly relevant to the tasks.
We visualize the personas automatically identified by
     <span class="ltx_text" id="S4.SS0.SSS0.Px2.p1.1.1">
      SPP
     </span>
     using a word cloud for each task in Figure
     <a class="ltx_ref" href="#S3.F7.sf1" title="In Figure 7 ‣ 3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       7(a)
      </span>
     </a>
     , where a larger font indicates a higher frequency. The key observations include: (1) The identified personas are closely correlated with the particular task. For example, in Logic Grid Puzzle, even though "logic puzzle" is not mentioned in the input, the LLM frequently identifies the persona "Logic Puzzle Expert."
(2) On knowledge-intensive tasks, such as Trivia Creative Writing,
     <span class="ltx_text" id="S4.SS0.SSS0.Px2.p1.1.2">
      SPP
     </span>
     identifies more diverse and specific personas, while on reasoning-intensive tasks, such as Logic Grid Puzzle, the personas are more homogeneous.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS0.SSS0.Px2.p2">
    <p class="ltx_p" id="S4.SS0.SSS0.Px2.p2.1">
     We further investigate whether a detailed profile for each persona is needed for eliciting domain knowledge, as suggested by
     <cite class="ltx_cite ltx_citemacro_cite">
      Xu et al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      )
     </cite>
     .
To this end, we design a variant of
     <span class="ltx_text" id="S4.SS0.SSS0.Px2.p2.1.1">
      SPP
     </span>
     ,
     <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS0.Px2.p2.1.2">
      SPP-Profile
     </span>
     , which involves generating profiles for each persona during the Persona Identification phase.
The results in Figure
     <a class="ltx_ref" href="#S3.F7.sf2" title="In Figure 7 ‣ 3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       7(b)
      </span>
     </a>
     show that
     <span class="ltx_text" id="S4.SS0.SSS0.Px2.p2.1.3">
      SPP-Profile
     </span>
     does not outperform
     <span class="ltx_text" id="S4.SS0.SSS0.Px2.p2.1.4">
      SPP
     </span>
     . This suggests that a fine-grained persona name without a detailed description may already be sufficient for eliciting certain domain knowledge.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F8">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S4.F8.g1" src="/html/2307.05300/assets/x7.png" width="410"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 8:
     </span>
     Qualitative examples on Trivia Creative Writing comparing
     <span class="ltx_text" id="S4.F8.5.1">
      SPP
     </span>
     , CoT and
     <span class="ltx_text" id="S4.F8.6.2">
      SPP-Fixed-Persona
     </span>
     .
While CoT provides reasonable intermediate steps, it still struggles with factual hallucination.
     <span class="ltx_text" id="S4.F8.7.3">
      SPP
     </span>
     v.s.
     <span class="ltx_text" id="S4.F8.8.4">
      SPP-Fixed-Persona
     </span>
     reveals that dynamically identified fine-grained personas, such as the "Film Expert," tend to outperform the fixed general persona of an "Expert.
More examples can be found in Figures
     <a class="ltx_ref" href="#A4.F11" title="Figure 11 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       11
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#A4.F12" title="Figure 12 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       12
      </span>
     </a>
     , and
     <a class="ltx_ref" href="#A4.F13" title="Figure 13 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       13
      </span>
     </a>
     .
    </figcaption>
   </figure>
  </section>
  <section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    Dynamic personas v.s. fixed personas.
   </h4>
   <div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">
     To further investigate the importance of dynamically identifying personas for each task instance instead of fixing a general persona, an ablated variant of
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.1">
      SPP
     </span>
     ,
     <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS0.Px3.p1.1.2">
      SPP-Fixed-Persona
     </span>
     , is introduced.
For
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.3">
      SPP-Fixed-Persona
     </span>
     , we modify the prompt (Figure
     <a class="ltx_ref" href="#A5.F17" title="Figure 17 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     ) to force the personas to be fixed as an "AI Assistant" and an "Expert".
Comparing
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.4">
      SPP
     </span>
     and
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.5">
      SPP-Fixed-Persona
     </span>
     in Figure
     <a class="ltx_ref" href="#S3.F7.sf2" title="In Figure 7 ‣ 3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       7(b)
      </span>
     </a>
     , we have the following insights: (1)
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.6">
      SPP
     </span>
     consistently outperforms
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.7">
      SPP-Fixed-Persona
     </span>
     across all tasks, suggesting that dynamic, fine-grained personas are more effective than fixed, general personas. Qualitative examples in Figure
     <a class="ltx_ref" href="#S4.F8" title="Figure 8 ‣ LLMs can effectively identify useful personas in a zero-shot manner. ‣ 4 Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       8
      </span>
     </a>
     and
     <a class="ltx_ref" href="#A4.F13" title="Figure 13 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       13
      </span>
     </a>
     shows that the fine-grained personas such as "Film Expert" and "Sports Enthusiast" correctly provide the answers, while the fixed persona "Expert" fails.
(2)
     <span class="ltx_text" id="S4.SS0.SSS0.Px3.p1.1.8">
      SPP-Fixed-Persona
     </span>
     also suffers from the
     <span class="ltx_text ltx_font_bold" id="S4.SS0.SSS0.Px3.p1.1.9">
      early-termination
     </span>
     problem as defined in §
     <a class="ltx_ref" href="#S3.SS4" title="3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3.4
      </span>
     </a>
     , where the LLM stops collaboration before providing the final answer as if it were waiting for external inputs.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
   <h4 class="ltx_title ltx_title_paragraph">
    Impact of the demonstrations in
    <span class="ltx_text" id="S4.SS0.SSS0.Px4.1.1">
     SPP
    </span>
    prompt.
   </h4>
   <div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
    <p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">
     To investigate the effectiveness of the hand-crafted demonstration examples in
     <span class="ltx_text" id="S4.SS0.SSS0.Px4.p1.1.1">
      SPP
     </span>
     , we conduct an ablation study where we remove the second demo example and preserve the first one, which shows only a two-persona collaboration setting. As shown in Figure
     <a class="ltx_ref" href="#A1.F9" title="Figure 9 ‣ Task Prefix. ‣ A.1 SPP Prompt Design ‣ Appendix A Prompts ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       9
      </span>
     </a>
     , we observe that (1) Adding the second example, which requires collaboration of more than two personas, effectively boosts the performance. (2)
     <span class="ltx_text" id="S4.SS0.SSS0.Px4.p1.1.2">
      SPP
     </span>
     is fairly robust to the prompt change and show good performance with only the first demo example.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Work
  </h2>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    LLMs as role-playing agents.
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">
     Recent research
     <cite class="ltx_cite ltx_citemacro_citep">
      (Deshpande et al.,
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      ; Xu et al.,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      ; Fu et al.,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      ; aut,
      <a class="ltx_ref" href="#bib.bib1" title="">
       2023
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      )
     </cite>
     demonstrates that assigning personas or roles to LLMs influences their generation behavior. AI societies with distinct personas or occupations have been explored for collaboration
     <cite class="ltx_cite ltx_citemacro_citep">
      (Park et al.,
      <a class="ltx_ref" href="#bib.bib26" title="">
       2023
      </a>
      ; Schick et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2022
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      ; Cai et al.,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2023
      </a>
      )
     </cite>
     . However, limitations in persona assignment and multi-agent collaboration include single or fixed persona assignments
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al.,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2023
      </a>
      ; Fu et al.,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      ; Schick et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2022
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      )
     </cite>
     and the need for multiple LLM instances, increasing inference cost. In contrast,
     <span class="ltx_text" id="S5.SS0.SSS0.Px1.p1.1.1">
      SPP
     </span>
     uses a single LLM to dynamically identify useful personas for general tasks.
Our discovery on the emergent nature of cognitive synergy
also aligns with related work
     <cite class="ltx_cite ltx_citemacro_citep">
      (Olausson et al.,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2023
      </a>
      )
     </cite>
     , which investigates the emergent ability of self-debugging in code generation.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    Enhancing reasoning and factual knowledge in LLMs.
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">
     LLMs face challenges in complex knowledge-intensive tasks due to hallucination
     <cite class="ltx_cite ltx_citemacro_citep">
      (Maynez et al.,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2020
      </a>
      )
     </cite>
     and reasoning-intensive tasks due to the lack of human-like slow thinking
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sloman,
      <a class="ltx_ref" href="#bib.bib33" title="">
       1996
      </a>
      ; Kahneman,
      <a class="ltx_ref" href="#bib.bib18" title="">
       2011
      </a>
      )
     </cite>
     . Approaches like Chain-of-Thought (CoT) and Self-Refinement encourage LLMs to solve tasks step by step or iteratively revise their answers
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      ; Kojima et al.,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2022
      </a>
      ; Zhang et al.,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2022
      </a>
      ; Fu et al.,
      <a class="ltx_ref" href="#bib.bib11" title="">
       2022
      </a>
      ; Xue et al.,
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      ; Yao et al.,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      ; Madaan et al.,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2023
      </a>
      ; Shinn et al.,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2023
      </a>
      ; Gou et al.,
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      ; Chen et al.,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2023
      </a>
      ; Huang et al.,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2022
      </a>
      ; Yao et al.,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2022
      </a>
      )
     </cite>
     . However, these methods do not necessarily reduce factual hallucination. Retrieval augmented LLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Borgeaud et al.,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      ; Izacard et al.,
      <a class="ltx_ref" href="#bib.bib16" title="">
       2022
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2022
      </a>
      ; Shuster et al.,
      <a class="ltx_ref" href="#bib.bib32" title="">
       2021
      </a>
      )
     </cite>
     enhance knowledge acquisition but do not improve reasoning abilities. We propose Solo Performance Prompting (
     <span class="ltx_text" id="S5.SS0.SSS0.Px2.p1.1.1">
      SPP
     </span>
     ) to elicit both knowledge and reasoning abilities in LLMs, improving factuality while maintaining strong performance on pure-reasoning tasks.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    Solo Performance Prompting unleashes the cognitive synergy abilities within powerful LLMs, significantly reducing factual hallucination while enhancing reasoning.
The performance is assessed using newly proposed tasks, e.g., Trivia Creative Writing and Codenames Collaborative, demonstrating superior results compared to Standard, CoT and Self-Refine.
The discovery of the emergent nature of cognitive synergy on different LLMs draws interesting analogy to human development.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Limitations
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    Although Solo Performance Prompting exhibits promising improvements in acquiring factually correct knowledge compared to Standard prompting, it has some limitations. For instance, even when a fine-grained persona is assigned, the answer may still be incorrect. It remains unclear to what extent assigning a persona can help enhance domain knowledge in a specific area. Dedicated diagnostic experiments and theoretical efforts are needed to quantify the impact of having a persona or not.
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p2">
   <p class="ltx_p" id="Sx1.p2.1">
    Furthermore, we currently adopt an identical
    <span class="ltx_text" id="Sx1.p2.1.1">
     SPP
    </span>
    prompt with the same two demonstration examples for any given task inputs, which may be suboptimal.
Future work investigating how to find better demonstration examples conditioned on each input could further improve the effectiveness of
    <span class="ltx_text" id="Sx1.p2.1.2">
     SPP
    </span>
    .
   </p>
  </div>
  <div class="ltx_para" id="Sx1.p3">
   <p class="ltx_p" id="Sx1.p3.1">
    Last but not least, if given sufficient computational budget, a natural variant of
    <span class="ltx_text" id="Sx1.p3.1.1">
     SPP
    </span>
    could extend to a
    <span class="ltx_text ltx_font_italic" id="Sx1.p3.1.2">
     multi-agent cognitive synergist
    </span>
    setup where a leader persona identifies several expert agents and forms a cabinet to collaboratively solve a task. The multi-agent setup allows for leveraging richer computation power, larger local memory, and more flexible human-computer interaction, which could be essential for deploying to real-world applications.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     aut (2023)
    </span>
    <span class="ltx_bibblock">
     2023.
    </span>
    <span class="ltx_bibblock">
     Auto-gpt.
    </span>
    <span class="ltx_bibblock">
     https://github.com/Significant-Gravitas/Auto-GPT.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2302.04023
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Borgeaud et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Improving language models by retrieving from trillions of tokens.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      International conference on machine learning
     </em>
     , pages 2206–2240. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      Advances in neural information processing systems
     </em>
     , 33:1877–1901.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bubeck et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Sparks of artificial general intelligence: Early experiments with gpt-4.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2303.12712
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     Large language models as tool makers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      arXiv preprint arXiv:2305.17126
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     Teaching large language models to self-debug.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2304.05128
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Curşeu et al. (2015)
    </span>
    <span class="ltx_bibblock">
     Petru L Curşeu, Nicoleta Meslec, Helen Pluut, and Gerardus JM Lucas. 2015.
    </span>
    <span class="ltx_bibblock">
     Cognitive synergy in groups and group-to-individual transfer of decision-making competencies.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      Frontiers in psychology
     </em>
     , 6:1375.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Deshpande et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and Karthik Narasimhan. 2023.
    </span>
    <span class="ltx_bibblock">
     Toxicity in chatgpt: Analyzing persona-assigned language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2304.05335
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. 2023.
    </span>
    <span class="ltx_bibblock">
     Improving language model negotiation with self-play and in-context learning from ai feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      arXiv preprint arXiv:2305.10142
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022.
    </span>
    <span class="ltx_bibblock">
     Complexity-based prompting for multi-step reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2210.00720
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Goertzel (2009)
    </span>
    <span class="ltx_bibblock">
     Ben Goertzel. 2009.
    </span>
    <span class="ltx_bibblock">
     Cognitive synergy: A universal principle for feasible general intelligence.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      2009 8th IEEE International Conference on Cognitive Informatics
     </em>
     , pages 464–468. IEEE.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Goertzel (2017)
    </span>
    <span class="ltx_bibblock">
     Ben Goertzel. 2017.
    </span>
    <span class="ltx_bibblock">
     A formal model of cognitive synergy.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      Artificial General Intelligence: 10th International Conference, AGI 2017, Melbourne, VIC, Australia, August 15-18, 2017, Proceedings 10
     </em>
     , pages 13–22. Springer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gou et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.11738" target="_blank" title="">
      Critic: Large language models can self-correct with tool-interactive critiquing
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Inner monologue: Embodied reasoning through planning with language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2207.05608
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Izacard et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2022.
    </span>
    <span class="ltx_bibblock">
     Few-shot learning with retrieval augmented language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2208.03299
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Joshi et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P17-1147" target="_blank" title="">
      TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 1601–1611, Vancouver, Canada. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kahneman (2011)
    </span>
    <span class="ltx_bibblock">
     Daniel Kahneman. 2011.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Thinking, fast and slow
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     macmillan.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kojima et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.
    </span>
    <span class="ltx_bibblock">
     Large language models are zero-shot reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2205.11916
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for" mind" exploration of large scale language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2303.17760
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Madaan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Self-refine: Iterative refinement with self-feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2303.17651
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Maynez et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.173" target="_blank" title="">
      On faithfulness and factuality in abstractive summarization
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics
     </em>
     , pages 1906–1919, Online. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Olausson et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama. 2023.
    </span>
    <span class="ltx_bibblock">
     Demystifying gpt self-repair for code generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2306.09896
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023a)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023a.
    </span>
    <span class="ltx_bibblock">
     Gpt-35.
    </span>
    <span class="ltx_bibblock">
     https://platform.openai.com/docs/models/gpt-3-5.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023b)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.08774" target="_blank" title="">
      Gpt-4 technical report
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. 2023.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human behavior.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:2304.03442
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pellegrini (2009)
    </span>
    <span class="ltx_bibblock">
     Anthony D Pellegrini. 2009.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      The role of play in human development
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Oxford University Press, USA.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Piaget (1954)
    </span>
    <span class="ltx_bibblock">
     Jean Piaget. 1954.
    </span>
    <span class="ltx_bibblock">
     The construction of reality in the child.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023.
    </span>
    <span class="ltx_bibblock">
     Is chatgpt a general-purpose natural language processing task solver?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2302.06476
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and Sebastian Riedel. 2022.
    </span>
    <span class="ltx_bibblock">
     Peer: A collaborative language model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      arXiv preprint arXiv:2208.11663
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023.
    </span>
    <span class="ltx_bibblock">
     Reflexion: an autonomous agent with dynamic memory and self-reflection.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2303.11366
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shuster et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.
    </span>
    <span class="ltx_bibblock">
     Retrieval augmentation reduces hallucination in conversation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2104.07567
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sloman (1996)
    </span>
    <span class="ltx_bibblock">
     Steven A Sloman. 1996.
    </span>
    <span class="ltx_bibblock">
     The empirical case for two systems of reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Psychological bulletin
     </em>
     , 119(1):3.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Srivastava et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2206.04615
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Llama 2: Open foundation and fine-tuned chat models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2307.09288
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Zhenhailong Wang, Xiaoman Pan, Dian Yu, Dong Yu, Jianshu Chen, and Heng Ji. 2022.
    </span>
    <span class="ltx_bibblock">
     Zemi: Learning zero-shot semi-parametric language models from multiple tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2210.00185
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2201.11903" target="_blank" title="">
      Chain-of-thought prompting elicits reasoning in large language models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong Mao. 2023.
    </span>
    <span class="ltx_bibblock">
     Expertprompting: Instructing large language models to be distinguished experts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2305.14688
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. 2023.
    </span>
    <span class="ltx_bibblock">
     Rcot: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2305.11499
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2305.10601
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      ArXiv
     </em>
     , abs/2210.03629.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2210.03493" target="_blank" title="">
      Automatic chain of thought prompting in large language models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.05685" target="_blank" title="">
      Judging llm-as-a-judge with mt-bench and chatbot arena
     </a>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Prompts
  </h2>
  <section class="ltx_subsection" id="A1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.1
    </span>
    <span class="ltx_text" id="A1.SS1.1.1">
     SPP
    </span>
    Prompt Design
   </h3>
   <div class="ltx_para" id="A1.SS1.p1">
    <p class="ltx_p" id="A1.SS1.p1.1">
     To prompt an LLM to behave as a cognitive synergist that follows the expected task-solving procedure as mentioned in §
     <a class="ltx_ref" href="#S2" title="2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , we carefully designed the structure of the
     <span class="ltx_text" id="A1.SS1.p1.1.1">
      SPP
     </span>
     prompt as follows. The full prompts can be found in §
     <a class="ltx_ref" href="#A1.SS2" title="A.2 Full Prompts ‣ Appendix A Prompts ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       A.2
      </span>
     </a>
     .
     <span class="ltx_note ltx_role_footnote" id="footnote3">
      <sup class="ltx_note_mark">
       3
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         3
        </sup>
        <span class="ltx_tag ltx_tag_note">
         3
        </span>
        We use the same prompt for any arbitrary tasks.
       </span>
      </span>
     </span>
    </p>
   </div>
   <section class="ltx_paragraph" id="A1.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     System Principle.
    </h4>
    <div class="ltx_para" id="A1.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="A1.SS1.SSS0.Px1.p1.1">
      The first part of the prompt contains a high-level instruction:
      <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px1.p1.1.1">
       "When faced with a task, begin by identifying the participants who will contribute to solving the task. Then, initiate a multi-turn collaboration process until a final solution is reached. The participants will give critical comments and detailed suggestions whenever necessary."
      </span>
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A1.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Demonstration Examples.
    </h4>
    <div class="ltx_para" id="A1.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="A1.SS1.SSS0.Px2.p1.1">
      Then, we include two manually crafted demonstration examples to showcase the expected task-solving behavior. The first example describes a
      <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.1">
       Game of 24
      </span>
      task, where we only include two personas: an AI Assistant and a Math Expert. This task aims to provide an example of a
      <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.2">
       reasoning-intensive task
      </span>
      , where the AI Assistant needs to propose multiple proposals, and the other participants need to give
      <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.3">
       fine-grained feedback
      </span>
      on where the current solution went wrong and how to improve it. The second example describes a poem-writing task with
      <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.4">
       diverse requirements
      </span>
      , including lexical constraints, semantic constraints, and audience awareness. This task aims to provide an example of a
      <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.5">
       knowledge-intensive task
      </span>
      , where diverse personas are required to collaboratively solve the task. This example also demonstrates a case where it is important to assign a dedicated persona to the audience, e.g., a ten-year-old child.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A1.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Task Prefix.
    </h4>
    <div class="ltx_para" id="A1.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="A1.SS1.SSS0.Px3.p1.1">
      The last part of the prompt reminds the model to
      <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px3.p1.1.1">
       "identify the participants and collaboratively solve the following task step by step."
      </span>
      followed by task-specific format instructions and inputs.
     </p>
    </div>
    <figure class="ltx_figure" id="A1.F9">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="196" id="A1.F9.g1" src="/html/2307.05300/assets/images/spp_prompt_vairants_comparison.png" width="269"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 9:
      </span>
      Analysis on the impact of the demonstration examples in
      <span class="ltx_text" id="A1.F9.4.1">
       SPP
      </span>
      prompt. We compare the effectiveness of the original
      <span class="ltx_text" id="A1.F9.5.2">
       SPP
      </span>
      prompt with a variant where we remove the second demonstration example, which shows a multi-persona scenario. We observe that (1)
      <span class="ltx_text" id="A1.F9.6.3">
       SPP
      </span>
      is fairly robust to the change in the prompt; (2) adding an additional multi-persona example apart from the single-persona one effectively boosts performance on all three tasks.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="A1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.2
    </span>
    Full Prompts
   </h3>
   <div class="ltx_para" id="A1.SS2.p1">
    <p class="ltx_p" id="A1.SS2.p1.1">
     Figures
     <a class="ltx_ref" href="#A5.F15" title="Figure 15 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       15
      </span>
     </a>
     ,
     <a class="ltx_ref" href="#A5.F16" title="Figure 16 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       16
      </span>
     </a>
     and
     <a class="ltx_ref" href="#A5.F17" title="Figure 17 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     show the full prompts for
     <span class="ltx_text" id="A1.SS2.p1.1.1">
      SPP
     </span>
     ,
     <span class="ltx_text" id="A1.SS2.p1.1.2">
      SPP-Profile
     </span>
     and
     <span class="ltx_text" id="A1.SS2.p1.1.3">
      SPP-Fixed-Persona
     </span>
     respectively. Figure
     <a class="ltx_ref" href="#A5.F18" title="Figure 18 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       18
      </span>
     </a>
     shows the prompts for Chain-of-Thought (CoT) prompting. Figure
     <a class="ltx_ref" href="#A5.F19" title="Figure 19 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       19
      </span>
     </a>
     shows the prompts for Self-Refine prompting.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Task Details
  </h2>
  <figure class="ltx_figure" id="A2.F10">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_2">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf1">
      <p class="ltx_p" id="A2.F10.sf1.1">
       <span class="ltx_text" id="A2.F10.sf1.1.1" style="position:relative; bottom:0.0pt;">
        <span class="ltx_inline-block ltx_transformed_outer" id="A2.F10.sf1.1.1.1.1.1" style="width:435.5pt;height:324.5pt;vertical-align:-0.0pt;">
         <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
          <span class="ltx_p" id="A2.F10.sf1.1.1.1.1.1.1">
           <span class="ltx_text" id="A2.F10.sf1.1.1.1.1.1.1.1">
            <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="A2.F10.sf1.1.1.1.1.1.1.1.g1" src="/html/2307.05300/assets/images/TCW-N-1-N-5.png" width="598"/>
           </span>
          </span>
         </span>
        </span>
       </span>
      </p>
      <figcaption class="ltx_caption">
       <span class="ltx_tag ltx_tag_figure">
        (a)
       </span>
       Trivia Creative Writing with a large enough number of questions (N) effectively pose challenge to GPT-4 in terms of factual correctness. With N=1, different prompting methods result in similar performance, while with N&gt;=5,
       <span class="ltx_text" id="A2.F10.sf1.3.1">
        SPP
       </span>
       shows visible superiority.
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_cell ltx_flex_size_2">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf2">
      <p class="ltx_p" id="A2.F10.sf2.1">
       <span class="ltx_text" id="A2.F10.sf2.1.1" style="position:relative; bottom:0.0pt;">
        <span class="ltx_inline-block ltx_transformed_outer" id="A2.F10.sf2.1.1.1.1.1" style="width:435.5pt;height:324.5pt;vertical-align:-0.0pt;">
         <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
          <span class="ltx_p" id="A2.F10.sf2.1.1.1.1.1.1">
           <span class="ltx_text" id="A2.F10.sf2.1.1.1.1.1.1.1">
            <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="A2.F10.sf2.1.1.1.1.1.1.1.g1" src="/html/2307.05300/assets/images/TCW-N-5-shuffled.png" width="598"/>
           </span>
          </span>
         </span>
        </span>
       </span>
      </p>
      <figcaption class="ltx_caption">
       <span class="ltx_tag ltx_tag_figure">
        (b)
       </span>
       The ordering of the questions in the Trivia Creative Writing task does not bring too much impact. The performance on shuffled questions is close to the original ordered questions.
      </figcaption>
     </figure>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 10:
    </span>
    Analysis on the impact of the number of questions (N) and the ordering of the questions for the Trivia Creative Writing task.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="A2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.1
    </span>
    Trivia Creative Writing
   </h3>
   <div class="ltx_para" id="A2.SS1.p1">
    <p class="ltx_p" id="A2.SS1.p1.1">
     Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Models. ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     shows a detailed illustration of the Trivia Creative Writing task. Additionally, we investigate how the number of the questions (N) and the ordering of the questions would affect the performance on the Trivia Creative Writing task. As shown in Figure
     <a class="ltx_ref" href="#A2.F10" title="Figure 10 ‣ Appendix B Task Details ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
      <span class="ltx_text ltx_ref_tag">
       10
      </span>
     </a>
     , with a larger number of questions (N
     <math alttext="\geq" class="ltx_Math" display="inline" id="A2.SS1.p1.1.m1.1">
      <semantics id="A2.SS1.p1.1.m1.1a">
       <mo id="A2.SS1.p1.1.m1.1.1" xref="A2.SS1.p1.1.m1.1.1.cmml">
        ≥
       </mo>
       <annotation-xml encoding="MathML-Content" id="A2.SS1.p1.1.m1.1b">
        <geq id="A2.SS1.p1.1.m1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1">
        </geq>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="A2.SS1.p1.1.m1.1c">
        \geq
       </annotation>
      </semantics>
     </math>
     5), Trivia Creative Writing effectively challenges GPT-4’s performance. While a single question (N=1) yields similar outcomes regardless of the prompting method,
     <span class="ltx_text" id="A2.SS1.p1.1.1">
      SPP
     </span>
     approach is notably superior for larger Ns. The ordering of the questions has minimal impact to the task performance.
    </p>
   </div>
   <div class="ltx_para" id="A2.SS1.p2">
    <p class="ltx_p" id="A2.SS1.p2.1">
     The topic list is automatically generated by prompting GPT-4 to provide 100 nouns from pop culture
     <span class="ltx_note ltx_role_footnote" id="footnote4">
      <sup class="ltx_note_mark">
       4
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         4
        </sup>
        <span class="ltx_tag ltx_tag_note">
         4
        </span>
        The full prompt for generating the topic list can be found in Figure
        <a class="ltx_ref" href="#A5.F20" title="Figure 20 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
         <span class="ltx_text ltx_ref_tag">
          20
         </span>
        </a>
        . We performed further human curation to avoid potential harmful content.
       </span>
      </span>
     </span>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Inference Configurations
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.3">
    The main results in Table
    <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ Multi-Persona Iterative Collaboration (𝑧⁰_𝑠, 𝑧^𝑖_𝑓). ‣ 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    are obtained from GPT-4. The GPT-4 API version we employ is Azure 2023-3-15-preview.
    <span class="ltx_note ltx_role_footnote" id="footnote5">
     <sup class="ltx_note_mark">
      5
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        5
       </sup>
       <span class="ltx_tag ltx_tag_note">
        5
       </span>
       There are rare cases when a generation triggers the content filter of the API. We exclude those instances from our results.
      </span>
     </span>
    </span>
    The
    <span class="ltx_text ltx_font_italic" id="A3.p1.3.1">
     temperature
    </span>
    is set to
    <math alttext="0.0" class="ltx_Math" display="inline" id="A3.p1.1.m1.1">
     <semantics id="A3.p1.1.m1.1a">
      <mn id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml">
       0.0
      </mn>
      <annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b">
       <cn id="A3.p1.1.m1.1.1.cmml" type="float" xref="A3.p1.1.m1.1.1">
        0.0
       </cn>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">
       0.0
      </annotation>
     </semantics>
    </math>
    (most conservative) and
    <span class="ltx_text ltx_font_italic" id="A3.p1.3.2">
     top_p
    </span>
    to
    <math alttext="1.0" class="ltx_Math" display="inline" id="A3.p1.2.m2.1">
     <semantics id="A3.p1.2.m2.1a">
      <mn id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml">
       1.0
      </mn>
      <annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b">
       <cn id="A3.p1.2.m2.1.1.cmml" type="float" xref="A3.p1.2.m2.1.1">
        1.0
       </cn>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">
       1.0
      </annotation>
     </semantics>
    </math>
    for all generations to maximize reproducibility. Since even though the temperature is set to
    <math alttext="0.0" class="ltx_Math" display="inline" id="A3.p1.3.m3.1">
     <semantics id="A3.p1.3.m3.1a">
      <mn id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml">
       0.0
      </mn>
      <annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b">
       <cn id="A3.p1.3.m3.1.1.cmml" type="float" xref="A3.p1.3.m3.1.1">
        0.0
       </cn>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">
       0.0
      </annotation>
     </semantics>
    </math>
    the GPT-4 generation can still be non-deterministic, we conduct additional experiment to investigate its generation consistency under this configuration. As shown in Table
    <a class="ltx_ref" href="#A3.T3" title="Table 3 ‣ Appendix C Inference Configurations ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    , we perform three individual runs and compute the mean and standard deviation of the metric score on Trivia Creative Writing. We find that the variance is sufficiently small and Solo Performance Prompting enjoys lower variance than Standard and CoT prompting.
   </p>
  </div>
  <figure class="ltx_table" id="A3.T3">
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T3.3">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A3.T3.3.4.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A3.T3.3.4.1.1">
       <span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.1.1">
        Methods
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T3.3.4.1.2">
       <span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.2.1">
        Run 1
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T3.3.4.1.3">
       <span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.3.1">
        Run 2
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A3.T3.3.4.1.4">
       <span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.4.1">
        Run 3
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T3.3.4.1.5">
       <span class="ltx_text ltx_font_bold" id="A3.T3.3.4.1.5.1">
        Mean (std)
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A3.T3.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T3.1.1.2">
       Standard
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3">
       75.6
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.4">
       74.4
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T3.1.1.5">
       73.1
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.1">
       74.4
       <math alttext="\pm 1.3" class="ltx_Math" display="inline" id="A3.T3.1.1.1.m1.1">
        <semantics id="A3.T3.1.1.1.m1.1a">
         <mrow id="A3.T3.1.1.1.m1.1.1" xref="A3.T3.1.1.1.m1.1.1.cmml">
          <mo id="A3.T3.1.1.1.m1.1.1a" xref="A3.T3.1.1.1.m1.1.1.cmml">
           ±
          </mo>
          <mn id="A3.T3.1.1.1.m1.1.1.2" xref="A3.T3.1.1.1.m1.1.1.2.cmml">
           1.3
          </mn>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.m1.1b">
          <apply id="A3.T3.1.1.1.m1.1.1.cmml" xref="A3.T3.1.1.1.m1.1.1">
           <csymbol cd="latexml" id="A3.T3.1.1.1.m1.1.1.1.cmml" xref="A3.T3.1.1.1.m1.1.1">
            plus-or-minus
           </csymbol>
           <cn id="A3.T3.1.1.1.m1.1.1.2.cmml" type="float" xref="A3.T3.1.1.1.m1.1.1.2">
            1.3
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.T3.1.1.1.m1.1c">
          \pm 1.3
         </annotation>
        </semantics>
       </math>
      </td>
     </tr>
     <tr class="ltx_tr" id="A3.T3.2.2">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T3.2.2.2">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="A3.T3.2.2.3">
       68.8
      </td>
      <td class="ltx_td ltx_align_center" id="A3.T3.2.2.4">
       69.6
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r" id="A3.T3.2.2.5">
       70.8
      </td>
      <td class="ltx_td ltx_align_center" id="A3.T3.2.2.1">
       69.7
       <math alttext="\pm 1.0" class="ltx_Math" display="inline" id="A3.T3.2.2.1.m1.1">
        <semantics id="A3.T3.2.2.1.m1.1a">
         <mrow id="A3.T3.2.2.1.m1.1.1" xref="A3.T3.2.2.1.m1.1.1.cmml">
          <mo id="A3.T3.2.2.1.m1.1.1a" xref="A3.T3.2.2.1.m1.1.1.cmml">
           ±
          </mo>
          <mn id="A3.T3.2.2.1.m1.1.1.2" xref="A3.T3.2.2.1.m1.1.1.2.cmml">
           1.0
          </mn>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A3.T3.2.2.1.m1.1b">
          <apply id="A3.T3.2.2.1.m1.1.1.cmml" xref="A3.T3.2.2.1.m1.1.1">
           <csymbol cd="latexml" id="A3.T3.2.2.1.m1.1.1.1.cmml" xref="A3.T3.2.2.1.m1.1.1">
            plus-or-minus
           </csymbol>
           <cn id="A3.T3.2.2.1.m1.1.1.2.cmml" type="float" xref="A3.T3.2.2.1.m1.1.1.2">
            1.0
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.T3.2.2.1.m1.1c">
          \pm 1.0
         </annotation>
        </semantics>
       </math>
      </td>
     </tr>
     <tr class="ltx_tr" id="A3.T3.3.3">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A3.T3.3.3.2">
       <span class="ltx_text" id="A3.T3.3.3.2.1">
        SPP
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.3.3.3">
       80.0
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.3.3.4">
       79.8
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A3.T3.3.3.5">
       80.8
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.3.3.1">
       80.2
       <math alttext="\pm 0.5" class="ltx_Math" display="inline" id="A3.T3.3.3.1.m1.1">
        <semantics id="A3.T3.3.3.1.m1.1a">
         <mrow id="A3.T3.3.3.1.m1.1.1" xref="A3.T3.3.3.1.m1.1.1.cmml">
          <mo id="A3.T3.3.3.1.m1.1.1a" xref="A3.T3.3.3.1.m1.1.1.cmml">
           ±
          </mo>
          <mn id="A3.T3.3.3.1.m1.1.1.2" xref="A3.T3.3.3.1.m1.1.1.2.cmml">
           0.5
          </mn>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A3.T3.3.3.1.m1.1b">
          <apply id="A3.T3.3.3.1.m1.1.1.cmml" xref="A3.T3.3.3.1.m1.1.1">
           <csymbol cd="latexml" id="A3.T3.3.3.1.m1.1.1.1.cmml" xref="A3.T3.3.3.1.m1.1.1">
            plus-or-minus
           </csymbol>
           <cn id="A3.T3.3.3.1.m1.1.1.2.cmml" type="float" xref="A3.T3.3.3.1.m1.1.1.2">
            0.5
           </cn>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.T3.3.3.1.m1.1c">
          \pm 0.5
         </annotation>
        </semantics>
       </math>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 3:
    </span>
    Investigation on the generation consistency of GPT-4 API. The experiment is performed on the Trivia Creative Task (N=5). We set the inference temperature to 0.0 and top_p to 1.0 as all experiments conducted in the paper. The results show that the GPT-4 generation is fairly consistent with a small variance (
    <math alttext="\sim 1\%" class="ltx_Math" display="inline" id="A3.T3.5.m1.1">
     <semantics id="A3.T3.5.m1.1b">
      <mrow id="A3.T3.5.m1.1.1" xref="A3.T3.5.m1.1.1.cmml">
       <mi id="A3.T3.5.m1.1.1.2" xref="A3.T3.5.m1.1.1.2.cmml">
       </mi>
       <mo id="A3.T3.5.m1.1.1.1" xref="A3.T3.5.m1.1.1.1.cmml">
        ∼
       </mo>
       <mrow id="A3.T3.5.m1.1.1.3" xref="A3.T3.5.m1.1.1.3.cmml">
        <mn id="A3.T3.5.m1.1.1.3.2" xref="A3.T3.5.m1.1.1.3.2.cmml">
         1
        </mn>
        <mo id="A3.T3.5.m1.1.1.3.1" xref="A3.T3.5.m1.1.1.3.1.cmml">
         %
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="A3.T3.5.m1.1c">
       <apply id="A3.T3.5.m1.1.1.cmml" xref="A3.T3.5.m1.1.1">
        <csymbol cd="latexml" id="A3.T3.5.m1.1.1.1.cmml" xref="A3.T3.5.m1.1.1.1">
         similar-to
        </csymbol>
        <csymbol cd="latexml" id="A3.T3.5.m1.1.1.2.cmml" xref="A3.T3.5.m1.1.1.2">
         absent
        </csymbol>
        <apply id="A3.T3.5.m1.1.1.3.cmml" xref="A3.T3.5.m1.1.1.3">
         <csymbol cd="latexml" id="A3.T3.5.m1.1.1.3.1.cmml" xref="A3.T3.5.m1.1.1.3.1">
          percent
         </csymbol>
         <cn id="A3.T3.5.m1.1.1.3.2.cmml" type="integer" xref="A3.T3.5.m1.1.1.3.2">
          1
         </cn>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A3.T3.5.m1.1d">
       \sim 1\%
      </annotation>
     </semantics>
    </math>
    ). We also observe that
    <span class="ltx_text" id="A3.T3.7.1">
     SPP
    </span>
    shows lower variance compared with Standard and CoT prompting across different runs.
   </figcaption>
  </figure>
  <div class="ltx_para" id="A3.p2">
   <p class="ltx_p" id="A3.p2.1">
    To evaluate the potential impact of initial persona assignment through a system message, we consider two inference settings:
    <span class="ltx_text ltx_font_italic" id="A3.p2.1.1">
     with
    </span>
    or
    <span class="ltx_text ltx_font_italic" id="A3.p2.1.2">
     without
    </span>
    the default system message,
    <span class="ltx_text ltx_font_typewriter" id="A3.p2.1.3">
     "You are an AI assistant that helps people find information"
    </span>
    . Divergent patterns are observed across various tasks and methods regarding the use of the system message. We report the average metric scores across both inference settings in Table
    <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ Multi-Persona Iterative Collaboration (𝑧⁰_𝑠, 𝑧^𝑖_𝑓). ‣ 2 Solo Performance Prompting ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    . Full GPT-4 results for each setting can be found in Appendix
    <a class="ltx_ref" href="#A6" title="Appendix F Full Results ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      F
     </span>
    </a>
    .
   </p>
  </div>
  <div class="ltx_para" id="A3.p3">
   <p class="ltx_p" id="A3.p3.1">
    For GPT-3.5 results in Figure
    <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ Results. ‣ 3.3 Logic Grid Puzzle: A Reasoning-Intensive Task ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    , we employ the same prompt, hyper-parameters and the best system message setting in terms of
    <span class="ltx_text" id="A3.p3.1.1">
     SPP
    </span>
    ’s GPT-4 performance. For Llama2, we leverage the Huggingface text-generation pipeline
    <span class="ltx_note ltx_role_footnote" id="footnote6">
     <sup class="ltx_note_mark">
      6
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        6
       </sup>
       <span class="ltx_tag ltx_tag_note">
        6
       </span>
       https://huggingface.co/blog/llama2
      </span>
     </span>
    </span>
    with greedy decoding.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A4">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix D
   </span>
   Additional Qualitative Analysis
  </h2>
  <figure class="ltx_figure" id="A4.F11">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="A4.F11.g1" src="/html/2307.05300/assets/x8.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 11:
    </span>
    SPP vs CoT qualitative examples on Trivia Creative Writing (N=5). We find that although CoT generates reasonable plans or steps, it tends to suffer from factual errors and hallucination.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A4.F12">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="564" id="A4.F12.g1" src="/html/2307.05300/assets/x9.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 12:
    </span>
    SPP vs CoT qualitative examples on Codenames Collaborative. We find that
    <span class="ltx_text" id="A4.F12.2.1">
     SPP
    </span>
    provides much more detailed and interpretable intermediate discussions from various perspectives, which leads to stronger knowledge selection, integration, and theory-of-mind capabilities.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A4.F13">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="345" id="A4.F13.g1" src="/html/2307.05300/assets/x10.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 13:
    </span>
    SPP vs SPP-Fixed-Persona qualitative examples on Trivia Creative Writing (N=5). Each example shows one of the trivia questions in the input instance, the identified participants and the provided answer. We observe that the dynamically identified fine-grained personas, such as "Film Expert", "Music Enthusiast" and "Sports Enthusiast", tend to outperform the fixed general personas, "Expert".
   </figcaption>
  </figure>
  <div class="ltx_para" id="A4.p1">
   <p class="ltx_p" id="A4.p1.1">
    Figure
    <a class="ltx_ref" href="#A4.F11" title="Figure 11 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      11
     </span>
    </a>
    presents examples of the Trivia Creative Writing task, illustrating that although CoT can generate plausible plans for task resolution, the final outcomes often contain factual inaccuracies and instances of hallucination. In contrast,
    <span class="ltx_text" id="A4.p1.1.1">
     SPP
    </span>
    elicits precise knowledge with fine-grained personas.
   </p>
  </div>
  <div class="ltx_para" id="A4.p2">
   <p class="ltx_p" id="A4.p2.1">
    Figure
    <a class="ltx_ref" href="#A4.F12" title="Figure 12 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      12
     </span>
    </a>
    displays examples of the Codenames Collaborative task, illustrating that
    <span class="ltx_text" id="A4.p2.1.1">
     SPP
    </span>
    generates intermediate dialogues that are both
    <span class="ltx_text ltx_font_italic" id="A4.p2.1.2">
     detailed
    </span>
    and
    <span class="ltx_text ltx_font_italic" id="A4.p2.1.3">
     interpretable
    </span>
    , leading to superior performance compared to CoT.
   </p>
  </div>
  <div class="ltx_para" id="A4.p3">
   <p class="ltx_p" id="A4.p3.1">
    Figure
    <a class="ltx_ref" href="#A4.F13" title="Figure 13 ‣ Appendix D Additional Qualitative Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      13
     </span>
    </a>
    shows additional qualitative examples on Solo Performance Prompting vs
    <span class="ltx_text" id="A4.p3.1.1">
     SPP-Profile
    </span>
    .
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A5">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix E
   </span>
   Early-termination with
   <span class="ltx_text" id="A5.1.1">
    SPP-Fixed-Persona
   </span>
  </h2>
  <figure class="ltx_figure" id="A5.F14">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="511" id="A5.F14.g1" src="/html/2307.05300/assets/x11.png" width="438"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 14:
    </span>
    Examples of the early-termination problem with
    <span class="ltx_text" id="A5.F14.3.1">
     SPP
    </span>
    on Llama2-13b-chat and
    <span class="ltx_text" id="A5.F14.4.2">
     SPP-Fixed-Persona
    </span>
    on GPT-4.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A5.T4">
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T4.1">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A5.T4.1.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A5.T4.1.1.1.1">
       <span class="ltx_text ltx_font_bold" id="A5.T4.1.1.1.1.1">
        Tasks
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T4.1.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A5.T4.1.1.1.2.1">
        added system message
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T4.1.1.1.3">
       <span class="ltx_text ltx_font_bold" id="A5.T4.1.1.1.3.1">
        # early-termination
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A5.T4.1.2.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T4.1.2.1.1" rowspan="2">
       <span class="ltx_text" id="A5.T4.1.2.1.1.1">
        Trivia Creative Writing (N=5)
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.2.1.2">
       yes
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.2.1.3">
       18 / 100
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.3.2">
      <td class="ltx_td ltx_align_center" id="A5.T4.1.3.2.1">
       no
      </td>
      <td class="ltx_td ltx_align_center" id="A5.T4.1.3.2.2">
       0 / 100
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.4.3">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T4.1.4.3.1" rowspan="2">
       <span class="ltx_text" id="A5.T4.1.4.3.1.1">
        Trivia Creative Writing (N=10)
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.4.3.2">
       yes
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.4.3.3">
       16 / 100
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.5.4">
      <td class="ltx_td ltx_align_center" id="A5.T4.1.5.4.1">
       no
      </td>
      <td class="ltx_td ltx_align_center" id="A5.T4.1.5.4.2">
       1 / 100
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.6.5">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T4.1.6.5.1" rowspan="2">
       <span class="ltx_text" id="A5.T4.1.6.5.1.1">
        Codenames Collaborative
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.6.5.2">
       yes
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.6.5.3">
       37 / 50
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.7.6">
      <td class="ltx_td ltx_align_center" id="A5.T4.1.7.6.1">
       no
      </td>
      <td class="ltx_td ltx_align_center" id="A5.T4.1.7.6.2">
       4 / 50
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.8.7">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A5.T4.1.8.7.1" rowspan="2">
       <span class="ltx_text" id="A5.T4.1.8.7.1.1">
        Logic Grid Puzzle
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.8.7.2">
       yes
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T4.1.8.7.3">
       11 / 200
      </td>
     </tr>
     <tr class="ltx_tr" id="A5.T4.1.9.8">
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T4.1.9.8.1">
       no
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T4.1.9.8.2">
       15 / 200
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 4:
    </span>
    Early termination statistics on
    <span class="ltx_text ltx_font_italic" id="A5.T4.4.1">
     SPP-Fixed-Persona
    </span>
    : Removing the system message,
    <span class="ltx_text ltx_font_typewriter" id="A5.T4.5.2">
     "You are an AI assistant that helps people find information."
    </span>
    , can effectively reduce the problem but cannot fully eliminate it.
   </figcaption>
  </figure>
  <div class="ltx_para" id="A5.p1">
   <p class="ltx_p" id="A5.p1.1">
    Figure
    <a class="ltx_ref" href="#A5.F14" title="Figure 14 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      14
     </span>
    </a>
    shows an example of the early-termination problem (defined in §
    <a class="ltx_ref" href="#S4" title="4 Analysis ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    ) where the generation stops before reaching the final solution as if the models is waiting input from an external user.
   </p>
  </div>
  <div class="ltx_para" id="A5.p2">
   <p class="ltx_p" id="A5.p2.1">
    The problem is particularly severe on certain tasks, e.g., Codenames Collaborative, resulting in unexpectedly low performance as shown in Figure
    <a class="ltx_ref" href="#S3.F7.sf2" title="In Figure 7 ‣ 3.4 The Emergence of Cognitive Synergy ‣ 3 Experiments ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      7(b)
     </span>
    </a>
    .
The problem can be largely alleviated by removing the system message but cannot be entirely eliminated. Table
    <a class="ltx_ref" href="#A5.T4" title="Table 4 ‣ Appendix E Early-termination with SPP-Fixed-Persona ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    shows the statistics of the early-termination problem for each task and method. In contrast, we did not observe early-termination on
    <span class="ltx_text" id="A5.p2.1.1">
     SPP
    </span>
    ,
    <span class="ltx_text" id="A5.p2.1.2">
     SPP-Profile
    </span>
    , Standard, or CoT prompting with GPT-4.
   </p>
  </div>
  <figure class="ltx_figure" id="A5.F15">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="531" id="A5.F15.g1" src="/html/2307.05300/assets/x12.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 15:
    </span>
    <span class="ltx_text" id="A5.F15.2.1">
     SPP
    </span>
    full prompt.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A5.F16">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="206" id="A5.F16.g1" src="/html/2307.05300/assets/x13.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 16:
    </span>
    <span class="ltx_text" id="A5.F16.5.1">
     SPP-Profile
    </span>
    full prompt. "[…]" indicates identical parts with
    <span class="ltx_text" id="A5.F16.6.2">
     SPP
    </span>
    . Green text indicates the key difference between
    <span class="ltx_text" id="A5.F16.7.3">
     SPP-Profile
    </span>
    and
    <span class="ltx_text" id="A5.F16.8.4">
     SPP
    </span>
    .
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A5.F17">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="525" id="A5.F17.g1" src="/html/2307.05300/assets/x14.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 17:
    </span>
    <span class="ltx_text" id="A5.F17.4.1">
     SPP-Fixed-Persona
    </span>
    full prompt. Red text indicates the key difference between
    <span class="ltx_text" id="A5.F17.5.2">
     SPP-Fixed-Persona
    </span>
    and
    <span class="ltx_text" id="A5.F17.6.3">
     SPP
    </span>
    .
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A5.F18">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="145" id="A5.F18.g1" src="/html/2307.05300/assets/x15.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 18:
    </span>
    CoT prompts.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A5.F19">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="207" id="A5.F19.g1" src="/html/2307.05300/assets/x16.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 19:
    </span>
    Self-refine prompts.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A5.F20">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="41" id="A5.F20.g1" src="/html/2307.05300/assets/x17.png" width="461"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 20:
    </span>
    Prompt for generating the topic list for the Trivia Creative Writing task.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A6">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix F
   </span>
   Full Results
  </h2>
  <div class="ltx_para" id="A6.p1">
   <p class="ltx_p" id="A6.p1.1">
    Full results of the three tasks: Trivia Creative Writing, Codenames Collaborative and Logic Grid Puzzle can be found in Tables
    <a class="ltx_ref" href="#A6.T5" title="Table 5 ‣ Appendix F Full Results ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A6.T6" title="Table 6 ‣ Appendix F Full Results ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    and
    <a class="ltx_ref" href="#A6.T7" title="Table 7 ‣ Appendix F Full Results ‣ Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    , respectively.
   </p>
  </div>
  <figure class="ltx_table" id="A6.T5">
   <div class="ltx_flex_figure ltx_flex_table">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A6.T5.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A6.T5.1.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A6.T5.1.1.1.1" rowspan="2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.1.1.1.1">
          Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A6.T5.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.1.1.2.1">
          Scores (N = 5) (%)
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.2.2">
        <td class="ltx_td ltx_align_center" id="A6.T5.1.2.2.1">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.2.2.1.1">
          w/ system message
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.2.2.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.2.2.2.1">
          w/o system message
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.2.2.3">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.2.2.3.1">
          average
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.2.2.4">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.2.2.4.1">
          max
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.1.3.3.1">
         Standard
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.3.3.2">
         75.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.3.3.3">
         73.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.3.3.4">
         74.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.3.3.5">
         75.6
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.1.4.4.1">
         CoT
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.4.4.2">
         68.8
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.4.4.3">
         65.6
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.4.4.4">
         67.1
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.4.4.5">
         68.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.5.5">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.1.5.5.1">
         Self-Refine [iter=0]
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.5.5.2">
         74.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.5.5.3">
         72.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.5.5.4">
         73.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.5.5.5">
         74.9
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.6.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.1.6.6.1">
         Self-Refine [iter=1]
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.6.6.2">
         75.3
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.6.6.3">
         72.5
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.6.6.4">
         73.9
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.6.6.5">
         75.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.7.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.1.7.7.1">
         SPP-Fixed-Persona
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.7.7.2">
         66.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.7.7.3">
         79.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.7.7.4">
         72.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.1.7.7.5">
         79.6
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.8.8">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.1.8.8.1">
         SPP-Profile
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.8.8.2">
         79.8
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.8.8.3">
         78.3
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.8.8.4">
         79.1
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.1.8.8.5">
         79.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.1.9.9">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A6.T5.1.9.9.1">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.9.9.1.1">
          SPP
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.1.9.9.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.9.9.2.1">
          80.0
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.1.9.9.3">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.9.9.3.1">
          79.8
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.1.9.9.4">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.9.9.4.1">
          79.9
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.1.9.9.5">
         <span class="ltx_text ltx_font_bold" id="A6.T5.1.9.9.5.1">
          80.0
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A6.T5.2">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A6.T5.2.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A6.T5.2.1.1.1" rowspan="2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.1.1.1.1">
          Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A6.T5.2.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.1.1.2.1">
          Scores (N = 10) (%)
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.2.2">
        <td class="ltx_td ltx_align_center" id="A6.T5.2.2.2.1">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.2.2.1.1">
          w/ system message
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.2.2.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.2.2.2.1">
          w/o system message
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.2.2.3">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.2.2.3.1">
          average
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.2.2.4">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.2.2.4.1">
          max
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.2.3.3.1">
         Standard
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.3.3.2">
         77.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.3.3.3">
         76.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.3.3.4">
         77.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.3.3.5">
         77.2
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.2.4.4.1">
         CoT
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.4.4.2">
         71.6
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.4.4.3">
         65.3
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.4.4.4">
         68.5
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.4.4.5">
         71.6
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.5.5">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.2.5.5.1">
         Self-Refine [iter=0]
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.5.5.2">
         77.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.5.5.3">
         75.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.5.5.4">
         76.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.5.5.5">
         77.1
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.6.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.2.6.6.1">
         Self-Refine [iter=1]
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.6.6.2">
         78.2
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.6.6.3">
         75.6
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.6.6.4">
         76.9
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.6.6.5">
         78.2
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.7.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T5.2.7.7.1">
         SPP-Fixed-Persona
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.7.7.2">
         70.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.7.7.3">
         81.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.7.7.4">
         75.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T5.2.7.7.5">
         81.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.8.8">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T5.2.8.8.1">
         SPP-Profile
        </th>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.8.8.2">
         82.3
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.8.8.3">
         83.8
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.8.8.4">
         83.0
        </td>
        <td class="ltx_td ltx_align_center" id="A6.T5.2.8.8.5">
         83.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A6.T5.2.9.9">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A6.T5.2.9.9.1">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.9.9.1.1">
          SPP
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.2.9.9.2">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.9.9.2.1">
          85.2
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.2.9.9.3">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.9.9.3.1">
          84.2
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.2.9.9.4">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.9.9.4.1">
          84.7
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T5.2.9.9.5">
         <span class="ltx_text ltx_font_bold" id="A6.T5.2.9.9.5.1">
          85.2
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 5:
    </span>
    Trivia Creative Writing full results, including two inference settings: with system message and without system message. "average" and "max" indicating the mean and max score across the two settings. The system message we use is:
    <span class="ltx_text ltx_font_typewriter" id="A6.T5.4.1">
     ‘‘You are an AI assistant that helps people find information.’’
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A6.T6">
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T6.1">
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A6.T6.1.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A6.T6.1.1.1.1" rowspan="2">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.1.1.1.1">
        Methods
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A6.T6.1.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.1.1.2.1">
        Scores (%)
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.2.2">
      <td class="ltx_td ltx_align_center" id="A6.T6.1.2.2.1">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.2.2.1.1">
        w/ system message
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.2.2.2">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.2.2.2.1">
        w/o system message
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.2.2.3">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.2.2.3.1">
        average
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.2.2.4">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.2.2.4.1">
        max
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.3.3">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T6.1.3.3.1">
       Standard
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.3.3.2">
       74.5
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.3.3.3">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.3.3.3.1">
        76.3
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.3.3.4">
       75.4
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.3.3.5">
       76.3
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.4.4">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T6.1.4.4.1">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.4.4.2">
       71.4
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.4.4.3">
       74.0
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.4.4.4">
       72.7
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.4.4.5">
       74.0
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.5.5">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T6.1.5.5.1">
       Self-Refine [iter=0]
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.5.5.2">
       77.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.5.5.3">
       73.2
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.5.5.4">
       75.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.5.5.5">
       77.3
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.6.6">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T6.1.6.6.1">
       Self-Refine [iter=1]
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.6.6.2">
       70.1
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.6.6.3">
       58.8
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.6.6.4">
       64.4
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.6.6.5">
       70.1
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.7.7">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T6.1.7.7.1">
       SPP-Fixed-Persona
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.7.7.2">
       10.1
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.7.7.3">
       66.0
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.7.7.4">
       38.1
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T6.1.7.7.5">
       66.0
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.8.8">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T6.1.8.8.1">
       SPP-Profile
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.8.8.2">
       80.4
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.8.8.3">
       72.9
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.8.8.4">
       76.7
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T6.1.8.8.5">
       80.4
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T6.1.9.9">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A6.T6.1.9.9.1">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.9.9.1.1">
        SPP
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T6.1.9.9.2">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.9.9.2.1">
        82.5
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T6.1.9.9.3">
       75.5
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T6.1.9.9.4">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.9.9.4.1">
        79.0
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T6.1.9.9.5">
       <span class="ltx_text ltx_font_bold" id="A6.T6.1.9.9.5.1">
        82.5
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 6:
    </span>
    Codenames Collaborative full results, including two inference settings: with system message and without system message. "average" and "max" indicating the mean and max score across the two settings. The system message we use is:
    <span class="ltx_text ltx_font_typewriter" id="A6.T6.3.1">
     ‘‘You are an AI assistant that helps people find information.’’
    </span>
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A6.T7">
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T7.1">
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A6.T7.1.1.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A6.T7.1.1.1.1" rowspan="2">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.1.1.1.1">
        Methods
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A6.T7.1.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.1.1.2.1">
        Scores (%)
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.2.2">
      <td class="ltx_td ltx_align_center" id="A6.T7.1.2.2.1">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.2.2.1.1">
        w/ system message
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.2.2.2">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.2.2.2.1">
        w/o system message
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.2.2.3">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.2.2.3.1">
        average
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.2.2.4">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.2.2.4.1">
        max
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.3.3">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T7.1.3.3.1">
       Standard
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.3.3.2">
       56.8
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.3.3.3">
       58.6
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.3.3.4">
       57.7
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.3.3.5">
       58.6
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.4.4">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T7.1.4.4.1">
       CoT
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.4.4.2">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.4.4.2.1">
        69.5
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.4.4.3">
       62.1
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.4.4.4">
       65.8
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.4.4.5">
       69.5
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.5.5">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T7.1.5.5.1">
       Self-Refine [iter=0]
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.5.5.2">
       62.0
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.5.5.3">
       55.5
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.5.5.4">
       58.8
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.5.5.5">
       62.0
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.6.6">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T7.1.6.6.1">
       Self-Refine [iter=1]
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.6.6.2">
       64.5
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.6.6.3">
       55.5
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.6.6.4">
       60.0
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.6.6.5">
       64.5
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.7.7">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T7.1.7.7.1">
       SPP-Fixed-Persona
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.7.7.2">
       63.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.7.7.3">
       65.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.7.7.4">
       64.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T7.1.7.7.5">
       65.3
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.8.8">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T7.1.8.8.1">
       SPP-Profile
      </th>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.8.8.2">
       65.7
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.8.8.3">
       64.0
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.8.8.4">
       64.8
      </td>
      <td class="ltx_td ltx_align_center" id="A6.T7.1.8.8.5">
       65.7
      </td>
     </tr>
     <tr class="ltx_tr" id="A6.T7.1.9.9">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A6.T7.1.9.9.1">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.9.9.1.1">
        SPP
       </span>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T7.1.9.9.2">
       66.3
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T7.1.9.9.3">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.9.9.3.1">
        70.4
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T7.1.9.9.4">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.9.9.4.1">
        68.3
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T7.1.9.9.5">
       <span class="ltx_text ltx_font_bold" id="A6.T7.1.9.9.5.1">
        70.4
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 7:
    </span>
    Logic Grid Puzzle full results, including two inference settings: with system message and without system message. "average" and "max" indicating the mean and max score across the two settings. The system message we use is:
    <span class="ltx_text ltx_font_typewriter" id="A6.T7.3.1">
     ‘‘You are an AI assistant that helps people find information.’’
    </span>
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A7">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix G
   </span>
   Usage of AI assistants in writing
  </h2>
  <div class="ltx_para" id="A7.p1">
   <p class="ltx_p" id="A7.p1.1">
    We used ChatGPT and GPT-4 solely for checking and correcting grammars.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
</article>
