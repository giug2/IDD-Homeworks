<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Evaluating Automatic Metrics with Incremental Machine Translation Systems</title>
<!--Generated on Thu Oct  3 13:51:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.03277v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S1" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S2" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS1" title="In 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS2" title="In 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS2.SSS1" title="In 3.2 Metrics ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Surface-level overlap</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS2.SSS2" title="In 3.2 Metrics ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Embedding based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS2.SSS3" title="In 3.2 Metrics ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Trained with human judgements</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.SS1" title="In 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>How do metric scores change over time?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.SS2" title="In 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>How good can the metrics rank incremental systems accurately?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.SS3" title="In 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Does the reliability of metrics depend on the quality of the systems evaluated?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.SS4" title="In 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Can synthetic references serve as an alternative to human references?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S5" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A1" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Metric scores for English <math alttext="\rightarrow" class="ltx_Math" display="inline"><semantics><mo stretchy="false">→</mo><annotation-xml encoding="MathML-Content"><ci>→</ci></annotation-xml><annotation encoding="application/x-tex">\rightarrow</annotation><annotation encoding="application/x-llamapun">→</annotation></semantics></math> Spanish translations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A2" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Metric scores over time</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A3" title="In Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Accuracy across language pairs</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Evaluating Automatic Metrics 
<br class="ltx_break"/>with Incremental Machine Translation Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.id1">Guojun Wu<sup class="ltx_sup" id="id1.1.id1.1"><span class="ltx_text ltx_font_medium" id="id1.1.id1.1.1">1</span></sup></span>  <span class="ltx_text ltx_font_bold" id="id2.2.id2">Shay B. Cohen<sup class="ltx_sup" id="id2.2.id2.1"><span class="ltx_text ltx_font_medium" id="id2.2.id2.1.1">2</span></sup></span>  <span class="ltx_text ltx_font_bold" id="id3.3.id3">Rico Sennrich<sup class="ltx_sup" id="id3.3.id3.1"><span class="ltx_text ltx_font_medium" id="id3.3.id3.1.1">1,2</span></sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id4.4.id4">1</sup>Department of Computational Linguistics, University of Zurich 
<br class="ltx_break"/><sup class="ltx_sup" id="id5.5.id5">2</sup>School of Informatics, University of Edinburgh 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.6.id6">guojun.wu@uzh.ch,</span> <span class="ltx_text ltx_font_typewriter" id="id7.7.id7">scohen@inf.ed.ac.uk,</span> <span class="ltx_text ltx_font_typewriter" id="id8.8.id8">sennrich@cl.uzh.ch</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id9.id1">We introduce a dataset comprising commercial machine translations, gathered weekly over six years across 12 translation directions. Since human A/B testing is commonly used, we assume commercial systems improve over time, which enables us to evaluate machine translation (MT) metrics based on their preference for more recent translations. Our study not only confirms several prior findings, such as the advantage of neural metrics over non-neural ones, but also explores the debated issue of how MT quality affects metric reliability—an investigation that smaller datasets in previous research could not sufficiently explore. Overall, our research demonstrates the dataset’s value as a testbed for metric evaluation. We release our code.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/gjwubyron/Evo" title="">https://github.com/gjwubyron/Evo</a></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Evaluating Automatic Metrics 
<br class="ltx_break"/>with Incremental Machine Translation Systems</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Guojun Wu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.1.1">1</span></sup>  Shay B. Cohen<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.2.1">2</span></sup>  Rico Sennrich<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.3.1">1,2</span></sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1">1</sup>Department of Computational Linguistics, University of Zurich</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">2</sup>School of Informatics, University of Edinburgh</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.4.1.1">guojun.wu@uzh.ch,</span> <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.4.1.2">scohen@inf.ed.ac.uk,</span> <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.4.1.3">sennrich@cl.uzh.ch</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Automatic metrics for machine translation (MT) are typically assessed by measuring their correlation with or accuracy with respect to human judgments <cite class="ltx_cite ltx_citemacro_cite">Macháček and Bojar (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib15" title="">2013</a>); Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib17" title="">2020b</a>); Kocmi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib11" title="">2021</a>)</cite>. However, human evaluation is resource-intensive and time-consuming, and the number of translation systems included in a meta-evaluation tends to be relatively small. In this study, we explore the use of commercial machine translations, collected weekly over a period of 6 years for 12 translation directions, for the evaluation of MT metrics. Given the common use of human A/B testing <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib26" title="">2010</a>); Caswell and Liang (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib1" title="">2020</a>)</cite>, our base assumption is that commercial systems show real improvements over time and that we can assess metrics as to whether they prefer more recent MT outputs. Using our dataset, we revisit a number of recent findings in MT metrics research, and find that our dataset supports these.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Trained metrics, developed to directly learn human judgments <cite class="ltx_cite ltx_citemacro_cite">Rei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib23" title="">2020</a>); Sellam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib25" title="">2020</a>)</cite>, showed notable advancements in correlating with human judgments compared to non-neural metrics like BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib19" title="">2002</a>); Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib8" title="">2021</a>)</cite>. Recent studies <cite class="ltx_cite ltx_citemacro_cite">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib7" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib6" title="">2023</a>)</cite> also revealed that neural metrics achieved significantly better correlation with human judgments than non-neural ones and were able to generalize to new domains and challenging test sets. In our experiments, we analyze metric scores over time and evaluate metrics’ ability to accurately rank MT systems. Our findings demonstrate that neural metrics show a more consistent upward trend, and achieve higher accuracy than non-neural metrics.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><cite class="ltx_cite ltx_citemacro_citet">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib14" title="">2019</a>)</cite> argued that the correlation between metrics and human judgments significantly decreased when considering only the top-performing systems. To be specific, they assessed the stability of metrics across top-N MT systems, and noticed that the correlation between metric and human scores diminished as N decreased. <cite class="ltx_cite ltx_citemacro_citet">Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite> highlighted the instability of correlations with small N, and instead employed a rolling window of N systems, moving from the worst to the best systems. Due to the limited number of MT systems (typically 10-15 systems) in the datasets, they were unable to confirm that the correlation declines as system quality improves with their approach. Due to the much larger size of our dataset (see Section <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS1" title="3.1 Data ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">3.1</span></a>), we can achieve more stable results when using the rolling window approach from <cite class="ltx_cite ltx_citemacro_citet">Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite>. Our findings reveal that a downward trend is the most common, supporting the results of <cite class="ltx_cite ltx_citemacro_citet">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib14" title="">2019</a>)</cite>, although upward or relatively flat trends are also seen in some language pairs.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In WMT23 Metrics shared task <cite class="ltx_cite ltx_citemacro_cite">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib6" title="">2023</a>)</cite>, human translations received unexpectedly low ratings, which prompted an investigation into using synthetic references as a potential alternative. They found that high-quality synthetic references could produce a stronger correlation between human evaluations and metrics compared to human references. In our study, we reexamine the usefulness of synthetic references with three language pairs and find that synthetic references can result in comparable correlation.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The metrics shared task at WMT <cite class="ltx_cite ltx_citemacro_cite">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib13" title="">2018</a>); Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib17" title="">2020b</a>)</cite> has played a key role in the development and evaluation of automatic metrics. The annual data collected from WMT’s comprehensive human evaluation of the translation task provides an ideal foundation for assessing these metrics. In this event, metrics are ranked based on the correlation calculated by comparing their scores to human ratings.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Machine translation systems that are compared typically come from the same evaluation campaign. An exception to this is the study by <cite class="ltx_cite ltx_citemacro_citet">Graham et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib9" title="">2014</a>)</cite>, who study longitudinal improvements in machine translation quality from 2007–2012 with human assessments, finding that translation quality of the top submissions to the WMT shared task indeed rose significantly.
Our study is similarly longitudinal, but our data stems from a single commercial system, and we do not perform our own human evaluation, but instead assume that improvements over time have been validated by company-internal human A/B testing.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Instead of evaluating metrics through comparison with human judgement, <cite class="ltx_cite ltx_citemacro_citet">Moghe et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib18" title="">2023</a>)</cite> explored a complementary approach by correlating metrics with the outcome of downstream tasks. Similarly, our study does not use human judgment directly; instead, we evaluate metrics based on their preference for newer MT outputs.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We turn next to describe our data and the metrics we use.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The original corpus contains sentences in English from Abstract Meaning Representation (AMR) Annotation Release 2.0 <cite class="ltx_cite ltx_citemacro_cite">Knight and et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib10" title="">2017</a>)</cite>, along with their German, Italian, Spanish, and Chinese translations developed by <cite class="ltx_cite ltx_citemacro_citet">Damonte and Cohen (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib4" title="">2018</a>)</cite> and released by LDC in <cite class="ltx_cite ltx_citemacro_citet">Damonte and Cohen (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib3" title="">2020</a>)</cite>. This corpus contains 1371 sentences per language. The source sentences were mainly drawn from content gathered in the news domain.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Translations<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Due to the origin of the translations, the data we use is to be licensed by the Linguistic Data Consortium. If you would like to use this dataset for your research, please contact the authors. The collection of the data continues.</span></span></span> are gathered weekly from May 2018 – March 2024 using Google Translate from each of the five languages to the other four languages. Early experiments revealed that for English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mo id="S3.SS1.p2.1.m1.1.1" stretchy="false" xref="S3.SS1.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">→</annotation></semantics></math>Spanish, there was a substantial similarity between professional translations and those generated by the earliest systems (details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A1" title="Appendix A Metric scores for English → Spanish translations ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">A</span></a>). Consequently, Spanish was removed from further investigation, reducing the number of language pairs to 12. As minimal variation was observed between consecutive weeks, we subsample for the following analysis, with consecutive systems being approximately one month apart. After removing duplicates (systems receiving identical scores across all metrics), we retained 56–63 systems per language pair.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="391" id="S3.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The Spearman correlation measures the relationship between metric score rankings and time rankings for MT systems. A positive correlation indicates an upward trend, with a higher correlation indicating a stronger trend. A red star indicates lack of statistical significance (p-value <math alttext="&gt;" class="ltx_Math" display="inline" id="S3.F1.2.m1.1"><semantics id="S3.F1.2.m1.1b"><mo id="S3.F1.2.m1.1.1" xref="S3.F1.2.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.F1.2.m1.1c"><gt id="S3.F1.2.m1.1.1.cmml" xref="S3.F1.2.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.2.m1.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="S3.F1.2.m1.1e">&gt;</annotation></semantics></math> 0.05).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Metrics</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In this section, we outline the three types of metrics used in this study.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Surface-level overlap</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p1.1.1">BLEU</span> <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib19" title="">2002</a>)</cite> measures n-grams overlap between the translation and its reference. We use <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS1.p1.1.2">corpus_bleu</em> in SacreBLEU <cite class="ltx_cite ltx_citemacro_cite">Post (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib21" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p2.1.1">chrF</span> <cite class="ltx_cite ltx_citemacro_citep">(Popović, <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib20" title="">2015</a>)</cite> assesses the overlap between the characters of the translation and the reference. We use <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS1.p2.1.2">corpus_chrf</em> in SacreBLEU.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Embedding based</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p1.1.1">BERTScore</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib29" title="">2020</a>)</cite> derives contextual embeddings from BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib5" title="">2019</a>)</cite> models and computes cosine similarity between embeddings of the translation and the reference. We use the F1 score without TF-IDF weighting.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Trained with human judgements</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p1.1.1">COMET-20</span> <cite class="ltx_cite ltx_citemacro_cite">Rei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib23" title="">2020</a>)</cite> is trained on top of XLM-R <cite class="ltx_cite ltx_citemacro_cite">Conneau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib2" title="">2020</a>)</cite> using Direct Assessments (DA) from WMT17 to WMT19. We use wmt20-comet-da.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p2.1.1">UniTE</span> <cite class="ltx_cite ltx_citemacro_citep">(Wan et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib27" title="">2022a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib28" title="">b</a>)</cite> is capable of evaluating translation outputs in source-only, reference-only, and source-reference-combined assessment scenarios. We use unite-mup.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p3.1.1">COMET-22</span> <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib22" title="">2022a</a>)</cite> is the current default model in COMET and trained on DA from WMT17 to WMT20. We use wmt22-comet-da.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p4">
<p class="ltx_p" id="S3.SS2.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p4.1.1">COMET-Kiwi</span> <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib24" title="">2022b</a>)</cite> is a reference-free metric trained using DA from WMT17 to WMT20, and DA from the MLQE-PE corpus. We use wmt22-cometkiwi-da.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p5">
<p class="ltx_p" id="S3.SS2.SSS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p5.1.1">MS-COMET-QE-22</span> <cite class="ltx_cite ltx_citemacro_citep">(Kocmi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib12" title="">2022</a>)</cite> is a reference-free metric, extending COMET by Microsoft Research with proprietary data.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.2">All</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.3">Into EN</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.4">From EN</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.5">Into DE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.6">Into IT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.7">Into ZH</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.2.1.1">COMET-22</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.1.2.1">73.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.3">66.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.4">71.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.5">76.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.1.6.1">79.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.7">72.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.3.2.1">COMET-Kiwi</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.2">73.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.3">72.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.4">73.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.5">74.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.6">75.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.7">71.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.4.3.1">UniTE</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.2">73.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.3">66.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.4">73.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.4.3.5.1">77.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.6">75.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.7">73.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.4.1">COMET-20</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.2">72.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.3">66.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.4.4.1">74.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.5">74.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.6">74.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.7">74.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.6.5.1">chrF</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.2">71.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.6.5.3.1">74.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.4">57.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.5">60.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.6">76.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.7">74.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.7.6.1">MS-COMET-22-QE</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.2">69.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.3">57.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.4">68.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.5">68.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.6">73.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.6.7.1">78.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.8.7.1">BLEU</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.2">68.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.3">71.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.4">57.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.5">56.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.6">68.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.7.7">76.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.1.9.8.1">BERTScore</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.2">68.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.3">65.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.4">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.5">68.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.6">69.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.7">68.6</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Accuracy for ranking system pairs. Column “All” shows the results for all system pairs. Each following column evaluates accuracy over a subset of systems. Rows are sorted by the accuracy over all system pairs.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>How do metric scores change over time?</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">While it is reasonable to expect that systems improve over time, how metric scores will reflect these improvements remains unclear. To investigate this, we visualize how metric scores vary over time for individual language pairs in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A2" title="Appendix B Metric scores over time ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">B</span></a>. In general, upward trends are evident for the metrics across the language pairs.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2">We use Spearman correlation to measure whether the upward trends are consistent. Metrics with higher correlation are deemed more reliable, as they better reflect the overall ranking of the systems. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.F1" title="Figure 1 ‣ 3.1 Data ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>, COMET-22, UniTE, COMET-20, and COMET-Kiwi consistently demonstrate high correlation across the language pairs. Among the remaining four metrics, we notice low correlations in specific language pairs, like BLEU and chrF in English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">→</annotation></semantics></math>German or MS-COMET-22-QE in Italian<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mo id="S4.SS1.p2.2.m2.1.1" stretchy="false" xref="S4.SS1.p2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">→</annotation></semantics></math>English.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="376" id="S4.F2.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Accuracy over a rolling window of 36 systems. The x-axis represents the index of the starting system, with systems ordered chronologically from the earliest to the most recent. The x-axis scale may vary due to differing numbers of systems, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.SS1" title="3.1 Data ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="171" id="S4.F3.g1" src="x3.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Accuracy across three language pairs using either human or synthetic references. The two reference-free metrics are not included as they will not be influenced by reference.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>How good can the metrics rank incremental systems accurately?</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">In this section, we evaluate metrics in a common scenario <cite class="ltx_cite ltx_citemacro_citep">(Mathur et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite>: ranking a pair of systems. As we assume newer systems are better than old ones, accuracy <cite class="ltx_cite ltx_citemacro_cite">Kocmi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib11" title="">2021</a>)</cite> is adopted as follows. For each system pair, we calculate the difference of the metric scores (metric<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" mathvariant="normal" xref="S4.SS2.p1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">roman_Δ</annotation></semantics></math>) and the difference in time (time<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S4.SS2.p1.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">roman_Δ</annotation></semantics></math>). Accuracy for a specific metric is calculated as the ratio of rank agreements between metric and time deltas to the total number of comparisons:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Accuracy}=\frac{|\text{sign(metric$\Delta$) == sign(time$\Delta$) }|}{|%
\text{all system pairs}|}" class="ltx_Math" display="block" id="S4.Ex1.m1.3"><semantics id="S4.Ex1.m1.3a"><mrow id="S4.Ex1.m1.3.4" xref="S4.Ex1.m1.3.4.cmml"><mtext id="S4.Ex1.m1.3.4.2" xref="S4.Ex1.m1.3.4.2a.cmml">Accuracy</mtext><mo id="S4.Ex1.m1.3.4.1" xref="S4.Ex1.m1.3.4.1.cmml">=</mo><mfrac id="S4.Ex1.m1.3.3" xref="S4.Ex1.m1.3.3.cmml"><mrow id="S4.Ex1.m1.2.2.2.4" xref="S4.Ex1.m1.2.2.2.3.cmml"><mo id="S4.Ex1.m1.2.2.2.4.1" stretchy="false" xref="S4.Ex1.m1.2.2.2.3.1.cmml">|</mo><mrow id="S4.Ex1.m1.2.2.2.2.2" xref="S4.Ex1.m1.2.2.2.2.2d.cmml"><mtext id="S4.Ex1.m1.2.2.2.2.2a" xref="S4.Ex1.m1.2.2.2.2.2d.cmml">sign(metric</mtext><mi id="S4.Ex1.m1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="S4.Ex1.m1.1.1.1.1.1.m1.1.1.cmml">Δ</mi><mtext id="S4.Ex1.m1.2.2.2.2.2b" xref="S4.Ex1.m1.2.2.2.2.2d.cmml">) == sign(time</mtext><mi id="S4.Ex1.m1.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="S4.Ex1.m1.2.2.2.2.2.m2.1.1.cmml">Δ</mi><mtext id="S4.Ex1.m1.2.2.2.2.2c" xref="S4.Ex1.m1.2.2.2.2.2d.cmml">) </mtext></mrow><mo id="S4.Ex1.m1.2.2.2.4.2" stretchy="false" xref="S4.Ex1.m1.2.2.2.3.1.cmml">|</mo></mrow><mrow id="S4.Ex1.m1.3.3.3.3" xref="S4.Ex1.m1.3.3.3.2.cmml"><mo id="S4.Ex1.m1.3.3.3.3.1" stretchy="false" xref="S4.Ex1.m1.3.3.3.2.1.cmml">|</mo><mtext id="S4.Ex1.m1.3.3.3.1" xref="S4.Ex1.m1.3.3.3.1a.cmml">all system pairs</mtext><mo id="S4.Ex1.m1.3.3.3.3.2" stretchy="false" xref="S4.Ex1.m1.3.3.3.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.3b"><apply id="S4.Ex1.m1.3.4.cmml" xref="S4.Ex1.m1.3.4"><eq id="S4.Ex1.m1.3.4.1.cmml" xref="S4.Ex1.m1.3.4.1"></eq><ci id="S4.Ex1.m1.3.4.2a.cmml" xref="S4.Ex1.m1.3.4.2"><mtext id="S4.Ex1.m1.3.4.2.cmml" xref="S4.Ex1.m1.3.4.2">Accuracy</mtext></ci><apply id="S4.Ex1.m1.3.3.cmml" xref="S4.Ex1.m1.3.3"><divide id="S4.Ex1.m1.3.3.4.cmml" xref="S4.Ex1.m1.3.3"></divide><apply id="S4.Ex1.m1.2.2.2.3.cmml" xref="S4.Ex1.m1.2.2.2.4"><abs id="S4.Ex1.m1.2.2.2.3.1.cmml" xref="S4.Ex1.m1.2.2.2.4.1"></abs><ci id="S4.Ex1.m1.2.2.2.2.2d.cmml" xref="S4.Ex1.m1.2.2.2.2.2"><mrow id="S4.Ex1.m1.2.2.2.2.2.cmml" xref="S4.Ex1.m1.2.2.2.2.2"><mtext id="S4.Ex1.m1.2.2.2.2.2a.cmml" xref="S4.Ex1.m1.2.2.2.2.2">sign(metric</mtext><mi id="S4.Ex1.m1.1.1.1.1.1.m1.1.1.cmml" mathvariant="normal" xref="S4.Ex1.m1.1.1.1.1.1.m1.1.1">Δ</mi><mtext id="S4.Ex1.m1.2.2.2.2.2b.cmml" xref="S4.Ex1.m1.2.2.2.2.2">) == sign(time</mtext><mi id="S4.Ex1.m1.2.2.2.2.2.m2.1.1.cmml" mathvariant="normal" xref="S4.Ex1.m1.2.2.2.2.2.m2.1.1">Δ</mi><mtext id="S4.Ex1.m1.2.2.2.2.2c.cmml" xref="S4.Ex1.m1.2.2.2.2.2">) </mtext></mrow></ci></apply><apply id="S4.Ex1.m1.3.3.3.2.cmml" xref="S4.Ex1.m1.3.3.3.3"><abs id="S4.Ex1.m1.3.3.3.2.1.cmml" xref="S4.Ex1.m1.3.3.3.3.1"></abs><ci id="S4.Ex1.m1.3.3.3.1a.cmml" xref="S4.Ex1.m1.3.3.3.1"><mtext id="S4.Ex1.m1.3.3.3.1.cmml" xref="S4.Ex1.m1.3.3.3.1">all system pairs</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.3c">\text{Accuracy}=\frac{|\text{sign(metric$\Delta$) == sign(time$\Delta$) }|}{|%
\text{all system pairs}|}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.3d">Accuracy = divide start_ARG | sign(metric roman_Δ ) == sign(time roman_Δ ) | end_ARG start_ARG | all system pairs | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Since the systems span from 2018 to 2024, those separated by a substantial time interval might exhibit considerable quality gaps, potentially resulting in an overestimate of metric reliability <cite class="ltx_cite ltx_citemacro_cite">Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite>. Consequently, we only pair systems with a gap of less than a year. Even within such a timeframe, substantial improvements in quality are possible <cite class="ltx_cite ltx_citemacro_cite">Caswell and Liang (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib1" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S3.T1" title="Table 1 ‣ 3.2.3 Trained with human judgements ‣ 3.2 Metrics ‣ 3 Methods ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">1</span></a> shows that trained metrics generally outperform non-trained metrics. For all system pairs, COMET-22 achieves the highest accuracy, followed by COMET-Kiwi. In contrast, MS-COMET-QE-22 struggles to attain high accuracy except for into Chinese. Among surface-level metrics, chrF outperforms BLEU, reflecting results in previous studies <cite class="ltx_cite ltx_citemacro_cite">Kocmi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib11" title="">2021</a>)</cite>, and achieves the highest accuracy for into English. We also examine performance for individual language pairs. Trained metrics exhibit high accuracy, yet no single metric excels across all pairs. More details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A3" title="Appendix C Accuracy across language pairs ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Does the reliability of metrics depend on the quality of the systems evaluated?</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">As mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S1" title="1 Introduction ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">1</span></a>, metric reliability may decline as the quality of evaluated systems improves <cite class="ltx_cite ltx_citemacro_cite">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib14" title="">2019</a>)</cite>. However, the limited number of MT systems made it difficult to fully confirm this trend <cite class="ltx_cite ltx_citemacro_cite">Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite>. We revisit this issue using a larger sample of MT systems. Following the approach of <cite class="ltx_cite ltx_citemacro_citet">Mathur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#bib.bib16" title="">2020a</a>)</cite>, we implement a rolling window of N systems, transitioning from the earliest to the most recent ones.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Using accuracy as explained in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.SS2" title="4.2 How good can the metrics rank incremental systems accurately? ‣ 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we conduct tests with N varying from 24 to 40. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.F2" title="Figure 2 ‣ 4.1 How do metric scores change over time? ‣ 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the results for N = 36, representing the identified scenarios. Different metrics display varying trends. For instance, in English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mo id="S4.SS3.p2.1.m1.1.1" stretchy="false" xref="S4.SS3.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">→</annotation></semantics></math>German, trained metrics show an upward trend, while surface-level metrics show a downward trend. A downward trend is most common, with each metric showing a clear decline across 7 or more language pairs. However, we also observe upward or relatively flat trends in the remaining language pairs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Can synthetic references serve as an alternative to human references?</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We generate synthetic references for three language pairs using another commercial MT system, DeepL, and examine their impact on metric evaluation. As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#S4.F3" title="Figure 3 ‣ 4.1 How do metric scores change over time? ‣ 4 Results ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">3</span></a>, we observe that for English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mo id="S4.SS4.p1.1.m1.1.1" stretchy="false" xref="S4.SS4.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">→</annotation></semantics></math>German, all metrics achieve a higher accuracy, while for the remaining language pairs, there are some drops. Overall, synthetic references lead to a comparable accuracy for the three language pairs we investigate, suggesting that they can be used when human references are unavailable.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our dataset, covering 12 language pairs with at least 56 machine translations each, surpasses previous datasets that typically included only 3 pairs with around 15 machine translations each. Based on the assumption that newer translations of a regularly updated commercial system tend to be of a higher quality, we apply the dataset to revisit prior findings on MT metrics. We provide larger-scale evidence for debated questions such as the relationship between MT quality and metric reliability—issues that previous research was unable to conclusively resolve on smaller datasets. Additionally, the systems are incremental (a baseline compared to improvements developed by the same group), reflecting the most common use case of the metrics. We encourage the use of our dataset for future investigations into MT metrics or the development of MT quality over time.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Our study bases on the assumption that newer systems of Google Translate outperform older ones due to the quality assurance measures, including human testing, taken before deployment. Although this is a reasonable belief, it might not always be true.</p>
</div>
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1">Recently, LLM-based evaluators have demonstrated great performance in evaluating MT systems. However, we have not included any LLM-based evaluators in this study because it would be costly to experiment with our extensive dataset.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">We thank Mengyu Wang, Pinzhen Chen, Yftah Ziser, Zheng Zhao and the anonymous reviewers for their comments.
Rico Sennrich acknowledges funding by the Swiss National Science Foundation (project MUTAMUR; no. 213976).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caswell and Liang (2020)</span>
<span class="ltx_bibblock">
Isaac Caswell and Bowen Liang. 2020.

</span>
<span class="ltx_bibblock">Recent advances in google translate.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://research.google/blog/recent-advances-in-google-translate/" title="">https://research.google/blog/recent-advances-in-google-translate/</a>.

</span>
<span class="ltx_bibblock">Google Research Blog.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2020)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.747" title="">Unsupervised
cross-lingual representation learning at scale</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 8440–8451, Online. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Damonte and Cohen (2020)</span>
<span class="ltx_bibblock">
Marco Damonte and Shay Cohen. 2020.

</span>
<span class="ltx_bibblock">Abstract Meaning Representation 2.0 - Four Translations LDC2020T07.

</span>
<span class="ltx_bibblock">Web Download. Philadelphia: Linguistic Data Consortium, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Damonte and Cohen (2018)</span>
<span class="ltx_bibblock">
Marco Damonte and Shay B. Cohen. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N18-1104" title="">Cross-lingual
Abstract Meaning Representation parsing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1146–1155, New Orleans,
Louisiana. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">BERT: Pre-training of
deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2023)</span>
<span class="ltx_bibblock">
Markus Freitag, Nitika Mathur, Chi-kiu Lo, Eleftherios Avramidis, Ricardo Rei,
Brian Thompson, Tom Kocmi, Frederic Blain, Daniel Deutsch, Craig Stewart,
Chrysoula Zerva, Sheila Castilho, Alon Lavie, and George Foster. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.51" title="">Results of WMT23
metrics shared task: Metrics might be guilty but references are not
innocent</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the Eighth Conference on Machine
Translation</em>, pages 578–628, Singapore. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart,
Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André
F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22
metrics shared task: Stop using BLEU – neural metrics are better and
more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2021)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, George
Foster, Alon Lavie, and Ondřej Bojar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.73" title="">Results of the
WMT21 metrics shared task: Evaluating metrics with expert-based human
evaluations on TED and news domain</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the Sixth Conference on Machine Translation</em>,
pages 733–774, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graham et al. (2014)</span>
<span class="ltx_bibblock">
Yvette Graham, Timothy Baldwin, Alistair Moffat, and Justin Zobel. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/v1/E14-1047" title="">Is machine translation
getting better over time?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 14th Conference of the European Chapter
of the Association for Computational Linguistics</em>, pages 443–451,
Gothenburg, Sweden. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Knight and et al. (2017)</span>
<span class="ltx_bibblock">
Kevin Knight and et al. 2017.

</span>
<span class="ltx_bibblock">Abstract Meaning Representation (AMR) Annotation Release 2.0
LDC2017T10.

</span>
<span class="ltx_bibblock">Web Download. Philadelphia: Linguistic Data Consortium, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi et al. (2021)</span>
<span class="ltx_bibblock">
Tom Kocmi, Christian Federmann, Roman Grundkiewicz, Marcin Junczys-Dowmunt,
Hitokazu Matsushita, and Arul Menezes. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.57" title="">To ship or not to
ship: An extensive evaluation of automatic metrics for machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the Sixth Conference on Machine Translation</em>,
pages 478–494, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi et al. (2022)</span>
<span class="ltx_bibblock">
Tom Kocmi, Hitokazu Matsushita, and Christian Federmann. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.47" title="">MS-COMET: More
and better human judgements improve metric performance</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 541–548, Abu Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2018)</span>
<span class="ltx_bibblock">
Qingsong Ma, Ondřej Bojar, and Yvette Graham. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6450" title="">Results of the WMT18
metrics shared task: Both characters and embeddings achieve good
performance</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the Third Conference on Machine Translation:
Shared Task Papers</em>, pages 671–688, Belgium, Brussels. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2019)</span>
<span class="ltx_bibblock">
Qingsong Ma, Johnny Wei, Ondřej Bojar, and Yvette Graham. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W19-5302" title="">Results of the WMT19
metrics shared task: Segment-level and strong MT systems pose big
challenges</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Fourth Conference on Machine Translation
(Volume 2: Shared Task Papers, Day 1)</em>, pages 62–90, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macháček and Bojar (2013)</span>
<span class="ltx_bibblock">
Matouš Macháček and Ondřej Bojar. 2013.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W13-2202" title="">Results of the WMT13
metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the Eighth Workshop on Statistical Machine
Translation</em>, pages 45–51, Sofia, Bulgaria. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathur et al. (2020a)</span>
<span class="ltx_bibblock">
Nitika Mathur, Timothy Baldwin, and Trevor Cohn. 2020a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.448" title="">Tangled up in
BLEU: Reevaluating the evaluation of automatic machine translation
evaluation metrics</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4984–4997, Online. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathur et al. (2020b)</span>
<span class="ltx_bibblock">
Nitika Mathur, Johnny Wei, Markus Freitag, Qingsong Ma, and Ondřej Bojar.
2020b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.wmt-1.77" title="">Results of the
WMT20 metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the Fifth Conference on Machine Translation</em>,
pages 688–725, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moghe et al. (2023)</span>
<span class="ltx_bibblock">
Nikita Moghe, Tom Sherborne, Mark Steedman, and Alexandra Birch. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.730" title="">Extrinsic
evaluation of machine translation metrics</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 13060–13078,
Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for
automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania,
USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović (2015)</span>
<span class="ltx_bibblock">
Maja Popović. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W15-3049" title="">chrF: character
n-gram F-score for automatic MT evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the Tenth Workshop on Statistical Machine
Translation</em>, pages 392–395, Lisbon, Portugal. Association for Computational
Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-6319" title="">A call for clarity in
reporting BLEU scores</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the Third Conference on Machine Translation:
Research Papers</em>, pages 186–191, Brussels, Belgium. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022a)</span>
<span class="ltx_bibblock">
Ricardo Rei, José G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana C
Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and André F. T.
Martins. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.52" title="">COMET-22:
Unbabel-IST 2022 submission for the metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 578–585, Abu Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2020)</span>
<span class="ltx_bibblock">
Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.213" title="">COMET: A
neural framework for MT evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 2685–2702, Online. Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022b)</span>
<span class="ltx_bibblock">
Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha,
Christine Maroti, José G. C. de Souza, Taisiya Glushkova, Duarte Alves,
Luisa Coheur, Alon Lavie, and André F. T. Martins. 2022b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.60" title="">CometKiwi:
IST-unbabel 2022 submission for the quality estimation shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 634–645, Abu Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sellam et al. (2020)</span>
<span class="ltx_bibblock">
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.704" title="">BLEURT:
Learning robust metrics for text generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7881–7892, Online. Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2010)</span>
<span class="ltx_bibblock">
Diane Tang, Ashish Agarwal, Deirdre O’Brien, and Mike Meyer. 2010.

</span>
<span class="ltx_bibblock">Overlapping experiment infrastructure: More, better, faster
experimentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings 16th Conference on Knowledge Discovery and Data
Mining</em>, pages 17–26, Washington, DC.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2022a)</span>
<span class="ltx_bibblock">
Yu Wan, Keqin Bao, Dayiheng Liu, Baosong Yang, Derek F. Wong, Lidia S. Chao,
Wenqiang Lei, and Jun Xie. 2022a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.53" title="">Alibaba-translate
China’s submission for WMT2022 metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 586–592, Abu Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2022b)</span>
<span class="ltx_bibblock">
Yu Wan, Dayiheng Liu, Baosong Yang, Haibo Zhang, Boxing Chen, Derek Wong, and
Lidia Chao. 2022b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.558" title="">UniTE:
Unified translation evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 8117–8127,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi.
2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=SkeHuCVFDr" title="">BERTScore:
Evaluating text generation with BERT</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">International Conference on Learning Representations</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\appendixpage</span>
</div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Metric scores for English <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.1.m1.1"><semantics id="A1.1.m1.1b"><mo id="A1.1.m1.1.1" stretchy="false" xref="A1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.1.m1.1c"><ci id="A1.1.m1.1.1.cmml" xref="A1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.1.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.1.m1.1e">→</annotation></semantics></math> Spanish translations</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A1.F4" title="Figure 4 ‣ Appendix A Metric scores for English → Spanish translations ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">4</span></a> displays the scores of four different metrics for English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><mo id="A1.p1.1.m1.1.1" stretchy="false" xref="A1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><ci id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">→</annotation></semantics></math>Spanish translations in our early experiments. Early systems achieved nearly perfect metric scores, whereas later systems displayed markedly lower scores. Upon closer examination of the human translations, we noticed roughly 25% of them are identical to that of the early systems. This indicates the use of Google Translate in the professional translation.</p>
</div>
<figure class="ltx_figure" id="A1.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="299" id="A1.F4.sf1.g1" src="x4.png" width="373"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>BLEU</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="299" id="A1.F4.sf2.g1" src="x5.png" width="373"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>chrF</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="299" id="A1.F4.sf3.g1" src="x6.png" width="373"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>BERTScore</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="299" id="A1.F4.sf4.g1" src="x7.png" width="373"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>COMET-22</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The metric scores for English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.F4.2.m1.1"><semantics id="A1.F4.2.m1.1b"><mo id="A1.F4.2.m1.1.1" stretchy="false" xref="A1.F4.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.F4.2.m1.1c"><ci id="A1.F4.2.m1.1.1.cmml" xref="A1.F4.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F4.2.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.F4.2.m1.1e">→</annotation></semantics></math>Spanish translations. While the earliest system achieved nearly perfect scores, subsequent systems showed a notable decline.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Metric scores over time</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03277v2#A2.F5" title="Figure 5 ‣ Appendix B Metric scores over time ‣ Evaluating Automatic Metrics with Incremental Machine Translation Systems"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the findings regarding the change of metric scores over time. Generally, upward trends are evident for the metrics across language pairs. Furthermore, these trends sometimes appear as step-like progressions. Based on a visual inspection of the results, we have some interesting findings as follows:</p>
<ol class="ltx_enumerate" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">Although there have been concerns that MT systems were optimized for BLEU, given its longstanding status as the primary evaluation metric, our findings suggest that the upward trends of BLEU are less consistent compared to other metrics. This observation might provide implicit evidence that BLEU is not solely used during system development.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">The trajectories of BLEU and chrF exhibit a high degree of similarity, as do the trajectories of COMET-20, COMET-22, COMET-Kiwi, and UniTE. In contrast, BERTScore and MS-COMET-22-QE follow distinct trajectories of their own. These similarities and discrepancies reflect the inherent properties of these metrics. BLEU and chrF both rely on measuring surface-level overlap, while BERTScore is unique in its reliance on contextual embeddings. As for the trained metrics, although they are all trained in a similar manner, MS-COMET-22-QE was trained using entirely different data.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.9">In certain language pairs, the trajectories of certain metrics may experience a downturn. For instance, noticeable troughs are observed for BLEU and chrF in English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.1.m1.1"><semantics id="A2.I1.i3.p1.1.m1.1a"><mo id="A2.I1.i3.p1.1.m1.1.1" stretchy="false" xref="A2.I1.i3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.m1.1b"><ci id="A2.I1.i3.p1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.1.m1.1d">→</annotation></semantics></math>German, Italian<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.2.m2.1"><semantics id="A2.I1.i3.p1.2.m2.1a"><mo id="A2.I1.i3.p1.2.m2.1.1" stretchy="false" xref="A2.I1.i3.p1.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.2.m2.1b"><ci id="A2.I1.i3.p1.2.m2.1.1.cmml" xref="A2.I1.i3.p1.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.2.m2.1d">→</annotation></semantics></math>German, and English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.3.m3.1"><semantics id="A2.I1.i3.p1.3.m3.1a"><mo id="A2.I1.i3.p1.3.m3.1.1" stretchy="false" xref="A2.I1.i3.p1.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.3.m3.1b"><ci id="A2.I1.i3.p1.3.m3.1.1.cmml" xref="A2.I1.i3.p1.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.3.m3.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.3.m3.1d">→</annotation></semantics></math>Italian; for BERTScore in English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.4.m4.1"><semantics id="A2.I1.i3.p1.4.m4.1a"><mo id="A2.I1.i3.p1.4.m4.1.1" stretchy="false" xref="A2.I1.i3.p1.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.4.m4.1b"><ci id="A2.I1.i3.p1.4.m4.1.1.cmml" xref="A2.I1.i3.p1.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.4.m4.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.4.m4.1d">→</annotation></semantics></math>German, German<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.5.m5.1"><semantics id="A2.I1.i3.p1.5.m5.1a"><mo id="A2.I1.i3.p1.5.m5.1.1" stretchy="false" xref="A2.I1.i3.p1.5.m5.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.5.m5.1b"><ci id="A2.I1.i3.p1.5.m5.1.1.cmml" xref="A2.I1.i3.p1.5.m5.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.5.m5.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.5.m5.1d">→</annotation></semantics></math>Italian, and English<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.6.m6.1"><semantics id="A2.I1.i3.p1.6.m6.1a"><mo id="A2.I1.i3.p1.6.m6.1.1" stretchy="false" xref="A2.I1.i3.p1.6.m6.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.6.m6.1b"><ci id="A2.I1.i3.p1.6.m6.1.1.cmml" xref="A2.I1.i3.p1.6.m6.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.6.m6.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.6.m6.1d">→</annotation></semantics></math>Italian; and for MS-COMET-22-QE in Italian<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.7.m7.1"><semantics id="A2.I1.i3.p1.7.m7.1a"><mo id="A2.I1.i3.p1.7.m7.1.1" stretchy="false" xref="A2.I1.i3.p1.7.m7.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.7.m7.1b"><ci id="A2.I1.i3.p1.7.m7.1.1.cmml" xref="A2.I1.i3.p1.7.m7.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.7.m7.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.7.m7.1d">→</annotation></semantics></math>English, Italian<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.8.m8.1"><semantics id="A2.I1.i3.p1.8.m8.1a"><mo id="A2.I1.i3.p1.8.m8.1.1" stretchy="false" xref="A2.I1.i3.p1.8.m8.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.8.m8.1b"><ci id="A2.I1.i3.p1.8.m8.1.1.cmml" xref="A2.I1.i3.p1.8.m8.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.8.m8.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.8.m8.1d">→</annotation></semantics></math>German, and Chinese<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A2.I1.i3.p1.9.m9.1"><semantics id="A2.I1.i3.p1.9.m9.1a"><mo id="A2.I1.i3.p1.9.m9.1.1" stretchy="false" xref="A2.I1.i3.p1.9.m9.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.9.m9.1b"><ci id="A2.I1.i3.p1.9.m9.1.1.cmml" xref="A2.I1.i3.p1.9.m9.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.9.m9.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.9.m9.1d">→</annotation></semantics></math>English. On the other hand, the trajectories of the remaining metrics may occasionally exhibit bumps but do not show clear troughs.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="A2.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F5.sf1.g1" src="x8.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F5.sf2.g1" src="x9.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Metric scores over time.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F6.sf1.g1" src="x10.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F6.sf2.g1" src="x11.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F6.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F6.sf3.g1" src="x12.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Metric scores over time.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F7.sf1.g1" src="x13.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F7.sf2.g1" src="x14.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F7.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="370" id="A2.F7.sf3.g1" src="x15.png" width="747"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Metric scores over time.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Accuracy across language pairs</h2>
<figure class="ltx_figure" id="A3.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="432" id="A3.F8.g1" src="x16.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Accuracy for ranking system pairs across individual language pairs.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct  3 13:51:46 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
