<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Relevance-guided Neural Machine Translation</title>
<!--Generated on Thu Nov 30 21:44:36 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.00214v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S2" title="2 Related Work â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method &amp; Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS1" title="3.1 Model &amp; Translation Quality Evaluation â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Model &amp; Translation Quality Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS2" title="3.2 Datasets â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS3" title="3.3 Layer-wise Relevance Propagation (LRP) â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Layer-wise Relevance Propagation (LRP)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS4" title="3.4 LRP-weighted training â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>LRP-weighted training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S4" title="4 Results &amp; Discussion â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results &amp; Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S5" title="5 Conclusions â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S6" title="6 Limitations â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S7" title="7 Ethics Statement â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Ethics Statement</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="package-alerts ltx_document" role="alert">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of <a href="https://corpora.mathweb.org/corpus/arxmliv/tex_to_html/info/loaded_file" target="_blank">supported packages</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2312.00214v1 [cs.CL] 30 Nov 2023</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Relevance-guided Neural Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Isidora Chara Tourni 
<br class="ltx_break"/>Boston University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">isidora@bu.edu</span>
<br class="ltx_break"/>&amp;Derry Wijaya 
<br class="ltx_break"/>Boston University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">wijaya@bu.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">With the advent of the Transformer architecture, Neural Machine Translation (NMT) results have shown great improvement lately.
However, results in low-resource conditions still lag behind in both bilingual and multilingual setups, due to the limited amount of available monolingual and/or parallel data; hence, the need for methods addressing data scarcity in an efficient, and explainable way, is eminent. We propose an explainability-based training approach for NMT, applied in Unsupervised and Supervised model training, for translation of three languages of varying resources, French, Gujarati, Kazakh, to and from English. Our results show our method can be promising, particularly when training in low-resource conditions, outperforming simple training baselines; though the improvement is marginal, it sets the ground for further exploration of the approach and the parameters, and its extension to other languages.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Unsupervised Neural Machine Translation (UNMT) has seen remarkable progress in recent years, with a very large number of methods proposed aiming to NMT when parallel data are few or non-existent for certain language pairs <cite class="ltx_cite ltx_citemacro_citep">(Artetxe etÂ al., <a class="ltx_ref" href="#bib.bib3" title="">2017</a>; Lample etÂ al., <a class="ltx_ref" href="#bib.bib16" title="">2018</a>; Conneau etÂ al., <a class="ltx_ref" href="#bib.bib9" title="">2017</a>; Wang and Zhao, <a class="ltx_ref" href="#bib.bib35" title="">2021</a>; Lample and Conneau, <a class="ltx_ref" href="#bib.bib14" title="">2019</a>; Song etÂ al., <a class="ltx_ref" href="#bib.bib28" title="">2019</a>; Liu etÂ al., <a class="ltx_ref" href="#bib.bib17" title="">2020</a>; Marchisio etÂ al., <a class="ltx_ref" href="#bib.bib19" title="">2020</a>; Kim etÂ al., <a class="ltx_ref" href="#bib.bib13" title="">2020</a>; Lample etÂ al., <a class="ltx_ref" href="#bib.bib15" title="">2017</a>; Artetxe etÂ al., <a class="ltx_ref" href="#bib.bib2" title="">2019</a>; Garcia etÂ al., <a class="ltx_ref" href="#bib.bib12" title="">2020</a>; Su etÂ al., <a class="ltx_ref" href="#bib.bib29" title="">2019</a>; Nguyen etÂ al., <a class="ltx_ref" href="#bib.bib21" title="">2022</a>)</cite>.
Training techniques such as Back-Translation <cite class="ltx_cite ltx_citemacro_citep">(Sennrich etÂ al., <a class="ltx_ref" href="#bib.bib26" title="">2015</a>)</cite> and Auto-Encoding have been widely studied, in order to efficiently train NMT models under those data scarcity conditions to obtain high quality translation results. However, there is little work in enhancing Neural Machine Translation (NMT) models with utilizing explainability of the model in order to improve quality of the output. We propose a method, based on Layer-wise Relevance Propagation (LRP), which leverages the contribution of the input tokens to the output, to boost NMT performance. Our results show LRP may be beneficial during model training for NMT output improvement, particularly in low-resource conditions and for specific well defined model setups.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Layer-wise Relevance Propagation (LRP)</h3>
<div class="ltx_para" id="S2.SSx1.p1">
<p class="ltx_p" id="S2.SSx1.p1.1">LRP was introduced by <cite class="ltx_cite ltx_citemacro_citet">Bach etÂ al. (<a class="ltx_ref" href="#bib.bib4" title="">2015</a>)</cite>, measuring the contribution of the input components, or the neurons of a network, to the next layerâ€™s output. Due to its nature, it is directly applicable to layer-wise architectures, and we extend its usage to the Transformer architecture, measuring the relevance of source and target sentencesâ€™ tokens to the NMT output during training.
</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Explanations &amp; Explanation-guided training</h3>
<div class="ltx_para" id="S2.SSx2.p1">
<p class="ltx_p" id="S2.SSx2.p1.1">Several previous works outline and summarize the findings of explainability and interpetability- related research in NLP <cite class="ltx_cite ltx_citemacro_citep">(Belinkov etÂ al., <a class="ltx_ref" href="#bib.bib5" title="">2020</a>; Sun etÂ al., <a class="ltx_ref" href="#bib.bib32" title="">2021b</a>; Tenney etÂ al., <a class="ltx_ref" href="#bib.bib33" title="">2020</a>; Madsen etÂ al., <a class="ltx_ref" href="#bib.bib18" title="">2021</a>; Danilevsky etÂ al., <a class="ltx_ref" href="#bib.bib10" title="">2020</a>; Qian etÂ al., <a class="ltx_ref" href="#bib.bib23" title="">2021</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Weber etÂ al. (<a class="ltx_ref" href="#bib.bib36" title="">2022</a>)</cite> provide a systematic review of explainable AI methods employed in improving various properties of Machine Learning models, such as performance, convergence, robustness, reasoning, efficiency and equality. Of these, of particular interest, and the focus of our work, are those that along with measuring feature importance and distinguishing relevant from irrelevant features, are utilized to augment the intermediate learned features, and improve model performance or reasoning <cite class="ltx_cite ltx_citemacro_citep">(Anders etÂ al., <a class="ltx_ref" href="#bib.bib1" title="">2022</a>; Sun etÂ al., <a class="ltx_ref" href="#bib.bib31" title="">2021a</a>; Zunino etÂ al., <a class="ltx_ref" href="#bib.bib38" title="">2021a</a>; Fukui etÂ al., <a class="ltx_ref" href="#bib.bib11" title="">2019</a>; Zhou etÂ al., <a class="ltx_ref" href="#bib.bib37" title="">2016</a>; Mitsuhara etÂ al., <a class="ltx_ref" href="#bib.bib20" title="">2019</a>; Schiller etÂ al., <a class="ltx_ref" href="#bib.bib24" title="">2019</a>; Zunino etÂ al., <a class="ltx_ref" href="#bib.bib39" title="">2021b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SSx2.p2">
<p class="ltx_p" id="S2.SSx2.p2.2">In our paper, we modify the approach of
<cite class="ltx_cite ltx_citemacro_citet">Sun etÂ al. (<a class="ltx_ref" href="#bib.bib31" title="">2021a</a>)</cite>, that proposes a model-agnostic LRP-guided training method for few shot classification, to improve model generalization to new classes, extending it to a transformer-based masked language model for NMT. Every intermediate feature representation f<sub class="ltx_sub" id="S2.SSx2.p2.2.1">p</sub> is weighted (multiplied) by its relevance R(f<sub class="ltx_sub" id="S2.SSx2.p2.2.2">p</sub>), with respect to the feature processing output, normalized in [-1,1]. The model is then trained on a loss function taking into account both predictions, <math alttext="p" class="ltx_Math" display="inline" id="S2.SSx2.p2.1.m1.1"><semantics id="S2.SSx2.p2.1.m1.1a"><mi id="S2.SSx2.p2.1.m1.1.1" xref="S2.SSx2.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SSx2.p2.1.m1.1b"><ci id="S2.SSx2.p2.1.m1.1.1.cmml" xref="S2.SSx2.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p2.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p2.1.m1.1d">italic_p</annotation></semantics></math> and <math alttext="p_{lpr}" class="ltx_Math" display="inline" id="S2.SSx2.p2.2.m2.1"><semantics id="S2.SSx2.p2.2.m2.1a"><msub id="S2.SSx2.p2.2.m2.1.1" xref="S2.SSx2.p2.2.m2.1.1.cmml"><mi id="S2.SSx2.p2.2.m2.1.1.2" xref="S2.SSx2.p2.2.m2.1.1.2.cmml">p</mi><mrow id="S2.SSx2.p2.2.m2.1.1.3" xref="S2.SSx2.p2.2.m2.1.1.3.cmml"><mi id="S2.SSx2.p2.2.m2.1.1.3.2" xref="S2.SSx2.p2.2.m2.1.1.3.2.cmml">l</mi><mo id="S2.SSx2.p2.2.m2.1.1.3.1" xref="S2.SSx2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S2.SSx2.p2.2.m2.1.1.3.3" xref="S2.SSx2.p2.2.m2.1.1.3.3.cmml">p</mi><mo id="S2.SSx2.p2.2.m2.1.1.3.1a" xref="S2.SSx2.p2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S2.SSx2.p2.2.m2.1.1.3.4" xref="S2.SSx2.p2.2.m2.1.1.3.4.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p2.2.m2.1b"><apply id="S2.SSx2.p2.2.m2.1.1.cmml" xref="S2.SSx2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p2.2.m2.1.1.1.cmml" xref="S2.SSx2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SSx2.p2.2.m2.1.1.2.cmml" xref="S2.SSx2.p2.2.m2.1.1.2">ğ‘</ci><apply id="S2.SSx2.p2.2.m2.1.1.3.cmml" xref="S2.SSx2.p2.2.m2.1.1.3"><times id="S2.SSx2.p2.2.m2.1.1.3.1.cmml" xref="S2.SSx2.p2.2.m2.1.1.3.1"></times><ci id="S2.SSx2.p2.2.m2.1.1.3.2.cmml" xref="S2.SSx2.p2.2.m2.1.1.3.2">ğ‘™</ci><ci id="S2.SSx2.p2.2.m2.1.1.3.3.cmml" xref="S2.SSx2.p2.2.m2.1.1.3.3">ğ‘</ci><ci id="S2.SSx2.p2.2.m2.1.1.3.4.cmml" xref="S2.SSx2.p2.2.m2.1.1.3.4">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p2.2.m2.1c">p_{lpr}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p2.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_l italic_p italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and given by the following formula</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{L^{\prime}=\xi*L(y,p)+\lambda*L(y,p\textsubscript{lrp})}" class="ltx_Math" display="block" id="S2.E1.m1.4"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><msup id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml"><mi id="S2.E1.m1.4.4.3.2" xref="S2.E1.m1.4.4.3.2.cmml">L</mi><mo id="S2.E1.m1.4.4.3.3" xref="S2.E1.m1.4.4.3.3.cmml">â€²</mo></msup><mo id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml">=</mo><mrow id="S2.E1.m1.4.4.1" xref="S2.E1.m1.4.4.1.cmml"><mrow id="S2.E1.m1.4.4.1.3" xref="S2.E1.m1.4.4.1.3.cmml"><mrow id="S2.E1.m1.4.4.1.3.2" xref="S2.E1.m1.4.4.1.3.2.cmml"><mi id="S2.E1.m1.4.4.1.3.2.2" xref="S2.E1.m1.4.4.1.3.2.2.cmml">Î¾</mi><mo id="S2.E1.m1.4.4.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.4.4.1.3.2.1.cmml">*</mo><mi id="S2.E1.m1.4.4.1.3.2.3" xref="S2.E1.m1.4.4.1.3.2.3.cmml">L</mi></mrow><mo id="S2.E1.m1.4.4.1.3.1" xref="S2.E1.m1.4.4.1.3.1.cmml">â¢</mo><mrow id="S2.E1.m1.4.4.1.3.3.2" xref="S2.E1.m1.4.4.1.3.3.1.cmml"><mo id="S2.E1.m1.4.4.1.3.3.2.1" stretchy="false" xref="S2.E1.m1.4.4.1.3.3.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">y</mi><mo id="S2.E1.m1.4.4.1.3.3.2.2" xref="S2.E1.m1.4.4.1.3.3.1.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">p</mi><mo id="S2.E1.m1.4.4.1.3.3.2.3" stretchy="false" xref="S2.E1.m1.4.4.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.1.2" xref="S2.E1.m1.4.4.1.2.cmml">+</mo><mrow id="S2.E1.m1.4.4.1.1" xref="S2.E1.m1.4.4.1.1.cmml"><mrow id="S2.E1.m1.4.4.1.1.3" xref="S2.E1.m1.4.4.1.1.3.cmml"><mi id="S2.E1.m1.4.4.1.1.3.2" xref="S2.E1.m1.4.4.1.1.3.2.cmml">Î»</mi><mo id="S2.E1.m1.4.4.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.4.4.1.1.3.1.cmml">*</mo><mi id="S2.E1.m1.4.4.1.1.3.3" xref="S2.E1.m1.4.4.1.1.3.3.cmml">L</mi></mrow><mo id="S2.E1.m1.4.4.1.1.2" xref="S2.E1.m1.4.4.1.1.2.cmml">â¢</mo><mrow id="S2.E1.m1.4.4.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.2.cmml"><mo id="S2.E1.m1.4.4.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.4.4.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">y</mi><mo id="S2.E1.m1.4.4.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.2.cmml">,</mo><mrow id="S2.E1.m1.4.4.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.cmml">p</mi><mo id="S2.E1.m1.4.4.1.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.1.cmml">â¢</mo><mtext id="S2.E1.m1.4.4.1.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.1.1.3b.cmml"><sub class="ltx_sub" id="S2.E1.m1.4.4.1.1.1.1.1.3.1nest">lrp</sub></mtext></mrow><mo id="S2.E1.m1.4.4.1.1.1.1.4" stretchy="false" xref="S2.E1.m1.4.4.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><eq id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"></eq><apply id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.3.1.cmml" xref="S2.E1.m1.4.4.3">superscript</csymbol><ci id="S2.E1.m1.4.4.3.2.cmml" xref="S2.E1.m1.4.4.3.2">ğ¿</ci><ci id="S2.E1.m1.4.4.3.3.cmml" xref="S2.E1.m1.4.4.3.3">â€²</ci></apply><apply id="S2.E1.m1.4.4.1.cmml" xref="S2.E1.m1.4.4.1"><plus id="S2.E1.m1.4.4.1.2.cmml" xref="S2.E1.m1.4.4.1.2"></plus><apply id="S2.E1.m1.4.4.1.3.cmml" xref="S2.E1.m1.4.4.1.3"><times id="S2.E1.m1.4.4.1.3.1.cmml" xref="S2.E1.m1.4.4.1.3.1"></times><apply id="S2.E1.m1.4.4.1.3.2.cmml" xref="S2.E1.m1.4.4.1.3.2"><times id="S2.E1.m1.4.4.1.3.2.1.cmml" xref="S2.E1.m1.4.4.1.3.2.1"></times><ci id="S2.E1.m1.4.4.1.3.2.2.cmml" xref="S2.E1.m1.4.4.1.3.2.2">ğœ‰</ci><ci id="S2.E1.m1.4.4.1.3.2.3.cmml" xref="S2.E1.m1.4.4.1.3.2.3">ğ¿</ci></apply><interval closure="open" id="S2.E1.m1.4.4.1.3.3.1.cmml" xref="S2.E1.m1.4.4.1.3.3.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ‘¦</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğ‘</ci></interval></apply><apply id="S2.E1.m1.4.4.1.1.cmml" xref="S2.E1.m1.4.4.1.1"><times id="S2.E1.m1.4.4.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.2"></times><apply id="S2.E1.m1.4.4.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.3"><times id="S2.E1.m1.4.4.1.1.3.1.cmml" xref="S2.E1.m1.4.4.1.1.3.1"></times><ci id="S2.E1.m1.4.4.1.1.3.2.cmml" xref="S2.E1.m1.4.4.1.1.3.2">ğœ†</ci><ci id="S2.E1.m1.4.4.1.1.3.3.cmml" xref="S2.E1.m1.4.4.1.1.3.3">ğ¿</ci></apply><interval closure="open" id="S2.E1.m1.4.4.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1"><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ‘¦</ci><apply id="S2.E1.m1.4.4.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1"><times id="S2.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.1"></times><ci id="S2.E1.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2">ğ‘</ci><ci id="S2.E1.m1.4.4.1.1.1.1.1.3b.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.3"><mtext id="S2.E1.m1.4.4.1.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.3"><sub class="ltx_sub" id="S2.E1.m1.4.4.1.1.1.1.1.3.1anest">lrp</sub></mtext></ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">{L^{\prime}=\xi*L(y,p)+\lambda*L(y,p\textsubscript{lrp})}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.4d">italic_L start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = italic_Î¾ * italic_L ( italic_y , italic_p ) + italic_Î» * italic_L ( italic_y , italic_p )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SSx2.p2.4">where <math alttext="{\xi}" class="ltx_Math" display="inline" id="S2.SSx2.p2.3.m1.1"><semantics id="S2.SSx2.p2.3.m1.1a"><mi id="S2.SSx2.p2.3.m1.1.1" xref="S2.SSx2.p2.3.m1.1.1.cmml">Î¾</mi><annotation-xml encoding="MathML-Content" id="S2.SSx2.p2.3.m1.1b"><ci id="S2.SSx2.p2.3.m1.1.1.cmml" xref="S2.SSx2.p2.3.m1.1.1">ğœ‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p2.3.m1.1c">{\xi}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p2.3.m1.1d">italic_Î¾</annotation></semantics></math>, <math alttext="{\lambda}" class="ltx_Math" display="inline" id="S2.SSx2.p2.4.m2.1"><semantics id="S2.SSx2.p2.4.m2.1a"><mi id="S2.SSx2.p2.4.m2.1.1" xref="S2.SSx2.p2.4.m2.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S2.SSx2.p2.4.m2.1b"><ci id="S2.SSx2.p2.4.m2.1.1.cmml" xref="S2.SSx2.p2.4.m2.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p2.4.m2.1c">{\lambda}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p2.4.m2.1d">italic_Î»</annotation></semantics></math>
are positive scalars. In this way, the features more relevant to the prediction are emphasized, while the less relevant ones are downscaled.
Other recent works utilize LRP for improving model performance in the medical domain
<cite class="ltx_cite ltx_citemacro_citep">(Sefcik and Benesova, <a class="ltx_ref" href="#bib.bib25" title="">2021</a>)</cite>, mitigating the influence of language
bias for image captioning models <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al., <a class="ltx_ref" href="#bib.bib30" title="">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method &amp; Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model &amp; Translation Quality Evaluation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In our experiments we use a 6-layers 8-heads encoder-decoder transformer-based model, XLM <cite class="ltx_cite ltx_citemacro_citep">(Lample and Conneau, <a class="ltx_ref" href="#bib.bib14" title="">2019</a>)</cite>, following the training configurations and hyperparameters suggested by the authors. We use Byte Pair Encoding <cite class="ltx_cite ltx_citemacro_citep">(Sennrich etÂ al., <a class="ltx_ref" href="#bib.bib27" title="">2016</a>)</cite> to extract a 60k vocabulary, and have an embedding layer size of 1024, a dropout value and an attention layer dropout value of 0.1, and a sequence length of 256. We measure the quality of the Language Model (LM) with perplexity, and quality of the NMT output with BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni etÂ al., <a class="ltx_ref" href="#bib.bib22" title="">2002</a>)</cite>, both used as training stopping criteria, when there is no improvement over 10 epochs. All further parameter values are provided in the Appendix.
We first pre-train a Language Model in each language with the MLM objective, which is then used to initialize the encoder and decoder of the NMT model. We further train a NMT model,
using backtranslation (BT) and denoising auto-encoding (AE) with the monolingual data used for LM pretraining for UNMT, the Machine Translation (MT) objective for the Supervised NMT model, and BT+MT for the joint Unsupervised and Supervised approach.
</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The languages we work with are English, French, Gujarati, Kazakh, and weâ€™re translating in all English-centric directions, Englishâ€“French (Enâ€“Fr), Frenchâ€“English (Frâ€“En), Englishâ€“Gujarati (Enâ€“Gu), Gujaratiâ€“English (Guâ€“En), Englishâ€“Kazakh (Enâ€“Kk), Kazakhâ€“English (Kkâ€“En). For English and French, we use 5 million News Crawl 2007-2008 monolingual sentences for each language, and 23 million WMT14 parallel sentences.
For Gujarati, we have 1.4 million sentences and for Kazakh we have 9.5M monolingual sentences, collected for both languages from Wikipedia, WMT 2018, 2019 and Leipzig Corpora (2016)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://wortschatz.unileipzig.de/en/download/</span></span></span>. As parallel data, we have 22k and 132k from the WMT 2019 News Translation Task<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>http://data.statmt.org/news-crawl/</span></span></span> for Guâ€“En and Kkâ€“En.As development and test sets, we use newstest2013 and newstest2014, respectively, for Enâ€“Fr and Frâ€“En, WMT19 for Enâ€“Gu and Guâ€“En and Enâ€“Kk and Kkâ€“En.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.1.1.1"></th>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Enâ€“Fr</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.1.1.6"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.7.1">Frâ€“En</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.1.1.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.2.2.1">Parametersâ€™ Set Values</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2.2">v1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2.3">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.2.4">v3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.2.5">Regular</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2.6">v1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2.7">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.2.8">v3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.2.9">Regular</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.3.3.1">22k</th>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.3.3.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.3.3.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.3.3.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.3.3.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.3.3.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.3.3.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.3.3.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.3.3.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.4.4.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.4.2">29.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.4.3">24.67</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.4.4.4">30.24</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.4.4.5">31.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.4.6">30.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.4.7">26.79</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.4.4.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.4.4.8.1">30.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.4.9">30.63</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.5.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.5.2">30.01</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.5.3">28.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.5.4.1">32.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.5.5.5">34.54</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.5.6">29.94</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.5.7">29.87</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.5.5.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.5.8.1">33.03</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.5.9">34.02</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.6.6.1">1m</th>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.6.6.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.6.6.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.6.6.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.6.6.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.6.6.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.6.6.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.6.6.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.6.6.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.7.7.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.7.7.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.7.2.1">39.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.7.7.3">38.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.7.7.4">35.44</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.7.7.5">41.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.7.7.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.7.6.1">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.7.7.7">38.43</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.7.7.8">36.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.7.7.9">41.33</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.8.8.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.8.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.8.8.2.1">37.58</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.8.3">37.22</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.8.8.4">36.89</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.8.8.5">40.37</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.8.6">37.66</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.8.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.8.8.7.1">37.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.8.8.8">37.38</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.8.9">40.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.9.9.1">2.5m</th>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.9.9.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.9.9.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.9.9.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.9.9.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.9.9.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.9.9.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.9.9.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.9.9.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.10.10.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.10.10.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.10.10.2.1">39.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.10.10.3">36.02</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.10.10.4">35.57</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.10.10.5">40.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.10.10.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.10.10.6.1">39.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.10.10.7">36.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.10.10.8">36.09</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.10.10.9">40.71</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.11.11.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.11.2">37.68</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.11.3">36.21</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.11.11.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.11.11.4.1">37.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.11.11.5">39.88</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.11.6">40.71</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.11.7">37.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.11.11.8">36.66</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.11.9"><span class="ltx_text ltx_font_bold" id="S3.T1.1.11.11.9.1">38.15</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.12.12.1">5m</th>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.12.12.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.12.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.12.12.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.12.12.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.12.12.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.12.12.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.12.12.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T1.1.12.12.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.13.13.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.13.13.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.13.13.2.1">39.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.13.13.3">37.55</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.13.13.4">39</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.13.13.5">41.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.13.13.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.13.13.6.1">39.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.13.13.7">38.01</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.13.13.8">39.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.13.13.9">41.18</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.14.14.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.14.14.2">30.71</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.14.14.3">36.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.14.14.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.14.14.4.1">37.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.14.14.5">40.89</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.14.14.6">32.02</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.14.14.7">37.03</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.14.14.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.14.14.8.1">37.67</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.14.14.9">40.8</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.1"><em class="ltx_emph ltx_font_italic" id="S3.T1.1.15.15.1.1">Other methods</em></th>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.2"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.3"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T1.1.15.15.4"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T1.1.15.15.5">45.9</td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.6"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.7"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T1.1.15.15.8"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S3.T1.1.15.15.9">-</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>BLEU scores for Supervised, and Unsupervised + Supervised NMT Layerwise Relevance Propagation-guided experiments, for Enâ€“Fr, Frâ€“En. <em class="ltx_emph ltx_font_italic" id="S3.T1.6.1">AE</em>, <em class="ltx_emph ltx_font_italic" id="S3.T1.7.2">BT</em> and <em class="ltx_emph ltx_font_italic" id="S3.T1.8.3">MT</em> stand for Auto-Encoding loss, Back Translation loss and Machine Translation loss, respectively. Test and validation sets are from newstest2013-14 for French. State of the art results (<span class="ltx_text ltx_font_italic" id="S3.T1.9.4">Other methods</span>) for Enâ€“Fr come from <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.deepl.com/press.html" title="">http://www.deepl.com/press.html</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://nlpprogress.com/english/machine_translation.html" title="">http://nlpprogress.com/english/machine_translation.html</a>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Layer-wise Relevance Propagation (LRP)</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">We follow the method proposed by <cite class="ltx_cite ltx_citemacro_citet">Voita etÂ al. (<a class="ltx_ref" href="#bib.bib34" title="">2020</a>)</cite> in calculating LRP in an encoder-decoder Transformer architecture. The Relevance Score is first propagated inversely through the decoder and then the encoder, up to the input layer of the architecture. The conservation principle only holds across all processed tokens, and the score is defined as relevance of the input neurons to the top-1 logit predicted by the Transformer model, and the sum of the input neuronsâ€™ relevance is regarded as the token contribution.
The total source and target sentence contributions to the result are defined as the summation of the Relevance of tokens in the source sentence, <math alttext="{x}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_x</annotation></semantics></math> and that of those in the target sentence, <math alttext="{y}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">{y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_y</annotation></semantics></math>, at generation step t.
</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R_{t}(source)=\sum_{i}{x_{i}},\\
\\
\hskip 8.53581ptR_{t}(target)=\sum_{j=1}^{t-1}{y_{j}}" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.3.2.cmml">R</mi><mi id="S3.E2.m1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml">o</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1a" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.1.1.1.1.4.cmml">u</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1b" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.5" xref="S3.E2.m1.1.1.1.1.1.1.1.1.5.cmml">r</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1c" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.6" xref="S3.E2.m1.1.1.1.1.1.1.1.1.6.cmml">c</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1d" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.7" xref="S3.E2.m1.1.1.1.1.1.1.1.1.7.cmml">e</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.1.1.1.1.2" rspace="0.111em" xref="S3.E2.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><munder id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml"><mo id="S3.E2.m1.1.1.1.1.3.1.2" movablelimits="false" xref="S3.E2.m1.1.1.1.1.3.1.2.cmml">âˆ‘</mo><mi id="S3.E2.m1.1.1.1.1.3.1.3" xref="S3.E2.m1.1.1.1.1.3.1.3.cmml">i</mi></munder><msub id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3.cmml">i</mi></msub></mrow></mrow><mo id="S3.E2.m1.2.2.2.3" rspace="1.017em" xref="S3.E2.m1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mrow id="S3.E2.m1.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.1.cmml"><msub id="S3.E2.m1.2.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.1.3.cmml"><mi id="S3.E2.m1.2.2.2.2.1.3.2" xref="S3.E2.m1.2.2.2.2.1.3.2.cmml">R</mi><mi id="S3.E2.m1.2.2.2.2.1.3.3" xref="S3.E2.m1.2.2.2.2.1.3.3.cmml">t</mi></msub><mo id="S3.E2.m1.2.2.2.2.1.2" xref="S3.E2.m1.2.2.2.2.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.1.cmml"><mo id="S3.E2.m1.2.2.2.2.1.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.2.1.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.1.1.2.cmml">t</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.1.1.3.cmml">a</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1.1.1a" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.4" xref="S3.E2.m1.2.2.2.2.1.1.1.1.4.cmml">r</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1.1.1b" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.5" xref="S3.E2.m1.2.2.2.2.1.1.1.1.5.cmml">g</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1.1.1c" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.6" xref="S3.E2.m1.2.2.2.2.1.1.1.1.6.cmml">e</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1.1.1d" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.2.2.1.1.1.1.7" xref="S3.E2.m1.2.2.2.2.1.1.1.1.7.cmml">t</mi></mrow><mo id="S3.E2.m1.2.2.2.2.1.1.1.3" stretchy="false" xref="S3.E2.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.2.2.2" rspace="0.111em" xref="S3.E2.m1.2.2.2.2.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml"><munderover id="S3.E2.m1.2.2.2.2.3.1" xref="S3.E2.m1.2.2.2.2.3.1.cmml"><mo id="S3.E2.m1.2.2.2.2.3.1.2.2" movablelimits="false" xref="S3.E2.m1.2.2.2.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.2.2.2.2.3.1.2.3" xref="S3.E2.m1.2.2.2.2.3.1.2.3.cmml"><mi id="S3.E2.m1.2.2.2.2.3.1.2.3.2" xref="S3.E2.m1.2.2.2.2.3.1.2.3.2.cmml">j</mi><mo id="S3.E2.m1.2.2.2.2.3.1.2.3.1" xref="S3.E2.m1.2.2.2.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.2.2.3.1.2.3.3" xref="S3.E2.m1.2.2.2.2.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E2.m1.2.2.2.2.3.1.3" xref="S3.E2.m1.2.2.2.2.3.1.3.cmml"><mi id="S3.E2.m1.2.2.2.2.3.1.3.2" xref="S3.E2.m1.2.2.2.2.3.1.3.2.cmml">t</mi><mo id="S3.E2.m1.2.2.2.2.3.1.3.1" xref="S3.E2.m1.2.2.2.2.3.1.3.1.cmml">âˆ’</mo><mn id="S3.E2.m1.2.2.2.2.3.1.3.3" xref="S3.E2.m1.2.2.2.2.3.1.3.3.cmml">1</mn></mrow></munderover><msub id="S3.E2.m1.2.2.2.2.3.2" xref="S3.E2.m1.2.2.2.2.3.2.cmml"><mi id="S3.E2.m1.2.2.2.2.3.2.2" xref="S3.E2.m1.2.2.2.2.3.2.2.cmml">y</mi><mi id="S3.E2.m1.2.2.2.2.3.2.3" xref="S3.E2.m1.2.2.2.2.3.2.3.cmml">j</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3a.cmml" xref="S3.E2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"></eq><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.3.2">ğ‘…</ci><ci id="S3.E2.m1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.4">ğ‘¢</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.5">ğ‘Ÿ</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.6">ğ‘</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.7">ğ‘’</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><apply id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E2.m1.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2"></sum><ci id="S3.E2.m1.1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><eq id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2"></eq><apply id="S3.E2.m1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.1"><times id="S3.E2.m1.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.2"></times><apply id="S3.E2.m1.2.2.2.2.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.3.1.cmml" xref="S3.E2.m1.2.2.2.2.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.3.2.cmml" xref="S3.E2.m1.2.2.2.2.1.3.2">ğ‘…</ci><ci id="S3.E2.m1.2.2.2.2.1.3.3.cmml" xref="S3.E2.m1.2.2.2.2.1.3.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1"><times id="S3.E2.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.1"></times><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.2">ğ‘¡</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.3">ğ‘</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.4.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.4">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.5.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.5">ğ‘”</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.6.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.6">ğ‘’</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.1.7.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.1.7">ğ‘¡</ci></apply></apply><apply id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3"><apply id="S3.E2.m1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.3.1.1.cmml" xref="S3.E2.m1.2.2.2.2.3.1">superscript</csymbol><apply id="S3.E2.m1.2.2.2.2.3.1.2.cmml" xref="S3.E2.m1.2.2.2.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.3.1.2.1.cmml" xref="S3.E2.m1.2.2.2.2.3.1">subscript</csymbol><sum id="S3.E2.m1.2.2.2.2.3.1.2.2.cmml" xref="S3.E2.m1.2.2.2.2.3.1.2.2"></sum><apply id="S3.E2.m1.2.2.2.2.3.1.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3.1.2.3"><eq id="S3.E2.m1.2.2.2.2.3.1.2.3.1.cmml" xref="S3.E2.m1.2.2.2.2.3.1.2.3.1"></eq><ci id="S3.E2.m1.2.2.2.2.3.1.2.3.2.cmml" xref="S3.E2.m1.2.2.2.2.3.1.2.3.2">ğ‘—</ci><cn id="S3.E2.m1.2.2.2.2.3.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.2.2.2.2.3.1.2.3.3">1</cn></apply></apply><apply id="S3.E2.m1.2.2.2.2.3.1.3.cmml" xref="S3.E2.m1.2.2.2.2.3.1.3"><minus id="S3.E2.m1.2.2.2.2.3.1.3.1.cmml" xref="S3.E2.m1.2.2.2.2.3.1.3.1"></minus><ci id="S3.E2.m1.2.2.2.2.3.1.3.2.cmml" xref="S3.E2.m1.2.2.2.2.3.1.3.2">ğ‘¡</ci><cn id="S3.E2.m1.2.2.2.2.3.1.3.3.cmml" type="integer" xref="S3.E2.m1.2.2.2.2.3.1.3.3">1</cn></apply></apply><apply id="S3.E2.m1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.2.3.2.2">ğ‘¦</ci><ci id="S3.E2.m1.2.2.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3.2.3">ğ‘—</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">R_{t}(source)=\sum_{i}{x_{i}},\\
\\
\hskip 8.53581ptR_{t}(target)=\sum_{j=1}^{t-1}{y_{j}}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_s italic_o italic_u italic_r italic_c italic_e ) = âˆ‘ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t italic_a italic_r italic_g italic_e italic_t ) = âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.3">At every step t, Relevance of the source and target sentences follow the conservation principle, summing up to 1.
Moreover, for every target token past the currently generated one, Relevance Score is 0.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.3.1">enâ€“gu</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.1.6"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.7.1">guâ€“en</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.1.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.1.2.2.1">Parametersâ€™ Set Values</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.2.2.2">v1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.2.2.3">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.2.2.4">v3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.2.2.5">Regular</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.2.2.6">v1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.2.2.7">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.1.2.2.8">v3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.2.2.9">Regular</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.3.3.1">22k</td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.3.3.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.1.3.3.5"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.6"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.7"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.8"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.1.3.3.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.4.4.1">MT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.2">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.3">2.18</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.4.1">2.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.5">1.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.6">0.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.7">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.4.8.1">0.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.4.4.9">2.65</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.5">
<td class="ltx_td ltx_align_left" id="S3.T2.1.5.5.1">BT+AE+MT</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.5.2">0.76</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.5.3.1">1.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.5.5.4">0.89</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.5.5.5">1.16</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.5.6">0.71</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.5.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.5.7.1">1.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.5.5.8">0.67</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.5.9">2.19</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.1"><em class="ltx_emph ltx_font_italic" id="S3.T2.1.6.6.1.1">Other methods</em></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.2"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.3"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T2.1.6.6.4"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T2.1.6.6.5">0.1</td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.6"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.7"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T2.1.6.6.8"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S3.T2.1.6.6.9">0.3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>BLEU scores for Supervised, and Unsupervised + Supervised NMT Layerwise Relevance Propagation-guided experiments, for Enâ€“Gu, Guâ€“En. <em class="ltx_emph ltx_font_italic" id="S3.T2.6.1">AE</em>, <em class="ltx_emph ltx_font_italic" id="S3.T2.7.2">BT</em> and <em class="ltx_emph ltx_font_italic" id="S3.T2.8.3">MT</em> stand for Auto-Encoding loss, Back Translation loss and Machine Translation loss, respectively. Test and validation sets are from WMT19 for Gujarati. State of the art results (<span class="ltx_text ltx_font_italic" id="S3.T2.9.4">Other methods</span>) can be found in <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google-research/bert/blob/master/multilingual.md" title="">https://github.com/google-research/bert/blob/master/multilingual.md</a>. </figcaption>
</figure>
<figure class="ltx_table" id="S3.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T3.1.1.1.1"></th>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.3.1">enâ€“kk</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.1.1.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.1.1.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.1.1.6"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.7.1">kkâ€“en</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.1.1.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.1.1.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.2.2.1">Parametersâ€™ Set Values</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2.2">v1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2.3">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.2.4">v3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.2.5">Regular</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2.6">v1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2.7">v2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.2.8">v3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2.9">Regular</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T3.1.3.3.1">22k</th>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.3.3.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.3.3.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.3.3.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.3.3.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.3.3.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.3.3.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.3.3.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.3.3.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.4.4.1">MT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.4.4.2">2.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.4.4.3">3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.4.4.1">3.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.5">2.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.4.4.6">2.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.4.4.7">2.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.4.4.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.4.8.1">2.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.4.4.9">2.6</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.1.5.5.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5.2">1.6</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.5.5.3.1">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.5.4">2.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.5.5">2.8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5.6">2.1</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.5.5.7.1">2.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.5.8">2.</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5.9">2.9</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T3.1.6.6.1">132k</th>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.6.6.2"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.6.6.3"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.6.6.4"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.6.6.5"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.6.6.6"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.6.6.7"></td>
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T3.1.6.6.8"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.6.6.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.1.7.7.1">MT</th>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7.2">4.8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7.3">5.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.7.4">5.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.7.5">5.2</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7.6">6.8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.7.7.7.1">8.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.7.8">8.4</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7.9">8</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.1.8.8.1">BT+AE+MT</th>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8.2">5.2</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.8.8.3.1">6.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.8.4">6.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.8.5">6.6</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8.6">8.7</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.8.8.7.1">9.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.8.8.8">9.2</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.8.9">8.9</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.1"><em class="ltx_emph ltx_font_italic" id="S3.T3.1.9.9.1.1">Other methods</em></th>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.2"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.3"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T3.1.9.9.4"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T3.1.9.9.5">2.5<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.deepl.com/press.html</span></span></span>
</td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.6"></td>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.7"></td>
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_tt" id="S3.T3.1.9.9.8"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S3.T3.1.9.9.9">7.4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>BLEU scores for Supervised, and Unsupervised + Supervised NMT Layerwise Relevance Propagation-guided experiments, for Enâ€“Kk, Kkâ€“En. <em class="ltx_emph ltx_font_italic" id="S3.T3.6.1">AE</em>, <em class="ltx_emph ltx_font_italic" id="S3.T3.7.2">BT</em> and <em class="ltx_emph ltx_font_italic" id="S3.T3.8.3">MT</em> stand for Auto-Encoding loss, Back Translation loss and Machine Translation loss, respectively. Test and validation sets are from WMT19. State of the art results (<span class="ltx_text ltx_font_italic" id="S3.T3.9.4">Other methods</span>) can be found in <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google-research/bert/blob/master/multilingual.md" title="">https://github.com/google-research/bert/blob/master/multilingual.md</a>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>LRP-weighted training</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.3">Following <cite class="ltx_cite ltx_citemacro_citet">Sun etÂ al. (<a class="ltx_ref" href="#bib.bib31" title="">2021a</a>)</cite>, we attempt to utilize LRP contributions during training, and examine performance. In our case, the representation of every intermediate source or target token <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, with Relevance Score <math alttext="R_{t}(x_{i})" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><mrow id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><msub id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.p1.2.m2.1.1.3.2" xref="S3.SS4.p1.2.m2.1.1.3.2.cmml">R</mi><mi id="S3.SS4.p1.2.m2.1.1.3.3" xref="S3.SS4.p1.2.m2.1.1.3.3.cmml">t</mi></msub><mo id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS4.p1.2.m2.1.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS4.p1.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p1.2.m2.1.1.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.1.1.1.2" xref="S3.SS4.p1.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS4.p1.2.m2.1.1.1.1.1.3" xref="S3.SS4.p1.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS4.p1.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS4.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><times id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2"></times><apply id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.p1.2.m2.1.1.3.2">ğ‘…</ci><ci id="S3.SS4.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.SS4.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS4.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">R_{t}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, is reweighted by its score at each layer, and included in a new loss term, <math alttext="L\textsubscript{ce}(y,x_{i})" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m3.2"><semantics id="S3.SS4.p1.3.m3.2a"><mrow id="S3.SS4.p1.3.m3.2.2" xref="S3.SS4.p1.3.m3.2.2.cmml"><mi id="S3.SS4.p1.3.m3.2.2.3" xref="S3.SS4.p1.3.m3.2.2.3.cmml">L</mi><mo id="S3.SS4.p1.3.m3.2.2.2" xref="S3.SS4.p1.3.m3.2.2.2.cmml">â¢</mo><mtext id="S3.SS4.p1.3.m3.2.2.4" xref="S3.SS4.p1.3.m3.2.2.4b.cmml"><sub class="ltx_sub" id="S3.SS4.p1.3.m3.2.2.4.1nest">ce</sub></mtext><mo id="S3.SS4.p1.3.m3.2.2.2a" xref="S3.SS4.p1.3.m3.2.2.2.cmml">â¢</mo><mrow id="S3.SS4.p1.3.m3.2.2.1.1" xref="S3.SS4.p1.3.m3.2.2.1.2.cmml"><mo id="S3.SS4.p1.3.m3.2.2.1.1.2" stretchy="false" xref="S3.SS4.p1.3.m3.2.2.1.2.cmml">(</mo><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">y</mi><mo id="S3.SS4.p1.3.m3.2.2.1.1.3" xref="S3.SS4.p1.3.m3.2.2.1.2.cmml">,</mo><msub id="S3.SS4.p1.3.m3.2.2.1.1.1" xref="S3.SS4.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS4.p1.3.m3.2.2.1.1.1.2" xref="S3.SS4.p1.3.m3.2.2.1.1.1.2.cmml">x</mi><mi id="S3.SS4.p1.3.m3.2.2.1.1.1.3" xref="S3.SS4.p1.3.m3.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS4.p1.3.m3.2.2.1.1.4" stretchy="false" xref="S3.SS4.p1.3.m3.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.2b"><apply id="S3.SS4.p1.3.m3.2.2.cmml" xref="S3.SS4.p1.3.m3.2.2"><times id="S3.SS4.p1.3.m3.2.2.2.cmml" xref="S3.SS4.p1.3.m3.2.2.2"></times><ci id="S3.SS4.p1.3.m3.2.2.3.cmml" xref="S3.SS4.p1.3.m3.2.2.3">ğ¿</ci><ci id="S3.SS4.p1.3.m3.2.2.4b.cmml" xref="S3.SS4.p1.3.m3.2.2.4"><mtext id="S3.SS4.p1.3.m3.2.2.4.cmml" xref="S3.SS4.p1.3.m3.2.2.4"><sub class="ltx_sub" id="S3.SS4.p1.3.m3.2.2.4.1anest">ce</sub></mtext></ci><interval closure="open" id="S3.SS4.p1.3.m3.2.2.1.2.cmml" xref="S3.SS4.p1.3.m3.2.2.1.1"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">ğ‘¦</ci><apply id="S3.SS4.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS4.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS4.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS4.p1.3.m3.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.SS4.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS4.p1.3.m3.2.2.1.1.1.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.2c">L\textsubscript{ce}(y,x_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m3.2d">italic_L ( italic_y , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. The formula takes the following form</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L^{\prime}=\xi*L(y,p(x_{i}))+\lambda*L(y,p({R_{t}}(x_{i}))" class="ltx_math_unparsed" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2b"><msup id="S3.E3.m1.2.3"><mi id="S3.E3.m1.2.3.2">L</mi><mo id="S3.E3.m1.2.3.3">â€²</mo></msup><mo id="S3.E3.m1.2.4">=</mo><mi id="S3.E3.m1.2.5">Î¾</mi><mo id="S3.E3.m1.2.6" lspace="0.222em" rspace="0.222em">*</mo><mi id="S3.E3.m1.2.7">L</mi><mrow id="S3.E3.m1.2.8"><mo id="S3.E3.m1.2.8.1" stretchy="false">(</mo><mi id="S3.E3.m1.1.1">y</mi><mo id="S3.E3.m1.2.8.2">,</mo><mi id="S3.E3.m1.2.8.3">p</mi><mrow id="S3.E3.m1.2.8.4"><mo id="S3.E3.m1.2.8.4.1" stretchy="false">(</mo><msub id="S3.E3.m1.2.8.4.2"><mi id="S3.E3.m1.2.8.4.2.2">x</mi><mi id="S3.E3.m1.2.8.4.2.3">i</mi></msub><mo id="S3.E3.m1.2.8.4.3" stretchy="false">)</mo></mrow><mo id="S3.E3.m1.2.8.5" stretchy="false">)</mo></mrow><mo id="S3.E3.m1.2.9">+</mo><mi id="S3.E3.m1.2.10">Î»</mi><mo id="S3.E3.m1.2.11" lspace="0.222em" rspace="0.222em">*</mo><mi id="S3.E3.m1.2.12">L</mi><mrow id="S3.E3.m1.2.13"><mo id="S3.E3.m1.2.13.1" stretchy="false">(</mo><mi id="S3.E3.m1.2.2">y</mi><mo id="S3.E3.m1.2.13.2">,</mo><mi id="S3.E3.m1.2.13.3">p</mi><mrow id="S3.E3.m1.2.13.4"><mo id="S3.E3.m1.2.13.4.1" stretchy="false">(</mo><msub id="S3.E3.m1.2.13.4.2"><mi id="S3.E3.m1.2.13.4.2.2">R</mi><mi id="S3.E3.m1.2.13.4.2.3">t</mi></msub><mrow id="S3.E3.m1.2.13.4.3"><mo id="S3.E3.m1.2.13.4.3.1" stretchy="false">(</mo><msub id="S3.E3.m1.2.13.4.3.2"><mi id="S3.E3.m1.2.13.4.3.2.2">x</mi><mi id="S3.E3.m1.2.13.4.3.2.3">i</mi></msub><mo id="S3.E3.m1.2.13.4.3.3" stretchy="false">)</mo></mrow><mo id="S3.E3.m1.2.13.4.4" stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L^{\prime}=\xi*L(y,p(x_{i}))+\lambda*L(y,p({R_{t}}(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">italic_L start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = italic_Î¾ * italic_L ( italic_y , italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) + italic_Î» * italic_L ( italic_y , italic_p ( italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p1.7">,where <math alttext="p(x_{i})" class="ltx_Math" display="inline" id="S3.SS4.p1.4.m1.1"><semantics id="S3.SS4.p1.4.m1.1a"><mrow id="S3.SS4.p1.4.m1.1.1" xref="S3.SS4.p1.4.m1.1.1.cmml"><mi id="S3.SS4.p1.4.m1.1.1.3" xref="S3.SS4.p1.4.m1.1.1.3.cmml">p</mi><mo id="S3.SS4.p1.4.m1.1.1.2" xref="S3.SS4.p1.4.m1.1.1.2.cmml">â¢</mo><mrow id="S3.SS4.p1.4.m1.1.1.1.1" xref="S3.SS4.p1.4.m1.1.1.1.1.1.cmml"><mo id="S3.SS4.p1.4.m1.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.4.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p1.4.m1.1.1.1.1.1" xref="S3.SS4.p1.4.m1.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.4.m1.1.1.1.1.1.2" xref="S3.SS4.p1.4.m1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS4.p1.4.m1.1.1.1.1.1.3" xref="S3.SS4.p1.4.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS4.p1.4.m1.1.1.1.1.3" stretchy="false" xref="S3.SS4.p1.4.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m1.1b"><apply id="S3.SS4.p1.4.m1.1.1.cmml" xref="S3.SS4.p1.4.m1.1.1"><times id="S3.SS4.p1.4.m1.1.1.2.cmml" xref="S3.SS4.p1.4.m1.1.1.2"></times><ci id="S3.SS4.p1.4.m1.1.1.3.cmml" xref="S3.SS4.p1.4.m1.1.1.3">ğ‘</ci><apply id="S3.SS4.p1.4.m1.1.1.1.1.1.cmml" xref="S3.SS4.p1.4.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.4.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.4.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.4.m1.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.4.m1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS4.p1.4.m1.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.4.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m1.1c">p(x_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.4.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="p({R_{t}}(x_{i}))" class="ltx_Math" display="inline" id="S3.SS4.p1.5.m2.1"><semantics id="S3.SS4.p1.5.m2.1a"><mrow id="S3.SS4.p1.5.m2.1.1" xref="S3.SS4.p1.5.m2.1.1.cmml"><mi id="S3.SS4.p1.5.m2.1.1.3" xref="S3.SS4.p1.5.m2.1.1.3.cmml">p</mi><mo id="S3.SS4.p1.5.m2.1.1.2" xref="S3.SS4.p1.5.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS4.p1.5.m2.1.1.1.1" xref="S3.SS4.p1.5.m2.1.1.1.1.1.cmml"><mo id="S3.SS4.p1.5.m2.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.5.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.p1.5.m2.1.1.1.1.1" xref="S3.SS4.p1.5.m2.1.1.1.1.1.cmml"><msub id="S3.SS4.p1.5.m2.1.1.1.1.1.3" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p1.5.m2.1.1.1.1.1.3.2" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3.2.cmml">R</mi><mi id="S3.SS4.p1.5.m2.1.1.1.1.1.3.3" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.SS4.p1.5.m2.1.1.1.1.1.2" xref="S3.SS4.p1.5.m2.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.2" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.3" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS4.p1.5.m2.1.1.1.1.3" stretchy="false" xref="S3.SS4.p1.5.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m2.1b"><apply id="S3.SS4.p1.5.m2.1.1.cmml" xref="S3.SS4.p1.5.m2.1.1"><times id="S3.SS4.p1.5.m2.1.1.2.cmml" xref="S3.SS4.p1.5.m2.1.1.2"></times><ci id="S3.SS4.p1.5.m2.1.1.3.cmml" xref="S3.SS4.p1.5.m2.1.1.3">ğ‘</ci><apply id="S3.SS4.p1.5.m2.1.1.1.1.1.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1"><times id="S3.SS4.p1.5.m2.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.2"></times><apply id="S3.SS4.p1.5.m2.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p1.5.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS4.p1.5.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3.2">ğ‘…</ci><ci id="S3.SS4.p1.5.m2.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.5.m2.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m2.1c">p({R_{t}}(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.5.m2.1d">italic_p ( italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math> are the model prediction and the explanation-guided prediction, respectively.
The loss then is the weighted sum of the previous and the new terms, each weighted by parameters <math alttext="\xi" class="ltx_Math" display="inline" id="S3.SS4.p1.6.m3.1"><semantics id="S3.SS4.p1.6.m3.1a"><mi id="S3.SS4.p1.6.m3.1.1" xref="S3.SS4.p1.6.m3.1.1.cmml">Î¾</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m3.1b"><ci id="S3.SS4.p1.6.m3.1.1.cmml" xref="S3.SS4.p1.6.m3.1.1">ğœ‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m3.1c">\xi</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.6.m3.1d">italic_Î¾</annotation></semantics></math>, <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS4.p1.7.m4.1"><semantics id="S3.SS4.p1.7.m4.1a"><mi id="S3.SS4.p1.7.m4.1.1" xref="S3.SS4.p1.7.m4.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m4.1b"><ci id="S3.SS4.p1.7.m4.1.1.cmml" xref="S3.SS4.p1.7.m4.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.7.m4.1d">italic_Î»</annotation></semantics></math> respectively, for which we experiment with three sets of values:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\xi,\lambda=\{v\textsubscript{1}=\{1,0.5\},v\textsubscript{2}=\{0,1\},v%
\textsubscript{3}=\{1,1\}\}." class="ltx_Math" display="block" id="S3.E4.m1.9"><semantics id="S3.E4.m1.9a"><mrow id="S3.E4.m1.9.9.1" xref="S3.E4.m1.9.9.1.1.cmml"><mrow id="S3.E4.m1.9.9.1.1" xref="S3.E4.m1.9.9.1.1.cmml"><mrow id="S3.E4.m1.9.9.1.1.3.2" xref="S3.E4.m1.9.9.1.1.3.1.cmml"><mi id="S3.E4.m1.7.7" xref="S3.E4.m1.7.7.cmml">Î¾</mi><mo id="S3.E4.m1.9.9.1.1.3.2.1" xref="S3.E4.m1.9.9.1.1.3.1.cmml">,</mo><mi id="S3.E4.m1.8.8" xref="S3.E4.m1.8.8.cmml">Î»</mi></mrow><mo id="S3.E4.m1.9.9.1.1.2" xref="S3.E4.m1.9.9.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.9.9.1.1.1.1" xref="S3.E4.m1.9.9.1.1.1.2.cmml"><mo id="S3.E4.m1.9.9.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.2.cmml">{</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2" xref="S3.E4.m1.9.9.1.1.1.1.1.3.cmml"><mrow id="S3.E4.m1.9.9.1.1.1.1.1.1.1" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.2.cmml">v</mi><mo id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.1.cmml">â¢</mo><mtext id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3b.cmml"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3.1nest">1</sub></mtext></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.1.1.1.1" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.1.cmml"><mo id="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.1.cmml">{</mo><mn id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">1</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.1.cmml">,</mo><mn id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">0.5</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.2.3" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.1.cmml">}</mo></mrow></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.3" xref="S3.E4.m1.9.9.1.1.1.1.1.3a.cmml">,</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.3.cmml"><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.cmml"><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.cmml"><mi id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.2.cmml">v</mi><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.1" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.1.cmml">â¢</mo><mtext id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3b.cmml"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3.1nest">2</sub></mtext></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.1" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.1.cmml"><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.1.cmml">{</mo><mn id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">0</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.1.cmml">,</mo><mn id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml">1</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.2.3" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.1.cmml">}</mo></mrow></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.3" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.3a.cmml">,</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.cmml"><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.2.cmml">v</mi><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.1" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.1.cmml">â¢</mo><mtext id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3b.cmml"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3.1nest">3</sub></mtext></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.1" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.1.cmml">=</mo><mrow id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.1.cmml"><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.2.1" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.1.cmml">{</mo><mn id="S3.E4.m1.5.5" xref="S3.E4.m1.5.5.cmml">1</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.2.2" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.1.cmml">,</mo><mn id="S3.E4.m1.6.6" xref="S3.E4.m1.6.6.cmml">1</mn><mo id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.2.3" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.1.cmml">}</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.9.9.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.9.9.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S3.E4.m1.9.9.1.2" lspace="0em" xref="S3.E4.m1.9.9.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.9b"><apply id="S3.E4.m1.9.9.1.1.cmml" xref="S3.E4.m1.9.9.1"><eq id="S3.E4.m1.9.9.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.2"></eq><list id="S3.E4.m1.9.9.1.1.3.1.cmml" xref="S3.E4.m1.9.9.1.1.3.2"><ci id="S3.E4.m1.7.7.cmml" xref="S3.E4.m1.7.7">ğœ‰</ci><ci id="S3.E4.m1.8.8.cmml" xref="S3.E4.m1.8.8">ğœ†</ci></list><set id="S3.E4.m1.9.9.1.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1"><apply id="S3.E4.m1.9.9.1.1.1.1.1.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.9.9.1.1.1.1.1.3a.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.9.9.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1"><eq id="S3.E4.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.1"></eq><apply id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.1"></times><ci id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.2">ğ‘£</ci><ci id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3b.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3"><mtext id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.1.1.2.3.1anest">1</sub></mtext></ci></apply><set id="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.1.1.3.2"><cn id="S3.E4.m1.1.1.cmml" type="integer" xref="S3.E4.m1.1.1">1</cn><cn id="S3.E4.m1.2.2.cmml" type="float" xref="S3.E4.m1.2.2">0.5</cn></set></apply><apply id="S3.E4.m1.9.9.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.9.9.1.1.1.1.1.2.2.3a.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1"><eq id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.1"></eq><apply id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2"><times id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.1"></times><ci id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.2">ğ‘£</ci><ci id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3b.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3"><mtext id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.2.3.1anest">2</sub></mtext></ci></apply><set id="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.1.1.3.2"><cn id="S3.E4.m1.3.3.cmml" type="integer" xref="S3.E4.m1.3.3">0</cn><cn id="S3.E4.m1.4.4.cmml" type="integer" xref="S3.E4.m1.4.4">1</cn></set></apply><apply id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2"><eq id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.1"></eq><apply id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2"><times id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.1"></times><ci id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.2">ğ‘£</ci><ci id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3b.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3"><mtext id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3"><sub class="ltx_sub" id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.2.3.1anest">3</sub></mtext></ci></apply><set id="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E4.m1.9.9.1.1.1.1.1.2.2.2.2.3.2"><cn id="S3.E4.m1.5.5.cmml" type="integer" xref="S3.E4.m1.5.5">1</cn><cn id="S3.E4.m1.6.6.cmml" type="integer" xref="S3.E4.m1.6.6">1</cn></set></apply></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.9c">\xi,\lambda=\{v\textsubscript{1}=\{1,0.5\},v\textsubscript{2}=\{0,1\},v%
\textsubscript{3}=\{1,1\}\}.</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.9d">italic_Î¾ , italic_Î» = { italic_v = { 1 , 0.5 } , italic_v = { 0 , 1 } , italic_v = { 1 , 1 } } .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p1.8">In the first layer we only weigh the word embedding of the token.
We hypothesize that in this way, the tokens with a higher contribution to the NMT result are enhanced, while the effect of the ones contributing less is reduced.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results &amp; Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In Tables <a class="ltx_ref" href="#S3.T1" title="Table 1 â€£ 3.2 Datasets â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a class="ltx_ref" href="#S3.T2" title="Table 2 â€£ 3.3 Layer-wise Relevance Propagation (LRP) â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a class="ltx_ref" href="#S3.T3" title="Table 3 â€£ 3.3 Layer-wise Relevance Propagation (LRP) â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>, we present our results for LRP-guided training, in certain low- and high-resource Semi-Supervised and Supervised experiments, for all languages and directions, providing the regular NMT model results as our baselines.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We see that for Enâ€“Fr and Frâ€“En NMT, in Table <a class="ltx_ref" href="#S3.T1" title="Table 1 â€£ 3.2 Datasets â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, the method fails to outperform baseline NMT results in all cases. The model translation quality is usually on par with baselines, and state-of-the art results on high scale experiments, and small differences in BLEU scores in the range of 0.1-0.5 can be considered negligible.
Among the three hypermarameter settings, choosing v1 for training seems to outperform the other two in the majority of experiments under a MT-only setting.
Results could indicate unsuitability of the method in high-resource settings; the original method was after all proposed in a few-shot classification context, hence we also seek more promising results in low-resource NMT experiments, examined below.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">A different model behavior is observed for all cases but one in English to Gujarati NMT, in Table <a class="ltx_ref" href="#S3.T2" title="Table 2 â€£ 3.3 Layer-wise Relevance Propagation (LRP) â€£ 3 Method &amp; Experiments â€£ Relevance-guided Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> when either the MT-only or BT-AE-MT objectives are used in training. This is an interesting finding - we can hypothesize that LRP-guided training might be more useful when translating into highly complex morphological languages such as Gujarati; Results marginally outperform previous state-of-the-art approaches, however more research including other languages and potentially other parameter values is required to verify that observation.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Encouraging is also the case of LRP-guided training in Enâ€“Kk and Kkâ€“En NMT. In a large number of settings, training with Relevance guidance improves NMT BLEU scores significantly compared to our regular modelsâ€™ results. More specifically, we see improvement in both low- (22k) and mid-resource (132k) experiments, with v2-parameterized models to outperform our baselines in the majority of cases. Also, all experiments we are able to perform better than the state of the art current result, hence relevance guidance shows potential again in NMT experiments where few parallel data are available.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We perform a series of Semi-Supervised and Supervised Neural Machine Translation experiments, using an explainability-based metric, namely Relevance-guided propagation, during training; we leverage the measure of influence of the input and intermediate layer outputs to the NMT result, in an attempt to improve NMT for three quite different languages, lying in both high- and low- resource data regimes. Our results, though showing marginal and very small improvements, indicate that Layerwise-relevance propagation shows potential in boosting NMT quality when training in small data scenarios. Further exploration of the method, different model hyperparameter setups, and expansion of our method to other languages is strongly recommended as a next step to identify the efficiency and robustness of the proposed method.
</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Training a large Neural Machine Translation model from scratch is a hard task computationally,
and employing LRP-guidance during training significantly raises training time, the amount and usage of required computational resources, and the complexity of the training process, calling for more efficient training solutions, in terms of memory distribution of the model and parallelization. These factors constitute the limitations of our approach, and allowed us to launch a small number of experiments, hence addressing those factors and expanding to more languages, in more efficient training and computational ways, is a strong requirement for further generalization of the method.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Ethics Statement</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Several ethical concerns ought to be addressed when working with large language models regarding quality, toxicity and bias related to their training process and output <cite class="ltx_cite ltx_citemacro_cite">Bender etÂ al. (<a class="ltx_ref" href="#bib.bib6" title="">2021</a>); Chowdhery etÂ al. (<a class="ltx_ref" href="#bib.bib8" title="">2022</a>); Brown etÂ al. (<a class="ltx_ref" href="#bib.bib7" title="">2020</a>)</cite>,of which the authors of the paper are aware in their work.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anders etÂ al. (2022)</span>
<span class="ltx_bibblock">
ChristopherÂ J Anders, Leander Weber, David Neumann, Wojciech Samek, Klaus-Robert MÃ¼ller, and Sebastian Lapuschkin. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.sciencedirect.com/science/article/pii/S1566253521001573" title="">Finding and removing clever hans: Using explanation methods to debug and improve deep models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Information Fusion</em>, 77:261â€“295.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe etÂ al. (2019)</span>
<span class="ltx_bibblock">
Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1902.01313.pdf" title="">An effective approach to unsupervised machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:1902.01313</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe etÂ al. (2017)</span>
<span class="ltx_bibblock">
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1710.11041.pdf" title="">Unsupervised neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:1710.11041</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach etÂ al. (2015)</span>
<span class="ltx_bibblock">
Sebastian Bach, Alexander Binder, GrÃ©goire Montavon, Frederick Klauschen, Klaus-Robert MÃ¼ller, and Wojciech Samek. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140" title="">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">PloS one</em>, 10(7):e0130140.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belinkov etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yonatan Belinkov, Sebastian Gehrmann, and Ellie Pavlick. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-tutorials.1" title="">Interpretability and analysis in neural NLP</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</em>, pages 1â€“5, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender etÂ al. (2021)</span>
<span class="ltx_bibblock">
EmilyÂ M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3442188.3445922" title="">On the dangers of stochastic parrots: Can language models be too big?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT â€™21, page 610â€“623, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, etÂ al. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Advances in neural information processing systems</em>, 33:1877â€“1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery etÂ al. (2022)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, HyungÂ Won Chung, Charles Sutton, Sebastian Gehrmann, etÂ al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2204.02311" title="">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2204.02311</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau etÂ al. (2017)</span>
<span class="ltx_bibblock">
Alexis Conneau, Guillaume Lample, Marcâ€™Aurelio Ranzato, Ludovic Denoyer, and HervÃ© JÃ©gou. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1710.04087.pdf" title="">Word translation without parallel data</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1710.04087</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Danilevsky etÂ al. (2020)</span>
<span class="ltx_bibblock">
Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katsis, Ban Kawas, and Prithviraj Sen. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2010.00711.pdf" title="">A survey of the state of explainable ai for natural language processing</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2010.00711</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fukui etÂ al. (2019)</span>
<span class="ltx_bibblock">
Hiroshi Fukui, Tsubasa Hirakawa, Takayoshi Yamashita, and Hironobu Fujiyoshi. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Fukui_Attention_Branch_Network_Learning_of_Attention_Mechanism_for_Visual_Explanation_CVPR_2019_paper.pdf" title="">Attention branch network: Learning of attention mechanism for visual explanation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pages 10705â€“10714.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garcia etÂ al. (2020)</span>
<span class="ltx_bibblock">
Xavier Garcia, Pierre Foret, Thibault Sellam, and AnkurÂ P Parikh. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://aclanthology.lst.uni-saarland.de/2020.findings-emnlp.283.pdf" title="">A multilingual view of unsupervised machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2002.02955</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yunsu Kim, Miguel GraÃ§a, and Hermann Ney. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2004.10581.pdf" title="">When and why is unsupervised neural machine translation useless?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2004.10581</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample and Conneau (2019)</span>
<span class="ltx_bibblock">
Guillaume Lample and Alexis Conneau. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf" title="">Cross-lingual language model pretraining</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1901.07291</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample etÂ al. (2017)</span>
<span class="ltx_bibblock">
Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marcâ€™Aurelio Ranzato. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1711.00043.pdf" title="">Unsupervised machine translation using monolingual corpora only</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:1711.00043</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample etÂ al. (2018)</span>
<span class="ltx_bibblock">
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marcâ€™Aurelio Ranzato. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/D18-1549.pdf" title="">Phrase-based &amp; neural unsupervised machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:1804.07755</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.tacl-1.47.pdf" title="">Multilingual denoising pre-training for neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Transactions of the Association for Computational Linguistics</em>, 8:726â€“742.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madsen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Andreas Madsen, Siva Reddy, and Sarath Chandar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://dl.acm.org/doi/10.1145/3546577" title="">Post-hoc interpretability for neural nlp: A survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2108.04840</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marchisio etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kelly Marchisio, Kevin Duh, and Philipp Koehn. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2004.05516.pdf" title="">When does unsupervised machine translation work?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2004.05516</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitsuhara etÂ al. (2019)</span>
<span class="ltx_bibblock">
Masahiro Mitsuhara, Hiroshi Fukui, Yusuke Sakashita, Takanori Ogata, Tsubasa Hirakawa, Takayoshi Yamashita, and Hironobu Fujiyoshi. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1905.03540.pdf" title="">Embedding human knowledge into deep neural network via attention map</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:1905.03540</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen etÂ al. (2022)</span>
<span class="ltx_bibblock">
Xuan-Phi Nguyen, Shafiq Joty, WuÂ Kui, and AiÂ Ti Aw. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2205.15544.pdf" title="">Refining low-resource unsupervised translation by language disentanglement of multilingual model</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2205.15544</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni etÂ al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P02-1040.pdf" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</em>, pages 311â€“318.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kun Qian, Marina Danilevsky, Yannis Katsis, Ban Kawas, Erick Oduor, Lucian Popa, and Yunyao Li. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://dl.acm.org/doi/pdf/10.1145/3397482.3450728" title="">Xnlp: A living survey for xai research in natural language processing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">26th International Conference on Intelligent User Interfaces-Companion</em>, pages 78â€“80.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schiller etÂ al. (2019)</span>
<span class="ltx_bibblock">
Dominik Schiller, Tobias Huber, Florian Lingenfelser, Michael Dietz, Andreas Seiderer, and Elisabeth AndrÃ©. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/deliver/index/docId/65146/file/2707.pdf" title="">Relevance-based feature masking: Improving neural network based whale classification through explainable artificial intelligence</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sefcik and Benesova (2021)</span>
<span class="ltx_bibblock">
Frantisek Sefcik and Wanda Benesova. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2107.02008.pdf" title="">Improving a neural network model by explanation-guided training for glioma classification based on mri data</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2107.02008</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich etÂ al. (2015)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P16-1009.pdf" title="">Improving neural machine translation models with monolingual data</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:1511.06709</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich etÂ al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P16-1162" title="">Neural machine translation of rare words with subword units</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1715â€“1725, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song etÂ al. (2019)</span>
<span class="ltx_bibblock">
Kaitao Song, XuÂ Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://proceedings.mlr.press/v97/song19d/song19d.pdf" title="">Mass: Masked sequence to sequence pre-training for language generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:1905.02450</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su etÂ al. (2019)</span>
<span class="ltx_bibblock">
Yuanhang Su, Kai Fan, Nguyen Bach, C-CÂ Jay Kuo, and Fei Huang. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Su_Unsupervised_Multi-Modal_Neural_Machine_Translation_CVPR_2019_paper.pdf" title="">Unsupervised multi-modal neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 10482â€“10491.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jiamei Sun, Sebastian Lapuschkin, Wojciech Samek, and Alexander Binder. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.sciencedirect.com/science/article/pii/S1566253521001494" title="">Explain and improve: Lrp-inference fine-tuning for image captioning models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Information Fusion</em>, 77:233â€“246.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2021a)</span>
<span class="ltx_bibblock">
Jiamei Sun, Sebastian Lapuschkin, Wojciech Samek, Yunqing Zhao, Ngai-Man Cheung, and Alexander Binder. 2021a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2007.08790.pdf" title="">Explanation-guided training for cross-domain few-shot classification</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">2020 25th International Conference on Pattern Recognition (ICPR)</em>, pages 7609â€“7616. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2021b)</span>
<span class="ltx_bibblock">
Xiaofei Sun, Diyi Yang, Xiaoya Li, Tianwei Zhang, Yuxian Meng, Qiu Han, Guoyin Wang, Eduard Hovy, and Jiwei Li. 2021b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2110.10470.pdf" title="">Interpreting deep learning models in natural language processing: A review</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2110.10470</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tenney etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ian Tenney, James Wexler, Jasmijn Bastings, Tolga Bolukbasi, Andy Coenen, Sebastian Gehrmann, Ellen Jiang, Mahima Pushkarna, Carey Radebaugh, Emily Reif, etÂ al. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.emnlp-demos.15.pdf" title="">The language interpretability tool: Extensible, interactive visualizations and analysis for nlp models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2008.05122</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voita etÂ al. (2020)</span>
<span class="ltx_bibblock">
Elena Voita, Rico Sennrich, and Ivan Titov. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.acl-long.91.pdf" title="">Analyzing the source and target contributions to predictions in neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2010.10907</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Zhao (2021)</span>
<span class="ltx_bibblock">
Rui Wang and Hai Zhao. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.eacl-tutorials.5/" title="">Advances and challenges in unsupervised neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts</em>, pages 17â€“21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber etÂ al. (2022)</span>
<span class="ltx_bibblock">
Leander Weber, Sebastian Lapuschkin, Alexander Binder, and Wojciech Samek. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.sciencedirect.com/science/article/pii/S1566253522002238" title="">Beyond explaining: Opportunities and challenges of xai-based model improvement</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2203.08008</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2016)</span>
<span class="ltx_bibblock">
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1512.04150.pdf" title="">Learning deep features for discriminative localization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 2921â€“2929.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zunino etÂ al. (2021a)</span>
<span class="ltx_bibblock">
Andrea Zunino, SarahÂ Adel Bargal, Pietro Morerio, Jianming Zhang, Stan Sclaroff, and Vittorio Murino. 2021a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://link.springer.com/article/10.1007/s11263-020-01422-y" title="">Excitation dropout: Encouraging plasticity in deep neural networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International Journal of Computer Vision</em>, 129(4):1139â€“1152.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zunino etÂ al. (2021b)</span>
<span class="ltx_bibblock">
Andrea Zunino, SarahÂ Adel Bargal, Riccardo Volpi, Mehrnoosh Sameki, Jianming Zhang, Stan Sclaroff, Vittorio Murino, and Kate Saenko. 2021b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/papers/Zunino_Explainable_Deep_Classification_Models_for_Domain_Generalization_CVPRW_2021_paper.pdf" title="">Explainable deep classification models for domain generalization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 3233â€“3242.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Nov 30 21:44:36 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
