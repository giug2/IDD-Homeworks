<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.08264] On the Impact of Explanations on Understanding of Algorithmic Decision-Making</title><meta property="og:description" content="Ethical principles for algorithms are gaining importance as more and more stakeholders are affected by ”high-risk” algorithmic decision-making (ADM) systems. Understanding how these systems work enables stakeholders to…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On the Impact of Explanations on Understanding of Algorithmic Decision-Making">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="On the Impact of Explanations on Understanding of Algorithmic Decision-Making">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.08264">

<!--Generated on Fri Mar  1 01:02:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="XAI,  learning Sciences,  algorithmic decision-making,  algorithmic fairness,  qualitative methods">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">On the Impact of Explanations on Understanding of Algorithmic Decision-Making</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Timothée Schmude
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:timothee.schmude@univie.ac.at">timothee.schmude@univie.ac.at</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">University of Vienna, Faculty of Computer Science, Research Network Data Science, UniVie Doctoral School Computer Science DoCS</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">Währinger Straße 29</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_state">Vienna</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_country">Austria</span><span id="id6.6.id6" class="ltx_text ltx_affiliation_postcode">1090</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Laura Koesten
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:laura.koesten@univie.ac.at">laura.koesten@univie.ac.at</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">University of Vienna, Faculty of Computer Science, Research Group Visualization and Data Analysis</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_streetaddress">Sensengasse 6</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id10.4.id4" class="ltx_text ltx_affiliation_state">Vienna</span><span id="id11.5.id5" class="ltx_text ltx_affiliation_country">Austria</span><span id="id12.6.id6" class="ltx_text ltx_affiliation_postcode">1090</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Torsten Möller
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:torsten.moeller@univie.ac.at">torsten.moeller@univie.ac.at</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">University of Vienna, Faculty of Computer Science, Research Network Data Science, Research Group Visualization and Data Analysis</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_streetaddress">Sensengasse 6</span><span id="id15.3.id3" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id16.4.id4" class="ltx_text ltx_affiliation_state">Vienna</span><span id="id17.5.id5" class="ltx_text ltx_affiliation_country">Austria</span><span id="id18.6.id6" class="ltx_text ltx_affiliation_postcode">1090</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sebastian Tschiatschek
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:sebastian.tschiatschek@univie.ac.at">sebastian.tschiatschek@univie.ac.at</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id19.1.id1" class="ltx_text ltx_affiliation_institution">University of Vienna, Faculty of Computer Science, Research Network Data Science, Research Group Data Mining and Machine Learning</span><span id="id20.2.id2" class="ltx_text ltx_affiliation_streetaddress">Währinger Straße 29</span><span id="id21.3.id3" class="ltx_text ltx_affiliation_city">Vienna</span><span id="id22.4.id4" class="ltx_text ltx_affiliation_state">Vienna</span><span id="id23.5.id5" class="ltx_text ltx_affiliation_country">Austria</span><span id="id24.6.id6" class="ltx_text ltx_affiliation_postcode">1090</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id25.id1" class="ltx_p">Ethical principles for algorithms are gaining importance as more and more stakeholders are affected by ”high-risk” algorithmic decision-making (ADM) systems. <span id="id25.id1.1" class="ltx_text ltx_font_italic">Understanding</span> how these systems work enables stakeholders to make informed decisions and to assess the systems’ adherence to ethical values. Explanations are a promising way to create understanding, but current explainable artificial intelligence (XAI) research does not always consider existent theories on how understanding is formed and evaluated. In this work, we aim to contribute to a better understanding of understanding by conducting a qualitative task-based study with 30 participants, including users and affected stakeholders. We use three explanation modalities (textual, dialogue, and interactive) to explain a ”high-risk” ADM system to participants and analyse their responses both inductively and deductively, using the ”six facets of understanding” framework by Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>. Our findings indicate that the ”six facets” framework is a promising approach to analyse participants’ thought processes in understanding, providing categories for both rational and emotional understanding. We further introduce the ”dialogue” modality as a valid explanation approach to increase participant engagement and interaction with the ”explainer”, allowing for more insight into their understanding in the process. Our analysis further suggests that individuality in understanding affects participants’ perceptions of algorithmic fairness, demonstrating the interdependence between understanding and ADM assessment that previous studies have outlined. We posit that drawing from theories on learning and understanding like the ”six facets” and leveraging explanation modalities can guide XAI research to better suit explanations to learning processes of individuals and consequently enable their assessment of ethical values of ADM systems.</p>
</div>
<div class="ltx_keywords">XAI, learning Sciences, algorithmic decision-making, algorithmic fairness, qualitative methods
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>2023 ACM Conference on Fairness, Accountability, and Transparency; June 12–15, 2023; Chicago, IL, USA</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’23), June 12–15, 2023, Chicago, IL, USA</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3593013.3594054</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0192-4/23/06</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Field studies</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Motivation</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">”Algorithmic decision-making” (ADM) systems analyse data to derive information used to support or facilitate decisions <cite class="ltx_cite ltx_citemacro_citep">(European Parliament. Directorate General for Parliamentary Research
Services., <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>. As such, they are increasingly used in public institutions and administration and thus affect our daily lives.
Examples include systems for recidivism prediction in criminal justice <cite class="ltx_cite ltx_citemacro_citep">(Chouldechova, <a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>, refugee resettlement advice in immigration policy <cite class="ltx_cite ltx_citemacro_citep">(Bansak et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>, and employability estimation in public employment <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>; Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2020a</a>)</cite>. The EU classifies ADM systems that are used to decide over human individuals as ”high-risk” and proposes to regulate them strictly <cite class="ltx_cite ltx_citemacro_citep">(Veale et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2018</a>; Commission, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, for example by prescribing adherence to standards of ”trustworthy artificial intelligence” (TAI) <cite class="ltx_cite ltx_citemacro_citep">(on Artificial Intelligence, <a href="#bib.bib40" title="" class="ltx_ref">2019</a>)</cite>. These standards state that a system should be, among other criteria, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">transparent</span>, <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">fair</span>, <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">accountable</span>, and have <span id="S1.p1.1.4" class="ltx_text ltx_font_italic">human oversight</span>, in order to be deemed ”trustworthy”. However, two problems pose a challenge in fulfilling these criteria: First, no definition is given of when a system is, for example, transparent or fair, and second, a system <span id="S1.p1.1.5" class="ltx_text ltx_font_italic">can be</span> transparent or fair, without being <span id="S1.p1.1.6" class="ltx_text ltx_font_italic">perceived</span> as such <cite class="ltx_cite ltx_citemacro_citep">(Lee and Baykal, <a href="#bib.bib32" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">How individuals perceive a system’s ethical values depends not only on the system’s characteristics, but also on individual factors, such as personality traits and demographics <cite class="ltx_cite ltx_citemacro_citep">(Shulner-Tal et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>; Pierson, <a href="#bib.bib43" title="" class="ltx_ref">2018</a>)</cite>, as well as on the relation between the individual stakeholder and the ADM system <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>; Jakesch et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>.
Stakeholders that are involved in a systems’ development, deployment, day-to-day usage, or regulation are known to have very different information needs and priorities in assessing ADM systems <cite class="ltx_cite ltx_citemacro_citep">(Jakesch et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>; Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>; Barredo Arrieta et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. For example, while an ADM system can produce benefits for an employer, such as informing employee decisions <cite class="ltx_cite ltx_citemacro_citep">(Bansak et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> and reducing costs <cite class="ltx_cite ltx_citemacro_citep">(Marabelli and Newell, <a href="#bib.bib38" title="" class="ltx_ref">2019</a>)</cite>, the same system can negatively impact stakeholders that are the decision targets by discriminating against certain population groups <cite class="ltx_cite ltx_citemacro_citep">(Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>, thus creating two divergent perspectives.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Explanations can aid different stakeholders in acquiring a basic <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">understanding</span> of ADM systems in order to ”assess” them in terms of ethical values <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>. To this end, numerous studies in Explainable Artificial Intelligence (XAI) examine how people’s understanding of a system can be increased by using e.g., input influence, sensitivity, counterfactuals, case-based, and white box explanations <cite class="ltx_cite ltx_citemacro_citep">(Dodge et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>; Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>; Wang and Yin, <a href="#bib.bib62" title="" class="ltx_ref">2021</a>)</cite>. Further, understanding can be affected by the <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">explanation modality</span>, meaning the presentation of information in e.g., textual, visual, and interactive form <cite class="ltx_cite ltx_citemacro_citep">(Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>. How to create an explanation that will address every stakeholder’s individual information needs, however, remains an open challenge. <cite class="ltx_cite ltx_citemacro_citep">(Shulner-Tal et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>; Dodge et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To acquire a concept of the mental processes involved in understanding, we employ definitions that are established and used in the learning sciences research. Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, by referring to Bloom’s widely-known ”taxonomy of educational objectives” <cite class="ltx_cite ltx_citemacro_citep">(Bloom et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">1956</a>; Anderson and Krathwohl, <a href="#bib.bib5" title="" class="ltx_ref">2001</a>)</cite>, suggest that understanding is essentially <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">transfer</span>: ”to take what we know and use it creatively, flexibly, fluently, in different settings or problems, on our own”. Students can demonstrate their understanding by showing their ability to <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">perform</span> specific things with their knowledge, which Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> describe as the ”six facets of understanding”. Novel explanation methods could benefit significantly from adopting theories such as the ”six facets” framework from the learning sciences in order to better construct and evaluate explanations along existent conceptualisations of understanding and learning. Recent XAI studies already began to leverage different theories of understanding to this end <cite class="ltx_cite ltx_citemacro_citep">(Kawakami et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>; Kaur et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this paper, we follow up on these approaches by investigating how a one-on-one explanation presented in three modalities (textual, dialogue, an interactive) creates understanding in different individuals. To this end, we conducted a task-based qualitative study with 30 participants. We analyse their responses using both inductive and deductive approaches, leveraging the ”six facets of understanding” <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> to examine if participants can <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">explain</span>, <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">interpret</span>, <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">apply</span>, <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">empathise</span>, <span id="S1.p5.1.5" class="ltx_text ltx_font_italic">take perspective</span>, and <span id="S1.p5.1.6" class="ltx_text ltx_font_italic">self-reflect</span> after receiving the explanation. We further provide a practical analysis of the assumption that understanding is a prerequisite for ethical assessment <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>, by relating participants’ ability to discuss the fairness of algorithmic decisions to their understanding. As a case study for high-risk ADM, we use the <span id="S1.p5.1.7" class="ltx_text ltx_font_italic">AMS algorithm</span>– a system that was planned to be deployed in Austria to predict job-seekers’ employability but which was stopped before its actual implementation <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>)</cite>. The <span id="S1.p5.1.8" class="ltx_text ltx_font_italic">AMS algorithm</span> represents a high-risk system that incited public discourse when it was planned <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2020a</a>)</cite> and which generalises to other ADM systems used in ”Public Employment Services” <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> due to the prevalence of individual scoring based on personal attributes.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We are guided by the following research question, including three sub-questions:
<br class="ltx_break"></p>
</div>
<div id="S1.p7" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">How does a ”global” explanation using textual, dialogue, and interactive modality impact participants’ understanding?</span></p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">RQ1: Which ”facets of understanding” emerge in the responses of participants after receiving the explanation?</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">RQ2: How is the explanation modality correlated to understanding?</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">RQ3: To what degree do participants demonstrate the ability to engage in meaningful discourse about the algorithm, for instance in evaluating the algorithms’ fairness with regard to decisions about job-seekers?</p>
</div>
</li>
</ul>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our findings demonstrate that the explanation method chosen for this study successfully gives participants the opportunity to articulate their thought processes that underlie their understanding of the algorithm. To capture and evaluate these thought processes, we highlight the utility of leveraging learning sciences frameworks, such as the ”facets of understanding” <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, to gain insight on participants’ understanding. Pertaining to the study design, we validate the one-on-one explanation and interview setup which allows for the gathering of ”evidence based on response processes” <cite class="ltx_cite ltx_citemacro_citep">(Association et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2014</a>)</cite> and for an ”interactive dialogue” which can ”more fully capture understanding” <cite class="ltx_cite ltx_citemacro_citep">(Sato et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019</a>)</cite>. Lastly, we observe that participants can successfully articulate fairness assessments of the given ADM system after proceeding through the explanation, which however vary in detail and argumentative reasoning depending on participants’ understanding. We thus practically illustrate the link between understanding and assessing a system’s ethical values as posited conceptually in recent XAI studies <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Relevance of algorithmic decision-making</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In this work, we focus on the <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span>, a system that is used for ”algorithmic decision-making” (ADM) i.e., processing data to support or drive decisions in a public institution <cite class="ltx_cite ltx_citemacro_citep">(Veale et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2018</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>; Wang and Yin, <a href="#bib.bib62" title="" class="ltx_ref">2021</a>)</cite>. high-risk ADM systems <cite class="ltx_cite ltx_citemacro_citep">(Commission, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite> are increasingly used throughout all countries and sectors, including the COMPAS<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Correctional Offender Management Profiling for Alternative Sanctions.</span></span></span> model to score defendants’ recidivism probability in US courts <cite class="ltx_cite ltx_citemacro_citep">(Chouldechova, <a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>, the GeoMatch refugee resettlement algorithm <cite class="ltx_cite ltx_citemacro_citep">(Bansak et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>, the Dutch, German, and Austrian classification systems for public employment <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>, and systems to decide on child welfare services <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>. Many of these systems suffer shortcomings, including unreliability of predictions <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>, a lack of transparency <cite class="ltx_cite ltx_citemacro_citep">(de Fine Licht and de Fine Licht, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, missing stakeholder involvement <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>, and biased training data <cite class="ltx_cite ltx_citemacro_citep">(Chouldechova, <a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>, resulting in negative effects on larger parts of the population due to ADM. Current literature further shows that ADM systems rarely comply with standards such as ”trustworthy artificial intelligence” <cite class="ltx_cite ltx_citemacro_citep">(on Artificial Intelligence, <a href="#bib.bib40" title="" class="ltx_ref">2019</a>)</cite> or ”value-based engineering” <cite class="ltx_cite ltx_citemacro_citep">(Spiekermann, <a href="#bib.bib56" title="" class="ltx_ref">2021</a>)</cite> for multiple reasons <cite class="ltx_cite ltx_citemacro_citep">(Madaio et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; de Fine Licht and de Fine Licht, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>; Bell et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Dodge et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>; Balagopalan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>. This is critical since research into the relationship between the use of high-risk ADM systems and societal values suggests that perceptions of such systems as unequal, untrustworthy, or unjust can erode trust in democratic institutions if a large number of people is affected <cite class="ltx_cite ltx_citemacro_citep">(Radavoi, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Hidalgo et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>; Floridi et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>; O’Neil, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>; Hermstrüwer and Langenbach, <a href="#bib.bib23" title="" class="ltx_ref">2022</a>; Binns et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>. Explanations of ADM systems are seen as one of the possible solutions to these problems, as they in theory lead to more transparency and thus more trustworthy systems <cite class="ltx_cite ltx_citemacro_citep">(on Artificial Intelligence, <a href="#bib.bib40" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Stakeholders and explanation design</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">We orient our explanation approach towards the high-level goals of explainable artificial intelligence (XAI), which as a research field is dedicated to ”amend the lack of understanding of AI-based systems” to enable different groups of people to assess whether a system’s output is, e.g., accurate, fair, just, or beneficent <cite class="ltx_cite ltx_citemacro_citep">(Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>; Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. However, the degree of understanding that explanations produce has been shown to vary depending on <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">who</span> the explanation’s recipient is. XAI literature defines individuals involved in the development, deployment, regulation, or use of an ADM system as ”stakeholders”. Stakeholders have different information needs and attitudes depending on their relation to the system <cite class="ltx_cite ltx_citemacro_citep">(Barredo Arrieta et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. For example, a ”deployer” might expect an explanation to tell them whether the system can inform employee decisions <cite class="ltx_cite ltx_citemacro_citep">(Bansak et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> and reduce costs <cite class="ltx_cite ltx_citemacro_citep">(Marabelli and Newell, <a href="#bib.bib38" title="" class="ltx_ref">2019</a>)</cite>, while affected stakeholders might expect to learn if the system discriminates against certain population groups <cite class="ltx_cite ltx_citemacro_citep">(Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">We use three different explanation <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_italic">modalities</span> to present information: textual, dialogue, and interactive modality. In this we are guided by several works that find that explanation modalities can vary in their impact on understanding <cite class="ltx_cite ltx_citemacro_citep">(Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>; Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>. We are further guided by works featuring in-person empirical studies <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>; Peck et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>; Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Lee and Baykal, <a href="#bib.bib32" title="" class="ltx_ref">2017</a>; Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>, as they enable a direct interaction with the participant and, in our case, the introduction of the dialogue explanation modality, in which information is conveyed verbally. A flow chart serves as the basis for all three explanation modalities, as it can depict the complete algorithmic decision-making process <cite class="ltx_cite ltx_citemacro_citep">(Kulesza et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2013</a>)</cite>, including the ”human-in-the-loop”, an individual overseeing the algorithm and an essential factor in many ADM analyses <cite class="ltx_cite ltx_citemacro_citep">(Bell et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Dodge et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>; Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>. Using Speith’s <cite class="ltx_cite ltx_citemacro_citep">(Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite> taxonomy of explanation methods, our explanation flowchart can be described as a both result- and functioning-focused, model-specific explanation with a visual output format that aims to globally explain the whole decision-making process <cite class="ltx_cite ltx_citemacro_citep">(Speith, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>. The three modalities build upon this base form and add information via textual, verbal, and interactive presentation.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Building and assessing understanding</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The purpose of an explanation arguably entails producing understanding in the explanation’s recipient. Many studies discuss and analyse how explanations can influence participants’ understanding <cite class="ltx_cite ltx_citemacro_citep">(Balagopalan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2022</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>; Reader et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Shang et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite>, but what <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">constitutes</span> understanding and how it can be evaluated is not always discussed. Seeing this as preliminary to our discussion, we will provide a brief description of how understanding is discussed in the learning sciences, before introducing Wiggins’ &amp; McTighe’s <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> framework on understanding and outlining the ”six facets of understanding”.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In Anderson’s and Krathwohl’s <cite class="ltx_cite ltx_citemacro_citep">(Anderson and Krathwohl, <a href="#bib.bib5" title="" class="ltx_ref">2001</a>)</cite> revised version of Bloom’s  <cite class="ltx_cite ltx_citemacro_citep">(Bloom et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">1956</a>)</cite> taxonomy of educational objectives, understanding is lined up as one of six categories in the ”cognitive process dimension”, which is counterposed with the ”knowledge dimension” to produce the ”cognitive” taxonomy of learning objectives. Bloom’s original taxonomy was later complemented by the ”affective” and ”psychomotor” domains; this separation however was criticised ”because it isolates aspects of the same objective – and nearly every cognitive objective has an affective component” <cite class="ltx_cite ltx_citemacro_citep">(Anderson and Krathwohl, <a href="#bib.bib5" title="" class="ltx_ref">2001</a>)</cite>. Wiggins and McTighe’s <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> framework is based on the revised taxonomy of educational objectives, but focuses on the process of understanding. In this work, we therefore use the definition of understanding given by <cite class="ltx_cite ltx_citemacro_citet">Wiggins and McTighe (<a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citet">Wiggins and McTighe (<a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, when someone truly understands a topic, they can: a) ”explain”, generalise, and make connections; b) ”interpret”, translate, or make the subject personal through analogies or anecdotes; c) ”apply” or ”do” the subject in different contexts; d) ”take perspectives” on the topic and see the big picture; e) ”empathise” with values that others might find odd and perceive sensitively; and f) ”self-reflect” on their own beliefs and habits that shape and impede understanding <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>. This list of ”understanding facets” aims towards ”transferability” of knowledge <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>. We utilise Wiggins’ &amp; McTighe’s <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> framework for multiple reasons: First, it includes both the cognitive and affective domain, as well as a notion of ”metacognition” <cite class="ltx_cite ltx_citemacro_citep">(Schraw et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2006</a>)</cite> – meaning to reflect on one’s knowledge and understanding. Second, their framework is well applicable to our study design, allowing us to compare our inductive analysis of understanding in participants’ responses with a deductive approach. Third, Kawakami et al. <cite class="ltx_cite ltx_citemacro_citep">(Kawakami et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite> outline a concept of using this framework to produce ”learner-centered” XAI, which we follow up on by transferring the theoretical considerations into an empirical study. Lastly, Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> also provide a categorisation of ”barriers to understanding”, which we adapt to our use case, consisting of: i) forgetting, ii) being unable to use what we learn, and iii) not knowing that we do not understand.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">We further base our one-on-one interview study design on studies from the learning sciences, which posit that ”evidence based on response processes” <cite class="ltx_cite ltx_citemacro_citep">(Association et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2014</a>)</cite> allows us to observe how understanding emerges in the learner’s responses and to distinguish it from knowledge or recall <cite class="ltx_cite ltx_citemacro_citep">(Bransford and Johnson, <a href="#bib.bib13" title="" class="ltx_ref">1972</a>)</cite>. We further include a task in our study design where participants are asked to explain the <span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> in their own words, drawing from Duckworth et al. <cite class="ltx_cite ltx_citemacro_citep">(Duckworth, <a href="#bib.bib20" title="" class="ltx_ref">2001</a>)</cite>, who underline that letting learners explain in their own words provides insight into their understanding.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Analysing perceptions of algorithmic fairness</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Fairness is seen as one of the central criteria for ”trustworthy AI” <cite class="ltx_cite ltx_citemacro_citep">(on Artificial Intelligence, <a href="#bib.bib40" title="" class="ltx_ref">2019</a>)</cite> or ”ethical AI” <cite class="ltx_cite ltx_citemacro_citep">(Floridi et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite>. Similar to other high-level criteria, the meaning of fairness as a moral value shifts depending on who is asked <cite class="ltx_cite ltx_citemacro_citep">(Jakesch et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>; Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Pierson, <a href="#bib.bib43" title="" class="ltx_ref">2018</a>; Shulner-Tal et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite>, and whether it applies to a human or to a machine <cite class="ltx_cite ltx_citemacro_citep">(Starke et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>; Lee and Baykal, <a href="#bib.bib32" title="" class="ltx_ref">2017</a>)</cite>. In this work, we focus on what Langer et al. <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> call the ”epistemic” satisfaction of fairness, meaning that we examine whether participants can engage in discourse about the fairness of the <span id="S2.SS4.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> after receiving our explanation. In contrast, we are <span id="S2.SS4.p1.1.2" class="ltx_text ltx_font_italic">not</span> focussing on the ”substantial” satisfaction of fairness <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, meaning our discussion will not cover whether the <span id="S2.SS4.p1.1.3" class="ltx_text ltx_font_italic">AMS algorithm</span> actually acts fairly or not. We thus use the fairness assessment as an indicator of whether the explanation served to increase participants’ understanding and enabled them to assess the system in ethical terms.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To gain insight into stakeholders’ understanding of ADM, we conducted a task-based qualitative study with 30 participants using three explanation modalities of the <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> (textual, dialogue, and interactive). In the study, an explanation of the algorithm (Section <a href="#S3.SS2.SSS1" title="3.2.1. Explanation modalities ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>) was followed by two tasks (Section <a href="#S3.SS2.SSS2" title="3.2.2. Tasks: predicting employability and explaining the algorithm ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>) and a short interview about the deployment of the algorithm in society. We analyse participants’ responses inductively and deductively, using the ”six facets of understanding” framework <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>. An overview of the study procedure is depicted in <a href="#S3.F3" title="Figure 3 ‣ 3.2.2. Tasks: predicting employability and explaining the algorithm ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>. See Section <a href="#S3.T1" title="Table 1 ‣ 3.4. Participants ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> for the participant sample.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>The algorithm</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In our study, we used the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The abbreviation AMS stands for the Public Employment Agency.</span></span></span> as a prototypical example of an algorithmic decision-making system in Public Employment Services <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>. The algorithm was developed between 2015 and 2021 by a private company for the Public Employment Agency and was piloted for a short time in the autumn of 2018, but was never used as a live system and is currently put on hold due to legal objections <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>)</cite>. The case has been covered by several academic studies and incited public discourse over the benefits and risks of its deployment <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>; Allhutter, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>; Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>; Lopez, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite>.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>An extended discussion of the public discourse and perception of the <span id="footnote3.1" class="ltx_text ltx_font_italic">AMS algorithm</span> is provided in Section A in the supplementary material.</span></span></span> As a great number of people could be affected by the implementation of such a system, and as the stakes generalise well to other high-risk settings, we use the <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">AMS algorithm</span> as a case example for our study.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The algorithm’s predictions and model</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">The <span id="S3.SS1.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> was constructed to assign job-seekers to one out of four categories (”high”, ”medium”, or ”low” employment chances, plus special cases), depending on their personal attributes, such as age, gender, and education. Every prediction would be confirmed or corrected by an employee of the Public Employment Agency. The groups of employability were defined as follows:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">”Medium”: Job-seekers would receive regular support measures<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Such as further training or application coaching.</span></span></span> to improve their chances of finding employment.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">”High”: Job-seekers were expected to find new employment quickly and would receive fewer support measures.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">”Low”: Job-seekers were expected to require more support and would be referred to another facility.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Other: Teenagers, people with disabilities, and people over 50 would receive additional support measures independent of their employability scoring <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.1" class="ltx_p">The algorithm’s model was trained on several years of job-seekers’ data, mainly consisting of personal attributes (features): gender, age, citizenship, education, impairment, obligations of care (only women), occupational group, prior occupations; as well as a representation of the local job market.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Attributes are listed in detail in Section A in the supplementary material.</span></span></span> People with similar personal attributes would be grouped and compared to the ”standard group” <cite class="ltx_cite ltx_citemacro_citep">(Holl et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> – young men with secondary school education – to be assigned a short-term<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>At least 90 days unsupported employment in seven months. Unsupported employment is not subsidised by the Employment Agency.</span></span></span> and long-term<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>At least 180 days unsupported employment in 24 months.</span></span></span> employability score. For further details please refer to the supplementary material and Allhutter et al. <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Biases in the algorithm</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">The weighting of personal features in the algorithm’s classification can be considered biased in that several attributes such as gender and nationality led to decreased employability predictions <cite class="ltx_cite ltx_citemacro_citep">(Holl et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>. However, these biases would in theory lead to higher support measures for job-seekers possessing these attributes, in effect supporting those that were potentially disadvantaged in the job market <cite class="ltx_cite ltx_citemacro_citep">(Holl et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>. Nonetheless, Allhutter et al. <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2020a</a>)</cite> point out how the algorithm’s practical implementation could have detrimental effects on the support and treament that job-seekers would receive. In summary, the <span id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> is an example of how personal and systemic considerations can lead to value conflicts and ethical dilemmas in algorithmic decision-making, which is why we chose it as a suitable example for the study. Explanation and task examples were chosen such that these issues were brought to the participants’ attention, without however preempting any judgement or value statement.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Study setup</h3>

<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Explanation modalities</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">We used a between-subjects study design, showing each participant one of the three distinct explanation modalities (textual, dialogue, interactive) of the <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span>. All modalities built upon a visual flowchart of the algorithmic decision-making pipeline, depicted in <a href="#S3.F1" title="Figure 1 ‣ 3.2.1. Explanation modalities ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Please note that alt-text for Figures 1 and 2 is provided in Section G of the supplementary material.</span></span></span>. In the explanation, the fictional job-seeker <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">Hannah</span> reports to the Employment Agency and is assigned to group ”medium” by the algorithm, which is confirmed by the employee. The modalities, depicted in <a href="#S3.F2" title="Figure 2 ‣ 3.2.1. Explanation modalities ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>, enriched the flowchart with additional information, which was identical between modalities but was presented in different ways<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>For a more detailed description of modalities confer Section C in the supplementary material.</span></span></span>:</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Textual</span>: Textual descriptions were added to the basic flowchart in the form of comments. Participants continued through the explanation slides at their own pace and asked questions at the end.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Dialogue</span>: The study examiner verbally added information to the flowchart, explaining depicted components in each slide. Participants could ask questions throughout the whole process.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p"><span id="S3.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Interactive</span>: The flowchart was implemented as a simple interactive web version that featured buttons which showed textual descriptions when clicked. Participants could ask questions at the end.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">We chose these modalities to achieve multiple aims: First, showing the whole ”global” decision-making process without requiring participants to have technical or specific domain knowledge, following the setups of Wang &amp; Yin <cite class="ltx_cite ltx_citemacro_citep">(Wang and Yin, <a href="#bib.bib62" title="" class="ltx_ref">2021</a>)</cite> and Logg et al. <cite class="ltx_cite ltx_citemacro_citep">(Logg et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>. Second, giving learners the opportunity to close gaps in their understanding by asking questions (”inquiring”) and interacting verbally in the dialogue modality, which can lead to more effective understanding <cite class="ltx_cite ltx_citemacro_citep">(Sato et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019</a>; Robertson et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>; Smith et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2009</a>; Liao et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. Third, examining the contrast between static and interactive interfaces, motivated by Cheng et al. <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>, who found that interactive interfaces led to increased understanding.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2302.08264/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="340" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">The flowchart that every explanation modality built upon. The different parts of the explanation are presented sequentially according to the indicated numbering. ① <span id="S3.F1.3.2.1" class="ltx_text ltx_font_italic">Hannah</span> is a fictional job-seeker reporting to the Employment Agency. ② Some of her personal attributes are recorded for the employability prediction. ③ <span id="S3.F1.3.2.2" class="ltx_text ltx_font_italic">Hannah’s</span> attributes are compared to the ”standard group”: young men with secondary school education. Based on this comparison, the weight and value of <span id="S3.F1.3.2.3" class="ltx_text ltx_font_italic">Hannah</span>’s attributes are calculated. ④ The sum of these values is put into a logistic regression function that maps it to a scale of 0 to 1. Multiplied by 100 this gives the short-term employability chance of <span id="S3.F1.3.2.4" class="ltx_text ltx_font_italic">Hannah</span>. ⑤ The long-term chance is calculated in a similar fashion with a different model. ⑥ According to three simple rules, <span id="S3.F1.3.2.5" class="ltx_text ltx_font_italic">Hannah</span> is assigned to one of three groups, which is then confirmed or corrected by the employee of the agency. ⑦ <span id="S3.F1.3.2.6" class="ltx_text ltx_font_italic">Hannah</span> receives the final decision and group assignment.</span></figcaption>
</figure>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2302.08264/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="304" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">The flowchart split into all three modalities: textual, dialogue, and interactive. Information was added by textual comments, verbal comments, and interactive controls, respectively.</span></figcaption>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Tasks: predicting employability and explaining the algorithm</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Participants had to complete two task sections that were meant to probe their understanding and fairness assessment of the algorithm, as depicted in <a href="#S3.F3" title="Figure 3 ‣ 3.2.2. Tasks: predicting employability and explaining the algorithm ‣ 3.2. Study setup ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Example cases are described in detail in Section D and E in the supplementary material. Cases were taken from a detailed report on the <span id="footnote10.1" class="ltx_text ltx_font_italic">AMS algorithm</span> by Allhutter et al. <cite class="ltx_cite ltx_citemacro_citep">(Allhutter et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020b</a>)</cite>.</span></span></span></p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">In the first task section, participants were presented with three example cases of job-seekers and were asked to (1) propose measures that could help the person find work again and (2) estimate their chances for short-term and long-term employment<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Short-term in the <span id="footnote11.1" class="ltx_text ltx_font_italic">AMS algorithm</span> is defined as being employed at least 90 days in the next seven months, long-term as at least six months in the next two years</span></span></span>. Participants then received the algorithmic decision for the job-seeker and the employee’s decision (accepting or correcting the algorithm’s scoring plus any additional measures), and indicated whether they perceived the (3) algorithmic and (4) human decision as fair.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">The second task section was split into two: In the first sub-task (2.1), participants were provided with a job-seeker case and were asked to explain to the study examiner how the algorithm would handle the case. In the second sub-task (2.2), participants received a case similar to the first one but ranked higher in terms of employability. Participants should then indicate why the two job-seekers were classified differently.<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>The first case was female and had duties of care, while the second was male and did not have duties of care (for further detail see supplementary material).</span></span></span></p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2302.08264/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="171" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Depiction of the study procedure. Participants received a short introduction about the goals and scope of the study, filled out a questionnaire, and then were asked about the possible consequences of implementing the <span id="S3.F3.3.2.1" class="ltx_text ltx_font_italic">AMS algorithm</span>. They then received one of three explanation modalities and were asked about their self-reported understanding. Participants then proceeded through both task sections, were asked again for their self-reported understanding and finally answered several interview questions.</span></figcaption>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Analysis</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">For our thematic analysis, we applied two levels of qualitative coding to the data: inductive analysis in the first pass, and deductive analysis in the second.<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>Both approaches are documented in the supplementary material.</span></span></span></p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">In our first pass, we examined the data for understanding and perceptions of fairness, letting the overarching themes and theory emerge from the data, following Thomas <cite class="ltx_cite ltx_citemacro_citep">(Thomas, <a href="#bib.bib59" title="" class="ltx_ref">2006</a>)</cite>. We created 18 categories capturing different aspects of understanding, such as the level of detail (e.g., whether participants attended more to the technical details or the societal consequences), the connection to personal knowledge and experience, emotional engagement, and instances in which understanding was impeded. We created 18 more categories to capture participants’ perceptions of algorithmic fairness, including statements about the algorithm’s precision, the importance of the human in ADM, and issues of inequality. We then compared statements addressing algorithmic fairness with the four dimensions of algorithmic fairness perceptions by <cite class="ltx_cite ltx_citemacro_citet">Starke et al<span class="ltx_text">.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> to find intersections and create overarching themes.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">In our second pass, we produced six deductive code categories according to the ”six facets of understanding” framework by <cite class="ltx_cite ltx_citemacro_citet">Wiggins and McTighe (<a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, which we split, according to the sub-processes involved in every category, into a total of 21 codes. We analysed the interviews once more using this deductive framework with the aim to examine whether participants’ responses could be mapped to these pre-defined categories and to examine whether the framework captured aspects that our inductive codes missed. We found that while most inductive codes from our first pass could be assigned to one of the ”six facets of understanding”, the framework also introduced additional differentiations that were useful for the analysis, which will be further described in Section <a href="#S4" title="4. Findings ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. A detailed description of both inductive and deductive codes is further included in the supplementary material.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Participants</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In <a href="#S3.T1" title="Table 1 ‣ 3.4. Participants ‣ 3. Methodology ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>, we present a description of the 30 study participants, whom we recruited in four locations: a café near a university, a café in another city district, an auto repair garage, and a local employment agency’s office. We conducted three of the studies online; all others were conducted personally in place. In our recruitment, we aimed for the inclusion of the two stakeholder groups ”users” and ”affected stakeholders”, a balance in terms of age, gender, and occupation, as well as a focus on people with no expert knowledge of algorithms. While of course not representative of the general population, the participant sample allowed us to gather a wide range of perspectives on how the <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> was understood and perceived in terms of fairness.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">As motivated in Section <a href="#S1" title="1. Motivation ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, algorithmic decision-making systems can be detrimental to democracy if their implementation is faulty or unaware of the public’s stance towards the system <cite class="ltx_cite ltx_citemacro_citep">(Radavoi, <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Hidalgo et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>; Floridi et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>; O’Neil, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>; Binns et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>. For this reason, we aimed to conduct the study with a balanced sample of the ”general public”, with the only condition being that participants would optimally not be experts on algorithms. The sample included both employees in the public employment sector and job-seekers, but also individuals of different educational and cultural backgrounds who were not directly affected by public employment. While our sample is not representative, it includes a range of different perspectives on the explanation, which provided a solid reasoning ground for examining the explanation’s effects on understanding.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.6.1.1" class="ltx_text" style="font-size:113%;">Table 1</span>. </span><span id="S3.T1.7.2" class="ltx_text" style="font-size:113%;">Details on the participants of our study. 5 participants were employees of the Public Employment Agency or similar institutions, whom we define as ”domain experts” and who are indicated with a <span id="S3.T1.7.2.1" class="ltx_text ltx_font_italic">d</span> attached to their ID. 5 participants were job-seeking at the time of the study, whom we define as ”affected stakeholders”.</span></figcaption>
<table id="S3.T1.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.8.1.1" class="ltx_tr">
<th id="S3.T1.8.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T1.8.1.1.1.1" class="ltx_text" style="font-size:80%;">ID</span></th>
<th id="S3.T1.8.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T1.8.1.1.2.1" class="ltx_text" style="font-size:80%;">Explanation</span></th>
<th id="S3.T1.8.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T1.8.1.1.3.1" class="ltx_text" style="font-size:80%;">Age</span></th>
<th id="S3.T1.8.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.8.1.1.4.1" class="ltx_text" style="font-size:80%;">Gender</span></th>
<th id="S3.T1.8.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.8.1.1.5.1" class="ltx_text" style="font-size:80%;">Education</span></th>
<th id="S3.T1.8.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.8.1.1.6.1" class="ltx_text" style="font-size:80%;">Occupation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.8.2.1" class="ltx_tr">
<th id="S3.T1.8.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T1.8.2.1.1.1" class="ltx_text" style="font-size:80%;">1</span></th>
<th id="S3.T1.8.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T1.8.2.1.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T1.8.2.1.3.1" class="ltx_text" style="font-size:80%;">32</span></th>
<td id="S3.T1.8.2.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.8.2.1.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.2.1.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.8.2.1.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.2.1.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.8.2.1.6.1" class="ltx_text" style="font-size:80%;">Researcher</span></td>
</tr>
<tr id="S3.T1.8.3.2" class="ltx_tr">
<th id="S3.T1.8.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.3.2.1.1" class="ltx_text" style="font-size:80%;">2</span></th>
<th id="S3.T1.8.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.3.2.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.3.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.3.2.3.1" class="ltx_text" style="font-size:80%;">26</span></th>
<td id="S3.T1.8.3.2.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.3.2.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.3.2.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.3.2.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.3.2.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.3.2.6.1" class="ltx_text" style="font-size:80%;">PhD Student</span></td>
</tr>
<tr id="S3.T1.8.4.3" class="ltx_tr">
<th id="S3.T1.8.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.4.3.1.1" class="ltx_text" style="font-size:80%;">3</span></th>
<th id="S3.T1.8.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.4.3.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.4.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.4.3.3.1" class="ltx_text" style="font-size:80%;">23</span></th>
<td id="S3.T1.8.4.3.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.4.3.4.1" class="ltx_text" style="font-size:80%;">D</span></td>
<td id="S3.T1.8.4.3.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.4.3.5.1" class="ltx_text" style="font-size:80%;">Bachelor</span></td>
<td id="S3.T1.8.4.3.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.4.3.6.1" class="ltx_text" style="font-size:80%;">Master’s student</span></td>
</tr>
<tr id="S3.T1.8.5.4" class="ltx_tr">
<th id="S3.T1.8.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.5.4.1.1" class="ltx_text" style="font-size:80%;">4</span></th>
<th id="S3.T1.8.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.5.4.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.5.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.5.4.3.1" class="ltx_text" style="font-size:80%;">36</span></th>
<td id="S3.T1.8.5.4.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.5.4.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.5.4.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.5.4.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.5.4.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.5.4.6.1" class="ltx_text" style="font-size:80%;">UX Researcher</span></td>
</tr>
<tr id="S3.T1.8.6.5" class="ltx_tr">
<th id="S3.T1.8.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.6.5.1.1" class="ltx_text" style="font-size:80%;">5</span></th>
<th id="S3.T1.8.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.6.5.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.6.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.6.5.3.1" class="ltx_text" style="font-size:80%;">49</span></th>
<td id="S3.T1.8.6.5.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.6.5.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.6.5.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.6.5.5.1" class="ltx_text" style="font-size:80%;">PhD</span></td>
<td id="S3.T1.8.6.5.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.6.5.6.1" class="ltx_text" style="font-size:80%;">Financial Advisor</span></td>
</tr>
<tr id="S3.T1.8.7.6" class="ltx_tr">
<th id="S3.T1.8.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.7.6.1.1" class="ltx_text" style="font-size:80%;">6</span></th>
<th id="S3.T1.8.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.7.6.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.7.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.7.6.3.1" class="ltx_text" style="font-size:80%;">25</span></th>
<td id="S3.T1.8.7.6.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.7.6.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.7.6.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.7.6.5.1" class="ltx_text" style="font-size:80%;">1st state examination</span></td>
<td id="S3.T1.8.7.6.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.7.6.6.1" class="ltx_text" style="font-size:80%;">PhD Student</span></td>
</tr>
<tr id="S3.T1.8.8.7" class="ltx_tr">
<th id="S3.T1.8.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.8.7.1.1" class="ltx_text" style="font-size:80%;">7</span></th>
<th id="S3.T1.8.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.8.7.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.8.7.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.8.7.3.1" class="ltx_text" style="font-size:80%;">47</span></th>
<td id="S3.T1.8.8.7.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.8.7.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.8.7.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.8.7.5.1" class="ltx_text" style="font-size:80%;">Academy</span></td>
<td id="S3.T1.8.8.7.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.8.7.6.1" class="ltx_text" style="font-size:80%;">Leisure pedagogue</span></td>
</tr>
<tr id="S3.T1.8.9.8" class="ltx_tr">
<th id="S3.T1.8.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.9.8.1.1" class="ltx_text" style="font-size:80%;">8d</span></th>
<th id="S3.T1.8.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.9.8.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.9.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.9.8.3.1" class="ltx_text" style="font-size:80%;">41</span></th>
<td id="S3.T1.8.9.8.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.9.8.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.9.8.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.9.8.5.1" class="ltx_text" style="font-size:80%;">Academy</span></td>
<td id="S3.T1.8.9.8.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.9.8.6.1" class="ltx_text" style="font-size:80%;">Social worker</span></td>
</tr>
<tr id="S3.T1.8.10.9" class="ltx_tr">
<th id="S3.T1.8.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.10.9.1.1" class="ltx_text" style="font-size:80%;">9</span></th>
<th id="S3.T1.8.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.10.9.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.10.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.10.9.3.1" class="ltx_text" style="font-size:80%;">26</span></th>
<td id="S3.T1.8.10.9.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.10.9.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.10.9.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.10.9.5.1" class="ltx_text" style="font-size:80%;">Bachelor</span></td>
<td id="S3.T1.8.10.9.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.10.9.6.1" class="ltx_text" style="font-size:80%;">Student</span></td>
</tr>
<tr id="S3.T1.8.11.10" class="ltx_tr">
<th id="S3.T1.8.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.11.10.1.1" class="ltx_text" style="font-size:80%;">10</span></th>
<th id="S3.T1.8.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.11.10.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.11.10.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.11.10.3.1" class="ltx_text" style="font-size:80%;">24</span></th>
<td id="S3.T1.8.11.10.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.11.10.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.11.10.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.11.10.5.1" class="ltx_text" style="font-size:80%;">Apprenticeship</span></td>
<td id="S3.T1.8.11.10.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.11.10.6.1" class="ltx_text" style="font-size:80%;">Car mechanic</span></td>
</tr>
<tr id="S3.T1.8.12.11" class="ltx_tr">
<th id="S3.T1.8.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.12.11.1.1" class="ltx_text" style="font-size:80%;">11</span></th>
<th id="S3.T1.8.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.12.11.2.1" class="ltx_text" style="font-size:80%;">textual</span></th>
<th id="S3.T1.8.12.11.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.12.11.3.1" class="ltx_text" style="font-size:80%;">24</span></th>
<td id="S3.T1.8.12.11.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.12.11.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.12.11.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.12.11.5.1" class="ltx_text" style="font-size:80%;">Apprenticeship</span></td>
<td id="S3.T1.8.12.11.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.12.11.6.1" class="ltx_text" style="font-size:80%;">Car mechanic</span></td>
</tr>
<tr id="S3.T1.8.13.12" class="ltx_tr">
<th id="S3.T1.8.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.13.12.1.1" class="ltx_text" style="font-size:80%;">12</span></th>
<th id="S3.T1.8.13.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.13.12.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.13.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.13.12.3.1" class="ltx_text" style="font-size:80%;">26</span></th>
<td id="S3.T1.8.13.12.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.13.12.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.13.12.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.13.12.5.1" class="ltx_text" style="font-size:80%;">Apprenticeship</span></td>
<td id="S3.T1.8.13.12.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.13.12.6.1" class="ltx_text" style="font-size:80%;">Car mechanic</span></td>
</tr>
<tr id="S3.T1.8.14.13" class="ltx_tr">
<th id="S3.T1.8.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.14.13.1.1" class="ltx_text" style="font-size:80%;">13</span></th>
<th id="S3.T1.8.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.14.13.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.14.13.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.14.13.3.1" class="ltx_text" style="font-size:80%;">58</span></th>
<td id="S3.T1.8.14.13.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.14.13.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.14.13.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.14.13.5.1" class="ltx_text" style="font-size:80%;">Bachelor</span></td>
<td id="S3.T1.8.14.13.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.14.13.6.1" class="ltx_text" style="font-size:80%;">Clerk</span></td>
</tr>
<tr id="S3.T1.8.15.14" class="ltx_tr">
<th id="S3.T1.8.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.15.14.1.1" class="ltx_text" style="font-size:80%;">14</span></th>
<th id="S3.T1.8.15.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.15.14.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.15.14.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.15.14.3.1" class="ltx_text" style="font-size:80%;">69</span></th>
<td id="S3.T1.8.15.14.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.15.14.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.15.14.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.15.14.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.15.14.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.15.14.6.1" class="ltx_text" style="font-size:80%;">Pension</span></td>
</tr>
<tr id="S3.T1.8.16.15" class="ltx_tr">
<th id="S3.T1.8.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.16.15.1.1" class="ltx_text" style="font-size:80%;">15</span></th>
<th id="S3.T1.8.16.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.16.15.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.16.15.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.16.15.3.1" class="ltx_text" style="font-size:80%;">42</span></th>
<td id="S3.T1.8.16.15.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.16.15.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.16.15.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.16.15.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.16.15.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.16.15.6.1" class="ltx_text" style="font-size:80%;">Job-seeking</span></td>
</tr>
<tr id="S3.T1.8.17.16" class="ltx_tr">
<th id="S3.T1.8.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.17.16.1.1" class="ltx_text" style="font-size:80%;">16</span></th>
<th id="S3.T1.8.17.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.17.16.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.17.16.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.17.16.3.1" class="ltx_text" style="font-size:80%;">52</span></th>
<td id="S3.T1.8.17.16.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.17.16.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.17.16.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.17.16.5.1" class="ltx_text" style="font-size:80%;">Apprenticeship</span></td>
<td id="S3.T1.8.17.16.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.17.16.6.1" class="ltx_text" style="font-size:80%;">Job-seeking</span></td>
</tr>
<tr id="S3.T1.8.18.17" class="ltx_tr">
<th id="S3.T1.8.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.18.17.1.1" class="ltx_text" style="font-size:80%;">17</span></th>
<th id="S3.T1.8.18.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.18.17.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.18.17.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.18.17.3.1" class="ltx_text" style="font-size:80%;">51</span></th>
<td id="S3.T1.8.18.17.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.18.17.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.18.17.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.18.17.5.1" class="ltx_text" style="font-size:80%;">Vocational college</span></td>
<td id="S3.T1.8.18.17.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.18.17.6.1" class="ltx_text" style="font-size:80%;">Job-seeking</span></td>
</tr>
<tr id="S3.T1.8.19.18" class="ltx_tr">
<th id="S3.T1.8.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.19.18.1.1" class="ltx_text" style="font-size:80%;">18d</span></th>
<th id="S3.T1.8.19.18.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.19.18.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.19.18.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.19.18.3.1" class="ltx_text" style="font-size:80%;">60</span></th>
<td id="S3.T1.8.19.18.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.19.18.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.19.18.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.19.18.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.19.18.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.19.18.6.1" class="ltx_text" style="font-size:80%;">Application trainer</span></td>
</tr>
<tr id="S3.T1.8.20.19" class="ltx_tr">
<th id="S3.T1.8.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.20.19.1.1" class="ltx_text" style="font-size:80%;">19d</span></th>
<th id="S3.T1.8.20.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.20.19.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.20.19.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.20.19.3.1" class="ltx_text" style="font-size:80%;">57</span></th>
<td id="S3.T1.8.20.19.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.20.19.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.20.19.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.20.19.5.1" class="ltx_text" style="font-size:80%;">A level</span></td>
<td id="S3.T1.8.20.19.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.20.19.6.1" class="ltx_text" style="font-size:80%;">Personnel consultant</span></td>
</tr>
<tr id="S3.T1.8.21.20" class="ltx_tr">
<th id="S3.T1.8.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.21.20.1.1" class="ltx_text" style="font-size:80%;">20d</span></th>
<th id="S3.T1.8.21.20.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.21.20.2.1" class="ltx_text" style="font-size:80%;">dialogue</span></th>
<th id="S3.T1.8.21.20.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.21.20.3.1" class="ltx_text" style="font-size:80%;">55</span></th>
<td id="S3.T1.8.21.20.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.21.20.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.21.20.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.21.20.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.21.20.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.21.20.6.1" class="ltx_text" style="font-size:80%;">Personnel consultant</span></td>
</tr>
<tr id="S3.T1.8.22.21" class="ltx_tr">
<th id="S3.T1.8.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.22.21.1.1" class="ltx_text" style="font-size:80%;">21</span></th>
<th id="S3.T1.8.22.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.22.21.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.22.21.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.22.21.3.1" class="ltx_text" style="font-size:80%;">28</span></th>
<td id="S3.T1.8.22.21.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.22.21.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.22.21.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.22.21.5.1" class="ltx_text" style="font-size:80%;">Bachelor</span></td>
<td id="S3.T1.8.22.21.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.22.21.6.1" class="ltx_text" style="font-size:80%;">Student</span></td>
</tr>
<tr id="S3.T1.8.23.22" class="ltx_tr">
<th id="S3.T1.8.23.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.23.22.1.1" class="ltx_text" style="font-size:80%;">22</span></th>
<th id="S3.T1.8.23.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.23.22.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.23.22.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.23.22.3.1" class="ltx_text" style="font-size:80%;">23</span></th>
<td id="S3.T1.8.23.22.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.23.22.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.23.22.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.23.22.5.1" class="ltx_text" style="font-size:80%;">A level</span></td>
<td id="S3.T1.8.23.22.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.23.22.6.1" class="ltx_text" style="font-size:80%;">Student</span></td>
</tr>
<tr id="S3.T1.8.24.23" class="ltx_tr">
<th id="S3.T1.8.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.24.23.1.1" class="ltx_text" style="font-size:80%;">23</span></th>
<th id="S3.T1.8.24.23.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.24.23.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.24.23.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.24.23.3.1" class="ltx_text" style="font-size:80%;">37</span></th>
<td id="S3.T1.8.24.23.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.24.23.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.24.23.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.24.23.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.24.23.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.24.23.6.1" class="ltx_text" style="font-size:80%;">Employed</span></td>
</tr>
<tr id="S3.T1.8.25.24" class="ltx_tr">
<th id="S3.T1.8.25.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.25.24.1.1" class="ltx_text" style="font-size:80%;">24d</span></th>
<th id="S3.T1.8.25.24.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.25.24.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.25.24.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.25.24.3.1" class="ltx_text" style="font-size:80%;">48</span></th>
<td id="S3.T1.8.25.24.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.25.24.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.25.24.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.25.24.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.25.24.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.25.24.6.1" class="ltx_text" style="font-size:80%;">Trainer</span></td>
</tr>
<tr id="S3.T1.8.26.25" class="ltx_tr">
<th id="S3.T1.8.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.26.25.1.1" class="ltx_text" style="font-size:80%;">25</span></th>
<th id="S3.T1.8.26.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.26.25.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.26.25.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.26.25.3.1" class="ltx_text" style="font-size:80%;">26</span></th>
<td id="S3.T1.8.26.25.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.26.25.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.26.25.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.26.25.5.1" class="ltx_text" style="font-size:80%;">Apprenticeship</span></td>
<td id="S3.T1.8.26.25.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.26.25.6.1" class="ltx_text" style="font-size:80%;">Short-term worker</span></td>
</tr>
<tr id="S3.T1.8.27.26" class="ltx_tr">
<th id="S3.T1.8.27.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.27.26.1.1" class="ltx_text" style="font-size:80%;">26</span></th>
<th id="S3.T1.8.27.26.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.27.26.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.27.26.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.27.26.3.1" class="ltx_text" style="font-size:80%;">60</span></th>
<td id="S3.T1.8.27.26.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.27.26.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.27.26.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.27.26.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.27.26.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.27.26.6.1" class="ltx_text" style="font-size:80%;">Job-seeking</span></td>
</tr>
<tr id="S3.T1.8.28.27" class="ltx_tr">
<th id="S3.T1.8.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.28.27.1.1" class="ltx_text" style="font-size:80%;">27</span></th>
<th id="S3.T1.8.28.27.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.28.27.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.28.27.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.28.27.3.1" class="ltx_text" style="font-size:80%;">35</span></th>
<td id="S3.T1.8.28.27.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.28.27.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.28.27.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.28.27.5.1" class="ltx_text" style="font-size:80%;">University</span></td>
<td id="S3.T1.8.28.27.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.28.27.6.1" class="ltx_text" style="font-size:80%;">Self-employed</span></td>
</tr>
<tr id="S3.T1.8.29.28" class="ltx_tr">
<th id="S3.T1.8.29.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.29.28.1.1" class="ltx_text" style="font-size:80%;">28</span></th>
<th id="S3.T1.8.29.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.29.28.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.29.28.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.29.28.3.1" class="ltx_text" style="font-size:80%;">27</span></th>
<td id="S3.T1.8.29.28.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.29.28.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.29.28.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.29.28.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.29.28.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.29.28.6.1" class="ltx_text" style="font-size:80%;">Journalist</span></td>
</tr>
<tr id="S3.T1.8.30.29" class="ltx_tr">
<th id="S3.T1.8.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.30.29.1.1" class="ltx_text" style="font-size:80%;">29</span></th>
<th id="S3.T1.8.30.29.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.30.29.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.30.29.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.8.30.29.3.1" class="ltx_text" style="font-size:80%;">29</span></th>
<td id="S3.T1.8.30.29.4" class="ltx_td ltx_align_left"><span id="S3.T1.8.30.29.4.1" class="ltx_text" style="font-size:80%;">F</span></td>
<td id="S3.T1.8.30.29.5" class="ltx_td ltx_align_left"><span id="S3.T1.8.30.29.5.1" class="ltx_text" style="font-size:80%;">Master</span></td>
<td id="S3.T1.8.30.29.6" class="ltx_td ltx_align_left"><span id="S3.T1.8.30.29.6.1" class="ltx_text" style="font-size:80%;">Consultant</span></td>
</tr>
<tr id="S3.T1.8.31.30" class="ltx_tr">
<th id="S3.T1.8.31.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="S3.T1.8.31.30.1.1" class="ltx_text" style="font-size:80%;">30</span></th>
<th id="S3.T1.8.31.30.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="S3.T1.8.31.30.2.1" class="ltx_text" style="font-size:80%;">interactive</span></th>
<th id="S3.T1.8.31.30.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="S3.T1.8.31.30.3.1" class="ltx_text" style="font-size:80%;">31</span></th>
<td id="S3.T1.8.31.30.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T1.8.31.30.4.1" class="ltx_text" style="font-size:80%;">M</span></td>
<td id="S3.T1.8.31.30.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T1.8.31.30.5.1" class="ltx_text" style="font-size:80%;">Bachelor</span></td>
<td id="S3.T1.8.31.30.6" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T1.8.31.30.6.1" class="ltx_text" style="font-size:80%;">Consultant</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Findings</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present the findings from our study, structured according to our RQs covering the following topics: understanding (Section <a href="#S4.SS1" title="4.1. Which ”facets of understanding” emerge in the responses of participants after receiving the explanation? (RQ1) ‣ 4. Findings ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), the effect of explanation modality (Section <a href="#S4.SS2" title="4.2. Which, if any, correlation to the explanation modality can be seen in the understanding facets? (RQ2) ‣ 4. Findings ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>), and enabling the ethical assessment of ADM (Section <a href="#S4.SS3" title="4.3. Do participants demonstrate the ability to engage in meaningful discourse about the algorithm, for instance in evaluating the algorithms’ fairness with regard to decisions about job-seekers? (RQ3) ‣ 4. Findings ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>Please note that some participant responses touch on sensitive topics, such as discrimination and self-harm.</span></span></span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Which ”facets of understanding” emerge in the responses of participants after receiving the explanation? (RQ1)</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>”Emotional” and ”analytical” facets of understanding:</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">Participants’ understanding of the explanation surfaced in different ways. The framework of Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> contains both ”analytical” (explain, apply, take perspective) and ”emotional” (interpret, empathise, self-reflect) facets of understanding. Participants tended to show facets of either one of the two sides, and the degree to which they felt personally affected by the algorithm made a difference in which facets they were most likely to use.
For example, participants who were looking for employment at the time of the study rather responded to the question of whether the <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> should be used to score job-seekers with the facet ”empathise”:</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p2.1" class="ltx_quote">
<p id="S4.SS1.SSS1.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p2.1.1.1" class="ltx_text ltx_font_italic">These are just numbers, you don’t know the background of why they lost the job. It’s not fair because it’s just a program and the human side is completely gone.</span> (P17)</p>
</blockquote>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p">In contrast, participants who never had contact with the Public Employment Agency and did not know anyone who was officially unemployed responded to the same question rather by critically ”taking perspective” on the algorithm’s application:</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<blockquote id="S4.SS1.SSS1.p4.1" class="ltx_quote">
<p id="S4.SS1.SSS1.p4.1.1" class="ltx_p"><span id="S4.SS1.SSS1.p4.1.1.1" class="ltx_text ltx_font_italic">I think it’s good as a recommendation. I think it turns into a procedure that is otherwise purely a human decision and provides a percentage probability, though I wouldn’t use it on its own. I think it’s good because the case worker has something to go by, but for some examples, it’s not complex enough, that’s what the human case worker is for.</span> (P6)</p>
</blockquote>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Relating to the information in more than one way indicates higher understanding</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">According to Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, successful understanding must show <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">all</span> of the six facets: ”explain,” ”interpret,” ”apply,” ”empathise,” ”take perspective,” and ”self-reflect.” While no participant used all six facets, we observe that several participants combined up to four facets in a single answer. In the following quote, the participant ”explains” the current labour market situation, ”interprets” what this would mean for the job-seeker, and as a result ”takes perspective” by critically questioning the algorithm’s employability scoring:</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS2.p2.1" class="ltx_quote">
<p id="S4.SS1.SSS2.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS2.p2.1.1.1" class="ltx_text ltx_font_italic">I disagree with the algorithm in this case because now there are shortages of employees in specific sectors like catering. So employers are forced to bend their requirements and will have a positive attitude towards applications from people such as Harald. He has a lot of experience, and he is motivated, so they will disregard his age, which would be bad in normal circumstances.</span> (P23)</p>
</blockquote>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<p id="S4.SS1.SSS2.p3.1" class="ltx_p">Notably, neither stakeholder group, demographic background, nor prior knowledge seemed to affect if someone would show the ability to use multiple facets of understanding to make sense of the algorithm. This stands in contrast to previous studies, which found that measurable understanding increases with domain expertise <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>; Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite> and the level of education<cite class="ltx_cite ltx_citemacro_citep">(Shulner-Tal et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>High understanding co-occurs with self-reflection</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Participants that used multiple facets of understanding and thus showed a higher understanding were able to give comprehensive answers to the tasks and often supplemented their responses by reflecting on their own understanding, beliefs, or circumstances. This occurred, for example, in response to the idea of being classified by the <span id="S4.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span>:</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS3.p2.1" class="ltx_quote">
<p id="S4.SS1.SSS3.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS3.p2.1.1.1" class="ltx_text ltx_font_italic">In my case it would not be a disadvantage, because I am privileged in terms of education and I have no care obligations. […] But if I were less privileged I wouldn’t want that and if I had support needs I wouldn’t want that either.</span> (P1)</p>
</blockquote>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">Reflections tended to occur at a ”turning point” of the interview, consisting of a question asking if the algorithm should be used on everyone, followed by a question asking if it should be used in the participant’s own case. Often when participants responded to these questions disparately, for example by voting against the general usage, but agreeing to the usage on themselves, they felt inclined to reflect on their understanding and their beliefs without being prompted.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Barriers to understanding</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> define three cognitive processes that can hamper understanding and learning: i) forgetting, ii) being unable to use what we learn, and iii) not knowing that we do not understand. Forgetting was an issue distributed throughout the participant sample, as participants could not refer back to the explanation while proceeding through the tasks. Notably, participants with lower levels of education encountered more issues of forgetting and were not always able to apply the learned information, which found its expression in incorrect recollections of the explanation and less emergence of understanding facets:</p>
</div>
<div id="S4.SS1.SSS4.p2" class="ltx_para">
<blockquote id="S4.SS1.SSS4.p2.1" class="ltx_quote">
<p id="S4.SS1.SSS4.p2.1.1" class="ltx_p"><span id="S4.SS1.SSS4.p2.1.1.1" class="ltx_text ltx_font_italic">I didn’t understand the conversion, I don’t know the formula. Otherwise, I halfway understood it, they simply take the data and… I don’t know how to explain it.</span> (P10)</p>
</blockquote>
</div>
<div id="S4.SS1.SSS4.p3" class="ltx_para">
<p id="S4.SS1.SSS4.p3.1" class="ltx_p">In contrast, we did not find many instances of a participant not realising their lack of understanding. This, however, is more likely due to the difficulty of distinguishing it from the inability to apply knowledge. Finding a way to better identify this barrier to understanding could be a topic for future work.</p>
</div>
</section>
<section id="S4.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.5. </span>Facets not covered by the framework</h4>

<div id="S4.SS1.SSS5.p1" class="ltx_para">
<p id="S4.SS1.SSS5.p1.1" class="ltx_p">The comparison between inductive and deductive thematic analysis shows that while most inductive themes of understanding could be mapped to the theoretical framework of Wiggins &amp; McTighe <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, we also identified themes that the framework did not include. First, the ”six facets of understanding” do not provide a clear categorisation of expressions that reflect a strong value statement, such as ”I believe that algorithms actually have no place in this field.” (P18d). The closest match is the facet ”interpret,” which however aims more towards making the topic ”personal or accessible through images, anecdotes,
analogies” <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>, and less towards value statements. It is debatable whether these statements bear evidence for understanding, but seeing that Langer et al. <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> describe value statements as an indicator for stakeholder understanding needs, this lack of categorisation stood out.</p>
</div>
<div id="S4.SS1.SSS5.p2" class="ltx_para">
<p id="S4.SS1.SSS5.p2.1" class="ltx_p">Second, our application of the framework does not allow us to distinguish between different domains of knowledge, which in our analysis sometimes blurred the lines between understanding the algorithm and understanding the public employment system. A clearer distinction between the subjects of understanding would be useful for future analyses.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Which, if any, correlation to the explanation modality can be seen in the understanding facets? (RQ2)</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The different modalities of how the explanation was presented (textual, dialogue, and interactive) had a limited effect on the emergence of specific understanding facets. However, we point out two findings related to the textual and dialogue explanation modality.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Textual modality leads to understanding barriers</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">The ”textual” modality group showed more and deeper barriers to understanding than other groups. Several participants commented on the amount of text in the explanation and their learning process:</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<blockquote id="S4.SS2.SSS1.p2.1" class="ltx_quote">
<p id="S4.SS2.SSS1.p2.1.1" class="ltx_p"><span id="S4.SS2.SSS1.p2.1.1.1" class="ltx_text ltx_font_italic">I have to be honest, I find it easier when someone explains something to me. Then I can also ask until I get it. It is hard for me to understand something like that just by reading it.</span> (P10)</p>
</blockquote>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">In contrast, participants expressed their satisfaction both with the dialogue and interactive modality, praising the option to ask questions and the engagement with the explanation. Of all 20 participants in the dialogue and interactive modality groups, only one stated that they would have rather liked a textual explanation.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Dialogue modality leads to increased expression of some understanding facets</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">Compared to the textual and interactive modality, the dialogue explanation showed an overall increase in the number of words spoken by participants and more usage of the facets ”interpret”, ”empathise”, and ”self-reflect”. Factual questions by participants mostly served the purpose of confirming information that was already present in the flowchart (e.g., ”<span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">So, having studied actually has the largest effect on your score?</span>” (P13)). In contrast, questions that pertained to personal concerns or systemic issues often touched on the ”emotional” facets of understanding (e.g., ”<span id="S4.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Do women automatically get less points? Where does discrimination begin, where does it end? (P15)</span>”). These questions were not answered in detail during the explanation, but instead served as points of entry to the later interview. The dialogue modality might have thus helped to later start the in-depth conversation about the algorithm by introducing a verbal interaction directly at the beginning and giving participants more opportunities to correct their understanding. Other possible reasons for these findings will be discussed in Section <a href="#S5" title="5. Discussion ‣ On the Impact of Explanations on Understanding of Algorithmic Decision-Making" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Do participants demonstrate the ability to engage in meaningful discourse about the algorithm, for instance in evaluating the algorithms’ fairness with regard to decisions about job-seekers? (RQ3)</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">After each case example in task section 1, participants were asked to assess and discuss the fairness of both the algorithmic and human decisions regarding the case. We used these fairness assessments as a form of proxy for their ability to engage in discourse about the algorithm’s ethical dimensions. We find that all participants were able to articulate a basic fairness assessment, but that their statements differed strongly in detail and argumentative reasoning.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Participants demonstrate the ability to individually assess algorithmic fairness</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">The ”epistemic” satisfaction of a trustworthy AI criterion means that people are able to assess on their own grounds whether a system fulfills a certain ethical criterion, such as being fair or not <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. This does not mean that the system <span id="S4.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">is</span> fair, only that people are able to <span id="S4.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_italic">discuss</span> it. Participants fulfilled this ”epistemic” criterion as they showed a rich and diverse range of fairness assessments of the <span id="S4.SS3.SSS1.p1.1.3" class="ltx_text ltx_font_italic">AMS algorithm</span>, including topics such as the influence of the ”human-in-the-loop”, the perceived gender inequality, the perception of ”algorithmic objectivity” and, in parallel to findings from Scott et al. <cite class="ltx_cite ltx_citemacro_citep">(Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>, the importance of using the system for ”orientation purposes, not to deny access to resources”.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">We further observe that the fairness assessments changed depending on whether participants made more use of analytical or emotional facets of understanding, as evident in these responses to the algorithm predicting ”low” employability for a job-seeker:</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<blockquote id="S4.SS3.SSS1.p3.1" class="ltx_quote">
<p id="S4.SS3.SSS1.p3.1.1" class="ltx_p"><span id="S4.SS3.SSS1.p3.1.1.1" class="ltx_text ltx_font_italic">I see him almost like me. He’s 49, so for me, he would already count as 50+ and should get extra support. […] 
<br class="ltx_break">I find the algorithm good and the human decision bad, because it goes by numbers and is not accommodating. The algorithm just sees 49 and makes the decision.</span> (P17)</p>
</blockquote>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<blockquote id="S4.SS3.SSS1.p4.1" class="ltx_quote">
<p id="S4.SS3.SSS1.p4.1.1" class="ltx_p"><span id="S4.SS3.SSS1.p4.1.1.1" class="ltx_text ltx_font_italic">I understand why the algorithm says Group ”Low” in this case. If he retrains and can explain his career well, I think he could find work, but needs support to do so. […] Personally, I would perhaps not rate him that way, but I think it’s good that he gets into the group.</span> (P6)</p>
</blockquote>
</div>
<div id="S4.SS3.SSS1.p5" class="ltx_para">
<p id="S4.SS3.SSS1.p5.1" class="ltx_p">The first participant relates the decision to his own personal circumstances and speaks about the difference between human and algorithmic decision-making, while the second takes a more analytical approach in speaking about the consequences of the decision to justify his assessment. Despite their different reasons, both participants were able to argue why they agreed with the algorithm, thus fulfilling the ”epistemic” criterion <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. At the same time, this case exemplifies that individuality in understanding also leads to individuality in the fairness assessment.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Understanding barriers lead to less nuanced fairness assessments</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">As expected, participants who encountered more understanding barriers assessed the algorithm’s fairness in much less detail. Often, some form of blanket statement was used that addressed neither dimensions of fairness nor facets of understanding:</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<blockquote id="S4.SS3.SSS2.p2.1" class="ltx_quote">
<p id="S4.SS3.SSS2.p2.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p2.1.1.1" class="ltx_text ltx_font_italic">I think the algorithmic classification is fair, because I was of the same opinion.</span> (P10)</p>
</blockquote>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">The difference to more detailed fairness assessments becomes apparent when we compare this to statements from participants with the same demographics, mostly similar education, but a different explanation modality and largely no barriers to understanding:</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<blockquote id="S4.SS3.SSS2.p4.1" class="ltx_quote">
<p id="S4.SS3.SSS2.p4.1.1" class="ltx_p"><span id="S4.SS3.SSS2.p4.1.1.1" class="ltx_text ltx_font_italic">I’ll try to leave out the current situation in the labour market. I mean, he has his problems. I understand that the chance is low, but this is too low, the algorithm and especially the employee are not fair. Perhaps the employee is new and has no experience in how to place people in the labour market.</span> (P12)</p>
</blockquote>
</div>
<div id="S4.SS3.SSS2.p5" class="ltx_para">
<p id="S4.SS3.SSS2.p5.1" class="ltx_p">The latter statement shows three different facets of understanding while the participant reasons about the fairness assessment: taking a critical perspective on the algorithm, reflecting on the particularities of the post-COVID labour market, and including the perspective of the employee.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Unwillingness to engage in discourse about the algorithm’s fairness</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">Besides understanding barriers, the most common reason for a lack of fairness assessments was a general objection to assessing the system as ”fair” or ”unfair”. These objections were often accompanied by the (flawed) argument that an ”objective” algorithm was not able to act fairly or unfairly:</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<blockquote id="S4.SS3.SSS3.p2.1" class="ltx_quote">
<p id="S4.SS3.SSS3.p2.1.1" class="ltx_p"><span id="S4.SS3.SSS3.p2.1.1.1" class="ltx_text ltx_font_italic">What does fair mean? I can understand the algorithmic decision. Fair is such a strong moral word, I don’t find it immoral, I rather find it ”justified”, ”understandable”, ”realistic”.</span> (P29)</p>
</blockquote>
</div>
<div id="S4.SS3.SSS3.p3" class="ltx_para">
<p id="S4.SS3.SSS3.p3.1" class="ltx_p">Similar responses were given when participants were prompted to rate the algorithm as ”just”, ”legitimate”, ”social”, ”biased”, and ”democratic”. Several participants commented on the close meaning between words, which points to the need of differentiating concepts when asking for complex moral value judgements.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we discuss our findings with regard to the research questions and suggest directions for designing explanations that create increased understanding in different stakeholders and enable the ethical assessment of ADM.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Designing explanations to address all six facets of understanding</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The ”understanding by design” framework <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> states that the primary objectives in creating understanding are to convey a topic’s central ideas, address all ”facets” of understanding, and uncover misunderstandings. Applying the framework to our explanation setup allowed us to gather insights into the participants’ mental processes involved in understanding, i.e., which facets emerged for which participant and how many facets emerged simultaneously.
In particular, we want to highlight that participants showed ”emotional” understanding facets, such as ”empathise” and ”interpret”, which are not always addressed in ADM explanations, despite their known importance in human perception of ADM systems <cite class="ltx_cite ltx_citemacro_citep">(Woodruff et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2018</a>; Scott et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022</a>; Lee and Baykal, <a href="#bib.bib32" title="" class="ltx_ref">2017</a>)</cite>. The facet ”self-reflect” is another valuable dimension that could improve future explanations, as several studies suggest that ”metacognition”, in the form of reflecting on one’s knowledge and understanding, is a ”most powerful predictor of learning” <cite class="ltx_cite ltx_citemacro_citep">(Veenman et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2006</a>; Schraw et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2006</a>)</cite>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Theories on learning and understanding like the ”six facets” <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> can thus guide explanation design by identifying distinct learning goals and by outlining mental processes that support understanding. We chose Wiggins’ &amp; McTighes’ <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> framework due to the practical interpretation of understanding and the well-established theoretical foundation in Bloom’s taxonomy <cite class="ltx_cite ltx_citemacro_citep">(Bloom et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">1956</a>; Anderson and Krathwohl, <a href="#bib.bib5" title="" class="ltx_ref">2001</a>)</cite>. Other promising sources for future studies include the concept of ”responsive teaching” <cite class="ltx_cite ltx_citemacro_citep">(Robertson et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite>, ”knowledge building and knowledge creation” <cite class="ltx_cite ltx_citemacro_citep">(Scardamalia and Bereiter, <a href="#bib.bib48" title="" class="ltx_ref">2014</a>)</cite>, and ”sensemaking theory” <cite class="ltx_cite ltx_citemacro_citep">(Weick et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2005</a>)</cite>. We posit that drawing from these theories in the design and development of explanations can guide research to better support ”humans in learning about particular AI systems and how to work with or around
them” <cite class="ltx_cite ltx_citemacro_citep">(Kawakami et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Effect of explanation modality on understanding</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Our findings suggest that the textual and dialogue modality had the most effect on understanding. The textual modality led to less emergence of understanding facets for several participants, some of whom stated that they did not usually rely on text to learn information. Compared to Szymanski et al. <cite class="ltx_cite ltx_citemacro_citep">(Szymanski et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>)</cite>, where participants disliked textual information but actually performed better using them, participants in our case did not show any advantages in understanding after receiving the textual explanation.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The dialogue modality, in contrast, led to an overall increase in observed facets of understanding, which could have multiple reasons: i) the higher amount of words spoken, ii) the option to ask questions during the explanation, and iii) the additional personal interaction. Although the dialogue modality in theory allowed for a higher amount of factual input, participants seldom chose to ask more than four or five brief factual questions, which mostly pertained to secondary details of the algorithm (e.g., the weighting of certain features) and in terms of information differed little from the textual modality. At the same time, several participants used the dialogue modality to express their opinions and attitudes towards specific information and to ask more profound questions about e.g., the intention behind the algorithm’s deployment and the selection of the ”standard group”. The dialogue modality might thus serve as a conversational ice-breaker due to the direct interaction between ”explainer” and participant, encouraging participants to share their own thoughts and, in turn, increase their understanding. This also connects to findings from Miller <cite class="ltx_cite ltx_citemacro_citep">(Miller, <a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>, who states that explanations between humans are ”social” and ”presented as part of a conversation.” This is striking considering that verbal or dialogue explanations are seldom used in contemporary XAI research. Our findings establish this explanation modality as a valid alternative to be explored in future ADM explanations.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Enabling participants to engage in discourse about the algorithm’s ethical values</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We used the fairness assessment of the <span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_italic">AMS algorithm</span> as a form of proxy to observe whether people are able to articulate value assessments after receiving the explanation. We find that i) the explanation provided most participants with the necessary information to form a detailed fairness assessment, and thus enabled them to successfully engage in discourse about the algorithm’s ethical values, and ii) in contrast to other participants, domain experts were able to discuss the algorithm’s implementation even before the explanation, stating that they had come in contact with automated tools.
On the other hand, participants who showed barriers to understanding articulated less nuanced fairness assessments. Further, some participants stated that an algorithm simply could not be judged in terms of fairness, despite showing multiple facets of understanding in their responses. This means that understanding the system might not be the only prerequisite for stakeholders to make a value assessment, but that understanding what specific ethical values mean when being applied to the system might be just as important. Future explanations should thus consider adding an explanation of the ethical values or finding stand-ins that convey the core of the value in a more accessible manner.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Limitations</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">In this section, we touch on four limitations of our study. First, our assessment of understanding relied largely on qualitative analysis of participants’ responses, which were self-reported and thus might limit objectivity. For future studies, we therefore consider including a quantitative evaluation of understanding. Second, some inductive codes such as strong value statements were not covered in the ”six facets” framework <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite>. Seeing that value statements can ”serve as an orientation for when stakeholders are more likely to demand higher degrees of understanding” <cite class="ltx_cite ltx_citemacro_citep">(Langer et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, future analyses should consider including a facet covering these forms of statements. Third, the study design relied on memorisation of information, as no reference was given to participants while proceeding through the tasks. While this impacted some participants, it also highlighted a difference in memorability of the textual, dialogue, and interactive modality. To offset over-reliance on recall, we consider providing participants with a way to review the explanation in future studies. Lastly, we noticed a bias towards higher education in our participant sample, with 22 participants having a university degree. However, we aimed to collect different perspectives by speaking to employees from the local employment agency, job-seekers and individuals with different educational backgrounds.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we inductively and deductively analyse participants’ understanding of an algorithmic decision-making system after they received one of three explanation modalities (textual, dialogue, and interactive). We find that all of the six ”facets of understanding” <cite class="ltx_cite ltx_citemacro_citep">(Wiggins and McTighe, <a href="#bib.bib64" title="" class="ltx_ref">2005</a>)</cite> (explain, interpret, apply, empathise, take perspective, self-reflect) emerge in participant responses throughout the study, with some participants expressing high understanding by combining multiple facets at once. We argue that incorporating theories from the learning sciences can significantly improve the design of ADM explanations by adapting them to the underlying thought processes of learning and understanding in individuals.
We further highlight the ”dialogue” explanation modality as a valid alternative to convey information and gather in-depth insights on how participants understand and contextualise explanations. Lastly, while we observe that most participants are able to articulate a fairness assessment of the explained ADM system and that a more pronounced understanding supports this articulation, it also becomes evident that participants have general difficulties considering the meaning of ”fairness” in the context of algorithmic systems. We posit that letting stakeholders independently assess algorithmic systems in terms of ethical values such as fairness, accountability, or transparency, could require an additional explanation of how to apply these values in an algorithmic context, in addition to increasing stakeholders’ understanding of the algorithm itself.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work has been funded by the Vienna Science and Technology Fund (WWTF) [10.47379/ICT20058] as well as [10.47379/ICT20065].

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allhutter (2021)</span>
<span class="ltx_bibblock">
Doris Allhutter.
2021.

</span>
<span class="ltx_bibblock">Ein Algorithmus zur effizienten Förderung der
Chancen auf dem Arbeitsmarkt?

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">WISO – Zeitschrift für Sozial- und
Wirtschaftswissenschaften</em> 44.JG (2021),
82–95.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allhutter et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Doris Allhutter, Florian
Cech, Fabian Fischer, Gabriel Grill,
and Astrid Mager. 2020a.

</span>
<span class="ltx_bibblock">Algorithmic Profiling of Job Seekers in Austria:
How Austerity Politics Are Made Effective.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Frontiers in Big Data</em> 3
(2020).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.3389/fdata.2020.00005" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3389/fdata.2020.00005</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allhutter et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Doris Allhutter, Astrid
Mager, Florian Cech, Fabian Fischer,
and Gabriel Grill. 2020b.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">DER AMS-ALGORITHMUS: Eine
Soziotechnische Analyse des Arbeitsmarktchancen-Assistenz-Systems
(AMAS)</em>.

</span>
<span class="ltx_bibblock">Technical Report.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://epub.oeaw.ac.at/0xc1aa5576_0x003bfdf3.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://epub.oeaw.ac.at/0xc1aa5576_0x003bfdf3.pdf</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anderson and Krathwohl (2001)</span>
<span class="ltx_bibblock">
Lorin W. Anderson and
David R. Krathwohl (Eds.).
2001.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">A taxonomy for learning, teaching, and
assessing: a revision of Bloom’s taxonomy of educational objectives</em>
(complete ed ed.).

</span>
<span class="ltx_bibblock">Longman, New York.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Association et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
American Educational Research Association,
American Psychological Association, and
National Council on Measurementin Education (Eds.).
2014.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">2014 - Standards for education and
psychological testing</em>.

</span>
<span class="ltx_bibblock">American Educational Research Association,
Washington, D.C.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">OCLC: ocn826867074.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balagopalan et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aparna Balagopalan, Haoran
Zhang, Kimia Hamidieh, Thomas
Hartvigsen, Frank Rudzicz, and Marzyeh
Ghassemi. 2022.

</span>
<span class="ltx_bibblock">The Road to Explainability is Paved with
Bias: Measuring the Fairness of Explanations. In
<em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness,
Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 1194–1206.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3531146.3533179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533179</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansak et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Kirk Bansak, Jeremy
Ferwerda, Jens Hainmueller, Andrea
Dillon, Dominik Hangartner, Duncan
Lawrence, and Jeremy Weinstein.
2018.

</span>
<span class="ltx_bibblock">Improving refugee integration through data-driven
algorithmic assignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Science</em> 359,
6373 (Jan. 2018),
325–329.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1126/science.aao4408" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1126/science.aao4408</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barredo Arrieta et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alejandro Barredo Arrieta,
Natalia Díaz-Rodríguez, Javier Del
Ser, Adrien Bennetot, Siham Tabik,
Alberto Barbado, Salvador Garcia,
Sergio Gil-Lopez, Daniel Molina,
Richard Benjamins, Raja Chatila, and
Francisco Herrera. 2020.

</span>
<span class="ltx_bibblock">Explainable Artificial Intelligence (XAI):
Concepts, taxonomies, opportunities and challenges toward responsible AI.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Information Fusion</em> 58
(2020), 82–115.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.inffus.2019.12.012" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.inffus.2019.12.012</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bell et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Andrew Bell, Ian
Solano-Kamaiko, Oded Nov, and Julia
Stoyanovich. 2022.

</span>
<span class="ltx_bibblock">It’s Just Not That Simple: An
Empirical Study of the Accuracy-Explainability Trade-off in
Machine Learning for Public Policy. In
<em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness,
Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 248–266.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3533090" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533090</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Binns et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Reuben Binns, Max
Van Kleek, Michael Veale, Ulrik Lyngs,
Jun Zhao, and Nigel Shadbolt.
2018.

</span>
<span class="ltx_bibblock">’It’s Reducing a Human Being to a
Percentage’; Perceptions of Justice in Algorithmic Decisions. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on
Human Factors in Computing Systems</em>. 1–14.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3173574.3173951" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3173951</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bloom et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (1956)</span>
<span class="ltx_bibblock">
Benjamin Bloom, M.
Engelhart, E. Furst, W. Hill, and
D. Krathwohl. 1956.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Taxonomy of Educational Objectives,
Handbook 1_ Cognitive Domain.pdf</em>.

</span>
<span class="ltx_bibblock">Addison Wesley Publishing Company.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bransford and Johnson (1972)</span>
<span class="ltx_bibblock">
John D. Bransford and
Marcia K. Johnson. 1972.

</span>
<span class="ltx_bibblock">Contextual Prerequisites for Understanding:
Some Investigations of Comprehension and Recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of Verbal Learning and Verbal
Behaviour 11</em> (1972).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Anna Brown, Alexandra
Chouldechova, Emily Putnam-Hornstein,
Andrew Tobin, and Rhema Vaithianathan.
2019.

</span>
<span class="ltx_bibblock">Toward Algorithmic Accountability in Public
Services: A Qualitative Study of Affected Community
Perspectives on Algorithmic Decision-making in Child Welfare
Services. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI
Conference on Human Factors in Computing Systems</em>.
ACM, Glasgow Scotland Uk,
1–12.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3290605.3300271" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300271</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Hao-Fei Cheng, Ruotong
Wang, Zheng Zhang, Fiona O’Connell,
Terrance Gray, F. Maxwell Harper, and
Haiyi Zhu. 2019.

</span>
<span class="ltx_bibblock">Explaining Decision-Making Algorithms through
UI: Strategies to Help Non-Expert Stakeholders. In
<em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on
Human Factors in Computing Systems</em>. ACM,
Glasgow Scotland Uk, 1–12.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3290605.3300789" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300789</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chouldechova (2017)</span>
<span class="ltx_bibblock">
Alexandra Chouldechova.
2017.

</span>
<span class="ltx_bibblock">Fair Prediction with Disparate Impact: A Study of
Bias in Recidivism Prediction Instruments.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Big Data</em> 5,
2 (2017), 153–163.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1089/big.2016.0047" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1089/big.2016.0047</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission (2021)</span>
<span class="ltx_bibblock">
European Commission.
2021.

</span>
<span class="ltx_bibblock">Laying Down Harmonised Rules on Artificial
Intelligence.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Fine Licht and de Fine Licht (2020)</span>
<span class="ltx_bibblock">
Karl de Fine Licht and
Jenny de Fine Licht. 2020.

</span>
<span class="ltx_bibblock">Artificial Intelligence, Transparency, and Public
Decision-Making: Why Explanations Are Key When Trying to Produce Perceived
Legitimacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">AI Soc.</em> 35,
4 (dec 2020),
917–926.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s00146-020-00960-w" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s00146-020-00960-w</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dodge et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jonathan Dodge, Q. Vera
Liao, Yunfeng Zhang, Rachel K. E.
Bellamy, and Casey Dugan.
2019.

</span>
<span class="ltx_bibblock">Explaining Models: An Empirical Study of
How Explanations Impact Fairness Judgment. In
<em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th International
Conference on Intelligent User Interfaces</em>.
275–285.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3301275.3302310" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3301275.3302310</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duckworth (2001)</span>
<span class="ltx_bibblock">
Eleanor Duckworth (Ed.).
2001.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">”Tell me more”: listening to learners
explain</em>.

</span>
<span class="ltx_bibblock">Teachers College Press, New
York.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">European Parliament. Directorate General for Parliamentary Research
Services. (2019)</span>
<span class="ltx_bibblock">
European Parliament. Directorate General
for Parliamentary Research Services. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Understanding algorithmic decision-making:
opportunities and challenges.</em>

</span>
<span class="ltx_bibblock">Publications Office, LU.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://data.europa.eu/doi/10.2861/536131" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://data.europa.eu/doi/10.2861/536131</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Floridi et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Luciano Floridi, Josh
Cowls, Monica Beltrametti, Raja Chatila,
Patrice Chazerand, Virginia Dignum,
Christoph Luetge, Robert Madelin,
Ugo Pagallo, Francesca Rossi,
Burkhard Schafer, Peggy Valcke, and
Effy Vayena. 2018.

</span>
<span class="ltx_bibblock">AI4People—An Ethical Framework for a
Good AI Society: Opportunities, Risks, Principles, and
Recommendations.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Minds and Machines</em> 28,
4 (Dec. 2018),
689–707.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s11023-018-9482-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s11023-018-9482-5</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermstrüwer and Langenbach (2022)</span>
<span class="ltx_bibblock">
Yoan Hermstrüwer and
Pascal Langenbach. 2022.

</span>
<span class="ltx_bibblock">Fair Governance with Humans and Machines.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">SSRN Electronic Journal</em>
(2022).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.2139/ssrn.4118650" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2139/ssrn.4118650</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hidalgo et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
César Hidalgo, Diana
Orghain, Filipa de Almeida Jordi Albo Canals, and
Natalia Martin. 2021.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">How Humans Judge Machines</em>.

</span>
<span class="ltx_bibblock">MIT Press, Cambridge, MA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holl et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jürgen Holl, Günter
Kernbeiß, and Michael Wagner-Pinter.
2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Das AMS-Arbeitsmarktchancen-Modell</em>.

</span>
<span class="ltx_bibblock">Technical concept. Synthesis
Forschung, Vienna.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holl et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jürgen Holl, Günter
Kernbeiß, and Michael Wagner-Pinter.
2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Personenbezogene
Wahrscheinlichkeitsaussagen (»Algorithmen«): Stichworte zur
Sozialverträglichkeit</em>.

</span>
<span class="ltx_bibblock">Technical concept. Synthesis
Forschung, Vienna.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jakesch et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Maurice Jakesch, Zana
Buçinca, Saleema Amershi, and
Alexandra Olteanu. 2022.

</span>
<span class="ltx_bibblock">How Different Groups Prioritize Ethical
Values for Responsible AI. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">2022 ACM
Conference on Fairness, Accountability, and Transparency</em>.
ACM, Seoul Republic of Korea,
310–323.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3533097" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533097</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaur et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Harmanpreet Kaur, Eytan
Adar, Eric Gilbert, and Cliff Lampe.
2022.

</span>
<span class="ltx_bibblock">Sensible AI: Re-imagining Interpretability
and Explainability using Sensemaking Theory. In
<em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness,
Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 702–714.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3533135" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533135</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kawakami et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Anna Kawakami, Luke
Guerdan, Yang Cheng, Anita Sun,
Alison Hu, Kate Glazko,
Nikos Arechiga, Matthew Lee,
Scott Carter, Haiyi Zhu, and
Kenneth Holstein. 2022.

</span>
<span class="ltx_bibblock">Towards a Learner-Centered Explainable AI:
Lessons from the learning sciences.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://arxiv.org/abs/2212.05588" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2212.05588</a>

</span>
<span class="ltx_bibblock">arXiv:2212.05588 [cs].

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulesza et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Todd Kulesza, Simone
Stumpf, Margaret Burnett, Sherry Yang,
Irwin Kwan, and Weng-Keen Wong.
2013.

</span>
<span class="ltx_bibblock">Too much, too little, or just right? Ways
explanations impact end users’ mental models. In
<em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">2013 IEEE Symposium on Visual Languages and
Human Centric Computing</em>. IEEE,
San Jose, CA, USA, 3–10.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/VLHCC.2013.6645235" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/VLHCC.2013.6645235</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Langer et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Markus Langer, Daniel
Oster, Timo Speith, Holger Hermanns,
Lena Kästner, Eva Schmidt,
Andreas Sesing, and Kevin Baum.
2021.

</span>
<span class="ltx_bibblock">What do we want from Explainable Artificial
Intelligence (XAI)? – A stakeholder perspective on XAI and a
conceptual model guiding interdisciplinary XAI research.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Artificial Intelligence</em>
296 (July 2021),
103473.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.artint.2021.103473" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.artint.2021.103473</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Baykal (2017)</span>
<span class="ltx_bibblock">
Min Kyung Lee and Su
Baykal. 2017.

</span>
<span class="ltx_bibblock">Algorithmic Mediation in Group Decisions:
Fairness Perceptions of Algorithmically Mediated vs.
Discussion-Based Social Division. In
<em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM Conference on
Computer Supported Cooperative Work and Social Computing</em>.
ACM, Portland Oregon USA,
1035–1048.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/2998181.2998230" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2998181.2998230</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Min Kyung Lee, Daniel
Kusbit, Anson Kahng, Ji Tae Kim,
Xinran Yuan, Allissa Chan,
Daniel See, Ritesh Noothigattu,
Siheon Lee, Alexandros Psomas, and
Ariel D. Procaccia. 2019.

</span>
<span class="ltx_bibblock">WeBuildAI: Participatory Framework for
Algorithmic Governance.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 3, CSCW
(Nov. 2019), 1–35.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3359283" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3359283</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Q. Vera Liao, Daniel
Gruen, and Sarah Miller.
2020.

</span>
<span class="ltx_bibblock">Questioning the AI: Informing Design Practices for
Explainable AI User Experiences. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2020 CHI Conference on Human Factors in Computing Systems</em> (Honolulu,
HI, USA) <em id="bib.bib34.4.2" class="ltx_emph ltx_font_italic">(CHI ’20)</em>. Association
for Computing Machinery, New York, NY, USA,
1–15.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3313831.3376590" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3313831.3376590</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Logg et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jennifer M. Logg, Julia A.
Minson, and Don A. Moore.
2019.

</span>
<span class="ltx_bibblock">Algorithm appreciation: People prefer algorithmic
to human judgment.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Organizational Behavior and Human Decision
Processes</em> 151 (2019),
90–103.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.obhdp.2018.12.005" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.obhdp.2018.12.005</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lopez (2019)</span>
<span class="ltx_bibblock">
Paola Lopez.
2019.

</span>
<span class="ltx_bibblock">Reinforcing Intersectional Inequality via the
AMS Algorithm in Austria.

</span>
<span class="ltx_bibblock">(2019), 21.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaio et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Michael A. Madaio, Luke
Stark, Jennifer Wortman Vaughan, and
Hanna Wallach. 2020.

</span>
<span class="ltx_bibblock">Co-Designing Checklists to Understand
Organizational Challenges and Opportunities around Fairness in AI.
In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 CHI Conference on
Human Factors in Computing Systems</em>. ACM,
Honolulu HI USA, 1–14.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3313831.3376445" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3313831.3376445</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marabelli and Newell (2019)</span>
<span class="ltx_bibblock">
Marco Marabelli and Sue
Newell. 2019.

</span>
<span class="ltx_bibblock">Algorithmic Decision-making in the US Healthcare
Industry: Good for Whom?

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Academy of Management Proceedings</em>
2019 (08 2019),
15581.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.5465/AMBPP.2019.15581abstract" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5465/AMBPP.2019.15581abstract</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miller (2019)</span>
<span class="ltx_bibblock">
Tim Miller.
2019.

</span>
<span class="ltx_bibblock">Explanation in artificial intelligence: Insights
from the social sciences.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence</em>
267 (Feb. 2019),
1–38.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.artint.2018.07.007" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.artint.2018.07.007</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">on Artificial Intelligence (2019)</span>
<span class="ltx_bibblock">
High-Level Expert Group on
Artificial Intelligence. 2019.

</span>
<span class="ltx_bibblock">Ethics guidelines for trustworthy AI.

</span>
<span class="ltx_bibblock">(April 2019).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">O’Neil (2016)</span>
<span class="ltx_bibblock">
Cathy O’Neil.
2016.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Weapons of math destruction: how big data
increases inequality and threatens democracy</em> (first
edition ed.).

</span>
<span class="ltx_bibblock">Crown, New York.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peck et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Evan M. Peck, Sofia E.
Ayuso, and Omar El-Etr.
2019.

</span>
<span class="ltx_bibblock">Data is Personal: Attitudes and Perceptions of Data
Visualization in Rural Pennsylvania. In
<em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em id="bib.bib42.4.2" class="ltx_emph ltx_font_italic">(CHI ’19)</em>. Association for
Computing Machinery, New York, NY, USA,
1–12.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3290605.3300474" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3290605.3300474</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pierson (2018)</span>
<span class="ltx_bibblock">
Emma Pierson.
2018.

</span>
<span class="ltx_bibblock">Demographics and discussion influence views on
algorithmic fairness.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://arxiv.org/abs/1712.09124" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1712.09124</a>

</span>
<span class="ltx_bibblock">arXiv:1712.09124 [cs].

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radavoi (2020)</span>
<span class="ltx_bibblock">
Ciprian N Radavoi.
2020.

</span>
<span class="ltx_bibblock">The Impact of Artificial Intelligence on
Freedom, Rationality, Rule of Law and Democracy: Should We
Not Be Debating It?

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Texas Journal on Civil Liberties &amp; Civil
Rights</em> 25, 2 (2020),
24.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reader et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Lydia Reader, Pegah
Nokhiz, Cathleen Power, Neal Patwari,
Suresh Venkatasubramanian, and Sorelle
Friedler. 2022.

</span>
<span class="ltx_bibblock">Models for understanding and quantifying feedback
in societal systems. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on
Fairness, Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 1765–1775.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3533230" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533230</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Amy D. Robertson, Rachel
Scherr, and David Hammer (Eds.).
2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Responsive Teaching in Science and
Mathematics</em> (0 ed.).

</span>
<span class="ltx_bibblock">Routledge.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.4324/9781315689302" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.4324/9781315689302</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sato et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Brian K. Sato, Cynthia
F. C. Hill, and Stanley M. Lo.
2019.

</span>
<span class="ltx_bibblock">Testing the test: Are exams measuring
understanding?

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Biochemistry and Molecular Biology
Education</em> 47, 3 (May
2019), 296–302.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1002/bmb.21231" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1002/bmb.21231</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scardamalia and Bereiter (2014)</span>
<span class="ltx_bibblock">
Marlene Scardamalia and
Carl Bereiter. 2014.

</span>
<span class="ltx_bibblock">Knowledge Building and Knowledge Creation:
Theory, Pedagogy, and Technology.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">The Cambridge Handbook of the
Learning Sciences</em> (2 ed.),
R. Keith Sawyer (Ed.).
Cambridge University Press, 397–417.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1017/CBO9781139519526.025" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1017/CBO9781139519526.025</a>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schraw et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2006)</span>
<span class="ltx_bibblock">
Gregory Schraw, Kent J.
Crippen, and Kendall Hartley.
2006.

</span>
<span class="ltx_bibblock">Promoting Self-Regulation in Science
Education: Metacognition as Part of a Broader Perspective on
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Research in Science Education</em>
36, 1-2 (March
2006), 111–139.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s11165-005-3917-8" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s11165-005-3917-8</a>

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scott et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kristen M. Scott,
Sonja Mei Wang, Milagros Miceli,
Pieter Delobelle, Karolina
Sztandar-Sztanderska, and Bettina Berendt.
2022.

</span>
<span class="ltx_bibblock">Algorithmic Tools in Public Employment
Services: Towards a Jobseeker-Centric Perspective. In
<em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness,
Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 2138–2148.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3534631" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3534631</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ruoxi Shang, K. J. Kevin
Feng, and Chirag Shah. 2022.

</span>
<span class="ltx_bibblock">Why Am I Not Seeing It? Understanding
Users’ Needs for Counterfactual Explanations in Everyday
Recommendations. In <em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on
Fairness, Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 1330–1340.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3533189" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3533189</a>

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hong Shen, Haojian Jin,
Ángel Alexander Cabrera, Adam Perer,
Haiyi Zhu, and Jason I. Hong.
2020.

</span>
<span class="ltx_bibblock">Designing Alternative Representations of
Confusion Matrices to Support Non-Expert Public Understanding
of Algorithm Performance.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer
Interaction</em> 4, CSCW2
(Oct. 2020), 1–22.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3415224" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3415224</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shulner-Tal et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Avital Shulner-Tal, Tsvi
Kuflik, and Doron Kliger.
2022.

</span>
<span class="ltx_bibblock">Enhancing Fairness Perception – Towards
Human-Centred AI and Personalized Explanations Understanding the
Factors Influencing Laypeople’s Fairness Perceptions of
Algorithmic Decisions.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">International Journal of Human–Computer
Interaction</em> (July 2022),
1–28.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1080/10447318.2022.2095705" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/10447318.2022.2095705</a>

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
M. K. Smith, W. B. Wood,
W. K. Adams, C. Wieman,
J. K. Knight, N. Guild, and
T. T. Su. 2009.

</span>
<span class="ltx_bibblock">Why Peer Discussion Improves Student
Performance on In-Class Concept Questions.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Science</em> 323,
5910 (Jan. 2009),
122–124.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1126/science.1165919" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1126/science.1165919</a>

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speith (2022)</span>
<span class="ltx_bibblock">
Timo Speith.
2022.

</span>
<span class="ltx_bibblock">A Review of Taxonomies of Explainable
Artificial Intelligence (XAI) Methods. In
<em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">2022 ACM Conference on Fairness,
Accountability, and Transparency</em>. ACM,
Seoul Republic of Korea, 2239–2250.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3531146.3534639" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3531146.3534639</a>

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spiekermann (2021)</span>
<span class="ltx_bibblock">
Sarah Spiekermann.
2021.

</span>
<span class="ltx_bibblock">From value-lists to value-based engineering with
IEEE 7000™. In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International
Symposium on Technology and Society (ISTAS)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ISTAS52410.2021.9629134" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ISTAS52410.2021.9629134</a>

</span>
<span class="ltx_bibblock">ISSN: 2158-3412.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Starke et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Christopher Starke, Janine
Baleis, Birte Keller, and Frank
Marcinkowski. 2021.

</span>
<span class="ltx_bibblock">Fairness Perceptions of Algorithmic
Decision-Making: A Systematic Review of the Empirical Literature.

</span>
<span class="ltx_bibblock">(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szymanski et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Maxwell Szymanski, Martijn
Millecamp, and Katrien Verbert.
2021.

</span>
<span class="ltx_bibblock">Visual, textual or hybrid: the effect of user
expertise on different explanations. In <em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">26th
International Conference on Intelligent User Interfaces</em>.
ACM, College Station TX USA,
109–119.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3397481.3450662" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3397481.3450662</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thomas (2006)</span>
<span class="ltx_bibblock">
David R. Thomas.
2006.

</span>
<span class="ltx_bibblock">A General Inductive Approach for Analyzing
Qualitative Evaluation Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">The American journal of evaluation</em>
27, 2 (2006),
237–246.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veale et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Michael Veale, Max
Van Kleek, and Reuben Binns.
2018.

</span>
<span class="ltx_bibblock">Fairness and Accountability Design Needs for
Algorithmic Support in High-Stakes Public Sector
Decision-Making.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 CHI Conference on
Human Factors in Computing Systems</em> (April
2018), 1–14.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3173574.3174014" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3174014</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veenman et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2006)</span>
<span class="ltx_bibblock">
Marcel V. J. Veenman,
Bernadette H. A. M. Van Hout-Wolters, and
Peter Afflerbach. 2006.

</span>
<span class="ltx_bibblock">Metacognition and learning: conceptual and
methodological considerations.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Metacognition and Learning</em>
1, 1 (April
2006), 3–14.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s11409-006-6893-0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s11409-006-6893-0</a>

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Yin (2021)</span>
<span class="ltx_bibblock">
Xinru Wang and Ming
Yin. 2021.

</span>
<span class="ltx_bibblock">Are Explanations Helpful? A Comparative Study of
the Effects of Explanations in AI-Assisted Decision-Making. In
<em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">26th International Conference on Intelligent User
Interfaces</em> <em id="bib.bib62.2.2" class="ltx_emph ltx_font_italic">(IUI ’21)</em>.
Association for Computing Machinery,
New York, NY, USA, 318–328.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3397481.3450650" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3397481.3450650</a>

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weick et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2005)</span>
<span class="ltx_bibblock">
Karl E. Weick, Kathleen M.
Sutcliffe, and David Obstfeld.
2005.

</span>
<span class="ltx_bibblock">Organizing and the Process of Sensemaking.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Organization Science</em> 16,
4 (2005), 409–421.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1287/orsc.1050.0133" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1287/orsc.1050.0133</a>
arXiv:https://doi.org/10.1287/orsc.1050.0133

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiggins and McTighe (2005)</span>
<span class="ltx_bibblock">
Grant P. Wiggins and Jay
McTighe. 2005.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Understanding by design</em>
(expanded 2nd ed ed.).

</span>
<span class="ltx_bibblock">Association for Supervision and Curriculum
Development, Alexandria, VA.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">OCLC: 60756429.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Woodruff et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Allison Woodruff, Sarah E.
Fox, Steven Rousso-Schindler, and
Jeffrey Warshaw. 2018.

</span>
<span class="ltx_bibblock">A Qualitative Exploration of Perceptions of
Algorithmic Fairness. In <em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2018 CHI Conference on Human Factors in Computing Systems</em>.
ACM, Montreal QC Canada,
1–14.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3173574.3174230" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3173574.3174230</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.08263" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.08264" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.08264">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.08264" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.08265" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 01:02:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
