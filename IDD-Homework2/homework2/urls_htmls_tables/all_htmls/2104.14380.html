<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.14380] PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments</title><meta property="og:description" content="We propose and implement a Privacy-preserving Federated Learning () framework for mobile systems to limit privacy leakages in federated learning. Leveraging the widespread presence of Trusted Execution Environments (TE…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.14380">

<!--Generated on Sat Mar  2 06:23:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fan Mo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Imperial College London
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamed Haddadi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Imperial College London
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kleomenis Katevas
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Telefónica Research
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Eduard Marin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Telefónica Research
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Diego Perino
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Telefónica Research
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicolas Kourtellis
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Telefónica Research
</span></span></span>
</div>
<div class="ltx_dates">(2021)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id9.9" class="ltx_p">We propose and implement a Privacy-preserving Federated Learning (<math id="1.m1.1" class="ltx_Math" alttext="PPFL" display="inline"><semantics id="1.m1.1a"><mrow id="1.m1.1.1" xref="1.m1.1.1.cmml"><mi id="1.m1.1.1.2" xref="1.m1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="1.m1.1.1.1" xref="1.m1.1.1.1.cmml">​</mo><mi id="1.m1.1.1.3" xref="1.m1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="1.m1.1.1.1a" xref="1.m1.1.1.1.cmml">​</mo><mi id="1.m1.1.1.4" xref="1.m1.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="1.m1.1.1.1b" xref="1.m1.1.1.1.cmml">​</mo><mi id="1.m1.1.1.5" xref="1.m1.1.1.5.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="1.m1.1b"><apply id="1.m1.1.1.cmml" xref="1.m1.1.1"><times id="1.m1.1.1.1.cmml" xref="1.m1.1.1.1"></times><ci id="1.m1.1.1.2.cmml" xref="1.m1.1.1.2">𝑃</ci><ci id="1.m1.1.1.3.cmml" xref="1.m1.1.1.3">𝑃</ci><ci id="1.m1.1.1.4.cmml" xref="1.m1.1.1.4">𝐹</ci><ci id="1.m1.1.1.5.cmml" xref="1.m1.1.1.5">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="1.m1.1c">PPFL</annotation></semantics></math>) framework for mobile systems to limit privacy leakages in federated learning. Leveraging the widespread presence of Trusted Execution Environments (TEEs) in high-end and mobile devices, we utilize TEEs on clients for local training, and on servers for secure aggregation, so that model/gradient updates are hidden from adversaries.
Challenged by the limited memory size of current TEEs, we leverage greedy layer-wise training to train each model’s layer inside the trusted area until its convergence.
The performance evaluation of our implementation shows that <math id="id2.2.m2.1" class="ltx_Math" alttext="PPFL" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">​</mo><mi id="id2.2.m2.1.1.3" xref="id2.2.m2.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="id2.2.m2.1.1.1a" xref="id2.2.m2.1.1.1.cmml">​</mo><mi id="id2.2.m2.1.1.4" xref="id2.2.m2.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="id2.2.m2.1.1.1b" xref="id2.2.m2.1.1.1.cmml">​</mo><mi id="id2.2.m2.1.1.5" xref="id2.2.m2.1.1.5.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><times id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1"></times><ci id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">𝑃</ci><ci id="id2.2.m2.1.1.3.cmml" xref="id2.2.m2.1.1.3">𝑃</ci><ci id="id2.2.m2.1.1.4.cmml" xref="id2.2.m2.1.1.4">𝐹</ci><ci id="id2.2.m2.1.1.5.cmml" xref="id2.2.m2.1.1.5">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">PPFL</annotation></semantics></math> can significantly improve privacy while incurring small system overheads at the client-side.
In particular, <math id="id3.3.m3.1" class="ltx_Math" alttext="PPFL" display="inline"><semantics id="id3.3.m3.1a"><mrow id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1.2" xref="id3.3.m3.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">​</mo><mi id="id3.3.m3.1.1.3" xref="id3.3.m3.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="id3.3.m3.1.1.1a" xref="id3.3.m3.1.1.1.cmml">​</mo><mi id="id3.3.m3.1.1.4" xref="id3.3.m3.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="id3.3.m3.1.1.1b" xref="id3.3.m3.1.1.1.cmml">​</mo><mi id="id3.3.m3.1.1.5" xref="id3.3.m3.1.1.5.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><times id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1.1"></times><ci id="id3.3.m3.1.1.2.cmml" xref="id3.3.m3.1.1.2">𝑃</ci><ci id="id3.3.m3.1.1.3.cmml" xref="id3.3.m3.1.1.3">𝑃</ci><ci id="id3.3.m3.1.1.4.cmml" xref="id3.3.m3.1.1.4">𝐹</ci><ci id="id3.3.m3.1.1.5.cmml" xref="id3.3.m3.1.1.5">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">PPFL</annotation></semantics></math> can successfully defend the trained model against data reconstruction, property inference, and membership inference attacks.
Furthermore, it can achieve <em id="id9.9.1" class="ltx_emph ltx_font_italic">comparable</em> model utility with fewer communication rounds (0.54<math id="id4.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id4.4.m4.1a"><mo id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><times id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">\times</annotation></semantics></math>) and a similar amount of network traffic (1.002<math id="id5.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id5.5.m5.1a"><mo id="id5.5.m5.1.1" xref="id5.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id5.5.m5.1b"><times id="id5.5.m5.1.1.cmml" xref="id5.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id5.5.m5.1c">\times</annotation></semantics></math>) compared to the standard federated learning of a complete model.
This is achieved while only introducing up to <math id="id6.6.m6.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id6.6.m6.1a"><mo id="id6.6.m6.1.1" xref="id6.6.m6.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id6.6.m6.1b"><csymbol cd="latexml" id="id6.6.m6.1.1.cmml" xref="id6.6.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id6.6.m6.1c">\sim</annotation></semantics></math>15% CPU time, <math id="id7.7.m7.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id7.7.m7.1a"><mo id="id7.7.m7.1.1" xref="id7.7.m7.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id7.7.m7.1b"><csymbol cd="latexml" id="id7.7.m7.1.1.cmml" xref="id7.7.m7.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id7.7.m7.1c">\sim</annotation></semantics></math>18% memory usage, and <math id="id8.8.m8.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id8.8.m8.1a"><mo id="id8.8.m8.1.1" xref="id8.8.m8.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id8.8.m8.1b"><csymbol cd="latexml" id="id8.8.m8.1.1.cmml" xref="id8.8.m8.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id8.8.m8.1c">\sim</annotation></semantics></math>21% energy consumption overhead in <math id="id9.9.m9.1" class="ltx_Math" alttext="PPFL" display="inline"><semantics id="id9.9.m9.1a"><mrow id="id9.9.m9.1.1" xref="id9.9.m9.1.1.cmml"><mi id="id9.9.m9.1.1.2" xref="id9.9.m9.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="id9.9.m9.1.1.1" xref="id9.9.m9.1.1.1.cmml">​</mo><mi id="id9.9.m9.1.1.3" xref="id9.9.m9.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="id9.9.m9.1.1.1a" xref="id9.9.m9.1.1.1.cmml">​</mo><mi id="id9.9.m9.1.1.4" xref="id9.9.m9.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="id9.9.m9.1.1.1b" xref="id9.9.m9.1.1.1.cmml">​</mo><mi id="id9.9.m9.1.1.5" xref="id9.9.m9.1.1.5.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="id9.9.m9.1b"><apply id="id9.9.m9.1.1.cmml" xref="id9.9.m9.1.1"><times id="id9.9.m9.1.1.1.cmml" xref="id9.9.m9.1.1.1"></times><ci id="id9.9.m9.1.1.2.cmml" xref="id9.9.m9.1.1.2">𝑃</ci><ci id="id9.9.m9.1.1.3.cmml" xref="id9.9.m9.1.1.3">𝑃</ci><ci id="id9.9.m9.1.1.4.cmml" xref="id9.9.m9.1.1.4">𝐹</ci><ci id="id9.9.m9.1.1.5.cmml" xref="id9.9.m9.1.1.5">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.m9.1c">PPFL</annotation></semantics></math>’s client-side.</p>
</div>
<span id="10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Security and privacy Privacy protections</span></span></span><span id="11" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Distributed algorithms</span></span></span><span id="12" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Security and privacy Distributed systems security</span></span></span><span id="13" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2021</span></span></span><span id="14" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="15" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>The 19th Annual International Conference on Mobile Systems, Applications, and Services; June 24-July 2, 2021; Virtual, WI, USA</span></span></span><span id="16" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>The 19th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys ’21), June 24-July 2, 2021, Virtual, WI, USA</span></span></span><span id="17" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="18" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3458864.3466628</span></span></span><span id="19" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-8443-8/21/07</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Training deep neural networks (DNNs) on multiple devices locally and building an aggregated global model on a server, namely federated learning (FL), has drawn significant attention from academia (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib17" title="" class="ltx_ref">geyer2017differentially, </a>; <a href="#bib.bib27" title="" class="ltx_ref">kairouz2019advances, </a>; <a href="#bib.bib42" title="" class="ltx_ref">liu2020secure, </a>)</cite>) and industry, and is even being deployed in real systems (e.g., Google Keyboard <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">bonawitz2019towards, </a>)</cite>).
Unlike traditional machine learning (ML), where a server collects all user data at a central point and trains a global model, in FL, users only send the locally updated model parameters to the server.
This allows training a model without the need for users to reveal their data, thus preserving their privacy.
Unfortunately, recent works have shown that adversaries can execute attacks to retrieve sensitive information from the model parameters themselves <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>; <a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>; <a href="#bib.bib20" title="" class="ltx_ref">hitaj2017deep, </a>)</cite>.
Prominent examples of such attacks are data reconstruction <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib20" title="" class="ltx_ref">hitaj2017deep, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>)</cite> and various types of inference attacks <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib20" title="" class="ltx_ref">hitaj2017deep, </a>; <a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>)</cite>.
The fundamental reason why these attacks are possible is because as a DNN learns to achieve their main task, it also learns irrelevant information from users’ training data that is inadvertently embedded in the model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib73" title="" class="ltx_ref">yeom2018privacy, </a>)</cite>.
Note that in FL scenarios, such attacks can be launched both at server and client sides.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Motivated by these attacks, researchers have recently introduced several countermeasures to prevent them.
Existing solutions can be grouped into three main categories depending on whether they rely on:
(i) homomorphic encryption (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib2" title="" class="ltx_ref">aono2017privacy, </a>; <a href="#bib.bib42" title="" class="ltx_ref">liu2020secure, </a>)</cite>),
(ii) multi-party computation (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib8" title="" class="ltx_ref">bonawitz2017practical, </a>)</cite>), or
(iii) differential privacy (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib17" title="" class="ltx_ref">geyer2017differentially, </a>; <a href="#bib.bib44" title="" class="ltx_ref">mcmahan2018learning, </a>; <a href="#bib.bib14" title="" class="ltx_ref">dwork2014algorithmic, </a>)</cite>). While homomorphic encryption is practical in both high-end and mobile devices, it only supports a limited number of arithmetic operations in the encrypted domain.
Alternatively, the use of fully homomorphic encryption has been employed to allow arbitrary operations in the encrypted domain, thus supports ML.
Yet, this comes with too much computational overhead, making it impractical for mobile devices <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib51" title="" class="ltx_ref">naehrig2011can, </a>; <a href="#bib.bib63" title="" class="ltx_ref">sealcrypto, </a>)</cite>. Similarly, multi-party computation-based solutions incur significant computational overhead.
Also, in some cases, differential privacy can fail to provide sufficient privacy as shown in <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>)</cite>.
Furthermore, it can negatively impact the utility and fairness of the model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib25" title="" class="ltx_ref">jayaraman2019relaxations, </a>; <a href="#bib.bib3" title="" class="ltx_ref">bagdasaryan2019differential, </a>)</cite>, as well as the system performance <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib68" title="" class="ltx_ref">testuggine2020opacus, </a>; <a href="#bib.bib66" title="" class="ltx_ref">subramani2020enabling, </a>)</cite>.
Overall, none of the existing solutions meets all requirements, hampering their adoption.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">More recently, the use of hardware-based Trusted Execution Environments (TEEs) has been proposed as a promising way to preclude attacks against DNN model parameters and gradients.
TEEs allow to securely store data and execute arbitrary code on an untrusted device almost at native speed through secure memory compartments.
All these advantages – together with the recent commoditization of TEEs both in high-end and mobile devices – make TEEs a suitable candidate to allow fully privacy-preserving ML modeling.
However, in order to keep the Trusted Computing Base (TCB) as small as possible, current TEEs have limited memory. This makes it impossible to simultaneously place all DNN layers inside the TEE.
As a result, prior work has opted for using TEEs to conceal only the most sensitive DNN layers from adversaries, leaving other layers unprotected <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib18" title="" class="ltx_ref">gu2018securing, </a>; <a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite>.
While this approach was sufficient to mitigate some attacks against traditional ML where clients obtain only the final model, in FL scenarios the attack surface is significantly larger. FL client devices are able to observe distinct snapshots of the model throughout the training, allowing them to realize attacks at different stages <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib20" title="" class="ltx_ref">hitaj2017deep, </a>)</cite>.
Therefore, it is of utmost importance to protect all DNN layers using the TEE.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose Privacy-preserving Federated Learning (PPFL), the first practical framework to <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">fully</em> prevent private information leakage at both <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">server</em> and <em id="S1.p4.1.3" class="ltx_emph ltx_font_italic">client-side</em> under FL scenarios.
PPFL is based on <em id="S1.p4.1.4" class="ltx_emph ltx_font_italic">greedy layer-wise</em> training and aggregation, overcoming the constraints posed by the limited TEE memory, and providing comparable accuracy of complete model training at the price of a tolerable delay.
Our layer-wise approach supports sophisticated settings such as training one or more layers (block) each time, which can potentially better deal with heterogeneous data at the client-side and speed up the training process.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.6" class="ltx_p">To show its feasibility, we implemented and evaluated a full prototype of PPFL system including server-side (with Intel SGX), client-side (with Arm TrustZone) elements of the design, and the secure communication between them.
Our experimental evaluation shows that PPFL provides full protection against data reconstruction, property inference, and membership inference attacks, whose outcomes are degraded to random guessing (e.g., white noise images or 50% precision scores).
PPFL is practical as it does not add significant overhead to the training process.
Compared to regular end-to-end FL, PPFL introduces a <math id="S1.p5.1.m1.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1b"><mn id="S1.p5.1.m1.1.1">3</mn><mo lspace="0.222em" id="S1.p5.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">3\times</annotation></semantics></math> or higher delay for completing the training of all DNN layers. However, PPFL achieves comparable ML performance when training only the first few layers, meaning that it is not needed to train all DNN layers. Due to this flexibility of layer-wise training, PPFL can provide a similar ML model utility as end-to-end FL, with fewer communication rounds (<math id="S1.p5.2.m2.1" class="ltx_math_unparsed" alttext="0.54\times" display="inline"><semantics id="S1.p5.2.m2.1a"><mrow id="S1.p5.2.m2.1b"><mn id="S1.p5.2.m2.1.1">0.54</mn><mo lspace="0.222em" id="S1.p5.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">0.54\times</annotation></semantics></math>), and a similar amount of network traffic (<math id="S1.p5.3.m3.1" class="ltx_math_unparsed" alttext="1.002\times" display="inline"><semantics id="S1.p5.3.m3.1a"><mrow id="S1.p5.3.m3.1b"><mn id="S1.p5.3.m3.1.1">1.002</mn><mo lspace="0.222em" id="S1.p5.3.m3.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.p5.3.m3.1c">1.002\times</annotation></semantics></math>), with only <math id="S1.p5.4.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p5.4.m4.1a"><mo id="S1.p5.4.m4.1.1" xref="S1.p5.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p5.4.m4.1b"><csymbol cd="latexml" id="S1.p5.4.m4.1.1.cmml" xref="S1.p5.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.4.m4.1c">\sim</annotation></semantics></math>15% CPU time, <math id="S1.p5.5.m5.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p5.5.m5.1a"><mo id="S1.p5.5.m5.1.1" xref="S1.p5.5.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p5.5.m5.1b"><csymbol cd="latexml" id="S1.p5.5.m5.1.1.cmml" xref="S1.p5.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.5.m5.1c">\sim</annotation></semantics></math>18% memory usage, and <math id="S1.p5.6.m6.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p5.6.m6.1a"><mo id="S1.p5.6.m6.1.1" xref="S1.p5.6.m6.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p5.6.m6.1b"><csymbol cd="latexml" id="S1.p5.6.m6.1.1.cmml" xref="S1.p5.6.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.6.m6.1c">\sim</annotation></semantics></math>21% energy consumption overhead at client-side.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background and Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we provide the background needed to understand the way TEEs work (Sec. <a href="#S2.SS1" title="2.1. Trusted Execution Environments (TEE) ‣ 2. Background and Related Work ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>), existing privacy risks in FL (Sec. <a href="#S2.SS2" title="2.2. Privacy Risks in FL ‣ 2. Background and Related Work ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>), privacy-preserving ML techniques using TEEs (Sec. <a href="#S2.SS3" title="2.3. Privacy-preserving ML using TEEs ‣ 2. Background and Related Work ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), as well as core ideas behind layer-wise DNN training for FL (Sec. <a href="#S2.SS4" title="2.4. Layer-wise DNN Training for FL ‣ 2. Background and Related Work ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>).</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Trusted Execution Environments (TEE)</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">A TEE enables the creation of a secure area on the main processor that provides strong confidentiality and integrity guarantees to any data and code it stores or processes.
TEEs realize strong isolation and attestation of secure compartments by enforcing a dual-world view where even compromised or malicious system (i.e., privileged) software in the normal world – also known as the Rich Operating System Execution Environment (REE) – cannot gain access to the secure world.
This allows for a drastic reduction of the TCB since only the code running in the secure world needs to be trusted.
Another key aspect of TEEs is that they allow arbitrary code to run inside almost at native speed.
In order to keep the TCB as small as possible, current TEEs have limited memory; beyond this, TEEs are required to swap pages between secure and unprotected memory, which incurs a significant overhead and hence must be prevented.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Over the last few years, significant research and industry efforts have been devoted to developing secure and programmable TEEs for high-end devices (e.g., servers<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Recently, cloud providers also offer TEE-enabled infrastructure-as-a-service solutions to their customers (e.g., Microsoft Azure Confidential).</span></span></span>) and mobile devices (e.g., smartphones).
In our work, we leverage Intel Software Guard Extensions (Intel SGX) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib13" title="" class="ltx_ref">costan2016intel, </a>)</cite> at the server-side, while in the client devices we rely on Open Portable Trusted Execution Environment (OP-TEE) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib40" title="" class="ltx_ref">optee2020, </a>)</cite>.
OP-TEE is a widely known open-source TEE framework that is supported by different boards equipped with Arm TrustZone. While some TEEs allow the creation of fixed-sized secure memory regions (e.g., of 128MB in Intel SGX), some others (e.g., ARM TrustZone) do not place any limit on the TEE size. However, creating large TEEs is considered to be bad practice since it has proven to significantly increase the attack surface. Therefore, the TEE size must always be kept as small as possible independently of the type of TEEs and devices being used. This principle has already been adopted by industry, e.g., in the HiKey 960 board the TEE size is only 16MiB.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Privacy Risks in FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Below we give a brief overview of the three main categories of privacy-related attacks in FL: data reconstruction, property inference, and membership inference attacks.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Data Reconstruction Attack (DRA).</span>
The DRA aims at reconstructing original input data based on the observed model or its gradients.
It works by inverting model gradients based on generative adversarial attack-similar techniques <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib2" title="" class="ltx_ref">aono2017privacy, </a>; <a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>)</cite>, and consequently reconstructing the corresponding original data used to produce the gradients.
DRAs are effective when attacking DNN’s early layers, and when gradients have been only updated on a small batch of data (i.e., less than 8) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>; <a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite>.
As the server typically observes updated models of each client in plaintext, it is more likely for this type of leakages to exist at the server.
By subtracting updated models with the global model, the server obtains gradients computed w.r.t. clients’ data during the local training.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Property Inference Attack (PIA).</span>
The goal of PIAs is to infer the value of private properties in the input data.
This attack is achieved by building a binary classifier trained on model gradients updated with auxiliary data and can be conducted on both server and client sides <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>)</cite>.
Specifically, property information, which also refers to the feature/latent information of the input data, is easier to be carried in stronger aggregation <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib47" title="" class="ltx_ref">mo2020layer, </a>)</cite>.
Even though clients in FL only observe multiple snapshots of broadcast global models that have been linearly aggregated on participating clients’ updates, property information can still be well preserved, providing attack points to client-side adversaries.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">Membership Inference Attack (MIA).</span>
The purpose of MIAs is to learn whether specific data instances are present in the training dataset.
One can follow a similar attack mechanism as PIAs to build a binary classifier when conducting MIAs <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>)</cite>, although there are other methods, e.g., using shadow models <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib64" title="" class="ltx_ref">shokri2017membership, </a>)</cite>.
The risk of MIAs can exist on both the server and client sides.
Moreover, because membership is ‘high-level’ latent information, adversaries can perform MIAs on the final (well-trained) model and its last layer <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>; <a href="#bib.bib64" title="" class="ltx_ref">shokri2017membership, </a>; <a href="#bib.bib73" title="" class="ltx_ref">yeom2018privacy, </a>)</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Privacy-preserving ML using TEEs</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Running ML inside TEEs can hide model parameters from REE adversaries and consequently preserve privacy, as already used for light data analytics on servers <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib62" title="" class="ltx_ref">schuster2015vc3, </a>; <a href="#bib.bib54" title="" class="ltx_ref">ohrimenko2016oblivious, </a>)</cite> and for heavy computations such as DNN training <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib23" title="" class="ltx_ref">hunt2018chiron, </a>; <a href="#bib.bib70" title="" class="ltx_ref">tramer2018slalom, </a>; <a href="#bib.bib18" title="" class="ltx_ref">gu2018securing, </a>; <a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite>.
However, due to TEEs’ limited memory size, previous studies run only part of the model (e.g., sensitive layers) inside the TEE <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib70" title="" class="ltx_ref">tramer2018slalom, </a>; <a href="#bib.bib18" title="" class="ltx_ref">gu2018securing, </a>; <a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>; <a href="#bib.bib48" title="" class="ltx_ref">mo2019efficient, </a>)</cite>.
In the on-device training case, DarkneTZ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite> runs the last layers with a Trusted Application inside TEEs to defend against MIAs, and leaves the first layers unprotected.
DarkneTZ’s evaluation showed no more than 10% overhead in CPU, memory, and energy on edge-like devices, demonstrating its suitability for client-side model updates in FL.
In an orthogonal direction, several works leveraged clients’ TEEs for verifying the integrity of local model training <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">chen2019deepattest, </a>; <a href="#bib.bib75" title="" class="ltx_ref">zhang2020enabling, </a>)</cite>, but did not consider privacy.
Considering a broader range of attacks (e.g., DRAs and PIAs), it is essential to protect all layers instead of the last layers only, something that PPFL does.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Layer-wise DNN Training for FL</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Instead of training the complete DNN model in an end-to-end fashion, one can train the model layer-by-layer from scratch, i.e., <em id="S2.SS4.p1.1.1" class="ltx_emph ltx_font_italic">greedy layer-wise training</em> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib6" title="" class="ltx_ref">bengio2006greedy, </a>; <a href="#bib.bib35" title="" class="ltx_ref">larochelle2009exploring, </a>)</cite>.
This method starts by training a shallow model (e.g., one layer) until its convergence.
Next, it appends one more layer to the converged model and trains only this new layer <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">belilovsky2019greedy, </a>)</cite>.
Usually, for each greedily added layer, the model developer builds a new classifier on top of it in order to output predictions and compute training loss.
Consequently, these classifiers provide multiple early exits, one per layer, during the forward pass in inference <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib29" title="" class="ltx_ref">kaya2019shallow, </a>)</cite>.
Furthermore, recently this method was shown to scale for large datasets such as ImageNet and to achieve performance comparable to regular end-to-end ML <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">belilovsky2019greedy, </a>)</cite>.
Notably, all previous studies on layer-wise training focused on generic ML.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para ltx_noindent">
<p id="S2.SS4.p2.1" class="ltx_p"><span id="S2.SS4.p2.1.1" class="ltx_text ltx_font_bold">Contribution.</span>
Our work is the first to build a DNN model in a FL setting with privacy-preserving guarantees using TEEs, by leveraging the greedy layer-wise training, and to train each DNN layer inside each FL client’s TEE.
Thus, PPFL satisfies the constraint of TEE’s limited memory while protecting the model from the aforementioned privacy attacks.
Interestingly, the classifiers built atop each layer may also provide personalization opportunities for the participating FL clients.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Threat Model and Assumptions</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text ltx_font_bold">Threat model.</span>
We consider a standard FL context where multiple client devices train a DNN locally and send their (local) model parameters to a remote, centralized server, which aggregates these parameters to create a global model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>; <a href="#bib.bib7" title="" class="ltx_ref">bonawitz2019towards, </a>; <a href="#bib.bib27" title="" class="ltx_ref">kairouz2019advances, </a>)</cite>.
The goal of adversaries is to obtain sensitive information embedded in the global model through data reconstruction <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>)</cite> or inference attacks <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>)</cite>.
We consider two types of (passive) adversaries: (i) users of client devices who have access to distinct snapshots of the global model and (ii) the server’s owner (e.g., a cloud or edge provider) who has access to the updated model gradients.
Adversaries are assumed to be <em id="S3.p1.1.2" class="ltx_emph ltx_font_italic">honest-but-curious</em>, meaning that they allow FL algorithms to run as intended while trying to infer as much information as possible from the global model or gradients.
Adversaries can have full control (i.e., root privileges) of the server or the client device, and can perform their attacks against any DNN layer.
However, attacks against the TEE, such as side-channel attacks (e.g., Voltpillager <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib12" title="" class="ltx_ref">Chen2021voltpillager, </a>)</cite>), physical attacks (e.g., Platypus <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib41" title="" class="ltx_ref">Lipp2021Platypus, </a>)</cite>) and those that exploit weaknesses in TEEs (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib38" title="" class="ltx_ref">10.5555/3241189.3241231, </a>)</cite>) and their SDKs (e.g., <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib71" title="" class="ltx_ref">10.1145/3319535.3363206, </a>)</cite>) are out of scope for this paper.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Assumptions.</span>
We assume that the server and enough participating FL client devices have a TEE whose memory size is larger than the largest layer of the DNN to be trained.
This is the case in current FL DNNs.
However, in the unlikely case that a layer does not fit in available TEEs, the network design needs to be adjusted with smaller, but more layer(s), or a smaller training batch size.
We also assume that there is a secure way to bootstrap trust between the server TEE and each of the client device TEE (e.g., using a slightly modified version of the SIGMA key exchange protocol <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib32" title="" class="ltx_ref">krawczyk2003sigma, </a>; <a href="#bib.bib77" title="" class="ltx_ref">zhao2019sectee, </a>)</cite>, or attested TLS <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib30" title="" class="ltx_ref">knauth2018integrating, </a>)</cite>), and that key management mechanisms exist to update and revoke keys when needed <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib55" title="" class="ltx_ref">trustanchors, </a>)</cite>. Finally, we assume that the centralized server will forward data to/from its TEE. Yet, it is important to note that if the server was malicious and would not do this, this would only affect the availability of the system (i.e., the security and privacy properties of our solution remain intact). This type of Denial-of-Service (DoS) attack is hard to defend against and is not considered within the standard TEE threat model.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>PPFL Framework</h2>

<figure id="S4.F1" class="ltx_figure"><img src="/html/2104.14380/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="922" height="218" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S4.F1.3.2" class="ltx_text" style="font-size:90%;">A schematic diagram of the PPFL framework. The main phases follow the system design in <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib7" title="" class="ltx_ref">bonawitz2019towards, </a>)</cite>.</span></figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we first present an overview of the proposed system and its functionalities (Sec. <a href="#S4.SS1" title="4.1. System Overview ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), and then detail how the framework employs layer-wise training and aggregation in conjunction to TEEs in FL (Sec. <a href="#S4.SS2" title="4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>System Overview</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We propose a Privacy-preserving Federated Learning framework which allows clients to collaboratively train a DNN model while keeping the model’s layers always inside TEEs during training.
Figure <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an overview of the framework and the various steps of the <em id="S4.SS1.p1.1.1" class="ltx_emph ltx_font_italic">greedy layer-wise training and aggregation</em>.
In general, starting from the first layer, each layer is trained until convergence, before moving to the next layer.
In this way, PPFL aims to achieve full privacy preservation without significantly increasing system cost.
PPFL’s design provides the following functionalities:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Privacy-by-design Guarantee.</span>
PPFL ensures that layers are always protected from adversaries while they are being updated.
Privacy risks depend on the aggregation level and frequency with which they happen, when exposing the model or its layers <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>; <a href="#bib.bib47" title="" class="ltx_ref">mo2020layer, </a>)</cite>.
In PPFL, lower-level information (i.e., original data and attributes) is not exposed because updated gradients during training are not accessible from adversaries (they happen inside the TEEs). This protects against DRAs and PIAs.
However, when one of such layers is exposed after convergence, there is a risk of MIAs.
We follow a more practical approach based on the observation that membership-related information is only sensitive in the <em id="S4.SS1.p2.1.2" class="ltx_emph ltx_font_italic">last DNN layer</em>, making it vulnerable to MIAs as indicated in previous research <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>; <a href="#bib.bib59" title="" class="ltx_ref">sablayrolles2019white, </a>; <a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>; <a href="#bib.bib47" title="" class="ltx_ref">mo2020layer, </a>)</cite>.
To avoid this risk on the final model, PPFL can keep the last layer inside the clients TEEs after training.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Device Selection.</span> After the server and a set of TEE-enabled clients agree on the training of a DNN model via FL, clients inform the server about their TEE’s memory constraints. The server then (re)constructs a DNN model suitable for this set of clients and selects the clients that can accommodate the model layers within their TEE. In each round, the server can select new clients and the device selection algorithm can follow existing FL approaches <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib53" title="" class="ltx_ref">nishio2019client, </a>; <a href="#bib.bib21" title="" class="ltx_ref">huang2020efficiency, </a>)</cite>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Secure Communication Channels.</span> The server establishes two secure communication channels with each of its clients: (i) one from its REE to the client’s REE (e.g., using TLS) to exchange data with clients and (ii) a logical one from its TEE to the client’s TEE for securely exchanging private information (e.g., model layer training information).
In the latter case, the transmitted data is encrypted using cryptographic keys known only to the server and client TEEs and is sent over the REE-REE channel.
It is important to note that the secure REE-REE channel is only an additional security layer.
All privacy guarantees offered by PPFL are based on the hardware-backed cryptographic keys stored inside TEEs.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Model Initialization and Configuration.</span>
The server configures the model architecture, decides the layers to be protected by TEEs, and then initializes model parameters inside the TEE (step \raisebox{-.9pt} {2}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
The latter ensures clients’ local training starts with the same weight distribution <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>; <a href="#bib.bib72" title="" class="ltx_ref">wang2020federated, </a>)</cite>.
In addition, the server configures other training hyper-parameters such as learning rate, batch size, and epochs, before transmitting such settings to the clients (step \raisebox{-.9pt} {3}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">In cases of typical ML tasks such as image recognition where public knowledge is available such as pre-trained DNN models or public datasets with features similar to the client private data, the server can transfer this knowledge (especially in cross-device FL <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib27" title="" class="ltx_ref">kairouz2019advances, </a>)</cite>) in order to bootstrap and speed up the training process.
In both cases, this knowledge is contained in the first layers.
Thus, the clients leave the first layers frozen and only train the last several layers of the global model.
This training process is similar to the concept of transfer learning <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib56" title="" class="ltx_ref">pan2009survey, </a>; <a href="#bib.bib9" title="" class="ltx_ref">brownlee2019gentle, </a>; <a href="#bib.bib69" title="" class="ltx_ref">torrey2010transfer, </a>)</cite>, where, in our case, public knowledge is transferred in a federated manner.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.1" class="ltx_p">In PPFL, the server can learn from <span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_italic">public models</span>.
Thus, during initialization, the server first chooses a model pre-trained on public data that have a similar distribution with private data.
The server keeps the first layers, removes the last layer(s), and assembles new layer(s) atop the reserved first ones.
These first layers are transferred to clients and are always kept frozen (step \raisebox{-.9pt} {1}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
New layers, attached to the reserved layers, are trained inside each client’s TEE, and then aggregated inside the server’s TEE (steps \raisebox{-.9pt} {2}⃝<math id="S4.SS1.p7.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS1.p7.1.m1.1a"><mo id="S4.SS1.p7.1.m1.1.1" xref="S4.SS1.p7.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p7.1.m1.1.1.cmml" xref="S4.SS1.p7.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.1.m1.1c">\sim</annotation></semantics></math>\raisebox{-.9pt} {6}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
In learning from <span id="S4.SS1.p7.1.2" class="ltx_text ltx_font_italic">public datasets</span>, the server first performs an initial training to build the model based on public datasets.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para ltx_noindent">
<p id="S4.SS1.p8.1" class="ltx_p"><span id="S4.SS1.p8.1.1" class="ltx_text ltx_font_bold">Local Training.</span>
After model transmission and configuration using secure channels, each client starts local training on their data on each layer via a model partitioned execution technique (step \raisebox{-.9pt} {4}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
We detail this step in Sec. <a href="#S4.SS2" title="4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para ltx_noindent">
<p id="S4.SS1.p9.1" class="ltx_p"><span id="S4.SS1.p9.1.1" class="ltx_text ltx_font_bold">Reporting and Aggregation.</span>
Once local training of a layer is completed inside TEEs, all participating clients report the layer parameters to the server through secure channels (step \raisebox{-.9pt} {5}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Finally, the server securely aggregates the received parameters within its TEE and applies FedAvg <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite>, resulting in a new global model layer (step \raisebox{-.9pt} {6}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Layer-wise Training and Aggregation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In order to address the problem of limited memory inside a TEE when training a DNN model, we modify the greedy layer-wise learning technique proposed in <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib6" title="" class="ltx_ref">bengio2006greedy, </a>)</cite> for general DNN training <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">belilovsky2019greedy, </a>)</cite>, to work in the FL setting.
The procedure of layer-wise training and aggregation is detailed in the following Algorithms <a href="#algorithm1" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#algorithm2" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.7" class="ltx_p"><span id="S4.SS2.p2.7.1" class="ltx_text ltx_font_bold">Algorithm <a href="#algorithm1" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</span>
This algorithm details the actions taken by PPFL on the server side.
When not specified, operations are carried out outside the TEE (i.e., in the REE).
First, the server initializes the global DNN model with random weights or public knowledge (steps \raisebox{-.9pt} {1}⃝-\raisebox{-.9pt} {2}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Thus, each layer <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">l</annotation></semantics></math> to be trained is initialized (<math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">𝜽</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝜽</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\bm{\theta}_{l}</annotation></semantics></math>) and prepared for broadcast.
The server checks all available devices and constructs a set of participating clients whose TEE is larger than the required memory usage of <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mi id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><ci id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">l</annotation></semantics></math>.
Then, it broadcasts the model’s layer to these participating clients (step \raisebox{-.9pt} {3}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), via <span id="S4.SS2.p2.7.2" class="ltx_text ltx_font_typewriter">ClientUpdate()</span> (see Algorithm <a href="#algorithm2" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
Upon receiving updates from all participating clients, the server decrypts the layer weights, performs secure layer aggregation and averaging inside its TEE (step \raisebox{-.9pt} {6}⃝), and broadcasts the new version of <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mi id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><ci id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">l</annotation></semantics></math> to the clients for the next FL round.
Steps \raisebox{-.9pt} {2}⃝<math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><mo id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><csymbol cd="latexml" id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">\sim</annotation></semantics></math>\raisebox{-.9pt} {6}⃝ are repeated until the training of <math id="S4.SS2.p2.6.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p2.6.m6.1a"><mi id="S4.SS2.p2.6.m6.1.1" xref="S4.SS2.p2.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m6.1b"><ci id="S4.SS2.p2.6.m6.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m6.1c">l</annotation></semantics></math> converges, or a fixed number of rounds are completed.
Then, this layer is considered fully trained (<math id="S4.SS2.p2.7.m7.1" class="ltx_Math" alttext="\bm{\theta}_{l}^{0}" display="inline"><semantics id="S4.SS2.p2.7.m7.1a"><msubsup id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml"><mi id="S4.SS2.p2.7.m7.1.1.2.2" xref="S4.SS2.p2.7.m7.1.1.2.2.cmml">𝜽</mi><mi id="S4.SS2.p2.7.m7.1.1.2.3" xref="S4.SS2.p2.7.m7.1.1.2.3.cmml">l</mi><mn id="S4.SS2.p2.7.m7.1.1.3" xref="S4.SS2.p2.7.m7.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.1b"><apply id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m7.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1">superscript</csymbol><apply id="S4.SS2.p2.7.m7.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m7.1.1.2.1.cmml" xref="S4.SS2.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.p2.7.m7.1.1.2.2.cmml" xref="S4.SS2.p2.7.m7.1.1.2.2">𝜽</ci><ci id="S4.SS2.p2.7.m7.1.1.2.3.cmml" xref="S4.SS2.p2.7.m7.1.1.2.3">𝑙</ci></apply><cn type="integer" id="S4.SS2.p2.7.m7.1.1.3.cmml" xref="S4.SS2.p2.7.m7.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.1c">\bm{\theta}_{l}^{0}</annotation></semantics></math>), it is passed to the REE, and is broadcasted to all clients to be used for training the next layer.
Interestingly, PPFL also allows grouping <em id="S4.SS2.p2.7.3" class="ltx_emph ltx_font_italic">multiple layers into blocks</em> and training each block inside client TEEs in a similar fashion as the individual layers.
This option allows for better utilization of the memory space available inside each TEE and reduces communication rounds for the convergence of more than one layer at the same time.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.3" class="ltx_p"><span id="S4.SS2.p3.3.1" class="ltx_text ltx_font_bold">Algorithm <a href="#algorithm2" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></span>.
This algorithm details the actions taken by PPFL on the client side.
Clients load the received model parameters from the server and decrypt and load the target training layer <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">l</annotation></semantics></math> inside their TEEs.
More specifically, in the front, this new layer <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">l</annotation></semantics></math> connects to the previous pre-trained layer(s) that are frozen during training.
In the back, the clients attach on <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">l</annotation></semantics></math> their <em id="S4.SS2.p3.3.2" class="ltx_emph ltx_font_italic">own derived classifier</em>, which consists of fully connected layers and a softmax layer as the model exit.
Then, for each epoch, the training process iteratively goes through batches of data and performs both <em id="S4.SS2.p3.3.3" class="ltx_emph ltx_font_italic">forward and backward passes</em> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib36" title="" class="ltx_ref">lecun2015deep, </a>)</cite> to update both the layer under training and the classifier inside the TEE (step \raisebox{-.9pt} {4}⃝, Fig. <a href="#S4.F1" title="Figure 1 ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
During this process, a <em id="S4.SS2.p3.3.4" class="ltx_emph ltx_font_italic">model partitioned execution</em> technique is utilized, where intermediate representations of the previously trained layers are passed from the REE to the TEE via shared memory in the forward pass.
After local training is completed (i.e., all batches and epochs are done), each client sends via the secure channel the (encrypted) layer’s weights from its TEE to the server’s TEE (step \raisebox{-.9pt} {5}⃝).</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.17" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.17.18" class="ltx_listingline">
<span id="algorithm1.17.18.1" class="ltx_text ltx_font_bold">Input:</span>
</div>
<div id="algorithm1.1.1" class="ltx_listingline">

<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Number of all clients: <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mi id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">N</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.2" class="ltx_p">TEE memory size of Client <math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">n</annotation></semantics></math>: <math id="S4.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="S^{(n)}" display="inline"><semantics id="S4.I1.i2.p1.2.m2.1a"><msup id="S4.I1.i2.p1.2.m2.1.2" xref="S4.I1.i2.p1.2.m2.1.2.cmml"><mi id="S4.I1.i2.p1.2.m2.1.2.2" xref="S4.I1.i2.p1.2.m2.1.2.2.cmml">S</mi><mrow id="S4.I1.i2.p1.2.m2.1.1.1.3" xref="S4.I1.i2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S4.I1.i2.p1.2.m2.1.1.1.3.1" xref="S4.I1.i2.p1.2.m2.1.2.cmml">(</mo><mi id="S4.I1.i2.p1.2.m2.1.1.1.1" xref="S4.I1.i2.p1.2.m2.1.1.1.1.cmml">n</mi><mo stretchy="false" id="S4.I1.i2.p1.2.m2.1.1.1.3.2" xref="S4.I1.i2.p1.2.m2.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b"><apply id="S4.I1.i2.p1.2.m2.1.2.cmml" xref="S4.I1.i2.p1.2.m2.1.2"><csymbol cd="ambiguous" id="S4.I1.i2.p1.2.m2.1.2.1.cmml" xref="S4.I1.i2.p1.2.m2.1.2">superscript</csymbol><ci id="S4.I1.i2.p1.2.m2.1.2.2.cmml" xref="S4.I1.i2.p1.2.m2.1.2.2">𝑆</ci><ci id="S4.I1.i2.p1.2.m2.1.1.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">S^{(n)}</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.2" class="ltx_p">Memory usage of layers <math id="S4.I1.i3.p1.1.m1.3" class="ltx_Math" alttext="\{1,...,L\}" display="inline"><semantics id="S4.I1.i3.p1.1.m1.3a"><mrow id="S4.I1.i3.p1.1.m1.3.4.2" xref="S4.I1.i3.p1.1.m1.3.4.1.cmml"><mo stretchy="false" id="S4.I1.i3.p1.1.m1.3.4.2.1" xref="S4.I1.i3.p1.1.m1.3.4.1.cmml">{</mo><mn id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml">1</mn><mo id="S4.I1.i3.p1.1.m1.3.4.2.2" xref="S4.I1.i3.p1.1.m1.3.4.1.cmml">,</mo><mi mathvariant="normal" id="S4.I1.i3.p1.1.m1.2.2" xref="S4.I1.i3.p1.1.m1.2.2.cmml">…</mi><mo id="S4.I1.i3.p1.1.m1.3.4.2.3" xref="S4.I1.i3.p1.1.m1.3.4.1.cmml">,</mo><mi id="S4.I1.i3.p1.1.m1.3.3" xref="S4.I1.i3.p1.1.m1.3.3.cmml">L</mi><mo stretchy="false" id="S4.I1.i3.p1.1.m1.3.4.2.4" xref="S4.I1.i3.p1.1.m1.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.3b"><set id="S4.I1.i3.p1.1.m1.3.4.1.cmml" xref="S4.I1.i3.p1.1.m1.3.4.2"><cn type="integer" id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">1</cn><ci id="S4.I1.i3.p1.1.m1.2.2.cmml" xref="S4.I1.i3.p1.1.m1.2.2">…</ci><ci id="S4.I1.i3.p1.1.m1.3.3.cmml" xref="S4.I1.i3.p1.1.m1.3.3">𝐿</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.3c">\{1,...,L\}</annotation></semantics></math> in training (forward and backward pass in total): <math id="S4.I1.i3.p1.2.m2.3" class="ltx_Math" alttext="\{S_{1},...,S_{L}\}" display="inline"><semantics id="S4.I1.i3.p1.2.m2.3a"><mrow id="S4.I1.i3.p1.2.m2.3.3.2" xref="S4.I1.i3.p1.2.m2.3.3.3.cmml"><mo stretchy="false" id="S4.I1.i3.p1.2.m2.3.3.2.3" xref="S4.I1.i3.p1.2.m2.3.3.3.cmml">{</mo><msub id="S4.I1.i3.p1.2.m2.2.2.1.1" xref="S4.I1.i3.p1.2.m2.2.2.1.1.cmml"><mi id="S4.I1.i3.p1.2.m2.2.2.1.1.2" xref="S4.I1.i3.p1.2.m2.2.2.1.1.2.cmml">S</mi><mn id="S4.I1.i3.p1.2.m2.2.2.1.1.3" xref="S4.I1.i3.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.I1.i3.p1.2.m2.3.3.2.4" xref="S4.I1.i3.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S4.I1.i3.p1.2.m2.1.1" xref="S4.I1.i3.p1.2.m2.1.1.cmml">…</mi><mo id="S4.I1.i3.p1.2.m2.3.3.2.5" xref="S4.I1.i3.p1.2.m2.3.3.3.cmml">,</mo><msub id="S4.I1.i3.p1.2.m2.3.3.2.2" xref="S4.I1.i3.p1.2.m2.3.3.2.2.cmml"><mi id="S4.I1.i3.p1.2.m2.3.3.2.2.2" xref="S4.I1.i3.p1.2.m2.3.3.2.2.2.cmml">S</mi><mi id="S4.I1.i3.p1.2.m2.3.3.2.2.3" xref="S4.I1.i3.p1.2.m2.3.3.2.2.3.cmml">L</mi></msub><mo stretchy="false" id="S4.I1.i3.p1.2.m2.3.3.2.6" xref="S4.I1.i3.p1.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.2.m2.3b"><set id="S4.I1.i3.p1.2.m2.3.3.3.cmml" xref="S4.I1.i3.p1.2.m2.3.3.2"><apply id="S4.I1.i3.p1.2.m2.2.2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.I1.i3.p1.2.m2.2.2.1.1.1.cmml" xref="S4.I1.i3.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S4.I1.i3.p1.2.m2.2.2.1.1.2.cmml" xref="S4.I1.i3.p1.2.m2.2.2.1.1.2">𝑆</ci><cn type="integer" id="S4.I1.i3.p1.2.m2.2.2.1.1.3.cmml" xref="S4.I1.i3.p1.2.m2.2.2.1.1.3">1</cn></apply><ci id="S4.I1.i3.p1.2.m2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1">…</ci><apply id="S4.I1.i3.p1.2.m2.3.3.2.2.cmml" xref="S4.I1.i3.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S4.I1.i3.p1.2.m2.3.3.2.2.1.cmml" xref="S4.I1.i3.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S4.I1.i3.p1.2.m2.3.3.2.2.2.cmml" xref="S4.I1.i3.p1.2.m2.3.3.2.2.2">𝑆</ci><ci id="S4.I1.i3.p1.2.m2.3.3.2.2.3.cmml" xref="S4.I1.i3.p1.2.m2.3.3.2.2.3">𝐿</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.2.m2.3c">\{S_{1},...,S_{L}\}</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Communication rounds: <math id="S4.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.I1.i4.p1.1.m1.1a"><mi id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><ci id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">R</annotation></semantics></math></p>
</div>
</li>
</ul>
<span id="algorithm1.1.1.1" class="ltx_text ltx_font_bold">Output:</span> Aggregated final parameters: <math id="algorithm1.1.1.m1.3" class="ltx_Math" alttext="\{\bm{\theta}_{1}^{0},...,\bm{\theta}_{L}^{0}\}" display="inline"><semantics id="algorithm1.1.1.m1.3a"><mrow id="algorithm1.1.1.m1.3.3.2" xref="algorithm1.1.1.m1.3.3.3.cmml"><mo stretchy="false" id="algorithm1.1.1.m1.3.3.2.3" xref="algorithm1.1.1.m1.3.3.3.cmml">{</mo><msubsup id="algorithm1.1.1.m1.2.2.1.1" xref="algorithm1.1.1.m1.2.2.1.1.cmml"><mi id="algorithm1.1.1.m1.2.2.1.1.2.2" xref="algorithm1.1.1.m1.2.2.1.1.2.2.cmml">𝜽</mi><mn id="algorithm1.1.1.m1.2.2.1.1.2.3" xref="algorithm1.1.1.m1.2.2.1.1.2.3.cmml">1</mn><mn id="algorithm1.1.1.m1.2.2.1.1.3" xref="algorithm1.1.1.m1.2.2.1.1.3.cmml">0</mn></msubsup><mo id="algorithm1.1.1.m1.3.3.2.4" xref="algorithm1.1.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="algorithm1.1.1.m1.1.1" xref="algorithm1.1.1.m1.1.1.cmml">…</mi><mo id="algorithm1.1.1.m1.3.3.2.5" xref="algorithm1.1.1.m1.3.3.3.cmml">,</mo><msubsup id="algorithm1.1.1.m1.3.3.2.2" xref="algorithm1.1.1.m1.3.3.2.2.cmml"><mi id="algorithm1.1.1.m1.3.3.2.2.2.2" xref="algorithm1.1.1.m1.3.3.2.2.2.2.cmml">𝜽</mi><mi id="algorithm1.1.1.m1.3.3.2.2.2.3" xref="algorithm1.1.1.m1.3.3.2.2.2.3.cmml">L</mi><mn id="algorithm1.1.1.m1.3.3.2.2.3" xref="algorithm1.1.1.m1.3.3.2.2.3.cmml">0</mn></msubsup><mo stretchy="false" id="algorithm1.1.1.m1.3.3.2.6" xref="algorithm1.1.1.m1.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.3b"><set id="algorithm1.1.1.m1.3.3.3.cmml" xref="algorithm1.1.1.m1.3.3.2"><apply id="algorithm1.1.1.m1.2.2.1.1.cmml" xref="algorithm1.1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.1.1.m1.2.2.1.1.1.cmml" xref="algorithm1.1.1.m1.2.2.1.1">superscript</csymbol><apply id="algorithm1.1.1.m1.2.2.1.1.2.cmml" xref="algorithm1.1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.1.1.m1.2.2.1.1.2.1.cmml" xref="algorithm1.1.1.m1.2.2.1.1">subscript</csymbol><ci id="algorithm1.1.1.m1.2.2.1.1.2.2.cmml" xref="algorithm1.1.1.m1.2.2.1.1.2.2">𝜽</ci><cn type="integer" id="algorithm1.1.1.m1.2.2.1.1.2.3.cmml" xref="algorithm1.1.1.m1.2.2.1.1.2.3">1</cn></apply><cn type="integer" id="algorithm1.1.1.m1.2.2.1.1.3.cmml" xref="algorithm1.1.1.m1.2.2.1.1.3">0</cn></apply><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">…</ci><apply id="algorithm1.1.1.m1.3.3.2.2.cmml" xref="algorithm1.1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.1.1.m1.3.3.2.2.1.cmml" xref="algorithm1.1.1.m1.3.3.2.2">superscript</csymbol><apply id="algorithm1.1.1.m1.3.3.2.2.2.cmml" xref="algorithm1.1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.1.1.m1.3.3.2.2.2.1.cmml" xref="algorithm1.1.1.m1.3.3.2.2">subscript</csymbol><ci id="algorithm1.1.1.m1.3.3.2.2.2.2.cmml" xref="algorithm1.1.1.m1.3.3.2.2.2.2">𝜽</ci><ci id="algorithm1.1.1.m1.3.3.2.2.2.3.cmml" xref="algorithm1.1.1.m1.3.3.2.2.2.3">𝐿</ci></apply><cn type="integer" id="algorithm1.1.1.m1.3.3.2.2.3.cmml" xref="algorithm1.1.1.m1.3.3.2.2.3">0</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.3c">\{\bm{\theta}_{1}^{0},...,\bm{\theta}_{L}^{0}\}</annotation></semantics></math>
</div>
<div id="algorithm1.17.19" class="ltx_listingline">

% <em id="algorithm1.17.19.1" class="ltx_emph ltx_font_italic">Layer-wise client updates</em> 
</div>
<div id="algorithm1.2.2" class="ltx_listingline">
<span id="algorithm1.2.2.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.2.2.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.2.2.1.m1.3" class="ltx_Math" alttext="l\in\{1,...,L\}" display="inline"><semantics id="algorithm1.2.2.1.m1.3a"><mrow id="algorithm1.2.2.1.m1.3.4" xref="algorithm1.2.2.1.m1.3.4.cmml"><mi id="algorithm1.2.2.1.m1.3.4.2" xref="algorithm1.2.2.1.m1.3.4.2.cmml">l</mi><mo id="algorithm1.2.2.1.m1.3.4.1" xref="algorithm1.2.2.1.m1.3.4.1.cmml">∈</mo><mrow id="algorithm1.2.2.1.m1.3.4.3.2" xref="algorithm1.2.2.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="algorithm1.2.2.1.m1.3.4.3.2.1" xref="algorithm1.2.2.1.m1.3.4.3.1.cmml">{</mo><mn id="algorithm1.2.2.1.m1.1.1" xref="algorithm1.2.2.1.m1.1.1.cmml">1</mn><mo id="algorithm1.2.2.1.m1.3.4.3.2.2" xref="algorithm1.2.2.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="algorithm1.2.2.1.m1.2.2" xref="algorithm1.2.2.1.m1.2.2.cmml">…</mi><mo id="algorithm1.2.2.1.m1.3.4.3.2.3" xref="algorithm1.2.2.1.m1.3.4.3.1.cmml">,</mo><mi id="algorithm1.2.2.1.m1.3.3" xref="algorithm1.2.2.1.m1.3.3.cmml">L</mi><mo stretchy="false" id="algorithm1.2.2.1.m1.3.4.3.2.4" xref="algorithm1.2.2.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.1.m1.3b"><apply id="algorithm1.2.2.1.m1.3.4.cmml" xref="algorithm1.2.2.1.m1.3.4"><in id="algorithm1.2.2.1.m1.3.4.1.cmml" xref="algorithm1.2.2.1.m1.3.4.1"></in><ci id="algorithm1.2.2.1.m1.3.4.2.cmml" xref="algorithm1.2.2.1.m1.3.4.2">𝑙</ci><set id="algorithm1.2.2.1.m1.3.4.3.1.cmml" xref="algorithm1.2.2.1.m1.3.4.3.2"><cn type="integer" id="algorithm1.2.2.1.m1.1.1.cmml" xref="algorithm1.2.2.1.m1.1.1">1</cn><ci id="algorithm1.2.2.1.m1.2.2.cmml" xref="algorithm1.2.2.1.m1.2.2">…</ci><ci id="algorithm1.2.2.1.m1.3.3.cmml" xref="algorithm1.2.2.1.m1.3.3">𝐿</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.1.m1.3c">l\in\{1,...,L\}</annotation></semantics></math></em> <span id="algorithm1.2.2.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.17.20" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

% <em id="algorithm1.17.20.1" class="ltx_emph ltx_font_italic">Select clients with enough TEE memory</em>
</div>
<div id="algorithm1.3.3" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Initialize participating client list <math id="algorithm1.3.3.m1.1" class="ltx_Math" alttext="\mathbf{J}=\{\}" display="inline"><semantics id="algorithm1.3.3.m1.1a"><mrow id="algorithm1.3.3.m1.1.1" xref="algorithm1.3.3.m1.1.1.cmml"><mi id="algorithm1.3.3.m1.1.1.2" xref="algorithm1.3.3.m1.1.1.2.cmml">𝐉</mi><mo id="algorithm1.3.3.m1.1.1.1" xref="algorithm1.3.3.m1.1.1.1.cmml">=</mo><mrow id="algorithm1.3.3.m1.1.1.3.2" xref="algorithm1.3.3.m1.1.1.cmml"><mo stretchy="false" id="algorithm1.3.3.m1.1.1.3.2.1" xref="algorithm1.3.3.m1.1.1.3.1.cmml">{</mo><mo stretchy="false" id="algorithm1.3.3.m1.1.1.3.2.2" xref="algorithm1.3.3.m1.1.1.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m1.1b"><apply id="algorithm1.3.3.m1.1.1.cmml" xref="algorithm1.3.3.m1.1.1"><eq id="algorithm1.3.3.m1.1.1.1.cmml" xref="algorithm1.3.3.m1.1.1.1"></eq><ci id="algorithm1.3.3.m1.1.1.2.cmml" xref="algorithm1.3.3.m1.1.1.2">𝐉</ci><list id="algorithm1.3.3.m1.1.1.3.1.cmml" xref="algorithm1.3.3.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m1.1c">\mathbf{J}=\{\}</annotation></semantics></math> 
</div>
<div id="algorithm1.4.4" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.4.4.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.4.4.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.4.4.1.m1.3" class="ltx_Math" alttext="n\in\{1,...,N\}" display="inline"><semantics id="algorithm1.4.4.1.m1.3a"><mrow id="algorithm1.4.4.1.m1.3.4" xref="algorithm1.4.4.1.m1.3.4.cmml"><mi id="algorithm1.4.4.1.m1.3.4.2" xref="algorithm1.4.4.1.m1.3.4.2.cmml">n</mi><mo id="algorithm1.4.4.1.m1.3.4.1" xref="algorithm1.4.4.1.m1.3.4.1.cmml">∈</mo><mrow id="algorithm1.4.4.1.m1.3.4.3.2" xref="algorithm1.4.4.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="algorithm1.4.4.1.m1.3.4.3.2.1" xref="algorithm1.4.4.1.m1.3.4.3.1.cmml">{</mo><mn id="algorithm1.4.4.1.m1.1.1" xref="algorithm1.4.4.1.m1.1.1.cmml">1</mn><mo id="algorithm1.4.4.1.m1.3.4.3.2.2" xref="algorithm1.4.4.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="algorithm1.4.4.1.m1.2.2" xref="algorithm1.4.4.1.m1.2.2.cmml">…</mi><mo id="algorithm1.4.4.1.m1.3.4.3.2.3" xref="algorithm1.4.4.1.m1.3.4.3.1.cmml">,</mo><mi id="algorithm1.4.4.1.m1.3.3" xref="algorithm1.4.4.1.m1.3.3.cmml">N</mi><mo stretchy="false" id="algorithm1.4.4.1.m1.3.4.3.2.4" xref="algorithm1.4.4.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.1.m1.3b"><apply id="algorithm1.4.4.1.m1.3.4.cmml" xref="algorithm1.4.4.1.m1.3.4"><in id="algorithm1.4.4.1.m1.3.4.1.cmml" xref="algorithm1.4.4.1.m1.3.4.1"></in><ci id="algorithm1.4.4.1.m1.3.4.2.cmml" xref="algorithm1.4.4.1.m1.3.4.2">𝑛</ci><set id="algorithm1.4.4.1.m1.3.4.3.1.cmml" xref="algorithm1.4.4.1.m1.3.4.3.2"><cn type="integer" id="algorithm1.4.4.1.m1.1.1.cmml" xref="algorithm1.4.4.1.m1.1.1">1</cn><ci id="algorithm1.4.4.1.m1.2.2.cmml" xref="algorithm1.4.4.1.m1.2.2">…</ci><ci id="algorithm1.4.4.1.m1.3.3.cmml" xref="algorithm1.4.4.1.m1.3.3">𝑁</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.1.m1.3c">n\in\{1,...,N\}</annotation></semantics></math></em> <span id="algorithm1.4.4.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.6.6" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.6.6.3" class="ltx_text ltx_font_bold">if</span> <em id="algorithm1.6.6.2" class="ltx_emph ltx_font_italic"><math id="algorithm1.5.5.1.m1.1" class="ltx_Math" alttext="S^{(n)}" display="inline"><semantics id="algorithm1.5.5.1.m1.1a"><msup id="algorithm1.5.5.1.m1.1.2" xref="algorithm1.5.5.1.m1.1.2.cmml"><mi id="algorithm1.5.5.1.m1.1.2.2" xref="algorithm1.5.5.1.m1.1.2.2.cmml">S</mi><mrow id="algorithm1.5.5.1.m1.1.1.1.3" xref="algorithm1.5.5.1.m1.1.2.cmml"><mo stretchy="false" id="algorithm1.5.5.1.m1.1.1.1.3.1" xref="algorithm1.5.5.1.m1.1.2.cmml">(</mo><mi id="algorithm1.5.5.1.m1.1.1.1.1" xref="algorithm1.5.5.1.m1.1.1.1.1.cmml">n</mi><mo stretchy="false" id="algorithm1.5.5.1.m1.1.1.1.3.2" xref="algorithm1.5.5.1.m1.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.1.m1.1b"><apply id="algorithm1.5.5.1.m1.1.2.cmml" xref="algorithm1.5.5.1.m1.1.2"><csymbol cd="ambiguous" id="algorithm1.5.5.1.m1.1.2.1.cmml" xref="algorithm1.5.5.1.m1.1.2">superscript</csymbol><ci id="algorithm1.5.5.1.m1.1.2.2.cmml" xref="algorithm1.5.5.1.m1.1.2.2">𝑆</ci><ci id="algorithm1.5.5.1.m1.1.1.1.1.cmml" xref="algorithm1.5.5.1.m1.1.1.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.1.m1.1c">S^{(n)}</annotation></semantics></math> ¿ <math id="algorithm1.6.6.2.m2.1" class="ltx_Math" alttext="S_{l}" display="inline"><semantics id="algorithm1.6.6.2.m2.1a"><msub id="algorithm1.6.6.2.m2.1.1" xref="algorithm1.6.6.2.m2.1.1.cmml"><mi id="algorithm1.6.6.2.m2.1.1.2" xref="algorithm1.6.6.2.m2.1.1.2.cmml">S</mi><mi id="algorithm1.6.6.2.m2.1.1.3" xref="algorithm1.6.6.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.2.m2.1b"><apply id="algorithm1.6.6.2.m2.1.1.cmml" xref="algorithm1.6.6.2.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.6.6.2.m2.1.1.1.cmml" xref="algorithm1.6.6.2.m2.1.1">subscript</csymbol><ci id="algorithm1.6.6.2.m2.1.1.2.cmml" xref="algorithm1.6.6.2.m2.1.1.2">𝑆</ci><ci id="algorithm1.6.6.2.m2.1.1.3.cmml" xref="algorithm1.6.6.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.2.m2.1c">S_{l}</annotation></semantics></math></em> <span id="algorithm1.6.6.4" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm1.7.7" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.7.7.m1.1" class="ltx_Math" alttext="\mathbf{J}\xleftarrow{}\mathbf{J}\cup\{n\}" display="inline"><semantics id="algorithm1.7.7.m1.1a"><mrow id="algorithm1.7.7.m1.1.2" xref="algorithm1.7.7.m1.1.2.cmml"><mi id="algorithm1.7.7.m1.1.2.2" xref="algorithm1.7.7.m1.1.2.2.cmml">𝐉</mi><mover accent="true" id="algorithm1.7.7.m1.1.2.1" xref="algorithm1.7.7.m1.1.2.1.cmml"><mo stretchy="false" id="algorithm1.7.7.m1.1.2.1.2" xref="algorithm1.7.7.m1.1.2.1.2.cmml">←</mo><mi id="algorithm1.7.7.m1.1.2.1.1" xref="algorithm1.7.7.m1.1.2.1.1.cmml"></mi></mover><mrow id="algorithm1.7.7.m1.1.2.3" xref="algorithm1.7.7.m1.1.2.3.cmml"><mi id="algorithm1.7.7.m1.1.2.3.2" xref="algorithm1.7.7.m1.1.2.3.2.cmml">𝐉</mi><mo id="algorithm1.7.7.m1.1.2.3.1" xref="algorithm1.7.7.m1.1.2.3.1.cmml">∪</mo><mrow id="algorithm1.7.7.m1.1.2.3.3.2" xref="algorithm1.7.7.m1.1.2.3.3.1.cmml"><mo stretchy="false" id="algorithm1.7.7.m1.1.2.3.3.2.1" xref="algorithm1.7.7.m1.1.2.3.3.1.cmml">{</mo><mi id="algorithm1.7.7.m1.1.1" xref="algorithm1.7.7.m1.1.1.cmml">n</mi><mo stretchy="false" id="algorithm1.7.7.m1.1.2.3.3.2.2" xref="algorithm1.7.7.m1.1.2.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m1.1b"><apply id="algorithm1.7.7.m1.1.2.cmml" xref="algorithm1.7.7.m1.1.2"><apply id="algorithm1.7.7.m1.1.2.1.cmml" xref="algorithm1.7.7.m1.1.2.1"><csymbol cd="latexml" id="algorithm1.7.7.m1.1.2.1.1.cmml" xref="algorithm1.7.7.m1.1.2.1.1">absent</csymbol><ci id="algorithm1.7.7.m1.1.2.1.2.cmml" xref="algorithm1.7.7.m1.1.2.1.2">←</ci></apply><ci id="algorithm1.7.7.m1.1.2.2.cmml" xref="algorithm1.7.7.m1.1.2.2">𝐉</ci><apply id="algorithm1.7.7.m1.1.2.3.cmml" xref="algorithm1.7.7.m1.1.2.3"><union id="algorithm1.7.7.m1.1.2.3.1.cmml" xref="algorithm1.7.7.m1.1.2.3.1"></union><ci id="algorithm1.7.7.m1.1.2.3.2.cmml" xref="algorithm1.7.7.m1.1.2.3.2">𝐉</ci><set id="algorithm1.7.7.m1.1.2.3.3.1.cmml" xref="algorithm1.7.7.m1.1.2.3.3.2"><ci id="algorithm1.7.7.m1.1.1.cmml" xref="algorithm1.7.7.m1.1.1">𝑛</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m1.1c">\mathbf{J}\xleftarrow{}\mathbf{J}\cup\{n\}</annotation></semantics></math>

</div>
<div id="algorithm1.9.9" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Initialize <math id="algorithm1.8.8.m1.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="algorithm1.8.8.m1.1a"><msub id="algorithm1.8.8.m1.1.1" xref="algorithm1.8.8.m1.1.1.cmml"><mi id="algorithm1.8.8.m1.1.1.2" xref="algorithm1.8.8.m1.1.1.2.cmml">𝜽</mi><mi id="algorithm1.8.8.m1.1.1.3" xref="algorithm1.8.8.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.1b"><apply id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.8.8.m1.1.1.1.cmml" xref="algorithm1.8.8.m1.1.1">subscript</csymbol><ci id="algorithm1.8.8.m1.1.1.2.cmml" xref="algorithm1.8.8.m1.1.1.2">𝜽</ci><ci id="algorithm1.8.8.m1.1.1.3.cmml" xref="algorithm1.8.8.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.1c">\bm{\theta}_{l}</annotation></semantics></math> (parameters of layers <math id="algorithm1.9.9.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="algorithm1.9.9.m2.1a"><mi id="algorithm1.9.9.m2.1.1" xref="algorithm1.9.9.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.m2.1b"><ci id="algorithm1.9.9.m2.1.1.cmml" xref="algorithm1.9.9.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.m2.1c">l</annotation></semantics></math>) <span id="algorithm1.9.9.1" class="ltx_text" style="color:#228B22;">in TEE</span>
</div>
<div id="algorithm1.10.10" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

<span id="algorithm1.10.10.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.10.10.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.10.10.1.m1.3" class="ltx_Math" alttext="r\in\{1,...,R\}" display="inline"><semantics id="algorithm1.10.10.1.m1.3a"><mrow id="algorithm1.10.10.1.m1.3.4" xref="algorithm1.10.10.1.m1.3.4.cmml"><mi id="algorithm1.10.10.1.m1.3.4.2" xref="algorithm1.10.10.1.m1.3.4.2.cmml">r</mi><mo id="algorithm1.10.10.1.m1.3.4.1" xref="algorithm1.10.10.1.m1.3.4.1.cmml">∈</mo><mrow id="algorithm1.10.10.1.m1.3.4.3.2" xref="algorithm1.10.10.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="algorithm1.10.10.1.m1.3.4.3.2.1" xref="algorithm1.10.10.1.m1.3.4.3.1.cmml">{</mo><mn id="algorithm1.10.10.1.m1.1.1" xref="algorithm1.10.10.1.m1.1.1.cmml">1</mn><mo id="algorithm1.10.10.1.m1.3.4.3.2.2" xref="algorithm1.10.10.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="algorithm1.10.10.1.m1.2.2" xref="algorithm1.10.10.1.m1.2.2.cmml">…</mi><mo id="algorithm1.10.10.1.m1.3.4.3.2.3" xref="algorithm1.10.10.1.m1.3.4.3.1.cmml">,</mo><mi id="algorithm1.10.10.1.m1.3.3" xref="algorithm1.10.10.1.m1.3.3.cmml">R</mi><mo stretchy="false" id="algorithm1.10.10.1.m1.3.4.3.2.4" xref="algorithm1.10.10.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.1.m1.3b"><apply id="algorithm1.10.10.1.m1.3.4.cmml" xref="algorithm1.10.10.1.m1.3.4"><in id="algorithm1.10.10.1.m1.3.4.1.cmml" xref="algorithm1.10.10.1.m1.3.4.1"></in><ci id="algorithm1.10.10.1.m1.3.4.2.cmml" xref="algorithm1.10.10.1.m1.3.4.2">𝑟</ci><set id="algorithm1.10.10.1.m1.3.4.3.1.cmml" xref="algorithm1.10.10.1.m1.3.4.3.2"><cn type="integer" id="algorithm1.10.10.1.m1.1.1.cmml" xref="algorithm1.10.10.1.m1.1.1">1</cn><ci id="algorithm1.10.10.1.m1.2.2.cmml" xref="algorithm1.10.10.1.m1.2.2">…</ci><ci id="algorithm1.10.10.1.m1.3.3.cmml" xref="algorithm1.10.10.1.m1.3.3">𝑅</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.1.m1.3c">r\in\{1,...,R\}</annotation></semantics></math></em> <span id="algorithm1.10.10.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.11.11" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.11.11.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.11.11.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.11.11.1.m1.1" class="ltx_Math" alttext="j\in\mathbf{J}" display="inline"><semantics id="algorithm1.11.11.1.m1.1a"><mrow id="algorithm1.11.11.1.m1.1.1" xref="algorithm1.11.11.1.m1.1.1.cmml"><mi id="algorithm1.11.11.1.m1.1.1.2" xref="algorithm1.11.11.1.m1.1.1.2.cmml">j</mi><mo id="algorithm1.11.11.1.m1.1.1.1" xref="algorithm1.11.11.1.m1.1.1.1.cmml">∈</mo><mi id="algorithm1.11.11.1.m1.1.1.3" xref="algorithm1.11.11.1.m1.1.1.3.cmml">𝐉</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.1.m1.1b"><apply id="algorithm1.11.11.1.m1.1.1.cmml" xref="algorithm1.11.11.1.m1.1.1"><in id="algorithm1.11.11.1.m1.1.1.1.cmml" xref="algorithm1.11.11.1.m1.1.1.1"></in><ci id="algorithm1.11.11.1.m1.1.1.2.cmml" xref="algorithm1.11.11.1.m1.1.1.2">𝑗</ci><ci id="algorithm1.11.11.1.m1.1.1.3.cmml" xref="algorithm1.11.11.1.m1.1.1.3">𝐉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.1.m1.1c">j\in\mathbf{J}</annotation></semantics></math></em> <span id="algorithm1.11.11.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.17.21" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

% <em id="algorithm1.17.21.1" class="ltx_emph ltx_font_italic">clients’ local updating: see Algorithm 2</em> 
</div>
<div id="algorithm1.13.13" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.12.12.m1.1" class="ltx_Math" alttext="\bm{\theta}_{l}^{(j)}" display="inline"><semantics id="algorithm1.12.12.m1.1a"><msubsup id="algorithm1.12.12.m1.1.2" xref="algorithm1.12.12.m1.1.2.cmml"><mi id="algorithm1.12.12.m1.1.2.2.2" xref="algorithm1.12.12.m1.1.2.2.2.cmml">𝜽</mi><mi id="algorithm1.12.12.m1.1.2.2.3" xref="algorithm1.12.12.m1.1.2.2.3.cmml">l</mi><mrow id="algorithm1.12.12.m1.1.1.1.3" xref="algorithm1.12.12.m1.1.2.cmml"><mo stretchy="false" id="algorithm1.12.12.m1.1.1.1.3.1" xref="algorithm1.12.12.m1.1.2.cmml">(</mo><mi id="algorithm1.12.12.m1.1.1.1.1" xref="algorithm1.12.12.m1.1.1.1.1.cmml">j</mi><mo stretchy="false" id="algorithm1.12.12.m1.1.1.1.3.2" xref="algorithm1.12.12.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m1.1b"><apply id="algorithm1.12.12.m1.1.2.cmml" xref="algorithm1.12.12.m1.1.2"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.1.2.1.cmml" xref="algorithm1.12.12.m1.1.2">superscript</csymbol><apply id="algorithm1.12.12.m1.1.2.2.cmml" xref="algorithm1.12.12.m1.1.2"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.1.2.2.1.cmml" xref="algorithm1.12.12.m1.1.2">subscript</csymbol><ci id="algorithm1.12.12.m1.1.2.2.2.cmml" xref="algorithm1.12.12.m1.1.2.2.2">𝜽</ci><ci id="algorithm1.12.12.m1.1.2.2.3.cmml" xref="algorithm1.12.12.m1.1.2.2.3">𝑙</ci></apply><ci id="algorithm1.12.12.m1.1.1.1.1.cmml" xref="algorithm1.12.12.m1.1.1.1.1">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m1.1c">\bm{\theta}_{l}^{(j)}</annotation></semantics></math>=<span id="algorithm1.13.13.1" class="ltx_text ltx_font_bold">ClientUpdate</span>(<math id="algorithm1.13.13.m2.2" class="ltx_Math" alttext="l,\bm{\theta}_{l}" display="inline"><semantics id="algorithm1.13.13.m2.2a"><mrow id="algorithm1.13.13.m2.2.2.1" xref="algorithm1.13.13.m2.2.2.2.cmml"><mi id="algorithm1.13.13.m2.1.1" xref="algorithm1.13.13.m2.1.1.cmml">l</mi><mo id="algorithm1.13.13.m2.2.2.1.2" xref="algorithm1.13.13.m2.2.2.2.cmml">,</mo><msub id="algorithm1.13.13.m2.2.2.1.1" xref="algorithm1.13.13.m2.2.2.1.1.cmml"><mi id="algorithm1.13.13.m2.2.2.1.1.2" xref="algorithm1.13.13.m2.2.2.1.1.2.cmml">𝜽</mi><mi id="algorithm1.13.13.m2.2.2.1.1.3" xref="algorithm1.13.13.m2.2.2.1.1.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m2.2b"><list id="algorithm1.13.13.m2.2.2.2.cmml" xref="algorithm1.13.13.m2.2.2.1"><ci id="algorithm1.13.13.m2.1.1.cmml" xref="algorithm1.13.13.m2.1.1">𝑙</ci><apply id="algorithm1.13.13.m2.2.2.1.1.cmml" xref="algorithm1.13.13.m2.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.13.13.m2.2.2.1.1.1.cmml" xref="algorithm1.13.13.m2.2.2.1.1">subscript</csymbol><ci id="algorithm1.13.13.m2.2.2.1.1.2.cmml" xref="algorithm1.13.13.m2.2.2.1.1.2">𝜽</ci><ci id="algorithm1.13.13.m2.2.2.1.1.3.cmml" xref="algorithm1.13.13.m2.2.2.1.1.3">𝑙</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m2.2c">l,\bm{\theta}_{l}</annotation></semantics></math>)

</div>
<div id="algorithm1.17.22" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
% <em id="algorithm1.17.22.1" class="ltx_emph ltx_font_italic">FedAvg with Secure Aggregation</em> 
</div>
<div id="algorithm1.14.14" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.14.14.m1.2" class="ltx_Math" alttext="\bm{\theta}_{l}=\frac{1}{\mathrm{size}(\mathbf{J})}\sum_{j\in\mathbf{J}}\bm{\theta}_{l}^{(j)}" display="inline"><semantics id="algorithm1.14.14.m1.2a"><mrow id="algorithm1.14.14.m1.2.3" xref="algorithm1.14.14.m1.2.3.cmml"><msub id="algorithm1.14.14.m1.2.3.2" xref="algorithm1.14.14.m1.2.3.2.cmml"><mi id="algorithm1.14.14.m1.2.3.2.2" xref="algorithm1.14.14.m1.2.3.2.2.cmml">𝜽</mi><mi id="algorithm1.14.14.m1.2.3.2.3" xref="algorithm1.14.14.m1.2.3.2.3.cmml">l</mi></msub><mo id="algorithm1.14.14.m1.2.3.1" xref="algorithm1.14.14.m1.2.3.1.cmml">=</mo><mrow id="algorithm1.14.14.m1.2.3.3" xref="algorithm1.14.14.m1.2.3.3.cmml"><mfrac id="algorithm1.14.14.m1.1.1" xref="algorithm1.14.14.m1.1.1.cmml"><mn id="algorithm1.14.14.m1.1.1.3" xref="algorithm1.14.14.m1.1.1.3.cmml">1</mn><mrow id="algorithm1.14.14.m1.1.1.1" xref="algorithm1.14.14.m1.1.1.1.cmml"><mi id="algorithm1.14.14.m1.1.1.1.3" xref="algorithm1.14.14.m1.1.1.1.3.cmml">size</mi><mo lspace="0em" rspace="0em" id="algorithm1.14.14.m1.1.1.1.2" xref="algorithm1.14.14.m1.1.1.1.2.cmml">​</mo><mrow id="algorithm1.14.14.m1.1.1.1.4.2" xref="algorithm1.14.14.m1.1.1.1.cmml"><mo stretchy="false" id="algorithm1.14.14.m1.1.1.1.4.2.1" xref="algorithm1.14.14.m1.1.1.1.cmml">(</mo><mi id="algorithm1.14.14.m1.1.1.1.1" xref="algorithm1.14.14.m1.1.1.1.1.cmml">𝐉</mi><mo stretchy="false" id="algorithm1.14.14.m1.1.1.1.4.2.2" xref="algorithm1.14.14.m1.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0em" rspace="0em" id="algorithm1.14.14.m1.2.3.3.1" xref="algorithm1.14.14.m1.2.3.3.1.cmml">​</mo><mrow id="algorithm1.14.14.m1.2.3.3.2" xref="algorithm1.14.14.m1.2.3.3.2.cmml"><msub id="algorithm1.14.14.m1.2.3.3.2.1" xref="algorithm1.14.14.m1.2.3.3.2.1.cmml"><mo id="algorithm1.14.14.m1.2.3.3.2.1.2" xref="algorithm1.14.14.m1.2.3.3.2.1.2.cmml">∑</mo><mrow id="algorithm1.14.14.m1.2.3.3.2.1.3" xref="algorithm1.14.14.m1.2.3.3.2.1.3.cmml"><mi id="algorithm1.14.14.m1.2.3.3.2.1.3.2" xref="algorithm1.14.14.m1.2.3.3.2.1.3.2.cmml">j</mi><mo id="algorithm1.14.14.m1.2.3.3.2.1.3.1" xref="algorithm1.14.14.m1.2.3.3.2.1.3.1.cmml">∈</mo><mi id="algorithm1.14.14.m1.2.3.3.2.1.3.3" xref="algorithm1.14.14.m1.2.3.3.2.1.3.3.cmml">𝐉</mi></mrow></msub><msubsup id="algorithm1.14.14.m1.2.3.3.2.2" xref="algorithm1.14.14.m1.2.3.3.2.2.cmml"><mi id="algorithm1.14.14.m1.2.3.3.2.2.2.2" xref="algorithm1.14.14.m1.2.3.3.2.2.2.2.cmml">𝜽</mi><mi id="algorithm1.14.14.m1.2.3.3.2.2.2.3" xref="algorithm1.14.14.m1.2.3.3.2.2.2.3.cmml">l</mi><mrow id="algorithm1.14.14.m1.2.2.1.3" xref="algorithm1.14.14.m1.2.3.3.2.2.cmml"><mo stretchy="false" id="algorithm1.14.14.m1.2.2.1.3.1" xref="algorithm1.14.14.m1.2.3.3.2.2.cmml">(</mo><mi id="algorithm1.14.14.m1.2.2.1.1" xref="algorithm1.14.14.m1.2.2.1.1.cmml">j</mi><mo stretchy="false" id="algorithm1.14.14.m1.2.2.1.3.2" xref="algorithm1.14.14.m1.2.3.3.2.2.cmml">)</mo></mrow></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.m1.2b"><apply id="algorithm1.14.14.m1.2.3.cmml" xref="algorithm1.14.14.m1.2.3"><eq id="algorithm1.14.14.m1.2.3.1.cmml" xref="algorithm1.14.14.m1.2.3.1"></eq><apply id="algorithm1.14.14.m1.2.3.2.cmml" xref="algorithm1.14.14.m1.2.3.2"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.3.2.1.cmml" xref="algorithm1.14.14.m1.2.3.2">subscript</csymbol><ci id="algorithm1.14.14.m1.2.3.2.2.cmml" xref="algorithm1.14.14.m1.2.3.2.2">𝜽</ci><ci id="algorithm1.14.14.m1.2.3.2.3.cmml" xref="algorithm1.14.14.m1.2.3.2.3">𝑙</ci></apply><apply id="algorithm1.14.14.m1.2.3.3.cmml" xref="algorithm1.14.14.m1.2.3.3"><times id="algorithm1.14.14.m1.2.3.3.1.cmml" xref="algorithm1.14.14.m1.2.3.3.1"></times><apply id="algorithm1.14.14.m1.1.1.cmml" xref="algorithm1.14.14.m1.1.1"><divide id="algorithm1.14.14.m1.1.1.2.cmml" xref="algorithm1.14.14.m1.1.1"></divide><cn type="integer" id="algorithm1.14.14.m1.1.1.3.cmml" xref="algorithm1.14.14.m1.1.1.3">1</cn><apply id="algorithm1.14.14.m1.1.1.1.cmml" xref="algorithm1.14.14.m1.1.1.1"><times id="algorithm1.14.14.m1.1.1.1.2.cmml" xref="algorithm1.14.14.m1.1.1.1.2"></times><ci id="algorithm1.14.14.m1.1.1.1.3.cmml" xref="algorithm1.14.14.m1.1.1.1.3">size</ci><ci id="algorithm1.14.14.m1.1.1.1.1.cmml" xref="algorithm1.14.14.m1.1.1.1.1">𝐉</ci></apply></apply><apply id="algorithm1.14.14.m1.2.3.3.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2"><apply id="algorithm1.14.14.m1.2.3.3.2.1.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.3.3.2.1.1.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1">subscript</csymbol><sum id="algorithm1.14.14.m1.2.3.3.2.1.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1.2"></sum><apply id="algorithm1.14.14.m1.2.3.3.2.1.3.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1.3"><in id="algorithm1.14.14.m1.2.3.3.2.1.3.1.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1.3.1"></in><ci id="algorithm1.14.14.m1.2.3.3.2.1.3.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1.3.2">𝑗</ci><ci id="algorithm1.14.14.m1.2.3.3.2.1.3.3.cmml" xref="algorithm1.14.14.m1.2.3.3.2.1.3.3">𝐉</ci></apply></apply><apply id="algorithm1.14.14.m1.2.3.3.2.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.3.3.2.2.1.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2">superscript</csymbol><apply id="algorithm1.14.14.m1.2.3.3.2.2.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.3.3.2.2.2.1.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2">subscript</csymbol><ci id="algorithm1.14.14.m1.2.3.3.2.2.2.2.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2.2.2">𝜽</ci><ci id="algorithm1.14.14.m1.2.3.3.2.2.2.3.cmml" xref="algorithm1.14.14.m1.2.3.3.2.2.2.3">𝑙</ci></apply><ci id="algorithm1.14.14.m1.2.2.1.1.cmml" xref="algorithm1.14.14.m1.2.2.1.1">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.m1.2c">\bm{\theta}_{l}=\frac{1}{\mathrm{size}(\mathbf{J})}\sum_{j\in\mathbf{J}}\bm{\theta}_{l}^{(j)}</annotation></semantics></math> <span id="algorithm1.14.14.1" class="ltx_text" style="color:#228B22;">in TEE</span>
</div>
<div id="algorithm1.17.23" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.16.16" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Save <math id="algorithm1.15.15.m1.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="algorithm1.15.15.m1.1a"><msub id="algorithm1.15.15.m1.1.1" xref="algorithm1.15.15.m1.1.1.cmml"><mi id="algorithm1.15.15.m1.1.1.2" xref="algorithm1.15.15.m1.1.1.2.cmml">𝜽</mi><mi id="algorithm1.15.15.m1.1.1.3" xref="algorithm1.15.15.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m1.1b"><apply id="algorithm1.15.15.m1.1.1.cmml" xref="algorithm1.15.15.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.15.15.m1.1.1.1.cmml" xref="algorithm1.15.15.m1.1.1">subscript</csymbol><ci id="algorithm1.15.15.m1.1.1.2.cmml" xref="algorithm1.15.15.m1.1.1.2">𝜽</ci><ci id="algorithm1.15.15.m1.1.1.3.cmml" xref="algorithm1.15.15.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m1.1c">\bm{\theta}_{l}</annotation></semantics></math> from TEE as <math id="algorithm1.16.16.m2.1" class="ltx_Math" alttext="\bm{\theta}_{l}^{0}" display="inline"><semantics id="algorithm1.16.16.m2.1a"><msubsup id="algorithm1.16.16.m2.1.1" xref="algorithm1.16.16.m2.1.1.cmml"><mi id="algorithm1.16.16.m2.1.1.2.2" xref="algorithm1.16.16.m2.1.1.2.2.cmml">𝜽</mi><mi id="algorithm1.16.16.m2.1.1.2.3" xref="algorithm1.16.16.m2.1.1.2.3.cmml">l</mi><mn id="algorithm1.16.16.m2.1.1.3" xref="algorithm1.16.16.m2.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="algorithm1.16.16.m2.1b"><apply id="algorithm1.16.16.m2.1.1.cmml" xref="algorithm1.16.16.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.16.16.m2.1.1.1.cmml" xref="algorithm1.16.16.m2.1.1">superscript</csymbol><apply id="algorithm1.16.16.m2.1.1.2.cmml" xref="algorithm1.16.16.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.16.16.m2.1.1.2.1.cmml" xref="algorithm1.16.16.m2.1.1">subscript</csymbol><ci id="algorithm1.16.16.m2.1.1.2.2.cmml" xref="algorithm1.16.16.m2.1.1.2.2">𝜽</ci><ci id="algorithm1.16.16.m2.1.1.2.3.cmml" xref="algorithm1.16.16.m2.1.1.2.3">𝑙</ci></apply><cn type="integer" id="algorithm1.16.16.m2.1.1.3.cmml" xref="algorithm1.16.16.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.16.m2.1c">\bm{\theta}_{l}^{0}</annotation></semantics></math> in REE

</div>
<div id="algorithm1.17.17" class="ltx_listingline">
return <math id="algorithm1.17.17.m1.3" class="ltx_Math" alttext="\{\bm{\theta}_{1}^{0},...,\bm{\theta}_{L}^{0}\}" display="inline"><semantics id="algorithm1.17.17.m1.3a"><mrow id="algorithm1.17.17.m1.3.3.2" xref="algorithm1.17.17.m1.3.3.3.cmml"><mo stretchy="false" id="algorithm1.17.17.m1.3.3.2.3" xref="algorithm1.17.17.m1.3.3.3.cmml">{</mo><msubsup id="algorithm1.17.17.m1.2.2.1.1" xref="algorithm1.17.17.m1.2.2.1.1.cmml"><mi id="algorithm1.17.17.m1.2.2.1.1.2.2" xref="algorithm1.17.17.m1.2.2.1.1.2.2.cmml">𝜽</mi><mn id="algorithm1.17.17.m1.2.2.1.1.2.3" xref="algorithm1.17.17.m1.2.2.1.1.2.3.cmml">1</mn><mn id="algorithm1.17.17.m1.2.2.1.1.3" xref="algorithm1.17.17.m1.2.2.1.1.3.cmml">0</mn></msubsup><mo id="algorithm1.17.17.m1.3.3.2.4" xref="algorithm1.17.17.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="algorithm1.17.17.m1.1.1" xref="algorithm1.17.17.m1.1.1.cmml">…</mi><mo id="algorithm1.17.17.m1.3.3.2.5" xref="algorithm1.17.17.m1.3.3.3.cmml">,</mo><msubsup id="algorithm1.17.17.m1.3.3.2.2" xref="algorithm1.17.17.m1.3.3.2.2.cmml"><mi id="algorithm1.17.17.m1.3.3.2.2.2.2" xref="algorithm1.17.17.m1.3.3.2.2.2.2.cmml">𝜽</mi><mi id="algorithm1.17.17.m1.3.3.2.2.2.3" xref="algorithm1.17.17.m1.3.3.2.2.2.3.cmml">L</mi><mn id="algorithm1.17.17.m1.3.3.2.2.3" xref="algorithm1.17.17.m1.3.3.2.2.3.cmml">0</mn></msubsup><mo stretchy="false" id="algorithm1.17.17.m1.3.3.2.6" xref="algorithm1.17.17.m1.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.17.17.m1.3b"><set id="algorithm1.17.17.m1.3.3.3.cmml" xref="algorithm1.17.17.m1.3.3.2"><apply id="algorithm1.17.17.m1.2.2.1.1.cmml" xref="algorithm1.17.17.m1.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.2.2.1.1.1.cmml" xref="algorithm1.17.17.m1.2.2.1.1">superscript</csymbol><apply id="algorithm1.17.17.m1.2.2.1.1.2.cmml" xref="algorithm1.17.17.m1.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.2.2.1.1.2.1.cmml" xref="algorithm1.17.17.m1.2.2.1.1">subscript</csymbol><ci id="algorithm1.17.17.m1.2.2.1.1.2.2.cmml" xref="algorithm1.17.17.m1.2.2.1.1.2.2">𝜽</ci><cn type="integer" id="algorithm1.17.17.m1.2.2.1.1.2.3.cmml" xref="algorithm1.17.17.m1.2.2.1.1.2.3">1</cn></apply><cn type="integer" id="algorithm1.17.17.m1.2.2.1.1.3.cmml" xref="algorithm1.17.17.m1.2.2.1.1.3">0</cn></apply><ci id="algorithm1.17.17.m1.1.1.cmml" xref="algorithm1.17.17.m1.1.1">…</ci><apply id="algorithm1.17.17.m1.3.3.2.2.cmml" xref="algorithm1.17.17.m1.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.3.3.2.2.1.cmml" xref="algorithm1.17.17.m1.3.3.2.2">superscript</csymbol><apply id="algorithm1.17.17.m1.3.3.2.2.2.cmml" xref="algorithm1.17.17.m1.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.3.3.2.2.2.1.cmml" xref="algorithm1.17.17.m1.3.3.2.2">subscript</csymbol><ci id="algorithm1.17.17.m1.3.3.2.2.2.2.cmml" xref="algorithm1.17.17.m1.3.3.2.2.2.2">𝜽</ci><ci id="algorithm1.17.17.m1.3.3.2.2.2.3.cmml" xref="algorithm1.17.17.m1.3.3.2.2.2.3">𝐿</ci></apply><cn type="integer" id="algorithm1.17.17.m1.3.3.2.2.3.cmml" xref="algorithm1.17.17.m1.3.3.2.2.3">0</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.17.17.m1.3c">\{\bm{\theta}_{1}^{0},...,\bm{\theta}_{L}^{0}\}</annotation></semantics></math>


</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm1.20.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span><span id="algorithm1.21.2" class="ltx_text ltx_font_bold">PPFL-Server with TEE</span></figcaption>
</figure>
<figure id="algorithm2" class="ltx_float ltx_algorithm">
<div id="algorithm2.26" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm2.2.2" class="ltx_listingline">
<span id="algorithm2.2.2.1" class="ltx_text ltx_font_bold">Initialization:</span>

<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.3" class="ltx_p">Local dataset <math id="S4.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S4.I2.i1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I2.i1.p1.1.m1.1.1" xref="S4.I2.i1.p1.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.1.m1.1b"><ci id="S4.I2.i1.p1.1.m1.1.1.cmml" xref="S4.I2.i1.p1.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.1.m1.1c">\mathcal{X}</annotation></semantics></math>: data <math id="S4.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="\{\bm{x}\}" display="inline"><semantics id="S4.I2.i1.p1.2.m2.1a"><mrow id="S4.I2.i1.p1.2.m2.1.2.2" xref="S4.I2.i1.p1.2.m2.1.2.1.cmml"><mo stretchy="false" id="S4.I2.i1.p1.2.m2.1.2.2.1" xref="S4.I2.i1.p1.2.m2.1.2.1.cmml">{</mo><mi id="S4.I2.i1.p1.2.m2.1.1" xref="S4.I2.i1.p1.2.m2.1.1.cmml">𝒙</mi><mo stretchy="false" id="S4.I2.i1.p1.2.m2.1.2.2.2" xref="S4.I2.i1.p1.2.m2.1.2.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.2.m2.1b"><set id="S4.I2.i1.p1.2.m2.1.2.1.cmml" xref="S4.I2.i1.p1.2.m2.1.2.2"><ci id="S4.I2.i1.p1.2.m2.1.1.cmml" xref="S4.I2.i1.p1.2.m2.1.1">𝒙</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.2.m2.1c">\{\bm{x}\}</annotation></semantics></math> and labels <math id="S4.I2.i1.p1.3.m3.1" class="ltx_Math" alttext="\{\bm{y}\}" display="inline"><semantics id="S4.I2.i1.p1.3.m3.1a"><mrow id="S4.I2.i1.p1.3.m3.1.2.2" xref="S4.I2.i1.p1.3.m3.1.2.1.cmml"><mo stretchy="false" id="S4.I2.i1.p1.3.m3.1.2.2.1" xref="S4.I2.i1.p1.3.m3.1.2.1.cmml">{</mo><mi id="S4.I2.i1.p1.3.m3.1.1" xref="S4.I2.i1.p1.3.m3.1.1.cmml">𝒚</mi><mo stretchy="false" id="S4.I2.i1.p1.3.m3.1.2.2.2" xref="S4.I2.i1.p1.3.m3.1.2.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.3.m3.1b"><set id="S4.I2.i1.p1.3.m3.1.2.1.cmml" xref="S4.I2.i1.p1.3.m3.1.2.2"><ci id="S4.I2.i1.p1.3.m3.1.1.cmml" xref="S4.I2.i1.p1.3.m3.1.1">𝒚</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.3.m3.1c">\{\bm{y}\}</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">Trained final parameters of all previous layers, i.e., <math id="S4.I2.i2.p1.1.m1.4" class="ltx_Math" alttext="\bm{\theta}_{1}^{0},\bm{\theta}_{2}^{0},...,\bm{\theta}_{l-1}^{0}" display="inline"><semantics id="S4.I2.i2.p1.1.m1.4a"><mrow id="S4.I2.i2.p1.1.m1.4.4.3" xref="S4.I2.i2.p1.1.m1.4.4.4.cmml"><msubsup id="S4.I2.i2.p1.1.m1.2.2.1.1" xref="S4.I2.i2.p1.1.m1.2.2.1.1.cmml"><mi id="S4.I2.i2.p1.1.m1.2.2.1.1.2.2" xref="S4.I2.i2.p1.1.m1.2.2.1.1.2.2.cmml">𝜽</mi><mn id="S4.I2.i2.p1.1.m1.2.2.1.1.2.3" xref="S4.I2.i2.p1.1.m1.2.2.1.1.2.3.cmml">1</mn><mn id="S4.I2.i2.p1.1.m1.2.2.1.1.3" xref="S4.I2.i2.p1.1.m1.2.2.1.1.3.cmml">0</mn></msubsup><mo id="S4.I2.i2.p1.1.m1.4.4.3.4" xref="S4.I2.i2.p1.1.m1.4.4.4.cmml">,</mo><msubsup id="S4.I2.i2.p1.1.m1.3.3.2.2" xref="S4.I2.i2.p1.1.m1.3.3.2.2.cmml"><mi id="S4.I2.i2.p1.1.m1.3.3.2.2.2.2" xref="S4.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml">𝜽</mi><mn id="S4.I2.i2.p1.1.m1.3.3.2.2.2.3" xref="S4.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn><mn id="S4.I2.i2.p1.1.m1.3.3.2.2.3" xref="S4.I2.i2.p1.1.m1.3.3.2.2.3.cmml">0</mn></msubsup><mo id="S4.I2.i2.p1.1.m1.4.4.3.5" xref="S4.I2.i2.p1.1.m1.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S4.I2.i2.p1.1.m1.1.1" xref="S4.I2.i2.p1.1.m1.1.1.cmml">…</mi><mo id="S4.I2.i2.p1.1.m1.4.4.3.6" xref="S4.I2.i2.p1.1.m1.4.4.4.cmml">,</mo><msubsup id="S4.I2.i2.p1.1.m1.4.4.3.3" xref="S4.I2.i2.p1.1.m1.4.4.3.3.cmml"><mi id="S4.I2.i2.p1.1.m1.4.4.3.3.2.2" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.2.cmml">𝜽</mi><mrow id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.cmml"><mi id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.2" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.2.cmml">l</mi><mo id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.1" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.1.cmml">−</mo><mn id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.3" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.3.cmml">1</mn></mrow><mn id="S4.I2.i2.p1.1.m1.4.4.3.3.3" xref="S4.I2.i2.p1.1.m1.4.4.3.3.3.cmml">0</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.1.m1.4b"><list id="S4.I2.i2.p1.1.m1.4.4.4.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3"><apply id="S4.I2.i2.p1.1.m1.2.2.1.1.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.2.2.1.1.1.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1">superscript</csymbol><apply id="S4.I2.i2.p1.1.m1.2.2.1.1.2.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.2.2.1.1.2.1.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S4.I2.i2.p1.1.m1.2.2.1.1.2.2.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1.2.2">𝜽</ci><cn type="integer" id="S4.I2.i2.p1.1.m1.2.2.1.1.2.3.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1.2.3">1</cn></apply><cn type="integer" id="S4.I2.i2.p1.1.m1.2.2.1.1.3.cmml" xref="S4.I2.i2.p1.1.m1.2.2.1.1.3">0</cn></apply><apply id="S4.I2.i2.p1.1.m1.3.3.2.2.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.3.3.2.2.1.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2">superscript</csymbol><apply id="S4.I2.i2.p1.1.m1.3.3.2.2.2.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S4.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2.2.2">𝜽</ci><cn type="integer" id="S4.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><cn type="integer" id="S4.I2.i2.p1.1.m1.3.3.2.2.3.cmml" xref="S4.I2.i2.p1.1.m1.3.3.2.2.3">0</cn></apply><ci id="S4.I2.i2.p1.1.m1.1.1.cmml" xref="S4.I2.i2.p1.1.m1.1.1">…</ci><apply id="S4.I2.i2.p1.1.m1.4.4.3.3.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.4.4.3.3.1.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3">superscript</csymbol><apply id="S4.I2.i2.p1.1.m1.4.4.3.3.2.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S4.I2.i2.p1.1.m1.4.4.3.3.2.1.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3">subscript</csymbol><ci id="S4.I2.i2.p1.1.m1.4.4.3.3.2.2.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.2">𝜽</ci><apply id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3"><minus id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.1.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.1"></minus><ci id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.2.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.2">𝑙</ci><cn type="integer" id="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.3.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.2.3.3">1</cn></apply></apply><cn type="integer" id="S4.I2.i2.p1.1.m1.4.4.3.3.3.cmml" xref="S4.I2.i2.p1.1.m1.4.4.3.3.3">0</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.1.m1.4c">\bm{\theta}_{1}^{0},\bm{\theta}_{2}^{0},...,\bm{\theta}_{l-1}^{0}</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Number of local training epochs: <math id="S4.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.I2.i3.p1.1.m1.1a"><mi id="S4.I2.i3.p1.1.m1.1.1" xref="S4.I2.i3.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i3.p1.1.m1.1b"><ci id="S4.I2.i3.p1.1.m1.1.1.cmml" xref="S4.I2.i3.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i3.p1.1.m1.1c">E</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.2" class="ltx_p">Activation function: <math id="S4.I2.i4.p1.1.m1.1" class="ltx_Math" alttext="\sigma()" display="inline"><semantics id="S4.I2.i4.p1.1.m1.1a"><mrow id="S4.I2.i4.p1.1.m1.1.1" xref="S4.I2.i4.p1.1.m1.1.1.cmml"><mi id="S4.I2.i4.p1.1.m1.1.1.2" xref="S4.I2.i4.p1.1.m1.1.1.2.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S4.I2.i4.p1.1.m1.1.1.1" xref="S4.I2.i4.p1.1.m1.1.1.1.cmml">​</mo><mrow id="S4.I2.i4.p1.1.m1.1.1.3.2" xref="S4.I2.i4.p1.1.m1.1.1.cmml"><mo stretchy="false" id="S4.I2.i4.p1.1.m1.1.1.3.2.1" xref="S4.I2.i4.p1.1.m1.1.1.3.1.cmml">(</mo><mo stretchy="false" id="S4.I2.i4.p1.1.m1.1.1.3.2.2" xref="S4.I2.i4.p1.1.m1.1.1.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I2.i4.p1.1.m1.1b"><apply id="S4.I2.i4.p1.1.m1.1.1.cmml" xref="S4.I2.i4.p1.1.m1.1.1"><times id="S4.I2.i4.p1.1.m1.1.1.1.cmml" xref="S4.I2.i4.p1.1.m1.1.1.1"></times><ci id="S4.I2.i4.p1.1.m1.1.1.2.cmml" xref="S4.I2.i4.p1.1.m1.1.1.2">𝜎</ci><list id="S4.I2.i4.p1.1.m1.1.1.3.1.cmml" xref="S4.I2.i4.p1.1.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i4.p1.1.m1.1c">\sigma()</annotation></semantics></math> and loss function: <math id="S4.I2.i4.p1.2.m2.1" class="ltx_Math" alttext="\ell" display="inline"><semantics id="S4.I2.i4.p1.2.m2.1a"><mi mathvariant="normal" id="S4.I2.i4.p1.2.m2.1.1" xref="S4.I2.i4.p1.2.m2.1.1.cmml">ℓ</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i4.p1.2.m2.1b"><ci id="S4.I2.i4.p1.2.m2.1.1.cmml" xref="S4.I2.i4.p1.2.m2.1.1">ℓ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i4.p1.2.m2.1c">\ell</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i5.p1" class="ltx_para">
<p id="S4.I2.i5.p1.1" class="ltx_p">Classifier: <math id="S4.I2.i5.p1.1.m1.1" class="ltx_Math" alttext="C()" display="inline"><semantics id="S4.I2.i5.p1.1.m1.1a"><mrow id="S4.I2.i5.p1.1.m1.1.1" xref="S4.I2.i5.p1.1.m1.1.1.cmml"><mi id="S4.I2.i5.p1.1.m1.1.1.2" xref="S4.I2.i5.p1.1.m1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I2.i5.p1.1.m1.1.1.1" xref="S4.I2.i5.p1.1.m1.1.1.1.cmml">​</mo><mrow id="S4.I2.i5.p1.1.m1.1.1.3.2" xref="S4.I2.i5.p1.1.m1.1.1.cmml"><mo stretchy="false" id="S4.I2.i5.p1.1.m1.1.1.3.2.1" xref="S4.I2.i5.p1.1.m1.1.1.3.1.cmml">(</mo><mo stretchy="false" id="S4.I2.i5.p1.1.m1.1.1.3.2.2" xref="S4.I2.i5.p1.1.m1.1.1.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I2.i5.p1.1.m1.1b"><apply id="S4.I2.i5.p1.1.m1.1.1.cmml" xref="S4.I2.i5.p1.1.m1.1.1"><times id="S4.I2.i5.p1.1.m1.1.1.1.cmml" xref="S4.I2.i5.p1.1.m1.1.1.1"></times><ci id="S4.I2.i5.p1.1.m1.1.1.2.cmml" xref="S4.I2.i5.p1.1.m1.1.1.2">𝐶</ci><list id="S4.I2.i5.p1.1.m1.1.1.3.1.cmml" xref="S4.I2.i5.p1.1.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i5.p1.1.m1.1c">C()</annotation></semantics></math></p>
</div>
</li>
</ul>
<span id="algorithm2.2.2.2" class="ltx_text ltx_font_bold">Input:</span>

<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p">Target layer: <math id="S4.I3.i1.p1.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.I3.i1.p1.1.m1.1a"><mi id="S4.I3.i1.p1.1.m1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.1.m1.1b"><ci id="S4.I3.i1.p1.1.m1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.1.m1.1c">l</annotation></semantics></math></p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.2" class="ltx_p">Broadcast parameters of layer <math id="S4.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.I3.i2.p1.1.m1.1a"><mi id="S4.I3.i2.p1.1.m1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.1.m1.1b"><ci id="S4.I3.i2.p1.1.m1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.1.m1.1c">l</annotation></semantics></math>: <math id="S4.I3.i2.p1.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="S4.I3.i2.p1.2.m2.1a"><msub id="S4.I3.i2.p1.2.m2.1.1" xref="S4.I3.i2.p1.2.m2.1.1.cmml"><mi id="S4.I3.i2.p1.2.m2.1.1.2" xref="S4.I3.i2.p1.2.m2.1.1.2.cmml">𝜽</mi><mi id="S4.I3.i2.p1.2.m2.1.1.3" xref="S4.I3.i2.p1.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.2.m2.1b"><apply id="S4.I3.i2.p1.2.m2.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.I3.i2.p1.2.m2.1.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.I3.i2.p1.2.m2.1.1.2.cmml" xref="S4.I3.i2.p1.2.m2.1.1.2">𝜽</ci><ci id="S4.I3.i2.p1.2.m2.1.1.3.cmml" xref="S4.I3.i2.p1.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.2.m2.1c">\bm{\theta}_{l}</annotation></semantics></math></p>
</div>
</li>
</ul>
<span id="algorithm2.2.2.3" class="ltx_text ltx_font_bold">Output:</span> Updated parameters of layer <math id="algorithm2.1.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="algorithm2.1.1.m1.1a"><mi id="algorithm2.1.1.m1.1.1" xref="algorithm2.1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="algorithm2.1.1.m1.1b"><ci id="algorithm2.1.1.m1.1.1.cmml" xref="algorithm2.1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.1.1.m1.1c">l</annotation></semantics></math>: <math id="algorithm2.2.2.m2.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="algorithm2.2.2.m2.1a"><msub id="algorithm2.2.2.m2.1.1" xref="algorithm2.2.2.m2.1.1.cmml"><mi id="algorithm2.2.2.m2.1.1.2" xref="algorithm2.2.2.m2.1.1.2.cmml">𝜽</mi><mi id="algorithm2.2.2.m2.1.1.3" xref="algorithm2.2.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm2.2.2.m2.1b"><apply id="algorithm2.2.2.m2.1.1.cmml" xref="algorithm2.2.2.m2.1.1"><csymbol cd="ambiguous" id="algorithm2.2.2.m2.1.1.1.cmml" xref="algorithm2.2.2.m2.1.1">subscript</csymbol><ci id="algorithm2.2.2.m2.1.1.2.cmml" xref="algorithm2.2.2.m2.1.1.2">𝜽</ci><ci id="algorithm2.2.2.m2.1.1.3.cmml" xref="algorithm2.2.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.2.2.m2.1c">\bm{\theta}_{l}</annotation></semantics></math>
</div>
<div id="algorithm2.4.4" class="ltx_listingline">

% <em id="algorithm2.4.4.2" class="ltx_emph ltx_font_italic">Weights and biases of layers <math id="algorithm2.3.3.1.m1.3" class="ltx_Math" alttext="1,...,(l-1)" display="inline"><semantics id="algorithm2.3.3.1.m1.3a"><mrow id="algorithm2.3.3.1.m1.3.3.1" xref="algorithm2.3.3.1.m1.3.3.2.cmml"><mn id="algorithm2.3.3.1.m1.1.1" xref="algorithm2.3.3.1.m1.1.1.cmml">1</mn><mo id="algorithm2.3.3.1.m1.3.3.1.2" xref="algorithm2.3.3.1.m1.3.3.2.cmml">,</mo><mi mathvariant="normal" id="algorithm2.3.3.1.m1.2.2" xref="algorithm2.3.3.1.m1.2.2.cmml">…</mi><mo id="algorithm2.3.3.1.m1.3.3.1.3" xref="algorithm2.3.3.1.m1.3.3.2.cmml">,</mo><mrow id="algorithm2.3.3.1.m1.3.3.1.1.1" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="algorithm2.3.3.1.m1.3.3.1.1.1.2" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="algorithm2.3.3.1.m1.3.3.1.1.1.1" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.cmml"><mi id="algorithm2.3.3.1.m1.3.3.1.1.1.1.2" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.2.cmml">l</mi><mo id="algorithm2.3.3.1.m1.3.3.1.1.1.1.1" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.1.cmml">−</mo><mn id="algorithm2.3.3.1.m1.3.3.1.1.1.1.3" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="algorithm2.3.3.1.m1.3.3.1.1.1.3" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.3.3.1.m1.3b"><list id="algorithm2.3.3.1.m1.3.3.2.cmml" xref="algorithm2.3.3.1.m1.3.3.1"><cn type="integer" id="algorithm2.3.3.1.m1.1.1.cmml" xref="algorithm2.3.3.1.m1.1.1">1</cn><ci id="algorithm2.3.3.1.m1.2.2.cmml" xref="algorithm2.3.3.1.m1.2.2">…</ci><apply id="algorithm2.3.3.1.m1.3.3.1.1.1.1.cmml" xref="algorithm2.3.3.1.m1.3.3.1.1.1"><minus id="algorithm2.3.3.1.m1.3.3.1.1.1.1.1.cmml" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.1"></minus><ci id="algorithm2.3.3.1.m1.3.3.1.1.1.1.2.cmml" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.2">𝑙</ci><cn type="integer" id="algorithm2.3.3.1.m1.3.3.1.1.1.1.3.cmml" xref="algorithm2.3.3.1.m1.3.3.1.1.1.1.3">1</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.3.3.1.m1.3c">1,...,(l-1)</annotation></semantics></math> and <math id="algorithm2.4.4.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="algorithm2.4.4.2.m2.1a"><mi id="algorithm2.4.4.2.m2.1.1" xref="algorithm2.4.4.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="algorithm2.4.4.2.m2.1b"><ci id="algorithm2.4.4.2.m2.1.1.cmml" xref="algorithm2.4.4.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.4.4.2.m2.1c">l</annotation></semantics></math></em> 
</div>
<div id="algorithm2.5.5" class="ltx_listingline">
<span id="algorithm2.5.5.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm2.5.5.1" class="ltx_emph ltx_font_italic"><math id="algorithm2.5.5.1.m1.3" class="ltx_Math" alttext="i\in\{1,...,l-1\}" display="inline"><semantics id="algorithm2.5.5.1.m1.3a"><mrow id="algorithm2.5.5.1.m1.3.3" xref="algorithm2.5.5.1.m1.3.3.cmml"><mi id="algorithm2.5.5.1.m1.3.3.3" xref="algorithm2.5.5.1.m1.3.3.3.cmml">i</mi><mo id="algorithm2.5.5.1.m1.3.3.2" xref="algorithm2.5.5.1.m1.3.3.2.cmml">∈</mo><mrow id="algorithm2.5.5.1.m1.3.3.1.1" xref="algorithm2.5.5.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="algorithm2.5.5.1.m1.3.3.1.1.2" xref="algorithm2.5.5.1.m1.3.3.1.2.cmml">{</mo><mn id="algorithm2.5.5.1.m1.1.1" xref="algorithm2.5.5.1.m1.1.1.cmml">1</mn><mo id="algorithm2.5.5.1.m1.3.3.1.1.3" xref="algorithm2.5.5.1.m1.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="algorithm2.5.5.1.m1.2.2" xref="algorithm2.5.5.1.m1.2.2.cmml">…</mi><mo id="algorithm2.5.5.1.m1.3.3.1.1.4" xref="algorithm2.5.5.1.m1.3.3.1.2.cmml">,</mo><mrow id="algorithm2.5.5.1.m1.3.3.1.1.1" xref="algorithm2.5.5.1.m1.3.3.1.1.1.cmml"><mi id="algorithm2.5.5.1.m1.3.3.1.1.1.2" xref="algorithm2.5.5.1.m1.3.3.1.1.1.2.cmml">l</mi><mo id="algorithm2.5.5.1.m1.3.3.1.1.1.1" xref="algorithm2.5.5.1.m1.3.3.1.1.1.1.cmml">−</mo><mn id="algorithm2.5.5.1.m1.3.3.1.1.1.3" xref="algorithm2.5.5.1.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="algorithm2.5.5.1.m1.3.3.1.1.5" xref="algorithm2.5.5.1.m1.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.5.5.1.m1.3b"><apply id="algorithm2.5.5.1.m1.3.3.cmml" xref="algorithm2.5.5.1.m1.3.3"><in id="algorithm2.5.5.1.m1.3.3.2.cmml" xref="algorithm2.5.5.1.m1.3.3.2"></in><ci id="algorithm2.5.5.1.m1.3.3.3.cmml" xref="algorithm2.5.5.1.m1.3.3.3">𝑖</ci><set id="algorithm2.5.5.1.m1.3.3.1.2.cmml" xref="algorithm2.5.5.1.m1.3.3.1.1"><cn type="integer" id="algorithm2.5.5.1.m1.1.1.cmml" xref="algorithm2.5.5.1.m1.1.1">1</cn><ci id="algorithm2.5.5.1.m1.2.2.cmml" xref="algorithm2.5.5.1.m1.2.2">…</ci><apply id="algorithm2.5.5.1.m1.3.3.1.1.1.cmml" xref="algorithm2.5.5.1.m1.3.3.1.1.1"><minus id="algorithm2.5.5.1.m1.3.3.1.1.1.1.cmml" xref="algorithm2.5.5.1.m1.3.3.1.1.1.1"></minus><ci id="algorithm2.5.5.1.m1.3.3.1.1.1.2.cmml" xref="algorithm2.5.5.1.m1.3.3.1.1.1.2">𝑙</ci><cn type="integer" id="algorithm2.5.5.1.m1.3.3.1.1.1.3.cmml" xref="algorithm2.5.5.1.m1.3.3.1.1.1.3">1</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.5.5.1.m1.3c">i\in\{1,...,l-1\}</annotation></semantics></math></em> <span id="algorithm2.5.5.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm2.6.6" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.6.6.m1.2" class="ltx_Math" alttext="\{\bm{W}_{i},\bm{b}_{i}\}\xleftarrow{}\bm{\theta}_{i}^{0}" display="inline"><semantics id="algorithm2.6.6.m1.2a"><mrow id="algorithm2.6.6.m1.2.2" xref="algorithm2.6.6.m1.2.2.cmml"><mrow id="algorithm2.6.6.m1.2.2.2.2" xref="algorithm2.6.6.m1.2.2.2.3.cmml"><mo stretchy="false" id="algorithm2.6.6.m1.2.2.2.2.3" xref="algorithm2.6.6.m1.2.2.2.3.cmml">{</mo><msub id="algorithm2.6.6.m1.1.1.1.1.1" xref="algorithm2.6.6.m1.1.1.1.1.1.cmml"><mi id="algorithm2.6.6.m1.1.1.1.1.1.2" xref="algorithm2.6.6.m1.1.1.1.1.1.2.cmml">𝑾</mi><mi id="algorithm2.6.6.m1.1.1.1.1.1.3" xref="algorithm2.6.6.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="algorithm2.6.6.m1.2.2.2.2.4" xref="algorithm2.6.6.m1.2.2.2.3.cmml">,</mo><msub id="algorithm2.6.6.m1.2.2.2.2.2" xref="algorithm2.6.6.m1.2.2.2.2.2.cmml"><mi id="algorithm2.6.6.m1.2.2.2.2.2.2" xref="algorithm2.6.6.m1.2.2.2.2.2.2.cmml">𝒃</mi><mi id="algorithm2.6.6.m1.2.2.2.2.2.3" xref="algorithm2.6.6.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="algorithm2.6.6.m1.2.2.2.2.5" xref="algorithm2.6.6.m1.2.2.2.3.cmml">}</mo></mrow><mover accent="true" id="algorithm2.6.6.m1.2.2.3" xref="algorithm2.6.6.m1.2.2.3.cmml"><mo stretchy="false" id="algorithm2.6.6.m1.2.2.3.2" xref="algorithm2.6.6.m1.2.2.3.2.cmml">←</mo><mi id="algorithm2.6.6.m1.2.2.3.1" xref="algorithm2.6.6.m1.2.2.3.1.cmml"></mi></mover><msubsup id="algorithm2.6.6.m1.2.2.4" xref="algorithm2.6.6.m1.2.2.4.cmml"><mi id="algorithm2.6.6.m1.2.2.4.2.2" xref="algorithm2.6.6.m1.2.2.4.2.2.cmml">𝜽</mi><mi id="algorithm2.6.6.m1.2.2.4.2.3" xref="algorithm2.6.6.m1.2.2.4.2.3.cmml">i</mi><mn id="algorithm2.6.6.m1.2.2.4.3" xref="algorithm2.6.6.m1.2.2.4.3.cmml">0</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.6.6.m1.2b"><apply id="algorithm2.6.6.m1.2.2.cmml" xref="algorithm2.6.6.m1.2.2"><apply id="algorithm2.6.6.m1.2.2.3.cmml" xref="algorithm2.6.6.m1.2.2.3"><csymbol cd="latexml" id="algorithm2.6.6.m1.2.2.3.1.cmml" xref="algorithm2.6.6.m1.2.2.3.1">absent</csymbol><ci id="algorithm2.6.6.m1.2.2.3.2.cmml" xref="algorithm2.6.6.m1.2.2.3.2">←</ci></apply><set id="algorithm2.6.6.m1.2.2.2.3.cmml" xref="algorithm2.6.6.m1.2.2.2.2"><apply id="algorithm2.6.6.m1.1.1.1.1.1.cmml" xref="algorithm2.6.6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm2.6.6.m1.1.1.1.1.1.1.cmml" xref="algorithm2.6.6.m1.1.1.1.1.1">subscript</csymbol><ci id="algorithm2.6.6.m1.1.1.1.1.1.2.cmml" xref="algorithm2.6.6.m1.1.1.1.1.1.2">𝑾</ci><ci id="algorithm2.6.6.m1.1.1.1.1.1.3.cmml" xref="algorithm2.6.6.m1.1.1.1.1.1.3">𝑖</ci></apply><apply id="algorithm2.6.6.m1.2.2.2.2.2.cmml" xref="algorithm2.6.6.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm2.6.6.m1.2.2.2.2.2.1.cmml" xref="algorithm2.6.6.m1.2.2.2.2.2">subscript</csymbol><ci id="algorithm2.6.6.m1.2.2.2.2.2.2.cmml" xref="algorithm2.6.6.m1.2.2.2.2.2.2">𝒃</ci><ci id="algorithm2.6.6.m1.2.2.2.2.2.3.cmml" xref="algorithm2.6.6.m1.2.2.2.2.2.3">𝑖</ci></apply></set><apply id="algorithm2.6.6.m1.2.2.4.cmml" xref="algorithm2.6.6.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm2.6.6.m1.2.2.4.1.cmml" xref="algorithm2.6.6.m1.2.2.4">superscript</csymbol><apply id="algorithm2.6.6.m1.2.2.4.2.cmml" xref="algorithm2.6.6.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm2.6.6.m1.2.2.4.2.1.cmml" xref="algorithm2.6.6.m1.2.2.4">subscript</csymbol><ci id="algorithm2.6.6.m1.2.2.4.2.2.cmml" xref="algorithm2.6.6.m1.2.2.4.2.2">𝜽</ci><ci id="algorithm2.6.6.m1.2.2.4.2.3.cmml" xref="algorithm2.6.6.m1.2.2.4.2.3">𝑖</ci></apply><cn type="integer" id="algorithm2.6.6.m1.2.2.4.3.cmml" xref="algorithm2.6.6.m1.2.2.4.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.6.6.m1.2c">\{\bm{W}_{i},\bm{b}_{i}\}\xleftarrow{}\bm{\theta}_{i}^{0}</annotation></semantics></math>

</div>
<div id="algorithm2.7.7" class="ltx_listingline">
<math id="algorithm2.7.7.m1.2" class="ltx_Math" alttext="\{\bm{W}_{l},\bm{b}_{l}\}\xleftarrow{}\bm{\theta}_{l}" display="inline"><semantics id="algorithm2.7.7.m1.2a"><mrow id="algorithm2.7.7.m1.2.2" xref="algorithm2.7.7.m1.2.2.cmml"><mrow id="algorithm2.7.7.m1.2.2.2.2" xref="algorithm2.7.7.m1.2.2.2.3.cmml"><mo stretchy="false" id="algorithm2.7.7.m1.2.2.2.2.3" xref="algorithm2.7.7.m1.2.2.2.3.cmml">{</mo><msub id="algorithm2.7.7.m1.1.1.1.1.1" xref="algorithm2.7.7.m1.1.1.1.1.1.cmml"><mi id="algorithm2.7.7.m1.1.1.1.1.1.2" xref="algorithm2.7.7.m1.1.1.1.1.1.2.cmml">𝑾</mi><mi id="algorithm2.7.7.m1.1.1.1.1.1.3" xref="algorithm2.7.7.m1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="algorithm2.7.7.m1.2.2.2.2.4" xref="algorithm2.7.7.m1.2.2.2.3.cmml">,</mo><msub id="algorithm2.7.7.m1.2.2.2.2.2" xref="algorithm2.7.7.m1.2.2.2.2.2.cmml"><mi id="algorithm2.7.7.m1.2.2.2.2.2.2" xref="algorithm2.7.7.m1.2.2.2.2.2.2.cmml">𝒃</mi><mi id="algorithm2.7.7.m1.2.2.2.2.2.3" xref="algorithm2.7.7.m1.2.2.2.2.2.3.cmml">l</mi></msub><mo stretchy="false" id="algorithm2.7.7.m1.2.2.2.2.5" xref="algorithm2.7.7.m1.2.2.2.3.cmml">}</mo></mrow><mover accent="true" id="algorithm2.7.7.m1.2.2.3" xref="algorithm2.7.7.m1.2.2.3.cmml"><mo stretchy="false" id="algorithm2.7.7.m1.2.2.3.2" xref="algorithm2.7.7.m1.2.2.3.2.cmml">←</mo><mi id="algorithm2.7.7.m1.2.2.3.1" xref="algorithm2.7.7.m1.2.2.3.1.cmml"></mi></mover><msub id="algorithm2.7.7.m1.2.2.4" xref="algorithm2.7.7.m1.2.2.4.cmml"><mi id="algorithm2.7.7.m1.2.2.4.2" xref="algorithm2.7.7.m1.2.2.4.2.cmml">𝜽</mi><mi id="algorithm2.7.7.m1.2.2.4.3" xref="algorithm2.7.7.m1.2.2.4.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.7.7.m1.2b"><apply id="algorithm2.7.7.m1.2.2.cmml" xref="algorithm2.7.7.m1.2.2"><apply id="algorithm2.7.7.m1.2.2.3.cmml" xref="algorithm2.7.7.m1.2.2.3"><csymbol cd="latexml" id="algorithm2.7.7.m1.2.2.3.1.cmml" xref="algorithm2.7.7.m1.2.2.3.1">absent</csymbol><ci id="algorithm2.7.7.m1.2.2.3.2.cmml" xref="algorithm2.7.7.m1.2.2.3.2">←</ci></apply><set id="algorithm2.7.7.m1.2.2.2.3.cmml" xref="algorithm2.7.7.m1.2.2.2.2"><apply id="algorithm2.7.7.m1.1.1.1.1.1.cmml" xref="algorithm2.7.7.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm2.7.7.m1.1.1.1.1.1.1.cmml" xref="algorithm2.7.7.m1.1.1.1.1.1">subscript</csymbol><ci id="algorithm2.7.7.m1.1.1.1.1.1.2.cmml" xref="algorithm2.7.7.m1.1.1.1.1.1.2">𝑾</ci><ci id="algorithm2.7.7.m1.1.1.1.1.1.3.cmml" xref="algorithm2.7.7.m1.1.1.1.1.1.3">𝑙</ci></apply><apply id="algorithm2.7.7.m1.2.2.2.2.2.cmml" xref="algorithm2.7.7.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm2.7.7.m1.2.2.2.2.2.1.cmml" xref="algorithm2.7.7.m1.2.2.2.2.2">subscript</csymbol><ci id="algorithm2.7.7.m1.2.2.2.2.2.2.cmml" xref="algorithm2.7.7.m1.2.2.2.2.2.2">𝒃</ci><ci id="algorithm2.7.7.m1.2.2.2.2.2.3.cmml" xref="algorithm2.7.7.m1.2.2.2.2.2.3">𝑙</ci></apply></set><apply id="algorithm2.7.7.m1.2.2.4.cmml" xref="algorithm2.7.7.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm2.7.7.m1.2.2.4.1.cmml" xref="algorithm2.7.7.m1.2.2.4">subscript</csymbol><ci id="algorithm2.7.7.m1.2.2.4.2.cmml" xref="algorithm2.7.7.m1.2.2.4.2">𝜽</ci><ci id="algorithm2.7.7.m1.2.2.4.3.cmml" xref="algorithm2.7.7.m1.2.2.4.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.7.7.m1.2c">\{\bm{W}_{l},\bm{b}_{l}\}\xleftarrow{}\bm{\theta}_{l}</annotation></semantics></math> <span id="algorithm2.7.7.1" class="ltx_text" style="color:#228B22;">in TEE</span>
</div>
<div id="algorithm2.26.25" class="ltx_listingline">

% <em id="algorithm2.26.25.1" class="ltx_emph ltx_font_italic">Training process</em> 
</div>
<div id="algorithm2.8.8" class="ltx_listingline">
<span id="algorithm2.8.8.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm2.8.8.1" class="ltx_emph ltx_font_italic"><math id="algorithm2.8.8.1.m1.1" class="ltx_math_unparsed" alttext="e\in\{1,..,E\}" display="inline"><semantics id="algorithm2.8.8.1.m1.1a"><mrow id="algorithm2.8.8.1.m1.1b"><mi id="algorithm2.8.8.1.m1.1.1">e</mi><mo id="algorithm2.8.8.1.m1.1.2">∈</mo><mrow id="algorithm2.8.8.1.m1.1.3"><mo stretchy="false" id="algorithm2.8.8.1.m1.1.3.1">{</mo><mn id="algorithm2.8.8.1.m1.1.3.2">1</mn><mo id="algorithm2.8.8.1.m1.1.3.3">,</mo><mo lspace="0em" rspace="0.0835em" id="algorithm2.8.8.1.m1.1.3.4">.</mo><mo lspace="0.0835em" rspace="0.167em" id="algorithm2.8.8.1.m1.1.3.5">.</mo><mo id="algorithm2.8.8.1.m1.1.3.6">,</mo><mi id="algorithm2.8.8.1.m1.1.3.7">E</mi><mo stretchy="false" id="algorithm2.8.8.1.m1.1.3.8">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="algorithm2.8.8.1.m1.1c">e\in\{1,..,E\}</annotation></semantics></math></em> <span id="algorithm2.8.8.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm2.9.9" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm2.9.9.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm2.9.9.1" class="ltx_emph ltx_font_italic"><math id="algorithm2.9.9.1.m1.2" class="ltx_Math" alttext="\{\bm{x},\bm{y}\}\in\mathcal{X}" display="inline"><semantics id="algorithm2.9.9.1.m1.2a"><mrow id="algorithm2.9.9.1.m1.2.3" xref="algorithm2.9.9.1.m1.2.3.cmml"><mrow id="algorithm2.9.9.1.m1.2.3.2.2" xref="algorithm2.9.9.1.m1.2.3.2.1.cmml"><mo stretchy="false" id="algorithm2.9.9.1.m1.2.3.2.2.1" xref="algorithm2.9.9.1.m1.2.3.2.1.cmml">{</mo><mi id="algorithm2.9.9.1.m1.1.1" xref="algorithm2.9.9.1.m1.1.1.cmml">𝐱</mi><mo id="algorithm2.9.9.1.m1.2.3.2.2.2" xref="algorithm2.9.9.1.m1.2.3.2.1.cmml">,</mo><mi id="algorithm2.9.9.1.m1.2.2" xref="algorithm2.9.9.1.m1.2.2.cmml">𝐲</mi><mo stretchy="false" id="algorithm2.9.9.1.m1.2.3.2.2.3" xref="algorithm2.9.9.1.m1.2.3.2.1.cmml">}</mo></mrow><mo id="algorithm2.9.9.1.m1.2.3.1" xref="algorithm2.9.9.1.m1.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="algorithm2.9.9.1.m1.2.3.3" xref="algorithm2.9.9.1.m1.2.3.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.9.9.1.m1.2b"><apply id="algorithm2.9.9.1.m1.2.3.cmml" xref="algorithm2.9.9.1.m1.2.3"><in id="algorithm2.9.9.1.m1.2.3.1.cmml" xref="algorithm2.9.9.1.m1.2.3.1"></in><set id="algorithm2.9.9.1.m1.2.3.2.1.cmml" xref="algorithm2.9.9.1.m1.2.3.2.2"><ci id="algorithm2.9.9.1.m1.1.1.cmml" xref="algorithm2.9.9.1.m1.1.1">𝐱</ci><ci id="algorithm2.9.9.1.m1.2.2.cmml" xref="algorithm2.9.9.1.m1.2.2">𝐲</ci></set><ci id="algorithm2.9.9.1.m1.2.3.3.cmml" xref="algorithm2.9.9.1.m1.2.3.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.9.9.1.m1.2c">\{\bm{x},\bm{y}\}\in\mathcal{X}</annotation></semantics></math></em> <span id="algorithm2.9.9.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm2.26.26" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

% <em id="algorithm2.26.26.1" class="ltx_emph ltx_font_italic">Forward pass</em>
</div>
<div id="algorithm2.11.11" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Intermediate representation <math id="algorithm2.10.10.m1.1" class="ltx_Math" alttext="\bm{T}_{0}=\bm{x}" display="inline"><semantics id="algorithm2.10.10.m1.1a"><mrow id="algorithm2.10.10.m1.1.1" xref="algorithm2.10.10.m1.1.1.cmml"><msub id="algorithm2.10.10.m1.1.1.2" xref="algorithm2.10.10.m1.1.1.2.cmml"><mi id="algorithm2.10.10.m1.1.1.2.2" xref="algorithm2.10.10.m1.1.1.2.2.cmml">𝑻</mi><mn id="algorithm2.10.10.m1.1.1.2.3" xref="algorithm2.10.10.m1.1.1.2.3.cmml">0</mn></msub><mo id="algorithm2.10.10.m1.1.1.1" xref="algorithm2.10.10.m1.1.1.1.cmml">=</mo><mi id="algorithm2.10.10.m1.1.1.3" xref="algorithm2.10.10.m1.1.1.3.cmml">𝒙</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.10.10.m1.1b"><apply id="algorithm2.10.10.m1.1.1.cmml" xref="algorithm2.10.10.m1.1.1"><eq id="algorithm2.10.10.m1.1.1.1.cmml" xref="algorithm2.10.10.m1.1.1.1"></eq><apply id="algorithm2.10.10.m1.1.1.2.cmml" xref="algorithm2.10.10.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.10.10.m1.1.1.2.1.cmml" xref="algorithm2.10.10.m1.1.1.2">subscript</csymbol><ci id="algorithm2.10.10.m1.1.1.2.2.cmml" xref="algorithm2.10.10.m1.1.1.2.2">𝑻</ci><cn type="integer" id="algorithm2.10.10.m1.1.1.2.3.cmml" xref="algorithm2.10.10.m1.1.1.2.3">0</cn></apply><ci id="algorithm2.10.10.m1.1.1.3.cmml" xref="algorithm2.10.10.m1.1.1.3">𝒙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.10.10.m1.1c">\bm{T}_{0}=\bm{x}</annotation></semantics></math> <svg id="algorithm2.11.11.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</div>
<div id="algorithm2.12.12" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm2.12.12.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm2.12.12.1" class="ltx_emph ltx_font_italic"><math id="algorithm2.12.12.1.m1.3" class="ltx_Math" alttext="i\in\{1,...,l-1\}" display="inline"><semantics id="algorithm2.12.12.1.m1.3a"><mrow id="algorithm2.12.12.1.m1.3.3" xref="algorithm2.12.12.1.m1.3.3.cmml"><mi id="algorithm2.12.12.1.m1.3.3.3" xref="algorithm2.12.12.1.m1.3.3.3.cmml">i</mi><mo id="algorithm2.12.12.1.m1.3.3.2" xref="algorithm2.12.12.1.m1.3.3.2.cmml">∈</mo><mrow id="algorithm2.12.12.1.m1.3.3.1.1" xref="algorithm2.12.12.1.m1.3.3.1.2.cmml"><mo stretchy="false" id="algorithm2.12.12.1.m1.3.3.1.1.2" xref="algorithm2.12.12.1.m1.3.3.1.2.cmml">{</mo><mn id="algorithm2.12.12.1.m1.1.1" xref="algorithm2.12.12.1.m1.1.1.cmml">1</mn><mo id="algorithm2.12.12.1.m1.3.3.1.1.3" xref="algorithm2.12.12.1.m1.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="algorithm2.12.12.1.m1.2.2" xref="algorithm2.12.12.1.m1.2.2.cmml">…</mi><mo id="algorithm2.12.12.1.m1.3.3.1.1.4" xref="algorithm2.12.12.1.m1.3.3.1.2.cmml">,</mo><mrow id="algorithm2.12.12.1.m1.3.3.1.1.1" xref="algorithm2.12.12.1.m1.3.3.1.1.1.cmml"><mi id="algorithm2.12.12.1.m1.3.3.1.1.1.2" xref="algorithm2.12.12.1.m1.3.3.1.1.1.2.cmml">l</mi><mo id="algorithm2.12.12.1.m1.3.3.1.1.1.1" xref="algorithm2.12.12.1.m1.3.3.1.1.1.1.cmml">−</mo><mn id="algorithm2.12.12.1.m1.3.3.1.1.1.3" xref="algorithm2.12.12.1.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="algorithm2.12.12.1.m1.3.3.1.1.5" xref="algorithm2.12.12.1.m1.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.12.12.1.m1.3b"><apply id="algorithm2.12.12.1.m1.3.3.cmml" xref="algorithm2.12.12.1.m1.3.3"><in id="algorithm2.12.12.1.m1.3.3.2.cmml" xref="algorithm2.12.12.1.m1.3.3.2"></in><ci id="algorithm2.12.12.1.m1.3.3.3.cmml" xref="algorithm2.12.12.1.m1.3.3.3">𝑖</ci><set id="algorithm2.12.12.1.m1.3.3.1.2.cmml" xref="algorithm2.12.12.1.m1.3.3.1.1"><cn type="integer" id="algorithm2.12.12.1.m1.1.1.cmml" xref="algorithm2.12.12.1.m1.1.1">1</cn><ci id="algorithm2.12.12.1.m1.2.2.cmml" xref="algorithm2.12.12.1.m1.2.2">…</ci><apply id="algorithm2.12.12.1.m1.3.3.1.1.1.cmml" xref="algorithm2.12.12.1.m1.3.3.1.1.1"><minus id="algorithm2.12.12.1.m1.3.3.1.1.1.1.cmml" xref="algorithm2.12.12.1.m1.3.3.1.1.1.1"></minus><ci id="algorithm2.12.12.1.m1.3.3.1.1.1.2.cmml" xref="algorithm2.12.12.1.m1.3.3.1.1.1.2">𝑙</ci><cn type="integer" id="algorithm2.12.12.1.m1.3.3.1.1.1.3.cmml" xref="algorithm2.12.12.1.m1.3.3.1.1.1.3">1</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.12.12.1.m1.3c">i\in\{1,...,l-1\}</annotation></semantics></math></em> <span id="algorithm2.12.12.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm2.13.13" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.13.13.m1.1" class="ltx_Math" alttext="\bm{T}_{i}=\sigma(\bm{W}_{i}\bm{T}_{i-1}+\bm{b}_{i})" display="inline"><semantics id="algorithm2.13.13.m1.1a"><mrow id="algorithm2.13.13.m1.1.1" xref="algorithm2.13.13.m1.1.1.cmml"><msub id="algorithm2.13.13.m1.1.1.3" xref="algorithm2.13.13.m1.1.1.3.cmml"><mi id="algorithm2.13.13.m1.1.1.3.2" xref="algorithm2.13.13.m1.1.1.3.2.cmml">𝑻</mi><mi id="algorithm2.13.13.m1.1.1.3.3" xref="algorithm2.13.13.m1.1.1.3.3.cmml">i</mi></msub><mo id="algorithm2.13.13.m1.1.1.2" xref="algorithm2.13.13.m1.1.1.2.cmml">=</mo><mrow id="algorithm2.13.13.m1.1.1.1" xref="algorithm2.13.13.m1.1.1.1.cmml"><mi id="algorithm2.13.13.m1.1.1.1.3" xref="algorithm2.13.13.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="algorithm2.13.13.m1.1.1.1.2" xref="algorithm2.13.13.m1.1.1.1.2.cmml">​</mo><mrow id="algorithm2.13.13.m1.1.1.1.1.1" xref="algorithm2.13.13.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algorithm2.13.13.m1.1.1.1.1.1.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="algorithm2.13.13.m1.1.1.1.1.1.1" xref="algorithm2.13.13.m1.1.1.1.1.1.1.cmml"><mrow id="algorithm2.13.13.m1.1.1.1.1.1.1.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.cmml"><msub id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.cmml"><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.2.cmml">𝑾</mi><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="algorithm2.13.13.m1.1.1.1.1.1.1.2.1" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.cmml"><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.2.cmml">𝑻</mi><mrow id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.2.cmml">i</mi><mo id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.1" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="algorithm2.13.13.m1.1.1.1.1.1.1.1" xref="algorithm2.13.13.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="algorithm2.13.13.m1.1.1.1.1.1.1.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3.cmml"><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.3.2" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3.2.cmml">𝒃</mi><mi id="algorithm2.13.13.m1.1.1.1.1.1.1.3.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="algorithm2.13.13.m1.1.1.1.1.1.3" xref="algorithm2.13.13.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.13.13.m1.1b"><apply id="algorithm2.13.13.m1.1.1.cmml" xref="algorithm2.13.13.m1.1.1"><eq id="algorithm2.13.13.m1.1.1.2.cmml" xref="algorithm2.13.13.m1.1.1.2"></eq><apply id="algorithm2.13.13.m1.1.1.3.cmml" xref="algorithm2.13.13.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.1.3.1.cmml" xref="algorithm2.13.13.m1.1.1.3">subscript</csymbol><ci id="algorithm2.13.13.m1.1.1.3.2.cmml" xref="algorithm2.13.13.m1.1.1.3.2">𝑻</ci><ci id="algorithm2.13.13.m1.1.1.3.3.cmml" xref="algorithm2.13.13.m1.1.1.3.3">𝑖</ci></apply><apply id="algorithm2.13.13.m1.1.1.1.cmml" xref="algorithm2.13.13.m1.1.1.1"><times id="algorithm2.13.13.m1.1.1.1.2.cmml" xref="algorithm2.13.13.m1.1.1.1.2"></times><ci id="algorithm2.13.13.m1.1.1.1.3.cmml" xref="algorithm2.13.13.m1.1.1.1.3">𝜎</ci><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1"><plus id="algorithm2.13.13.m1.1.1.1.1.1.1.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.1"></plus><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2"><times id="algorithm2.13.13.m1.1.1.1.1.1.1.2.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.1"></times><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.2">𝑾</ci><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.2">𝑻</ci><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3"><minus id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.1"></minus><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.2">𝑖</ci><cn type="integer" id="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><apply id="algorithm2.13.13.m1.1.1.1.1.1.1.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.1.1.1.1.1.3.1.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.3.2.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3.2">𝒃</ci><ci id="algorithm2.13.13.m1.1.1.1.1.1.1.3.3.cmml" xref="algorithm2.13.13.m1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.13.13.m1.1c">\bm{T}_{i}=\sigma(\bm{W}_{i}\bm{T}_{i-1}+\bm{b}_{i})</annotation></semantics></math>
</div>
<div id="algorithm2.26.27" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.15.15" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.14.14.m1.1" class="ltx_Math" alttext="\bm{T}_{l}=\sigma(\bm{W}_{l}\bm{T}_{l-1}+\bm{b}_{l})" display="inline"><semantics id="algorithm2.14.14.m1.1a"><mrow id="algorithm2.14.14.m1.1.1" xref="algorithm2.14.14.m1.1.1.cmml"><msub id="algorithm2.14.14.m1.1.1.3" xref="algorithm2.14.14.m1.1.1.3.cmml"><mi id="algorithm2.14.14.m1.1.1.3.2" xref="algorithm2.14.14.m1.1.1.3.2.cmml">𝑻</mi><mi id="algorithm2.14.14.m1.1.1.3.3" xref="algorithm2.14.14.m1.1.1.3.3.cmml">l</mi></msub><mo id="algorithm2.14.14.m1.1.1.2" xref="algorithm2.14.14.m1.1.1.2.cmml">=</mo><mrow id="algorithm2.14.14.m1.1.1.1" xref="algorithm2.14.14.m1.1.1.1.cmml"><mi id="algorithm2.14.14.m1.1.1.1.3" xref="algorithm2.14.14.m1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="algorithm2.14.14.m1.1.1.1.2" xref="algorithm2.14.14.m1.1.1.1.2.cmml">​</mo><mrow id="algorithm2.14.14.m1.1.1.1.1.1" xref="algorithm2.14.14.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algorithm2.14.14.m1.1.1.1.1.1.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="algorithm2.14.14.m1.1.1.1.1.1.1" xref="algorithm2.14.14.m1.1.1.1.1.1.1.cmml"><mrow id="algorithm2.14.14.m1.1.1.1.1.1.1.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.cmml"><msub id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.cmml"><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.2.cmml">𝑾</mi><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="algorithm2.14.14.m1.1.1.1.1.1.1.2.1" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.cmml"><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.2.cmml">𝑻</mi><mrow id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.2.cmml">l</mi><mo id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.1" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="algorithm2.14.14.m1.1.1.1.1.1.1.1" xref="algorithm2.14.14.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="algorithm2.14.14.m1.1.1.1.1.1.1.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3.cmml"><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.3.2" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3.2.cmml">𝒃</mi><mi id="algorithm2.14.14.m1.1.1.1.1.1.1.3.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3.3.cmml">l</mi></msub></mrow><mo stretchy="false" id="algorithm2.14.14.m1.1.1.1.1.1.3" xref="algorithm2.14.14.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.14.14.m1.1b"><apply id="algorithm2.14.14.m1.1.1.cmml" xref="algorithm2.14.14.m1.1.1"><eq id="algorithm2.14.14.m1.1.1.2.cmml" xref="algorithm2.14.14.m1.1.1.2"></eq><apply id="algorithm2.14.14.m1.1.1.3.cmml" xref="algorithm2.14.14.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm2.14.14.m1.1.1.3.1.cmml" xref="algorithm2.14.14.m1.1.1.3">subscript</csymbol><ci id="algorithm2.14.14.m1.1.1.3.2.cmml" xref="algorithm2.14.14.m1.1.1.3.2">𝑻</ci><ci id="algorithm2.14.14.m1.1.1.3.3.cmml" xref="algorithm2.14.14.m1.1.1.3.3">𝑙</ci></apply><apply id="algorithm2.14.14.m1.1.1.1.cmml" xref="algorithm2.14.14.m1.1.1.1"><times id="algorithm2.14.14.m1.1.1.1.2.cmml" xref="algorithm2.14.14.m1.1.1.1.2"></times><ci id="algorithm2.14.14.m1.1.1.1.3.cmml" xref="algorithm2.14.14.m1.1.1.1.3">𝜎</ci><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1"><plus id="algorithm2.14.14.m1.1.1.1.1.1.1.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.1"></plus><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2"><times id="algorithm2.14.14.m1.1.1.1.1.1.1.2.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.1"></times><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.2">𝑾</ci><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.2.3">𝑙</ci></apply><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.2">𝑻</ci><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3"><minus id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.1"></minus><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.2">𝑙</ci><cn type="integer" id="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><apply id="algorithm2.14.14.m1.1.1.1.1.1.1.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="algorithm2.14.14.m1.1.1.1.1.1.1.3.1.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.3.2.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3.2">𝒃</ci><ci id="algorithm2.14.14.m1.1.1.1.1.1.1.3.3.cmml" xref="algorithm2.14.14.m1.1.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.14.14.m1.1c">\bm{T}_{l}=\sigma(\bm{W}_{l}\bm{T}_{l-1}+\bm{b}_{l})</annotation></semantics></math> <svg id="algorithm2.15.15.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</div>
<div id="algorithm2.16.16" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.16.16.m1.2" class="ltx_Math" alttext="\ell\xleftarrow{}\ell(C(\bm{T}_{l}),\bm{y})" display="inline"><semantics id="algorithm2.16.16.m1.2a"><mrow id="algorithm2.16.16.m1.2.2" xref="algorithm2.16.16.m1.2.2.cmml"><mi mathvariant="normal" id="algorithm2.16.16.m1.2.2.3" xref="algorithm2.16.16.m1.2.2.3.cmml">ℓ</mi><mover accent="true" id="algorithm2.16.16.m1.2.2.2" xref="algorithm2.16.16.m1.2.2.2.cmml"><mo stretchy="false" id="algorithm2.16.16.m1.2.2.2.2" xref="algorithm2.16.16.m1.2.2.2.2.cmml">←</mo><mi id="algorithm2.16.16.m1.2.2.2.1" xref="algorithm2.16.16.m1.2.2.2.1.cmml"></mi></mover><mrow id="algorithm2.16.16.m1.2.2.1" xref="algorithm2.16.16.m1.2.2.1.cmml"><mi mathvariant="normal" id="algorithm2.16.16.m1.2.2.1.3" xref="algorithm2.16.16.m1.2.2.1.3.cmml">ℓ</mi><mo lspace="0em" rspace="0em" id="algorithm2.16.16.m1.2.2.1.2" xref="algorithm2.16.16.m1.2.2.1.2.cmml">​</mo><mrow id="algorithm2.16.16.m1.2.2.1.1.1" xref="algorithm2.16.16.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="algorithm2.16.16.m1.2.2.1.1.1.2" xref="algorithm2.16.16.m1.2.2.1.1.2.cmml">(</mo><mrow id="algorithm2.16.16.m1.2.2.1.1.1.1" xref="algorithm2.16.16.m1.2.2.1.1.1.1.cmml"><mi id="algorithm2.16.16.m1.2.2.1.1.1.1.3" xref="algorithm2.16.16.m1.2.2.1.1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="algorithm2.16.16.m1.2.2.1.1.1.1.2" xref="algorithm2.16.16.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.2" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.2" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.2.cmml">𝑻</mi><mi id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.3" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.3.cmml">l</mi></msub><mo stretchy="false" id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.3" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="algorithm2.16.16.m1.2.2.1.1.1.3" xref="algorithm2.16.16.m1.2.2.1.1.2.cmml">,</mo><mi id="algorithm2.16.16.m1.1.1" xref="algorithm2.16.16.m1.1.1.cmml">𝒚</mi><mo stretchy="false" id="algorithm2.16.16.m1.2.2.1.1.1.4" xref="algorithm2.16.16.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.16.16.m1.2b"><apply id="algorithm2.16.16.m1.2.2.cmml" xref="algorithm2.16.16.m1.2.2"><apply id="algorithm2.16.16.m1.2.2.2.cmml" xref="algorithm2.16.16.m1.2.2.2"><csymbol cd="latexml" id="algorithm2.16.16.m1.2.2.2.1.cmml" xref="algorithm2.16.16.m1.2.2.2.1">absent</csymbol><ci id="algorithm2.16.16.m1.2.2.2.2.cmml" xref="algorithm2.16.16.m1.2.2.2.2">←</ci></apply><ci id="algorithm2.16.16.m1.2.2.3.cmml" xref="algorithm2.16.16.m1.2.2.3">ℓ</ci><apply id="algorithm2.16.16.m1.2.2.1.cmml" xref="algorithm2.16.16.m1.2.2.1"><times id="algorithm2.16.16.m1.2.2.1.2.cmml" xref="algorithm2.16.16.m1.2.2.1.2"></times><ci id="algorithm2.16.16.m1.2.2.1.3.cmml" xref="algorithm2.16.16.m1.2.2.1.3">ℓ</ci><interval closure="open" id="algorithm2.16.16.m1.2.2.1.1.2.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1"><apply id="algorithm2.16.16.m1.2.2.1.1.1.1.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1"><times id="algorithm2.16.16.m1.2.2.1.1.1.1.2.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.2"></times><ci id="algorithm2.16.16.m1.2.2.1.1.1.1.3.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.3">𝐶</ci><apply id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.2">𝑻</ci><ci id="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="algorithm2.16.16.m1.2.2.1.1.1.1.1.1.1.3">𝑙</ci></apply></apply><ci id="algorithm2.16.16.m1.1.1.cmml" xref="algorithm2.16.16.m1.1.1">𝒚</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.16.16.m1.2c">\ell\xleftarrow{}\ell(C(\bm{T}_{l}),\bm{y})</annotation></semantics></math>
</div>
<div id="algorithm2.26.28" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

% <em id="algorithm2.26.28.1" class="ltx_emph ltx_font_italic">Backward pass</em>
</div>
<div id="algorithm2.18.18" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.17.17.m1.1" class="ltx_Math" alttext="\frac{\partial\ell}{\partial C}" display="inline"><semantics id="algorithm2.17.17.m1.1a"><mfrac id="algorithm2.17.17.m1.1.1" xref="algorithm2.17.17.m1.1.1.cmml"><mrow id="algorithm2.17.17.m1.1.1.2" xref="algorithm2.17.17.m1.1.1.2.cmml"><mo rspace="0em" id="algorithm2.17.17.m1.1.1.2.1" xref="algorithm2.17.17.m1.1.1.2.1.cmml">∂</mo><mi mathvariant="normal" id="algorithm2.17.17.m1.1.1.2.2" xref="algorithm2.17.17.m1.1.1.2.2.cmml">ℓ</mi></mrow><mrow id="algorithm2.17.17.m1.1.1.3" xref="algorithm2.17.17.m1.1.1.3.cmml"><mo rspace="0em" id="algorithm2.17.17.m1.1.1.3.1" xref="algorithm2.17.17.m1.1.1.3.1.cmml">∂</mo><mi id="algorithm2.17.17.m1.1.1.3.2" xref="algorithm2.17.17.m1.1.1.3.2.cmml">C</mi></mrow></mfrac><annotation-xml encoding="MathML-Content" id="algorithm2.17.17.m1.1b"><apply id="algorithm2.17.17.m1.1.1.cmml" xref="algorithm2.17.17.m1.1.1"><divide id="algorithm2.17.17.m1.1.1.1.cmml" xref="algorithm2.17.17.m1.1.1"></divide><apply id="algorithm2.17.17.m1.1.1.2.cmml" xref="algorithm2.17.17.m1.1.1.2"><partialdiff id="algorithm2.17.17.m1.1.1.2.1.cmml" xref="algorithm2.17.17.m1.1.1.2.1"></partialdiff><ci id="algorithm2.17.17.m1.1.1.2.2.cmml" xref="algorithm2.17.17.m1.1.1.2.2">ℓ</ci></apply><apply id="algorithm2.17.17.m1.1.1.3.cmml" xref="algorithm2.17.17.m1.1.1.3"><partialdiff id="algorithm2.17.17.m1.1.1.3.1.cmml" xref="algorithm2.17.17.m1.1.1.3.1"></partialdiff><ci id="algorithm2.17.17.m1.1.1.3.2.cmml" xref="algorithm2.17.17.m1.1.1.3.2">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.17.17.m1.1c">\frac{\partial\ell}{\partial C}</annotation></semantics></math> to update parameters of <math id="algorithm2.18.18.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="algorithm2.18.18.m2.1a"><mi id="algorithm2.18.18.m2.1.1" xref="algorithm2.18.18.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="algorithm2.18.18.m2.1b"><ci id="algorithm2.18.18.m2.1.1.cmml" xref="algorithm2.18.18.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.18.18.m2.1c">C</annotation></semantics></math>
</div>
<div id="algorithm2.26.29" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

% <em id="algorithm2.26.29.1" class="ltx_emph ltx_font_italic">Updating layer l</em>
</div>
<div id="algorithm2.21.21" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm2.19.19.m1.1" class="ltx_Math" alttext="\bm{W}_{l}\xleftarrow{}\bm{W}_{l}+\frac{\partial\ell}{\partial\bm{W}_{l}}" display="inline"><semantics id="algorithm2.19.19.m1.1a"><mrow id="algorithm2.19.19.m1.1.1" xref="algorithm2.19.19.m1.1.1.cmml"><msub id="algorithm2.19.19.m1.1.1.2" xref="algorithm2.19.19.m1.1.1.2.cmml"><mi id="algorithm2.19.19.m1.1.1.2.2" xref="algorithm2.19.19.m1.1.1.2.2.cmml">𝑾</mi><mi id="algorithm2.19.19.m1.1.1.2.3" xref="algorithm2.19.19.m1.1.1.2.3.cmml">l</mi></msub><mover accent="true" id="algorithm2.19.19.m1.1.1.1" xref="algorithm2.19.19.m1.1.1.1.cmml"><mo stretchy="false" id="algorithm2.19.19.m1.1.1.1.2" xref="algorithm2.19.19.m1.1.1.1.2.cmml">←</mo><mi id="algorithm2.19.19.m1.1.1.1.1" xref="algorithm2.19.19.m1.1.1.1.1.cmml"></mi></mover><mrow id="algorithm2.19.19.m1.1.1.3" xref="algorithm2.19.19.m1.1.1.3.cmml"><msub id="algorithm2.19.19.m1.1.1.3.2" xref="algorithm2.19.19.m1.1.1.3.2.cmml"><mi id="algorithm2.19.19.m1.1.1.3.2.2" xref="algorithm2.19.19.m1.1.1.3.2.2.cmml">𝑾</mi><mi id="algorithm2.19.19.m1.1.1.3.2.3" xref="algorithm2.19.19.m1.1.1.3.2.3.cmml">l</mi></msub><mo id="algorithm2.19.19.m1.1.1.3.1" xref="algorithm2.19.19.m1.1.1.3.1.cmml">+</mo><mfrac id="algorithm2.19.19.m1.1.1.3.3" xref="algorithm2.19.19.m1.1.1.3.3.cmml"><mrow id="algorithm2.19.19.m1.1.1.3.3.2" xref="algorithm2.19.19.m1.1.1.3.3.2.cmml"><mo rspace="0em" id="algorithm2.19.19.m1.1.1.3.3.2.1" xref="algorithm2.19.19.m1.1.1.3.3.2.1.cmml">∂</mo><mi mathvariant="normal" id="algorithm2.19.19.m1.1.1.3.3.2.2" xref="algorithm2.19.19.m1.1.1.3.3.2.2.cmml">ℓ</mi></mrow><mrow id="algorithm2.19.19.m1.1.1.3.3.3" xref="algorithm2.19.19.m1.1.1.3.3.3.cmml"><mo rspace="0em" id="algorithm2.19.19.m1.1.1.3.3.3.1" xref="algorithm2.19.19.m1.1.1.3.3.3.1.cmml">∂</mo><msub id="algorithm2.19.19.m1.1.1.3.3.3.2" xref="algorithm2.19.19.m1.1.1.3.3.3.2.cmml"><mi id="algorithm2.19.19.m1.1.1.3.3.3.2.2" xref="algorithm2.19.19.m1.1.1.3.3.3.2.2.cmml">𝑾</mi><mi id="algorithm2.19.19.m1.1.1.3.3.3.2.3" xref="algorithm2.19.19.m1.1.1.3.3.3.2.3.cmml">l</mi></msub></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.19.19.m1.1b"><apply id="algorithm2.19.19.m1.1.1.cmml" xref="algorithm2.19.19.m1.1.1"><apply id="algorithm2.19.19.m1.1.1.1.cmml" xref="algorithm2.19.19.m1.1.1.1"><csymbol cd="latexml" id="algorithm2.19.19.m1.1.1.1.1.cmml" xref="algorithm2.19.19.m1.1.1.1.1">absent</csymbol><ci id="algorithm2.19.19.m1.1.1.1.2.cmml" xref="algorithm2.19.19.m1.1.1.1.2">←</ci></apply><apply id="algorithm2.19.19.m1.1.1.2.cmml" xref="algorithm2.19.19.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.19.19.m1.1.1.2.1.cmml" xref="algorithm2.19.19.m1.1.1.2">subscript</csymbol><ci id="algorithm2.19.19.m1.1.1.2.2.cmml" xref="algorithm2.19.19.m1.1.1.2.2">𝑾</ci><ci id="algorithm2.19.19.m1.1.1.2.3.cmml" xref="algorithm2.19.19.m1.1.1.2.3">𝑙</ci></apply><apply id="algorithm2.19.19.m1.1.1.3.cmml" xref="algorithm2.19.19.m1.1.1.3"><plus id="algorithm2.19.19.m1.1.1.3.1.cmml" xref="algorithm2.19.19.m1.1.1.3.1"></plus><apply id="algorithm2.19.19.m1.1.1.3.2.cmml" xref="algorithm2.19.19.m1.1.1.3.2"><csymbol cd="ambiguous" id="algorithm2.19.19.m1.1.1.3.2.1.cmml" xref="algorithm2.19.19.m1.1.1.3.2">subscript</csymbol><ci id="algorithm2.19.19.m1.1.1.3.2.2.cmml" xref="algorithm2.19.19.m1.1.1.3.2.2">𝑾</ci><ci id="algorithm2.19.19.m1.1.1.3.2.3.cmml" xref="algorithm2.19.19.m1.1.1.3.2.3">𝑙</ci></apply><apply id="algorithm2.19.19.m1.1.1.3.3.cmml" xref="algorithm2.19.19.m1.1.1.3.3"><divide id="algorithm2.19.19.m1.1.1.3.3.1.cmml" xref="algorithm2.19.19.m1.1.1.3.3"></divide><apply id="algorithm2.19.19.m1.1.1.3.3.2.cmml" xref="algorithm2.19.19.m1.1.1.3.3.2"><partialdiff id="algorithm2.19.19.m1.1.1.3.3.2.1.cmml" xref="algorithm2.19.19.m1.1.1.3.3.2.1"></partialdiff><ci id="algorithm2.19.19.m1.1.1.3.3.2.2.cmml" xref="algorithm2.19.19.m1.1.1.3.3.2.2">ℓ</ci></apply><apply id="algorithm2.19.19.m1.1.1.3.3.3.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3"><partialdiff id="algorithm2.19.19.m1.1.1.3.3.3.1.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3.1"></partialdiff><apply id="algorithm2.19.19.m1.1.1.3.3.3.2.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="algorithm2.19.19.m1.1.1.3.3.3.2.1.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3.2">subscript</csymbol><ci id="algorithm2.19.19.m1.1.1.3.3.3.2.2.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3.2.2">𝑾</ci><ci id="algorithm2.19.19.m1.1.1.3.3.3.2.3.cmml" xref="algorithm2.19.19.m1.1.1.3.3.3.2.3">𝑙</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.19.19.m1.1c">\bm{W}_{l}\xleftarrow{}\bm{W}_{l}+\frac{\partial\ell}{\partial\bm{W}_{l}}</annotation></semantics></math>; <math id="algorithm2.20.20.m2.1" class="ltx_Math" alttext="\bm{b}_{l}\xleftarrow{}\bm{b}_{l}+\frac{\partial\ell}{\partial\bm{b}_{l}}" display="inline"><semantics id="algorithm2.20.20.m2.1a"><mrow id="algorithm2.20.20.m2.1.1" xref="algorithm2.20.20.m2.1.1.cmml"><msub id="algorithm2.20.20.m2.1.1.2" xref="algorithm2.20.20.m2.1.1.2.cmml"><mi id="algorithm2.20.20.m2.1.1.2.2" xref="algorithm2.20.20.m2.1.1.2.2.cmml">𝒃</mi><mi id="algorithm2.20.20.m2.1.1.2.3" xref="algorithm2.20.20.m2.1.1.2.3.cmml">l</mi></msub><mover accent="true" id="algorithm2.20.20.m2.1.1.1" xref="algorithm2.20.20.m2.1.1.1.cmml"><mo stretchy="false" id="algorithm2.20.20.m2.1.1.1.2" xref="algorithm2.20.20.m2.1.1.1.2.cmml">←</mo><mi id="algorithm2.20.20.m2.1.1.1.1" xref="algorithm2.20.20.m2.1.1.1.1.cmml"></mi></mover><mrow id="algorithm2.20.20.m2.1.1.3" xref="algorithm2.20.20.m2.1.1.3.cmml"><msub id="algorithm2.20.20.m2.1.1.3.2" xref="algorithm2.20.20.m2.1.1.3.2.cmml"><mi id="algorithm2.20.20.m2.1.1.3.2.2" xref="algorithm2.20.20.m2.1.1.3.2.2.cmml">𝒃</mi><mi id="algorithm2.20.20.m2.1.1.3.2.3" xref="algorithm2.20.20.m2.1.1.3.2.3.cmml">l</mi></msub><mo id="algorithm2.20.20.m2.1.1.3.1" xref="algorithm2.20.20.m2.1.1.3.1.cmml">+</mo><mfrac id="algorithm2.20.20.m2.1.1.3.3" xref="algorithm2.20.20.m2.1.1.3.3.cmml"><mrow id="algorithm2.20.20.m2.1.1.3.3.2" xref="algorithm2.20.20.m2.1.1.3.3.2.cmml"><mo rspace="0em" id="algorithm2.20.20.m2.1.1.3.3.2.1" xref="algorithm2.20.20.m2.1.1.3.3.2.1.cmml">∂</mo><mi mathvariant="normal" id="algorithm2.20.20.m2.1.1.3.3.2.2" xref="algorithm2.20.20.m2.1.1.3.3.2.2.cmml">ℓ</mi></mrow><mrow id="algorithm2.20.20.m2.1.1.3.3.3" xref="algorithm2.20.20.m2.1.1.3.3.3.cmml"><mo rspace="0em" id="algorithm2.20.20.m2.1.1.3.3.3.1" xref="algorithm2.20.20.m2.1.1.3.3.3.1.cmml">∂</mo><msub id="algorithm2.20.20.m2.1.1.3.3.3.2" xref="algorithm2.20.20.m2.1.1.3.3.3.2.cmml"><mi id="algorithm2.20.20.m2.1.1.3.3.3.2.2" xref="algorithm2.20.20.m2.1.1.3.3.3.2.2.cmml">𝒃</mi><mi id="algorithm2.20.20.m2.1.1.3.3.3.2.3" xref="algorithm2.20.20.m2.1.1.3.3.3.2.3.cmml">l</mi></msub></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.20.20.m2.1b"><apply id="algorithm2.20.20.m2.1.1.cmml" xref="algorithm2.20.20.m2.1.1"><apply id="algorithm2.20.20.m2.1.1.1.cmml" xref="algorithm2.20.20.m2.1.1.1"><csymbol cd="latexml" id="algorithm2.20.20.m2.1.1.1.1.cmml" xref="algorithm2.20.20.m2.1.1.1.1">absent</csymbol><ci id="algorithm2.20.20.m2.1.1.1.2.cmml" xref="algorithm2.20.20.m2.1.1.1.2">←</ci></apply><apply id="algorithm2.20.20.m2.1.1.2.cmml" xref="algorithm2.20.20.m2.1.1.2"><csymbol cd="ambiguous" id="algorithm2.20.20.m2.1.1.2.1.cmml" xref="algorithm2.20.20.m2.1.1.2">subscript</csymbol><ci id="algorithm2.20.20.m2.1.1.2.2.cmml" xref="algorithm2.20.20.m2.1.1.2.2">𝒃</ci><ci id="algorithm2.20.20.m2.1.1.2.3.cmml" xref="algorithm2.20.20.m2.1.1.2.3">𝑙</ci></apply><apply id="algorithm2.20.20.m2.1.1.3.cmml" xref="algorithm2.20.20.m2.1.1.3"><plus id="algorithm2.20.20.m2.1.1.3.1.cmml" xref="algorithm2.20.20.m2.1.1.3.1"></plus><apply id="algorithm2.20.20.m2.1.1.3.2.cmml" xref="algorithm2.20.20.m2.1.1.3.2"><csymbol cd="ambiguous" id="algorithm2.20.20.m2.1.1.3.2.1.cmml" xref="algorithm2.20.20.m2.1.1.3.2">subscript</csymbol><ci id="algorithm2.20.20.m2.1.1.3.2.2.cmml" xref="algorithm2.20.20.m2.1.1.3.2.2">𝒃</ci><ci id="algorithm2.20.20.m2.1.1.3.2.3.cmml" xref="algorithm2.20.20.m2.1.1.3.2.3">𝑙</ci></apply><apply id="algorithm2.20.20.m2.1.1.3.3.cmml" xref="algorithm2.20.20.m2.1.1.3.3"><divide id="algorithm2.20.20.m2.1.1.3.3.1.cmml" xref="algorithm2.20.20.m2.1.1.3.3"></divide><apply id="algorithm2.20.20.m2.1.1.3.3.2.cmml" xref="algorithm2.20.20.m2.1.1.3.3.2"><partialdiff id="algorithm2.20.20.m2.1.1.3.3.2.1.cmml" xref="algorithm2.20.20.m2.1.1.3.3.2.1"></partialdiff><ci id="algorithm2.20.20.m2.1.1.3.3.2.2.cmml" xref="algorithm2.20.20.m2.1.1.3.3.2.2">ℓ</ci></apply><apply id="algorithm2.20.20.m2.1.1.3.3.3.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3"><partialdiff id="algorithm2.20.20.m2.1.1.3.3.3.1.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3.1"></partialdiff><apply id="algorithm2.20.20.m2.1.1.3.3.3.2.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3.2"><csymbol cd="ambiguous" id="algorithm2.20.20.m2.1.1.3.3.3.2.1.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3.2">subscript</csymbol><ci id="algorithm2.20.20.m2.1.1.3.3.3.2.2.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3.2.2">𝒃</ci><ci id="algorithm2.20.20.m2.1.1.3.3.3.2.3.cmml" xref="algorithm2.20.20.m2.1.1.3.3.3.2.3">𝑙</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.20.20.m2.1c">\bm{b}_{l}\xleftarrow{}\bm{b}_{l}+\frac{\partial\ell}{\partial\bm{b}_{l}}</annotation></semantics></math>  <svg id="algorithm2.21.21.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>

</div>
<div id="algorithm2.22.22" class="ltx_listingline">
<math id="algorithm2.22.22.m1.2" class="ltx_Math" alttext="\bm{\theta}_{l}=\{\bm{W}_{l},\bm{b}_{l}\}" display="inline"><semantics id="algorithm2.22.22.m1.2a"><mrow id="algorithm2.22.22.m1.2.2" xref="algorithm2.22.22.m1.2.2.cmml"><msub id="algorithm2.22.22.m1.2.2.4" xref="algorithm2.22.22.m1.2.2.4.cmml"><mi id="algorithm2.22.22.m1.2.2.4.2" xref="algorithm2.22.22.m1.2.2.4.2.cmml">𝜽</mi><mi id="algorithm2.22.22.m1.2.2.4.3" xref="algorithm2.22.22.m1.2.2.4.3.cmml">l</mi></msub><mo id="algorithm2.22.22.m1.2.2.3" xref="algorithm2.22.22.m1.2.2.3.cmml">=</mo><mrow id="algorithm2.22.22.m1.2.2.2.2" xref="algorithm2.22.22.m1.2.2.2.3.cmml"><mo stretchy="false" id="algorithm2.22.22.m1.2.2.2.2.3" xref="algorithm2.22.22.m1.2.2.2.3.cmml">{</mo><msub id="algorithm2.22.22.m1.1.1.1.1.1" xref="algorithm2.22.22.m1.1.1.1.1.1.cmml"><mi id="algorithm2.22.22.m1.1.1.1.1.1.2" xref="algorithm2.22.22.m1.1.1.1.1.1.2.cmml">𝑾</mi><mi id="algorithm2.22.22.m1.1.1.1.1.1.3" xref="algorithm2.22.22.m1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="algorithm2.22.22.m1.2.2.2.2.4" xref="algorithm2.22.22.m1.2.2.2.3.cmml">,</mo><msub id="algorithm2.22.22.m1.2.2.2.2.2" xref="algorithm2.22.22.m1.2.2.2.2.2.cmml"><mi id="algorithm2.22.22.m1.2.2.2.2.2.2" xref="algorithm2.22.22.m1.2.2.2.2.2.2.cmml">𝒃</mi><mi id="algorithm2.22.22.m1.2.2.2.2.2.3" xref="algorithm2.22.22.m1.2.2.2.2.2.3.cmml">l</mi></msub><mo stretchy="false" id="algorithm2.22.22.m1.2.2.2.2.5" xref="algorithm2.22.22.m1.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.22.22.m1.2b"><apply id="algorithm2.22.22.m1.2.2.cmml" xref="algorithm2.22.22.m1.2.2"><eq id="algorithm2.22.22.m1.2.2.3.cmml" xref="algorithm2.22.22.m1.2.2.3"></eq><apply id="algorithm2.22.22.m1.2.2.4.cmml" xref="algorithm2.22.22.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm2.22.22.m1.2.2.4.1.cmml" xref="algorithm2.22.22.m1.2.2.4">subscript</csymbol><ci id="algorithm2.22.22.m1.2.2.4.2.cmml" xref="algorithm2.22.22.m1.2.2.4.2">𝜽</ci><ci id="algorithm2.22.22.m1.2.2.4.3.cmml" xref="algorithm2.22.22.m1.2.2.4.3">𝑙</ci></apply><set id="algorithm2.22.22.m1.2.2.2.3.cmml" xref="algorithm2.22.22.m1.2.2.2.2"><apply id="algorithm2.22.22.m1.1.1.1.1.1.cmml" xref="algorithm2.22.22.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm2.22.22.m1.1.1.1.1.1.1.cmml" xref="algorithm2.22.22.m1.1.1.1.1.1">subscript</csymbol><ci id="algorithm2.22.22.m1.1.1.1.1.1.2.cmml" xref="algorithm2.22.22.m1.1.1.1.1.1.2">𝑾</ci><ci id="algorithm2.22.22.m1.1.1.1.1.1.3.cmml" xref="algorithm2.22.22.m1.1.1.1.1.1.3">𝑙</ci></apply><apply id="algorithm2.22.22.m1.2.2.2.2.2.cmml" xref="algorithm2.22.22.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm2.22.22.m1.2.2.2.2.2.1.cmml" xref="algorithm2.22.22.m1.2.2.2.2.2">subscript</csymbol><ci id="algorithm2.22.22.m1.2.2.2.2.2.2.cmml" xref="algorithm2.22.22.m1.2.2.2.2.2.2">𝒃</ci><ci id="algorithm2.22.22.m1.2.2.2.2.2.3.cmml" xref="algorithm2.22.22.m1.2.2.2.2.2.3">𝑙</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.22.22.m1.2c">\bm{\theta}_{l}=\{\bm{W}_{l},\bm{b}_{l}\}</annotation></semantics></math> <span id="algorithm2.22.22.1" class="ltx_text" style="color:#228B22;">in TEE</span>
</div>
<div id="algorithm2.26.24" class="ltx_listingline">

return <math id="algorithm2.23.23.m1.1" class="ltx_Math" alttext="\bm{\theta}_{l}" display="inline"><semantics id="algorithm2.23.23.m1.1a"><msub id="algorithm2.23.23.m1.1.1" xref="algorithm2.23.23.m1.1.1.cmml"><mi id="algorithm2.23.23.m1.1.1.2" xref="algorithm2.23.23.m1.1.1.2.cmml">𝜽</mi><mi id="algorithm2.23.23.m1.1.1.3" xref="algorithm2.23.23.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm2.23.23.m1.1b"><apply id="algorithm2.23.23.m1.1.1.cmml" xref="algorithm2.23.23.m1.1.1"><csymbol cd="ambiguous" id="algorithm2.23.23.m1.1.1.1.cmml" xref="algorithm2.23.23.m1.1.1">subscript</csymbol><ci id="algorithm2.23.23.m1.1.1.2.cmml" xref="algorithm2.23.23.m1.1.1.2">𝜽</ci><ci id="algorithm2.23.23.m1.1.1.3.cmml" xref="algorithm2.23.23.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.23.23.m1.1c">\bm{\theta}_{l}</annotation></semantics></math>

 <svg id="algorithm2.26.24.pic1" class="ltx_picture" height="18.91" overflow="visible" version="1.1" width="70.49"><g transform="translate(0,18.91) matrix(1 0 0 -1 0 0) translate(1.11,0) translate(0,9.45)" fill="#000000" stroke="#000000" stroke-width="1.6pt"><g stroke="#228B22" fill="#228B22" color="#228B22"><path d="M 0 4.89 M 0 4.89 C 2.08 4.52 3.46 3.67 3.46 2.44 L 3.46 2.44 C 3.46 1.22 4.84 0.37 6.92 0 C 4.84 -0.37 3.46 -1.22 3.46 -2.44 L 3.46 -2.44 C 3.46 -3.67 2.08 -4.52 0 -4.89" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 5.72 -4.84)" fill="#228B22" stroke="#228B22" color="#228B22"><foreignObject width="59.06" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">
<span id="algorithm2.26.24.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top" style="width:42.7pt;">
<span id="algorithm2.26.24.pic1.1.1.1.1.1.1" class="ltx_p"></span>
<span id="algorithm2.26.24.pic1.1.1.1.1.1.2" class="ltx_p">in TEE</span>
</span></foreignObject></g></g></svg>


</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm2.28.2.1" class="ltx_text ltx_font_bold">Algorithm 2</span> </span><span id="algorithm2.25.1" class="ltx_text ltx_font_bold">ClientUpdate<math id="algorithm2.25.1.m1.2" class="ltx_Math" alttext="(l,\bm{\theta}_{l})" display="inline"><semantics id="algorithm2.25.1.m1.2b"><mrow id="algorithm2.25.1.m1.2.2.1" xref="algorithm2.25.1.m1.2.2.2.cmml"><mo stretchy="false" id="algorithm2.25.1.m1.2.2.1.2" xref="algorithm2.25.1.m1.2.2.2.cmml">(</mo><mi id="algorithm2.25.1.m1.1.1" xref="algorithm2.25.1.m1.1.1.cmml">l</mi><mo id="algorithm2.25.1.m1.2.2.1.3" xref="algorithm2.25.1.m1.2.2.2.cmml">,</mo><msub id="algorithm2.25.1.m1.2.2.1.1" xref="algorithm2.25.1.m1.2.2.1.1.cmml"><mi id="algorithm2.25.1.m1.2.2.1.1.2" xref="algorithm2.25.1.m1.2.2.1.1.2.cmml">θ</mi><mi id="algorithm2.25.1.m1.2.2.1.1.3" xref="algorithm2.25.1.m1.2.2.1.1.3.cmml">l</mi></msub><mo stretchy="false" id="algorithm2.25.1.m1.2.2.1.4" xref="algorithm2.25.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.25.1.m1.2c"><interval closure="open" id="algorithm2.25.1.m1.2.2.2.cmml" xref="algorithm2.25.1.m1.2.2.1"><ci id="algorithm2.25.1.m1.1.1.cmml" xref="algorithm2.25.1.m1.1.1">𝑙</ci><apply id="algorithm2.25.1.m1.2.2.1.1.cmml" xref="algorithm2.25.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="algorithm2.25.1.m1.2.2.1.1.1.cmml" xref="algorithm2.25.1.m1.2.2.1.1">subscript</csymbol><ci id="algorithm2.25.1.m1.2.2.1.1.2.cmml" xref="algorithm2.25.1.m1.2.2.1.1.2">𝜃</ci><ci id="algorithm2.25.1.m1.2.2.1.1.3.cmml" xref="algorithm2.25.1.m1.2.2.1.1.3">𝑙</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.25.1.m1.2d">(l,\bm{\theta}_{l})</annotation></semantics></math></span> with TEEs</figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.4" class="ltx_p"><span id="S4.SS2.p4.4.1" class="ltx_text ltx_font_bold">Model Partitioned Execution.</span>
The above learning process is based on a technique that conducts model training (including both forward and backward passes) across REEs and TEEs, namely model partitioned execution.
The transmission of the forward activations (i.e., intermediate representation) and updated parameters happens between the REE and the TEE via <em id="S4.SS2.p4.4.2" class="ltx_emph ltx_font_italic">shared memory</em>.
On a high level, when a set of layers is in the TEE, activations are transferred from the REE to the TEE (see Algorithm <a href="#algorithm2" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Assuming global layer <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">l</annotation></semantics></math> is under training, the layer with its classifier <math id="S4.SS2.p4.2.m2.1" class="ltx_math_unparsed" alttext="C(.)" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1b"><mi id="S4.SS2.p4.2.m2.1.1">C</mi><mrow id="S4.SS2.p4.2.m2.1.2"><mo stretchy="false" id="S4.SS2.p4.2.m2.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S4.SS2.p4.2.m2.1.2.2">.</mo><mo stretchy="false" id="S4.SS2.p4.2.m2.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">C(.)</annotation></semantics></math> are executed in the TEE, and the previous layers (i.e., <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mn id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><cn type="integer" id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">1</annotation></semantics></math> to <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="l-1" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mrow id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml"><mi id="S4.SS2.p4.4.m4.1.1.2" xref="S4.SS2.p4.4.m4.1.1.2.cmml">l</mi><mo id="S4.SS2.p4.4.m4.1.1.1" xref="S4.SS2.p4.4.m4.1.1.1.cmml">−</mo><mn id="S4.SS2.p4.4.m4.1.1.3" xref="S4.SS2.p4.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><apply id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1"><minus id="S4.SS2.p4.4.m4.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1"></minus><ci id="S4.SS2.p4.4.m4.1.1.2.cmml" xref="S4.SS2.p4.4.m4.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p4.4.m4.1.1.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">l-1</annotation></semantics></math>) are in the REE.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.9" class="ltx_p">Before training, layer <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mi id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><ci id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">l</annotation></semantics></math>’s parameters are loaded and decrypted securely within the TEE.
During the <em id="S4.SS2.p5.9.1" class="ltx_emph ltx_font_italic">forward pass</em>, local data <math id="S4.SS2.p5.2.m2.1" class="ltx_Math" alttext="\bm{x}" display="inline"><semantics id="S4.SS2.p5.2.m2.1a"><mi id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><ci id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">\bm{x}</annotation></semantics></math> are inputted, and the REE processes the previous layers from <math id="S4.SS2.p5.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS2.p5.3.m3.1a"><mn id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.1b"><cn type="integer" id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.1c">1</annotation></semantics></math> to <math id="S4.SS2.p5.4.m4.1" class="ltx_Math" alttext="l-1" display="inline"><semantics id="S4.SS2.p5.4.m4.1a"><mrow id="S4.SS2.p5.4.m4.1.1" xref="S4.SS2.p5.4.m4.1.1.cmml"><mi id="S4.SS2.p5.4.m4.1.1.2" xref="S4.SS2.p5.4.m4.1.1.2.cmml">l</mi><mo id="S4.SS2.p5.4.m4.1.1.1" xref="S4.SS2.p5.4.m4.1.1.1.cmml">−</mo><mn id="S4.SS2.p5.4.m4.1.1.3" xref="S4.SS2.p5.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.4.m4.1b"><apply id="S4.SS2.p5.4.m4.1.1.cmml" xref="S4.SS2.p5.4.m4.1.1"><minus id="S4.SS2.p5.4.m4.1.1.1.cmml" xref="S4.SS2.p5.4.m4.1.1.1"></minus><ci id="S4.SS2.p5.4.m4.1.1.2.cmml" xref="S4.SS2.p5.4.m4.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p5.4.m4.1.1.3.cmml" xref="S4.SS2.p5.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.4.m4.1c">l-1</annotation></semantics></math> and invokes a command to transfer the layer <math id="S4.SS2.p5.5.m5.1" class="ltx_Math" alttext="l-1" display="inline"><semantics id="S4.SS2.p5.5.m5.1a"><mrow id="S4.SS2.p5.5.m5.1.1" xref="S4.SS2.p5.5.m5.1.1.cmml"><mi id="S4.SS2.p5.5.m5.1.1.2" xref="S4.SS2.p5.5.m5.1.1.2.cmml">l</mi><mo id="S4.SS2.p5.5.m5.1.1.1" xref="S4.SS2.p5.5.m5.1.1.1.cmml">−</mo><mn id="S4.SS2.p5.5.m5.1.1.3" xref="S4.SS2.p5.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.5.m5.1b"><apply id="S4.SS2.p5.5.m5.1.1.cmml" xref="S4.SS2.p5.5.m5.1.1"><minus id="S4.SS2.p5.5.m5.1.1.1.cmml" xref="S4.SS2.p5.5.m5.1.1.1"></minus><ci id="S4.SS2.p5.5.m5.1.1.2.cmml" xref="S4.SS2.p5.5.m5.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p5.5.m5.1.1.3.cmml" xref="S4.SS2.p5.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.5.m5.1c">l-1</annotation></semantics></math>’s activations (i.e., <math id="S4.SS2.p5.6.m6.1" class="ltx_Math" alttext="T_{l-1}" display="inline"><semantics id="S4.SS2.p5.6.m6.1a"><msub id="S4.SS2.p5.6.m6.1.1" xref="S4.SS2.p5.6.m6.1.1.cmml"><mi id="S4.SS2.p5.6.m6.1.1.2" xref="S4.SS2.p5.6.m6.1.1.2.cmml">T</mi><mrow id="S4.SS2.p5.6.m6.1.1.3" xref="S4.SS2.p5.6.m6.1.1.3.cmml"><mi id="S4.SS2.p5.6.m6.1.1.3.2" xref="S4.SS2.p5.6.m6.1.1.3.2.cmml">l</mi><mo id="S4.SS2.p5.6.m6.1.1.3.1" xref="S4.SS2.p5.6.m6.1.1.3.1.cmml">−</mo><mn id="S4.SS2.p5.6.m6.1.1.3.3" xref="S4.SS2.p5.6.m6.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.6.m6.1b"><apply id="S4.SS2.p5.6.m6.1.1.cmml" xref="S4.SS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.6.m6.1.1.1.cmml" xref="S4.SS2.p5.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.p5.6.m6.1.1.2.cmml" xref="S4.SS2.p5.6.m6.1.1.2">𝑇</ci><apply id="S4.SS2.p5.6.m6.1.1.3.cmml" xref="S4.SS2.p5.6.m6.1.1.3"><minus id="S4.SS2.p5.6.m6.1.1.3.1.cmml" xref="S4.SS2.p5.6.m6.1.1.3.1"></minus><ci id="S4.SS2.p5.6.m6.1.1.3.2.cmml" xref="S4.SS2.p5.6.m6.1.1.3.2">𝑙</ci><cn type="integer" id="S4.SS2.p5.6.m6.1.1.3.3.cmml" xref="S4.SS2.p5.6.m6.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.6.m6.1c">T_{l-1}</annotation></semantics></math>) to the secure memory through a buffer in shared memory.
The TEE switches to the corresponding invoked command in order to receive layer <math id="S4.SS2.p5.7.m7.1" class="ltx_Math" alttext="l-1" display="inline"><semantics id="S4.SS2.p5.7.m7.1a"><mrow id="S4.SS2.p5.7.m7.1.1" xref="S4.SS2.p5.7.m7.1.1.cmml"><mi id="S4.SS2.p5.7.m7.1.1.2" xref="S4.SS2.p5.7.m7.1.1.2.cmml">l</mi><mo id="S4.SS2.p5.7.m7.1.1.1" xref="S4.SS2.p5.7.m7.1.1.1.cmml">−</mo><mn id="S4.SS2.p5.7.m7.1.1.3" xref="S4.SS2.p5.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.7.m7.1b"><apply id="S4.SS2.p5.7.m7.1.1.cmml" xref="S4.SS2.p5.7.m7.1.1"><minus id="S4.SS2.p5.7.m7.1.1.1.cmml" xref="S4.SS2.p5.7.m7.1.1.1"></minus><ci id="S4.SS2.p5.7.m7.1.1.2.cmml" xref="S4.SS2.p5.7.m7.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p5.7.m7.1.1.3.cmml" xref="S4.SS2.p5.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.7.m7.1c">l-1</annotation></semantics></math>’s activations and processes the forward pass of layer <math id="S4.SS2.p5.8.m8.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p5.8.m8.1a"><mi id="S4.SS2.p5.8.m8.1.1" xref="S4.SS2.p5.8.m8.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.8.m8.1b"><ci id="S4.SS2.p5.8.m8.1.1.cmml" xref="S4.SS2.p5.8.m8.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.8.m8.1c">l</annotation></semantics></math> and classifier <math id="S4.SS2.p5.9.m9.1" class="ltx_math_unparsed" alttext="C(.)" display="inline"><semantics id="S4.SS2.p5.9.m9.1a"><mrow id="S4.SS2.p5.9.m9.1b"><mi id="S4.SS2.p5.9.m9.1.1">C</mi><mrow id="S4.SS2.p5.9.m9.1.2"><mo stretchy="false" id="S4.SS2.p5.9.m9.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S4.SS2.p5.9.m9.1.2.2">.</mo><mo stretchy="false" id="S4.SS2.p5.9.m9.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.SS2.p5.9.m9.1c">C(.)</annotation></semantics></math> in the TEE.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.9" class="ltx_p">During the <em id="S4.SS2.p6.9.1" class="ltx_emph ltx_font_italic">backward pass</em>, the TEE computes the <math id="S4.SS2.p6.1.m1.1" class="ltx_math_unparsed" alttext="C(.)" display="inline"><semantics id="S4.SS2.p6.1.m1.1a"><mrow id="S4.SS2.p6.1.m1.1b"><mi id="S4.SS2.p6.1.m1.1.1">C</mi><mrow id="S4.SS2.p6.1.m1.1.2"><mo stretchy="false" id="S4.SS2.p6.1.m1.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S4.SS2.p6.1.m1.1.2.2">.</mo><mo stretchy="false" id="S4.SS2.p6.1.m1.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.1c">C(.)</annotation></semantics></math>’s gradients based on received labels <math id="S4.SS2.p6.2.m2.1" class="ltx_Math" alttext="\bm{y}" display="inline"><semantics id="S4.SS2.p6.2.m2.1a"><mi id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml">𝒚</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.1b"><ci id="S4.SS2.p6.2.m2.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1">𝒚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.1c">\bm{y}</annotation></semantics></math> and outputs of <math id="S4.SS2.p6.3.m3.1" class="ltx_math_unparsed" alttext="C(.)" display="inline"><semantics id="S4.SS2.p6.3.m3.1a"><mrow id="S4.SS2.p6.3.m3.1b"><mi id="S4.SS2.p6.3.m3.1.1">C</mi><mrow id="S4.SS2.p6.3.m3.1.2"><mo stretchy="false" id="S4.SS2.p6.3.m3.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S4.SS2.p6.3.m3.1.2.2">.</mo><mo stretchy="false" id="S4.SS2.p6.3.m3.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.SS2.p6.3.m3.1c">C(.)</annotation></semantics></math> (produced in the forward pass) and uses them to compute the gradients of the layer <math id="S4.SS2.p6.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p6.4.m4.1a"><mi id="S4.SS2.p6.4.m4.1.1" xref="S4.SS2.p6.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.4.m4.1b"><ci id="S4.SS2.p6.4.m4.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.4.m4.1c">l</annotation></semantics></math> in the TEE.
The training of this batch of data (i.e., <math id="S4.SS2.p6.5.m5.1" class="ltx_Math" alttext="\bm{x}" display="inline"><semantics id="S4.SS2.p6.5.m5.1a"><mi id="S4.SS2.p6.5.m5.1.1" xref="S4.SS2.p6.5.m5.1.1.cmml">𝒙</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.5.m5.1b"><ci id="S4.SS2.p6.5.m5.1.1.cmml" xref="S4.SS2.p6.5.m5.1.1">𝒙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.5.m5.1c">\bm{x}</annotation></semantics></math>) finishes here, and there is no need to transfer <math id="S4.SS2.p6.6.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p6.6.m6.1a"><mi id="S4.SS2.p6.6.m6.1.1" xref="S4.SS2.p6.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.6.m6.1b"><ci id="S4.SS2.p6.6.m6.1.1.cmml" xref="S4.SS2.p6.6.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.6.m6.1c">l</annotation></semantics></math>’s errors from the TEE to the REE via shared memory, as previous layers are frozen outside the TEE.
After that, the parameters of layer <math id="S4.SS2.p6.7.m7.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p6.7.m7.1a"><mi id="S4.SS2.p6.7.m7.1.1" xref="S4.SS2.p6.7.m7.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.7.m7.1b"><ci id="S4.SS2.p6.7.m7.1.1.cmml" xref="S4.SS2.p6.7.m7.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.7.m7.1c">l</annotation></semantics></math> are encrypted and passed to the REE, ready to be uploaded to the server, corresponding to the <math id="S4.SS2.p6.8.m8.1" class="ltx_Math" alttext="FedSGD" display="inline"><semantics id="S4.SS2.p6.8.m8.1a"><mrow id="S4.SS2.p6.8.m8.1.1" xref="S4.SS2.p6.8.m8.1.1.cmml"><mi id="S4.SS2.p6.8.m8.1.1.2" xref="S4.SS2.p6.8.m8.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.8.m8.1.1.1" xref="S4.SS2.p6.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.8.m8.1.1.3" xref="S4.SS2.p6.8.m8.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.8.m8.1.1.1a" xref="S4.SS2.p6.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.8.m8.1.1.4" xref="S4.SS2.p6.8.m8.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.8.m8.1.1.1b" xref="S4.SS2.p6.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.8.m8.1.1.5" xref="S4.SS2.p6.8.m8.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.8.m8.1.1.1c" xref="S4.SS2.p6.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.8.m8.1.1.6" xref="S4.SS2.p6.8.m8.1.1.6.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.8.m8.1.1.1d" xref="S4.SS2.p6.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.8.m8.1.1.7" xref="S4.SS2.p6.8.m8.1.1.7.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.8.m8.1b"><apply id="S4.SS2.p6.8.m8.1.1.cmml" xref="S4.SS2.p6.8.m8.1.1"><times id="S4.SS2.p6.8.m8.1.1.1.cmml" xref="S4.SS2.p6.8.m8.1.1.1"></times><ci id="S4.SS2.p6.8.m8.1.1.2.cmml" xref="S4.SS2.p6.8.m8.1.1.2">𝐹</ci><ci id="S4.SS2.p6.8.m8.1.1.3.cmml" xref="S4.SS2.p6.8.m8.1.1.3">𝑒</ci><ci id="S4.SS2.p6.8.m8.1.1.4.cmml" xref="S4.SS2.p6.8.m8.1.1.4">𝑑</ci><ci id="S4.SS2.p6.8.m8.1.1.5.cmml" xref="S4.SS2.p6.8.m8.1.1.5">𝑆</ci><ci id="S4.SS2.p6.8.m8.1.1.6.cmml" xref="S4.SS2.p6.8.m8.1.1.6">𝐺</ci><ci id="S4.SS2.p6.8.m8.1.1.7.cmml" xref="S4.SS2.p6.8.m8.1.1.7">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.8.m8.1c">FedSGD</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib11" title="" class="ltx_ref">chen2016revisiting, </a>)</cite>.
Further, <math id="S4.SS2.p6.9.m9.1" class="ltx_Math" alttext="FedAvg" display="inline"><semantics id="S4.SS2.p6.9.m9.1a"><mrow id="S4.SS2.p6.9.m9.1.1" xref="S4.SS2.p6.9.m9.1.1.cmml"><mi id="S4.SS2.p6.9.m9.1.1.2" xref="S4.SS2.p6.9.m9.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.9.m9.1.1.1" xref="S4.SS2.p6.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.9.m9.1.1.3" xref="S4.SS2.p6.9.m9.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.9.m9.1.1.1a" xref="S4.SS2.p6.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.9.m9.1.1.4" xref="S4.SS2.p6.9.m9.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.9.m9.1.1.1b" xref="S4.SS2.p6.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.9.m9.1.1.5" xref="S4.SS2.p6.9.m9.1.1.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.9.m9.1.1.1c" xref="S4.SS2.p6.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.9.m9.1.1.6" xref="S4.SS2.p6.9.m9.1.1.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p6.9.m9.1.1.1d" xref="S4.SS2.p6.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS2.p6.9.m9.1.1.7" xref="S4.SS2.p6.9.m9.1.1.7.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.9.m9.1b"><apply id="S4.SS2.p6.9.m9.1.1.cmml" xref="S4.SS2.p6.9.m9.1.1"><times id="S4.SS2.p6.9.m9.1.1.1.cmml" xref="S4.SS2.p6.9.m9.1.1.1"></times><ci id="S4.SS2.p6.9.m9.1.1.2.cmml" xref="S4.SS2.p6.9.m9.1.1.2">𝐹</ci><ci id="S4.SS2.p6.9.m9.1.1.3.cmml" xref="S4.SS2.p6.9.m9.1.1.3">𝑒</ci><ci id="S4.SS2.p6.9.m9.1.1.4.cmml" xref="S4.SS2.p6.9.m9.1.1.4">𝑑</ci><ci id="S4.SS2.p6.9.m9.1.1.5.cmml" xref="S4.SS2.p6.9.m9.1.1.5">𝐴</ci><ci id="S4.SS2.p6.9.m9.1.1.6.cmml" xref="S4.SS2.p6.9.m9.1.1.6">𝑣</ci><ci id="S4.SS2.p6.9.m9.1.1.7.cmml" xref="S4.SS2.p6.9.m9.1.1.7">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.9.m9.1c">FedAvg</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite> which requires multiple batches to be processed before updating, repeats the same number of forward and backward passes across the REE and the TEE for each batch of data.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para ltx_noindent">
<p id="S4.SS2.p7.6" class="ltx_p"><span id="S4.SS2.p7.6.1" class="ltx_text ltx_font_bold">Algorithmic Complexity Analysis.</span>
Next, we analyze the algorithmic complexity of PPFL and compare it to standard end-to-end FL.
For the global model’s layers <math id="S4.SS2.p7.1.m1.3" class="ltx_Math" alttext="l\in\{1,\dots,L\}" display="inline"><semantics id="S4.SS2.p7.1.m1.3a"><mrow id="S4.SS2.p7.1.m1.3.4" xref="S4.SS2.p7.1.m1.3.4.cmml"><mi id="S4.SS2.p7.1.m1.3.4.2" xref="S4.SS2.p7.1.m1.3.4.2.cmml">l</mi><mo id="S4.SS2.p7.1.m1.3.4.1" xref="S4.SS2.p7.1.m1.3.4.1.cmml">∈</mo><mrow id="S4.SS2.p7.1.m1.3.4.3.2" xref="S4.SS2.p7.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS2.p7.1.m1.3.4.3.2.1" xref="S4.SS2.p7.1.m1.3.4.3.1.cmml">{</mo><mn id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">1</mn><mo id="S4.SS2.p7.1.m1.3.4.3.2.2" xref="S4.SS2.p7.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p7.1.m1.2.2" xref="S4.SS2.p7.1.m1.2.2.cmml">…</mi><mo id="S4.SS2.p7.1.m1.3.4.3.2.3" xref="S4.SS2.p7.1.m1.3.4.3.1.cmml">,</mo><mi id="S4.SS2.p7.1.m1.3.3" xref="S4.SS2.p7.1.m1.3.3.cmml">L</mi><mo stretchy="false" id="S4.SS2.p7.1.m1.3.4.3.2.4" xref="S4.SS2.p7.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.3b"><apply id="S4.SS2.p7.1.m1.3.4.cmml" xref="S4.SS2.p7.1.m1.3.4"><in id="S4.SS2.p7.1.m1.3.4.1.cmml" xref="S4.SS2.p7.1.m1.3.4.1"></in><ci id="S4.SS2.p7.1.m1.3.4.2.cmml" xref="S4.SS2.p7.1.m1.3.4.2">𝑙</ci><set id="S4.SS2.p7.1.m1.3.4.3.1.cmml" xref="S4.SS2.p7.1.m1.3.4.3.2"><cn type="integer" id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">1</cn><ci id="S4.SS2.p7.1.m1.2.2.cmml" xref="S4.SS2.p7.1.m1.2.2">…</ci><ci id="S4.SS2.p7.1.m1.3.3.cmml" xref="S4.SS2.p7.1.m1.3.3">𝐿</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.3c">l\in\{1,\dots,L\}</annotation></semantics></math>, we denote the forward and backward pass cost on layer <math id="S4.SS2.p7.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p7.2.m2.1a"><mi id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><ci id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">l</annotation></semantics></math> as <math id="S4.SS2.p7.3.m3.1" class="ltx_Math" alttext="\mathtt{F}_{l}" display="inline"><semantics id="S4.SS2.p7.3.m3.1a"><msub id="S4.SS2.p7.3.m3.1.1" xref="S4.SS2.p7.3.m3.1.1.cmml"><mi id="S4.SS2.p7.3.m3.1.1.2" xref="S4.SS2.p7.3.m3.1.1.2.cmml">𝙵</mi><mi id="S4.SS2.p7.3.m3.1.1.3" xref="S4.SS2.p7.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.3.m3.1b"><apply id="S4.SS2.p7.3.m3.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.3.m3.1.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p7.3.m3.1.1.2.cmml" xref="S4.SS2.p7.3.m3.1.1.2">𝙵</ci><ci id="S4.SS2.p7.3.m3.1.1.3.cmml" xref="S4.SS2.p7.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.3.m3.1c">\mathtt{F}_{l}</annotation></semantics></math> and <math id="S4.SS2.p7.4.m4.1" class="ltx_Math" alttext="\mathtt{B}_{l}" display="inline"><semantics id="S4.SS2.p7.4.m4.1a"><msub id="S4.SS2.p7.4.m4.1.1" xref="S4.SS2.p7.4.m4.1.1.cmml"><mi id="S4.SS2.p7.4.m4.1.1.2" xref="S4.SS2.p7.4.m4.1.1.2.cmml">𝙱</mi><mi id="S4.SS2.p7.4.m4.1.1.3" xref="S4.SS2.p7.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.4.m4.1b"><apply id="S4.SS2.p7.4.m4.1.1.cmml" xref="S4.SS2.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.4.m4.1.1.1.cmml" xref="S4.SS2.p7.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p7.4.m4.1.1.2.cmml" xref="S4.SS2.p7.4.m4.1.1.2">𝙱</ci><ci id="S4.SS2.p7.4.m4.1.1.3.cmml" xref="S4.SS2.p7.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.4.m4.1c">\mathtt{B}_{l}</annotation></semantics></math>, respectively.
The corresponding cost on the classifier is denoted as <math id="S4.SS2.p7.5.m5.1" class="ltx_Math" alttext="\mathtt{F}_{c}" display="inline"><semantics id="S4.SS2.p7.5.m5.1a"><msub id="S4.SS2.p7.5.m5.1.1" xref="S4.SS2.p7.5.m5.1.1.cmml"><mi id="S4.SS2.p7.5.m5.1.1.2" xref="S4.SS2.p7.5.m5.1.1.2.cmml">𝙵</mi><mi id="S4.SS2.p7.5.m5.1.1.3" xref="S4.SS2.p7.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.5.m5.1b"><apply id="S4.SS2.p7.5.m5.1.1.cmml" xref="S4.SS2.p7.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.5.m5.1.1.1.cmml" xref="S4.SS2.p7.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.p7.5.m5.1.1.2.cmml" xref="S4.SS2.p7.5.m5.1.1.2">𝙵</ci><ci id="S4.SS2.p7.5.m5.1.1.3.cmml" xref="S4.SS2.p7.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.5.m5.1c">\mathtt{F}_{c}</annotation></semantics></math> and <math id="S4.SS2.p7.6.m6.1" class="ltx_Math" alttext="\mathtt{B}_{c}" display="inline"><semantics id="S4.SS2.p7.6.m6.1a"><msub id="S4.SS2.p7.6.m6.1.1" xref="S4.SS2.p7.6.m6.1.1.cmml"><mi id="S4.SS2.p7.6.m6.1.1.2" xref="S4.SS2.p7.6.m6.1.1.2.cmml">𝙱</mi><mi id="S4.SS2.p7.6.m6.1.1.3" xref="S4.SS2.p7.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.6.m6.1b"><apply id="S4.SS2.p7.6.m6.1.1.cmml" xref="S4.SS2.p7.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.6.m6.1.1.1.cmml" xref="S4.SS2.p7.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.p7.6.m6.1.1.2.cmml" xref="S4.SS2.p7.6.m6.1.1.2">𝙱</ci><ci id="S4.SS2.p7.6.m6.1.1.3.cmml" xref="S4.SS2.p7.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.6.m6.1c">\mathtt{B}_{c}</annotation></semantics></math>.
Then, in end-to-end FL, the total training cost for one client is:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="\left(\sum_{l=1}^{L}(\mathtt{F}_{l}+\mathtt{B}_{l})+\mathtt{F}_{c}+\mathtt{B}_{c}\right)\cdot S\cdot E" display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mo id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml"><munderover id="S4.E1.m1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.2.cmml"><mo lspace="0em" movablelimits="false" rspace="0em" id="S4.E1.m1.1.1.1.1.1.1.2.2.2" xref="S4.E1.m1.1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.2.2.3" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.2.2.3.2" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml">l</mi><mo id="S4.E1.m1.1.1.1.1.1.1.2.2.3.1" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E1.m1.1.1.1.1.1.1.2.2.3.3" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E1.m1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.2.3.cmml">L</mi></munderover><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝙵</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">l</mi></msub><mo id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">𝙱</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">l</mi></msub></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.cmml">+</mo><msub id="S4.E1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.1.3.2.cmml">𝙵</mi><mi id="S4.E1.m1.1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.1.3.3.cmml">c</mi></msub><mo id="S4.E1.m1.1.1.1.1.1.2a" xref="S4.E1.m1.1.1.1.1.1.2.cmml">+</mo><msub id="S4.E1.m1.1.1.1.1.1.4" xref="S4.E1.m1.1.1.1.1.1.4.cmml"><mi id="S4.E1.m1.1.1.1.1.1.4.2" xref="S4.E1.m1.1.1.1.1.1.4.2.cmml">𝙱</mi><mi id="S4.E1.m1.1.1.1.1.1.4.3" xref="S4.E1.m1.1.1.1.1.1.4.3.cmml">c</mi></msub></mrow><mo rspace="0.055em" id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml">⋅</mo><mi id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.1.1.2a" xref="S4.E1.m1.1.1.2.cmml">⋅</mo><mi id="S4.E1.m1.1.1.4" xref="S4.E1.m1.1.1.4.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><ci id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2">⋅</ci><apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1"><plus id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2"></plus><apply id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"><apply id="S4.E1.m1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S4.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S4.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.2"></sum><apply id="S4.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3"><eq id="S4.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S4.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.2">𝑙</ci><cn type="integer" id="S4.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.3">𝐿</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1"><plus id="S4.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.2">𝙵</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑙</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2">𝙱</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply><apply id="S4.E1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.3.2">𝙵</ci><ci id="S4.E1.m1.1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.4.cmml" xref="S4.E1.m1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.4.1.cmml" xref="S4.E1.m1.1.1.1.1.1.4">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.4.2.cmml" xref="S4.E1.m1.1.1.1.1.1.4.2">𝙱</ci><ci id="S4.E1.m1.1.1.1.1.1.4.3.cmml" xref="S4.E1.m1.1.1.1.1.1.4.3">𝑐</ci></apply></apply><ci id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3">𝑆</ci><ci id="S4.E1.m1.1.1.4.cmml" xref="S4.E1.m1.1.1.4">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\left(\sum_{l=1}^{L}(\mathtt{F}_{l}+\mathtt{B}_{l})+\mathtt{F}_{c}+\mathtt{B}_{c}\right)\cdot S\cdot E</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.p7.10" class="ltx_p">where <math id="S4.SS2.p7.7.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS2.p7.7.m1.1a"><mi id="S4.SS2.p7.7.m1.1.1" xref="S4.SS2.p7.7.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.7.m1.1b"><ci id="S4.SS2.p7.7.m1.1.1.cmml" xref="S4.SS2.p7.7.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.7.m1.1c">S</annotation></semantics></math> is the number of steps in one epoch (i.e., number of samples inside local datasets divided by the batch size).
As in PPFL all layers before the training layer <math id="S4.SS2.p7.8.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p7.8.m2.1a"><mi id="S4.SS2.p7.8.m2.1.1" xref="S4.SS2.p7.8.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.8.m2.1b"><ci id="S4.SS2.p7.8.m2.1.1.cmml" xref="S4.SS2.p7.8.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.8.m2.1c">l</annotation></semantics></math> are kept frozen, the cost of training layer <math id="S4.SS2.p7.9.m3.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p7.9.m3.1a"><mi id="S4.SS2.p7.9.m3.1.1" xref="S4.SS2.p7.9.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.9.m3.1b"><ci id="S4.SS2.p7.9.m3.1.1.cmml" xref="S4.SS2.p7.9.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.9.m3.1c">l</annotation></semantics></math> is <math id="S4.SS2.p7.10.m4.1" class="ltx_Math" alttext="(\sum_{k=1}^{l}\mathtt{F}_{k}+\mathtt{F}_{c}+\mathtt{B}_{l}+\mathtt{B}_{c})\cdot S\cdot E" display="inline"><semantics id="S4.SS2.p7.10.m4.1a"><mrow id="S4.SS2.p7.10.m4.1.1" xref="S4.SS2.p7.10.m4.1.1.cmml"><mrow id="S4.SS2.p7.10.m4.1.1.1.1" xref="S4.SS2.p7.10.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p7.10.m4.1.1.1.1.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p7.10.m4.1.1.1.1.1" xref="S4.SS2.p7.10.m4.1.1.1.1.1.cmml"><mrow id="S4.SS2.p7.10.m4.1.1.1.1.1.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.cmml"><msubsup id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.cmml"><mo lspace="0em" id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.2.cmml">∑</mo><mrow id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.cmml"><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.2.cmml">k</mi><mo id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.1" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.1.cmml">=</mo><mn id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.3.cmml">l</mi></msubsup><msub id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.cmml"><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.2.cmml">𝙵</mi><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.SS2.p7.10.m4.1.1.1.1.1.1" xref="S4.SS2.p7.10.m4.1.1.1.1.1.1.cmml">+</mo><msub id="S4.SS2.p7.10.m4.1.1.1.1.1.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3.cmml"><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.3.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3.2.cmml">𝙵</mi><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.3.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3.3.cmml">c</mi></msub><mo id="S4.SS2.p7.10.m4.1.1.1.1.1.1a" xref="S4.SS2.p7.10.m4.1.1.1.1.1.1.cmml">+</mo><msub id="S4.SS2.p7.10.m4.1.1.1.1.1.4" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4.cmml"><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.4.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4.2.cmml">𝙱</mi><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.4.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4.3.cmml">l</mi></msub><mo id="S4.SS2.p7.10.m4.1.1.1.1.1.1b" xref="S4.SS2.p7.10.m4.1.1.1.1.1.1.cmml">+</mo><msub id="S4.SS2.p7.10.m4.1.1.1.1.1.5" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5.cmml"><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.5.2" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5.2.cmml">𝙱</mi><mi id="S4.SS2.p7.10.m4.1.1.1.1.1.5.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5.3.cmml">c</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S4.SS2.p7.10.m4.1.1.1.1.3" xref="S4.SS2.p7.10.m4.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.SS2.p7.10.m4.1.1.2" xref="S4.SS2.p7.10.m4.1.1.2.cmml">⋅</mo><mi id="S4.SS2.p7.10.m4.1.1.3" xref="S4.SS2.p7.10.m4.1.1.3.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p7.10.m4.1.1.2a" xref="S4.SS2.p7.10.m4.1.1.2.cmml">⋅</mo><mi id="S4.SS2.p7.10.m4.1.1.4" xref="S4.SS2.p7.10.m4.1.1.4.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.10.m4.1b"><apply id="S4.SS2.p7.10.m4.1.1.cmml" xref="S4.SS2.p7.10.m4.1.1"><ci id="S4.SS2.p7.10.m4.1.1.2.cmml" xref="S4.SS2.p7.10.m4.1.1.2">⋅</ci><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1"><plus id="S4.SS2.p7.10.m4.1.1.1.1.1.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.1"></plus><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2"><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1">superscript</csymbol><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1">subscript</csymbol><sum id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.2"></sum><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3"><eq id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.1"></eq><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.2">𝑘</ci><cn type="integer" id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.1.3">𝑙</ci></apply><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.2">𝙵</ci><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.2.2.3">𝑘</ci></apply></apply><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.3.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.3.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3.2">𝙵</ci><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.3.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.4.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.4.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4">subscript</csymbol><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.4.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4.2">𝙱</ci><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.4.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.4.3">𝑙</ci></apply><apply id="S4.SS2.p7.10.m4.1.1.1.1.1.5.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S4.SS2.p7.10.m4.1.1.1.1.1.5.1.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5">subscript</csymbol><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.5.2.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5.2">𝙱</ci><ci id="S4.SS2.p7.10.m4.1.1.1.1.1.5.3.cmml" xref="S4.SS2.p7.10.m4.1.1.1.1.1.5.3">𝑐</ci></apply></apply><ci id="S4.SS2.p7.10.m4.1.1.3.cmml" xref="S4.SS2.p7.10.m4.1.1.3">𝑆</ci><ci id="S4.SS2.p7.10.m4.1.1.4.cmml" xref="S4.SS2.p7.10.m4.1.1.4">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.10.m4.1c">(\sum_{k=1}^{l}\mathtt{F}_{k}+\mathtt{F}_{c}+\mathtt{B}_{l}+\mathtt{B}_{c})\cdot S\cdot E</annotation></semantics></math>.
Then, by summation, we get the total cost of all layers as:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\left(\sum_{l=1}^{L}\sum_{k=1}^{l}\mathtt{F}_{k}+\sum_{l=1}^{L}\mathtt{B}_{l}+L\cdot(\mathtt{F}_{c}+\mathtt{B}_{c})\right)\cdot S\cdot E" display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.3.cmml"><munderover id="S4.E2.m1.1.1.1.1.1.3.1" xref="S4.E2.m1.1.1.1.1.1.3.1.cmml"><mo lspace="0em" movablelimits="false" rspace="0em" id="S4.E2.m1.1.1.1.1.1.3.1.2.2" xref="S4.E2.m1.1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.1.1.1.1.1.3.1.2.3" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.3.1.2.3.2" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.2.cmml">l</mi><mo id="S4.E2.m1.1.1.1.1.1.3.1.2.3.1" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.1.1.1.1.1.3.1.2.3.3" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.1.1.1.1.1.3.1.3" xref="S4.E2.m1.1.1.1.1.1.3.1.3.cmml">L</mi></munderover><mrow id="S4.E2.m1.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.3.2.cmml"><munderover id="S4.E2.m1.1.1.1.1.1.3.2.1" xref="S4.E2.m1.1.1.1.1.1.3.2.1.cmml"><mo movablelimits="false" id="S4.E2.m1.1.1.1.1.1.3.2.1.2.2" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.2" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.2.cmml">k</mi><mo id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.1" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.3" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.1.1.1.1.1.3.2.1.3" xref="S4.E2.m1.1.1.1.1.1.3.2.1.3.cmml">l</mi></munderover><msub id="S4.E2.m1.1.1.1.1.1.3.2.2" xref="S4.E2.m1.1.1.1.1.1.3.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.3.2.2.2" xref="S4.E2.m1.1.1.1.1.1.3.2.2.2.cmml">𝙵</mi><mi id="S4.E2.m1.1.1.1.1.1.3.2.2.3" xref="S4.E2.m1.1.1.1.1.1.3.2.2.3.cmml">k</mi></msub></mrow></mrow><mo rspace="0.055em" id="S4.E2.m1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S4.E2.m1.1.1.1.1.1.4" xref="S4.E2.m1.1.1.1.1.1.4.cmml"><munderover id="S4.E2.m1.1.1.1.1.1.4.1" xref="S4.E2.m1.1.1.1.1.1.4.1.cmml"><mo movablelimits="false" id="S4.E2.m1.1.1.1.1.1.4.1.2.2" xref="S4.E2.m1.1.1.1.1.1.4.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.1.1.1.1.1.4.1.2.3" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.4.1.2.3.2" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.2.cmml">l</mi><mo id="S4.E2.m1.1.1.1.1.1.4.1.2.3.1" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.1.1.1.1.1.4.1.2.3.3" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.1.1.1.1.1.4.1.3" xref="S4.E2.m1.1.1.1.1.1.4.1.3.cmml">L</mi></munderover><msub id="S4.E2.m1.1.1.1.1.1.4.2" xref="S4.E2.m1.1.1.1.1.1.4.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.4.2.2" xref="S4.E2.m1.1.1.1.1.1.4.2.2.cmml">𝙱</mi><mi id="S4.E2.m1.1.1.1.1.1.4.2.3" xref="S4.E2.m1.1.1.1.1.1.4.2.3.cmml">l</mi></msub></mrow><mo id="S4.E2.m1.1.1.1.1.1.2a" xref="S4.E2.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.3.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝙵</mi><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">c</mi></msub><mo id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">𝙱</mi><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.055em" id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">⋅</mo><mi id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.1.1.2a" xref="S4.E2.m1.1.1.2.cmml">⋅</mo><mi id="S4.E2.m1.1.1.4" xref="S4.E2.m1.1.1.4.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><ci id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2">⋅</ci><apply id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1"><plus id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.2"></plus><apply id="S4.E2.m1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3"><apply id="S4.E2.m1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.3.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.1.3.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.3.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1">subscript</csymbol><sum id="S4.E2.m1.1.1.1.1.1.3.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.2.2"></sum><apply id="S4.E2.m1.1.1.1.1.1.3.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3"><eq id="S4.E2.m1.1.1.1.1.1.3.1.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.1"></eq><ci id="S4.E2.m1.1.1.1.1.1.3.1.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.2">𝑙</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.3.1.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.1.1.1.1.1.3.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.1.3">𝐿</ci></apply><apply id="S4.E2.m1.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2"><apply id="S4.E2.m1.1.1.1.1.1.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.3.2.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.1.3.2.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.3.2.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1">subscript</csymbol><sum id="S4.E2.m1.1.1.1.1.1.3.2.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.2"></sum><apply id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3"><eq id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.1"></eq><ci id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.2">𝑘</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.1.1.1.1.1.3.2.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.1.3">𝑙</ci></apply><apply id="S4.E2.m1.1.1.1.1.1.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.3.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.3.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.2.2">𝙵</ci><ci id="S4.E2.m1.1.1.1.1.1.3.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3.2.2.3">𝑘</ci></apply></apply></apply><apply id="S4.E2.m1.1.1.1.1.1.4.cmml" xref="S4.E2.m1.1.1.1.1.1.4"><apply id="S4.E2.m1.1.1.1.1.1.4.1.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.4.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.1.4.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.4.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1">subscript</csymbol><sum id="S4.E2.m1.1.1.1.1.1.4.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.2.2"></sum><apply id="S4.E2.m1.1.1.1.1.1.4.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3"><eq id="S4.E2.m1.1.1.1.1.1.4.1.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.1"></eq><ci id="S4.E2.m1.1.1.1.1.1.4.1.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.2">𝑙</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.4.1.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.1.1.1.1.1.4.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.4.1.3">𝐿</ci></apply><apply id="S4.E2.m1.1.1.1.1.1.4.2.cmml" xref="S4.E2.m1.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.4.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.4.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.4.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.4.2.2">𝙱</ci><ci id="S4.E2.m1.1.1.1.1.1.4.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.4.2.3">𝑙</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1"><ci id="S4.E2.m1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2">⋅</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3">𝐿</ci><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1"><plus id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.2">𝙵</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.2.3">𝑐</ci></apply><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.2">𝙱</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.3.3">𝑐</ci></apply></apply></apply></apply><ci id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3">𝑆</ci><ci id="S4.E2.m1.1.1.4.cmml" xref="S4.E2.m1.1.1.4">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\left(\sum_{l=1}^{L}\sum_{k=1}^{l}\mathtt{F}_{k}+\sum_{l=1}^{L}\mathtt{B}_{l}+L\cdot(\mathtt{F}_{c}+\mathtt{B}_{c})\right)\cdot S\cdot E</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.p7.13" class="ltx_p">By comparing Equations <a href="#S4.E1" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S4.E2" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we see the overhead of PPFL comes from: (i) repeated forward pass in previous layers (<math id="S4.SS2.p7.11.m1.3" class="ltx_Math" alttext="l\in\{1,\dots,l-1\}" display="inline"><semantics id="S4.SS2.p7.11.m1.3a"><mrow id="S4.SS2.p7.11.m1.3.3" xref="S4.SS2.p7.11.m1.3.3.cmml"><mi id="S4.SS2.p7.11.m1.3.3.3" xref="S4.SS2.p7.11.m1.3.3.3.cmml">l</mi><mo id="S4.SS2.p7.11.m1.3.3.2" xref="S4.SS2.p7.11.m1.3.3.2.cmml">∈</mo><mrow id="S4.SS2.p7.11.m1.3.3.1.1" xref="S4.SS2.p7.11.m1.3.3.1.2.cmml"><mo stretchy="false" id="S4.SS2.p7.11.m1.3.3.1.1.2" xref="S4.SS2.p7.11.m1.3.3.1.2.cmml">{</mo><mn id="S4.SS2.p7.11.m1.1.1" xref="S4.SS2.p7.11.m1.1.1.cmml">1</mn><mo id="S4.SS2.p7.11.m1.3.3.1.1.3" xref="S4.SS2.p7.11.m1.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p7.11.m1.2.2" xref="S4.SS2.p7.11.m1.2.2.cmml">…</mi><mo id="S4.SS2.p7.11.m1.3.3.1.1.4" xref="S4.SS2.p7.11.m1.3.3.1.2.cmml">,</mo><mrow id="S4.SS2.p7.11.m1.3.3.1.1.1" xref="S4.SS2.p7.11.m1.3.3.1.1.1.cmml"><mi id="S4.SS2.p7.11.m1.3.3.1.1.1.2" xref="S4.SS2.p7.11.m1.3.3.1.1.1.2.cmml">l</mi><mo id="S4.SS2.p7.11.m1.3.3.1.1.1.1" xref="S4.SS2.p7.11.m1.3.3.1.1.1.1.cmml">−</mo><mn id="S4.SS2.p7.11.m1.3.3.1.1.1.3" xref="S4.SS2.p7.11.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS2.p7.11.m1.3.3.1.1.5" xref="S4.SS2.p7.11.m1.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.11.m1.3b"><apply id="S4.SS2.p7.11.m1.3.3.cmml" xref="S4.SS2.p7.11.m1.3.3"><in id="S4.SS2.p7.11.m1.3.3.2.cmml" xref="S4.SS2.p7.11.m1.3.3.2"></in><ci id="S4.SS2.p7.11.m1.3.3.3.cmml" xref="S4.SS2.p7.11.m1.3.3.3">𝑙</ci><set id="S4.SS2.p7.11.m1.3.3.1.2.cmml" xref="S4.SS2.p7.11.m1.3.3.1.1"><cn type="integer" id="S4.SS2.p7.11.m1.1.1.cmml" xref="S4.SS2.p7.11.m1.1.1">1</cn><ci id="S4.SS2.p7.11.m1.2.2.cmml" xref="S4.SS2.p7.11.m1.2.2">…</ci><apply id="S4.SS2.p7.11.m1.3.3.1.1.1.cmml" xref="S4.SS2.p7.11.m1.3.3.1.1.1"><minus id="S4.SS2.p7.11.m1.3.3.1.1.1.1.cmml" xref="S4.SS2.p7.11.m1.3.3.1.1.1.1"></minus><ci id="S4.SS2.p7.11.m1.3.3.1.1.1.2.cmml" xref="S4.SS2.p7.11.m1.3.3.1.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p7.11.m1.3.3.1.1.1.3.cmml" xref="S4.SS2.p7.11.m1.3.3.1.1.1.3">1</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.11.m1.3c">l\in\{1,\dots,l-1\}</annotation></semantics></math>) when training layer <math id="S4.SS2.p7.12.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p7.12.m2.1a"><mi id="S4.SS2.p7.12.m2.1.1" xref="S4.SS2.p7.12.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.12.m2.1b"><ci id="S4.SS2.p7.12.m2.1.1.cmml" xref="S4.SS2.p7.12.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.12.m2.1c">l</annotation></semantics></math>, and (ii) repeated forward and backward pass for the classifier atop layer <math id="S4.SS2.p7.13.m3.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.p7.13.m3.1a"><mi id="S4.SS2.p7.13.m3.1.1" xref="S4.SS2.p7.13.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.13.m3.1b"><ci id="S4.SS2.p7.13.m3.1.1.cmml" xref="S4.SS2.p7.13.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.13.m3.1c">l</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Implementation &amp; Evaluation Setup</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we first describe the implementation of the PPFL system (Sec. <a href="#S5.SS1" title="5.1. PPFL Prototype ‣ 5. Implementation &amp; Evaluation Setup ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), and then detail how we assess its performance on various DNN models and datasets (Sec. <a href="#S5.SS2" title="5.2. Models and Datasets ‣ 5. Implementation &amp; Evaluation Setup ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>) using different metrics (Sec. <a href="#S5.SS3" title="5.3. Performance Metrics ‣ 5. Implementation &amp; Evaluation Setup ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>).
We follow common setups of past FL systems <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>; <a href="#bib.bib72" title="" class="ltx_ref">wang2020federated, </a>)</cite> and on-device TEE works <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>; <a href="#bib.bib1" title="" class="ltx_ref">amacher2019performance, </a>)</cite>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>PPFL Prototype</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We implement the <em id="S5.SS1.p1.1.1" class="ltx_emph ltx_font_italic">client-side</em> of PPFL by building on top of DarkneTZ <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite>,
in order to support on-device FL with Arm TrustZone.
In total, we changed 4075 lines of code of DarkneTZ in C.
We run the client-side on a HiKey 960 Board, which has four ARM Cortex-A73 and four ARM Cortex-A53 cores configured at 2362MHz and 533MHz, respectively, as well as a 4GB LPDDR4 RAM with 16MiB TEE secure memory (i.e., TrustZone).
Since the CPU power/frequency setting can impact the TrustZone’s performance <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib1" title="" class="ltx_ref">amacher2019performance, </a>)</cite>, we execute the on-device FL training with full CPU frequency.
In order to emulate multiple device clients and their participation in FL rounds, we use the HiKey board in a repeated, iterative fashion, one time per client device.
We implement the <em id="S5.SS1.p1.1.2" class="ltx_emph ltx_font_italic">server-side</em> of PPFL on generic Darknet ML framework <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib58" title="" class="ltx_ref">darknet13, </a>)</cite> by adding 751 lines of C code based on Microsoft OpenEnclave <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib46" title="" class="ltx_ref">microsoft2020oe, </a>)</cite> with Intel SGX.
For this, an Intel Next Unit of Computing (ver.NUC8BEK, i3-8109U CPU, 8GB DDR4-2400MHz) was used with SGX-enabled capabilities.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Besides, we developed a set of bash shell scripts to control the <em id="S5.SS1.p2.1.1" class="ltx_emph ltx_font_italic">FL process</em> and create the <em id="S5.SS1.p2.1.2" class="ltx_emph ltx_font_italic">communication channels</em>.
For the communication channels between server and client to be secure, we employ standard cryptographic-based network protocols such as <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">SSH</span> and <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">SCP</span>.
All data leaving the TEE are encrypted using the Advanced Encryption Standard (AES) in Cipher Block Chaining (CBC) mode with random Initialization Values (IV) and 128-bit cryptographic keys.
Without loss of generality, we opted for manually hardcoding the cryptographic keys inside the TEEs ourselves.
Despite key management in TEE-to-TEE channels being an interesting research problem, we argue that establishing, updating, and revoking keys do not happen frequently and hence the overhead these tasks introduce is negligible compared to one from the DNN training.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The implementation of PPFL server and client is available for replication and extension: <a target="_blank" href="https://github.com/mofanv/PPFL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/mofanv/PPFL</a>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Models and Datasets</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We focus on Convolutional Neural Networks (CNNs) since the privacy risks we consider (Sec. <a href="#S3" title="3. Threat Model and Assumptions ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4.SS1" title="4.1. System Overview ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) have been extensively studied on such DNNs <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>)</cite>.
Also, layer-based learning methods mostly aim at CNN-like DNNs <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib5" title="" class="ltx_ref">belilovsky2019greedy, </a>)</cite>.
Specifically, in our PPFL evaluation, we employ DNNs commonly used in the relevant literature (Table <a href="#S5.T1" title="Table 1 ‣ 5.2. Models and Datasets ‣ 5. Implementation &amp; Evaluation Setup ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<figure id="S5.T1" class="ltx_table">

<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>DNNs used in the evaluation of PPFL. </figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S5.T1.9" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.9.10.1" class="ltx_tr">
<th id="S5.T1.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T1.9.10.1.1.1" class="ltx_text" style="font-size:90%;">DNN</span></th>
<td id="S5.T1.9.10.1.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T1.9.10.1.2.1" class="ltx_text" style="font-size:90%;">Architecture</span></td>
</tr>
<tr id="S5.T1.9.11.2" class="ltx_tr">
<th id="S5.T1.9.11.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.9.11.2.1.1" class="ltx_text" style="font-size:90%;">LeNet </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.9.11.2.1.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib37" title="" class="ltx_ref">lecun1998gradient<span id="S5.T1.9.11.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a>; <a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication<span id="S5.T1.9.11.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.9.11.2.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S5.T1.9.11.2.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T1.9.11.2.2.1" class="ltx_text" style="font-size:90%;">C20-MP-C50-MP-FC500-FC10</span></td>
</tr>
<tr id="S5.T1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.1.1.2.1" class="ltx_text" style="font-size:90%;">AlexNet </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.1.1.2.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib34" title="" class="ltx_ref">krizhevsky2017imagenet<span id="S5.T1.1.1.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a>; <a href="#bib.bib5" title="" class="ltx_ref">belilovsky2019greedy<span id="S5.T1.1.1.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.1.1.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.1.1.1.1" class="ltx_text" style="font-size:90%;">C128</span><math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mo mathsize="90%" id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><times id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">\times</annotation></semantics></math><span id="S5.T1.1.1.1.2" class="ltx_text" style="font-size:90%;">3-AP16-FC10</span>
</td>
</tr>
<tr id="S5.T1.4.4" class="ltx_tr">
<th id="S5.T1.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.4.4.4.1" class="ltx_text" style="font-size:90%;">VGG9 </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.4.4.4.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib65" title="" class="ltx_ref">simonyan2014very<span id="S5.T1.4.4.4.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a>; <a href="#bib.bib72" title="" class="ltx_ref">wang2020federated<span id="S5.T1.4.4.4.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.4.4.4.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S5.T1.4.4.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.4.4.3.3" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.3.3.2.2.2" class="ltx_p"><span id="S5.T1.3.3.2.2.2.1" class="ltx_text" style="font-size:90%;">C32-C64-MP-C128</span><math id="S5.T1.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.2.2.1.1.1.m1.1a"><mo mathsize="90%" id="S5.T1.2.2.1.1.1.m1.1.1" xref="S5.T1.2.2.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.1.1.m1.1b"><times id="S5.T1.2.2.1.1.1.m1.1.1.cmml" xref="S5.T1.2.2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.1.1.m1.1c">\times</annotation></semantics></math><span id="S5.T1.3.3.2.2.2.2" class="ltx_text" style="font-size:90%;">2-MP-D0.05-C256</span><math id="S5.T1.3.3.2.2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.3.3.2.2.2.m2.1a"><mo mathsize="90%" id="S5.T1.3.3.2.2.2.m2.1.1" xref="S5.T1.3.3.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.2.2.2.m2.1b"><times id="S5.T1.3.3.2.2.2.m2.1.1.cmml" xref="S5.T1.3.3.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.2.2.2.m2.1c">\times</annotation></semantics></math><span id="S5.T1.3.3.2.2.2.3" class="ltx_text" style="font-size:90%;">2</span></span>
<span id="S5.T1.4.4.3.3.3" class="ltx_p"><span id="S5.T1.4.4.3.3.3.1" class="ltx_text" style="font-size:90%;">-MP-D0.1-FC512</span><math id="S5.T1.4.4.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.4.4.3.3.3.m1.1a"><mo mathsize="90%" id="S5.T1.4.4.3.3.3.m1.1.1" xref="S5.T1.4.4.3.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.3.3.3.m1.1b"><times id="S5.T1.4.4.3.3.3.m1.1.1.cmml" xref="S5.T1.4.4.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.3.3.3.m1.1c">\times</annotation></semantics></math><span id="S5.T1.4.4.3.3.3.2" class="ltx_text" style="font-size:90%;">2-FC10</span></span>
</span>
</td>
</tr>
<tr id="S5.T1.9.9" class="ltx_tr">
<th id="S5.T1.9.9.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.9.9.6.1" class="ltx_text" style="font-size:90%;">VGG16 </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.9.9.6.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib65" title="" class="ltx_ref">simonyan2014very<span id="S5.T1.9.9.6.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.9.9.6.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S5.T1.9.9.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.9.9.5.5" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.8.8.4.4.4" class="ltx_p"><span id="S5.T1.8.8.4.4.4.1" class="ltx_text" style="font-size:90%;">C64</span><math id="S5.T1.5.5.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.5.5.1.1.1.m1.1a"><mo mathsize="90%" id="S5.T1.5.5.1.1.1.m1.1.1" xref="S5.T1.5.5.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.1.1.1.m1.1b"><times id="S5.T1.5.5.1.1.1.m1.1.1.cmml" xref="S5.T1.5.5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.1.1.1.m1.1c">\times</annotation></semantics></math><span id="S5.T1.8.8.4.4.4.2" class="ltx_text" style="font-size:90%;">2-MP-C128</span><math id="S5.T1.6.6.2.2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.6.6.2.2.2.m2.1a"><mo mathsize="90%" id="S5.T1.6.6.2.2.2.m2.1.1" xref="S5.T1.6.6.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.2.2.2.m2.1b"><times id="S5.T1.6.6.2.2.2.m2.1.1.cmml" xref="S5.T1.6.6.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.2.2.2.m2.1c">\times</annotation></semantics></math><span id="S5.T1.8.8.4.4.4.3" class="ltx_text" style="font-size:90%;">2-MP-C256</span><math id="S5.T1.7.7.3.3.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.7.7.3.3.3.m3.1a"><mo mathsize="90%" id="S5.T1.7.7.3.3.3.m3.1.1" xref="S5.T1.7.7.3.3.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.3.3.3.m3.1b"><times id="S5.T1.7.7.3.3.3.m3.1.1.cmml" xref="S5.T1.7.7.3.3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.3.3.3.m3.1c">\times</annotation></semantics></math><span id="S5.T1.8.8.4.4.4.4" class="ltx_text" style="font-size:90%;">3-C512</span><math id="S5.T1.8.8.4.4.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.8.8.4.4.4.m4.1a"><mo mathsize="90%" id="S5.T1.8.8.4.4.4.m4.1.1" xref="S5.T1.8.8.4.4.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.4.4.4.m4.1b"><times id="S5.T1.8.8.4.4.4.m4.1.1.cmml" xref="S5.T1.8.8.4.4.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.4.4.4.m4.1c">\times</annotation></semantics></math><span id="S5.T1.8.8.4.4.4.5" class="ltx_text" style="font-size:90%;">3</span></span>
<span id="S5.T1.9.9.5.5.5" class="ltx_p"><span id="S5.T1.9.9.5.5.5.1" class="ltx_text" style="font-size:90%;">-MP-FC4096</span><math id="S5.T1.9.9.5.5.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T1.9.9.5.5.5.m1.1a"><mo mathsize="90%" id="S5.T1.9.9.5.5.5.m1.1.1" xref="S5.T1.9.9.5.5.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.5.5.5.m1.1b"><times id="S5.T1.9.9.5.5.5.m1.1.1.cmml" xref="S5.T1.9.9.5.5.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.5.5.5.m1.1c">\times</annotation></semantics></math><span id="S5.T1.9.9.5.5.5.2" class="ltx_text" style="font-size:90%;">2-FC1000-FC10</span></span>
</span>
</td>
</tr>
<tr id="S5.T1.9.12.3" class="ltx_tr">
<th id="S5.T1.9.12.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.9.12.3.1.1" class="ltx_text" style="font-size:90%;">MobileNetv2 </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.9.12.3.1.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib61" title="" class="ltx_ref">sandler2018mobilenetv2<span id="S5.T1.9.12.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.9.12.3.1.4.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S5.T1.9.12.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T1.9.12.3.2.1" class="ltx_text" style="font-size:90%;">68 layers, unmodified refer to </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T1.9.12.3.2.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib61" title="" class="ltx_ref">sandler2018mobilenetv2<span id="S5.T1.9.12.3.2.3.2.1.1" class="ltx_text" style="font-size:90%;">, </span></a><span id="S5.T1.9.12.3.2.4.3" class="ltx_text" style="font-size:90%;">)</span></cite><span id="S5.T1.9.12.3.2.5" class="ltx_text" style="font-size:90%;"> for details</span>
</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.T1.11.2" class="ltx_p ltx_figure_panel ltx_align_left"><span id="S5.T1.11.2.2" class="ltx_text" style="font-size:80%;">Architecture notation: Convolution layer (C) with a given number of filters; filter size is <math id="S5.T1.10.1.1.m1.1" class="ltx_Math" alttext="5\times 5" display="inline"><semantics id="S5.T1.10.1.1.m1.1a"><mrow id="S5.T1.10.1.1.m1.1.1" xref="S5.T1.10.1.1.m1.1.1.cmml"><mn id="S5.T1.10.1.1.m1.1.1.2" xref="S5.T1.10.1.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T1.10.1.1.m1.1.1.1" xref="S5.T1.10.1.1.m1.1.1.1.cmml">×</mo><mn id="S5.T1.10.1.1.m1.1.1.3" xref="S5.T1.10.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.10.1.1.m1.1b"><apply id="S5.T1.10.1.1.m1.1.1.cmml" xref="S5.T1.10.1.1.m1.1.1"><times id="S5.T1.10.1.1.m1.1.1.1.cmml" xref="S5.T1.10.1.1.m1.1.1.1"></times><cn type="integer" id="S5.T1.10.1.1.m1.1.1.2.cmml" xref="S5.T1.10.1.1.m1.1.1.2">5</cn><cn type="integer" id="S5.T1.10.1.1.m1.1.1.3.cmml" xref="S5.T1.10.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.1.1.m1.1c">5\times 5</annotation></semantics></math> in LeNet and <math id="S5.T1.11.2.2.m2.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S5.T1.11.2.2.m2.1a"><mrow id="S5.T1.11.2.2.m2.1.1" xref="S5.T1.11.2.2.m2.1.1.cmml"><mn id="S5.T1.11.2.2.m2.1.1.2" xref="S5.T1.11.2.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T1.11.2.2.m2.1.1.1" xref="S5.T1.11.2.2.m2.1.1.1.cmml">×</mo><mn id="S5.T1.11.2.2.m2.1.1.3" xref="S5.T1.11.2.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.11.2.2.m2.1b"><apply id="S5.T1.11.2.2.m2.1.1.cmml" xref="S5.T1.11.2.2.m2.1.1"><times id="S5.T1.11.2.2.m2.1.1.1.cmml" xref="S5.T1.11.2.2.m2.1.1.1"></times><cn type="integer" id="S5.T1.11.2.2.m2.1.1.2.cmml" xref="S5.T1.11.2.2.m2.1.1.2">3</cn><cn type="integer" id="S5.T1.11.2.2.m2.1.1.3.cmml" xref="S5.T1.11.2.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.2.2.m2.1c">3\times 3</annotation></semantics></math> in AlexNet, VGG9, and VGG16. Fully Connected (FC) with a given number of neurons. All C and FC layers are followed by ReLU activation functions. MaxPooling (MP). AveragePooling (AP) with a given stride size. Dropout layer (D) with a given dropping rate.  
<br class="ltx_break"></span></p>
</div>
</div>
</figure>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.2" class="ltx_p">For our experimental analysis, we used <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="MNIST" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.1.m1.1.1.1" xref="S5.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.1.m1.1.1.1a" xref="S5.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.1.m1.1.1.4" xref="S5.SS2.p2.1.m1.1.1.4.cmml">I</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.1.m1.1.1.1b" xref="S5.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.1.m1.1.1.5" xref="S5.SS2.p2.1.m1.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.1.m1.1.1.1c" xref="S5.SS2.p2.1.m1.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.1.m1.1.1.6" xref="S5.SS2.p2.1.m1.1.1.6.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><times id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1"></times><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">𝑀</ci><ci id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3">𝑁</ci><ci id="S5.SS2.p2.1.m1.1.1.4.cmml" xref="S5.SS2.p2.1.m1.1.1.4">𝐼</ci><ci id="S5.SS2.p2.1.m1.1.1.5.cmml" xref="S5.SS2.p2.1.m1.1.1.5">𝑆</ci><ci id="S5.SS2.p2.1.m1.1.1.6.cmml" xref="S5.SS2.p2.1.m1.1.1.6">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">MNIST</annotation></semantics></math> and <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="CIFAR10" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">I</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.2.m2.1.1.1a" xref="S5.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.2.m2.1.1.4" xref="S5.SS2.p2.2.m2.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.2.m2.1.1.1b" xref="S5.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.2.m2.1.1.5" xref="S5.SS2.p2.2.m2.1.1.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.2.m2.1.1.1c" xref="S5.SS2.p2.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS2.p2.2.m2.1.1.6" xref="S5.SS2.p2.2.m2.1.1.6.cmml">R</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p2.2.m2.1.1.1d" xref="S5.SS2.p2.2.m2.1.1.1.cmml">​</mo><mn id="S5.SS2.p2.2.m2.1.1.7" xref="S5.SS2.p2.2.m2.1.1.7.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><times id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1"></times><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">𝐶</ci><ci id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">𝐼</ci><ci id="S5.SS2.p2.2.m2.1.1.4.cmml" xref="S5.SS2.p2.2.m2.1.1.4">𝐹</ci><ci id="S5.SS2.p2.2.m2.1.1.5.cmml" xref="S5.SS2.p2.2.m2.1.1.5">𝐴</ci><ci id="S5.SS2.p2.2.m2.1.1.6.cmml" xref="S5.SS2.p2.2.m2.1.1.6">𝑅</ci><cn type="integer" id="S5.SS2.p2.2.m2.1.1.7.cmml" xref="S5.SS2.p2.2.m2.1.1.7">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">CIFAR10</annotation></semantics></math>, two datasets commonly employed by FL researchers.
Note that in practice, FL training needs labeled data locally stored at the clients’ side.
Indeed, the number of labeled examples expected to be present in a real setting could be fewer than what these datasets may allocate per FL client.
Nonetheless, using them allows comparison of our results with state-of-art end-to-end FL methods <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib39" title="" class="ltx_ref">li2018federated, </a>; <a href="#bib.bib72" title="" class="ltx_ref">wang2020federated, </a>; <a href="#bib.bib16" title="" class="ltx_ref">geiping2020inverting, </a>)</cite>.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.12" class="ltx_p">Specifically, LeNet is tested on MNIST <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib37" title="" class="ltx_ref">lecun1998gradient, </a>)</cite> and all other models are tested on CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib33" title="" class="ltx_ref">krizhevsky2009learning, </a>)</cite>.
The former is a handwritten digit image (<math id="S5.SS2.p3.1.m1.1" class="ltx_Math" alttext="28" display="inline"><semantics id="S5.SS2.p3.1.m1.1a"><mn id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><cn type="integer" id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">28</annotation></semantics></math><math id="S5.SS2.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p3.2.m2.1a"><mo id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><times id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">\times</annotation></semantics></math><math id="S5.SS2.p3.3.m3.1" class="ltx_Math" alttext="28" display="inline"><semantics id="S5.SS2.p3.3.m3.1a"><mn id="S5.SS2.p3.3.m3.1.1" xref="S5.SS2.p3.3.m3.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m3.1b"><cn type="integer" id="S5.SS2.p3.3.m3.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m3.1c">28</annotation></semantics></math>) dataset consisting of <math id="S5.SS2.p3.4.m4.1" class="ltx_Math" alttext="60k" display="inline"><semantics id="S5.SS2.p3.4.m4.1a"><mrow id="S5.SS2.p3.4.m4.1.1" xref="S5.SS2.p3.4.m4.1.1.cmml"><mn id="S5.SS2.p3.4.m4.1.1.2" xref="S5.SS2.p3.4.m4.1.1.2.cmml">60</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p3.4.m4.1.1.1" xref="S5.SS2.p3.4.m4.1.1.1.cmml">​</mo><mi id="S5.SS2.p3.4.m4.1.1.3" xref="S5.SS2.p3.4.m4.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.4.m4.1b"><apply id="S5.SS2.p3.4.m4.1.1.cmml" xref="S5.SS2.p3.4.m4.1.1"><times id="S5.SS2.p3.4.m4.1.1.1.cmml" xref="S5.SS2.p3.4.m4.1.1.1"></times><cn type="integer" id="S5.SS2.p3.4.m4.1.1.2.cmml" xref="S5.SS2.p3.4.m4.1.1.2">60</cn><ci id="S5.SS2.p3.4.m4.1.1.3.cmml" xref="S5.SS2.p3.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.4.m4.1c">60k</annotation></semantics></math> training samples and <math id="S5.SS2.p3.5.m5.1" class="ltx_Math" alttext="10k" display="inline"><semantics id="S5.SS2.p3.5.m5.1a"><mrow id="S5.SS2.p3.5.m5.1.1" xref="S5.SS2.p3.5.m5.1.1.cmml"><mn id="S5.SS2.p3.5.m5.1.1.2" xref="S5.SS2.p3.5.m5.1.1.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p3.5.m5.1.1.1" xref="S5.SS2.p3.5.m5.1.1.1.cmml">​</mo><mi id="S5.SS2.p3.5.m5.1.1.3" xref="S5.SS2.p3.5.m5.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.5.m5.1b"><apply id="S5.SS2.p3.5.m5.1.1.cmml" xref="S5.SS2.p3.5.m5.1.1"><times id="S5.SS2.p3.5.m5.1.1.1.cmml" xref="S5.SS2.p3.5.m5.1.1.1"></times><cn type="integer" id="S5.SS2.p3.5.m5.1.1.2.cmml" xref="S5.SS2.p3.5.m5.1.1.2">10</cn><ci id="S5.SS2.p3.5.m5.1.1.3.cmml" xref="S5.SS2.p3.5.m5.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.5.m5.1c">10k</annotation></semantics></math> test samples with 10 classes.
The latter is an object image (<math id="S5.SS2.p3.6.m6.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S5.SS2.p3.6.m6.1a"><mn id="S5.SS2.p3.6.m6.1.1" xref="S5.SS2.p3.6.m6.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.6.m6.1b"><cn type="integer" id="S5.SS2.p3.6.m6.1.1.cmml" xref="S5.SS2.p3.6.m6.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.6.m6.1c">32</annotation></semantics></math><math id="S5.SS2.p3.7.m7.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p3.7.m7.1a"><mo id="S5.SS2.p3.7.m7.1.1" xref="S5.SS2.p3.7.m7.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.7.m7.1b"><times id="S5.SS2.p3.7.m7.1.1.cmml" xref="S5.SS2.p3.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.7.m7.1c">\times</annotation></semantics></math><math id="S5.SS2.p3.8.m8.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S5.SS2.p3.8.m8.1a"><mn id="S5.SS2.p3.8.m8.1.1" xref="S5.SS2.p3.8.m8.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.8.m8.1b"><cn type="integer" id="S5.SS2.p3.8.m8.1.1.cmml" xref="S5.SS2.p3.8.m8.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.8.m8.1c">32</annotation></semantics></math><math id="S5.SS2.p3.9.m9.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p3.9.m9.1a"><mo id="S5.SS2.p3.9.m9.1.1" xref="S5.SS2.p3.9.m9.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.9.m9.1b"><times id="S5.SS2.p3.9.m9.1.1.cmml" xref="S5.SS2.p3.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.9.m9.1c">\times</annotation></semantics></math><math id="S5.SS2.p3.10.m10.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.p3.10.m10.1a"><mn id="S5.SS2.p3.10.m10.1.1" xref="S5.SS2.p3.10.m10.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.10.m10.1b"><cn type="integer" id="S5.SS2.p3.10.m10.1.1.cmml" xref="S5.SS2.p3.10.m10.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.10.m10.1c">3</annotation></semantics></math>) dataset consisting of <math id="S5.SS2.p3.11.m11.1" class="ltx_Math" alttext="50k" display="inline"><semantics id="S5.SS2.p3.11.m11.1a"><mrow id="S5.SS2.p3.11.m11.1.1" xref="S5.SS2.p3.11.m11.1.1.cmml"><mn id="S5.SS2.p3.11.m11.1.1.2" xref="S5.SS2.p3.11.m11.1.1.2.cmml">50</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p3.11.m11.1.1.1" xref="S5.SS2.p3.11.m11.1.1.1.cmml">​</mo><mi id="S5.SS2.p3.11.m11.1.1.3" xref="S5.SS2.p3.11.m11.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.11.m11.1b"><apply id="S5.SS2.p3.11.m11.1.1.cmml" xref="S5.SS2.p3.11.m11.1.1"><times id="S5.SS2.p3.11.m11.1.1.1.cmml" xref="S5.SS2.p3.11.m11.1.1.1"></times><cn type="integer" id="S5.SS2.p3.11.m11.1.1.2.cmml" xref="S5.SS2.p3.11.m11.1.1.2">50</cn><ci id="S5.SS2.p3.11.m11.1.1.3.cmml" xref="S5.SS2.p3.11.m11.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.11.m11.1c">50k</annotation></semantics></math> training samples and <math id="S5.SS2.p3.12.m12.1" class="ltx_Math" alttext="10k" display="inline"><semantics id="S5.SS2.p3.12.m12.1a"><mrow id="S5.SS2.p3.12.m12.1.1" xref="S5.SS2.p3.12.m12.1.1.cmml"><mn id="S5.SS2.p3.12.m12.1.1.2" xref="S5.SS2.p3.12.m12.1.1.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p3.12.m12.1.1.1" xref="S5.SS2.p3.12.m12.1.1.1.cmml">​</mo><mi id="S5.SS2.p3.12.m12.1.1.3" xref="S5.SS2.p3.12.m12.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.12.m12.1b"><apply id="S5.SS2.p3.12.m12.1.1.cmml" xref="S5.SS2.p3.12.m12.1.1"><times id="S5.SS2.p3.12.m12.1.1.1.cmml" xref="S5.SS2.p3.12.m12.1.1.1"></times><cn type="integer" id="S5.SS2.p3.12.m12.1.1.2.cmml" xref="S5.SS2.p3.12.m12.1.1.2">10</cn><ci id="S5.SS2.p3.12.m12.1.1.3.cmml" xref="S5.SS2.p3.12.m12.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.12.m12.1c">10k</annotation></semantics></math> test samples with 10 classes.
We follow the setup in <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite> to partition training datasets into 100 parts, one per client, in two versions: i) Independent and Identically Distributed (IID) where a client has samples of all classes; ii) Non-Independent and Identically Distributed (Non-IID) where a client has samples only from two random classes.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Performance Metrics</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The evaluation of PPFL prototype presented in the next section focuses on assessing the framework from the point of view of (i) privacy of data, (ii) ML model performance, and (iii) client-side system cost.
Although ML computations (i.e., model training) have the same precision and accuracy no matter in REEs or TEEs, PPFL changes the FL model training process into a layer-based training.
This affects ML accuracy and the number of communication rounds needed for the model to converge (among others).
Thus, we devise several metrics and perform extensive measurements to assess overall PPFL performance.
We conduct system cost measurements only on client devices since their computational resources are more limited compared to the server.
All experiments are done with 10% of the total number of clients (i.e., 10 out of 100) participating in each communication round. We run FL experiments on our PPFL prototype (Sec. <a href="#S5.SS1" title="5.1. PPFL Prototype ‣ 5. Implementation &amp; Evaluation Setup ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>) to measure the system cost. To measure privacy risks and ML model performance, we perform simulations on a cluster with multiple NVIDIA RTX6000 GPUs (24GB) nodes running PyTorch v1.4.0 under Python v3.6.0.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text ltx_font_bold">Model Performance.</span>
We measure three metrics to assess the performance of the model and PPFL-related process:</p>
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><em id="S5.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Test Accuracy</em>: ML accuracy of test data on a given FL model, for a fixed number of communication rounds.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><em id="S5.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Communication Rounds</em>: Iterations of communication between server and clients needed to achieve a particular test accuracy.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p"><em id="S5.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Amount of communication</em>: Total amount of data exchanged to reach a test accuracy. Transmitted data sizes may be different among communication rounds when considering different layers’ sizes in layer-wise training.</p>
</div>
</li>
</ol>
</div>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_bold">Privacy Assessment.</span>
We measure privacy risk of PPFL by applying three FL-applicable, privacy-related attacks:</p>
<ol id="S5.I2" class="ltx_enumerate">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p">Data Reconstruction Attack (DRA) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>)</cite></p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p">Property Inference Attack (PIA) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>)</cite></p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p id="S5.I2.i3.p1.1" class="ltx_p">Membership Inference Attack (MIA) <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>)</cite></p>
</div>
</li>
</ol>
<p id="S5.SS3.p3.2" class="ltx_p">We follow the proposing papers and their settings to conduct each attack on the model trained in FL process.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text ltx_font_bold">Client-side System Cost.</span>
We monitor the efficiency of client on-device training, and measure the following device costs for PPFL-related process information:</p>
<ol id="S5.I3" class="ltx_enumerate">
<li id="S5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S5.I3.i1.p1" class="ltx_para">
<p id="S5.I3.i1.p1.1" class="ltx_p"><em id="S5.I3.i1.p1.1.1" class="ltx_emph ltx_font_italic">CPU Execution Time (s)</em>: Time the CPU was used for processing the on-device model training, including time spent in REE and the TEE’s user and kernel time, which is reported by using function <span id="S5.I3.i1.p1.1.2" class="ltx_text ltx_font_typewriter">getrusage(RUSAGE_SELF)</span>.</p>
</div>
</li>
<li id="S5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S5.I3.i2.p1" class="ltx_para">
<p id="S5.I3.i2.p1.1" class="ltx_p"><em id="S5.I3.i2.p1.1.1" class="ltx_emph ltx_font_italic">Memory Usage (MB)</em>:
We add REE memory (the maximum resident set size in RAM, accessible by <span id="S5.I3.i2.p1.1.2" class="ltx_text ltx_font_typewriter">getrusage()</span>) and allocated TEE memory (accessible by <span id="S5.I3.i2.p1.1.3" class="ltx_text ltx_font_typewriter">mdbg_check(1)</span>) to get the total memory usage.</p>
</div>
</li>
<li id="S5.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S5.I3.i3.p1" class="ltx_para">
<p id="S5.I3.i3.p1.1" class="ltx_p"><em id="S5.I3.i3.p1.1.1" class="ltx_emph ltx_font_italic">Energy Consumption (J)</em>:
Measured by all energy used to perform one on-device training step when the model runs with/without TEEs. For this, we use the <em id="S5.I3.i3.p1.1.2" class="ltx_emph ltx_font_italic">Monsoon High Voltage Power Monitor</em> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib50" title="" class="ltx_ref">msoon, </a>)</cite>. We configure the power to HiKey board as 12V voltage while recording the current in a <math id="S5.I3.i3.p1.1.m1.1" class="ltx_Math" alttext="50Hz" display="inline"><semantics id="S5.I3.i3.p1.1.m1.1a"><mrow id="S5.I3.i3.p1.1.m1.1.1" xref="S5.I3.i3.p1.1.m1.1.1.cmml"><mn id="S5.I3.i3.p1.1.m1.1.1.2" xref="S5.I3.i3.p1.1.m1.1.1.2.cmml">50</mn><mo lspace="0em" rspace="0em" id="S5.I3.i3.p1.1.m1.1.1.1" xref="S5.I3.i3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I3.i3.p1.1.m1.1.1.3" xref="S5.I3.i3.p1.1.m1.1.1.3.cmml">H</mi><mo lspace="0em" rspace="0em" id="S5.I3.i3.p1.1.m1.1.1.1a" xref="S5.I3.i3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I3.i3.p1.1.m1.1.1.4" xref="S5.I3.i3.p1.1.m1.1.1.4.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.I3.i3.p1.1.m1.1b"><apply id="S5.I3.i3.p1.1.m1.1.1.cmml" xref="S5.I3.i3.p1.1.m1.1.1"><times id="S5.I3.i3.p1.1.m1.1.1.1.cmml" xref="S5.I3.i3.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.I3.i3.p1.1.m1.1.1.2.cmml" xref="S5.I3.i3.p1.1.m1.1.1.2">50</cn><ci id="S5.I3.i3.p1.1.m1.1.1.3.cmml" xref="S5.I3.i3.p1.1.m1.1.1.3">𝐻</ci><ci id="S5.I3.i3.p1.1.m1.1.1.4.cmml" xref="S5.I3.i3.p1.1.m1.1.1.4">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.i3.p1.1.m1.1c">50Hz</annotation></semantics></math> sampling rate.
Training with a high-performance power setting can lead to high temperature and consequently under-clocking. Thus, we run each trial with 2000 steps continuously, starting with 120s cooling time.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Evaluation Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we present the experimental evaluation of PPFL aiming to answer a set of key questions.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>How Effectively does PPFL Thwart Known Privacy-related Attacks?</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">To measure the exposure of the model to known privacy risks, we conduct data reconstruction, property inference, and membership inference attacks (i.e., DRAs, PIAs, and MIAs) on the PPFL model.
While training AlexNet and VGG9 models on CIFAR10 in an IID setting.
We compare the exposure of PPFL to these attacks against a standard, end-to-end FL-trained model.
Table <a href="#S6.T2" title="Table 2 ‣ 6.1. How Effectively does PPFL Thwart Known Privacy-related Attacks? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the average performance of each attack in the same way it is measured in literature <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib78" title="" class="ltx_ref">zhu2019deep, </a>; <a href="#bib.bib45" title="" class="ltx_ref">melis2019exploiting, </a>; <a href="#bib.bib52" title="" class="ltx_ref">nasr2019comprehensive, </a>)</cite>: Mean-Square-Error (MSE) for the DRA, Area-Under-Curve (AUC) for the PIA, and Precision for the MIA.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.3" class="ltx_p">From the results, it becomes clear that, while these attacks can successfully disclose private information in regular end-to-end FL, they fail in PPFL.
As DRAs and PIAs rely on intermediate training models (i.e., gradients) that remain protected, PPFL can fully defend against them. The DRA can only reconstruct a fully noised image for any target image (i.e., an MSE of <math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mo id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">\sim</annotation></semantics></math>1.3 for the specific dataset), while the PIA always reports a random guess on private properties (i.e., an AUC of <math id="S6.SS1.p2.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.SS1.p2.2.m2.1a"><mo id="S6.SS1.p2.2.m2.1.1" xref="S6.SS1.p2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.2.m2.1b"><csymbol cd="latexml" id="S6.SS1.p2.2.m2.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.2.m2.1c">\sim</annotation></semantics></math>0.5).
Regarding the MIA on final trained models, as PPFL keeps the last layer and its outputs always protected inside the client’s TEE, it forces the adversary to access only previous layers, which significantly drops the MIA’s advantage (i.e., Precision<math id="S6.SS1.p2.3.m3.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S6.SS1.p2.3.m3.1a"><mo id="S6.SS1.p2.3.m3.1.1" xref="S6.SS1.p2.3.m3.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.3.m3.1b"><approx id="S6.SS1.p2.3.m3.1.1.cmml" xref="S6.SS1.p2.3.m3.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.3.m3.1c">\approx</annotation></semantics></math>0.5).
Thus, PPFL fully addresses privacy issues raised by such attacks.</p>
</div>
<figure id="S6.T2" class="ltx_table">

<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2. </span>Results of three privacy-related attacks (DRA, PIA and MIA) on PPFL vs. end-to-end (E2E) FL.
Average score reported with 95% confidence interval in parenthesis.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S6.T2.7" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.7.8.1" class="ltx_tr">
<th id="S6.T2.7.8.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2">
<span class="ltx_rule" style="width:0.0pt;height:11.6pt;background:black;display:inline-block;"></span><span id="S6.T2.7.8.1.1.1" class="ltx_text" style="font-size:90%;"> </span><span id="S6.T2.7.8.1.1.2" class="ltx_text" style="font-size:90%;">
<span id="S6.T2.7.8.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T2.7.8.1.1.2.1.1" class="ltx_tr">
<span id="S6.T2.7.8.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Learning</span></span>
<span id="S6.T2.7.8.1.1.2.1.2" class="ltx_tr">
<span id="S6.T2.7.8.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Method</span></span>
</span></span>
</th>
<th id="S6.T2.7.8.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S6.T2.7.8.1.2.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T2.7.8.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="3"><span id="S6.T2.7.8.1.3.1" class="ltx_text" style="font-size:90%;">Privacy-related Attack</span></th>
</tr>
<tr id="S6.T2.3.3" class="ltx_tr">
<th id="S6.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_rule" style="width:0.0pt;height:11.6pt;background:black;display:inline-block;"></span><span id="S6.T2.1.1.1.2" class="ltx_text" style="font-size:90%;"> DRA</span><span id="S6.T2.1.1.1.1" class="ltx_text" style="font-size:70%;">, in MSE <sup id="S6.T2.1.1.1.1.1" class="ltx_sup"><span id="S6.T2.1.1.1.1.1.1" class="ltx_text ltx_font_italic" style="font-size:129%;">α</span></sup></span>
</th>
<th id="S6.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S6.T2.2.2.2.2" class="ltx_text" style="font-size:90%;">PIA</span><span id="S6.T2.2.2.2.1" class="ltx_text" style="font-size:70%;">, in AUC <sup id="S6.T2.2.2.2.1.1" class="ltx_sup"><span id="S6.T2.2.2.2.1.1.1" class="ltx_text ltx_font_italic" style="font-size:129%;">δ</span></sup></span>
</th>
<th id="S6.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S6.T2.3.3.3.2" class="ltx_text" style="font-size:90%;">MIA</span><span id="S6.T2.3.3.3.1" class="ltx_text" style="font-size:70%;">, in Prec. <sup id="S6.T2.3.3.3.1.1" class="ltx_sup"><span id="S6.T2.3.3.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:129%;">ϵ</span></sup></span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.4.4" class="ltx_tr">
<th id="S6.T2.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_rule" style="width:0.0pt;height:15.5pt;background:black;display:inline-block;"></span><span id="S6.T2.4.4.2.1" class="ltx_text" style="font-size:90%;"> E2E</span>
</th>
<th id="S6.T2.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S6.T2.4.4.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.4.4.3.1.1" class="ltx_tr">
<td id="S6.T2.4.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">AlexNet</span></td>
</tr>
<tr id="S6.T2.4.4.3.1.2" class="ltx_tr">
<td id="S6.T2.4.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.3.1.2.1.1" class="ltx_text" style="font-size:90%;">VGG9</span></td>
</tr>
</table>
</th>
<td id="S6.T2.4.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S6.T2.4.4.1.1" class="ltx_text" style="font-size:90%;position:relative; bottom:-5.0pt;"><img src="/html/2104.14380/assets/x2.png" id="S6.T2.4.4.1.1.g1" class="ltx_graphics ltx_img_square" width="16" height="16" alt="[Uncaptioned image]"></span><span id="S6.T2.4.4.1.2" class="ltx_text" style="font-size:90%;"> </span>
<table id="S6.T2.4.4.1.3" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.4.4.1.3.1" class="ltx_tr">
<td id="S6.T2.4.4.1.3.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.1.3.1.1.1" class="ltx_text" style="font-size:90%;">0.017 (0.01)</span></td>
</tr>
<tr id="S6.T2.4.4.1.3.2" class="ltx_tr">
<td id="S6.T2.4.4.1.3.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.1.3.2.1.1" class="ltx_text" style="font-size:90%;">0.008 (¡0.01)</span></td>
</tr>
</table>
</td>
<td id="S6.T2.4.4.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S6.T2.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.4.4.4.1.1" class="ltx_tr">
<td id="S6.T2.4.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.4.1.1.1.1" class="ltx_text" style="font-size:90%;">0.930 (0.03)</span></td>
</tr>
<tr id="S6.T2.4.4.4.1.2" class="ltx_tr">
<td id="S6.T2.4.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.4.1.2.1.1" class="ltx_text" style="font-size:90%;">0.862 (0.05)</span></td>
</tr>
</table>
</td>
<td id="S6.T2.4.4.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S6.T2.4.4.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.4.4.5.1.1" class="ltx_tr">
<td id="S6.T2.4.4.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.5.1.1.1.1" class="ltx_text" style="font-size:90%;">0.874 (0.01)</span></td>
</tr>
<tr id="S6.T2.4.4.5.1.2" class="ltx_tr">
<td id="S6.T2.4.4.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.4.4.5.1.2.1.1" class="ltx_text" style="font-size:90%;">0.765 (0.04)</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S6.T2.7.7" class="ltx_tr">
<th id="S6.T2.7.7.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_rule" style="width:0.0pt;height:15.5pt;background:black;display:inline-block;"></span><span id="S6.T2.7.7.4.1" class="ltx_text" style="font-size:90%;"> PPFL</span>
</th>
<th id="S6.T2.7.7.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S6.T2.7.7.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.7.7.5.1.1" class="ltx_tr">
<td id="S6.T2.7.7.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.7.7.5.1.1.1.1" class="ltx_text" style="font-size:90%;">AlexNet</span></td>
</tr>
<tr id="S6.T2.7.7.5.1.2" class="ltx_tr">
<td id="S6.T2.7.7.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.7.7.5.1.2.1.1" class="ltx_text" style="font-size:90%;">VGG9</span></td>
</tr>
</table>
</th>
<td id="S6.T2.6.6.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S6.T2.5.5.1.1" class="ltx_text" style="font-size:90%;position:relative; bottom:-5.0pt;"><img src="/html/2104.14380/assets/x3.png" id="S6.T2.5.5.1.1.g1" class="ltx_graphics ltx_img_square" width="16" height="16" alt="[Uncaptioned image]"></span><span id="S6.T2.6.6.2.2" class="ltx_text" style="font-size:90%;"> </span><math id="S6.T2.6.6.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.T2.6.6.2.m1.1a"><mo mathsize="90%" id="S6.T2.6.6.2.m1.1.1" xref="S6.T2.6.6.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.T2.6.6.2.m1.1b"><csymbol cd="latexml" id="S6.T2.6.6.2.m1.1.1.cmml" xref="S6.T2.6.6.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.6.6.2.m1.1c">\sim</annotation></semantics></math><span id="S6.T2.6.6.2.3" class="ltx_text" style="font-size:90%;">1.3</span>
</td>
<td id="S6.T2.7.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<math id="S6.T2.7.7.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.T2.7.7.3.m1.1a"><mo mathsize="90%" id="S6.T2.7.7.3.m1.1.1" xref="S6.T2.7.7.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.T2.7.7.3.m1.1b"><csymbol cd="latexml" id="S6.T2.7.7.3.m1.1.1.cmml" xref="S6.T2.7.7.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.7.7.3.m1.1c">\sim</annotation></semantics></math><span id="S6.T2.7.7.3.1" class="ltx_text" style="font-size:90%;">0.5</span>
</td>
<td id="S6.T2.7.7.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S6.T2.7.7.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.7.7.6.1.1" class="ltx_tr">
<td id="S6.T2.7.7.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.7.7.6.1.1.1.1" class="ltx_text" style="font-size:90%;">0.506 (0.01)</span></td>
</tr>
<tr id="S6.T2.7.7.6.1.2" class="ltx_tr">
<td id="S6.T2.7.7.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S6.T2.7.7.6.1.2.1.1" class="ltx_text" style="font-size:90%;">0.507 (¡0.01)</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S6.T2.12.5" class="ltx_p ltx_figure_panel ltx_align_left"><sup id="S6.T2.12.5.5" class="ltx_sup"><span id="S6.T2.12.5.5.1" class="ltx_text ltx_font_italic" style="font-size:80%;">α</span></sup><span id="S6.T2.12.5.4" class="ltx_text" style="font-size:80%;">MSE (mean-square error) measures the difference between constructed images and target images (range is <math id="S6.T2.9.2.1.m1.2" class="ltx_Math" alttext="[0,\infty)" display="inline"><semantics id="S6.T2.9.2.1.m1.2a"><mrow id="S6.T2.9.2.1.m1.2.3.2" xref="S6.T2.9.2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S6.T2.9.2.1.m1.2.3.2.1" xref="S6.T2.9.2.1.m1.2.3.1.cmml">[</mo><mn id="S6.T2.9.2.1.m1.1.1" xref="S6.T2.9.2.1.m1.1.1.cmml">0</mn><mo id="S6.T2.9.2.1.m1.2.3.2.2" xref="S6.T2.9.2.1.m1.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S6.T2.9.2.1.m1.2.2" xref="S6.T2.9.2.1.m1.2.2.cmml">∞</mi><mo stretchy="false" id="S6.T2.9.2.1.m1.2.3.2.3" xref="S6.T2.9.2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T2.9.2.1.m1.2b"><interval closure="closed-open" id="S6.T2.9.2.1.m1.2.3.1.cmml" xref="S6.T2.9.2.1.m1.2.3.2"><cn type="integer" id="S6.T2.9.2.1.m1.1.1.cmml" xref="S6.T2.9.2.1.m1.1.1">0</cn><infinity id="S6.T2.9.2.1.m1.2.2.cmml" xref="S6.T2.9.2.1.m1.2.2"></infinity></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.9.2.1.m1.2c">[0,\infty)</annotation></semantics></math>, and the lower MSE is, the more privacy loss);
<sup id="S6.T2.12.5.4.1" class="ltx_sup"><span id="S6.T2.12.5.4.1.1" class="ltx_text ltx_font_italic">δ</span></sup>AUC refers to the area under receiver operating curve;
<sup id="S6.T2.12.5.4.2" class="ltx_sup"><span id="S6.T2.12.5.4.2.1" class="ltx_text ltx_font_italic">ϵ</span></sup>Prec. refers to Precision.
The range of both AUC and Prec. is <math id="S6.T2.12.5.4.m4.2" class="ltx_Math" alttext="[0.5,1]" display="inline"><semantics id="S6.T2.12.5.4.m4.2a"><mrow id="S6.T2.12.5.4.m4.2.3.2" xref="S6.T2.12.5.4.m4.2.3.1.cmml"><mo stretchy="false" id="S6.T2.12.5.4.m4.2.3.2.1" xref="S6.T2.12.5.4.m4.2.3.1.cmml">[</mo><mn id="S6.T2.12.5.4.m4.1.1" xref="S6.T2.12.5.4.m4.1.1.cmml">0.5</mn><mo id="S6.T2.12.5.4.m4.2.3.2.2" xref="S6.T2.12.5.4.m4.2.3.1.cmml">,</mo><mn id="S6.T2.12.5.4.m4.2.2" xref="S6.T2.12.5.4.m4.2.2.cmml">1</mn><mo stretchy="false" id="S6.T2.12.5.4.m4.2.3.2.3" xref="S6.T2.12.5.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T2.12.5.4.m4.2b"><interval closure="closed" id="S6.T2.12.5.4.m4.2.3.1.cmml" xref="S6.T2.12.5.4.m4.2.3.2"><cn type="float" id="S6.T2.12.5.4.m4.1.1.cmml" xref="S6.T2.12.5.4.m4.1.1">0.5</cn><cn type="integer" id="S6.T2.12.5.4.m4.2.2.cmml" xref="S6.T2.12.5.4.m4.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.12.5.4.m4.2c">[0.5,1]</annotation></semantics></math> (assuming 0.5 is for random guesses), and the higher AUC or Prec. is, the more privacy loss).</span></p>
</div>
</div>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>What is the PPFL Communication Cost?</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p"><span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_bold">Predefined ML Performance.</span>
Next, we measure PPFL’s communication cost to complete the FL process, when a specific ML performance is desired.
For this, we first execute the standard end-to-end FL without TEEs for 150 rounds and record the achieved ML performance.
Subsequently, we set the same test accuracy as a requirement, and measure the number of communication rounds and amount of communication required by PPFL to achieve this ML performance.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">In this experiment, we set the number of local epochs at clients as 10.
We use SGD as the optimization algorithm and set the learning rate as 0.01, with a decay of 0.99 after each epoch.
Momentum is set to 0.5 and the batch size to 16.
When training each layer locally, we build one classifier on top of it.
The classifier’s architecture follows the last convolutional (Conv) layer and fully-connected (FC) layers of the target model (e.g., AlexNet or VGG9).
Thus, the training of each global model’s layer progresses until all Conv layers are finished.
We choose AlexNet and VGG9 on CIFAR10, because MNIST is too simple for testing.
Then, the classifier atop all Conv layers is finally trained to provide outputs for the global model.
Note that we also aggregate the client classifiers while training one global layer to provide the test accuracy after each communication round.
We perform these experiments on IID and Non-IID data.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">Overall, the results in Table <a href="#S6.T3" title="Table 3 ‣ 6.2. What is the PPFL Communication Cost? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> show that, while trying to reach the ML performance achieved by the standard end-to-end FL system, PPFL adds small communication overhead, if any, to the FL process.
In fact, in some cases, it can even reduce the communication cost, while preserving privacy when using TEEs.
As expected, using Non-IID data leads to lower ML performance across the system, which also implies less communication cost for PPFL as well.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">The reason why in many cases PPFL has reduced communication cost, while still achieving comparable ML performance, is that training these models on datasets such as CIFAR10 may not require training the complete model.
Instead, during the early stage of PPFL’s layer-wise training (e.g., first global layer+classifier), it can already reach good ML performance, and in some cases even better than training the entire model.
We explore this aspect further in the next subsection.
Consequently, and due to the needed rounds being fewer, the amount of communication is also reduced.</p>
</div>
<div id="S6.SS2.p5" class="ltx_para">
<p id="S6.SS2.p5.1" class="ltx_p">The increased cost when training VGG9 is due to the large number of neurons in the classifier’s FC layer connected to the first Conv layer.
Thus, even if the number of total layers considered (one global layer + classifier) is smaller compared to the latter stages (multiple global layers + classifier), the model size (i.e., number of parameters) can be larger.</p>
</div>
<div id="S6.SS2.p6" class="ltx_para">
<p id="S6.SS2.p6.1" class="ltx_p">Indeed, we are aware that by training any of these models on CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>)</cite> for more communication rounds, either the PPFL or the regular end-to-end FL can reach higher test accuracy such as 85% with standard <math id="S6.SS2.p6.1.m1.1" class="ltx_Math" alttext="FedAvg" display="inline"><semantics id="S6.SS2.p6.1.m1.1a"><mrow id="S6.SS2.p6.1.m1.1.1" xref="S6.SS2.p6.1.m1.1.1.cmml"><mi id="S6.SS2.p6.1.m1.1.1.2" xref="S6.SS2.p6.1.m1.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p6.1.m1.1.1.1" xref="S6.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p6.1.m1.1.1.3" xref="S6.SS2.p6.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p6.1.m1.1.1.1a" xref="S6.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p6.1.m1.1.1.4" xref="S6.SS2.p6.1.m1.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p6.1.m1.1.1.1b" xref="S6.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p6.1.m1.1.1.5" xref="S6.SS2.p6.1.m1.1.1.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p6.1.m1.1.1.1c" xref="S6.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p6.1.m1.1.1.6" xref="S6.SS2.p6.1.m1.1.1.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p6.1.m1.1.1.1d" xref="S6.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p6.1.m1.1.1.7" xref="S6.SS2.p6.1.m1.1.1.7.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p6.1.m1.1b"><apply id="S6.SS2.p6.1.m1.1.1.cmml" xref="S6.SS2.p6.1.m1.1.1"><times id="S6.SS2.p6.1.m1.1.1.1.cmml" xref="S6.SS2.p6.1.m1.1.1.1"></times><ci id="S6.SS2.p6.1.m1.1.1.2.cmml" xref="S6.SS2.p6.1.m1.1.1.2">𝐹</ci><ci id="S6.SS2.p6.1.m1.1.1.3.cmml" xref="S6.SS2.p6.1.m1.1.1.3">𝑒</ci><ci id="S6.SS2.p6.1.m1.1.1.4.cmml" xref="S6.SS2.p6.1.m1.1.1.4">𝑑</ci><ci id="S6.SS2.p6.1.m1.1.1.5.cmml" xref="S6.SS2.p6.1.m1.1.1.5">𝐴</ci><ci id="S6.SS2.p6.1.m1.1.1.6.cmml" xref="S6.SS2.p6.1.m1.1.1.6">𝑣</ci><ci id="S6.SS2.p6.1.m1.1.1.7.cmml" xref="S6.SS2.p6.1.m1.1.1.7">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p6.1.m1.1c">FedAvg</annotation></semantics></math>.
However, the training rounds used here are sufficient for our needs, as our goal is to evaluate the performance of PPFL (i.e., what is the cost for reaching the same accuracy), and not to achieve the best possible accuracy on this classification task.</p>
</div>
<figure id="S6.T3" class="ltx_table">

<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3. </span>Communication overhead (rounds and amount) of PPFL to reach the same accuracy as end-to-end FL system.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S6.T3.13" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.1.1" class="ltx_tr">
<th id="S6.T3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.2.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.3.1" class="ltx_text" style="font-size:90%;">Data</span></th>
<th id="S6.T3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S6.T3.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.1.1.1.2" class="ltx_tr">
<td id="S6.T3.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S6.T3.1.1.1.1.2.1.1" class="ltx_text" style="font-size:90%;">Baseline</span></td>
</tr>
<tr id="S6.T3.1.1.1.1.1" class="ltx_tr">
<td id="S6.T3.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S6.T3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Acc.</span><sup id="S6.T3.1.1.1.1.1.1.2" class="ltx_sup"><span id="S6.T3.1.1.1.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">α</span></sup>
</td>
</tr>
</table>
</th>
<th id="S6.T3.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S6.T3.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.1.4.1.1" class="ltx_tr">
<td id="S6.T3.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S6.T3.1.1.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Comm.</span></td>
</tr>
<tr id="S6.T3.1.1.4.1.2" class="ltx_tr">
<td id="S6.T3.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S6.T3.1.1.4.1.2.1.1" class="ltx_text" style="font-size:90%;">Rounds</span></td>
</tr>
</table>
</th>
<th id="S6.T3.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S6.T3.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.1.1.5.1.1" class="ltx_tr">
<td id="S6.T3.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S6.T3.1.1.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Comm.</span></td>
</tr>
<tr id="S6.T3.1.1.5.1.2" class="ltx_tr">
<td id="S6.T3.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S6.T3.1.1.5.1.2.1.1" class="ltx_text" style="font-size:90%;">Amount</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.4.4" class="ltx_tr">
<td id="S6.T3.4.4.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.4.4.4.1" class="ltx_text" style="font-size:90%;">LeNet</span></td>
<td id="S6.T3.4.4.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.4.4.5.1" class="ltx_text" style="font-size:90%;">IID</span></td>
<td id="S6.T3.4.4.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.4.4.6.1" class="ltx_text" style="font-size:90%;">98.93%</span></td>
<td id="S6.T3.3.3.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.3.3.2.1" class="ltx_text" style="font-size:90%;">56 (0.37</span><math id="S6.T3.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.2.2.1.m1.1a"><mo mathsize="90%" id="S6.T3.2.2.1.m1.1.1" xref="S6.T3.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.1.m1.1b"><times id="S6.T3.2.2.1.m1.1.1.cmml" xref="S6.T3.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.1.m1.1c">\times</annotation></semantics></math><span id="S6.T3.3.3.2.2" class="ltx_text" style="font-size:90%;">)</span><sup id="S6.T3.3.3.2.3" class="ltx_sup"><span id="S6.T3.3.3.2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">δ</span></sup>
</td>
<td id="S6.T3.4.4.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.4.4.3.1" class="ltx_text" style="font-size:90%;">0.38 </span><math id="S6.T3.4.4.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.4.4.3.m1.1a"><mo mathsize="90%" id="S6.T3.4.4.3.m1.1.1" xref="S6.T3.4.4.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.3.m1.1b"><times id="S6.T3.4.4.3.m1.1.1.cmml" xref="S6.T3.4.4.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.3.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T3.5.5" class="ltx_tr">
<td id="S6.T3.5.5.2" class="ltx_td"></td>
<td id="S6.T3.5.5.3" class="ltx_td ltx_align_left"><span id="S6.T3.5.5.3.1" class="ltx_text" style="font-size:90%;">Non-IID</span></td>
<td id="S6.T3.5.5.1" class="ltx_td ltx_align_left">
<span id="S6.T3.5.5.1.1" class="ltx_text" style="font-size:90%;">97.06%</span><sup id="S6.T3.5.5.1.2" class="ltx_sup"><span id="S6.T3.5.5.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ϵ</span></sup>
</td>
<td id="S6.T3.5.5.4" class="ltx_td ltx_align_left"><span id="S6.T3.5.5.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S6.T3.5.5.5" class="ltx_td ltx_align_left"><span id="S6.T3.5.5.5.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S6.T3.7.7" class="ltx_tr">
<td id="S6.T3.7.7.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.7.7.3.1" class="ltx_text" style="font-size:90%;">AlexNet</span></td>
<td id="S6.T3.7.7.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.7.7.4.1" class="ltx_text" style="font-size:90%;">IID</span></td>
<td id="S6.T3.7.7.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.7.7.5.1" class="ltx_text" style="font-size:90%;">68.50%</span></td>
<td id="S6.T3.6.6.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.6.6.1.1" class="ltx_text" style="font-size:90%;">97 (0.65</span><math id="S6.T3.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.6.6.1.m1.1a"><mo mathsize="90%" id="S6.T3.6.6.1.m1.1.1" xref="S6.T3.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.6.6.1.m1.1b"><times id="S6.T3.6.6.1.m1.1.1.cmml" xref="S6.T3.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.6.6.1.m1.1c">\times</annotation></semantics></math><span id="S6.T3.6.6.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S6.T3.7.7.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.7.7.2.1" class="ltx_text" style="font-size:90%;">0.63 </span><math id="S6.T3.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.7.7.2.m1.1a"><mo mathsize="90%" id="S6.T3.7.7.2.m1.1.1" xref="S6.T3.7.7.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.7.7.2.m1.1b"><times id="S6.T3.7.7.2.m1.1.1.cmml" xref="S6.T3.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.7.7.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T3.9.9" class="ltx_tr">
<td id="S6.T3.9.9.3" class="ltx_td"></td>
<td id="S6.T3.9.9.4" class="ltx_td ltx_align_left"><span id="S6.T3.9.9.4.1" class="ltx_text" style="font-size:90%;">Non-IID</span></td>
<td id="S6.T3.9.9.5" class="ltx_td ltx_align_left"><span id="S6.T3.9.9.5.1" class="ltx_text" style="font-size:90%;">49.49%</span></td>
<td id="S6.T3.8.8.1" class="ltx_td ltx_align_left">
<span id="S6.T3.8.8.1.1" class="ltx_text" style="font-size:90%;">79 (0.53</span><math id="S6.T3.8.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.8.8.1.m1.1a"><mo mathsize="90%" id="S6.T3.8.8.1.m1.1.1" xref="S6.T3.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.8.8.1.m1.1b"><times id="S6.T3.8.8.1.m1.1.1.cmml" xref="S6.T3.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.8.8.1.m1.1c">\times</annotation></semantics></math><span id="S6.T3.8.8.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S6.T3.9.9.2" class="ltx_td ltx_align_left">
<span id="S6.T3.9.9.2.1" class="ltx_text" style="font-size:90%;">0.53 </span><math id="S6.T3.9.9.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.9.9.2.m1.1a"><mo mathsize="90%" id="S6.T3.9.9.2.m1.1.1" xref="S6.T3.9.9.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.9.9.2.m1.1b"><times id="S6.T3.9.9.2.m1.1.1.cmml" xref="S6.T3.9.9.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.9.9.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T3.11.11" class="ltx_tr">
<td id="S6.T3.11.11.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.11.11.3.1" class="ltx_text" style="font-size:90%;">VGG9</span></td>
<td id="S6.T3.11.11.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.11.11.4.1" class="ltx_text" style="font-size:90%;">IID</span></td>
<td id="S6.T3.11.11.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T3.11.11.5.1" class="ltx_text" style="font-size:90%;">63.09%</span></td>
<td id="S6.T3.10.10.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.10.10.1.1" class="ltx_text" style="font-size:90%;">171 (1.14</span><math id="S6.T3.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.10.10.1.m1.1a"><mo mathsize="90%" id="S6.T3.10.10.1.m1.1.1" xref="S6.T3.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.10.10.1.m1.1b"><times id="S6.T3.10.10.1.m1.1.1.cmml" xref="S6.T3.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.10.10.1.m1.1c">\times</annotation></semantics></math><span id="S6.T3.10.10.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S6.T3.11.11.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S6.T3.11.11.2.1" class="ltx_text" style="font-size:90%;">2.87 </span><math id="S6.T3.11.11.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.11.11.2.m1.1a"><mo mathsize="90%" id="S6.T3.11.11.2.m1.1.1" xref="S6.T3.11.11.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.11.11.2.m1.1b"><times id="S6.T3.11.11.2.m1.1.1.cmml" xref="S6.T3.11.11.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.11.11.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T3.13.13" class="ltx_tr">
<td id="S6.T3.13.13.3" class="ltx_td ltx_border_b"></td>
<td id="S6.T3.13.13.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S6.T3.13.13.4.1" class="ltx_text" style="font-size:90%;">Non-IID</span></td>
<td id="S6.T3.13.13.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S6.T3.13.13.5.1" class="ltx_text" style="font-size:90%;">46.70%</span></td>
<td id="S6.T3.12.12.1" class="ltx_td ltx_align_left ltx_border_b">
<span id="S6.T3.12.12.1.1" class="ltx_text" style="font-size:90%;">36 (0.24</span><math id="S6.T3.12.12.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.12.12.1.m1.1a"><mo mathsize="90%" id="S6.T3.12.12.1.m1.1.1" xref="S6.T3.12.12.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.12.12.1.m1.1b"><times id="S6.T3.12.12.1.m1.1.1.cmml" xref="S6.T3.12.12.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.12.12.1.m1.1c">\times</annotation></semantics></math><span id="S6.T3.12.12.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S6.T3.13.13.2" class="ltx_td ltx_align_left ltx_border_b">
<span id="S6.T3.13.13.2.1" class="ltx_text" style="font-size:90%;">0.60 </span><math id="S6.T3.13.13.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T3.13.13.2.m1.1a"><mo mathsize="90%" id="S6.T3.13.13.2.m1.1.1" xref="S6.T3.13.13.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T3.13.13.2.m1.1b"><times id="S6.T3.13.13.2.m1.1.1.cmml" xref="S6.T3.13.13.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.13.13.2.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S6.T3.16.3" class="ltx_p ltx_figure_panel ltx_align_left"><sup id="S6.T3.16.3.3" class="ltx_sup"><span id="S6.T3.16.3.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">α</span></sup><span id="S6.T3.16.3.2" class="ltx_text" style="font-size:80%;">Acc.: Test accuracy of 150 communication rounds in end-to-end FL;
<br class="ltx_break"><math id="S6.T3.15.2.1.m1.1" class="ltx_math_unparsed" alttext="{}^{\delta}1\times" display="inline"><semantics id="S6.T3.15.2.1.m1.1a"><mrow id="S6.T3.15.2.1.m1.1b"><mmultiscripts id="S6.T3.15.2.1.m1.1.1"><mn id="S6.T3.15.2.1.m1.1.1.2">1</mn><mprescripts id="S6.T3.15.2.1.m1.1.1a"></mprescripts><mrow id="S6.T3.15.2.1.m1.1.1b"></mrow><mi id="S6.T3.15.2.1.m1.1.1.3">δ</mi></mmultiscripts><mo lspace="0.222em" id="S6.T3.15.2.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T3.15.2.1.m1.1c">{}^{\delta}1\times</annotation></semantics></math> refers to no overhead;
<sup id="S6.T3.16.3.2.1" class="ltx_sup"><span id="S6.T3.16.3.2.1.1" class="ltx_text ltx_font_italic">ϵ</span></sup>PPFL reaches a maximum of 95.99%.</span></p>
</div>
</div>
</figure>
<figure id="S6.T4" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.9.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>. </span><span id="S6.T4.10.2" class="ltx_text" style="font-size:90%;">Time duration of FL phases in <em id="S6.T4.10.2.1" class="ltx_emph ltx_font_italic">one communication round</em>, when training LeNet, AlexNet and VGG9 models with PPFL and end-to-end (E2E) FL.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S6.T4.3" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.3.4.1" class="ltx_tr">
<th id="S6.T4.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S6.T4.3.4.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T4.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S6.T4.3.4.1.2.1" class="ltx_text" style="font-size:90%;">Method</span></th>
<td id="S6.T4.3.4.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" colspan="5"><span id="S6.T4.3.4.1.3.1" class="ltx_text" style="font-size:90%;">Duration of FL phases (s)</span></td>
</tr>
<tr id="S6.T4.2.2" class="ltx_tr">
<td id="S6.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S6.T4.1.1.1.1" class="ltx_text" style="font-size:90%;">B.cast</span><sup id="S6.T4.1.1.1.2" class="ltx_sup"><span id="S6.T4.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">α</span></sup>
</td>
<td id="S6.T4.2.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.2.2.3.1" class="ltx_text" style="font-size:90%;">Training</span></td>
<td id="S6.T4.2.2.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.2.2.4.1" class="ltx_text" style="font-size:90%;">Upload</span></td>
<td id="S6.T4.2.2.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S6.T4.2.2.2.1" class="ltx_text" style="font-size:90%;">Aggr.</span><sup id="S6.T4.2.2.2.2" class="ltx_sup"><span id="S6.T4.2.2.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">δ</span></sup>
</td>
<td id="S6.T4.2.2.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.2.2.5.1" class="ltx_text" style="font-size:90%;">Total</span></td>
</tr>
<tr id="S6.T4.3.5.2" class="ltx_tr">
<th id="S6.T4.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S6.T4.3.5.2.1.1" class="ltx_text" style="font-size:90%;">
<span id="S6.T4.3.5.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T4.3.5.2.1.1.1.1" class="ltx_tr">
<span id="S6.T4.3.5.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S6.T4.3.5.2.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:32.9pt;vertical-align:-13.4pt;"><span class="ltx_transformed_inner" style="width:32.9pt;transform:translate(-13.36pt,0pt) rotate(-90deg) ;">
<span id="S6.T4.3.5.2.1.1.1.1.1.1.1" class="ltx_p">LeNet</span>
</span></span></span></span>
</span></span></th>
<th id="S6.T4.3.5.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.2.1" class="ltx_text" style="font-size:90%;">E2E</span></th>
<td id="S6.T4.3.5.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.3.1" class="ltx_text" style="font-size:90%;">4.520</span></td>
<td id="S6.T4.3.5.2.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.4.1" class="ltx_text" style="font-size:90%;">2691.0</span></td>
<td id="S6.T4.3.5.2.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.5.1" class="ltx_text" style="font-size:90%;">6.645</span></td>
<td id="S6.T4.3.5.2.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.6.1" class="ltx_text" style="font-size:90%;">0.064</span></td>
<td id="S6.T4.3.5.2.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.5.2.7.1" class="ltx_text" style="font-size:90%;">2702.3</span></td>
</tr>
<tr id="S6.T4.3.6.3" class="ltx_tr">
<th id="S6.T4.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.1.1" class="ltx_text" style="font-size:90%;">PPFL</span></th>
<td id="S6.T4.3.6.3.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.2.1" class="ltx_text" style="font-size:90%;">18.96</span></td>
<td id="S6.T4.3.6.3.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.3.1" class="ltx_text" style="font-size:90%;">6466.2</span></td>
<td id="S6.T4.3.6.3.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.4.1" class="ltx_text" style="font-size:90%;">7.535</span></td>
<td id="S6.T4.3.6.3.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.5.1" class="ltx_text" style="font-size:90%;">1.887</span></td>
<td id="S6.T4.3.6.3.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.6.3.6.1" class="ltx_text" style="font-size:90%;">6496.5</span></td>
</tr>
<tr id="S6.T4.3.7.4" class="ltx_tr">
<th id="S6.T4.3.7.4.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.7.4.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 1</span></th>
<td id="S6.T4.3.7.4.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.3.1" class="ltx_text" style="font-size:90%;">4.117</span></td>
<td id="S6.T4.3.7.4.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.4.1" class="ltx_text" style="font-size:90%;">1063.3</span></td>
<td id="S6.T4.3.7.4.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.5.1" class="ltx_text" style="font-size:90%;">1.488</span></td>
<td id="S6.T4.3.7.4.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.6.1" class="ltx_text" style="font-size:90%;">0.426</span></td>
<td id="S6.T4.3.7.4.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.7.4.7.1" class="ltx_text" style="font-size:90%;">1069.8</span></td>
</tr>
<tr id="S6.T4.3.8.5" class="ltx_tr">
<th id="S6.T4.3.8.5.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.8.5.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 2</span></th>
<td id="S6.T4.3.8.5.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.3.1" class="ltx_text" style="font-size:90%;">4.670</span></td>
<td id="S6.T4.3.8.5.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.4.1" class="ltx_text" style="font-size:90%;">2130.6</span></td>
<td id="S6.T4.3.8.5.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.5.1" class="ltx_text" style="font-size:90%;">1.627</span></td>
<td id="S6.T4.3.8.5.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.6.1" class="ltx_text" style="font-size:90%;">0.692</span></td>
<td id="S6.T4.3.8.5.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.8.5.7.1" class="ltx_text" style="font-size:90%;">2138.3</span></td>
</tr>
<tr id="S6.T4.3.9.6" class="ltx_tr">
<th id="S6.T4.3.9.6.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.9.6.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 3</span></th>
<td id="S6.T4.3.9.6.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.3.1" class="ltx_text" style="font-size:90%;">5.332</span></td>
<td id="S6.T4.3.9.6.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.4.1" class="ltx_text" style="font-size:90%;">2315.2</span></td>
<td id="S6.T4.3.9.6.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.5.1" class="ltx_text" style="font-size:90%;">1.745</span></td>
<td id="S6.T4.3.9.6.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.6.1" class="ltx_text" style="font-size:90%;">0.676</span></td>
<td id="S6.T4.3.9.6.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.9.6.7.1" class="ltx_text" style="font-size:90%;">2323.6</span></td>
</tr>
<tr id="S6.T4.3.3" class="ltx_tr">
<th id="S6.T4.3.3.2" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- clf.<sup id="S6.T4.3.3.1.1.1" class="ltx_sup">ϵ</sup></span></th>
<td id="S6.T4.3.3.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.3.1" class="ltx_text" style="font-size:90%;">4.845</span></td>
<td id="S6.T4.3.3.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.4.1" class="ltx_text" style="font-size:90%;">957.16</span></td>
<td id="S6.T4.3.3.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.5.1" class="ltx_text" style="font-size:90%;">2.675</span></td>
<td id="S6.T4.3.3.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.6.1" class="ltx_text" style="font-size:90%;">0.093</span></td>
<td id="S6.T4.3.3.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.3.7.1" class="ltx_text" style="font-size:90%;">964.87</span></td>
</tr>
<tr id="S6.T4.3.10.7" class="ltx_tr">
<th id="S6.T4.3.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S6.T4.3.10.7.1.1" class="ltx_text" style="font-size:90%;">
<span id="S6.T4.3.10.7.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T4.3.10.7.1.1.1.1" class="ltx_tr">
<span id="S6.T4.3.10.7.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S6.T4.3.10.7.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:41.3pt;vertical-align:-17.5pt;"><span class="ltx_transformed_inner" style="width:41.3pt;transform:translate(-17.5pt,0pt) rotate(-90deg) ;">
<span id="S6.T4.3.10.7.1.1.1.1.1.1.1" class="ltx_p">AlexNet</span>
</span></span></span></span>
</span></span></th>
<th id="S6.T4.3.10.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.2.1" class="ltx_text" style="font-size:90%;">E2E</span></th>
<td id="S6.T4.3.10.7.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.3.1" class="ltx_text" style="font-size:90%;">14.58</span></td>
<td id="S6.T4.3.10.7.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.4.1" class="ltx_text" style="font-size:90%;">3772.0</span></td>
<td id="S6.T4.3.10.7.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.5.1" class="ltx_text" style="font-size:90%;">6.122</span></td>
<td id="S6.T4.3.10.7.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.6.1" class="ltx_text" style="font-size:90%;">0.061</span></td>
<td id="S6.T4.3.10.7.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.10.7.7.1" class="ltx_text" style="font-size:90%;">3792.8</span></td>
</tr>
<tr id="S6.T4.3.11.8" class="ltx_tr">
<th id="S6.T4.3.11.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.1.1" class="ltx_text" style="font-size:90%;">PPFL</span></th>
<td id="S6.T4.3.11.8.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.2.1" class="ltx_text" style="font-size:90%;">57.24</span></td>
<td id="S6.T4.3.11.8.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.3.1" class="ltx_text" style="font-size:90%;">14236</span></td>
<td id="S6.T4.3.11.8.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.4.1" class="ltx_text" style="font-size:90%;">16.89</span></td>
<td id="S6.T4.3.11.8.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.5.1" class="ltx_text" style="font-size:90%;">3.290</span></td>
<td id="S6.T4.3.11.8.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.11.8.6.1" class="ltx_text" style="font-size:90%;">14316</span></td>
</tr>
<tr id="S6.T4.3.12.9" class="ltx_tr">
<th id="S6.T4.3.12.9.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.12.9.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 1</span></th>
<td id="S6.T4.3.12.9.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.3.1" class="ltx_text" style="font-size:90%;">16.20</span></td>
<td id="S6.T4.3.12.9.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.4.1" class="ltx_text" style="font-size:90%;">2301.8</span></td>
<td id="S6.T4.3.12.9.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.5.1" class="ltx_text" style="font-size:90%;">4.690</span></td>
<td id="S6.T4.3.12.9.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.6.1" class="ltx_text" style="font-size:90%;">0.129</span></td>
<td id="S6.T4.3.12.9.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.12.9.7.1" class="ltx_text" style="font-size:90%;">2322.9</span></td>
</tr>
<tr id="S6.T4.3.13.10" class="ltx_tr">
<th id="S6.T4.3.13.10.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.13.10.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 2</span></th>
<td id="S6.T4.3.13.10.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.3.1" class="ltx_text" style="font-size:90%;">12.56</span></td>
<td id="S6.T4.3.13.10.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.4.1" class="ltx_text" style="font-size:90%;">4041.1</span></td>
<td id="S6.T4.3.13.10.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.5.1" class="ltx_text" style="font-size:90%;">4.777</span></td>
<td id="S6.T4.3.13.10.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.6.1" class="ltx_text" style="font-size:90%;">0.174</span></td>
<td id="S6.T4.3.13.10.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.13.10.7.1" class="ltx_text" style="font-size:90%;">4058.8</span></td>
</tr>
<tr id="S6.T4.3.14.11" class="ltx_tr">
<th id="S6.T4.3.14.11.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.14.11.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 3</span></th>
<td id="S6.T4.3.14.11.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.3.1" class="ltx_text" style="font-size:90%;">10.31</span></td>
<td id="S6.T4.3.14.11.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.4.1" class="ltx_text" style="font-size:90%;">4609.4</span></td>
<td id="S6.T4.3.14.11.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.5.1" class="ltx_text" style="font-size:90%;">5.388</span></td>
<td id="S6.T4.3.14.11.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.6.1" class="ltx_text" style="font-size:90%;">0.243</span></td>
<td id="S6.T4.3.14.11.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.14.11.7.1" class="ltx_text" style="font-size:90%;">4625.6</span></td>
</tr>
<tr id="S6.T4.3.15.12" class="ltx_tr">
<th id="S6.T4.3.15.12.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.15.12.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- clf.</span></th>
<td id="S6.T4.3.15.12.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.3.1" class="ltx_text" style="font-size:90%;">18.17</span></td>
<td id="S6.T4.3.15.12.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.4.1" class="ltx_text" style="font-size:90%;">3283.8</span></td>
<td id="S6.T4.3.15.12.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.5.1" class="ltx_text" style="font-size:90%;">2.033</span></td>
<td id="S6.T4.3.15.12.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.6.1" class="ltx_text" style="font-size:90%;">2.744</span></td>
<td id="S6.T4.3.15.12.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.15.12.7.1" class="ltx_text" style="font-size:90%;">3309.5</span></td>
</tr>
<tr id="S6.T4.3.16.13" class="ltx_tr">
<th id="S6.T4.3.16.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S6.T4.3.16.13.1.1" class="ltx_text" style="font-size:90%;">
<span id="S6.T4.3.16.13.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T4.3.16.13.1.1.1.1" class="ltx_tr">
<span id="S6.T4.3.16.13.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S6.T4.3.16.13.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.1pt;height:34.1pt;vertical-align:-14.0pt;"><span class="ltx_transformed_inner" style="width:34.1pt;transform:translate(-13.99pt,0pt) rotate(-90deg) ;">
<span id="S6.T4.3.16.13.1.1.1.1.1.1.1" class="ltx_p">VGG9</span>
</span></span></span></span>
</span></span></th>
<th id="S6.T4.3.16.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.2.1" class="ltx_text" style="font-size:90%;">E2E</span></th>
<td id="S6.T4.3.16.13.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.3.1" class="ltx_text" style="font-size:90%;">14.10</span></td>
<td id="S6.T4.3.16.13.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.4.1" class="ltx_text" style="font-size:90%;">2867.1</span></td>
<td id="S6.T4.3.16.13.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.5.1" class="ltx_text" style="font-size:90%;">8.883</span></td>
<td id="S6.T4.3.16.13.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.6.1" class="ltx_text" style="font-size:90%;">0.067</span></td>
<td id="S6.T4.3.16.13.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.16.13.7.1" class="ltx_text" style="font-size:90%;">2890.2</span></td>
</tr>
<tr id="S6.T4.3.17.14" class="ltx_tr">
<th id="S6.T4.3.17.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.1.1" class="ltx_text" style="font-size:90%;">PPFL</span></th>
<td id="S6.T4.3.17.14.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.2.1" class="ltx_text" style="font-size:90%;">353.5</span></td>
<td id="S6.T4.3.17.14.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.3.1" class="ltx_text" style="font-size:90%;">21389</span></td>
<td id="S6.T4.3.17.14.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.4.1" class="ltx_text" style="font-size:90%;">173.8</span></td>
<td id="S6.T4.3.17.14.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.5.1" class="ltx_text" style="font-size:90%;">4.066</span></td>
<td id="S6.T4.3.17.14.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.17.14.6.1" class="ltx_text" style="font-size:90%;">21924</span></td>
</tr>
<tr id="S6.T4.3.18.15" class="ltx_tr">
<th id="S6.T4.3.18.15.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.18.15.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 1</span></th>
<td id="S6.T4.3.18.15.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.3.1" class="ltx_text" style="font-size:90%;">127.5</span></td>
<td id="S6.T4.3.18.15.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.4.1" class="ltx_text" style="font-size:90%;">4245.7</span></td>
<td id="S6.T4.3.18.15.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.5.1" class="ltx_text" style="font-size:90%;">95.58</span></td>
<td id="S6.T4.3.18.15.6" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.6.1" class="ltx_text" style="font-size:90%;">0.375</span></td>
<td id="S6.T4.3.18.15.7" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.18.15.7.1" class="ltx_text" style="font-size:90%;">4469.5</span></td>
</tr>
<tr id="S6.T4.3.19.16" class="ltx_tr">
<th id="S6.T4.3.19.16.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.19.16.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 2</span></th>
<td id="S6.T4.3.19.16.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.3.1" class="ltx_text" style="font-size:90%;">77.22</span></td>
<td id="S6.T4.3.19.16.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.4.1" class="ltx_text" style="font-size:90%;">2900.6</span></td>
<td id="S6.T4.3.19.16.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.5.1" class="ltx_text" style="font-size:90%;">24.82</span></td>
<td id="S6.T4.3.19.16.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.6.1" class="ltx_text" style="font-size:90%;">0.207</span></td>
<td id="S6.T4.3.19.16.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.19.16.7.1" class="ltx_text" style="font-size:90%;">3003.1</span></td>
</tr>
<tr id="S6.T4.3.20.17" class="ltx_tr">
<th id="S6.T4.3.20.17.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.20.17.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 3</span></th>
<td id="S6.T4.3.20.17.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.3.1" class="ltx_text" style="font-size:90%;">79.18</span></td>
<td id="S6.T4.3.20.17.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.4.1" class="ltx_text" style="font-size:90%;">3703.1</span></td>
<td id="S6.T4.3.20.17.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.5.1" class="ltx_text" style="font-size:90%;">24.84</span></td>
<td id="S6.T4.3.20.17.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.6.1" class="ltx_text" style="font-size:90%;">0.223</span></td>
<td id="S6.T4.3.20.17.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.20.17.7.1" class="ltx_text" style="font-size:90%;">3807.6</span></td>
</tr>
<tr id="S6.T4.3.21.18" class="ltx_tr">
<th id="S6.T4.3.21.18.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.21.18.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 4</span></th>
<td id="S6.T4.3.21.18.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.3.1" class="ltx_text" style="font-size:90%;">27.05</span></td>
<td id="S6.T4.3.21.18.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.4.1" class="ltx_text" style="font-size:90%;">2987.9</span></td>
<td id="S6.T4.3.21.18.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.5.1" class="ltx_text" style="font-size:90%;">12.15</span></td>
<td id="S6.T4.3.21.18.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.6.1" class="ltx_text" style="font-size:90%;">0.235</span></td>
<td id="S6.T4.3.21.18.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.21.18.7.1" class="ltx_text" style="font-size:90%;">3027.6</span></td>
</tr>
<tr id="S6.T4.3.22.19" class="ltx_tr">
<th id="S6.T4.3.22.19.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.22.19.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 5</span></th>
<td id="S6.T4.3.22.19.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.3.1" class="ltx_text" style="font-size:90%;">21.47</span></td>
<td id="S6.T4.3.22.19.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.4.1" class="ltx_text" style="font-size:90%;">2404.4</span></td>
<td id="S6.T4.3.22.19.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.5.1" class="ltx_text" style="font-size:90%;">9.137</span></td>
<td id="S6.T4.3.22.19.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.6.1" class="ltx_text" style="font-size:90%;">0.347</span></td>
<td id="S6.T4.3.22.19.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.22.19.7.1" class="ltx_text" style="font-size:90%;">2435.7</span></td>
</tr>
<tr id="S6.T4.3.23.20" class="ltx_tr">
<th id="S6.T4.3.23.20.1" class="ltx_td ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.23.20.2" class="ltx_td ltx_align_right ltx_th ltx_th_row" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- layer 6</span></th>
<td id="S6.T4.3.23.20.3" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.3.1" class="ltx_text" style="font-size:90%;">10.95</span></td>
<td id="S6.T4.3.23.20.4" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.4.1" class="ltx_text" style="font-size:90%;">2671.0</span></td>
<td id="S6.T4.3.23.20.5" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.5.1" class="ltx_text" style="font-size:90%;">4.768</span></td>
<td id="S6.T4.3.23.20.6" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.6.1" class="ltx_text" style="font-size:90%;">0.571</span></td>
<td id="S6.T4.3.23.20.7" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.23.20.7.1" class="ltx_text" style="font-size:90%;">2687.9</span></td>
</tr>
<tr id="S6.T4.3.24.21" class="ltx_tr">
<th id="S6.T4.3.24.21.1" class="ltx_td ltx_th ltx_th_row ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"></th>
<th id="S6.T4.3.24.21.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">- clf.</span></th>
<td id="S6.T4.3.24.21.3" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.3.1" class="ltx_text" style="font-size:90%;">10.11</span></td>
<td id="S6.T4.3.24.21.4" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.4.1" class="ltx_text" style="font-size:90%;">2476.4</span></td>
<td id="S6.T4.3.24.21.5" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.5.1" class="ltx_text" style="font-size:90%;">2.478</span></td>
<td id="S6.T4.3.24.21.6" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.6.1" class="ltx_text" style="font-size:90%;">2.108</span></td>
<td id="S6.T4.3.24.21.7" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S6.T4.3.24.21.7.1" class="ltx_text" style="font-size:90%;">2493.2</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S6.T4.6.3" class="ltx_p ltx_figure_panel ltx_align_left"><sup id="S6.T4.6.3.3" class="ltx_sup"><span id="S6.T4.6.3.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">α</span></sup><span id="S6.T4.6.3.2" class="ltx_text" style="font-size:80%;">B.cast: Broadcast;
<sup id="S6.T4.6.3.2.1" class="ltx_sup"><span id="S6.T4.6.3.2.1.1" class="ltx_text ltx_font_italic">δ</span></sup>Aggr.: Aggregation;
<sup id="S6.T4.6.3.2.2" class="ltx_sup"><span id="S6.T4.6.3.2.2.1" class="ltx_text ltx_font_italic">ϵ</span></sup>clf.: Classifier.</span></p>
</div>
</div>
</figure>
<div id="S6.SS2.p7" class="ltx_para ltx_noindent">
<p id="S6.SS2.p7.1" class="ltx_p"><span id="S6.SS2.p7.1.1" class="ltx_text ltx_font_bold">Communication Duration of FL Phases.</span>
In the next experiment, we investigate the wall-clock time needed for running PPFL’s phases in one communication round: broadcast of the layer from server to clients, training of the layer at the client device, upload the layer to the server, aggregate all updates from clients and apply <math id="S6.SS2.p7.1.m1.1" class="ltx_Math" alttext="FedAvg" display="inline"><semantics id="S6.SS2.p7.1.m1.1a"><mrow id="S6.SS2.p7.1.m1.1.1" xref="S6.SS2.p7.1.m1.1.1.cmml"><mi id="S6.SS2.p7.1.m1.1.1.2" xref="S6.SS2.p7.1.m1.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p7.1.m1.1.1.1" xref="S6.SS2.p7.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p7.1.m1.1.1.3" xref="S6.SS2.p7.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p7.1.m1.1.1.1a" xref="S6.SS2.p7.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p7.1.m1.1.1.4" xref="S6.SS2.p7.1.m1.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p7.1.m1.1.1.1b" xref="S6.SS2.p7.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p7.1.m1.1.1.5" xref="S6.SS2.p7.1.m1.1.1.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p7.1.m1.1.1.1c" xref="S6.SS2.p7.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p7.1.m1.1.1.6" xref="S6.SS2.p7.1.m1.1.1.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S6.SS2.p7.1.m1.1.1.1d" xref="S6.SS2.p7.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS2.p7.1.m1.1.1.7" xref="S6.SS2.p7.1.m1.1.1.7.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p7.1.m1.1b"><apply id="S6.SS2.p7.1.m1.1.1.cmml" xref="S6.SS2.p7.1.m1.1.1"><times id="S6.SS2.p7.1.m1.1.1.1.cmml" xref="S6.SS2.p7.1.m1.1.1.1"></times><ci id="S6.SS2.p7.1.m1.1.1.2.cmml" xref="S6.SS2.p7.1.m1.1.1.2">𝐹</ci><ci id="S6.SS2.p7.1.m1.1.1.3.cmml" xref="S6.SS2.p7.1.m1.1.1.3">𝑒</ci><ci id="S6.SS2.p7.1.m1.1.1.4.cmml" xref="S6.SS2.p7.1.m1.1.1.4">𝑑</ci><ci id="S6.SS2.p7.1.m1.1.1.5.cmml" xref="S6.SS2.p7.1.m1.1.1.5">𝐴</ci><ci id="S6.SS2.p7.1.m1.1.1.6.cmml" xref="S6.SS2.p7.1.m1.1.1.6">𝑣</ci><ci id="S6.SS2.p7.1.m1.1.1.7.cmml" xref="S6.SS2.p7.1.m1.1.1.7">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p7.1.m1.1c">FedAvg</annotation></semantics></math>.
Depending on each layer’s size and TEE memory size, batch size can start from 1 and go as high as the TEE allows.
However, since our models are uneven in layer sizes (with VGG9 being the largest), we set the batch size to 1 to allow comparison, and also capture an upper bound on the possible duration of each phase in each model training.
Indeed, we confirmed that increasing batch size for small models that allow it (e.g., AlexNet with batch size=16), incrementally reduces the duration of phases.</p>
</div>
<div id="S6.SS2.p8" class="ltx_para">
<p id="S6.SS2.p8.1" class="ltx_p">Table <a href="#S6.T4" title="Table 4 ‣ 6.2. What is the PPFL Communication Cost? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the break-down of time taken for each phase, for three models and two datasets (LeNet on MNIST; AlexNet and VGG9 on CIFAR10) and IID data.
As expected, layer-wise FL increases the total time compared to end-to-end FL because each layer is trained separately, but the previously trained and finalized layers still need to be processed in the forward pass.
In fact, these results are in line with the complexity analysis shown earlier in Sec. <a href="#S4.SS2" title="4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, i.e., to finish the training of all layers, layer-wise training introduces a <math id="S6.SS2.p8.1.m1.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S6.SS2.p8.1.m1.1a"><mrow id="S6.SS2.p8.1.m1.1b"><mn id="S6.SS2.p8.1.m1.1.1">3</mn><mo lspace="0.222em" id="S6.SS2.p8.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.SS2.p8.1.m1.1c">3\times</annotation></semantics></math> or higher delay, similar to the number of layers.
On the one hand, we argue that applications can tolerate this additional delay if they are to be protected from privacy-related attacks, despite the execution time increase being non-negligible and up to a few hours of training.
Indeed, models can be (re)trained on longer timescales (e.g., weekly, monthly), and rounds can have a duration of 10s of minutes, while being executed in an asynchronous manner.
On the other hand, training one layer in PPFL costs similar time to the end-to-end FL training of the complete model.
This highlights that the minimum client contribution time is the same as end-to-end FL: clients can choose to participate in portions of an FL round, and in just a few FL rounds.
For example, a client may contribute to the model training for only a few layers in any given FL round.</p>
</div>
<div id="S6.SS2.p9" class="ltx_para">
<p id="S6.SS2.p9.1" class="ltx_p">Among all FL phases, local training costs the most, while the time spent in server aggregation and averaging is trivial, regardless if it is non-secure (i.e., end-to-end FL) or secure (PPFL).
Regarding VGG9, layer-wise training of early layers significantly increases the communication time in broadcast and upload, because the Conv layers are with a small number of filters and consequently the following classifier’s FC layer has a large size.
This finding hints that selecting suitable DNNs to be trained in PPFL (e.g., AlexNet vs. VGG9) is crucial for practical performance.
Moreover, and according to the earlier FL performance results (also see Table <a href="#S6.F2" title="Figure 2 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), it may not be necessary to train all layers to reach the desired ML utility.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Is the PPFL ML Performance Comparable to State-of-art FL?</h3>

<figure id="S6.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x4.png" id="S6.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="200" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x5.png" id="S6.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="200" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F2.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x6.png" id="S6.F2.3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="200" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F2.6.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S6.F2.7.2" class="ltx_text" style="font-size:90%;">Test accuracy of training LeNet, AlexNet, and VGG9 models on IID and Non-IID datasets when using PPFL. Horizontal dashed lines refer to the accuracy that the centralized training reaches after every 50 epochs.
Note: end-to-end (E2E) FL trains the complete model rather than each layer, and the ‘Layer No.’ at x-axis are <em id="S6.F2.7.2.1" class="ltx_emph ltx_font_italic">only</em> applicable to PPFL.</span></figcaption>
</figure>
<figure id="S6.F3" class="ltx_figure"><img src="/html/2104.14380/assets/x7.png" id="S6.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="922" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.7.3.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S6.F3.4.2" class="ltx_text" style="font-size:90%;">System performance of the client devices when training LeNet, AlexNet, and VGG9 using PPFL, measured on <em id="S6.F3.4.2.1" class="ltx_emph ltx_font_italic">one step of training</em> (i.e., one batch of data).
The light grey bar ( <svg id="S6.F3.3.1.pic1" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#CCCCCC" stroke="#CCCCCC" stroke-width="0.4pt" color="#CCCCCC"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>) refers to learning without TEEs, and the black bar ( <svg id="S6.F3.4.2.pic2" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>) refers to overhead when the layer under training is inside the TEE. Percentage (%) of the overhead (averaged on one model) is shown above these bars. Horizontal dashed lines signify the cost of end-to-end FL.
In x-axis, ‘c’ refers to ‘classifier’.</span></figcaption>
</figure>
<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In these experiments, we reduce the number of communication rounds that each layer in PPFL is trained to 50, finish the training process per layer, and compare its performance with centralized layer-wise training, as well as regular end-to-end FL.
The latter trains the full model for all rounds up to that point.
For example, if PPFL trains the first layer for 50 rounds, and then the second layer for 50 rounds, the end-to-end FL will train all the model (end-to-end) for 100 rounds.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">As shown in Figure <a href="#S6.F2" title="Figure 2 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, training LeNet on the “easy” task of MNIST data (IID or not) leads quickly to high ML performance, regardless of the FL system used.
Training AlexNet on IID and Non-IID CIFAR10 data can lead to test accuracy of 74% and 60.78%, respectively, while centralized training reaches 83.34%.
Training VGG9, which is a more complex model on IID and Non-IID CIFAR10 data leads to lower performances of 74.60% and 38.35%, respectively, while centralized training reaches 85.09%.
We note the drop of performance in PPFL when every new layer is considered into training.
This is to be expected, since PPFL starts from scratch with the new layer, leading to a significant performance drop in the first FL rounds.
Of course, towards the end of the 50 rounds, PPFL performance matches and in some cases surpasses that of end-to-end FL.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">In general, with more layers being included in the training, the test accuracy increases.
Interestingly, in more complex models (e.g., VGG9) with Non-IID data, PPFL can lead to a drop in ML performance when the number of layers keeps increasing.
In fact, in these experiments, it only reaches <math id="S6.SS3.p3.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.SS3.p3.1.m1.1a"><mo id="S6.SS3.p3.1.m1.1.1" xref="S6.SS3.p3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.1.m1.1b"><csymbol cd="latexml" id="S6.SS3.p3.1.m1.1.1.cmml" xref="S6.SS3.p3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.1.m1.1c">\sim</annotation></semantics></math>55% after finishing the second layer and drops.
One possible reason for this degradation is that the first layers of VGG9 are small and maybe not capable of capturing heterogeneous features among Non-IID data, which consequently has a negative influence on the training of latter layers.
On the other hand, this reminds us that we can have early exits for greedy layer-wise PPFL on Non-IID data.
For example, clients that do not have enough data, or already have high test accuracy after training the first layers can quit before participating in further communication rounds.
Overall, the layer-wise training outperforms end-to-end FL during the training of the first or second layer.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">We further discuss possible reasons for PPFL’s better ML performance compared to end-to-end FL.
On the one hand, this could be due to some DNN architectures (e.g., VGG9) being more suitable for layer-wise FL.
For example, training each layer separately may allow PPFL to overcome possible local optima at which the backward propagation can “get stuck” in end-to-end FL.
On the other hand, hyper-parameter tuning may help improve performance in both layer-wise and end-to-end FL, always with the risk of overfitting the data.
Indeed, achieving the best ML performance possible was not our focus, and more in-depth studying is needed in the future, to understand under what setups layer-wise can perform better than end-to-end FL.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>What is the PPFL Client-Side System Cost?</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.3" class="ltx_p">We further investigate the system performance and costs on the client devices with respect to CPU execution time, memory usage, and energy consumption.
Figure <a href="#S6.F3" title="Figure 3 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results for all three metrics, when training LeNet on MNIST, AlexNet and VGG9 on CIFAR10, on IID data.
The metrics are computed for one step of training (i.e., one batch of data).
More training steps require analogously more CPU time and energy, but do not influence memory usage since the memory allocated for the model is reused for all subsequent steps.
Here, we compare PPFL with layer-wise training without TEEs, to measure the overhead of using the TEE.
Among the trained models, the maximum overhead is <math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="14.6\%" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mrow id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml"><mn id="S6.SS4.p1.1.m1.1.1.2" xref="S6.SS4.p1.1.m1.1.1.2.cmml">14.6</mn><mo id="S6.SS4.p1.1.m1.1.1.1" xref="S6.SS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><apply id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.SS4.p1.1.m1.1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS4.p1.1.m1.1.1.2.cmml" xref="S6.SS4.p1.1.m1.1.1.2">14.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">14.6\%</annotation></semantics></math> for CPU time, <math id="S6.SS4.p1.2.m2.1" class="ltx_Math" alttext="18.31\%" display="inline"><semantics id="S6.SS4.p1.2.m2.1a"><mrow id="S6.SS4.p1.2.m2.1.1" xref="S6.SS4.p1.2.m2.1.1.cmml"><mn id="S6.SS4.p1.2.m2.1.1.2" xref="S6.SS4.p1.2.m2.1.1.2.cmml">18.31</mn><mo id="S6.SS4.p1.2.m2.1.1.1" xref="S6.SS4.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.2.m2.1b"><apply id="S6.SS4.p1.2.m2.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.SS4.p1.2.m2.1.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.SS4.p1.2.m2.1.1.2.cmml" xref="S6.SS4.p1.2.m2.1.1.2">18.31</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.2.m2.1c">18.31\%</annotation></semantics></math> for memory usage, and <math id="S6.SS4.p1.3.m3.1" class="ltx_Math" alttext="21.19\%" display="inline"><semantics id="S6.SS4.p1.3.m3.1a"><mrow id="S6.SS4.p1.3.m3.1.1" xref="S6.SS4.p1.3.m3.1.1.cmml"><mn id="S6.SS4.p1.3.m3.1.1.2" xref="S6.SS4.p1.3.m3.1.1.2.cmml">21.19</mn><mo id="S6.SS4.p1.3.m3.1.1.1" xref="S6.SS4.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.3.m3.1b"><apply id="S6.SS4.p1.3.m3.1.1.cmml" xref="S6.SS4.p1.3.m3.1.1"><csymbol cd="latexml" id="S6.SS4.p1.3.m3.1.1.1.cmml" xref="S6.SS4.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S6.SS4.p1.3.m3.1.1.2.cmml" xref="S6.SS4.p1.3.m3.1.1.2">21.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.3.m3.1c">21.19\%</annotation></semantics></math> for energy consumption.
In addition, when training each layer, PPFL has comparable results with end-to-end training (i.e., horizontal dashed lines in Figure <a href="#S6.F3" title="Figure 3 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5. </span>What is the PPFL ML and System Costs if Blocks of Layers were Trained in Clients?</h3>

<figure id="S6.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x8.png" id="S6.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="200" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x9.png" id="S6.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="200" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.4.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S6.F4.5.2" class="ltx_text" style="font-size:90%;">Test accuracy of training AlexNet and VGG9 models on CIFAR10 (IID and Non-IID) when using PPFL with blocks of two layers in TEE (Note: horizontal dashed lines refer to the accuracy that the end-to-end (E2E) FL reaches after 50 communication rounds).</span></figcaption>
</figure>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2104.14380/assets/x10.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F5.6.3.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S6.F5.4.2" class="ltx_text" style="font-size:90%;">System performance of the client devices when training AlexNet and VGG9 models on CIFAR10 when using PPFL with blocks of two layers in TEE (same settings as in Figure <a href="#S6.F4" title="Figure 4 ‣ 6.5. What is the PPFL ML and System Costs if Blocks of Layers were Trained in Clients? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), measured on one step of training.
The light grey bar ( <svg id="S6.F5.3.1.pic1" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#CCCCCC" stroke="#CCCCCC" stroke-width="0.4pt" color="#CCCCCC"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>) refers to learning without TEEs, and the black bar ( <svg id="S6.F5.4.2.pic2" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>) refers to overhead when the block’s layers under training are inside the TEE.
Percentage (%) of the overhead is shown above these bars.
Horizontal dashed lines refer to the cost of end-to-end FL.
‘c’ refers to ‘classifier’.</span></figcaption>
</figure>
<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">As explained in Algorithm <a href="#algorithm1" title="In 4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> of Sec. <a href="#S4.SS2" title="4.2. Layer-wise Training and Aggregation ‣ 4. PPFL Framework ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, if the TEEs can hold more than one layers, it is also possible to put a block of layers inside the TEE for training.
Indeed, heterogeneous devices and TEEs can have different memory sizes, thus supporting a wide range of block sizes.
For these experiments, we assume all devices have the same TEE size and construct 2-layer blocks, and measure the system’s test accuracy and ML performance on CIFAR10.
The performance of three or more layers inside TEEs could be measured in a similar fashion (if the TEE’s memory can fit them).
We do not test LeNet on MNIST because it can easily reach high accuracy (around 99%) as shown earlier and in previous studies <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib43" title="" class="ltx_ref">mcmahan2017communication, </a>; <a href="#bib.bib72" title="" class="ltx_ref">wang2020federated, </a>)</cite>.</p>
</div>
<div id="S6.SS5.p2" class="ltx_para">
<p id="S6.SS5.p2.1" class="ltx_p">Results in Figure <a href="#S6.F4" title="Figure 4 ‣ 6.5. What is the PPFL ML and System Costs if Blocks of Layers were Trained in Clients? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> indicate that training blocks of layers can reach similar or even better ML performance compared to training each layer separately (i.e., see Fig. <a href="#S6.F2" title="Figure 2 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
It can also improve the test accuracy of complex models such as VGG9, for which we noted a degradation of ML performance caused by the first layer’s small size and incapacity to model the data (see Fig. <a href="#S6.F2" title="Figure 2 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
In addition, compared to training one layer at a time, training 2-layer blocks reduces the total required communication to reach the desired ML performance.
In fact, while aiming to reach same baseline accuracy as in Table <a href="#S6.T3" title="Table 3 ‣ 6.2. What is the PPFL Communication Cost? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, training 2-layer blocks requires half or less of communication cost than 1-layer blocks see Table <a href="#S6.T5" title="Table 5 ‣ 6.5. What is the PPFL ML and System Costs if Blocks of Layers were Trained in Clients? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Also, layer-wise training outperforms end-to-end FL for similar reasons as outlined for Figure <a href="#S6.F2" title="Figure 2 ‣ 6.3. Is the PPFL ML Performance Comparable to State-of-art FL? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5. </span>Reduction of communication rounds and amount when training 2-layer instead of 1-layer blocks.</figcaption>
<table id="S6.T5.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T5.8.9.1" class="ltx_tr">
<th id="S6.T5.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T5.8.9.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T5.8.9.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T5.8.9.1.2.1" class="ltx_text" style="font-size:90%;">Data</span></th>
<th id="S6.T5.8.9.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S6.T5.8.9.1.3.1" class="ltx_text" style="font-size:90%;">Comm. Rounds</span></th>
<th id="S6.T5.8.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T5.8.9.1.4.1" class="ltx_text" style="font-size:90%;">Comm. Amount</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T5.2.2" class="ltx_tr">
<td id="S6.T5.2.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T5.2.2.3.1" class="ltx_text" style="font-size:90%;">AlexNet</span></td>
<td id="S6.T5.2.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T5.2.2.4.1" class="ltx_text" style="font-size:90%;">IID</span></td>
<td id="S6.T5.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S6.T5.1.1.1.m1.1" class="ltx_math_unparsed" alttext="0.65\times\xrightarrow{}0.18\times" display="inline"><semantics id="S6.T5.1.1.1.m1.1a"><mrow id="S6.T5.1.1.1.m1.1b"><mn mathsize="90%" id="S6.T5.1.1.1.m1.1.1">0.65</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.1.1.1.m1.1.2">×</mo><mover accent="true" id="S6.T5.1.1.1.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.1.1.1.m1.1.3.2">→</mo><mi id="S6.T5.1.1.1.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.1.1.1.m1.1.4">0.18</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.1.1.1.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.1.1.1.m1.1c">0.65\times\xrightarrow{}0.18\times</annotation></semantics></math></td>
<td id="S6.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T5.2.2.2.m1.1" class="ltx_math_unparsed" alttext="0.63\times\xrightarrow{}0.27\times" display="inline"><semantics id="S6.T5.2.2.2.m1.1a"><mrow id="S6.T5.2.2.2.m1.1b"><mn mathsize="90%" id="S6.T5.2.2.2.m1.1.1">0.63</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.2.2.2.m1.1.2">×</mo><mover accent="true" id="S6.T5.2.2.2.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.2.2.2.m1.1.3.2">→</mo><mi id="S6.T5.2.2.2.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.2.2.2.m1.1.4">0.27</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.2.2.2.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.2.2.2.m1.1c">0.63\times\xrightarrow{}0.27\times</annotation></semantics></math></td>
</tr>
<tr id="S6.T5.4.4" class="ltx_tr">
<td id="S6.T5.4.4.3" class="ltx_td"></td>
<td id="S6.T5.4.4.4" class="ltx_td ltx_align_left"><span id="S6.T5.4.4.4.1" class="ltx_text" style="font-size:90%;">Non-IID</span></td>
<td id="S6.T5.3.3.1" class="ltx_td ltx_align_left"><math id="S6.T5.3.3.1.m1.1" class="ltx_math_unparsed" alttext="0.53\times\xrightarrow{}0.29\times" display="inline"><semantics id="S6.T5.3.3.1.m1.1a"><mrow id="S6.T5.3.3.1.m1.1b"><mn mathsize="90%" id="S6.T5.3.3.1.m1.1.1">0.53</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.3.3.1.m1.1.2">×</mo><mover accent="true" id="S6.T5.3.3.1.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.3.3.1.m1.1.3.2">→</mo><mi id="S6.T5.3.3.1.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.3.3.1.m1.1.4">0.29</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.3.3.1.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.3.3.1.m1.1c">0.53\times\xrightarrow{}0.29\times</annotation></semantics></math></td>
<td id="S6.T5.4.4.2" class="ltx_td ltx_align_center"><math id="S6.T5.4.4.2.m1.1" class="ltx_math_unparsed" alttext="0.53\times\xrightarrow{}0.44\times" display="inline"><semantics id="S6.T5.4.4.2.m1.1a"><mrow id="S6.T5.4.4.2.m1.1b"><mn mathsize="90%" id="S6.T5.4.4.2.m1.1.1">0.53</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.4.4.2.m1.1.2">×</mo><mover accent="true" id="S6.T5.4.4.2.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.4.4.2.m1.1.3.2">→</mo><mi id="S6.T5.4.4.2.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.4.4.2.m1.1.4">0.44</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.4.4.2.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.4.4.2.m1.1c">0.53\times\xrightarrow{}0.44\times</annotation></semantics></math></td>
</tr>
<tr id="S6.T5.6.6" class="ltx_tr">
<td id="S6.T5.6.6.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T5.6.6.3.1" class="ltx_text" style="font-size:90%;">VGG9</span></td>
<td id="S6.T5.6.6.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T5.6.6.4.1" class="ltx_text" style="font-size:90%;">IID</span></td>
<td id="S6.T5.5.5.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S6.T5.5.5.1.m1.1" class="ltx_math_unparsed" alttext="1.14\times\xrightarrow{}0.43\times" display="inline"><semantics id="S6.T5.5.5.1.m1.1a"><mrow id="S6.T5.5.5.1.m1.1b"><mn mathsize="90%" id="S6.T5.5.5.1.m1.1.1">1.14</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.5.5.1.m1.1.2">×</mo><mover accent="true" id="S6.T5.5.5.1.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.5.5.1.m1.1.3.2">→</mo><mi id="S6.T5.5.5.1.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.5.5.1.m1.1.4">0.43</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.5.5.1.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.5.5.1.m1.1c">1.14\times\xrightarrow{}0.43\times</annotation></semantics></math></td>
<td id="S6.T5.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T5.6.6.2.m1.1" class="ltx_math_unparsed" alttext="2.87\times\xrightarrow{}1.07\times" display="inline"><semantics id="S6.T5.6.6.2.m1.1a"><mrow id="S6.T5.6.6.2.m1.1b"><mn mathsize="90%" id="S6.T5.6.6.2.m1.1.1">2.87</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.6.6.2.m1.1.2">×</mo><mover accent="true" id="S6.T5.6.6.2.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.6.6.2.m1.1.3.2">→</mo><mi id="S6.T5.6.6.2.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.6.6.2.m1.1.4">1.07</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.6.6.2.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.6.6.2.m1.1c">2.87\times\xrightarrow{}1.07\times</annotation></semantics></math></td>
</tr>
<tr id="S6.T5.8.8" class="ltx_tr">
<td id="S6.T5.8.8.3" class="ltx_td ltx_border_b"></td>
<td id="S6.T5.8.8.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S6.T5.8.8.4.1" class="ltx_text" style="font-size:90%;">Non-IID</span></td>
<td id="S6.T5.7.7.1" class="ltx_td ltx_align_left ltx_border_b"><math id="S6.T5.7.7.1.m1.1" class="ltx_math_unparsed" alttext="0.24\times\xrightarrow{}0.11\times" display="inline"><semantics id="S6.T5.7.7.1.m1.1a"><mrow id="S6.T5.7.7.1.m1.1b"><mn mathsize="90%" id="S6.T5.7.7.1.m1.1.1">0.24</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.7.7.1.m1.1.2">×</mo><mover accent="true" id="S6.T5.7.7.1.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.7.7.1.m1.1.3.2">→</mo><mi id="S6.T5.7.7.1.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.7.7.1.m1.1.4">0.11</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.7.7.1.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.7.7.1.m1.1c">0.24\times\xrightarrow{}0.11\times</annotation></semantics></math></td>
<td id="S6.T5.8.8.2" class="ltx_td ltx_align_center ltx_border_b"><math id="S6.T5.8.8.2.m1.1" class="ltx_math_unparsed" alttext="0.60\times\xrightarrow{}0.27\times" display="inline"><semantics id="S6.T5.8.8.2.m1.1a"><mrow id="S6.T5.8.8.2.m1.1b"><mn mathsize="90%" id="S6.T5.8.8.2.m1.1.1">0.60</mn><mo lspace="0.222em" mathsize="90%" rspace="0em" id="S6.T5.8.8.2.m1.1.2">×</mo><mover accent="true" id="S6.T5.8.8.2.m1.1.3"><mo lspace="0em" mathsize="90%" stretchy="false" id="S6.T5.8.8.2.m1.1.3.2">→</mo><mi id="S6.T5.8.8.2.m1.1.3.1"></mi></mover><mn mathsize="90%" id="S6.T5.8.8.2.m1.1.4">0.27</mn><mo lspace="0.222em" mathsize="90%" id="S6.T5.8.8.2.m1.1.5">×</mo></mrow><annotation encoding="application/x-tex" id="S6.T5.8.8.2.m1.1c">0.60\times\xrightarrow{}0.27\times</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS5.p3" class="ltx_para">
<p id="S6.SS5.p3.1" class="ltx_p">Regarding the system cost, results across models show that the maximum overhead is 13.24% in CPU time, 32.71% in memory usage, and 14.47% in energy consumption (see Fig. <a href="#S6.F5" title="Figure 5 ‣ 6.5. What is the PPFL ML and System Costs if Blocks of Layers were Trained in Clients? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).
Compared to training one layer at a time, training layer blocks does not always increase the overhead.
For example, overhead when running VGG9 drops from 13.22% to 8.46% in CPU, from 2.44% to 3.17% in memory usage, and from 21.19% to 14.47% in energy consumption.
One explanation is that combining layers into blocks amortizes the cost of “expensive” with “cheap” layers.
Interestingly, PPFL still has a comparable cost with end-to-end FL training.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6. </span>Can Bootstrapping the PPFL with Public Knowledge Help?</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">We investigate how the backend server of PPFL can use existing, public models to bootstrap the training process for a given task.
For this purpose, we leverage two models (MobileNetv2 and VGG16) pre-trained on ImageNet to the classification task on CIFAR10.
Because these pre-trained models contain sufficient knowledge relevant to the target task, training the last few layers is already adequate for a good ML performance.
Consequently, we can freeze all Conv layers and train the last FC layers within TEEs, thus protecting them as well.
By default, MobileNetv2 has one FC layer, and VGG16 has three FC layers at the end.
We test both cases that one and three FC layers are attached and re-trained for these two models, respectively.
CIFAR10 is resized to <math id="S6.SS6.p1.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S6.SS6.p1.1.m1.1a"><mrow id="S6.SS6.p1.1.m1.1.1" xref="S6.SS6.p1.1.m1.1.1.cmml"><mn id="S6.SS6.p1.1.m1.1.1.2" xref="S6.SS6.p1.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS6.p1.1.m1.1.1.1" xref="S6.SS6.p1.1.m1.1.1.1.cmml">×</mo><mn id="S6.SS6.p1.1.m1.1.1.3" xref="S6.SS6.p1.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS6.p1.1.m1.1b"><apply id="S6.SS6.p1.1.m1.1.1.cmml" xref="S6.SS6.p1.1.m1.1.1"><times id="S6.SS6.p1.1.m1.1.1.1.cmml" xref="S6.SS6.p1.1.m1.1.1.1"></times><cn type="integer" id="S6.SS6.p1.1.m1.1.1.2.cmml" xref="S6.SS6.p1.1.m1.1.1.2">224</cn><cn type="integer" id="S6.SS6.p1.1.m1.1.1.3.cmml" xref="S6.SS6.p1.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS6.p1.1.m1.1c">224\times 224</annotation></semantics></math> in order to fit with the input size of these pre-trained models.
We start with a smaller learning rate of 0.001 to avoid divergence and a momentum of 0.9 because the feature extractors are well-trained.</p>
</div>
<div id="S6.SS6.p2" class="ltx_para ltx_noindent">
<p id="S6.SS6.p2.1" class="ltx_p"><span id="S6.SS6.p2.1.1" class="ltx_text ltx_font_bold">Test Accuracy.</span>
Figure <a href="#S6.F6" title="Figure 6 ‣ 6.6. Can Bootstrapping the PPFL with Public Knowledge Help? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows that the use of pre-trained first layers (i.e., feature extractors) to bootstrap the learning process can help the final PPFL models reach test accuracy similar to centralized training.
Interestingly, transferring pre-trained layers from VGG16 can reach higher test accuracy than MobileNetv2.
This is expected because VGG16 contains many more DNN parameters than MobileNetv2, which provides better feature extraction capabilities.
Surprisingly, attaching and training more FC layers at the end of any of the models does not improve test accuracy.
This can be due to the bottleneck of the transferred feature extractors, which since they are frozen, they do not allow the model to <em id="S6.SS6.p2.1.2" class="ltx_emph ltx_font_italic">fully</em> capture the variability of the new data.</p>
</div>
<div id="S6.SS6.p3" class="ltx_para ltx_noindent">
<p id="S6.SS6.p3.1" class="ltx_p"><span id="S6.SS6.p3.1.1" class="ltx_text ltx_font_bold">Client-side System Cost.</span>
In order to measure client-side cost under this setting, we need to do some experimental adjustments.
The VGG16 (even the last FC layers) is too large to fit in TEEs.
Thus, we reduce the batch size to 1 and proportionally scale down all layers (e.g., from 4096 to 1024 neurons for one FC layer).
Indeed, scaling layers may lead to biases in results, but the actual performance cannot be worse than this estimation.
As shown in <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib49" title="" class="ltx_ref">mo2020darknetz, </a>)</cite>, larger models have less overhead because the last layers are relatively smaller compared to the complete size of the model.</p>
</div>
<div id="S6.SS6.p4" class="ltx_para">
<p id="S6.SS6.p4.1" class="ltx_p">Interestingly, results shown in Figure <a href="#S6.F7" title="Figure 7 ‣ 6.6. Can Bootstrapping the PPFL with Public Knowledge Help? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> indicate that when we train and keep the last FC layers inside the client’s on-device TEEs, there is only a small overhead incurred in terms of CPU time (6.9%), memory usage (1.3%), and energy consumption (5.5%) in either model.
These results highlight that transferring knowledge can be a good alternative for bootstrapping PPFL training and keep system overhead low.
In addition, we note that when the server does not have suitable public models, it is possible to first train a model on public datasets that have similar distribution with local datasets.
We refer to Appendix <a href="#A1.SS1" title="A.1. Transferring Public Datasets ‣ Appendix A Appendix ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> for more details on experimental results.</p>
</div>
<figure id="S6.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x11.png" id="S6.F6.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="405" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Transfer from MobileNetv2</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x12.png" id="S6.F6.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="405" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Transfer from VGG16</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S6.F6.3.2" class="ltx_text" style="font-size:90%;">Test accuracy of training on CIFAR10 (IID and Non-IID) with public models MobileNetv2 and VGG16, pre-trained on ImageNet).
Both models are trained and tested with 1 and 3 FC layers attached at the end of each model.</span></figcaption>
</figure>
<figure id="S6.F7" class="ltx_figure"><img src="/html/2104.14380/assets/x13.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="210" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F7.6.3.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="S6.F7.4.2" class="ltx_text" style="font-size:90%;">System performance of client devices when training with transferred public models on CIFAR10, measured on 1 step of training. Light grey bar ( <svg id="S6.F7.3.1.pic1" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#CCCCCC" stroke="#CCCCCC" stroke-width="0.4pt" color="#CCCCCC"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>): learning without TEEs; Black bar ( <svg id="S6.F7.4.2.pic2" class="ltx_picture" height="9.45" overflow="visible" version="1.1" width="9.45"><g transform="translate(0,9.45) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 0 M 0 0 L 0 9.45 L 9.45 9.45 L 9.45 0 Z M 9.45 9.45" style="stroke:none"></path></g></svg>): overhead when layers under training are in TEE. Percentage (%) of overhead shown above bars. MN1: MobileNetv2 with one layer for training (i.e., ‘1 layer’ in Figure <a href="#S6.F6.sf1" title="In Figure 6 ‣ 6.6. Can Bootstrapping the PPFL with Public Knowledge Help? ‣ 6. Evaluation Results ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>). VGGs: a small size of VGG16.</span></figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Discussion &amp; Future Work</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p"><span id="S7.p1.1.1" class="ltx_text ltx_font_bold">Key Findings.</span>
PPFL’s experimental evaluation showed that:</p>
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">Protecting the training process (i.e., gradient updates) inside TEEs, and exposing layers only after convergence can thwart data reconstruction and property inference attacks. Also, keeping a model’s last layer inside TEEs mitigates membership inference attacks.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.2" class="ltx_p">Greedy layer-wise FL can achieve comparable ML utility with end-to-end FL. While layer-wise FL increases the total of communication rounds needed to finish all layers, it can reach the same test accuracy as end-to-end FL with fewer rounds (<math id="S7.I1.i2.p1.1.m1.1" class="ltx_math_unparsed" alttext="0.538\times" display="inline"><semantics id="S7.I1.i2.p1.1.m1.1a"><mrow id="S7.I1.i2.p1.1.m1.1b"><mn id="S7.I1.i2.p1.1.m1.1.1">0.538</mn><mo lspace="0.222em" id="S7.I1.i2.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S7.I1.i2.p1.1.m1.1c">0.538\times</annotation></semantics></math>) and amount of communication (<math id="S7.I1.i2.p1.2.m2.1" class="ltx_math_unparsed" alttext="1.002\times" display="inline"><semantics id="S7.I1.i2.p1.2.m2.1a"><mrow id="S7.I1.i2.p1.2.m2.1b"><mn id="S7.I1.i2.p1.2.m2.1.1">1.002</mn><mo lspace="0.222em" id="S7.I1.i2.p1.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S7.I1.i2.p1.2.m2.1c">1.002\times</annotation></semantics></math>).</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p id="S7.I1.i3.p1.3" class="ltx_p">Most PPFL system cost comes from clients’ local training: up to <math id="S7.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S7.I1.i3.p1.1.m1.1a"><mo id="S7.I1.i3.p1.1.m1.1.1" xref="S7.I1.i3.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S7.I1.i3.p1.1.m1.1b"><csymbol cd="latexml" id="S7.I1.i3.p1.1.m1.1.1.cmml" xref="S7.I1.i3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i3.p1.1.m1.1c">\sim</annotation></semantics></math>15% CPU time, <math id="S7.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S7.I1.i3.p1.2.m2.1a"><mo id="S7.I1.i3.p1.2.m2.1.1" xref="S7.I1.i3.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S7.I1.i3.p1.2.m2.1b"><csymbol cd="latexml" id="S7.I1.i3.p1.2.m2.1.1.cmml" xref="S7.I1.i3.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i3.p1.2.m2.1c">\sim</annotation></semantics></math>18% memory usage, and <math id="S7.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S7.I1.i3.p1.3.m3.1a"><mo id="S7.I1.i3.p1.3.m3.1.1" xref="S7.I1.i3.p1.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S7.I1.i3.p1.3.m3.1b"><csymbol cd="latexml" id="S7.I1.i3.p1.3.m3.1.1.cmml" xref="S7.I1.i3.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i3.p1.3.m3.1c">\sim</annotation></semantics></math>21% energy consumption in client cost when training different models and data, compared to training without TEEs.</p>
</div>
</li>
<li id="S7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i4.p1" class="ltx_para">
<p id="S7.I1.i4.p1.1" class="ltx_p">Training 2-layer blocks decreases communication cost by at least half, and slightly increases system overhead (i.e., CPU time, memory usage, energy consumption) in cases of small models.</p>
</div>
</li>
<li id="S7.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i5.p1" class="ltx_para">
<p id="S7.I1.i5.p1.1" class="ltx_p">Bootstrapping PPFL training process with pre-trained models can significantly increase ML utility, and reduce overall cost in communications and system overhead.</p>
</div>
</li>
</ul>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p"><span id="S7.p2.1.1" class="ltx_text ltx_font_bold">Dishonest Attacks.</span>
The attacks tested here assume the classic ‘honest-but-curious’ adversary <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib57" title="" class="ltx_ref">paverd2014modelling, </a>)</cite>.
In FL, however, there are also dishonest attacks such as backdoor <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib67" title="" class="ltx_ref">sun2019can, </a>; <a href="#bib.bib4" title="" class="ltx_ref">bagdasaryan2020backdoor, </a>)</cite> or poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib15" title="" class="ltx_ref">fang2020local, </a>)</cite>, whose goal is to actively change the global model behavior, e.g., for surreptitious unauthorized access to the global model <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib26" title="" class="ltx_ref">jere2020taxonomy, </a>)</cite>.
In the future, we will investigate how TEEs’ security properties can defend against such attacks.</p>
</div>
<div id="S7.p3" class="ltx_para ltx_noindent">
<p id="S7.p3.1" class="ltx_p"><span id="S7.p3.1.1" class="ltx_text ltx_font_bold">Privacy and Cost Trade-off.</span>
PPFL guarantees ‘full’ privacy by keeping layers inside TEEs.
However, executing computations in secure environments inevitably leads to system costs.
To reduce such costs, one can relax their privacy requirements, potentially increasing privacy risks due inference attacks with higher “advantage” <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib76" title="" class="ltx_ref">zhao2020privacy-utility, </a>)</cite>.
For example, clients who do not care about high-level information leakages (i.e., learned model parameters), but want to protect the original local data, can choose to hide only the first layers of the model in TEEs.
We expect that by dropping clients already achieving good performance when training latter layers, we could gain better performance.
This may further benefit personalization and achieve better privacy, utility, and cost trade-offs.</p>
</div>
<div id="S7.p4" class="ltx_para ltx_noindent">
<p id="S7.p4.1" class="ltx_p"><span id="S7.p4.1.1" class="ltx_text ltx_font_bold">Model Architectures.</span>
The models tested in our layer-wise FL are linear links cross consecutive layers. However, our framework can be easily extended to other model architectures that have been studied in standard layer-wise training.
For example, one can perform layer-wise training on (i) Graph Neural Networks by disentangling feature aggregation and feature transformation <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib74" title="" class="ltx_ref">you2020l2, </a>)</cite>, and (ii) Long Short-Term Memory networks (LSTMs), by adding hidden layers <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib60" title="" class="ltx_ref">sagheer2019unsupervised, </a>)</cite>.
There are other architectures that contain skipping connections to jump over some layers such as ResNet <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib19" title="" class="ltx_ref">he2016deep, </a>)</cite>.
No layer-wise training has been investigated for ResNets, but training a block of layers could be attempted by including the jumping shortcut inside a block.</p>
</div>
<div id="S7.p5" class="ltx_para ltx_noindent">
<p id="S7.p5.1" class="ltx_p"><span id="S7.p5.1.1" class="ltx_text ltx_font_bold">Accelerating Local Training.</span>
PPFL uses only the CPU of client devices for local training. Training each layer does not introduce parallel processing on a device.
Indeed, more effective ways to perform this compute load can be devised. One way is that clients could use specialized processors (i.e., GPUs) to accelerate training.
PPFL’s design can integrate such advances mainly in two ways.
First, the client can outsource the first, well-trained, but non-sensitive layers, to specialized processors that can share computation and speed-up local training.
Second, recently proposed GPU-based TEEs can support intensive deep learning-like computation in high-end servers <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib22" title="" class="ltx_ref">hunt2020telekine, </a>; <a href="#bib.bib24" title="" class="ltx_ref">jang2019heterogeneous, </a>)</cite>.
Thus, such TEEs on client devices can greatly speed-up local training.
However, as GPU-TEE still requires small TCB to restrict attack surface, PPFL’s design can provide a way to leverage limited TEE space for privacy-preserving local training.</p>
</div>
<div id="S7.p6" class="ltx_para ltx_noindent">
<p id="S7.p6.6" class="ltx_p"><span id="S7.p6.6.1" class="ltx_text ltx_font_bold">Federated Learning Paradigms.</span>
PPFL was tested with <math id="S7.p6.1.m1.1" class="ltx_Math" alttext="FedAvg" display="inline"><semantics id="S7.p6.1.m1.1a"><mrow id="S7.p6.1.m1.1.1" xref="S7.p6.1.m1.1.1.cmml"><mi id="S7.p6.1.m1.1.1.2" xref="S7.p6.1.m1.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.1.m1.1.1.1" xref="S7.p6.1.m1.1.1.1.cmml">​</mo><mi id="S7.p6.1.m1.1.1.3" xref="S7.p6.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.1.m1.1.1.1a" xref="S7.p6.1.m1.1.1.1.cmml">​</mo><mi id="S7.p6.1.m1.1.1.4" xref="S7.p6.1.m1.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.1.m1.1.1.1b" xref="S7.p6.1.m1.1.1.1.cmml">​</mo><mi id="S7.p6.1.m1.1.1.5" xref="S7.p6.1.m1.1.1.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S7.p6.1.m1.1.1.1c" xref="S7.p6.1.m1.1.1.1.cmml">​</mo><mi id="S7.p6.1.m1.1.1.6" xref="S7.p6.1.m1.1.1.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S7.p6.1.m1.1.1.1d" xref="S7.p6.1.m1.1.1.1.cmml">​</mo><mi id="S7.p6.1.m1.1.1.7" xref="S7.p6.1.m1.1.1.7.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.1.m1.1b"><apply id="S7.p6.1.m1.1.1.cmml" xref="S7.p6.1.m1.1.1"><times id="S7.p6.1.m1.1.1.1.cmml" xref="S7.p6.1.m1.1.1.1"></times><ci id="S7.p6.1.m1.1.1.2.cmml" xref="S7.p6.1.m1.1.1.2">𝐹</ci><ci id="S7.p6.1.m1.1.1.3.cmml" xref="S7.p6.1.m1.1.1.3">𝑒</ci><ci id="S7.p6.1.m1.1.1.4.cmml" xref="S7.p6.1.m1.1.1.4">𝑑</ci><ci id="S7.p6.1.m1.1.1.5.cmml" xref="S7.p6.1.m1.1.1.5">𝐴</ci><ci id="S7.p6.1.m1.1.1.6.cmml" xref="S7.p6.1.m1.1.1.6">𝑣</ci><ci id="S7.p6.1.m1.1.1.7.cmml" xref="S7.p6.1.m1.1.1.7">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.1.m1.1c">FedAvg</annotation></semantics></math>, but there are other state-of-art FL paradigms that are compatible with PPFL.
PPFL leverages greedy layer-wise learning but does not modify the hyper-parameter determination and loss function (which have been improved in <math id="S7.p6.2.m2.1" class="ltx_Math" alttext="FedProx" display="inline"><semantics id="S7.p6.2.m2.1a"><mrow id="S7.p6.2.m2.1.1" xref="S7.p6.2.m2.1.1.cmml"><mi id="S7.p6.2.m2.1.1.2" xref="S7.p6.2.m2.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.3" xref="S7.p6.2.m2.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1a" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.4" xref="S7.p6.2.m2.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1b" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.5" xref="S7.p6.2.m2.1.1.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1c" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.6" xref="S7.p6.2.m2.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1d" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.7" xref="S7.p6.2.m2.1.1.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.p6.2.m2.1.1.1e" xref="S7.p6.2.m2.1.1.1.cmml">​</mo><mi id="S7.p6.2.m2.1.1.8" xref="S7.p6.2.m2.1.1.8.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.2.m2.1b"><apply id="S7.p6.2.m2.1.1.cmml" xref="S7.p6.2.m2.1.1"><times id="S7.p6.2.m2.1.1.1.cmml" xref="S7.p6.2.m2.1.1.1"></times><ci id="S7.p6.2.m2.1.1.2.cmml" xref="S7.p6.2.m2.1.1.2">𝐹</ci><ci id="S7.p6.2.m2.1.1.3.cmml" xref="S7.p6.2.m2.1.1.3">𝑒</ci><ci id="S7.p6.2.m2.1.1.4.cmml" xref="S7.p6.2.m2.1.1.4">𝑑</ci><ci id="S7.p6.2.m2.1.1.5.cmml" xref="S7.p6.2.m2.1.1.5">𝑃</ci><ci id="S7.p6.2.m2.1.1.6.cmml" xref="S7.p6.2.m2.1.1.6">𝑟</ci><ci id="S7.p6.2.m2.1.1.7.cmml" xref="S7.p6.2.m2.1.1.7">𝑜</ci><ci id="S7.p6.2.m2.1.1.8.cmml" xref="S7.p6.2.m2.1.1.8">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.2.m2.1c">FedProx</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib39" title="" class="ltx_ref">li2018federated, </a>)</cite>) or aggregation (which is neuron matching-based in <math id="S7.p6.3.m3.1" class="ltx_Math" alttext="FedMA" display="inline"><semantics id="S7.p6.3.m3.1a"><mrow id="S7.p6.3.m3.1.1" xref="S7.p6.3.m3.1.1.cmml"><mi id="S7.p6.3.m3.1.1.2" xref="S7.p6.3.m3.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.3.m3.1.1.1" xref="S7.p6.3.m3.1.1.1.cmml">​</mo><mi id="S7.p6.3.m3.1.1.3" xref="S7.p6.3.m3.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.3.m3.1.1.1a" xref="S7.p6.3.m3.1.1.1.cmml">​</mo><mi id="S7.p6.3.m3.1.1.4" xref="S7.p6.3.m3.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.3.m3.1.1.1b" xref="S7.p6.3.m3.1.1.1.cmml">​</mo><mi id="S7.p6.3.m3.1.1.5" xref="S7.p6.3.m3.1.1.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.p6.3.m3.1.1.1c" xref="S7.p6.3.m3.1.1.1.cmml">​</mo><mi id="S7.p6.3.m3.1.1.6" xref="S7.p6.3.m3.1.1.6.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.3.m3.1b"><apply id="S7.p6.3.m3.1.1.cmml" xref="S7.p6.3.m3.1.1"><times id="S7.p6.3.m3.1.1.1.cmml" xref="S7.p6.3.m3.1.1.1"></times><ci id="S7.p6.3.m3.1.1.2.cmml" xref="S7.p6.3.m3.1.1.2">𝐹</ci><ci id="S7.p6.3.m3.1.1.3.cmml" xref="S7.p6.3.m3.1.1.3">𝑒</ci><ci id="S7.p6.3.m3.1.1.4.cmml" xref="S7.p6.3.m3.1.1.4">𝑑</ci><ci id="S7.p6.3.m3.1.1.5.cmml" xref="S7.p6.3.m3.1.1.5">𝑀</ci><ci id="S7.p6.3.m3.1.1.6.cmml" xref="S7.p6.3.m3.1.1.6">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.3.m3.1c">FedMA</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib72" title="" class="ltx_ref">wang2020federated, </a>)</cite>).
Compared with PPFL that trains one layer until convergence, <math id="S7.p6.4.m4.1" class="ltx_Math" alttext="FedMA" display="inline"><semantics id="S7.p6.4.m4.1a"><mrow id="S7.p6.4.m4.1.1" xref="S7.p6.4.m4.1.1.cmml"><mi id="S7.p6.4.m4.1.1.2" xref="S7.p6.4.m4.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.4.m4.1.1.1" xref="S7.p6.4.m4.1.1.1.cmml">​</mo><mi id="S7.p6.4.m4.1.1.3" xref="S7.p6.4.m4.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.4.m4.1.1.1a" xref="S7.p6.4.m4.1.1.1.cmml">​</mo><mi id="S7.p6.4.m4.1.1.4" xref="S7.p6.4.m4.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.4.m4.1.1.1b" xref="S7.p6.4.m4.1.1.1.cmml">​</mo><mi id="S7.p6.4.m4.1.1.5" xref="S7.p6.4.m4.1.1.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.p6.4.m4.1.1.1c" xref="S7.p6.4.m4.1.1.1.cmml">​</mo><mi id="S7.p6.4.m4.1.1.6" xref="S7.p6.4.m4.1.1.6.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.4.m4.1b"><apply id="S7.p6.4.m4.1.1.cmml" xref="S7.p6.4.m4.1.1"><times id="S7.p6.4.m4.1.1.1.cmml" xref="S7.p6.4.m4.1.1.1"></times><ci id="S7.p6.4.m4.1.1.2.cmml" xref="S7.p6.4.m4.1.1.2">𝐹</ci><ci id="S7.p6.4.m4.1.1.3.cmml" xref="S7.p6.4.m4.1.1.3">𝑒</ci><ci id="S7.p6.4.m4.1.1.4.cmml" xref="S7.p6.4.m4.1.1.4">𝑑</ci><ci id="S7.p6.4.m4.1.1.5.cmml" xref="S7.p6.4.m4.1.1.5">𝑀</ci><ci id="S7.p6.4.m4.1.1.6.cmml" xref="S7.p6.4.m4.1.1.6">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.4.m4.1c">FedMA</annotation></semantics></math>, which also uses layer-wise learning, trains each layer for one round, and then moves to the next layer.
After finishing all layers, it starts again from the first.
Thus, <math id="S7.p6.5.m5.1" class="ltx_Math" alttext="FedMA" display="inline"><semantics id="S7.p6.5.m5.1a"><mrow id="S7.p6.5.m5.1.1" xref="S7.p6.5.m5.1.1.cmml"><mi id="S7.p6.5.m5.1.1.2" xref="S7.p6.5.m5.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.5.m5.1.1.1" xref="S7.p6.5.m5.1.1.1.cmml">​</mo><mi id="S7.p6.5.m5.1.1.3" xref="S7.p6.5.m5.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.5.m5.1.1.1a" xref="S7.p6.5.m5.1.1.1.cmml">​</mo><mi id="S7.p6.5.m5.1.1.4" xref="S7.p6.5.m5.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.5.m5.1.1.1b" xref="S7.p6.5.m5.1.1.1.cmml">​</mo><mi id="S7.p6.5.m5.1.1.5" xref="S7.p6.5.m5.1.1.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.p6.5.m5.1.1.1c" xref="S7.p6.5.m5.1.1.1.cmml">​</mo><mi id="S7.p6.5.m5.1.1.6" xref="S7.p6.5.m5.1.1.6.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.5.m5.1b"><apply id="S7.p6.5.m5.1.1.cmml" xref="S7.p6.5.m5.1.1"><times id="S7.p6.5.m5.1.1.1.cmml" xref="S7.p6.5.m5.1.1.1"></times><ci id="S7.p6.5.m5.1.1.2.cmml" xref="S7.p6.5.m5.1.1.2">𝐹</ci><ci id="S7.p6.5.m5.1.1.3.cmml" xref="S7.p6.5.m5.1.1.3">𝑒</ci><ci id="S7.p6.5.m5.1.1.4.cmml" xref="S7.p6.5.m5.1.1.4">𝑑</ci><ci id="S7.p6.5.m5.1.1.5.cmml" xref="S7.p6.5.m5.1.1.5">𝑀</ci><ci id="S7.p6.5.m5.1.1.6.cmml" xref="S7.p6.5.m5.1.1.6">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.5.m5.1c">FedMA</annotation></semantics></math> is still vulnerable because gradients of one layer are accessible to adversaries.
PPFL could leverage <math id="S7.p6.6.m6.1" class="ltx_Math" alttext="FedMA" display="inline"><semantics id="S7.p6.6.m6.1a"><mrow id="S7.p6.6.m6.1.1" xref="S7.p6.6.m6.1.1.cmml"><mi id="S7.p6.6.m6.1.1.2" xref="S7.p6.6.m6.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.p6.6.m6.1.1.1" xref="S7.p6.6.m6.1.1.1.cmml">​</mo><mi id="S7.p6.6.m6.1.1.3" xref="S7.p6.6.m6.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.p6.6.m6.1.1.1a" xref="S7.p6.6.m6.1.1.1.cmml">​</mo><mi id="S7.p6.6.m6.1.1.4" xref="S7.p6.6.m6.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.p6.6.m6.1.1.1b" xref="S7.p6.6.m6.1.1.1.cmml">​</mo><mi id="S7.p6.6.m6.1.1.5" xref="S7.p6.6.m6.1.1.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.p6.6.m6.1.1.1c" xref="S7.p6.6.m6.1.1.1.cmml">​</mo><mi id="S7.p6.6.m6.1.1.6" xref="S7.p6.6.m6.1.1.6.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.p6.6.m6.1b"><apply id="S7.p6.6.m6.1.1.cmml" xref="S7.p6.6.m6.1.1"><times id="S7.p6.6.m6.1.1.1.cmml" xref="S7.p6.6.m6.1.1.1"></times><ci id="S7.p6.6.m6.1.1.2.cmml" xref="S7.p6.6.m6.1.1.2">𝐹</ci><ci id="S7.p6.6.m6.1.1.3.cmml" xref="S7.p6.6.m6.1.1.3">𝑒</ci><ci id="S7.p6.6.m6.1.1.4.cmml" xref="S7.p6.6.m6.1.1.4">𝑑</ci><ci id="S7.p6.6.m6.1.1.5.cmml" xref="S7.p6.6.m6.1.1.5">𝑀</ci><ci id="S7.p6.6.m6.1.1.6.cmml" xref="S7.p6.6.m6.1.1.6">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p6.6.m6.1c">FedMA</annotation></semantics></math>’s neuron-matching technique when dealing with heterogeneous (i.e., Non-IID) data <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib28" title="" class="ltx_ref">polifl, </a>)</cite>.
Besides, our framework is compatible with other privacy-preserving techniques (e.g., differential privacy) in FL.
This is useful during the model usage phase where some users may not have TEEs.
PPFL can also be useful to systems such as FLaaS <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib31" title="" class="ltx_ref">kourtellis2020flaas, </a>)</cite> that enable third-party applications to build collaborative ML models on the device shared by said applications.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this work, we proposed PPFL, a practical, privacy-preserving federated learning framework, which protects clients’ private information against known privacy-related attacks.
PPFL adopts greedy layer-wise FL training and updates layers always inside Trusted Execution Environments (TEEs) at both server and clients.
We implemented PPFL with mobile-like TEE (i.e., TrustZone) and server-like TEE (i.e., Intel SGX) and empirically tested its performance.
For the first time, we showed the possibility of fully guaranteeing privacy and achieving comparable ML model utility with regular end-to-end FL, without significant communication and system overhead.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Acknowledgments</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">We acknowledge the constructive feedback from the anonymous reviewers.
The research leading to these results received partial funding from the EU H2020 Research and Innovation programme under grant agreements No 830927 (Concordia), No 871793 (Accordion), No 871370 (Pimcity), and EPSRC Databox and DADA grants (EP/N028260/1, EP/R03351X/1).
These results reflect only the authors’ view and the Commission and EPSRC are not responsible for any use that may be made of the information it contains.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
<span id="bib.bib1.1.1" class="ltx_text ltx_font_smallcaps">Amacher, J., and Schiavoni, V.</span>

</span>
<span class="ltx_bibblock">On the performance of arm trustzone.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.2.1" class="ltx_text ltx_font_italic">IFIP International Conference on Distributed Applications and
Interoperable Systems</span> (2019), Springer, pp. 133–151.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
<span id="bib.bib2.1.1" class="ltx_text ltx_font_smallcaps">Aono, Y., Hayashi, T., Wang, L., Moriai, S., et al.</span>

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning via additively homomorphic
encryption.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security 13</span>, 5
(2017), 1333–1345.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
<span id="bib.bib3.1.1" class="ltx_text ltx_font_smallcaps">Bagdasaryan, E., Poursaeed, O., and Shmatikov, V.</span>

</span>
<span class="ltx_bibblock">Differential privacy has disparate impact on model accuracy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.2.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span> (2019),
pp. 15479–15488.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
<span id="bib.bib4.1.1" class="ltx_text ltx_font_smallcaps">Bagdasaryan, E., Veit, A., Hua, Y., Estrin, D., and Shmatikov, V.</span>

</span>
<span class="ltx_bibblock">How to backdoor federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.2.1" class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</span> (2020), PMLR, pp. 2938–2948.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
<span id="bib.bib5.1.1" class="ltx_text ltx_font_smallcaps">Belilovsky, E., Eickenberg, M., and Oyallon, E.</span>

</span>
<span class="ltx_bibblock">Greedy layerwise learning can scale to imagenet.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.2.1" class="ltx_text ltx_font_italic">International conference on machine learning</span> (2019), PMLR,
pp. 583–593.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
<span id="bib.bib6.1.1" class="ltx_text ltx_font_smallcaps">Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H.</span>

</span>
<span class="ltx_bibblock">Greedy layer-wise training of deep networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems 19</span> (2006),
153–160.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
<span id="bib.bib7.1.1" class="ltx_text ltx_font_smallcaps">Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov,
V., Kiddon, C., Konečnỳ, J., Mazzocchi, S., McMahan, H. B., et al.</span>

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.2.1" class="ltx_text ltx_font_italic">Conference on Machine Learning and Systems</span> (2019).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
<span id="bib.bib8.1.1" class="ltx_text ltx_font_smallcaps">Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H. B.,
Patel, S., Ramage, D., Segal, A., and Seth, K.</span>

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.2.1" class="ltx_text ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security</span> (2017), pp. 1175–1191.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
<span id="bib.bib9.1.1" class="ltx_text ltx_font_smallcaps">Brownlee, J.</span>

</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text ltx_font_italic">A Gentle Introduction to Transfer Learning for Deep Learning</span>,
2019 (accessed November 11, 2020).

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
<span id="bib.bib10.1.1" class="ltx_text ltx_font_smallcaps">Chen, H., Fu, C., Rouhani, B. D., Zhao, J., and Koushanfar, F.</span>

</span>
<span class="ltx_bibblock">Deepattest: An end-to-end attestation framework for deep neural
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.2.1" class="ltx_text ltx_font_italic">2019 ACM/IEEE 46th Annual International Symposium on Computer
Architecture (ISCA)</span> (2019), IEEE, pp. 487–498.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
<span id="bib.bib11.1.1" class="ltx_text ltx_font_smallcaps">Chen, J., Pan, X., Monga, R., Bengio, S., and Jozefowicz, R.</span>

</span>
<span class="ltx_bibblock">Revisiting distributed synchronous sgd.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.2.1" class="ltx_text ltx_font_italic">ICLR Workshop Track</span> (2016).

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
<span id="bib.bib12.1.1" class="ltx_text ltx_font_smallcaps">Chen, Z., Vasilakis, G., Murdock, K., Dean, E., Oswald, D., and Garcia,
F. D.</span>

</span>
<span class="ltx_bibblock">Voltpillager: Hardware-based fault injection attacks against intel
SGX enclaves using the SVID voltage scaling interface.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.2.1" class="ltx_text ltx_font_italic">30th USENIX Security Symposium</span> (Vancouver, B.C., Aug.
2021).

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
<span id="bib.bib13.1.1" class="ltx_text ltx_font_smallcaps">Costan, V., and Devadas, S.</span>

</span>
<span class="ltx_bibblock">Intel sgx explained.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text ltx_font_italic">IACR Cryptol. ePrint Arch. 2016</span>, 86 (2016), 1–118.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
<span id="bib.bib14.1.1" class="ltx_text ltx_font_smallcaps">Dwork, C., Roth, A., et al.</span>

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text ltx_font_italic">Foundations and Trends in Theoretical Computer Science 9</span>, 3-4
(2014), 211–407.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
<span id="bib.bib15.1.1" class="ltx_text ltx_font_smallcaps">Fang, M., Cao, X., Jia, J., and Gong, N.</span>

</span>
<span class="ltx_bibblock">Local model poisoning attacks to byzantine-robust federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.2.1" class="ltx_text ltx_font_italic">29th USENIX Security Symposium</span> (2020), pp. 1605–1622.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
<span id="bib.bib16.1.1" class="ltx_text ltx_font_smallcaps">Geiping, J., Bauermeister, H., Dröge, H., and Moeller, M.</span>

</span>
<span class="ltx_bibblock">Inverting gradients–how easy is it to break privacy in federated
learning?

</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.14053</span> (2020).

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
<span id="bib.bib17.1.1" class="ltx_text ltx_font_smallcaps">Geyer, R. C., Klein, T., and Nabi, M.</span>

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client level
perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1712.07557</span> (2017).

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
<span id="bib.bib18.1.1" class="ltx_text ltx_font_smallcaps">Gu, Z., Huang, H., Zhang, J., Su, D., Jamjoom, H., Lamba, A., Pendarakis,
D., and Molloy, I.</span>

</span>
<span class="ltx_bibblock">Yerbabuena: Securing deep learning inference data via enclave-based
ternary model partitioning.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1807.00969</span> (2018).

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
<span id="bib.bib19.1.1" class="ltx_text ltx_font_smallcaps">He, K., Zhang, X., Ren, S., and Sun, J.</span>

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.2.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span> (2016), pp. 770–778.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
<span id="bib.bib20.1.1" class="ltx_text ltx_font_smallcaps">Hitaj, B., Ateniese, G., and Perez-Cruz, F.</span>

</span>
<span class="ltx_bibblock">Deep models under the gan: information leakage from collaborative
deep learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.2.1" class="ltx_text ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security</span> (2017), pp. 603–618.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
<span id="bib.bib21.1.1" class="ltx_text ltx_font_smallcaps">Huang, T., Lin, W., Wu, W., He, L., Li, K., and Zomaya, A. Y.</span>

</span>
<span class="ltx_bibblock">An efficiency-boosting client selection scheme for federated learning
with fairness guarantee.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.01783</span> (2020).

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
<span id="bib.bib22.1.1" class="ltx_text ltx_font_smallcaps">Hunt, T., Jia, Z., Miller, V., Szekely, A., Hu, Y., Rossbach, C. J., and
Witchel, E.</span>

</span>
<span class="ltx_bibblock">Telekine: Secure computing with cloud gpus.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.2.1" class="ltx_text ltx_font_italic">17th USENIX Symposium on Networked Systems Design and
Implementation (NSDI’20)</span> (2020), pp. 817–833.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
<span id="bib.bib23.1.1" class="ltx_text ltx_font_smallcaps">Hunt, T., Song, C., Shokri, R., Shmatikov, V., and Witchel, E.</span>

</span>
<span class="ltx_bibblock">Chiron: Privacy-preserving machine learning as a service.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1803.05961</span> (2018).

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
<span id="bib.bib24.1.1" class="ltx_text ltx_font_smallcaps">Jang, I., Tang, A., Kim, T., Sethumadhavan, S., and Huh, J.</span>

</span>
<span class="ltx_bibblock">Heterogeneous isolated execution for commodity gpus.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.2.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Fourth International Conference on
Architectural Support for Programming Languages and Operating Systems</span>
(2019), pp. 455–468.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
<span id="bib.bib25.1.1" class="ltx_text ltx_font_smallcaps">Jayaraman, B., and Evans, D.</span>

</span>
<span class="ltx_bibblock">Evaluating differentially private machine learning in practice.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.2.1" class="ltx_text ltx_font_italic">28th USENIX Security Symposium (USENIX Security 19)</span>
(Santa Clara, CA, Aug. 2019), USENIX Association, pp. 1895–1912.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
<span id="bib.bib26.1.1" class="ltx_text ltx_font_smallcaps">Jere, M. S., Farnan, T., and Koushanfar, F.</span>

</span>
<span class="ltx_bibblock">A taxonomy of attacks on federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text ltx_font_italic">IEEE Security &amp; Privacy</span> (2020), 0–0.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(27)</span>
<span class="ltx_bibblock">
<span id="bib.bib27.1.1" class="ltx_text ltx_font_smallcaps">Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji,
A. N., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al.</span>

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.04977</span> (2019).

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(28)</span>
<span class="ltx_bibblock">
<span id="bib.bib28.1.1" class="ltx_text ltx_font_smallcaps">Katevas, K., Bagdasaryan, E., Waterman, J., Safadieh, M. M., Birrell, E.,
Haddadi, H., and Estrin, D.</span>

</span>
<span class="ltx_bibblock">Policy-based federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.06612</span> (2021).

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(29)</span>
<span class="ltx_bibblock">
<span id="bib.bib29.1.1" class="ltx_text ltx_font_smallcaps">Kaya, Y., Hong, S., and Dumitras, T.</span>

</span>
<span class="ltx_bibblock">Shallow-deep networks: Understanding and mitigating network
overthinking.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.2.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span> (2019), PMLR,
pp. 3301–3310.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(30)</span>
<span class="ltx_bibblock">
<span id="bib.bib30.1.1" class="ltx_text ltx_font_smallcaps">Knauth, T., Steiner, M., Chakrabarti, S., Lei, L., Xing, C., and Vij, M.</span>

</span>
<span class="ltx_bibblock">Integrating remote attestation with transport layer security.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1801.05863</span> (2018).

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(31)</span>
<span class="ltx_bibblock">
<span id="bib.bib31.1.1" class="ltx_text ltx_font_smallcaps">Kourtellis, N., Katevas, K., and Perino, D.</span>

</span>
<span class="ltx_bibblock">Flaas: Federated learning as a service.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.2.1" class="ltx_text ltx_font_italic">Workshop on Distributed ML</span> (2020), ACM CoNEXT.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(32)</span>
<span class="ltx_bibblock">
<span id="bib.bib32.1.1" class="ltx_text ltx_font_smallcaps">Krawczyk, H.</span>

</span>
<span class="ltx_bibblock">Sigma: The ‘sign-and-mac’approach to authenticated diffie-hellman
and its use in the ike protocols.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.2.1" class="ltx_text ltx_font_italic">Annual International Cryptology Conference</span> (2003),
Springer, pp. 400–425.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(33)</span>
<span class="ltx_bibblock">
<span id="bib.bib33.1.1" class="ltx_text ltx_font_smallcaps">Krizhevsky, A., Hinton, G., et al.</span>

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text ltx_font_italic">Citeseer</span> (2009).

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
<span id="bib.bib34.1.1" class="ltx_text ltx_font_smallcaps">Krizhevsky, A., Sutskever, I., and Hinton, G. E.</span>

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text ltx_font_italic">Communications of the ACM 60</span>, 6 (2017), 84–90.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(35)</span>
<span class="ltx_bibblock">
<span id="bib.bib35.1.1" class="ltx_text ltx_font_smallcaps">Larochelle, H., Bengio, Y., Louradour, J., and Lamblin, P.</span>

</span>
<span class="ltx_bibblock">Exploring strategies for training deep neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text ltx_font_italic">Journal of machine learning research 10</span>, 1 (2009).

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(36)</span>
<span class="ltx_bibblock">
<span id="bib.bib36.1.1" class="ltx_text ltx_font_smallcaps">LeCun, Y., Bengio, Y., and Hinton, G.</span>

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text ltx_font_italic">nature 521</span>, 7553 (2015), 436–444.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(37)</span>
<span class="ltx_bibblock">
<span id="bib.bib37.1.1" class="ltx_text ltx_font_smallcaps">LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.</span>

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE 86</span>, 11 (1998), 2278–2324.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
<span id="bib.bib38.1.1" class="ltx_text ltx_font_smallcaps">Lee, J., Jang, J., Jang, Y., Kwak, N., Choi, Y., Choi, C., Kim, T.,
Peinado, M., and Kang, B. B.</span>

</span>
<span class="ltx_bibblock">Hacking in Darkness: Return-Oriented Programming against Secure
Enclaves.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.2.1" class="ltx_text ltx_font_italic">Proceedings of the 26th USENIX Conference on Security
Symposium</span> (2017), pp. 523–539.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(39)</span>
<span class="ltx_bibblock">
<span id="bib.bib39.1.1" class="ltx_text ltx_font_smallcaps">Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith,
V.</span>

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.06127</span> (2018).

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(40)</span>
<span class="ltx_bibblock">
<span id="bib.bib40.1.1" class="ltx_text ltx_font_smallcaps">Linaro.org</span>.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text ltx_font_italic">Open Portable Trusted Execution Environment</span>, 2020 (accessed
September 3, 2020).

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(41)</span>
<span class="ltx_bibblock">
<span id="bib.bib41.1.1" class="ltx_text ltx_font_smallcaps">Lipp, M., Kogler, A., Oswald, D., Schwarz, M., Easdon, C., Canella, C.,
and Gruss, D.</span>

</span>
<span class="ltx_bibblock">PLATYPUS: Software-based Power Side-Channel Attacks on x86.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.2.1" class="ltx_text ltx_font_italic">2021 IEEE Symposium on Security and Privacy (SP)</span> (2021),
IEEE.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(42)</span>
<span class="ltx_bibblock">
<span id="bib.bib42.1.1" class="ltx_text ltx_font_smallcaps">Liu, Y., Kang, Y., Xing, C., Chen, T., and Yang, Q.</span>

</span>
<span class="ltx_bibblock">A secure federated transfer learning framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text ltx_font_italic">IEEE Intelligent Systems</span> (2020).

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(43)</span>
<span class="ltx_bibblock">
<span id="bib.bib43.1.1" class="ltx_text ltx_font_smallcaps">McMahan, B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B. A.</span>

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.2.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span> (2017), PMLR,
pp. 1273–1282.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
<span id="bib.bib44.1.1" class="ltx_text ltx_font_smallcaps">McMahan, H. B., Ramage, D., Talwar, K., and Zhang, L.</span>

</span>
<span class="ltx_bibblock">Learning differentially private recurrent language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.2.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>
(2018).

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(45)</span>
<span class="ltx_bibblock">
<span id="bib.bib45.1.1" class="ltx_text ltx_font_smallcaps">Melis, L., Song, C., De Cristofaro, E., and Shmatikov, V.</span>

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in collaborative learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.2.1" class="ltx_text ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</span> (2019),
IEEE, pp. 691–706.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(46)</span>
<span class="ltx_bibblock">
<span id="bib.bib46.1.1" class="ltx_text ltx_font_smallcaps">Microsoft</span>.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text ltx_font_italic">Open Enclave SDK</span>, 2020 (accessed Decemenber 4, 2020).

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(47)</span>
<span class="ltx_bibblock">
<span id="bib.bib47.1.1" class="ltx_text ltx_font_smallcaps">Mo, F., Borovykh, A., Malekzadeh, M., Haddadi, H., and Demetriou, S.</span>

</span>
<span class="ltx_bibblock">Layer-wise characterization of latent information leakage in
federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text ltx_font_italic">ICLR Distributed and Private Machine Learning workshop</span>
(2021).

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(48)</span>
<span class="ltx_bibblock">
<span id="bib.bib48.1.1" class="ltx_text ltx_font_smallcaps">Mo, F., and Haddadi, H.</span>

</span>
<span class="ltx_bibblock">Efficient and private federated learning using tee.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.2.1" class="ltx_text ltx_font_italic">EuroSys</span> (2019).

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(49)</span>
<span class="ltx_bibblock">
<span id="bib.bib49.1.1" class="ltx_text ltx_font_smallcaps">Mo, F., Shamsabadi, A. S., Katevas, K., Demetriou, S., Leontiadis, I.,
Cavallaro, A., and Haddadi, H.</span>

</span>
<span class="ltx_bibblock">Darknetz: towards model privacy at the edge using trusted execution
environments.

</span>
<span class="ltx_bibblock">In <span id="bib.bib49.2.1" class="ltx_text ltx_font_italic">Proceedings of the 18th International Conference on Mobile
Systems, Applications, and Services</span> (2020), pp. 161–174.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(50)</span>
<span class="ltx_bibblock">
<span id="bib.bib50.1.1" class="ltx_text ltx_font_smallcaps">Monsoon</span>.

</span>
<span class="ltx_bibblock">Monsoon solutions inc. home page.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.msoon.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.msoon.com/</a>, 2020 (accessed November 12, 2020).

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(51)</span>
<span class="ltx_bibblock">
<span id="bib.bib51.1.1" class="ltx_text ltx_font_smallcaps">Naehrig, M., Lauter, K., and Vaikuntanathan, V.</span>

</span>
<span class="ltx_bibblock">Can homomorphic encryption be practical?

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.2.1" class="ltx_text ltx_font_italic">Proceedings of the 3rd ACM workshop on Cloud computing
security workshop</span> (2011), pp. 113–124.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(52)</span>
<span class="ltx_bibblock">
<span id="bib.bib52.1.1" class="ltx_text ltx_font_smallcaps">Nasr, M., Shokri, R., and Houmansadr, A.</span>

</span>
<span class="ltx_bibblock">Comprehensive privacy analysis of deep learning: Passive and active
white-box inference attacks against centralized and federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.2.1" class="ltx_text ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</span> (2019),
IEEE, pp. 739–753.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(53)</span>
<span class="ltx_bibblock">
<span id="bib.bib53.1.1" class="ltx_text ltx_font_smallcaps">Nishio, T., and Yonetani, R.</span>

</span>
<span class="ltx_bibblock">Client selection for federated learning with heterogeneous resources
in mobile edge.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.2.1" class="ltx_text ltx_font_italic">IEEE International Conference on Communications (ICC)</span>
(2019), IEEE, pp. 1–7.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(54)</span>
<span class="ltx_bibblock">
<span id="bib.bib54.1.1" class="ltx_text ltx_font_smallcaps">Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani,
K., and Costa, M.</span>

</span>
<span class="ltx_bibblock">Oblivious multi-party machine learning on trusted processors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.2.1" class="ltx_text ltx_font_italic">25th USENIX Security Symposium</span> (2016), pp. 619–636.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(55)</span>
<span class="ltx_bibblock">
<span id="bib.bib55.1.1" class="ltx_text ltx_font_smallcaps">Paladi, N., Karlsson, L., and Elbashir, K.</span>

</span>
<span class="ltx_bibblock">Trust Anchors in Software Defined Networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.2.1" class="ltx_text ltx_font_italic">Computer Security</span> (2018), pp. 485–504.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(56)</span>
<span class="ltx_bibblock">
<span id="bib.bib56.1.1" class="ltx_text ltx_font_smallcaps">Pan, S. J., and Yang, Q.</span>

</span>
<span class="ltx_bibblock">A survey on transfer learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text ltx_font_italic">IEEE Transactions on knowledge and data engineering 22</span>, 10
(2009), 1345–1359.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(57)</span>
<span class="ltx_bibblock">
<span id="bib.bib57.1.1" class="ltx_text ltx_font_smallcaps">Paverd, A., Martin, A., and Brown, I.</span>

</span>
<span class="ltx_bibblock">Modelling and automatically analysing privacy properties for
honest-but-curious adversaries.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text ltx_font_italic">Tech. Rep.</span> (2014).

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(58)</span>
<span class="ltx_bibblock">
<span id="bib.bib58.1.1" class="ltx_text ltx_font_smallcaps">Redmon, J.</span>

</span>
<span class="ltx_bibblock">Darknet: Open source neural networks in c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://pjreddie.com/darknet/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://pjreddie.com/darknet/</a>, 2013–2016.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(59)</span>
<span class="ltx_bibblock">
<span id="bib.bib59.1.1" class="ltx_text ltx_font_smallcaps">Sablayrolles, A., Douze, M., Schmid, C., Ollivier, Y., and Jégou, H.</span>

</span>
<span class="ltx_bibblock">White-box vs black-box: Bayes optimal strategies for membership
inference.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.2.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span> (2019),
pp. 5558–5567.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(60)</span>
<span class="ltx_bibblock">
<span id="bib.bib60.1.1" class="ltx_text ltx_font_smallcaps">Sagheer, A., and Kotb, M.</span>

</span>
<span class="ltx_bibblock">Unsupervised pre-training of a deep lstm-based stacked autoencoder
for multivariate time series forecasting problems.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text ltx_font_italic">Scientific reports 9</span>, 1 (2019), 1–16.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(61)</span>
<span class="ltx_bibblock">
<span id="bib.bib61.1.1" class="ltx_text ltx_font_smallcaps">Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.</span>

</span>
<span class="ltx_bibblock">Mobilenetv2: Inverted residuals and linear bottlenecks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.2.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span> (2018), pp. 4510–4520.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(62)</span>
<span class="ltx_bibblock">
<span id="bib.bib62.1.1" class="ltx_text ltx_font_smallcaps">Schuster, F., Costa, M., Fournet, C., Gkantsidis, C., Peinado, M.,
Mainar-Ruiz, G., and Russinovich, M.</span>

</span>
<span class="ltx_bibblock">Vc3: Trustworthy data analytics in the cloud using sgx.

</span>
<span class="ltx_bibblock">In <span id="bib.bib62.2.1" class="ltx_text ltx_font_italic">2015 IEEE Symposium on Security and Privacy</span> (2015), IEEE,
pp. 38–54.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(63)</span>
<span class="ltx_bibblock">
Microsoft SEAL (release 3.5).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Microsoft/SEAL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Microsoft/SEAL</a>, Apr. 2020.

</span>
<span class="ltx_bibblock">Microsoft Research, Redmond, WA.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(64)</span>
<span class="ltx_bibblock">
<span id="bib.bib64.1.1" class="ltx_text ltx_font_smallcaps">Shokri, R., Stronati, M., Song, C., and Shmatikov, V.</span>

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib64.2.1" class="ltx_text ltx_font_italic">2017 IEEE Symposium on Security and Privacy (SP)</span> (2017),
IEEE, pp. 3–18.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(65)</span>
<span class="ltx_bibblock">
<span id="bib.bib65.1.1" class="ltx_text ltx_font_smallcaps">Simonyan, K., and Zisserman, A.</span>

</span>
<span class="ltx_bibblock">Very deep convolutional networks for large-scale image recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1556</span> (2014).

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(66)</span>
<span class="ltx_bibblock">
<span id="bib.bib66.1.1" class="ltx_text ltx_font_smallcaps">Subramani, P., Vadivelu, N., and Kamath, G.</span>

</span>
<span class="ltx_bibblock">Enabling fast differentially private sgd via just-in-time compilation
and vectorization.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.09063</span> (2020).

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(67)</span>
<span class="ltx_bibblock">
<span id="bib.bib67.1.1" class="ltx_text ltx_font_smallcaps">Sun, Z., Kairouz, P., Suresh, A. T., and McMahan, H. B.</span>

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?

</span>
<span class="ltx_bibblock"><span id="bib.bib67.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.07963</span> (2019).

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(68)</span>
<span class="ltx_bibblock">
<span id="bib.bib68.1.1" class="ltx_text ltx_font_smallcaps">Testuggine, D., and Mironov, I.</span>

</span>
<span class="ltx_bibblock"><span id="bib.bib68.2.1" class="ltx_text ltx_font_italic">Introducing Opacus: A high-speed library for training PyTorch
models with differential privacy</span>, 2020 (accessed January 1, 2021).

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(69)</span>
<span class="ltx_bibblock">
<span id="bib.bib69.1.1" class="ltx_text ltx_font_smallcaps">Torrey, L., and Shavlik, J.</span>

</span>
<span class="ltx_bibblock">Transfer learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib69.2.1" class="ltx_text ltx_font_italic">Handbook of research on machine learning applications and
trends: algorithms, methods, and techniques</span>. IGI global, 2010, pp. 242–264.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(70)</span>
<span class="ltx_bibblock">
<span id="bib.bib70.1.1" class="ltx_text ltx_font_smallcaps">Tramèr, F., and Boneh, D.</span>

</span>
<span class="ltx_bibblock">Slalom: Fast, verifiable and private execution of neural networks in
trusted hardware.

</span>
<span class="ltx_bibblock">In <span id="bib.bib70.2.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations
(ICLR)</span> (2019).

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(71)</span>
<span class="ltx_bibblock">
<span id="bib.bib71.1.1" class="ltx_text ltx_font_smallcaps">Van Bulck, Jo and Oswald, David and Marin, Eduard and Aldoseri, Abdulla
and Garcia, Flavio D. and Piessens, Frank</span>.

</span>
<span class="ltx_bibblock">A Tale of Two Worlds: Assessing the Vulnerability of Enclave
Shielding Runtimes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib71.2.1" class="ltx_text ltx_font_italic">Proceedings of the ACM SIGSAC Conference on Computer and
Communications Security (CCS)</span> (2019), pp. 1741–1758.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(72)</span>
<span class="ltx_bibblock">
<span id="bib.bib72.1.1" class="ltx_text ltx_font_smallcaps">Wang, H., Yurochkin, M., Sun, Y., Papailiopoulos, D., and Khazaeni, Y.</span>

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.2.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.06440</span> (2020).

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(73)</span>
<span class="ltx_bibblock">
<span id="bib.bib73.1.1" class="ltx_text ltx_font_smallcaps">Yeom, S., Giacomelli, I., Fredrikson, M., and Jha, S.</span>

</span>
<span class="ltx_bibblock">Privacy risk in machine learning: Analyzing the connection to
overfitting.

</span>
<span class="ltx_bibblock">In <span id="bib.bib73.2.1" class="ltx_text ltx_font_italic">2018 IEEE 31st Computer Security Foundations Symposium
(CSF)</span> (2018), IEEE, pp. 268–282.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(74)</span>
<span class="ltx_bibblock">
<span id="bib.bib74.1.1" class="ltx_text ltx_font_smallcaps">You, Y., Chen, T., Wang, Z., and Shen, Y.</span>

</span>
<span class="ltx_bibblock">L2-gcn: Layer-wise and learned efficient training of graph
convolutional networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib74.2.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span> (2020), pp. 2127–2135.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(75)</span>
<span class="ltx_bibblock">
<span id="bib.bib75.1.1" class="ltx_text ltx_font_smallcaps">Zhang, X., Li, F., Zhang, Z., Li, Q., Wang, C., and Wu, J.</span>

</span>
<span class="ltx_bibblock">Enabling execution assurance of federated learning at untrusted
participants.

</span>
<span class="ltx_bibblock">In <span id="bib.bib75.2.1" class="ltx_text ltx_font_italic">IEEE INFOCOM 2020-IEEE Conference on Computer
Communications</span> (2020), IEEE, pp. 1877–1886.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(76)</span>
<span class="ltx_bibblock">
<span id="bib.bib76.1.1" class="ltx_text ltx_font_smallcaps">Zhao, B. Z. H., Kaafar, M. A., and Kourtellis, N.</span>

</span>
<span class="ltx_bibblock">Not one but many tradeoffs: Privacy vs. utility in differentially
private machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.2.1" class="ltx_text ltx_font_italic">Cloud Computing Security Workshop</span> (2020), ACM CCS.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(77)</span>
<span class="ltx_bibblock">
<span id="bib.bib77.1.1" class="ltx_text ltx_font_smallcaps">Zhao, S., Zhang, Q., Qin, Y., Feng, W., and Feng, D.</span>

</span>
<span class="ltx_bibblock">Sectee: A software-based approach to secure enclave architecture
using tee.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.2.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security</span> (2019), pp. 1723–1740.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(78)</span>
<span class="ltx_bibblock">
<span id="bib.bib78.1.1" class="ltx_text ltx_font_smallcaps">Zhu, L., Liu, Z., and Han, S.</span>

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock">In <span id="bib.bib78.2.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span> (2019),
pp. 14774–14784.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1. </span>Transferring Public Datasets</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">The server can potentially gather data that have a similar distribution to clients’ private data.
In initialization, the server trains a global model based on the gathered data rather than using one existing model.
Then, the server broadcasts the trained model to clients’ devices.
Clients feed their private data into the model but update only the last layers inside the TEE during local training.
Also, only the last layers being trained are uploaded to the server for secure aggregation.
Because the server holds public data, we expect it to retrain the complete model before each communication round in order to keep fine-tuning the first layers.
Here, we fix the communication rounds to 20 and measure only the test accuracy.
We expect the system cost to be similar to transferring from models because, similarly, only the last layers are trained at the client-side.</p>
</div>
<figure id="A1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x14.png" id="A1.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="183" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A1.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">Transfer from public MNIST, to train LeNet.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.14380/assets/x15.png" id="A1.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="183" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A1.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">Transfer from public CIFAR10, to train VGG9.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.4.2.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="A1.F8.2.1" class="ltx_text" style="font-size:90%;">Test accuracy when learning with public datasets. The short red line ( <svg id="A1.F8.2.1.pic1" class="ltx_picture" height="1.11" overflow="visible" version="1.1" width="8.98"><g transform="translate(0,1.11) matrix(1 0 0 -1 0 0) translate(0.55,0) translate(0,-3.38)" fill="#CC0033" stroke="#CC0033" stroke-width="0.8pt" color="#CC0033"><path d="M 0 3.94 L 7.87 3.94" style="fill:none"></path></g></svg>) starting from y-axis refers to end-to-end FL. Each trail runs for 10 times, and error bars refer to 95% confidence interval (Note: In the top left figure, test accuracy is very high and almost the same, as the range of y-axis is set as the same for the same dataset (i.e., MNIST here). In the bottom right figure (i.e., for CIFAR10), several trails fail to train and thus corresponding points are not plotted).</span></figcaption>
</figure>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">Test accuracy results are shown in Figure <a href="#A1.F8" title="Figure 8 ‣ A.1. Transferring Public Datasets ‣ Appendix A Appendix ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
It is indicated that in general when the server holds more public data, the final global model can reach a higher test accuracy.
This is as expected since the server gathers a larger part of the training datasets.
With complete training datasets, this process will finally become centralized training.
Nevertheless, this indication is not always held.
For example, in the IID case (see the two left plots in Figure <a href="#A1.F8" title="Figure 8 ‣ A.1. Transferring Public Datasets ‣ Appendix A Appendix ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>), when training all layers, servers with public data of 0.1 fraction outperform servers without public data, i.e., the end-to-end FL, while regarding Non-IID of CIFAR10, servers with 0.1 fraction cannot outperform that without public data (see right plots in Figure <a href="#A1.F8.sf2" title="In Figure 8 ‣ A.1. Transferring Public Datasets ‣ Appendix A Appendix ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>).
One reason for it is that the first layers, which are trained on public datasets, cannot represent all features of privacy datasets.
We also observe that when the server does not have enough public data (e.g., 0.1 fraction), training only the last 1 or 2 layers can lead to extremely low performance or even failure.
Still, this is because the first layers cannot represent sufficiently the clients’ datasets.</p>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p id="A1.SS1.p3.1" class="ltx_p">Another observation is that the number of training last layers does not have a significant influence on test accuracy in terms of IID cases, especially when the server holds more public data.
This is because learning from IID public data is able to represent the feature space of the complete (private) training datasets.
However, the results change when it comes to the Non-IID case.
The number of training last layers has a significant influence on test accuracy.
For instance, regarding VGG9, training only the last 1 or 2 layers at the client-side performs much worse compared to training 3 or 4 layers (see right plots in Figure <a href="#A1.F8.sf2" title="In Figure 8 ‣ A.1. Transferring Public Datasets ‣ Appendix A Appendix ‣ PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>).
Moreover, training 3 or 4 layers tend to have better test accuracy than training more layers (e.g., all layers).
One explanation is that the feature extraction capability of first layers is good enough when the server has many public data, so fine-tuning these first layers at the client (e.g., training all layers) may destroy the model and consequently drop the accuracy.</p>
</div>
<div id="A1.SS1.p4" class="ltx_para">
<p id="A1.SS1.p4.1" class="ltx_p">Overall, by training only the last several layers at the client-side, PPFL with public datasets can guarantee privacy, and in the meanwhile, achieve better performance than that of training all layers.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.14379" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.14380" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.14380">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.14380" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.14381" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 06:23:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
