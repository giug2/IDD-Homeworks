<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.03202] ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction</title><meta property="og:description" content="We explore and improve the capabilities of LLMs to generate data for grammatical error correction (GEC). When merely producing parallel sentences, their patterns are too simplistic to be valuable as a corpus. To addres…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.03202">

<!--Generated on Fri Jul  5 22:00:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jeiyoon Park<sup id="id7.7.id1" class="ltx_sup"><span id="id7.7.id1.1" class="ltx_text ltx_font_italic">1</span></sup>,    Chanjun Park<sup id="id8.8.id2" class="ltx_sup"><span id="id8.8.id2.1" class="ltx_text ltx_font_italic">2†</span></sup>,     Heuiseok Lim<sup id="id9.9.id3" class="ltx_sup"><span id="id9.9.id3.1" class="ltx_text ltx_font_italic">3†</span></sup>

<br class="ltx_break"><sup id="id10.10.id4" class="ltx_sup"><span id="id10.10.id4.1" class="ltx_text ltx_font_italic">1</span></sup> Atommerce,   <sup id="id11.11.id5" class="ltx_sup"><span id="id11.11.id5.1" class="ltx_text ltx_font_italic">2</span></sup> Upstage AI,   <sup id="id12.12.id6" class="ltx_sup"><span id="id12.12.id6.1" class="ltx_text ltx_font_italic">3</span></sup> Korea University 
<br class="ltx_break"><span id="id13.13.id7" class="ltx_text ltx_font_typewriter">jypark1@atommerce.com</span> 
<br class="ltx_break"><span id="id14.14.id8" class="ltx_text ltx_font_typewriter">chanjun.park@upstage.ai</span> 
<br class="ltx_break"><span id="id15.15.id9" class="ltx_text ltx_font_typewriter">limhseok@korea.ac.kr</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup id="footnote1.1" class="ltx_sup">†</sup> Corresponding Author</span></span></span>
<p id="id16.id1" class="ltx_p">We explore and improve the capabilities of LLMs to generate data for grammatical error correction (GEC). When merely producing parallel sentences, their patterns are too simplistic to be valuable as a corpus. To address this issue, we propose an automated framework that includes a Subject Selector, Grammar Selector, Prompt Manager, and Evaluator. Additionally, we introduce a new dataset for GEC tasks, named <span id="id16.id1.1" class="ltx_text ltx_font_bold">ChatLang-8</span>, which encompasses eight types of subject nouns and 23 types of grammar. It consists of 1 million pairs featuring human-like grammatical errors. Our experiments reveal that ChatLang-8 exhibits a more uniform pattern composition compared to existing GEC datasets. Furthermore, we observe improved model performance when using ChatLang-8 instead of existing GEC datasets. The experimental results suggest that our framework and ChatLang-8 are valuable resources for enhancing ChatGPT’s data generation capabilities.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.6" class="ltx_block ltx_align_bottom">
<p id="p1.6.7" class="ltx_p"><span id="p1.6.7.1" class="ltx_text ltx_font_bold">ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.6.6" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.6.6.6" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.6.6.6.6" class="ltx_tabular ltx_align_top">
<span id="p1.3.3.3.3.3" class="ltx_tr">
<span id="p1.3.3.3.3.3.3" class="ltx_td ltx_align_center"><span id="p1.3.3.3.3.3.3.3" class="ltx_text ltx_font_bold">Jeiyoon Park<sup id="p1.3.3.3.3.3.3.3.1" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>,    Chanjun Park<sup id="p1.3.3.3.3.3.3.3.2" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.2.1" class="ltx_text ltx_font_medium ltx_font_italic">2†</span></sup>,     Heuiseok Lim<sup id="p1.3.3.3.3.3.3.3.3" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_medium ltx_font_italic">3†</span></sup></span></span></span>
<span id="p1.6.6.6.6.6" class="ltx_tr">
<span id="p1.6.6.6.6.6.3" class="ltx_td ltx_align_center"><sup id="p1.6.6.6.6.6.3.1" class="ltx_sup"><span id="p1.6.6.6.6.6.3.1.1" class="ltx_text ltx_font_italic">1</span></sup> Atommerce,   <sup id="p1.6.6.6.6.6.3.2" class="ltx_sup"><span id="p1.6.6.6.6.6.3.2.1" class="ltx_text ltx_font_italic">2</span></sup> Upstage AI,   <sup id="p1.6.6.6.6.6.3.3" class="ltx_sup"><span id="p1.6.6.6.6.6.3.3.1" class="ltx_text ltx_font_italic">3</span></sup> Korea University</span></span>
<span id="p1.6.6.6.6.7" class="ltx_tr">
<span id="p1.6.6.6.6.7.1" class="ltx_td ltx_align_center"><span id="p1.6.6.6.6.7.1.1" class="ltx_text ltx_font_typewriter">jypark1@atommerce.com</span></span></span>
<span id="p1.6.6.6.6.8" class="ltx_tr">
<span id="p1.6.6.6.6.8.1" class="ltx_td ltx_align_center"><span id="p1.6.6.6.6.8.1.1" class="ltx_text ltx_font_typewriter">chanjun.park@upstage.ai</span></span></span>
<span id="p1.6.6.6.6.9" class="ltx_tr">
<span id="p1.6.6.6.6.9.1" class="ltx_td ltx_align_center"><span id="p1.6.6.6.6.9.1.1" class="ltx_text ltx_font_typewriter">limhseok@korea.ac.kr</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the advent of large language models (LLM) <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a href="#bib.bib23" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib25" title="" class="ltx_ref">c</a>, <a href="#bib.bib24" title="" class="ltx_ref">b</a>)</cite>, fundamental paradigm shift is underway and many subfields of NLP such as machine translation <cite class="ltx_cite ltx_citemacro_cite">Jiao et al. (<a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, summarization <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>, question answering <cite class="ltx_cite ltx_citemacro_cite">Omar et al. (<a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite>, and grammatical error correction <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a href="#bib.bib31" title="" class="ltx_ref">2023</a>); Fang et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> are being validated by LLM <cite class="ltx_cite ltx_citemacro_cite">Bang et al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>. However, there still lacks investigations into the ability of LLM to correct grammatical errors in text. For instance, ChatGPT gets much lower automatic evaluation scores <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite> than GECToR <cite class="ltx_cite ltx_citemacro_cite">Omelianchuk et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, based on pretrained RoBERTa model, and GEC product <cite class="ltx_cite ltx_citemacro_cite">Grammarly (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>. ChatGPT also suffers from <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Overcorrection</span> problem <cite class="ltx_cite ltx_citemacro_cite">Fang et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> and shows much lower performance than TagGEC <cite class="ltx_cite ltx_citemacro_cite">Stahlberg and Kumar (<a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>, T5 large, and T5 xxl <cite class="ltx_cite ltx_citemacro_cite">Rothe et al. (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>, despite its cutting-edge prompting techniques.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In order to solve these problems, it is indispensable to improve the performance of existing methods or leverage a hybrid model consisting of a GEC model and LLM, using high-quality training datasets. However, these approaches require a lot of manually annotated sentence pairs and these pairs are very expensive and even hard to obtain. In addition, LLM’s data generation capabilities are not sufficiently corroborated and reinforced yet.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<div id="S1.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:199.5pt;height:309.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,43.4pt) scale(0.78087052128199,0.78087052128199) ;">
<table id="S1.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt"><span id="S1.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S1.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt"><span id="S1.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Generated Subjects</span></td>
</tr>
<tr id="S1.T1.1.1.2" class="ltx_tr">
<td id="S1.T1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S1.T1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.2.1.1.1" class="ltx_p" style="width:54.1pt;"><span id="S1.T1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Prompt (<span id="S1.T1.1.1.2.1.1.1.1.1" class="ltx_text" style="color:#800000;">✖</span> SS)</span></span>
</span>
</td>
<td id="S1.T1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.2.2.1.1" class="ltx_p" style="width:170.7pt;">{<span id="S1.T1.1.1.2.2.1.1.1" class="ltx_text ltx_font_bold">’I’</span>: 42, <span id="S1.T1.1.1.2.2.1.1.2" class="ltx_text ltx_font_bold">’She’</span>: 22, <span id="S1.T1.1.1.2.2.1.1.3" class="ltx_text ltx_font_bold">’He’</span>: 11, <span id="S1.T1.1.1.2.2.1.1.4" class="ltx_text ltx_font_bold">’Dog’</span>: 5, <span id="S1.T1.1.1.2.2.1.1.5" class="ltx_text ltx_font_bold">’Cat’</span>: 4, <span id="S1.T1.1.1.2.2.1.1.6" class="ltx_text ltx_font_bold">’Children’</span>: 2, <span id="S1.T1.1.1.2.2.1.1.7" class="ltx_text ltx_font_bold">’Boys’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.8" class="ltx_text ltx_font_bold">’Dogs’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.9" class="ltx_text ltx_font_bold">’Book’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.10" class="ltx_text ltx_font_bold">’They’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.11" class="ltx_text ltx_font_bold">’Person’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.12" class="ltx_text ltx_font_bold">’Child’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.13" class="ltx_text ltx_font_bold">’You’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.14" class="ltx_text ltx_font_bold">’It’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.15" class="ltx_text ltx_font_bold">’House’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.16" class="ltx_text ltx_font_bold">’John and Sarah’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.17" class="ltx_text ltx_font_bold">’Restaurant’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.18" class="ltx_text ltx_font_bold">’Chair’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.19" class="ltx_text ltx_font_bold">’Elephant’</span>: 1, <span id="S1.T1.1.1.2.2.1.1.20" class="ltx_text ltx_font_bold">’Friend’</span>: 1}</span>
</span>
</td>
</tr>
<tr id="S1.T1.1.1.3" class="ltx_tr">
<td id="S1.T1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" rowspan="21">
<span id="S1.T1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.3.1.1.1" class="ltx_p" style="width:54.1pt;"><span id="S1.T1.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Prompt (<span id="S1.T1.1.1.3.1.1.1.1.1" class="ltx_text" style="color:#008000;">✙</span> SS)</span></span>
</span>
</td>
<td id="S1.T1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.3.2.1.1" class="ltx_p" style="width:170.7pt;">{<span id="S1.T1.1.1.3.2.1.1.1" class="ltx_text ltx_font_bold">’I’</span>: 6, <span id="S1.T1.1.1.3.2.1.1.2" class="ltx_text ltx_font_bold">’Book’</span>: 4, <span id="S1.T1.1.1.3.2.1.1.3" class="ltx_text ltx_font_bold">’Patience’</span>: 4, <span id="S1.T1.1.1.3.2.1.1.4" class="ltx_text ltx_font_bold">’Computer’</span>: 3, <span id="S1.T1.1.1.3.2.1.1.5" class="ltx_text ltx_font_bold">’Water’</span>: 3, <span id="S1.T1.1.1.3.2.1.1.6" class="ltx_text ltx_font_bold">’Monkeys’</span>: 3, <span id="S1.T1.1.1.3.2.1.1.7" class="ltx_text ltx_font_bold">’Dog’</span>: 3, <span id="S1.T1.1.1.3.2.1.1.8" class="ltx_text ltx_font_bold">’Headphone’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.9" class="ltx_text ltx_font_bold">’Tree’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.10" class="ltx_text ltx_font_bold">’Courage’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.11" class="ltx_text ltx_font_bold">’Flock’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.12" class="ltx_text ltx_font_bold">’Cat’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.13" class="ltx_text ltx_font_bold">’Car and Motocycle’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.14" class="ltx_text ltx_font_bold">’Firefighter’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.15" class="ltx_text ltx_font_bold">’Chair’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.16" class="ltx_text ltx_font_bold">’Everest’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.17" class="ltx_text ltx_font_bold">’Jellyfish’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.18" class="ltx_text ltx_font_bold">’Dogs’</span>: 2, <span id="S1.T1.1.1.3.2.1.1.19" class="ltx_text ltx_font_bold">’Eiffel Tower’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.20" class="ltx_text ltx_font_bold">’Cups’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.21" class="ltx_text ltx_font_bold">’Wheelchair’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.22" class="ltx_text ltx_font_bold">’Compassion’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.23" class="ltx_text ltx_font_bold">’Guitar’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.24" class="ltx_text ltx_font_bold">’Freedom’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.25" class="ltx_text ltx_font_bold">’Perserverance’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.26" class="ltx_text ltx_font_bold">’Grace’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.27" class="ltx_text ltx_font_bold">’Camera’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.28" class="ltx_text ltx_font_bold">’She’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.29" class="ltx_text ltx_font_bold">’Authenticity’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.30" class="ltx_text ltx_font_bold">’Taj Mahal’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.31" class="ltx_text ltx_font_bold">’Elephants’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.32" class="ltx_text ltx_font_bold">’Children’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.33" class="ltx_text ltx_font_bold">’Windmill’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.34" class="ltx_text ltx_font_bold">’Road’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.35" class="ltx_text ltx_font_bold">’Shoe’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.36" class="ltx_text ltx_font_bold">’Happiness’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.37" class="ltx_text ltx_font_bold">’Refrigerator and Oven’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.38" class="ltx_text ltx_font_bold">’Pillow’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.39" class="ltx_text ltx_font_bold">’Soldiers’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.40" class="ltx_text ltx_font_bold">’Cupcake’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.41" class="ltx_text ltx_font_bold">’Airplane’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.42" class="ltx_text ltx_font_bold">’Chairs’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.43" class="ltx_text ltx_font_bold">’Bird’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.44" class="ltx_text ltx_font_bold">’Spoon’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.45" class="ltx_text ltx_font_bold">’Barack Obama’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.46" class="ltx_text ltx_font_bold">’Serenity and peace’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.47" class="ltx_text ltx_font_bold">’Great Barrier’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.48" class="ltx_text ltx_font_bold">’Thunderstorm’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.49" class="ltx_text ltx_font_bold">’Door’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.50" class="ltx_text ltx_font_bold">’Leaves’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.51" class="ltx_text ltx_font_bold">’Humility’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.52" class="ltx_text ltx_font_bold">’Mona Lisa’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.53" class="ltx_text ltx_font_bold">’Desk’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.54" class="ltx_text ltx_font_bold">’Snowman and Snowwoman’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.55" class="ltx_text ltx_font_bold">’John’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.56" class="ltx_text ltx_font_bold">’Pizza’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.57" class="ltx_text ltx_font_bold">’Place’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.58" class="ltx_text ltx_font_bold">’Herd’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.59" class="ltx_text ltx_font_bold">’Cows’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.60" class="ltx_text ltx_font_bold">’Bookshelf’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.61" class="ltx_text ltx_font_bold">’Toothbrush’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.62" class="ltx_text ltx_font_bold">’Respect’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.63" class="ltx_text ltx_font_bold">’Diversity’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.64" class="ltx_text ltx_font_bold">’Ink’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.65" class="ltx_text ltx_font_bold">’Beatles’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.66" class="ltx_text ltx_font_bold">’Plant’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.67" class="ltx_text ltx_font_bold">’Pride’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.68" class="ltx_text ltx_font_bold">’Wolves’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.69" class="ltx_text ltx_font_bold">’Congress’</span>: 1, <span id="S1.T1.1.1.3.2.1.1.70" class="ltx_text ltx_font_bold">’Honesty’</span>: 1}</span>
</span>
</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>100 sentences were randomly sampled from each generated result.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Contributions.</span> In this paper, (i) we investigate LLM’s ability to generate synthetic data, (ii) propose an automatic framework to bolster up the quality of generated data, and (iii) leverage a new GEC dataset, ChatLang-8, which is composed of 1M pairs with a distribution of human-like grammatical errors. We find that ChatLang-8 has a more uniform pattern composition than the existing GEC datasets. We also observe that the model performed better when trained with ChatLang-8 than with the existing GEC dataset with the same corpus size. To the best of our knowledge, we are the first to introduce a GEC dataset using LLM and to demonstrate it outperforms previous human-generated corpora.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>ChatLang-8</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The foremost goal is to generate data containing human-like grammatical mistakes. Thus, we aim to create parallel sentence pairs with a distribution of human-like grammatical errors, not unrealistic pairs <cite class="ltx_cite ltx_citemacro_cite">Grundkiewicz and Junczys-Dowmunt (<a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite>. When generating pairs, one of the most intuitive ways is to control all elements of the statement. However, because of productivity of language <cite class="ltx_cite ltx_citemacro_cite">O’Donnell et al. (<a href="#bib.bib20" title="" class="ltx_ref">2011</a>)</cite>, sentences can be infinitely long with recursive rules. It is impossible to control all elements of the generated pairs, and even this approach rather deteriorates the quality of data. Therefore, we first hypothesize that the main factors determining the quality of pairs are the subject types and grammatical error types, and then we diversify them based on our framework.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<div id="S2.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:199.5pt;height:208.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,29.3pt) scale(0.78087052128199,0.78087052128199) ;">
<table id="S2.T2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt"><span id="S2.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S2.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt"><span id="S2.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Generated Conjunction Errors</span></td>
</tr>
<tr id="S2.T2.1.1.2" class="ltx_tr">
<td id="S2.T2.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.1.1.2.1.1.1" class="ltx_p" style="width:54.1pt;"><span id="S2.T2.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Prompt (<span id="S2.T2.1.1.2.1.1.1.1.1" class="ltx_text" style="color:#800000;">✖</span> GS)</span></span>
</span>
</td>
<td id="S2.T2.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.1.1.2.2.1.1" class="ltx_p" style="width:170.7pt;">{<span id="S2.T2.1.1.2.2.1.1.1" class="ltx_text ltx_font_bold">’And’</span>: 59, <span id="S2.T2.1.1.2.2.1.1.2" class="ltx_text ltx_font_bold">’But’</span>: 38, <span id="S2.T2.1.1.2.2.1.1.3" class="ltx_text ltx_font_bold">’Nor’</span>: 2, <span id="S2.T2.1.1.2.2.1.1.4" class="ltx_text ltx_font_bold">’Or’</span>: 1}</span>
</span>
</td>
</tr>
<tr id="S2.T2.1.1.3" class="ltx_tr">
<td id="S2.T2.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" rowspan="20">
<span id="S2.T2.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.1.1.3.1.1.1" class="ltx_p" style="width:54.1pt;"><span id="S2.T2.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Prompt (<span id="S2.T2.1.1.3.1.1.1.1.1" class="ltx_text" style="color:#008000;">✙</span> GS)</span></span>
</span>
</td>
<td id="S2.T2.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T2.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.1.1.3.2.1.1" class="ltx_p" style="width:170.7pt;">{<span id="S2.T2.1.1.3.2.1.1.1" class="ltx_text ltx_font_bold">’The…the’</span>: 6, <span id="S2.T2.1.1.3.2.1.1.2" class="ltx_text ltx_font_bold">’Neither…nor’</span>: 6, <span id="S2.T2.1.1.3.2.1.1.3" class="ltx_text ltx_font_bold">’Both…and’</span>: 4, <span id="S2.T2.1.1.3.2.1.1.4" class="ltx_text ltx_font_bold">’So’</span>: 4, <span id="S2.T2.1.1.3.2.1.1.5" class="ltx_text ltx_font_bold">’While’</span>: 4, <span id="S2.T2.1.1.3.2.1.1.6" class="ltx_text ltx_font_bold">’When’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.7" class="ltx_text ltx_font_bold">’So…that:’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.8" class="ltx_text ltx_font_bold">’Yet’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.9" class="ltx_text ltx_font_bold">’Rather…than’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.10" class="ltx_text ltx_font_bold">’Now that’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.11" class="ltx_text ltx_font_bold">’And’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.12" class="ltx_text ltx_font_bold">’But’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.13" class="ltx_text ltx_font_bold">’As’</span>: 3, <span id="S2.T2.1.1.3.2.1.1.14" class="ltx_text ltx_font_bold">’Nor’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.15" class="ltx_text ltx_font_bold">’Before’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.16" class="ltx_text ltx_font_bold">’As soon as’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.17" class="ltx_text ltx_font_bold">’As long as’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.18" class="ltx_text ltx_font_bold">’As well as’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.19" class="ltx_text ltx_font_bold">’Either…or’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.20" class="ltx_text ltx_font_bold">’Even if’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.21" class="ltx_text ltx_font_bold">’If’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.22" class="ltx_text ltx_font_bold">’Or’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.23" class="ltx_text ltx_font_bold">’Although’</span>: 2, <span id="S2.T2.1.1.3.2.1.1.24" class="ltx_text ltx_font_bold">’Hardly…when’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.25" class="ltx_text ltx_font_bold">’Because’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.26" class="ltx_text ltx_font_bold">’In case’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.27" class="ltx_text ltx_font_bold">’Once’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.28" class="ltx_text ltx_font_bold">’Not…but’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.29" class="ltx_text ltx_font_bold">’Besides’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.30" class="ltx_text ltx_font_bold">’Since’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.31" class="ltx_text ltx_font_bold">’Whether…or’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.32" class="ltx_text ltx_font_bold">’If…then’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.33" class="ltx_text ltx_font_bold">’As many…as’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.34" class="ltx_text ltx_font_bold">’So that’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.35" class="ltx_text ltx_font_bold">’Not so…as’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.36" class="ltx_text ltx_font_bold">’Supposing’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.37" class="ltx_text ltx_font_bold">’Not only…but also’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.38" class="ltx_text ltx_font_bold">’Provided that’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.39" class="ltx_text ltx_font_bold">’For’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.40" class="ltx_text ltx_font_bold">’Till’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.41" class="ltx_text ltx_font_bold">’Even though’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.42" class="ltx_text ltx_font_bold">’Too…to’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.43" class="ltx_text ltx_font_bold">’Nonetheless’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.44" class="ltx_text ltx_font_bold">’As…as’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.45" class="ltx_text ltx_font_bold">’By the time’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.46" class="ltx_text ltx_font_bold">’Still’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.47" class="ltx_text ltx_font_bold">’Even if’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.48" class="ltx_text ltx_font_bold">’No sooner…than’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.49" class="ltx_text ltx_font_bold">’That’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.50" class="ltx_text ltx_font_bold">’Scarcely…when’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.51" class="ltx_text ltx_font_bold">’In order to’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.52" class="ltx_text ltx_font_bold">’If only’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.53" class="ltx_text ltx_font_bold">’Indeed’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.54" class="ltx_text ltx_font_bold">’Otherwise’</span>: 1, <span id="S2.T2.1.1.3.2.1.1.55" class="ltx_text ltx_font_bold">’Though’</span>: 1}</span>
</span>
</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>100 sentences were randomly sampled from each generated result.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Subject Selector</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.3" class="ltx_p">One naive approach is to design the prompt to generate pairs without considering the subject element. However, as shown in Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, when simply generating parallel sentences, the type of subject of the sentence becomes too limited. To mitigate this risk, we propose <span id="S2.SS1.p1.3.1" class="ltx_text ltx_font_italic">Subject Selector (SS)</span>, a novel algorithm for diversifying subject <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">S</annotation></semantics></math> of parallel sentences. First, we predefine the type of subject <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="S_{k}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><msub id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">S</mi><mi id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">𝑆</ci><ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">S_{k}</annotation></semantics></math> to be created<span id="footnote1a" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Predefined types: Common Noun, Proper Noun, Collective Noun, Compound Noun, Concrete Noun, Abstract Noun, Countable Noun, and Uncountable Noun.</span></span></span>. Then Subject Selector randomly choose a type of subject <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="S_{k}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">S</mi><mi id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝑆</ci><ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">S_{k}</annotation></semantics></math> among the predefined noun types and generate subject candidates as large as the window size. For example, if the noun type selected by Subject Selector is <span id="S2.SS1.p1.3.2" class="ltx_text ltx_font_italic">proper noun</span> and the window size is 30, 30 proper nouns are created. Then, one of the candidates is randomly determine as a subject of a sentence.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Grammar Selector</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.2" class="ltx_p">Similar to the problem in Section <a href="#S2.SS1" title="2.1 Subject Selector ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, a vanilla prompt to generate pairs of wrong and correct sentences produces an extremely constrained set of sentences. Table <a href="#S2.T2" title="Table 2 ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that the method just specifying the grammar type also could not ameliorate this problem. For instance, when generating data related to <span id="S2.SS2.p1.2.1" class="ltx_text ltx_font_italic">Conjunction</span>, most of the outputs consist of <span id="S2.SS2.p1.2.2" class="ltx_text ltx_font_italic">And</span>, and <span id="S2.SS2.p1.2.3" class="ltx_text ltx_font_italic">But</span>. In this paper, we propose <span id="S2.SS2.p1.2.4" class="ltx_text ltx_font_italic">Grammar Selector (GS)</span> to consider various grammar errors <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">G</annotation></semantics></math> and thereby improve the quality of generated data. We take into account the same grammatical error categories <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="G_{l}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><msub id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">G</mi><mi id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">𝐺</ci><ci id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">G_{l}</annotation></semantics></math> in <cite class="ltx_cite ltx_citemacro_cite">Bryant et al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. Unlike Subject Selector in Section <a href="#S2.SS1" title="2.1 Subject Selector ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, Grammar Selector first divides the grammar errors into two types: Errors that require diversification of grammar types and those that do not. For example, <span id="S2.SS2.p1.2.5" class="ltx_text ltx_font_italic">Word Order (WO)</span> and <span id="S2.SS2.p1.2.6" class="ltx_text ltx_font_italic">Spelling (SPELL)</span> don’t need to consider patterns as large as the window size: We can get good results just by instructing the LLM to create representative of real human errors.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Prompt Manager</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Given a subject and grammatical error generated from Section <a href="#S2.SS1" title="2.1 Subject Selector ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a> and Section <a href="#S2.SS2" title="2.2 Grammar Selector ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> respectively, <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">Prompt Manager</span> combines them into one prompt. To improve production stability, we incorporate the CoT technique <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite> into the Prompt Manager. To circumvent unnecessary errors, Prompt Manager matches a subject of wrong sentence to a subject of right sentence. Prompt Manager maintains the rest of the elements are the same, except for the grammatical error of parallel sentences.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Evaluator</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.3" class="ltx_p">Although generated pairs can be multifarious by exploiting Subject Selector, Grammar Selector, and Prompt Manager, due to uniform randomness of our method to encourage diversity, data that violates prompt instructions were generated occasionally. For example, a prompt <span id="S2.SS4.p1.3.1" class="ltx_text ltx_font_italic">subject: Concrete Noun (car), and grammar_ type: Verb (swim)</span> created pairs <span id="S2.SS4.p1.3.2" class="ltx_text ltx_font_italic">"Wrong: The car swims to the shore.", "Right: The car drives to the shore."</span>. They are the result of breaking the instruction to use the swim verb correctly (i.e., sentences related to verb tense or active/passive voice errors should have been output, not a semantic error.). To alleviate this risk, we propose <span id="S2.SS4.p1.3.3" class="ltx_text ltx_font_italic">Evaluator</span>, a simple LLM-based evaluator using four criteria <math id="S2.SS4.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS4.p1.1.m1.1a"><mi id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><ci id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">C</annotation></semantics></math> (Figure <a href="#S2.F1" title="Figure 1 ‣ 2.4 Evaluator ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Evaluator <math id="S2.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S2.SS4.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><ci id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">\mathcal{E}</annotation></semantics></math> evaluates itself for compliance with the data creation process and employs a unanimous vote: If even a single criterion <math id="S2.SS4.p1.3.m3.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.SS4.p1.3.m3.1a"><msub id="S2.SS4.p1.3.m3.1.1" xref="S2.SS4.p1.3.m3.1.1.cmml"><mi id="S2.SS4.p1.3.m3.1.1.2" xref="S2.SS4.p1.3.m3.1.1.2.cmml">C</mi><mi id="S2.SS4.p1.3.m3.1.1.3" xref="S2.SS4.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.3.m3.1b"><apply id="S2.SS4.p1.3.m3.1.1.cmml" xref="S2.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.3.m3.1.1.1.cmml" xref="S2.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS4.p1.3.m3.1.1.2.cmml" xref="S2.SS4.p1.3.m3.1.1.2">𝐶</ci><ci id="S2.SS4.p1.3.m3.1.1.3.cmml" xref="S2.SS4.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.3.m3.1c">C_{i}</annotation></semantics></math> is not met, the generated result is discarded:</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2406.03202/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="244" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The pipeline of Evaluator.</figcaption>
</figure>
<div id="S2.SS4.p2" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.6" class="ltx_Math" alttext="\mathcal{E}(D)=\left\{\begin{array}[]{ll}\displaystyle{1},\quad if\quad C_{1}\wedge C_{2}\wedge C_{3}\wedge C_{4}\\[11.38109pt]
\displaystyle{0},\quad otherwise\end{array}\right." display="block"><semantics id="S2.E1.m1.6a"><mrow id="S2.E1.m1.6.7" xref="S2.E1.m1.6.7.cmml"><mrow id="S2.E1.m1.6.7.2" xref="S2.E1.m1.6.7.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.6.7.2.2" xref="S2.E1.m1.6.7.2.2.cmml">ℰ</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.7.2.1" xref="S2.E1.m1.6.7.2.1.cmml">​</mo><mrow id="S2.E1.m1.6.7.2.3.2" xref="S2.E1.m1.6.7.2.cmml"><mo stretchy="false" id="S2.E1.m1.6.7.2.3.2.1" xref="S2.E1.m1.6.7.2.cmml">(</mo><mi id="S2.E1.m1.6.6" xref="S2.E1.m1.6.6.cmml">D</mi><mo stretchy="false" id="S2.E1.m1.6.7.2.3.2.2" xref="S2.E1.m1.6.7.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.6.7.1" xref="S2.E1.m1.6.7.1.cmml">=</mo><mrow id="S2.E1.m1.6.7.3.2" xref="S2.E1.m1.6.7.3.1.cmml"><mo id="S2.E1.m1.6.7.3.2.1" xref="S2.E1.m1.6.7.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml"><mtr id="S2.E1.m1.5.5a" xref="S2.E1.m1.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E1.m1.5.5b" xref="S2.E1.m1.5.5.cmml"><mrow id="S2.E1.m1.3.3.3.3.3.3" xref="S2.E1.m1.3.3.3.3.3.4.cmml"><mn id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml">1</mn><mo rspace="1.167em" id="S2.E1.m1.3.3.3.3.3.3.3" xref="S2.E1.m1.3.3.3.3.3.4.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.1.2" xref="S2.E1.m1.2.2.2.2.2.2.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.2.2.1.3" xref="S2.E1.m1.2.2.2.2.2.2.1.3.cmml">f</mi></mrow><mspace width="1em" id="S2.E1.m1.3.3.3.3.3.3.4" xref="S2.E1.m1.3.3.3.3.3.4.cmml"></mspace><mrow id="S2.E1.m1.3.3.3.3.3.3.2" xref="S2.E1.m1.3.3.3.3.3.3.2.cmml"><msub id="S2.E1.m1.3.3.3.3.3.3.2.2" xref="S2.E1.m1.3.3.3.3.3.3.2.2.cmml"><mi id="S2.E1.m1.3.3.3.3.3.3.2.2.2" xref="S2.E1.m1.3.3.3.3.3.3.2.2.2.cmml">C</mi><mn id="S2.E1.m1.3.3.3.3.3.3.2.2.3" xref="S2.E1.m1.3.3.3.3.3.3.2.2.3.cmml">1</mn></msub><mo id="S2.E1.m1.3.3.3.3.3.3.2.1" xref="S2.E1.m1.3.3.3.3.3.3.2.1.cmml">∧</mo><msub id="S2.E1.m1.3.3.3.3.3.3.2.3" xref="S2.E1.m1.3.3.3.3.3.3.2.3.cmml"><mi id="S2.E1.m1.3.3.3.3.3.3.2.3.2" xref="S2.E1.m1.3.3.3.3.3.3.2.3.2.cmml">C</mi><mn id="S2.E1.m1.3.3.3.3.3.3.2.3.3" xref="S2.E1.m1.3.3.3.3.3.3.2.3.3.cmml">2</mn></msub><mo id="S2.E1.m1.3.3.3.3.3.3.2.1a" xref="S2.E1.m1.3.3.3.3.3.3.2.1.cmml">∧</mo><msub id="S2.E1.m1.3.3.3.3.3.3.2.4" xref="S2.E1.m1.3.3.3.3.3.3.2.4.cmml"><mi id="S2.E1.m1.3.3.3.3.3.3.2.4.2" xref="S2.E1.m1.3.3.3.3.3.3.2.4.2.cmml">C</mi><mn id="S2.E1.m1.3.3.3.3.3.3.2.4.3" xref="S2.E1.m1.3.3.3.3.3.3.2.4.3.cmml">3</mn></msub><mo id="S2.E1.m1.3.3.3.3.3.3.2.1b" xref="S2.E1.m1.3.3.3.3.3.3.2.1.cmml">∧</mo><msub id="S2.E1.m1.3.3.3.3.3.3.2.5" xref="S2.E1.m1.3.3.3.3.3.3.2.5.cmml"><mi id="S2.E1.m1.3.3.3.3.3.3.2.5.2" xref="S2.E1.m1.3.3.3.3.3.3.2.5.2.cmml">C</mi><mn id="S2.E1.m1.3.3.3.3.3.3.2.5.3" xref="S2.E1.m1.3.3.3.3.3.3.2.5.3.cmml">4</mn></msub></mrow></mrow></mtd><mtd id="S2.E1.m1.5.5c" xref="S2.E1.m1.5.5.cmml"></mtd></mtr><mtr id="S2.E1.m1.5.5d" xref="S2.E1.m1.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E1.m1.5.5e" xref="S2.E1.m1.5.5.cmml"><mrow id="S2.E1.m1.5.5.5.2.2.2" xref="S2.E1.m1.5.5.5.2.2.3.cmml"><mn id="S2.E1.m1.4.4.4.1.1.1" xref="S2.E1.m1.4.4.4.1.1.1.cmml">0</mn><mo rspace="1.167em" id="S2.E1.m1.5.5.5.2.2.2.2" xref="S2.E1.m1.5.5.5.2.2.3.cmml">,</mo><mrow id="S2.E1.m1.5.5.5.2.2.2.1" xref="S2.E1.m1.5.5.5.2.2.2.1.cmml"><mi id="S2.E1.m1.5.5.5.2.2.2.1.2" xref="S2.E1.m1.5.5.5.2.2.2.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.3" xref="S2.E1.m1.5.5.5.2.2.2.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1a" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.4" xref="S2.E1.m1.5.5.5.2.2.2.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1b" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.5" xref="S2.E1.m1.5.5.5.2.2.2.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1c" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.6" xref="S2.E1.m1.5.5.5.2.2.2.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1d" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.7" xref="S2.E1.m1.5.5.5.2.2.2.1.7.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1e" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.8" xref="S2.E1.m1.5.5.5.2.2.2.1.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1f" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.9" xref="S2.E1.m1.5.5.5.2.2.2.1.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.5.2.2.2.1.1g" xref="S2.E1.m1.5.5.5.2.2.2.1.1.cmml">​</mo><mi id="S2.E1.m1.5.5.5.2.2.2.1.10" xref="S2.E1.m1.5.5.5.2.2.2.1.10.cmml">e</mi></mrow></mrow></mtd><mtd id="S2.E1.m1.5.5f" xref="S2.E1.m1.5.5.cmml"></mtd></mtr></mtable><mi id="S2.E1.m1.6.7.3.2.2" xref="S2.E1.m1.6.7.3.1.1.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.6b"><apply id="S2.E1.m1.6.7.cmml" xref="S2.E1.m1.6.7"><eq id="S2.E1.m1.6.7.1.cmml" xref="S2.E1.m1.6.7.1"></eq><apply id="S2.E1.m1.6.7.2.cmml" xref="S2.E1.m1.6.7.2"><times id="S2.E1.m1.6.7.2.1.cmml" xref="S2.E1.m1.6.7.2.1"></times><ci id="S2.E1.m1.6.7.2.2.cmml" xref="S2.E1.m1.6.7.2.2">ℰ</ci><ci id="S2.E1.m1.6.6.cmml" xref="S2.E1.m1.6.6">𝐷</ci></apply><apply id="S2.E1.m1.6.7.3.1.cmml" xref="S2.E1.m1.6.7.3.2"><csymbol cd="latexml" id="S2.E1.m1.6.7.3.1.1.cmml" xref="S2.E1.m1.6.7.3.2.1">cases</csymbol><matrix id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5"><matrixrow id="S2.E1.m1.5.5a.cmml" xref="S2.E1.m1.5.5"><list id="S2.E1.m1.3.3.3.3.3.4.cmml" xref="S2.E1.m1.3.3.3.3.3.3"><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">1</cn><apply id="S2.E1.m1.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1"><times id="S2.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.1"></times><ci id="S2.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.2">𝑖</ci><ci id="S2.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1.3">𝑓</ci></apply><apply id="S2.E1.m1.3.3.3.3.3.3.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2"><and id="S2.E1.m1.3.3.3.3.3.3.2.1.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.1"></and><apply id="S2.E1.m1.3.3.3.3.3.3.2.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.3.3.3.2.2.1.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.2">subscript</csymbol><ci id="S2.E1.m1.3.3.3.3.3.3.2.2.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.2.2">𝐶</ci><cn type="integer" id="S2.E1.m1.3.3.3.3.3.3.2.2.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.2.3">1</cn></apply><apply id="S2.E1.m1.3.3.3.3.3.3.2.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.3.3.3.2.3.1.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.3">subscript</csymbol><ci id="S2.E1.m1.3.3.3.3.3.3.2.3.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.3.2">𝐶</ci><cn type="integer" id="S2.E1.m1.3.3.3.3.3.3.2.3.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.3.3">2</cn></apply><apply id="S2.E1.m1.3.3.3.3.3.3.2.4.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.3.3.3.2.4.1.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.4">subscript</csymbol><ci id="S2.E1.m1.3.3.3.3.3.3.2.4.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.4.2">𝐶</ci><cn type="integer" id="S2.E1.m1.3.3.3.3.3.3.2.4.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.4.3">3</cn></apply><apply id="S2.E1.m1.3.3.3.3.3.3.2.5.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.5"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.3.3.3.2.5.1.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.5">subscript</csymbol><ci id="S2.E1.m1.3.3.3.3.3.3.2.5.2.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.5.2">𝐶</ci><cn type="integer" id="S2.E1.m1.3.3.3.3.3.3.2.5.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3.2.5.3">4</cn></apply></apply></list><cerror id="S2.E1.m1.5.5b.cmml" xref="S2.E1.m1.5.5"><csymbol cd="ambiguous" id="S2.E1.m1.5.5c.cmml" xref="S2.E1.m1.5.5">missing-subexpression</csymbol></cerror></matrixrow><matrixrow id="S2.E1.m1.5.5d.cmml" xref="S2.E1.m1.5.5"><list id="S2.E1.m1.5.5.5.2.2.3.cmml" xref="S2.E1.m1.5.5.5.2.2.2"><cn type="integer" id="S2.E1.m1.4.4.4.1.1.1.cmml" xref="S2.E1.m1.4.4.4.1.1.1">0</cn><apply id="S2.E1.m1.5.5.5.2.2.2.1.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1"><times id="S2.E1.m1.5.5.5.2.2.2.1.1.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.1"></times><ci id="S2.E1.m1.5.5.5.2.2.2.1.2.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.2">𝑜</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.3.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.3">𝑡</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.4.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.4">ℎ</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.5.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.5">𝑒</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.6.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.6">𝑟</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.7.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.7">𝑤</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.8.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.8">𝑖</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.9.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.9">𝑠</ci><ci id="S2.E1.m1.5.5.5.2.2.2.1.10.cmml" xref="S2.E1.m1.5.5.5.2.2.2.1.10">𝑒</ci></apply></list><cerror id="S2.E1.m1.5.5e.cmml" xref="S2.E1.m1.5.5"><csymbol cd="ambiguous" id="S2.E1.m1.5.5f.cmml" xref="S2.E1.m1.5.5">missing-subexpression</csymbol></cerror></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.6c">\mathcal{E}(D)=\left\{\begin{array}[]{ll}\displaystyle{1},\quad if\quad C_{1}\wedge C_{2}\wedge C_{3}\wedge C_{4}\\[11.38109pt]
\displaystyle{0},\quad otherwise\end{array}\right.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Dataset Details</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Our implementation utilizes GPT-3.5 Turbo. We gathered approximately 1M pairs that cover eight subject type and 23 grammar type. Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Statistical Analysis ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows statistics of <span id="S2.SS5.p1.1.1" class="ltx_text ltx_font_italic">ChatLang-8</span> (ours), FCE <cite class="ltx_cite ltx_citemacro_cite">Yannakoudakis et al. (<a href="#bib.bib33" title="" class="ltx_ref">2011</a>)</cite>, Lang-8 <cite class="ltx_cite ltx_citemacro_cite">Mizumoto et al. (<a href="#bib.bib17" title="" class="ltx_ref">2012</a>); Tajiri et al. (<a href="#bib.bib28" title="" class="ltx_ref">2012</a>)</cite>, NUCLE <cite class="ltx_cite ltx_citemacro_cite">Dahlmeier et al. (<a href="#bib.bib5" title="" class="ltx_ref">2013</a>)</cite> and W&amp;I+LOCNESS <cite class="ltx_cite ltx_citemacro_cite">Bryant et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. Note that we leverage ChatLang-8 that has a corpus size similar to Lang-8, one of the largest GEC corpus, and much larger than the other corpora.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2406.03202/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="716" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparison of M<sup id="S3.F2.4.1" class="ltx_sup">2</sup> outputs of GEC models, trained on Lang-8 and ChatLang-8 respectively.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Statistical Analysis</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Note that numerous studies show that the imbalance of a dataset causes performance degradation <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>); Lin et al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>); Li and Shi (<a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite>. In order to demonstrate whether the dataset is created evenly, we conduct statistical analysis by comparing ChatLang-8 with existing datasets. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Quantitative Results ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows a subject distribution of ChatLang-8. We observe that the distribution of subject types in ChatLang-8 is evenly distributed. It suggests that the Subject Selector and evaluator affect data quality improvement even though the evaluator abandons all unsuitable data. In Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 Quantitative Results ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a href="#A2.T5" title="Table 5 ‣ Appendix B Architecture ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we find that the grammar types of ChatLang-8 are most evenly distributed while the other corpora have highly unbalanced grammar labels. For example, W&amp;I+LOCNESS dataset has 10.7% (averaged) of Determiner (DET) errors, and 17.75% of Punctuation (PUNCT) errors, whereas 0.6133% of Conjunction (CONJ) and 0.21% of Adjective Form (ADJ:FORM). Existing datasets have a very small proportion of important grammatical patterns, which can cause performance degradation during model training. In addition, since ChatLang-8 excluded OTHER and UNK labels when generating data, while the other corpora have a great proportion of UNK label (e.g., NUCLE: 25.65%) and OTHER label (e.g., NUCLE: 2.57%), it is easier to handle dataset and to predict the model outputs.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<div id="S3.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.8pt;height:22pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-68.0pt,7.0pt) scale(0.61,0.61) ;">
<table id="S3.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">ChatLang-8</td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FCE</td>
<td id="S3.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Lang-8</td>
<td id="S3.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">NUCLE</td>
<td id="S3.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">W&amp;I+LOCNESS</td>
</tr>
<tr id="S3.T3.1.1.2" class="ltx_tr">
<td id="S3.T3.1.1.2.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Sentences</td>
<td id="S3.T3.1.1.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1,016,588</td>
<td id="S3.T3.1.1.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">33,236</td>
<td id="S3.T3.1.1.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1,037,561</td>
<td id="S3.T3.1.1.2.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">57,151</td>
<td id="S3.T3.1.1.2.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">43,169</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>ChatLang-8, FCE, Lang-8, NUCLE, and W&amp;I+LOCNESS dataset statistics.</figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.T4.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:212.2pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.4pt,9.0pt) scale(0.75,0.75) ;">
<table id="S3.T4.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.2.2.3" class="ltx_tr">
<td id="S3.T4.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S3.T4.2.2.3.1.1" class="ltx_text ltx_font_bold">CoNLL-2014</span></td>
<td id="S3.T4.2.2.3.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.2.2.3.2.1" class="ltx_text ltx_font_bold">ChatLang-8</span></td>
<td id="S3.T4.2.2.3.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.2.2.3.3.1" class="ltx_text ltx_font_bold">Lang-8</span></td>
</tr>
<tr id="S3.T4.2.2.2" class="ltx_tr">
<td id="S3.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.2.2.2.3.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.2.2.2.4.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.1.1.1.1.1.m1.1a"><msub id="S3.T4.1.1.1.1.1.m1.1.1" xref="S3.T4.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T4.1.1.1.1.1.m1.1.1a" xref="S3.T4.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.1.1.1.1.1.m1.1.1.1" xref="S3.T4.1.1.1.1.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.1.1.m1.1b"><apply id="S3.T4.1.1.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.1.1.m1.1.1"><ci id="S3.T4.1.1.1.1.1.m1.1.1.1a.cmml" xref="S3.T4.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T4.1.1.1.1.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.1.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
<td id="S3.T4.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.2.2.2.5.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.2.2.2.6.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.2.2.2.2.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.2.2.2.2.1.m1.1a"><msub id="S3.T4.2.2.2.2.1.m1.1.1" xref="S3.T4.2.2.2.2.1.m1.1.1.cmml"><mi id="S3.T4.2.2.2.2.1.m1.1.1a" xref="S3.T4.2.2.2.2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.2.2.2.2.1.m1.1.1.1" xref="S3.T4.2.2.2.2.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.2.1.m1.1b"><apply id="S3.T4.2.2.2.2.1.m1.1.1.cmml" xref="S3.T4.2.2.2.2.1.m1.1.1"><ci id="S3.T4.2.2.2.2.1.m1.1.1.1a.cmml" xref="S3.T4.2.2.2.2.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.2.2.2.2.1.m1.1.1.1.cmml" xref="S3.T4.2.2.2.2.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.2.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
</tr>
<tr id="S3.T4.2.2.4" class="ltx_tr">
<td id="S3.T4.2.2.4.1" class="ltx_td ltx_align_left ltx_border_t">Transformer</td>
<td id="S3.T4.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">47.79</td>
<td id="S3.T4.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">26.39</td>
<td id="S3.T4.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">41.12</td>
<td id="S3.T4.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">54.37</td>
<td id="S3.T4.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">13.28</td>
<td id="S3.T4.2.2.4.7" class="ltx_td ltx_align_center ltx_border_t">33.58</td>
</tr>
<tr id="S3.T4.2.2.5" class="ltx_tr">
<td id="S3.T4.2.2.5.1" class="ltx_td ltx_align_left ltx_border_bb">BART</td>
<td id="S3.T4.2.2.5.2" class="ltx_td ltx_align_center ltx_border_bb">52.50</td>
<td id="S3.T4.2.2.5.3" class="ltx_td ltx_align_center ltx_border_bb">34.31</td>
<td id="S3.T4.2.2.5.4" class="ltx_td ltx_align_center ltx_border_bb">47.47</td>
<td id="S3.T4.2.2.5.5" class="ltx_td ltx_align_center ltx_border_bb">27.89</td>
<td id="S3.T4.2.2.5.6" class="ltx_td ltx_align_center ltx_border_bb">16.01</td>
<td id="S3.T4.2.2.5.7" class="ltx_td ltx_align_center ltx_border_bb">24.29</td>
</tr>
</table>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.T4.4.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:216.2pt;height:55.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.3pt,8.3pt) scale(0.77,0.77) ;">
<table id="S3.T4.4.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.4.2.2.3" class="ltx_tr">
<td id="S3.T4.4.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S3.T4.4.2.2.3.1.1" class="ltx_text ltx_font_bold">BEA-2019</span></td>
<td id="S3.T4.4.2.2.3.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.4.2.2.3.2.1" class="ltx_text ltx_font_bold">ChatLang-8</span></td>
<td id="S3.T4.4.2.2.3.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.4.2.2.3.3.1" class="ltx_text ltx_font_bold">Lang-8</span></td>
</tr>
<tr id="S3.T4.4.2.2.2" class="ltx_tr">
<td id="S3.T4.4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.4.2.2.2.3.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.4.2.2.2.4.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.3.1.1.1.1.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.3.1.1.1.1.1.m1.1a"><msub id="S3.T4.3.1.1.1.1.1.m1.1.1" xref="S3.T4.3.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T4.3.1.1.1.1.1.m1.1.1a" xref="S3.T4.3.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.3.1.1.1.1.1.m1.1.1.1" xref="S3.T4.3.1.1.1.1.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.3.1.1.1.1.1.m1.1b"><apply id="S3.T4.3.1.1.1.1.1.m1.1.1.cmml" xref="S3.T4.3.1.1.1.1.1.m1.1.1"><ci id="S3.T4.3.1.1.1.1.1.m1.1.1.1a.cmml" xref="S3.T4.3.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.3.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T4.3.1.1.1.1.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.1.1.1.1.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
<td id="S3.T4.4.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.4.2.2.2.5.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.4.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.4.2.2.2.6.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.4.2.2.2.2.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.4.2.2.2.2.1.m1.1a"><msub id="S3.T4.4.2.2.2.2.1.m1.1.1" xref="S3.T4.4.2.2.2.2.1.m1.1.1.cmml"><mi id="S3.T4.4.2.2.2.2.1.m1.1.1a" xref="S3.T4.4.2.2.2.2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.4.2.2.2.2.1.m1.1.1.1" xref="S3.T4.4.2.2.2.2.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.4.2.2.2.2.1.m1.1b"><apply id="S3.T4.4.2.2.2.2.1.m1.1.1.cmml" xref="S3.T4.4.2.2.2.2.1.m1.1.1"><ci id="S3.T4.4.2.2.2.2.1.m1.1.1.1a.cmml" xref="S3.T4.4.2.2.2.2.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.4.2.2.2.2.1.m1.1.1.1.cmml" xref="S3.T4.4.2.2.2.2.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.2.2.2.2.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
</tr>
<tr id="S3.T4.4.2.2.4" class="ltx_tr">
<td id="S3.T4.4.2.2.4.1" class="ltx_td ltx_align_left ltx_border_t">Transformer</td>
<td id="S3.T4.4.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">34.44</td>
<td id="S3.T4.4.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">19.69</td>
<td id="S3.T4.4.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">29.95</td>
<td id="S3.T4.4.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">44.81</td>
<td id="S3.T4.4.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">8.5</td>
<td id="S3.T4.4.2.2.4.7" class="ltx_td ltx_align_center ltx_border_t">24.16</td>
</tr>
<tr id="S3.T4.4.2.2.5" class="ltx_tr">
<td id="S3.T4.4.2.2.5.1" class="ltx_td ltx_align_left ltx_border_bb">BART</td>
<td id="S3.T4.4.2.2.5.2" class="ltx_td ltx_align_center ltx_border_bb">34.86</td>
<td id="S3.T4.4.2.2.5.3" class="ltx_td ltx_align_center ltx_border_bb">24.38</td>
<td id="S3.T4.4.2.2.5.4" class="ltx_td ltx_align_center ltx_border_bb">32.10</td>
<td id="S3.T4.4.2.2.5.5" class="ltx_td ltx_align_center ltx_border_bb">23.69</td>
<td id="S3.T4.4.2.2.5.6" class="ltx_td ltx_align_center ltx_border_bb">11.00</td>
<td id="S3.T4.4.2.2.5.7" class="ltx_td ltx_align_center ltx_border_bb">19.25</td>
</tr>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T4.6.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:213.4pt;height:54.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.7pt,8.6pt) scale(0.76,0.76) ;">
<table id="S3.T4.6.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.6.2.2.3" class="ltx_tr">
<td id="S3.T4.6.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S3.T4.6.2.2.3.1.1" class="ltx_text ltx_font_bold">GMEG-wiki</span></td>
<td id="S3.T4.6.2.2.3.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.6.2.2.3.2.1" class="ltx_text ltx_font_bold">ChatLang-8</span></td>
<td id="S3.T4.6.2.2.3.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T4.6.2.2.3.3.1" class="ltx_text ltx_font_bold">Lang-8</span></td>
</tr>
<tr id="S3.T4.6.2.2.2" class="ltx_tr">
<td id="S3.T4.6.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.2.2.2.3.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.6.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.2.2.2.4.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.5.1.1.1.1.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.5.1.1.1.1.1.m1.1a"><msub id="S3.T4.5.1.1.1.1.1.m1.1.1" xref="S3.T4.5.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T4.5.1.1.1.1.1.m1.1.1a" xref="S3.T4.5.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.5.1.1.1.1.1.m1.1.1.1" xref="S3.T4.5.1.1.1.1.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.5.1.1.1.1.1.m1.1b"><apply id="S3.T4.5.1.1.1.1.1.m1.1.1.cmml" xref="S3.T4.5.1.1.1.1.1.m1.1.1"><ci id="S3.T4.5.1.1.1.1.1.m1.1.1.1a.cmml" xref="S3.T4.5.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.5.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T4.5.1.1.1.1.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.1.1.1.1.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
<td id="S3.T4.6.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.2.2.2.5.1" class="ltx_text ltx_font_bold">P</span></td>
<td id="S3.T4.6.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.2.2.2.6.1" class="ltx_text ltx_font_bold">R</span></td>
<td id="S3.T4.6.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.2.2.2.2.1" class="ltx_text ltx_font_bold">F<math id="S3.T4.6.2.2.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\text{0.5}}" display="inline"><semantics id="S3.T4.6.2.2.2.2.1.m1.1a"><msub id="S3.T4.6.2.2.2.2.1.m1.1.1" xref="S3.T4.6.2.2.2.2.1.m1.1.1.cmml"><mi id="S3.T4.6.2.2.2.2.1.m1.1.1a" xref="S3.T4.6.2.2.2.2.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S3.T4.6.2.2.2.2.1.m1.1.1.1" xref="S3.T4.6.2.2.2.2.1.m1.1.1.1a.cmml">0.5</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T4.6.2.2.2.2.1.m1.1b"><apply id="S3.T4.6.2.2.2.2.1.m1.1.1.cmml" xref="S3.T4.6.2.2.2.2.1.m1.1.1"><ci id="S3.T4.6.2.2.2.2.1.m1.1.1.1a.cmml" xref="S3.T4.6.2.2.2.2.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.T4.6.2.2.2.2.1.m1.1.1.1.cmml" xref="S3.T4.6.2.2.2.2.1.m1.1.1.1">0.5</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.2.2.2.2.1.m1.1c">{}_{\text{0.5}}</annotation></semantics></math></span></td>
</tr>
<tr id="S3.T4.6.2.2.4" class="ltx_tr">
<td id="S3.T4.6.2.2.4.1" class="ltx_td ltx_align_left ltx_border_t">Transformer</td>
<td id="S3.T4.6.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">46.56</td>
<td id="S3.T4.6.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">34.33</td>
<td id="S3.T4.6.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">43.46</td>
<td id="S3.T4.6.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">41.44</td>
<td id="S3.T4.6.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">11.38</td>
<td id="S3.T4.6.2.2.4.7" class="ltx_td ltx_align_center ltx_border_t">27.11</td>
</tr>
<tr id="S3.T4.6.2.2.5" class="ltx_tr">
<td id="S3.T4.6.2.2.5.1" class="ltx_td ltx_align_left ltx_border_bb">BART</td>
<td id="S3.T4.6.2.2.5.2" class="ltx_td ltx_align_center ltx_border_bb">49.09</td>
<td id="S3.T4.6.2.2.5.3" class="ltx_td ltx_align_center ltx_border_bb">41.77</td>
<td id="S3.T4.6.2.2.5.4" class="ltx_td ltx_align_center ltx_border_bb">47.42</td>
<td id="S3.T4.6.2.2.5.5" class="ltx_td ltx_align_center ltx_border_bb">23.54</td>
<td id="S3.T4.6.2.2.5.6" class="ltx_td ltx_align_center ltx_border_bb">15.68</td>
<td id="S3.T4.6.2.2.5.7" class="ltx_td ltx_align_center ltx_border_bb">21.39</td>
</tr>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Evaluation results on English CoNLL-2014, BEA-2019, and GMEG-wiki.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Quantitative Results</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">To investigate whether ChatLang-8 has value as a dataset, we train a vanilla Transformer <cite class="ltx_cite ltx_citemacro_cite">Vaswani et al. (<a href="#bib.bib29" title="" class="ltx_ref">2017</a>)</cite> and BART <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>, much larger model, on both ChatLang-8 and Lang-8 <cite class="ltx_cite ltx_citemacro_cite">Mizumoto et al. (<a href="#bib.bib17" title="" class="ltx_ref">2012</a>); Tajiri et al. (<a href="#bib.bib28" title="" class="ltx_ref">2012</a>)</cite>. Note that for the fairness of the experiment, we choose Lang-8, which has a similar dataset structure and corpus size, and which effectively improve performance <cite class="ltx_cite ltx_citemacro_cite">Lichtarge et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>, <a href="#bib.bib14" title="" class="ltx_ref">2020</a>); Flachs et al. (<a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>. In addition, though there is previous attempt to improve the Lang-8 <cite class="ltx_cite ltx_citemacro_cite">Flachs et al. (<a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>, it reports only five error types on BEA test while we considers 25 error types and three benchmarks. Thus, we employ Lang-8 to the experiments, instead of cLang-8. We evaluate performance on three popular GEC benchmarks: CoNLL-2014 <cite class="ltx_cite ltx_citemacro_cite">Ng et al. (<a href="#bib.bib19" title="" class="ltx_ref">2014</a>)</cite>, BEA-2019 <cite class="ltx_cite ltx_citemacro_cite">Bryant et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>, and GMEG-wiki <cite class="ltx_cite ltx_citemacro_cite">Napoles et al. (<a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite>. As evaluation metrics, we use M<sup id="S3.SS2.p1.4.4" class="ltx_sup">2</sup> scorer <cite class="ltx_cite ltx_citemacro_cite">Dahlmeier and Ng (<a href="#bib.bib4" title="" class="ltx_ref">2012</a>)</cite> for CoNLL-2014, and ERRANT <cite class="ltx_cite ltx_citemacro_cite">Bryant et al. (<a href="#bib.bib3" title="" class="ltx_ref">2017</a>)</cite> for BEA-2019 and GMEG-wiki. Table <a href="#S3.T4" title="Table 4 ‣ 3.1 Statistical Analysis ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that GEC models trained on ChatLang-8 can surpass its counterparts which are trained on Lang-8 corpus, by a large margin in both recall (<span id="S3.SS2.p1.4.5" class="ltx_text ltx_font_bold">R</span>) and <span id="S3.SS2.p1.2.1" class="ltx_text ltx_font_bold">F<sub id="S3.SS2.p1.2.1.1" class="ltx_sub"><span id="S3.SS2.p1.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">0.5</span></sub></span>. It represents that the GEC system trained with ChatLang-8 can simultaneously detect multiple types grammatical errors in a sentence and correct them, while system trained with Lang-8 can’t. Simply a high <span id="S3.SS2.p1.4.6" class="ltx_text ltx_font_bold">R</span> and a low <span id="S3.SS2.p1.3.2" class="ltx_text ltx_font_bold">F<sub id="S3.SS2.p1.3.2.1" class="ltx_sub"><span id="S3.SS2.p1.3.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">0.5</span></sub></span> indicate overcorrection. We observe that transformer learned with Lang-8 shows higher precision (<span id="S3.SS2.p1.4.7" class="ltx_text ltx_font_bold">P</span>) than its counterpart on CoNLL-2014 and BEA-2019 benchmark evaluations, entailing much lower <span id="S3.SS2.p1.4.3" class="ltx_text ltx_font_bold">F<sub id="S3.SS2.p1.4.3.1" class="ltx_sub"><span id="S3.SS2.p1.4.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">0.5</span></sub></span>. This means that it corrects only very obvious grammatical errors and leaves the rest uncorrected. We also find that leveraging a high-quality GEC corpus is overarching problem, as merely enlarging the model does not always ensure improved performance.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2406.03202/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="65" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Subject distribution of ChatLang-8.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2406.03202/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Distributions of the ChatLang-8 and the other datasets with respect to 25 grammatical errors.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Qualitative Results</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Figure <a href="#S3.F2" title="Figure 2 ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows an example and its corresponding M<sup id="S3.SS3.p1.1.1" class="ltx_sup">2</sup> outputs, which qualitatively demonstrate the effect of dataset used for training, as shown in Section <a href="#S3.SS2" title="3.2 Quantitative Results ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. We observe that the learned model using ChatLang-8 can detect and correct multiple errors including punctuation (PUNCT), orthography (ORTH), and conjunction (CONJ) while its opponent can not find any errors. Indeed, the output of model learned with ChatLang-8 is <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">In India, we have various types of public transport, like Cycle, Bike, Car, Train, and Flight</span>. Results in Figure <a href="#S3.F2" title="Figure 2 ‣ 3 Experiments ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates that ChatLang-8 has the error distribution shown in Table <a href="#A2.T5" title="Table 5 ‣ Appendix B Architecture ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> very well, and thereby efficiently helps the learning of the GEC system.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We propose a framework with a hypothesize that determining the quality of dataset is the types of subject and grammatical error. We introduce that ChatLang-8, a high-quality dataset for GEC task that is composed of 1M pairs and covers eight subject type and 23 grammar type. We are the first to build a GEC dataset using ChatGPT and verify it outperforms existing corpora. We hope that our method and dataset can help researchers make a better-informed decision about their research.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Factuality and Morality.</span> Though ChatLang-8 effectively can reflect a distribution of human-like grammatical errors in Figure <a href="#A2.T5" title="Table 5 ‣ Appendix B Architecture ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and guide a GEC model to perform well, due to uniform randomness of our method to encourage diversity, sometimes generated pairs have information that is literally not true. For instance, in Section <a href="#S2.SS1" title="2.1 Subject Selector ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, Subject Selector, of course, can generate celebrity (e.g., <span id="Sx1.p1.1.2" class="ltx_text ltx_font_italic">Michael Jackson</span> or <span id="Sx1.p1.1.3" class="ltx_text ltx_font_italic">Taylor Swift</span>), or even company name (e.g., <span id="Sx1.p1.1.4" class="ltx_text ltx_font_italic">Google</span> or <span id="Sx1.p1.1.5" class="ltx_text ltx_font_italic">Amazon</span>). By combining the selected subject and grammatical information, sentences that are not true can be generated as follows:</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<blockquote id="Sx1.p2.1" class="ltx_quote">
<p id="Sx1.p2.1.1" class="ltx_p"><span id="Sx1.p2.1.1.1" class="ltx_text ltx_font_italic">Michael Jackson was known for his music career, in order that he could be more successful, he decided to try his hand at acting.
<br class="ltx_break">
<br class="ltx_break">Taylor Swift is really good at using a computer.</span></p>
</blockquote>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">In addition, the generated sentences may contain biased information such as subjective opinions:</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<blockquote id="Sx1.p4.1" class="ltx_quote">
<p id="Sx1.p4.1.1" class="ltx_p"><span id="Sx1.p4.1.1.1" class="ltx_text ltx_font_italic">Barack Obama’s speeches were always inspiring the crowds.
<br class="ltx_break">
<br class="ltx_break">Google is the best search engine in the world.</span></p>
</blockquote>
</div>
<div id="Sx1.p5" class="ltx_para">
<p id="Sx1.p5.1" class="ltx_p">Note that, although most of pairs are normal and fabricated information is found in some generated examples, this factuality problem must be resolved.</p>
</div>
<div id="Sx1.p6" class="ltx_para">
<p id="Sx1.p6.1" class="ltx_p">On the other hand, we also observed whether ChatLang-8 has a problem with moral deviations. Fortunately, no morality issue was found in most of the pairs constituting ChatLang-8:</p>
</div>
<div id="Sx1.p7" class="ltx_para">
<blockquote id="Sx1.p7.1" class="ltx_quote">
<p id="Sx1.p7.1.1" class="ltx_p"><span id="Sx1.p7.1.1.1" class="ltx_text ltx_font_italic">The equality between races, genders, and sexual orientations is important.
<br class="ltx_break">
<br class="ltx_break">The importance of maintaining equality among all genders is evident in society.</span></p>
</blockquote>
</div>
<div id="Sx1.p8" class="ltx_para">
<p id="Sx1.p8.1" class="ltx_p">However, we found one sentence and removed from ChatLang-8:</p>
</div>
<div id="Sx1.p9" class="ltx_para">
<blockquote id="Sx1.p9.1" class="ltx_quote">
<p id="Sx1.p9.1.1" class="ltx_p"><span id="Sx1.p9.1.1.1" class="ltx_text ltx_font_italic">The equality of the sexes is not a big issue.</span></p>
</blockquote>
</div>
<div id="Sx1.p10" class="ltx_para">
<p id="Sx1.p10.1" class="ltx_p">These observations suggest that semantic information as well as grammatical information of the generated sentence should be added to the evaluation criteria of our Evaluator.</p>
</div>
<div id="Sx1.p11" class="ltx_para">
<p id="Sx1.p11.1" class="ltx_p"><span id="Sx1.p11.1.1" class="ltx_text ltx_font_bold">Time and Cost.</span> As mentioned in Section <a href="#S2.SS5" title="2.5 Dataset Details ‣ 2 ChatLang-8 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.5</span></a>, Our implementation utilizes gpt3.5-turbo version of ChatGPT. It took about two weeks to gather ChatLang-8. To collect 1M pairs dataset, we spent about 1.1K <span id="Sx1.p11.1.2" class="ltx_text ltx_font_italic">dollars</span>. However, It should be noted that the cost was higher than expected because some pairs are discarded by Evaluator. Evaluator disposed of about 0.7M sentences out of a total of 1.7M generated sentences. We consider that though it is much more efficient than having annotators create the dataset, this a great waste of time and resources. Also, there is a trade-off in our framework: The larger window size, the more diverse and high-quality dataset can be obtained, but the time and cost to create dataset increases accordingly.</p>
</div>
<div id="Sx1.p12" class="ltx_para">
<p id="Sx1.p12.1" class="ltx_p"><span id="Sx1.p12.1.1" class="ltx_text ltx_font_bold">Discussion and Future Works.</span> In this paper, we strived to validate the ability of LLM to generate datasets. Of course, efficient dataset acquisition and model training are important challenges in the GEC task, but in fact, we also wanted to know what information is important and should be considered in Natural language generation in order to improve quality of outputs generated by LLM. We hope that this study and its results will be helpful to researchers who have the same concerns as us.</p>
</div>
<div id="Sx1.p13" class="ltx_para">
<p id="Sx1.p13.1" class="ltx_p">Our direction of future work is threefold:</p>
</div>
<div id="Sx1.p14" class="ltx_para">
<ol id="Sx1.I1" class="ltx_enumerate">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">We will establish new criteria for factuality and morality, and improve the evaluator through methods such as giving penalties for the generated results that violate the criteria.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">We also will devise methods such as soft alignment to minimize the amount of data discarded by Evaluator to prevent resource waste.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">Though we conducted an in-depth analysis through statistical, quantitative, and qualitative methods, we relied on LLM for data collection, leaving human evaluation behind. We will experiment with more off-the-shelf baselines by increasing the size of the corpus, and human evaluation will also be conducted on the generated results.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">There are no ethical issues in this study. The data was collected through legitimate methods. Moreover, the experimental results were obtained through an objective comparison. The authors confirm that the research was conducted in accordance with the relevant ethical guidelines and principles.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang et al. (2023)</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.04023</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bryant et al. (2019)</span>
<span class="ltx_bibblock">
Christopher Bryant, Mariano Felice, Øistein E. Andersen, and Ted Briscoe. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W19-4406" title="" class="ltx_ref ltx_href">The BEA-2019 shared task on grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 52–75, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bryant et al. (2017)</span>
<span class="ltx_bibblock">
Christopher Bryant, Mariano Felice, and Ted Briscoe. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1074" title="" class="ltx_ref ltx_href">Automatic annotation and evaluation of error types for grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 793–805, Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahlmeier and Ng (2012)</span>
<span class="ltx_bibblock">
Daniel Dahlmeier and Hwee Tou Ng. 2012.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/N12-1067" title="" class="ltx_ref ltx_href">Better evaluation for grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 568–572, Montréal, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahlmeier et al. (2013)</span>
<span class="ltx_bibblock">
Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu. 2013.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/W13-1703" title="" class="ltx_ref ltx_href">Building a large annotated corpus of learner English: The NUS corpus of learner English</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 22–31, Atlanta, Georgia. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2023)</span>
<span class="ltx_bibblock">
Tao Fang, Shu Yang, Kaixin Lan, Derek F Wong, Jinpeng Hu, Lidia S Chao, and Yue Zhang. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01746</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Flachs et al. (2021)</span>
<span class="ltx_bibblock">
Simon Flachs, Felix Stahlberg, and Shankar Kumar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.bea-1.12" title="" class="ltx_ref ltx_href">Data strategies for low-resource grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 117–122, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grammarly (2023)</span>
<span class="ltx_bibblock">
Grammarly. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.grammarly.com/about" title="" class="ltx_ref ltx_href">Grammarly website about us page</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grundkiewicz and Junczys-Dowmunt (2014)</span>
<span class="ltx_bibblock">
Roman Grundkiewicz and Marcin Junczys-Dowmunt. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.microsoft.com/en-us/research/publication/wiked-error-corpus-corpus-corrective-wikipedia-edits-application-grammatical-error-correction/" title="" class="ltx_ref ltx_href">The wiked error corpus: A corpus of corrective wikipedia edits and its application to grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Conference on Natural Language Processing</em>, pages 478–490.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2021)</span>
<span class="ltx_bibblock">
Yi Huang, Buse Giledereli, Abdullatif Köksal, Arzucan Özgür, and Elif Ozkirimli. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.643" title="" class="ltx_ref ltx_href">Balancing methods for multi-label text classification with long-tailed class distribution</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 8153–8161, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiao et al. (2023)</span>
<span class="ltx_bibblock">
Wenxiang Jiao, Wenxuan Wang, JT Huang, Xing Wang, and ZP Tu. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt a good translator? yes with gpt-4 as the engine.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.08745</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="" class="ltx_ref ltx_href">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7871–7880, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Shi (2021)</span>
<span class="ltx_bibblock">
Piji Li and Shuming Shi. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-long.385" title="" class="ltx_ref ltx_href">Tail-to-tail non-autoregressive sequence prediction for Chinese grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 4973–4984, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lichtarge et al. (2020)</span>
<span class="ltx_bibblock">
Jared Lichtarge, Chris Alberti, and Shankar Kumar. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00336" title="" class="ltx_ref ltx_href">Data weighted training strategies for grammatical error correction</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 8:634–646.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lichtarge et al. (2019)</span>
<span class="ltx_bibblock">
Jared Lichtarge, Chris Alberti, Shankar Kumar, Noam Shazeer, Niki Parmar, and Simon Tong. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1333" title="" class="ltx_ref ltx_href">Corpora generation for grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 3291–3301, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
Jionghao Lin, Wei Tan, Ngoc Dang Nguyen, David Lang, Lan Du, Wray Buntine, Richard Beare, Guanliang Chen, and Dragan Gasevic. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2304.07499" title="" class="ltx_ref ltx_href">Robust educational dialogue act classifiers with low-resource and imbalanced datasets</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mizumoto et al. (2012)</span>
<span class="ltx_bibblock">
Tomoya Mizumoto, Yuta Hayashibe, Mamoru Komachi, Masaaki Nagata, and Yuji Matsumoto. 2012.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/C12-2084" title="" class="ltx_ref ltx_href">The effect of learner corpus size in grammatical error correction of ESL writings</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of COLING 2012: Posters</em>, pages 863–872, Mumbai, India. The COLING 2012 Organizing Committee.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Napoles et al. (2019)</span>
<span class="ltx_bibblock">
Courtney Napoles, Maria Nădejde, and Joel Tetreault. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00282" title="" class="ltx_ref ltx_href">Enabling robust grammatical error correction in new domains: Data sets, metrics, and analyses</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 7:551–566.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng et al. (2014)</span>
<span class="ltx_bibblock">
Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian Hadiwinoto, Raymond Hendy Susanto, and Christopher Bryant. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/W14-1701" title="" class="ltx_ref ltx_href">The CoNLL-2014 shared task on grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task</em>, pages 1–14, Baltimore, Maryland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">O’Donnell et al. (2011)</span>
<span class="ltx_bibblock">
Timothy O’Donnell, Jesse Snedeker, Joshua Tenenbaum, and Noah Goodman. 2011.

</span>
<span class="ltx_bibblock">Productivity and reuse in language.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Meeting of the Cognitive Science Society</em>, volume 33.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Omar et al. (2023)</span>
<span class="ltx_bibblock">
Reham Omar, Omij Mangukiya, Panos Kalnis, and Essam Mansour. 2023.

</span>
<span class="ltx_bibblock">Chatgpt versus traditional question answering for knowledge graphs: Current status and future directions towards knowledge graph chatbots.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.06466</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Omelianchuk et al. (2020)</span>
<span class="ltx_bibblock">
Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, and Oleksandr Skurzhanskyi. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.bea-1.16" title="" class="ltx_ref ltx_href">GECToR – grammatical error correction: Tag, not rewrite</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 163–170, Seattle, WA, USA → Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2303.08774" title="" class="ltx_ref ltx_href">Gpt-4 technical report</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://platform.openai.com/docs/assistants/overview" title="" class="ltx_ref ltx_href">no date provided. introducing assistants api</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023c)</span>
<span class="ltx_bibblock">
OpenAI. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/blog/chatgpt" title="" class="ltx_ref ltx_href">no date provided. introducing chatgpt</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rothe et al. (2021)</span>
<span class="ltx_bibblock">
Sascha Rothe, Jonathan Mallinson, Eric Malmi, Sebastian Krause, and Aliaksei Severyn. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-short.89" title="" class="ltx_ref ltx_href">A simple recipe for multilingual grammatical error correction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</em>, pages 702–707, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stahlberg and Kumar (2021)</span>
<span class="ltx_bibblock">
Felix Stahlberg and Shankar Kumar. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.bea-1.4" title="" class="ltx_ref ltx_href">Synthetic data generation for grammatical error correction with tagged corruption models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</em>, pages 37–47, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tajiri et al. (2012)</span>
<span class="ltx_bibblock">
Toshikazu Tajiri, Mamoru Komachi, and Yuji Matsumoto. 2012.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P12-2039" title="" class="ltx_ref ltx_href">Tense and aspect error correction for ESL learners using global context</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 198–202, Jeju Island, Korea. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="" class="ltx_ref ltx_href">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Chain of thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2201.11903.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, and Michael Lyu. 2023.

</span>
<span class="ltx_bibblock">Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.13648</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Xianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, and Wei Cheng. 2023.

</span>
<span class="ltx_bibblock">Exploring the limits of chatgpt for query or aspect-based text summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.08081</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yannakoudakis et al. (2011)</span>
<span class="ltx_bibblock">
Helen Yannakoudakis, Ted Briscoe, and Ben Medlock. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P11-1019" title="" class="ltx_ref ltx_href">A new dataset and method for automatically grading ESOL texts</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em>, pages 180–189, Portland, Oregon, USA. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A0.F5" class="ltx_figure"><img src="/html/2406.03202/assets/x5.png" id="A0.F5.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="738" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Schematic depiction of overall architecture</figcaption>
</figure>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Statistical Analysis: Error Type Distributions</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Table <a href="#A2.T5" title="Table 5 ‣ Appendix B Architecture ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the ERRANT error type distributions of ChatLang-8 and The Other Corpora. We find that ChatLang-8 are most evenly distributed while the other corpora have highly unbalanced grammar labels.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Architecture</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">As shown in Figure <a href="#A0.F5" title="Figure 5 ‣ ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, our framework consists of Subject Selector, Grammar Selector, Prompt Manager, and Evaluator. Subject Selector and Grammar Selector ensure the diversity of the generated data, Prompt Manager maintains the format of the generated data, and Evaluator manages the quality of the generated data.</p>
</div>
<figure id="A2.T5" class="ltx_table">
<div id="A2.T5.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:339.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-94.6pt,73.8pt) scale(0.696297353703405,0.696297353703405) ;">
<table id="A2.T5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A2.T5.1.1.1" class="ltx_tr">
<td id="A2.T5.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="A2.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">ChatLang-8</td>
<td id="A2.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">FCE</td>
<td id="A2.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Lang-8</td>
<td id="A2.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">NUCLE</td>
<td id="A2.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">W&amp;I+LOCNESS (Train)</td>
<td id="A2.T5.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">W&amp;I+LOCNESS (Dev)</td>
<td id="A2.T5.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">W&amp;I+LOCNESS (Test)</td>
</tr>
<tr id="A2.T5.1.1.2" class="ltx_tr">
<td id="A2.T5.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">ADJ</td>
<td id="A2.T5.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.44</td>
<td id="A2.T5.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1.36</td>
<td id="A2.T5.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1.25</td>
<td id="A2.T5.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">1.58</td>
<td id="A2.T5.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">1.52</td>
<td id="A2.T5.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">1.48</td>
<td id="A2.T5.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">1.05</td>
</tr>
<tr id="A2.T5.1.1.3" class="ltx_tr">
<td id="A2.T5.1.1.3.1" class="ltx_td ltx_align_left">ADJ:FORM</td>
<td id="A2.T5.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r">3.26</td>
<td id="A2.T5.1.1.3.3" class="ltx_td ltx_align_center">0.28</td>
<td id="A2.T5.1.1.3.4" class="ltx_td ltx_align_center">0.19</td>
<td id="A2.T5.1.1.3.5" class="ltx_td ltx_align_center">0.27</td>
<td id="A2.T5.1.1.3.6" class="ltx_td ltx_align_center">0.24</td>
<td id="A2.T5.1.1.3.7" class="ltx_td ltx_align_center">0.21</td>
<td id="A2.T5.1.1.3.8" class="ltx_td ltx_align_center">0.18</td>
</tr>
<tr id="A2.T5.1.1.4" class="ltx_tr">
<td id="A2.T5.1.1.4.1" class="ltx_td ltx_align_left">ADV</td>
<td id="A2.T5.1.1.4.2" class="ltx_td ltx_align_center ltx_border_r">1.55</td>
<td id="A2.T5.1.1.4.3" class="ltx_td ltx_align_center">1.94</td>
<td id="A2.T5.1.1.4.4" class="ltx_td ltx_align_center">3.37</td>
<td id="A2.T5.1.1.4.5" class="ltx_td ltx_align_center">1.95</td>
<td id="A2.T5.1.1.4.6" class="ltx_td ltx_align_center">1.51</td>
<td id="A2.T5.1.1.4.7" class="ltx_td ltx_align_center">1.51</td>
<td id="A2.T5.1.1.4.8" class="ltx_td ltx_align_center">1.45</td>
</tr>
<tr id="A2.T5.1.1.5" class="ltx_tr">
<td id="A2.T5.1.1.5.1" class="ltx_td ltx_align_left">CONJ</td>
<td id="A2.T5.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r">8.18</td>
<td id="A2.T5.1.1.5.3" class="ltx_td ltx_align_center">0.67</td>
<td id="A2.T5.1.1.5.4" class="ltx_td ltx_align_center">0.98</td>
<td id="A2.T5.1.1.5.5" class="ltx_td ltx_align_center">0.71</td>
<td id="A2.T5.1.1.5.6" class="ltx_td ltx_align_center">0.51</td>
<td id="A2.T5.1.1.5.7" class="ltx_td ltx_align_center">0.58</td>
<td id="A2.T5.1.1.5.8" class="ltx_td ltx_align_center">0.75</td>
</tr>
<tr id="A2.T5.1.1.6" class="ltx_tr">
<td id="A2.T5.1.1.6.1" class="ltx_td ltx_align_left">CONTR</td>
<td id="A2.T5.1.1.6.2" class="ltx_td ltx_align_center ltx_border_r">2.44</td>
<td id="A2.T5.1.1.6.3" class="ltx_td ltx_align_center">0.32</td>
<td id="A2.T5.1.1.6.4" class="ltx_td ltx_align_center">0.99</td>
<td id="A2.T5.1.1.6.5" class="ltx_td ltx_align_center">0.11</td>
<td id="A2.T5.1.1.6.6" class="ltx_td ltx_align_center">0.3</td>
<td id="A2.T5.1.1.6.7" class="ltx_td ltx_align_center">0.39</td>
<td id="A2.T5.1.1.6.8" class="ltx_td ltx_align_center">0.32</td>
</tr>
<tr id="A2.T5.1.1.7" class="ltx_tr">
<td id="A2.T5.1.1.7.1" class="ltx_td ltx_align_left">DET</td>
<td id="A2.T5.1.1.7.2" class="ltx_td ltx_align_center ltx_border_r">2.51</td>
<td id="A2.T5.1.1.7.3" class="ltx_td ltx_align_center">10.86</td>
<td id="A2.T5.1.1.7.4" class="ltx_td ltx_align_center">11.93</td>
<td id="A2.T5.1.1.7.5" class="ltx_td ltx_align_center">15.98</td>
<td id="A2.T5.1.1.7.6" class="ltx_td ltx_align_center">11.25</td>
<td id="A2.T5.1.1.7.7" class="ltx_td ltx_align_center">10.43</td>
<td id="A2.T5.1.1.7.8" class="ltx_td ltx_align_center">10.41</td>
</tr>
<tr id="A2.T5.1.1.8" class="ltx_tr">
<td id="A2.T5.1.1.8.1" class="ltx_td ltx_align_left">MORTH</td>
<td id="A2.T5.1.1.8.2" class="ltx_td ltx_align_center ltx_border_r">3.73</td>
<td id="A2.T5.1.1.8.3" class="ltx_td ltx_align_center">1.9</td>
<td id="A2.T5.1.1.8.4" class="ltx_td ltx_align_center">1.62</td>
<td id="A2.T5.1.1.8.5" class="ltx_td ltx_align_center">3.14</td>
<td id="A2.T5.1.1.8.6" class="ltx_td ltx_align_center">1.85</td>
<td id="A2.T5.1.1.8.7" class="ltx_td ltx_align_center">2.07</td>
<td id="A2.T5.1.1.8.8" class="ltx_td ltx_align_center">2.5</td>
</tr>
<tr id="A2.T5.1.1.9" class="ltx_tr">
<td id="A2.T5.1.1.9.1" class="ltx_td ltx_align_left">NOUN</td>
<td id="A2.T5.1.1.9.2" class="ltx_td ltx_align_center ltx_border_r">1.46</td>
<td id="A2.T5.1.1.9.3" class="ltx_td ltx_align_center">4.57</td>
<td id="A2.T5.1.1.9.4" class="ltx_td ltx_align_center">4.51</td>
<td id="A2.T5.1.1.9.5" class="ltx_td ltx_align_center">3.8</td>
<td id="A2.T5.1.1.9.6" class="ltx_td ltx_align_center">4.36</td>
<td id="A2.T5.1.1.9.7" class="ltx_td ltx_align_center">4.3</td>
<td id="A2.T5.1.1.9.8" class="ltx_td ltx_align_center">2.89</td>
</tr>
<tr id="A2.T5.1.1.10" class="ltx_tr">
<td id="A2.T5.1.1.10.1" class="ltx_td ltx_align_left">NOUN:INFL</td>
<td id="A2.T5.1.1.10.2" class="ltx_td ltx_align_center ltx_border_r">3.69</td>
<td id="A2.T5.1.1.10.3" class="ltx_td ltx_align_center">0.5</td>
<td id="A2.T5.1.1.10.4" class="ltx_td ltx_align_center">0.18</td>
<td id="A2.T5.1.1.10.5" class="ltx_td ltx_align_center">0.12</td>
<td id="A2.T5.1.1.10.6" class="ltx_td ltx_align_center">0.12</td>
<td id="A2.T5.1.1.10.7" class="ltx_td ltx_align_center">0.13</td>
<td id="A2.T5.1.1.10.8" class="ltx_td ltx_align_center">0.28</td>
</tr>
<tr id="A2.T5.1.1.11" class="ltx_tr">
<td id="A2.T5.1.1.11.1" class="ltx_td ltx_align_left">NOUN:NUM</td>
<td id="A2.T5.1.1.11.2" class="ltx_td ltx_align_center ltx_border_r">4.03</td>
<td id="A2.T5.1.1.11.3" class="ltx_td ltx_align_center">3.34</td>
<td id="A2.T5.1.1.11.4" class="ltx_td ltx_align_center">4.28</td>
<td id="A2.T5.1.1.11.5" class="ltx_td ltx_align_center">8.13</td>
<td id="A2.T5.1.1.11.6" class="ltx_td ltx_align_center">4.05</td>
<td id="A2.T5.1.1.11.7" class="ltx_td ltx_align_center">3.29</td>
<td id="A2.T5.1.1.11.8" class="ltx_td ltx_align_center">4.07</td>
</tr>
<tr id="A2.T5.1.1.12" class="ltx_tr">
<td id="A2.T5.1.1.12.1" class="ltx_td ltx_align_left">NOUN:POSS</td>
<td id="A2.T5.1.1.12.2" class="ltx_td ltx_align_center ltx_border_r">3.83</td>
<td id="A2.T5.1.1.12.3" class="ltx_td ltx_align_center">0.51</td>
<td id="A2.T5.1.1.12.4" class="ltx_td ltx_align_center">0.35</td>
<td id="A2.T5.1.1.12.5" class="ltx_td ltx_align_center">0.61</td>
<td id="A2.T5.1.1.12.6" class="ltx_td ltx_align_center">0.6</td>
<td id="A2.T5.1.1.12.7" class="ltx_td ltx_align_center">0.87</td>
<td id="A2.T5.1.1.12.8" class="ltx_td ltx_align_center">0.93</td>
</tr>
<tr id="A2.T5.1.1.13" class="ltx_tr">
<td id="A2.T5.1.1.13.1" class="ltx_td ltx_align_left">ORTH</td>
<td id="A2.T5.1.1.13.2" class="ltx_td ltx_align_center ltx_border_r">7.56</td>
<td id="A2.T5.1.1.13.3" class="ltx_td ltx_align_center">2.94</td>
<td id="A2.T5.1.1.13.4" class="ltx_td ltx_align_center">3.99</td>
<td id="A2.T5.1.1.13.5" class="ltx_td ltx_align_center">1.62</td>
<td id="A2.T5.1.1.13.6" class="ltx_td ltx_align_center">4.77</td>
<td id="A2.T5.1.1.13.7" class="ltx_td ltx_align_center">4.61</td>
<td id="A2.T5.1.1.13.8" class="ltx_td ltx_align_center">8.03</td>
</tr>
<tr id="A2.T5.1.1.14" class="ltx_tr">
<td id="A2.T5.1.1.14.1" class="ltx_td ltx_align_left">OTHER</td>
<td id="A2.T5.1.1.14.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A2.T5.1.1.14.3" class="ltx_td ltx_align_center">13.26</td>
<td id="A2.T5.1.1.14.4" class="ltx_td ltx_align_center">26.62</td>
<td id="A2.T5.1.1.14.5" class="ltx_td ltx_align_center">25.65</td>
<td id="A2.T5.1.1.14.6" class="ltx_td ltx_align_center">12.76</td>
<td id="A2.T5.1.1.14.7" class="ltx_td ltx_align_center">12.84</td>
<td id="A2.T5.1.1.14.8" class="ltx_td ltx_align_center">15.69</td>
</tr>
<tr id="A2.T5.1.1.15" class="ltx_tr">
<td id="A2.T5.1.1.15.1" class="ltx_td ltx_align_left">PART</td>
<td id="A2.T5.1.1.15.2" class="ltx_td ltx_align_center ltx_border_r">3.83</td>
<td id="A2.T5.1.1.15.3" class="ltx_td ltx_align_center">0.29</td>
<td id="A2.T5.1.1.15.4" class="ltx_td ltx_align_center">0.5</td>
<td id="A2.T5.1.1.15.5" class="ltx_td ltx_align_center">0.46</td>
<td id="A2.T5.1.1.15.6" class="ltx_td ltx_align_center">0.84</td>
<td id="A2.T5.1.1.15.7" class="ltx_td ltx_align_center">0.79</td>
<td id="A2.T5.1.1.15.8" class="ltx_td ltx_align_center">0.49</td>
</tr>
<tr id="A2.T5.1.1.16" class="ltx_tr">
<td id="A2.T5.1.1.16.1" class="ltx_td ltx_align_left">PREP</td>
<td id="A2.T5.1.1.16.2" class="ltx_td ltx_align_center ltx_border_r">3.18</td>
<td id="A2.T5.1.1.16.3" class="ltx_td ltx_align_center">11.21</td>
<td id="A2.T5.1.1.16.4" class="ltx_td ltx_align_center">8</td>
<td id="A2.T5.1.1.16.5" class="ltx_td ltx_align_center">7.69</td>
<td id="A2.T5.1.1.16.6" class="ltx_td ltx_align_center">9.79</td>
<td id="A2.T5.1.1.16.7" class="ltx_td ltx_align_center">9.7</td>
<td id="A2.T5.1.1.16.8" class="ltx_td ltx_align_center">8.33</td>
</tr>
<tr id="A2.T5.1.1.17" class="ltx_tr">
<td id="A2.T5.1.1.17.1" class="ltx_td ltx_align_left">PRON</td>
<td id="A2.T5.1.1.17.2" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="A2.T5.1.1.17.3" class="ltx_td ltx_align_center">3.51</td>
<td id="A2.T5.1.1.17.4" class="ltx_td ltx_align_center">2.72</td>
<td id="A2.T5.1.1.17.5" class="ltx_td ltx_align_center">1.26</td>
<td id="A2.T5.1.1.17.6" class="ltx_td ltx_align_center">2.64</td>
<td id="A2.T5.1.1.17.7" class="ltx_td ltx_align_center">2.33</td>
<td id="A2.T5.1.1.17.8" class="ltx_td ltx_align_center">2.45</td>
</tr>
<tr id="A2.T5.1.1.18" class="ltx_tr">
<td id="A2.T5.1.1.18.1" class="ltx_td ltx_align_left">PUNCT</td>
<td id="A2.T5.1.1.18.2" class="ltx_td ltx_align_center ltx_border_r">2.33</td>
<td id="A2.T5.1.1.18.3" class="ltx_td ltx_align_center">9.71</td>
<td id="A2.T5.1.1.18.4" class="ltx_td ltx_align_center">6.06</td>
<td id="A2.T5.1.1.18.5" class="ltx_td ltx_align_center">5.16</td>
<td id="A2.T5.1.1.18.6" class="ltx_td ltx_align_center">17.16</td>
<td id="A2.T5.1.1.18.7" class="ltx_td ltx_align_center">19.37</td>
<td id="A2.T5.1.1.18.8" class="ltx_td ltx_align_center">16.73</td>
</tr>
<tr id="A2.T5.1.1.19" class="ltx_tr">
<td id="A2.T5.1.1.19.1" class="ltx_td ltx_align_left">SPELL</td>
<td id="A2.T5.1.1.19.2" class="ltx_td ltx_align_center ltx_border_r">4.03</td>
<td id="A2.T5.1.1.19.3" class="ltx_td ltx_align_center">9.59</td>
<td id="A2.T5.1.1.19.4" class="ltx_td ltx_align_center">4.45</td>
<td id="A2.T5.1.1.19.5" class="ltx_td ltx_align_center">0.26</td>
<td id="A2.T5.1.1.19.6" class="ltx_td ltx_align_center">3.74</td>
<td id="A2.T5.1.1.19.7" class="ltx_td ltx_align_center">5.07</td>
<td id="A2.T5.1.1.19.8" class="ltx_td ltx_align_center">4.63</td>
</tr>
<tr id="A2.T5.1.1.20" class="ltx_tr">
<td id="A2.T5.1.1.20.1" class="ltx_td ltx_align_left">UNK</td>
<td id="A2.T5.1.1.20.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A2.T5.1.1.20.3" class="ltx_td ltx_align_center">3.13</td>
<td id="A2.T5.1.1.20.4" class="ltx_td ltx_align_center">0</td>
<td id="A2.T5.1.1.20.5" class="ltx_td ltx_align_center">2.57</td>
<td id="A2.T5.1.1.20.6" class="ltx_td ltx_align_center">2.59</td>
<td id="A2.T5.1.1.20.7" class="ltx_td ltx_align_center">2.24</td>
<td id="A2.T5.1.1.20.8" class="ltx_td ltx_align_center">1.41</td>
</tr>
<tr id="A2.T5.1.1.21" class="ltx_tr">
<td id="A2.T5.1.1.21.1" class="ltx_td ltx_align_left">VERB</td>
<td id="A2.T5.1.1.21.2" class="ltx_td ltx_align_center ltx_border_r">6.54</td>
<td id="A2.T5.1.1.21.3" class="ltx_td ltx_align_center">7.01</td>
<td id="A2.T5.1.1.21.4" class="ltx_td ltx_align_center">6.52</td>
<td id="A2.T5.1.1.21.5" class="ltx_td ltx_align_center">4.31</td>
<td id="A2.T5.1.1.21.6" class="ltx_td ltx_align_center">5.86</td>
<td id="A2.T5.1.1.21.7" class="ltx_td ltx_align_center">5.27</td>
<td id="A2.T5.1.1.21.8" class="ltx_td ltx_align_center">5.09</td>
</tr>
<tr id="A2.T5.1.1.22" class="ltx_tr">
<td id="A2.T5.1.1.22.1" class="ltx_td ltx_align_left">VERB:FORM</td>
<td id="A2.T5.1.1.22.2" class="ltx_td ltx_align_center ltx_border_r">5.23</td>
<td id="A2.T5.1.1.22.3" class="ltx_td ltx_align_center">3.55</td>
<td id="A2.T5.1.1.22.4" class="ltx_td ltx_align_center">2.56</td>
<td id="A2.T5.1.1.22.5" class="ltx_td ltx_align_center">3.49</td>
<td id="A2.T5.1.1.22.6" class="ltx_td ltx_align_center">3.56</td>
<td id="A2.T5.1.1.22.7" class="ltx_td ltx_align_center">3.09</td>
<td id="A2.T5.1.1.22.8" class="ltx_td ltx_align_center">3.1</td>
</tr>
<tr id="A2.T5.1.1.23" class="ltx_tr">
<td id="A2.T5.1.1.23.1" class="ltx_td ltx_align_left">VERB:INFL</td>
<td id="A2.T5.1.1.23.2" class="ltx_td ltx_align_center ltx_border_r">12.07</td>
<td id="A2.T5.1.1.23.3" class="ltx_td ltx_align_center">0.19</td>
<td id="A2.T5.1.1.23.4" class="ltx_td ltx_align_center">0.15</td>
<td id="A2.T5.1.1.23.5" class="ltx_td ltx_align_center">0.01</td>
<td id="A2.T5.1.1.23.6" class="ltx_td ltx_align_center">0.04</td>
<td id="A2.T5.1.1.23.7" class="ltx_td ltx_align_center">0.07</td>
<td id="A2.T5.1.1.23.8" class="ltx_td ltx_align_center">0.12</td>
</tr>
<tr id="A2.T5.1.1.24" class="ltx_tr">
<td id="A2.T5.1.1.24.1" class="ltx_td ltx_align_left">VERB:SVA</td>
<td id="A2.T5.1.1.24.2" class="ltx_td ltx_align_center ltx_border_r">0.95</td>
<td id="A2.T5.1.1.24.3" class="ltx_td ltx_align_center">1.52</td>
<td id="A2.T5.1.1.24.4" class="ltx_td ltx_align_center">1.58</td>
<td id="A2.T5.1.1.24.5" class="ltx_td ltx_align_center">3.47</td>
<td id="A2.T5.1.1.24.6" class="ltx_td ltx_align_center">2.23</td>
<td id="A2.T5.1.1.24.7" class="ltx_td ltx_align_center">1.94</td>
<td id="A2.T5.1.1.24.8" class="ltx_td ltx_align_center">2.28</td>
</tr>
<tr id="A2.T5.1.1.25" class="ltx_tr">
<td id="A2.T5.1.1.25.1" class="ltx_td ltx_align_left">VERB:TENSE</td>
<td id="A2.T5.1.1.25.2" class="ltx_td ltx_align_center ltx_border_r">12.6</td>
<td id="A2.T5.1.1.25.3" class="ltx_td ltx_align_center">6.04</td>
<td id="A2.T5.1.1.25.4" class="ltx_td ltx_align_center">6.03</td>
<td id="A2.T5.1.1.25.5" class="ltx_td ltx_align_center">7.01</td>
<td id="A2.T5.1.1.25.6" class="ltx_td ltx_align_center">6.07</td>
<td id="A2.T5.1.1.25.7" class="ltx_td ltx_align_center">6.2</td>
<td id="A2.T5.1.1.25.8" class="ltx_td ltx_align_center">5.43</td>
</tr>
<tr id="A2.T5.1.1.26" class="ltx_tr">
<td id="A2.T5.1.1.26.1" class="ltx_td ltx_align_left">WO</td>
<td id="A2.T5.1.1.26.2" class="ltx_td ltx_align_center ltx_border_r">3.58</td>
<td id="A2.T5.1.1.26.3" class="ltx_td ltx_align_center">1.82</td>
<td id="A2.T5.1.1.26.4" class="ltx_td ltx_align_center">1.18</td>
<td id="A2.T5.1.1.26.5" class="ltx_td ltx_align_center">0.66</td>
<td id="A2.T5.1.1.26.6" class="ltx_td ltx_align_center">1.64</td>
<td id="A2.T5.1.1.26.7" class="ltx_td ltx_align_center">1.25</td>
<td id="A2.T5.1.1.26.8" class="ltx_td ltx_align_center">1.4</td>
</tr>
<tr id="A2.T5.1.1.27" class="ltx_tr">
<td id="A2.T5.1.1.27.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_tt">Total (%)</td>
<td id="A2.T5.1.1.27.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
<td id="A2.T5.1.1.27.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt">100</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Distributions of the ChatLang-8 and the other datasets with respect to 25 grammatical errors.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.03201" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.03202" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.03202">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.03202" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.03203" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 22:00:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
