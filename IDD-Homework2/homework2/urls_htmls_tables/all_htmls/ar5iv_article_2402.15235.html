<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  Multi-Agent Collaboration Framework for Recommender Systems
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Zhefan Wang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">
      DCST, Tsinghua University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id2.2.id2">
      Beijing 100084
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id3.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id4.4.id4">
      100084
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:thuwzf2000@gmail.com">
      thuwzf2000@gmail.com
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yuanqing Yu
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">
      DCST, Tsinghua University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id6.2.id2">
      Beijing 100084
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id7.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id8.4.id4">
      100084
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:yuyq0114@gmail.com">
      yuyq0114@gmail.com
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Wendi Zheng
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">
      DCST, Tsinghua University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id10.2.id2">
      Beijing 100084
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id11.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id12.4.id4">
      100084
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:zhengwd23@mails.tsinghua.edu.cn">
      zhengwd23@mails.tsinghua.edu.cn
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   ,
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Weizhi Ma
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">
      AIR, Tsinghua University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id14.2.id2">
      Beijing 100084
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id15.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id16.4.id4">
      100084
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:mawz@tsinghua.edu.cn">
      mawz@tsinghua.edu.cn
     </a>
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
   and
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Min Zhang
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">
      DCST, Tsinghua University
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id18.2.id2">
      Beijing 100084
     </span>
     <span class="ltx_text ltx_affiliation_country" id="id19.3.id3">
      China
     </span>
     <span class="ltx_text ltx_affiliation_postcode" id="id20.4.id4">
      100084
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:z-m@tsinghua.edu.cn">
      z-m@tsinghua.edu.cn
     </a>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_dates">
  (2018)
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id21.id1">
   LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks.
Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce
   <span class="ltx_text ltx_font_bold" id="id21.id1.1">
    MACRec
   </span>
   , a novel framework designed to enhance recommendation systems through multi-agent collaboration.
Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly.
In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including
   <span class="ltx_text ltx_font_slanted" id="id21.id1.2">
    Manager
   </span>
   ,
   <span class="ltx_text ltx_font_slanted" id="id21.id1.3">
    User/Item Analyst
   </span>
   ,
   <span class="ltx_text ltx_font_slanted" id="id21.id1.4">
    Reflector
   </span>
   ,
   <span class="ltx_text ltx_font_slanted" id="id21.id1.5">
    Searcher
   </span>
   , and
   <span class="ltx_text ltx_font_slanted" id="id21.id1.6">
    Task Interpreter
   </span>
   , with different working flows.
Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation,
and explanation generation of recommendation results.
The framework and demonstration video are publicly available at https://github.com/wzf2000/MACRec.
  </p>
 </div>
 <span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     copyright:
    </span>
    acmcopyright
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journalyear:
    </span>
    2018
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     doi:
    </span>
    XXXXXXX.XXXXXXX
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     conference:
    </span>
    Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_price" id="id5">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     price:
    </span>
    15.00
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     isbn:
    </span>
    978-1-4503-XXXX-X/18/06
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Recommender systems (RSs) play a vital role in improving user experience and platform economic benefits, which have become an essential part of various domains, such as e-commerce, social media, and so on.
Currently, the advancement of Large Language Models (LLMs)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2020
     </a>
     ; OpenAI,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2023
     </a>
     ; Touvron et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023
     </a>
     ; Zeng et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2022
     </a>
     )
    </cite>
    has introduced LLM-based agents
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2022
     </a>
     ; Nakano et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2021
     </a>
     ; Shen et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib11" title="">
      2023
     </a>
     )
    </cite>
    capable of completing complex tasks. These agents’ semantic understanding, planning, and decision-making skills unlock new potentials for more nuanced and context-aware recommendations.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Researchers have started to utilize the capabilities of agents to solve recommendation tasks.
Existing work like
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib22" title="">
      2023c
     </a>
     ; Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023b
     </a>
     ; Zhang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023b
     </a>
     )
    </cite>
    primarily focuses on employing agents for simulating user or item behaviors, providing insights into user preferences but falling short of integration into RSs.
On the other hand, some studies
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2023a
     </a>
     ; Huang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2023
     </a>
     )
    </cite>
    attempt to leverage the capabilities of agents to directly build a recommender, primarily using one single agent with planning and memory components and auxiliary tools (e.g., search engine).
However, there are various complex decision-making tasks in recommendation scenarios, on which single-agent instances are unable to perform well.
Multi-agent collaboration, which is near to human workflows, is believed to accomplish complex tasks better with collective intelligence.
Although work
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2023
     </a>
     )
    </cite>
    proposes a multi-agent recommendation framework, it only has limited agent types and a fixed collaboration mode.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    To better unleash the potential of multi-agent collaboration for recommendation tasks, we propose
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">
     MACRec
    </span>
    , a novel
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">
     M
    </span>
    ulti-
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">
     A
    </span>
    gent
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">
     C
    </span>
    ollaboration framework for recommender systems, designed to harness the diverse capabilities of each agent.
Notably, this framework differs from studies for simulation with agents but focuses on building a recommender directly.
MACRec provides customizable agents with abilities powered by LLMs and useful tools. For example, we offer
    <span class="ltx_text ltx_font_slanted" id="S1.p3.1.5">
     Manager
    </span>
    to plan and manage task execution,
    <span class="ltx_text ltx_font_slanted" id="S1.p3.1.6">
     Reflector
    </span>
    to reflect on previous errors,
    <span class="ltx_text ltx_font_slanted" id="S1.p3.1.7">
     User/Item Analysts
    </span>
    to analyze user/item characteristics,
    <span class="ltx_text ltx_font_slanted" id="S1.p3.1.8">
     Searcher
    </span>
    to search more information using the search tool, and
    <span class="ltx_text ltx_font_slanted" id="S1.p3.1.9">
     Task Interpreter
    </span>
    to translate the dialogs into executable recommendation tasks.
These agents with different roles work collaboratively to tackle a specific recommendation task.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    Additionally, we provide application examples to use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation,
and explanation generation of recommendation results.
Considering the varying requirements for agents in different scenarios, we showcase examples of selecting and customizing agents to collaborate on diverse recommendation tasks.
Furthermore, we developed an online web interface for our MACRec, providing a user-friendly visualization of the agents’ collaboration process.
The main strengths of this work can be summarized as follows:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">
        A New Multi-agent Collaboration Framework for Recommendation.
       </span>
       Unlike previous studies focused on user/item simulation with agents, we propose a new multi-agent collaboration framework for recommendation
       <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.2">
        MACRec
       </span>
       . In this framework, agents with different abilities, work collaboratively are involved to tackle specific recommendation tasks.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">
        Diverse Applications on Recommendation Scenarios.
       </span>
       We present application examples on various recommendation scenarios, including rating prediction, sequential recommendation, explanation generation,
and conversational recommendation.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">
        A User-friendly Online Web Interface.
       </span>
       We developed an online web interface for MACRec, visualizing how agents collaboratively tackle tasks.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1.
    </span>
    Comparison between previous work and our MACRec. Note that
    <span class="ltx_text ltx_font_slanted" id="S1.T1.3.1">
     Single-type Agents
    </span>
    indicate all agents serve the same role (e.g., users), while
    <span class="ltx_text ltx_font_slanted" id="S1.T1.4.2">
     Multi-type Agents
    </span>
    refer to agents having multiple roles and capabilities (e.g., managers, reflectors).
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.T1.5">
    <tr class="ltx_tr" id="S1.T1.5.1">
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.1">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.1.1">
       Model
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.2">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.2.1">
       Objectives
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.3">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.3.1">
       Single-type Agents
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.4">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.4.1">
       Multi-type Agents
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.5">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.5.1">
       Diverse Rec. Scenarios
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.5.1.6">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.1.6.1">
       Open-source
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.2">
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.2.1">
      RecAgent
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib16" title="">
        2023b
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.2.2">
      User Simulation
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.2.3">
      ✓
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.5.2.4">
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.5.2.5">
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.2.6">
      ✓
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.3">
     <td class="ltx_td ltx_align_center" id="S1.T1.5.3.1">
      Agent4Rec
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib22" title="">
        2023c
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.3.2">
      User Simulation
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.3.3">
      ✓
     </td>
     <td class="ltx_td" id="S1.T1.5.3.4">
     </td>
     <td class="ltx_td" id="S1.T1.5.3.5">
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.3.6">
      ✓
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.4">
     <td class="ltx_td ltx_align_center" id="S1.T1.5.4.1">
      AgentCF
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib24" title="">
        2023b
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.4.2">
      U-I Inter Simulation
     </td>
     <td class="ltx_td" id="S1.T1.5.4.3">
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.4.4">
      ✓
     </td>
     <td class="ltx_td" id="S1.T1.5.4.5">
     </td>
     <td class="ltx_td" id="S1.T1.5.4.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.5">
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.5.1">
      RAH
      <cite class="ltx_cite ltx_citemacro_citep">
       (Shu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib12" title="">
        2023
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.5.2">
      Recommender
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.5.5.3">
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.5.5.4">
      ✓
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.5.5.5">
     </td>
     <td class="ltx_td ltx_border_t" id="S1.T1.5.5.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.6">
     <td class="ltx_td ltx_align_center" id="S1.T1.5.6.1">
      RecMind
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib17" title="">
        2023a
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.6.2">
      Recommender
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.6.3">
      ✓
     </td>
     <td class="ltx_td" id="S1.T1.5.6.4">
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.6.5">
      ✓
     </td>
     <td class="ltx_td" id="S1.T1.5.6.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.7">
     <td class="ltx_td ltx_align_center" id="S1.T1.5.7.1">
      InteRecAgent
      <cite class="ltx_cite ltx_citemacro_citep">
       (Huang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib6" title="">
        2023
       </a>
       )
      </cite>
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.7.2">
      Recommender
     </td>
     <td class="ltx_td ltx_align_center" id="S1.T1.5.7.3">
      ✓
     </td>
     <td class="ltx_td" id="S1.T1.5.7.4">
     </td>
     <td class="ltx_td" id="S1.T1.5.7.5">
     </td>
     <td class="ltx_td" id="S1.T1.5.7.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S1.T1.5.8">
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.1">
      <span class="ltx_text ltx_font_bold" id="S1.T1.5.8.1.1">
       MACRec
      </span>
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.2">
      Recommender
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.3">
      ✓
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.4">
      ✓
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.5">
      ✓
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.8.6">
      ✓
     </td>
    </tr>
   </table>
  </figure>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   Related Work
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    Agents-based Recommendation
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     Currently, research on integrating LLM-based agents for recommendation can be categorized into two primary orientations:
     <span class="ltx_text ltx_font_slanted" id="S2.SS1.p1.1.1">
      simulation-oriented
     </span>
     and
     <span class="ltx_text ltx_font_slanted" id="S2.SS1.p1.1.2">
      recommender-oriented
     </span>
     approaches. Table
     <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Multi-Agent Collaboration Framework for Recommender Systems">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     compares our MACRec and previous agents-based work.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     The
     <span class="ltx_text ltx_font_slanted" id="S2.SS1.p2.1.1">
      simulation-oriented
     </span>
     work focuses on using agents to simulate user behaviors and item characteristics in RSs. RecAgent
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2023c
      </a>
      )
     </cite>
     and Agent4Rec
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib16" title="">
       2023b
      </a>
      )
     </cite>
     both propose to use agents as user simulators to empower the evaluation of RSs, which feature single-type agents (as users).
AgentCF
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2023b
      </a>
      )
     </cite>
     explores the simulation of user-item interactions through user-agents and item-agents. It belongs to a multi-type agent system, with only two types and simple interactions.
This line of research aims to provide a deeper understanding of user preferences but falls short of integration into RSs.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     The goal of
     <span class="ltx_text ltx_font_slanted" id="S2.SS1.p3.1.1">
      recommender-oriented
     </span>
     studies is to build a ”recommender agent” with planning and memory components to tackle recommendation tasks.
InteRecAgent
     <cite class="ltx_cite ltx_citemacro_citep">
      (Huang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       2023
      </a>
      )
     </cite>
     and RecMind
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib17" title="">
       2023a
      </a>
      )
     </cite>
     primarily focus on improving a single recommender agent’s planning and reflection ability.
RAH
     <cite class="ltx_cite ltx_citemacro_citep">
      (Shu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib12" title="">
       2023
      </a>
      )
     </cite>
     proposes a human-centered framework using LLM Agents as assistants.
It supports collaboration among different types of agents, yet only in a fixed mode, whereas MACRec enables adaptable collaboration for various uses. Moreover, RAH lacks publicly accessible code or demos.
To the best of our knowledge, MACRec is the first open-source framework supporting multi-type agents for diverse recommendation scenarios.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    Multi-agent Collaboration
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Multi-agent systems, initially grounded in DAI
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chaib-Draa et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       1992
      </a>
      )
     </cite>
     and MAS
     <cite class="ltx_cite ltx_citemacro_citep">
      (Stone and Veloso,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2000
      </a>
      )
     </cite>
     , evolved with foundational concepts of agent coordination and communication by
     <cite class="ltx_cite ltx_citemacro_citet">
      Wooldridge and Jennings (
      <a class="ltx_ref" href="#bib.bib18" title="">
       1995
      </a>
      )
     </cite>
     .
The advent of powerful LLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brown et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2020
      </a>
      ; OpenAI,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      ; Touvron et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      ; Zeng et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2022
      </a>
      )
     </cite>
     has shifted focus towards their application in multi-agent collaboration.
     <cite class="ltx_cite ltx_citemacro_citet">
      Brown et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib2" title="">
       2020
      </a>
      )
     </cite>
     demonstrated LLMs’ potential in human-like dialogues, applicable to agent-agent communication.
     <cite class="ltx_cite ltx_citemacro_citet">
      Vinyals et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib15" title="">
       2019
      </a>
      ); Nascimento et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      )
     </cite>
     illustrates how LLM agents can collaborate for shared objectives, achieving specific and complex task solutions.
Recent work
     <cite class="ltx_cite ltx_citemacro_citep">
      (Du et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      ; Zhang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2023a
      </a>
      ; Chen et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib4" title="">
       2023
      </a>
      )
     </cite>
     leverage multi-agent collaboration to achieve better performance on complex tasks. CAMEL
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2023
      </a>
      )
     </cite>
     and AutoGen
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2023
      </a>
      )
     </cite>
     focus on communicative agent systems for complex task solutions through inter-agent dialogue.
However, existing research on multi-agent collaboration has not investigated its potential in recommendation scenarios.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   The MACRec Framework
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1.
    </span>
    Framework Overview
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.1. Framework Overview ‣ 3. The MACRec Framework ‣ Multi-Agent Collaboration Framework for Recommender Systems">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     illustrates our proposed multi-agent collaboration recommendation framework.
A sequential recommendation task is given as an example.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     As shown in the example in Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.1. Framework Overview ‣ 3. The MACRec Framework ‣ Multi-Agent Collaboration Framework for Recommender Systems">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     ,
the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.1">
      Task Interpreter
     </span>
     first translates the task in a better way to understand.
Then, as the central component of the entire system, the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.2">
      Manager
     </span>
     starts calling other agents to obtain detailed analyses of the user and items.
These agents, including the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.3">
      Searcher
     </span>
     and the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.4">
      User/Item Analyst
     </span>
     , support the call of some tools,
e.g., the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.5">
      Searcher
     </span>
     has access to the search engine and the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.6">
      User/Item Analyst
     </span>
     can access detailed information about users and items.
After receiving responses from the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.7">
      Searcher
     </span>
     and
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.8">
      Analyst
     </span>
     , the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.9">
      Manager
     </span>
     will attempt to provide an answer, i.e., give a ranking order of the candidate sets.
The
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.10">
      Reflector
     </span>
     will be responsible for analyzing and reflecting on the
     <span class="ltx_text ltx_font_slanted" id="S3.SS1.p2.1.11">
      Manager
     </span>
     ’s answer in the last trial and giving suggestions, e.g., modifying the answer format to follow the task requirements.
Eventually, the Manager will reattempt to solve the task based on the reflections and provide a more reasonable answer, e.g., adding the missed item ID.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     The following sections will detail each agent’s specific characteristics and functions.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F1">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="263" id="S3.F1.g1" src="/html/2402.15235/assets/x1.png" width="664"/>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 1.
     </span>
     The Framework of MACRec. We take a sequential recommendation task as an example to show how these agents work collaboratively.
    </figcaption>
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_1">
      <span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S3.F1.1">
       \Description
      </span>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <p class="ltx_p ltx_figure_panel ltx_align_center" id="S3.F1.2">
       [The framework of MACRec.]The framework of MACRec.
      </p>
     </div>
    </div>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2.
    </span>
    Agent Roles
   </h3>
   <section class="ltx_subsubsection" id="S3.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.1.
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.1.1">
      Manager
     </span>
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS1.p1">
     <p class="ltx_p" id="S3.SS2.SSS1.p1.1">
      For the given task, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p1.1.1">
       Manager
      </span>
      would assign sub-tasks to other agents and complete the main execution process. It oversees the coordination and collaboration among all other agents, acting like a manager.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS1.p2">
     <p class="ltx_p" id="S3.SS2.SSS1.p2.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.1">
       Manager
      </span>
      always performs the three steps of
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.2">
       Thought
      </span>
      ,
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.3">
       Action
      </span>
      , and
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.4">
       Observation
      </span>
      alternately.
In the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.5">
       Thought
      </span>
      phase, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.6">
       Manager
      </span>
      reasons about the current situation of the task (e.g., whether the analysis is sufficient, whether additional information is needed, etc.).
During the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.7">
       Action
      </span>
      phase, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.8">
       Manager
      </span>
      can choose to give an answer to end the task or seek help from other agents (under a particular interface format).
Responses given by other agents will be given in the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.9">
       Observation
      </span>
      phase of the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS1.p2.1.10">
       Manager
      </span>
      .
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.2.
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.1.1">
      Reflector
     </span>
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS2.p1">
     <p class="ltx_p" id="S3.SS2.SSS2.p1.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p1.1.1">
       Reflector
      </span>
      is responsible for judging the correctness of the answer given by the Manager. A further reflection will be given if the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p1.1.2">
       Reflector
      </span>
      determines the answer is correct.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p2">
     <p class="ltx_p" id="S3.SS2.SSS2.p2.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.1">
       Reflector
      </span>
      will step in when the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.2">
       Manager
      </span>
      is about to perform the second or more run on the same task input.
If the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.3">
       Reflector
      </span>
      judges that the answer given by the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.4">
       Manager
      </span>
      has no room for improvement, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.5">
       Manager
      </span>
      will no longer perform the current run. Otherwise, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.6">
       Reflector
      </span>
      will further summarize where the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS2.p2.1.7">
       Manager
      </span>
      can be improved, e.g., not considering the few highly rated items/movies in the user’s historical interactions.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.3.
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.1.1">
      User/Item Analyst
     </span>
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS3.p1">
     <p class="ltx_p" id="S3.SS2.SSS3.p1.1">
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS3.p1.1.1">
       User/Item Analyst
      </span>
      specializes in examining and understanding the characteristics and preferences of users, as well as the attributes of items.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS3.p2">
     <p class="ltx_p" id="S3.SS2.SSS3.p2.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS3.p2.1.1">
       Analyst
      </span>
      will be given access to two tools to assist in the analysis, including info database and interaction retriever.
The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS3.p2.1.2">
       Analyst
      </span>
      can get the user profile of each user and the attributes of each item through the info database.
Through the interaction retriever, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS3.p2.1.3">
       Analyst
      </span>
      can get the user/item interaction history before the current time.
With the combination of these two tools, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS3.p2.1.4">
       Analyst
      </span>
      can have an in-depth analysis of the user or the item.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.4.
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS4.1.1">
      Searcher
     </span>
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS4.p1">
     <p class="ltx_p" id="S3.SS2.SSS4.p1.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p1.1.1">
       Searcher
      </span>
      is responsible for searching under the requirements given by the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p1.1.2">
       Manager
      </span>
      with the search tool, and finally summarizing the text reply to the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p1.1.3">
       Manager
      </span>
      .
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS4.p2">
     <p class="ltx_p" id="S3.SS2.SSS4.p2.1">
      Take Wikipedia as an example of a search tool.
The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p2.1.1">
       Searcher
      </span>
      can give a search query to get the most relevant entry in Wikipedia.
The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p2.1.2">
       Searcher
      </span>
      can further retrieve passages in a specific entry where the given keywords exist.
Eventually, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p2.1.3">
       Searcher
      </span>
      is asked to summarize the paragraph to respond the the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS4.p2.1.4">
       Manager
      </span>
      ’s query.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.5.
     </span>
     <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS5.1.1">
      Task Interpreter
     </span>
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS5.p1">
     <p class="ltx_p" id="S3.SS2.SSS5.p1.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p1.1.1">
       Task Interpreter
      </span>
      translates the dialogs into executable recommendation tasks.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS5.p2">
     <p class="ltx_p" id="S3.SS2.SSS5.p2.1">
      The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p2.1.1">
       Task Interpreter
      </span>
      will get the history of the user’s conversations with the system when starts running.
Since conversation histories can be long, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p2.1.2">
       Task Interpreter
      </span>
      will only get the last part of the history.
The
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p2.1.3">
       Task Interpreter
      </span>
      also has access to call the text summarization tool to get a more concise overview of the history.
Eventually, the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p2.1.4">
       Task Interpreter
      </span>
      will give a specific description of the task requirements that will be used to guide the subsequent runs of the
      <span class="ltx_text ltx_font_slanted" id="S3.SS2.SSS5.p2.1.5">
       Manager
      </span>
      .
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   Applications on Recommendation Scenarios
  </h2>
  <figure class="ltx_figure" id="S4.F2">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="210" id="S4.F2.g1" src="/html/2402.15235/assets/x2.png" width="664"/>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2.
    </span>
    The web interfaces of our MACRec, along with a case of how three agents collaboratively address a conversational recommendation task. The interface is composed by the leftmost configuration panel and the main interaction panel.
   </figcaption>
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F2.1">
      \Description
     </span>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.2">
      [The web interfaces of our MACRec.]The web interfaces of our MACRec, along with a detailed case study demonstrating the collaborative efforts of three agents in addressing this task. The interface is composed by the leftmost configuration panel and the main interaction panel.
     </p>
    </div>
   </div>
  </figure>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    Here, we present the applications of MACRec on four recommendation scenarios. Table
    <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4. Applications on Recommendation Scenarios ‣ Multi-Agent Collaboration Framework for Recommender Systems">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    summarizes the agents’ selection for each scenario.
   </p>
  </div>
  <figure class="ltx_table" id="S4.T2">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
    <tr class="ltx_tr" id="S4.T2.1.1">
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.1.1.1">
      Task
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.2">
      U.Analy.
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.3">
      I.Analy.
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.4">
      Reflector
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.5">
      Searcher
     </td>
     <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.6">
      Interpreter
     </td>
    </tr>
    <tr class="ltx_tr" id="S4.T2.1.2">
     <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.1">
      RP
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2">
      <span class="ltx_ERROR undefined" id="S4.T2.1.2.2.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.3">
      <span class="ltx_ERROR undefined" id="S4.T2.1.2.3.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.4">
      <span class="ltx_ERROR undefined" id="S4.T2.1.2.4.1">
       \usym
      </span>
      2610
     </td>
     <td class="ltx_td ltx_border_t" id="S4.T2.1.2.5">
     </td>
     <td class="ltx_td ltx_border_t" id="S4.T2.1.2.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S4.T2.1.3">
     <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.3.1">
      SR
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.3.2">
      <span class="ltx_ERROR undefined" id="S4.T2.1.3.2.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.3.3">
      <span class="ltx_ERROR undefined" id="S4.T2.1.3.3.1">
       \usym
      </span>
      2610
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.3.4">
      <span class="ltx_ERROR undefined" id="S4.T2.1.3.4.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td" id="S4.T2.1.3.5">
     </td>
     <td class="ltx_td" id="S4.T2.1.3.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S4.T2.1.4">
     <td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.4.1">
      EG
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.4.2">
      <span class="ltx_ERROR undefined" id="S4.T2.1.4.2.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.4.3">
      <span class="ltx_ERROR undefined" id="S4.T2.1.4.3.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.4.4">
      <span class="ltx_ERROR undefined" id="S4.T2.1.4.4.1">
       \usym
      </span>
      2610
     </td>
     <td class="ltx_td ltx_align_center" id="S4.T2.1.4.5">
      <span class="ltx_ERROR undefined" id="S4.T2.1.4.5.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td" id="S4.T2.1.4.6">
     </td>
    </tr>
    <tr class="ltx_tr" id="S4.T2.1.5">
     <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.1.5.1">
      CR
     </td>
     <td class="ltx_td ltx_border_bb" id="S4.T2.1.5.2">
     </td>
     <td class="ltx_td ltx_border_bb" id="S4.T2.1.5.3">
     </td>
     <td class="ltx_td ltx_border_bb" id="S4.T2.1.5.4">
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.5.5">
      <span class="ltx_ERROR undefined" id="S4.T2.1.5.5.1">
       \usym
      </span>
      2611
     </td>
     <td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.5.6">
      <span class="ltx_ERROR undefined" id="S4.T2.1.5.6.1">
       \usym
      </span>
      2611
     </td>
    </tr>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 2.
    </span>
    The agents’ selection for four applications supported by MACRec.
    <span class="ltx_ERROR undefined" id="S4.T2.4.1">
     \usym
    </span>
    2611 means required and
    <span class="ltx_ERROR undefined" id="S4.T2.5.2">
     \usym
    </span>
    2610 means optional.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1.
    </span>
    Rating Prediction (RP)
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     Rating prediction task involves predicting the numerical rating a user might give to an item, such as a movie or a product, based on their preferences and historical interactions.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     In the rating prediction task, each user will have different rating preferences.
The
     <span class="ltx_text ltx_font_slanted" id="S4.SS1.p2.1.1">
      User Analyst
     </span>
     can provide a detailed analysis of the user’s historical interactions and preferences.
Meanwhile, the
     <span class="ltx_text ltx_font_slanted" id="S4.SS1.p2.1.2">
      Manager
     </span>
     also needs characteristic analysis of the target item, which can be provided by the
     <span class="ltx_text ltx_font_slanted" id="S4.SS1.p2.1.3">
      Item Analyst
     </span>
     .
With the help of two types of
     <span class="ltx_text ltx_font_slanted" id="S4.SS1.p2.1.4">
      Analysts
     </span>
     , the
     <span class="ltx_text ltx_font_slanted" id="S4.SS1.p2.1.5">
      Manager
     </span>
     can know the user’s tendency to rate and the item’s recent ratings before giving a prediction.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2.
    </span>
    Sequential Recommendation (SR)
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     Sequential recommendation systems analyze the sequence of items a user has interacted with to predict their next likely interest.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     Modeling of user’s long-term and short-term interests is important in sequential recommendation tasks.
Hence, the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.1">
      User Analyst
     </span>
     ’s role is self-evident.
The number of relevant items in the sequence recommendation is significantly higher than the rating prediction task.
It is hard to ask the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.2">
      Item Analyst
     </span>
     to analyze every item that appeared in either the history or the candidate set.
Therefore, the role of the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.3">
      Item Analyst
     </span>
     is comparatively limited compared to other scenarios.
Moreover, given that the answers to the sequential recommendation task are much more complex (i.e., a ranking order of the candidate set), the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.4">
      Reflector
     </span>
     can help to avoid the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.5">
      Manager
     </span>
     getting into formatting troubles.
A single round of behavioral analysis may omit consideration of long-term user behavior, and reflection on this is something the
     <span class="ltx_text ltx_font_slanted" id="S4.SS2.p2.1.6">
      Reflector
     </span>
     can do.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3.
    </span>
    Explanation Generation (EG)
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     This task involves generating understandable and relevant explanations for the recommendations provided to users.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     The explanation generation task also requires a detailed analysis of both the user and the item.
In addition, more information about the item may also help the
     <span class="ltx_text ltx_font_slanted" id="S4.SS3.p2.1.1">
      Manager
     </span>
     understand the user’s behavior towards it.
For example, a user may have similar preferences for multiple movies by the same director.
The information about the director may not be contained in the dataset.
Retrieving these extra pieces of information is suitable for the
     <span class="ltx_text ltx_font_slanted" id="S4.SS3.p2.1.2">
      Searcher
     </span>
     to perform.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4.
    </span>
    Conversational Recommendation (CR)
   </h3>
   <div class="ltx_para" id="S4.SS4.p1">
    <p class="ltx_p" id="S4.SS4.p1.1">
     Conversational recommendation systems (CRS) engage users in a dialogue to refine their preferences and deliver more accurate suggestions.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p2">
    <p class="ltx_p" id="S4.SS4.p2.1">
     In conversational scenarios, the user’s input text is not necessarily explicitly instructive.
Hence, the
     <span class="ltx_text ltx_font_slanted" id="S4.SS4.p2.1.1">
      Task Interpreter
     </span>
     can help translate the conversation history into a more concise and clear task prompt.
In addition, the user’s input requirements may contain information unknown to the
     <span class="ltx_text ltx_font_slanted" id="S4.SS4.p2.1.2">
      Manager
     </span>
     , e.g., a product that has not sold on the platform.
In this case, the
     <span class="ltx_text ltx_font_slanted" id="S4.SS4.p2.1.3">
      Searcher
     </span>
     can help the Manager understand what the user mentioned.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS4.p3">
    <p class="ltx_p" id="S4.SS4.p3.1">
     Beyond the abovementioned applications, our framework can support other scenarios by customizing the prompts
and agents’ collaboration modes.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5.
   </span>
   Interface Demonstration
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    Figure
    <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4. Applications on Recommendation Scenarios ‣ Multi-Agent Collaboration Framework for Recommender Systems">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    presents the web interfaces of our framework, along with a detailed case study demonstrating the collaborative efforts of three agents in addressing a conversational recommendation task.
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    The interface can be divided into two main panels:
1)
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">
     The configuration panel
    </span>
    , where users can select different tasks to tackle, such as ”Conversational Recommendation.” Users can also customize different systems and configuration files for the task execution.
2)
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.2">
     The interaction panel
    </span>
    , where the whole collaboration process takes place. Agents with different abilities would complete this task collaboratively.
   </p>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    In Figure
    <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4. Applications on Recommendation Scenarios ‣ Multi-Agent Collaboration Framework for Recommender Systems">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , the user has expressed a preference for the movie ”Schindler’s List” and seeks recommendations for similar historical movies.
As shown in subfigure (a), the
    <span class="ltx_text ltx_font_slanted" id="S5.p3.1.1">
     Interpreter
    </span>
    summarizes this input and translates it into a clearer task successfully.
Then, the
    <span class="ltx_text ltx_font_slanted" id="S5.p3.1.2">
     Manager
    </span>
    calls for the help of the
    <span class="ltx_text ltx_font_slanted" id="S5.p3.1.3">
     Searcher
    </span>
    for two rounds, searching for movies about history and movies similar to ”Schindler’s List”.
According to all the information, the
    <span class="ltx_text ltx_font_slanted" id="S5.p3.1.4">
     Manager
    </span>
    gives the final recommendation movie ”Amistad”.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6.
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this work, we propose a novel LLM-based multi-agent collaboration framework for recommendation, called MACRec.
Unlike existing studies on using agents for user/item simulation, we directly tackle recommendation tasks through the collaborative efforts of various specialized agents.
We present applications of MACRec on four different recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation of recommendation results.
Moreover, We developed an online web interface for MACRec, visualizing how agents collaboratively tackle tasks.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al
     <span class="ltx_text" id="bib.bib2.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al
     <span class="ltx_text" id="bib.bib2.3.1">
      .
     </span>
     2020.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.4.1">
      Advances in neural information processing systems
     </em>
     33 (2020), 1877–1901.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chaib-Draa et al
     <span class="ltx_text" id="bib.bib3.2.2.1">
      .
     </span>
     (1992)
    </span>
    <span class="ltx_bibblock">
     Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot. 1992.
    </span>
    <span class="ltx_bibblock">
     Trends in distributed artificial intelligence.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">
      Artificial Intelligence Review
     </em>
     6 (1992), 35–66.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib4.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al
     <span class="ltx_text" id="bib.bib4.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.4.1">
      arXiv preprint arXiv:2308.10848
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al
     <span class="ltx_text" id="bib.bib5.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023.
    </span>
    <span class="ltx_bibblock">
     Improving Factuality and Reasoning in Language Models through Multiagent Debate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">
      arXiv preprint arXiv:2305.14325
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al
     <span class="ltx_text" id="bib.bib6.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023.
    </span>
    <span class="ltx_bibblock">
     Recommender ai agent: Integrating large language models for interactive recommendations.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">
      arXiv preprint arXiv:2308.16505
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al
     <span class="ltx_text" id="bib.bib7.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for” mind” exploration of large scale language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">
      arXiv preprint arXiv:2303.17760
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nakano et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al
     <span class="ltx_text" id="bib.bib8.3.1">
      .
     </span>
     2021.
    </span>
    <span class="ltx_bibblock">
     Webgpt: Browser-assisted question-answering with human feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.4.1">
      arXiv preprint arXiv:2112.09332
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nascimento et al
     <span class="ltx_text" id="bib.bib9.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Nathalia Nascimento, Paulo Alencar, and Donald Cowan. 2023.
    </span>
    <span class="ltx_bibblock">
     GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">
      arXiv preprint arXiv:2308.10435
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     GPT-4 Technical Report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      arXiv preprint arXiv:2303.08774
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shen et al
     <span class="ltx_text" id="bib.bib11.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023.
    </span>
    <span class="ltx_bibblock">
     Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">
      arXiv preprint arXiv:2303.17580
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shu et al
     <span class="ltx_text" id="bib.bib12.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu. 2023.
    </span>
    <span class="ltx_bibblock">
     RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">
      arXiv preprint arXiv:2308.09904
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Stone and Veloso (2000)
    </span>
    <span class="ltx_bibblock">
     Peter Stone and Manuela Veloso. 2000.
    </span>
    <span class="ltx_bibblock">
     Multiagent systems: A survey from a machine learning perspective.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      Autonomous Robots
     </em>
     8 (2000), 345–383.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al
     <span class="ltx_text" id="bib.bib14.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al
     <span class="ltx_text" id="bib.bib14.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Llama: Open and efficient foundation language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.4.1">
      arXiv preprint arXiv:2302.13971
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vinyals et al
     <span class="ltx_text" id="bib.bib15.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al
     <span class="ltx_text" id="bib.bib15.3.1">
      .
     </span>
     2019.
    </span>
    <span class="ltx_bibblock">
     Grandmaster level in StarCraft II using multi-agent reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.4.1">
      Nature
     </em>
     575, 7782 (2019), 350–354.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al
     <span class="ltx_text" id="bib.bib16.3.1">
      .
     </span>
     2023b.
    </span>
    <span class="ltx_bibblock">
     When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.4.1">
      arXiv preprint ArXiv:2306.02552
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Recmind: Large language model powered agent for recommendation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">
      arXiv preprint arXiv:2308.14296
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wooldridge and Jennings (1995)
    </span>
    <span class="ltx_bibblock">
     Michael Wooldridge and Nicholas R Jennings. 1995.
    </span>
    <span class="ltx_bibblock">
     Intelligent agents: Theory and practice.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      The knowledge engineering review
     </em>
     10, 2 (1995), 115–152.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Autogen: Enabling next-gen llm applications via multi-agent conversation framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">
      arXiv preprint arXiv:2308.08155
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al
     <span class="ltx_text" id="bib.bib20.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">
      arXiv preprint arXiv:2210.03629
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zeng et al
     <span class="ltx_text" id="bib.bib21.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al
     <span class="ltx_text" id="bib.bib21.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Glm-130b: An open bilingual pre-trained model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.4.1">
      arXiv preprint arXiv:2210.02414
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al
     <span class="ltx_text" id="bib.bib22.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2023c.
    </span>
    <span class="ltx_bibblock">
     On generative agents in recommendation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">
      arXiv preprint arXiv:2310.10108
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. 2023a.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      arXiv preprint arXiv:2307.02485
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al
     <span class="ltx_text" id="bib.bib24.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023b.
    </span>
    <span class="ltx_bibblock">
     Agentcf: Collaborative learning with autonomous language agents for recommender systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">
      arXiv preprint arXiv:2310.09233
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
