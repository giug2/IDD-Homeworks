<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios</title>
<!--Generated on Tue Sep 17 13:52:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.11205v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S1" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">INTRODUCTION</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S2" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Benchmark: HS3-Bench</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.SS1" title="In III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.SS2" title="In III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Metrics</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.SS3" title="In III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Benchmark guidelines</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Strong baselines</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.SS1" title="In IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.SS2" title="In IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Using HS3-Bench for Hyperparameter Tuning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.SS3" title="In IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Synthesizing (Pseudo-)RGB Images</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Experiments &amp; Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS1" title="In V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Applying HS3-Bench for Comparison of Full-Spectrum <span class="ltx_glossaryref" title="">HSI</span> Data and Reduction to a Single Channel</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS2" title="In V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Comparison of <span class="ltx_glossaryref" title="">HSI</span> and (Pseudo-)RGB Data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS3" title="In V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Impact of Pretraining on Model Performance</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS4" title="In V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Qualitative Evaluation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS5" title="In V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">Comparison to the State of the Art</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S6" title="In HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Summary</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nick Theisen, Robin Bartsch, Dietrich Paulus and Peer Neubert
</span><span class="ltx_author_notes">This paper was accepted for IROS 2024 — © 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. — All authors are with the Institute of Computational Visualistics, University of Koblenz, Germany. Correspondence Email: <span class="ltx_text ltx_font_typewriter" id="id1.1.id1" style="font-size:90%;">nicktheisen@uni-koblenz.de</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Semantic segmentation is an essential step for many vision applications in order to understand a scene and the objects within. Recent progress in hyperspectral imaging technology enables the application in driving scenarios and the hope is that the devices perceptive abilities provide an advantage over RGB-cameras.
Even though some datasets exist, there is no standard benchmark available to systematically measure progress on this task and evaluate the benefit of hyperspectral data.
In this paper, we work towards closing this gap by providing the HyperSpectral Semantic Segmentation benchmark (HS3-Bench). It combines annotated hyperspectral images from three driving scenario datasets and provides standardized metrics, implementations, and evaluation protocols.
We use the benchmark to derive two strong baseline models that surpass the previous state-of-the-art performances with and without pre-training on the individual datasets.
Further, our results indicate that the existing learning-based methods benefit more from leveraging additional RGB training data than from leveraging the additional hyperspectral channels. This poses important questions for future research on hyperspectral imaging for semantic segmentation in driving scenarios. Code to run the benchmark and the strong baseline approaches are available under <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/nickstheisen/hyperseg" title="">https://github.com/nickstheisen/hyperseg</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">INTRODUCTION</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Semantic segmentation models assign class labels to pixels and partition the image into regions with a problem-dependent semantic meaning. This is an important step in many vision applications such as scene understanding or the identification of image areas with certain task relevant properties.
<span class="ltx_glossaryref" title="">Hyperspectral imaging (HSI)</span> systems capture light in up to hundreds of very narrow spectral bands, often including ranges of the electromagnetic spectrum that are invisible to classical RGB-cameras and the human eye.
These advantages were exploited in the past to solve problems in many different domains, e. g. remote sensing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib1" title="">1</a>]</cite>, medicine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib2" title="">2</a>]</cite> and agriculture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib3" title="">3</a>]</cite>.
The application in dynamic scenes is difficult, because many <span class="ltx_glossaryref" title="">HSI</span>-sensors rely on scanning along the spectral dimension or along the spatial dimensions to capture a full hyperspectral cube, which takes time.
However, through steady improvement of imaging systems, sensors became smaller, cheaper and simpler in usage.
The latter is especially true for snapshot hyperspectral cameras which do not rely on scanning techniques but instead capture a full hyperspectral cube in an instant.
This progress enables the adoption of <span class="ltx_glossaryref" title="">HSI</span>-sensors in novel applications and domains, e. g. dynamic driving scenarios, thus increasing the need for well-generalizing models for tasks such as semantic segmentation. However, the question whether <span class="ltx_glossaryref" title="">HSI</span>-sensors provide a significant advantage in dynamic driving scenarios remains open.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="784" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples scenes from the hyperspectral image datasets used in HS3-Bench (HyKo2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib4" title="">4</a>]</cite>, HSI-Drive<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib5" title="">5</a>]</cite>, and <span class="ltx_glossaryref" title="">HCV2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib6" title="">6</a>]</cite>) together with ground-truth semantic segmentation labels.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The lack of a standardized benchmark makes the comparison of different approaches very challenging. In the literature only evaluation results on individual datasets without a common evaluation protocol are published. To address this problem, we present HS3-Bench, a hyperspectral semantic segmentation benchmark with the focus on driving scenarios. Example images can be seen in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">1</span></a>. The benchmark includes three datasets and allows systematic comparison of different approaches.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Our contributions can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce HS3-Bench a hyperspectral semantic segmentation benchmark focused on driving scenarios systematic evaluation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose two strong baselines for our benchmark, one based on the U-Net architecture, that uses only the <span class="ltx_glossaryref" title="">HSI</span> data from the benchmark datasets and one based on <span class="ltx_glossaryref" title="">DeeplabV3+ (DL3+)</span> that leverages additional data through pre-trained model weights. Our baselines outperform current state-of-the-art models.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We provide evidence that the existing learning based-methods benefit more from leveraging additional RGB training data than from leveraging the additional <span class="ltx_glossaryref" title="">HSI</span> channels. This poses important questions for future <span class="ltx_glossaryref" title="">HSI</span> research.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This paper is organized as follows. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S2" title="II Related Work ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">II</span></a> discusses the availability of hyperspectral benchmarks in the literature. In <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3" title="III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a> we introduce HS3-Bench and present the used datasets, evaluation metrics as well as benchmark guidelines. Section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4" title="IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">IV</span></a> describes the strong baselines. Description and results of our experiments can be found in section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5" title="V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">V</span></a>, followed by a summary of our findings in section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S6" title="VI Summary ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Deep learning and particularly <span class="ltx_glossaryref" title="">Convolutional Neural Network (CNN)</span>-based architectures establish the state of the art in semantic segmentation.
There exist multiple datasets with well-defined benchmarks for <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">RGB-images</span> in driving scenarios, e. g. Cityscapes Pixel-Level Semantic Labeling Task <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib7" title="">7</a>]</cite> or KITTI Semantic Segmentation benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib8" title="">8</a>]</cite>.
However, the combination of deep learning and <span class="ltx_glossaryref ltx_font_italic" title="">HSI</span> suffers from the limited amount of available data. Typically, hyperspectral datasets are small and therefore only very limited data is available for training. The most common datasets are remote sensing datasets consisting only of a single image, which can be considered solved, e. g. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib1" title="">1</a>]</cite>. The train-test split is created by splitting the image into pixels (or patches) which restricts the applicable models to pixel classification models.
In recent years, some larger, multi-image datasets showing urban and driving scenarios have been published (HyKo2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib4" title="">4</a>]</cite>, HSI-Drive v1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib5" title="">5</a>]</cite> and v2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib9" title="">9</a>]</cite>, <span class="ltx_glossaryref" title="">HCV2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib6" title="">6</a>]</cite>, HSI-Road <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib10" title="">10</a>]</cite>). They allow the application of encoder-decoder models that predict pixel-precise classification maps for whole images during inference, such as U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib11" title="">11</a>]</cite> or <span class="ltx_glossaryref" title="">DL3+</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib12" title="">12</a>]</cite>.
Unfortunately, for HyKo2 a well-defined benchmark does not exist and HSI-Road consists of only two classes – road and not road – from which only one is considered during evaluation, making it closer to segmentation than semantic segmentation. Results for HSI-Drive were published in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib13" title="">13</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib9" title="">9</a>]</cite> using a fully-convolutional network but in their experiments the authors use at most six different classes, as they combine certain combinations of minority classes into the class ’other’. On <span class="ltx_glossaryref" title="">HCV2</span> the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite> achieved good results with a dual stream model using <span class="ltx_glossaryref" title="">HSI</span> as well as synthesized RGB. This allowed them to use a ResNet50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib15" title="">15</a>]</cite> backbone pre-trained on ImageNet, which led to a significant improvement of the model performance.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Benchmark: HS3-Bench</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section describes HS3-Bench, the HyperSpectral Semantic Segmentation Benchmark for driving scenarios. Detailed results and implementations are available in the benchmark repository.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Datasets</span>
</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Overview of the <span class="ltx_glossaryref" title="">HSI</span> datasets used in HS3-Bench</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.28" style="width:433.6pt;height:196.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(77.6pt,-35.1pt) scale(1.55766400936296,1.55766400936296) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.28.28">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.28.28.29.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S3.T1.28.28.29.1.1"><span class="ltx_text" id="S3.T1.28.28.29.1.1.1" style="font-size:80%;">Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.28.28.29.1.2"><span class="ltx_text" id="S3.T1.28.28.29.1.2.1" style="font-size:80%;">HyKo2-VIS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.28.28.29.1.3"><span class="ltx_glossaryref" style="font-size:80%;" title="">HCV2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.28.28.29.1.4"><span class="ltx_text" id="S3.T1.28.28.29.1.4.1" style="font-size:80%;">HSI-Drive</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.3.3.3.4"><span class="ltx_text" id="S3.T1.3.3.3.4.1" style="font-size:80%;">Image size</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.1.1"><math alttext="254\times 510" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml"><mn id="S3.T1.1.1.1.1.m1.1.1.2" mathsize="80%" xref="S3.T1.1.1.1.1.m1.1.1.2.cmml">254</mn><mo id="S3.T1.1.1.1.1.m1.1.1.1" lspace="0.222em" mathsize="80%" rspace="0.222em" xref="S3.T1.1.1.1.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.1.1.1.1.m1.1.1.3" mathsize="80%" xref="S3.T1.1.1.1.1.m1.1.1.3.cmml">510</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1"><times id="S3.T1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1.1"></times><cn id="S3.T1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="S3.T1.1.1.1.1.m1.1.1.2">254</cn><cn id="S3.T1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S3.T1.1.1.1.1.m1.1.1.3">510</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">254\times 510</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">254 × 510</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.2.2.2"><math alttext="1400\times 1800" class="ltx_Math" display="inline" id="S3.T1.2.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.2.m1.1a"><mrow id="S3.T1.2.2.2.2.m1.1.1" xref="S3.T1.2.2.2.2.m1.1.1.cmml"><mn id="S3.T1.2.2.2.2.m1.1.1.2" mathsize="80%" xref="S3.T1.2.2.2.2.m1.1.1.2.cmml">1400</mn><mo id="S3.T1.2.2.2.2.m1.1.1.1" lspace="0.222em" mathsize="80%" rspace="0.222em" xref="S3.T1.2.2.2.2.m1.1.1.1.cmml">×</mo><mn id="S3.T1.2.2.2.2.m1.1.1.3" mathsize="80%" xref="S3.T1.2.2.2.2.m1.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.1b"><apply id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1"><times id="S3.T1.2.2.2.2.m1.1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1.1"></times><cn id="S3.T1.2.2.2.2.m1.1.1.2.cmml" type="integer" xref="S3.T1.2.2.2.2.m1.1.1.2">1400</cn><cn id="S3.T1.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S3.T1.2.2.2.2.m1.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.1c">1400\times 1800</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.2.m1.1d">1400 × 1800</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.3.3.3"><math alttext="409\times 216" class="ltx_Math" display="inline" id="S3.T1.3.3.3.3.m1.1"><semantics id="S3.T1.3.3.3.3.m1.1a"><mrow id="S3.T1.3.3.3.3.m1.1.1" xref="S3.T1.3.3.3.3.m1.1.1.cmml"><mn id="S3.T1.3.3.3.3.m1.1.1.2" mathsize="80%" xref="S3.T1.3.3.3.3.m1.1.1.2.cmml">409</mn><mo id="S3.T1.3.3.3.3.m1.1.1.1" lspace="0.222em" mathsize="80%" rspace="0.222em" xref="S3.T1.3.3.3.3.m1.1.1.1.cmml">×</mo><mn id="S3.T1.3.3.3.3.m1.1.1.3" mathsize="80%" xref="S3.T1.3.3.3.3.m1.1.1.3.cmml">216</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m1.1b"><apply id="S3.T1.3.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1"><times id="S3.T1.3.3.3.3.m1.1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1.1"></times><cn id="S3.T1.3.3.3.3.m1.1.1.2.cmml" type="integer" xref="S3.T1.3.3.3.3.m1.1.1.2">409</cn><cn id="S3.T1.3.3.3.3.m1.1.1.3.cmml" type="integer" xref="S3.T1.3.3.3.3.m1.1.1.3">216</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m1.1c">409\times 216</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.3.m1.1d">409 × 216</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.6.6.4"><span class="ltx_text" id="S3.T1.6.6.6.4.1" style="font-size:80%;">Bands</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.4.1"><math alttext="15" class="ltx_Math" display="inline" id="S3.T1.4.4.4.1.m1.1"><semantics id="S3.T1.4.4.4.1.m1.1a"><mn id="S3.T1.4.4.4.1.m1.1.1" mathsize="80%" xref="S3.T1.4.4.4.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.1.m1.1b"><cn id="S3.T1.4.4.4.1.m1.1.1.cmml" type="integer" xref="S3.T1.4.4.4.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.1.m1.1c">15</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.1.m1.1d">15</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.5.5.2"><math alttext="128" class="ltx_Math" display="inline" id="S3.T1.5.5.5.2.m1.1"><semantics id="S3.T1.5.5.5.2.m1.1a"><mn id="S3.T1.5.5.5.2.m1.1.1" mathsize="80%" xref="S3.T1.5.5.5.2.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.2.m1.1b"><cn id="S3.T1.5.5.5.2.m1.1.1.cmml" type="integer" xref="S3.T1.5.5.5.2.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.2.m1.1c">128</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.2.m1.1d">128</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.6.3"><math alttext="25" class="ltx_Math" display="inline" id="S3.T1.6.6.6.3.m1.1"><semantics id="S3.T1.6.6.6.3.m1.1a"><mn id="S3.T1.6.6.6.3.m1.1.1" mathsize="80%" xref="S3.T1.6.6.6.3.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.3.m1.1b"><cn id="S3.T1.6.6.6.3.m1.1.1.cmml" type="integer" xref="S3.T1.6.6.6.3.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.3.m1.1c">25</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.3.m1.1d">25</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.12.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.12.12.12.7"><span class="ltx_text" id="S3.T1.12.12.12.7.1" style="font-size:80%;">Range (nm)</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.2">
<math alttext="470" class="ltx_Math" display="inline" id="S3.T1.7.7.7.1.m1.1"><semantics id="S3.T1.7.7.7.1.m1.1a"><mn id="S3.T1.7.7.7.1.m1.1.1" mathsize="80%" xref="S3.T1.7.7.7.1.m1.1.1.cmml">470</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><cn id="S3.T1.7.7.7.1.m1.1.1.cmml" type="integer" xref="S3.T1.7.7.7.1.m1.1.1">470</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">470</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.7.1.m1.1d">470</annotation></semantics></math><span class="ltx_text" id="S3.T1.8.8.8.2.1" style="font-size:80%;">-</span><math alttext="630" class="ltx_Math" display="inline" id="S3.T1.8.8.8.2.m2.1"><semantics id="S3.T1.8.8.8.2.m2.1a"><mn id="S3.T1.8.8.8.2.m2.1.1" mathsize="80%" xref="S3.T1.8.8.8.2.m2.1.1.cmml">630</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.2.m2.1b"><cn id="S3.T1.8.8.8.2.m2.1.1.cmml" type="integer" xref="S3.T1.8.8.8.2.m2.1.1">630</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.2.m2.1c">630</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.8.2.m2.1d">630</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.10.4">
<math alttext="450" class="ltx_Math" display="inline" id="S3.T1.9.9.9.3.m1.1"><semantics id="S3.T1.9.9.9.3.m1.1a"><mn id="S3.T1.9.9.9.3.m1.1.1" mathsize="80%" xref="S3.T1.9.9.9.3.m1.1.1.cmml">450</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.3.m1.1b"><cn id="S3.T1.9.9.9.3.m1.1.1.cmml" type="integer" xref="S3.T1.9.9.9.3.m1.1.1">450</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.3.m1.1c">450</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.9.3.m1.1d">450</annotation></semantics></math><span class="ltx_text" id="S3.T1.10.10.10.4.1" style="font-size:80%;">-</span><math alttext="950" class="ltx_Math" display="inline" id="S3.T1.10.10.10.4.m2.1"><semantics id="S3.T1.10.10.10.4.m2.1a"><mn id="S3.T1.10.10.10.4.m2.1.1" mathsize="80%" xref="S3.T1.10.10.10.4.m2.1.1.cmml">950</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.4.m2.1b"><cn id="S3.T1.10.10.10.4.m2.1.1.cmml" type="integer" xref="S3.T1.10.10.10.4.m2.1.1">950</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.4.m2.1c">950</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.10.4.m2.1d">950</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.12.12.12.6">
<math alttext="600" class="ltx_Math" display="inline" id="S3.T1.11.11.11.5.m1.1"><semantics id="S3.T1.11.11.11.5.m1.1a"><mn id="S3.T1.11.11.11.5.m1.1.1" mathsize="80%" xref="S3.T1.11.11.11.5.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.5.m1.1b"><cn id="S3.T1.11.11.11.5.m1.1.1.cmml" type="integer" xref="S3.T1.11.11.11.5.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.5.m1.1c">600</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.11.5.m1.1d">600</annotation></semantics></math><span class="ltx_text" id="S3.T1.12.12.12.6.1" style="font-size:80%;">-</span><math alttext="975" class="ltx_Math" display="inline" id="S3.T1.12.12.12.6.m2.1"><semantics id="S3.T1.12.12.12.6.m2.1a"><mn id="S3.T1.12.12.12.6.m2.1.1" mathsize="80%" xref="S3.T1.12.12.12.6.m2.1.1.cmml">975</mn><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.6.m2.1b"><cn id="S3.T1.12.12.12.6.m2.1.1.cmml" type="integer" xref="S3.T1.12.12.12.6.m2.1.1">975</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.6.m2.1c">975</annotation><annotation encoding="application/x-llamapun" id="S3.T1.12.12.12.6.m2.1d">975</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.15.15.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.15.15.15.4"><span class="ltx_text" id="S3.T1.15.15.15.4.1" style="font-size:80%;">Images</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.13.13.13.1"><math alttext="371" class="ltx_Math" display="inline" id="S3.T1.13.13.13.1.m1.1"><semantics id="S3.T1.13.13.13.1.m1.1a"><mn id="S3.T1.13.13.13.1.m1.1.1" mathsize="80%" xref="S3.T1.13.13.13.1.m1.1.1.cmml">371</mn><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.1b"><cn id="S3.T1.13.13.13.1.m1.1.1.cmml" type="integer" xref="S3.T1.13.13.13.1.m1.1.1">371</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.1c">371</annotation><annotation encoding="application/x-llamapun" id="S3.T1.13.13.13.1.m1.1d">371</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.14.14.14.2"><math alttext="1330" class="ltx_Math" display="inline" id="S3.T1.14.14.14.2.m1.1"><semantics id="S3.T1.14.14.14.2.m1.1a"><mn id="S3.T1.14.14.14.2.m1.1.1" mathsize="80%" xref="S3.T1.14.14.14.2.m1.1.1.cmml">1330</mn><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m1.1b"><cn id="S3.T1.14.14.14.2.m1.1.1.cmml" type="integer" xref="S3.T1.14.14.14.2.m1.1.1">1330</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m1.1c">1330</annotation><annotation encoding="application/x-llamapun" id="S3.T1.14.14.14.2.m1.1d">1330</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.15.15.15.3"><math alttext="752" class="ltx_Math" display="inline" id="S3.T1.15.15.15.3.m1.1"><semantics id="S3.T1.15.15.15.3.m1.1a"><mn id="S3.T1.15.15.15.3.m1.1.1" mathsize="80%" xref="S3.T1.15.15.15.3.m1.1.1.cmml">752</mn><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.3.m1.1b"><cn id="S3.T1.15.15.15.3.m1.1.1.cmml" type="integer" xref="S3.T1.15.15.15.3.m1.1.1">752</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.3.m1.1c">752</annotation><annotation encoding="application/x-llamapun" id="S3.T1.15.15.15.3.m1.1d">752</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.18.18.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.18.18.18.4"><span class="ltx_text" id="S3.T1.18.18.18.4.1" style="font-size:80%;">Classes</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.16.16.16.1"><math alttext="10" class="ltx_Math" display="inline" id="S3.T1.16.16.16.1.m1.1"><semantics id="S3.T1.16.16.16.1.m1.1a"><mn id="S3.T1.16.16.16.1.m1.1.1" mathsize="80%" xref="S3.T1.16.16.16.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.1.m1.1b"><cn id="S3.T1.16.16.16.1.m1.1.1.cmml" type="integer" xref="S3.T1.16.16.16.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.T1.16.16.16.1.m1.1d">10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.17.17.17.2"><math alttext="19" class="ltx_Math" display="inline" id="S3.T1.17.17.17.2.m1.1"><semantics id="S3.T1.17.17.17.2.m1.1a"><mn id="S3.T1.17.17.17.2.m1.1.1" mathsize="80%" xref="S3.T1.17.17.17.2.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.17.2.m1.1b"><cn id="S3.T1.17.17.17.2.m1.1.1.cmml" type="integer" xref="S3.T1.17.17.17.2.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.17.2.m1.1c">19</annotation><annotation encoding="application/x-llamapun" id="S3.T1.17.17.17.2.m1.1d">19</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.18.18.18.3"><math alttext="9" class="ltx_Math" display="inline" id="S3.T1.18.18.18.3.m1.1"><semantics id="S3.T1.18.18.18.3.m1.1a"><mn id="S3.T1.18.18.18.3.m1.1.1" mathsize="80%" xref="S3.T1.18.18.18.3.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.18.3.m1.1b"><cn id="S3.T1.18.18.18.3.m1.1.1.cmml" type="integer" xref="S3.T1.18.18.18.3.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.18.3.m1.1c">9</annotation><annotation encoding="application/x-llamapun" id="S3.T1.18.18.18.3.m1.1d">9</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.28.28.28">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T1.19.19.19.1">
<span class="ltx_text" id="S3.T1.19.19.19.1.1" style="font-size:80%;">Train/Test/Val-split (</span><math alttext="\%" class="ltx_Math" display="inline" id="S3.T1.19.19.19.1.m1.1"><semantics id="S3.T1.19.19.19.1.m1.1a"><mo id="S3.T1.19.19.19.1.m1.1.1" mathsize="80%" xref="S3.T1.19.19.19.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S3.T1.19.19.19.1.m1.1b"><csymbol cd="latexml" id="S3.T1.19.19.19.1.m1.1.1.cmml" xref="S3.T1.19.19.19.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.19.19.1.m1.1c">\%</annotation><annotation encoding="application/x-llamapun" id="S3.T1.19.19.19.1.m1.1d">%</annotation></semantics></math><span class="ltx_text" id="S3.T1.19.19.19.1.2" style="font-size:80%;">)</span>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.22.22.22.4">
<math alttext="50" class="ltx_Math" display="inline" id="S3.T1.20.20.20.2.m1.1"><semantics id="S3.T1.20.20.20.2.m1.1a"><mn id="S3.T1.20.20.20.2.m1.1.1" mathsize="80%" xref="S3.T1.20.20.20.2.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.T1.20.20.20.2.m1.1b"><cn id="S3.T1.20.20.20.2.m1.1.1.cmml" type="integer" xref="S3.T1.20.20.20.2.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.20.20.2.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.T1.20.20.20.2.m1.1d">50</annotation></semantics></math><span class="ltx_text" id="S3.T1.22.22.22.4.1" style="font-size:80%;">/</span><math alttext="20" class="ltx_Math" display="inline" id="S3.T1.21.21.21.3.m2.1"><semantics id="S3.T1.21.21.21.3.m2.1a"><mn id="S3.T1.21.21.21.3.m2.1.1" mathsize="80%" xref="S3.T1.21.21.21.3.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.T1.21.21.21.3.m2.1b"><cn id="S3.T1.21.21.21.3.m2.1.1.cmml" type="integer" xref="S3.T1.21.21.21.3.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.21.21.3.m2.1c">20</annotation><annotation encoding="application/x-llamapun" id="S3.T1.21.21.21.3.m2.1d">20</annotation></semantics></math><span class="ltx_text" id="S3.T1.22.22.22.4.2" style="font-size:80%;">/</span><math alttext="30" class="ltx_Math" display="inline" id="S3.T1.22.22.22.4.m3.1"><semantics id="S3.T1.22.22.22.4.m3.1a"><mn id="S3.T1.22.22.22.4.m3.1.1" mathsize="80%" xref="S3.T1.22.22.22.4.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.T1.22.22.22.4.m3.1b"><cn id="S3.T1.22.22.22.4.m3.1.1.cmml" type="integer" xref="S3.T1.22.22.22.4.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.22.22.22.4.m3.1c">30</annotation><annotation encoding="application/x-llamapun" id="S3.T1.22.22.22.4.m3.1d">30</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.25.25.25.7">
<math alttext="72" class="ltx_Math" display="inline" id="S3.T1.23.23.23.5.m1.1"><semantics id="S3.T1.23.23.23.5.m1.1a"><mn id="S3.T1.23.23.23.5.m1.1.1" mathsize="80%" xref="S3.T1.23.23.23.5.m1.1.1.cmml">72</mn><annotation-xml encoding="MathML-Content" id="S3.T1.23.23.23.5.m1.1b"><cn id="S3.T1.23.23.23.5.m1.1.1.cmml" type="integer" xref="S3.T1.23.23.23.5.m1.1.1">72</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.23.23.23.5.m1.1c">72</annotation><annotation encoding="application/x-llamapun" id="S3.T1.23.23.23.5.m1.1d">72</annotation></semantics></math><span class="ltx_text" id="S3.T1.25.25.25.7.1" style="font-size:80%;">/</span><math alttext="8" class="ltx_Math" display="inline" id="S3.T1.24.24.24.6.m2.1"><semantics id="S3.T1.24.24.24.6.m2.1a"><mn id="S3.T1.24.24.24.6.m2.1.1" mathsize="80%" xref="S3.T1.24.24.24.6.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S3.T1.24.24.24.6.m2.1b"><cn id="S3.T1.24.24.24.6.m2.1.1.cmml" type="integer" xref="S3.T1.24.24.24.6.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.24.24.24.6.m2.1c">8</annotation><annotation encoding="application/x-llamapun" id="S3.T1.24.24.24.6.m2.1d">8</annotation></semantics></math><span class="ltx_text" id="S3.T1.25.25.25.7.2" style="font-size:80%;">/</span><math alttext="20" class="ltx_Math" display="inline" id="S3.T1.25.25.25.7.m3.1"><semantics id="S3.T1.25.25.25.7.m3.1a"><mn id="S3.T1.25.25.25.7.m3.1.1" mathsize="80%" xref="S3.T1.25.25.25.7.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.T1.25.25.25.7.m3.1b"><cn id="S3.T1.25.25.25.7.m3.1.1.cmml" type="integer" xref="S3.T1.25.25.25.7.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.25.25.25.7.m3.1c">20</annotation><annotation encoding="application/x-llamapun" id="S3.T1.25.25.25.7.m3.1d">20</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.28.28.28.10">
<math alttext="60" class="ltx_Math" display="inline" id="S3.T1.26.26.26.8.m1.1"><semantics id="S3.T1.26.26.26.8.m1.1a"><mn id="S3.T1.26.26.26.8.m1.1.1" mathsize="80%" xref="S3.T1.26.26.26.8.m1.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S3.T1.26.26.26.8.m1.1b"><cn id="S3.T1.26.26.26.8.m1.1.1.cmml" type="integer" xref="S3.T1.26.26.26.8.m1.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.26.26.26.8.m1.1c">60</annotation><annotation encoding="application/x-llamapun" id="S3.T1.26.26.26.8.m1.1d">60</annotation></semantics></math><span class="ltx_text" id="S3.T1.28.28.28.10.1" style="font-size:80%;">/</span><math alttext="20" class="ltx_Math" display="inline" id="S3.T1.27.27.27.9.m2.1"><semantics id="S3.T1.27.27.27.9.m2.1a"><mn id="S3.T1.27.27.27.9.m2.1.1" mathsize="80%" xref="S3.T1.27.27.27.9.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.T1.27.27.27.9.m2.1b"><cn id="S3.T1.27.27.27.9.m2.1.1.cmml" type="integer" xref="S3.T1.27.27.27.9.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.27.27.27.9.m2.1c">20</annotation><annotation encoding="application/x-llamapun" id="S3.T1.27.27.27.9.m2.1d">20</annotation></semantics></math><span class="ltx_text" id="S3.T1.28.28.28.10.2" style="font-size:80%;">/</span><math alttext="20" class="ltx_Math" display="inline" id="S3.T1.28.28.28.10.m3.1"><semantics id="S3.T1.28.28.28.10.m3.1a"><mn id="S3.T1.28.28.28.10.m3.1.1" mathsize="80%" xref="S3.T1.28.28.28.10.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.T1.28.28.28.10.m3.1b"><cn id="S3.T1.28.28.28.10.m3.1.1.cmml" type="integer" xref="S3.T1.28.28.28.10.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.28.28.28.10.m3.1c">20</annotation><annotation encoding="application/x-llamapun" id="S3.T1.28.28.28.10.m3.1d">20</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For our benchmark we built upon the three existing datasets
HyKo2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib4" title="">4</a>]</cite>,
HSI-Drive <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib5" title="">5</a>]</cite>, and
<span class="ltx_glossaryref" title="">HCV2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib6" title="">6</a>]</cite>.
Example images can be seen in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">1</span></a>.
An overview over the datasets is given in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.T1" title="TABLE I ‣ III-A Datasets ‣ III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">I</span></a>.
We do not include the HSI-Road <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib10" title="">10</a>]</cite> dataset since it only uses two classes (cf. section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S2" title="II Related Work ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">II</span></a>). All datasets show a high class imbalance, as apparent in many semantic segmentation datasets.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">HyKo2-VIS</span> consists of images showing urban and rural driving scenarios segmented into 10 classes with classes ”road” (35.8%), ”sky” (15.2%), ”grass” (14.7%) and ”vegetation” (14.1%) being most apparent, and ”lane markers” (1.1%), ”panels” (1.5%) and ”person” (.03%) being least apparent. As the name suggests the images are captured in the visual light spectrum.
We omitted the near-infrared data set of HyKo2 because of the unfavorable sensor setup, which resulted in most images only showing a small patch of street in front of the vehicle.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_glossaryref ltx_font_bold" title="">HCV2</span> was published in the context of the 2021 physics based learning ICCV workshop and shows urban scenarios. It has the highest spectral and spatial resolution and spectral range of the available datasets, covering the visual and near-infrared spectrum. With 19 classes it also has the highest number of distinct class labels. However, eight of the available classes make up less than 1% of all labeled data and there exist no samples for the class ”pole”. The train set includes only coarse labels, while the test set includes fine labels, i. e. objects are very precisely labeled as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.F2" title="Figure 2 ‣ III-A Datasets ‣ III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="226" id="S3.F2.g1" src="extracted/5860638/hcv_labels.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Coarse labels from <span class="ltx_glossaryref" title="">HCV2</span> train set (left) and fine labels from test set (right).</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">HSI-Drive</span> contains 10 classes with ”road” (60.7%) and ”vegetation” (21.3%) being most apparent. All other classes are below 6%, the authors even propose to not use the class ”water” (.03%) because of the low amount of samples available. We follow this recommendation in our benchmark and ignore pixels with this class. When we mention HSI-Drive in this paper we always refer to v2 if not stated otherwise, as it includes v1.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_glossaryref" title="">HCV2</span> comes with a defined train-test split. For the others we calculate dataset splits using pytorch’s <span class="ltx_text ltx_font_italic" id="S3.SS1.p5.1.1">random_split</span>-method to sample train-val-test-splits with proportions as shown in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S3.T1" title="TABLE I ‣ III-A Datasets ‣ III Benchmark: HS3-Bench ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">I</span></a>.
The sample lists for each split and each dataset will be published with the code.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Metrics</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.3">The benchmark implements the commonly used metrics Accuracy (<span class="ltx_text ltx_markedasmath" id="S3.SS2.p1.3.1">Acc</span>), F1-Score (<math alttext="\textnormal{F}_{1}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mtext id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2a.cmml">F</mtext><mn id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2a.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><mtext id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">F</mtext></ci><cn id="S3.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\textnormal{F}_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>) as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib16" title="">16</a>]</cite>, and Jaccard Index (<span class="ltx_text ltx_markedasmath" id="S3.SS2.p1.3.2">J</span>) as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib17" title="">17</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.5"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.5.1">Micro- and macro-averaging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib16" title="">16</a>]</cite>:</span>
Accuracy is calculated in micro- and macro-averaged form, denoted with <math alttext="\mu" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mu</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_μ</annotation></semantics></math> and <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_M</annotation></semantics></math> in subscript, respectively. All other metrics are only calculated in macro averaged form.
With micro averaging, the metric is calculated by averaging over all sample predictions (per pixel), while in macro averaging the metric is calculated per class and the average is then calculated over all class-wise scores. As we are dealing with highly class imbalanced datasets, our evaluation is mostly focused on macro averaged metrics, as micro averaged metrics can be very much influenced by a data set’s majority class. For example in an extreme case of a binary classification problem where <math alttext="99\%" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mn id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">99</mn><mo id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1">percent</csymbol><cn id="S3.SS2.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS2.p2.3.m3.1.1.2">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">99\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">99 %</annotation></semantics></math> of pixels belong to class A a classifier that always predicts A will have a micro-averaged accuracy of <math alttext="99\%" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><mrow id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mn id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">99</mn><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="latexml" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">percent</csymbol><cn id="S3.SS2.p2.4.m4.1.1.2.cmml" type="integer" xref="S3.SS2.p2.4.m4.1.1.2">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">99\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">99 %</annotation></semantics></math> and a macro-averaged accuracy of <math alttext="(100\%+0\%)/2=50\%" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mrow id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mrow id="S3.SS2.p2.5.m5.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.cmml"><mrow id="S3.SS2.p2.5.m5.1.1.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.5.m5.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p2.5.m5.1.1.1.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.cmml"><mrow id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.cmml"><mn id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.2" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.2.cmml">100</mn><mo id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.1" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.1.cmml">%</mo></mrow><mo id="S3.SS2.p2.5.m5.1.1.1.1.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.cmml"><mn id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.2.cmml">0</mn><mo id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.1.cmml">%</mo></mrow></mrow><mo id="S3.SS2.p2.5.m5.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p2.5.m5.1.1.1.2" xref="S3.SS2.p2.5.m5.1.1.1.2.cmml">/</mo><mn id="S3.SS2.p2.5.m5.1.1.1.3" xref="S3.SS2.p2.5.m5.1.1.1.3.cmml">2</mn></mrow><mo id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mn id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">50</mn><mo id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><eq id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2"></eq><apply id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1"><divide id="S3.SS2.p2.5.m5.1.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.1.2"></divide><apply id="S3.SS2.p2.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1"><plus id="S3.SS2.p2.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.1"></plus><apply id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2"><csymbol cd="latexml" id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.1">percent</csymbol><cn id="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.2.cmml" type="integer" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.2.2">100</cn></apply><apply id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.1">percent</csymbol><cn id="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.SS2.p2.5.m5.1.1.1.1.1.1.3.2">0</cn></apply></apply><cn id="S3.SS2.p2.5.m5.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.5.m5.1.1.1.3">2</cn></apply><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1">percent</csymbol><cn id="S3.SS2.p2.5.m5.1.1.3.2.cmml" type="integer" xref="S3.SS2.p2.5.m5.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">(100\%+0\%)/2=50\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">( 100 % + 0 % ) / 2 = 50 %</annotation></semantics></math>. The former would in many cases be seen as overoptimistic, while the latter may be seen as overly pessimistic. Which value carries more weight depends on the problem at hand. Therefore, we provide both values for Accuracy.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.2.1">Summary statistics:</span> In order to capture the performance across multiple datasets in a single number, the benchmark reports the average performance over all datasets <math alttext="d\in\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">d</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><in id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></in><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑑</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">d\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_d ∈ caligraphic_D</annotation></semantics></math> and metric scores <math alttext="S=\{\textnormal{Acc},\textnormal{F}_{1},\textnormal{J}\}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.3"><semantics id="S3.SS2.p3.2.m2.3a"><mrow id="S3.SS2.p3.2.m2.3.3" xref="S3.SS2.p3.2.m2.3.3.cmml"><mi id="S3.SS2.p3.2.m2.3.3.3" xref="S3.SS2.p3.2.m2.3.3.3.cmml">S</mi><mo id="S3.SS2.p3.2.m2.3.3.2" xref="S3.SS2.p3.2.m2.3.3.2.cmml">=</mo><mrow id="S3.SS2.p3.2.m2.3.3.1.1" xref="S3.SS2.p3.2.m2.3.3.1.2.cmml"><mo id="S3.SS2.p3.2.m2.3.3.1.1.2" stretchy="false" xref="S3.SS2.p3.2.m2.3.3.1.2.cmml">{</mo><mtext id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1a.cmml">Acc</mtext><mo id="S3.SS2.p3.2.m2.3.3.1.1.3" xref="S3.SS2.p3.2.m2.3.3.1.2.cmml">,</mo><msub id="S3.SS2.p3.2.m2.3.3.1.1.1" xref="S3.SS2.p3.2.m2.3.3.1.1.1.cmml"><mtext id="S3.SS2.p3.2.m2.3.3.1.1.1.2" xref="S3.SS2.p3.2.m2.3.3.1.1.1.2a.cmml">F</mtext><mn id="S3.SS2.p3.2.m2.3.3.1.1.1.3" xref="S3.SS2.p3.2.m2.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p3.2.m2.3.3.1.1.4" xref="S3.SS2.p3.2.m2.3.3.1.2.cmml">,</mo><mtext id="S3.SS2.p3.2.m2.2.2" xref="S3.SS2.p3.2.m2.2.2a.cmml">J</mtext><mo id="S3.SS2.p3.2.m2.3.3.1.1.5" stretchy="false" xref="S3.SS2.p3.2.m2.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.3b"><apply id="S3.SS2.p3.2.m2.3.3.cmml" xref="S3.SS2.p3.2.m2.3.3"><eq id="S3.SS2.p3.2.m2.3.3.2.cmml" xref="S3.SS2.p3.2.m2.3.3.2"></eq><ci id="S3.SS2.p3.2.m2.3.3.3.cmml" xref="S3.SS2.p3.2.m2.3.3.3">𝑆</ci><set id="S3.SS2.p3.2.m2.3.3.1.2.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1"><ci id="S3.SS2.p3.2.m2.1.1a.cmml" xref="S3.SS2.p3.2.m2.1.1"><mtext id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">Acc</mtext></ci><apply id="S3.SS2.p3.2.m2.3.3.1.1.1.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.3.3.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.3.3.1.1.1.2a.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.1.2"><mtext id="S3.SS2.p3.2.m2.3.3.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.1.2">F</mtext></ci><cn id="S3.SS2.p3.2.m2.3.3.1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.2.m2.3.3.1.1.1.3">1</cn></apply><ci id="S3.SS2.p3.2.m2.2.2a.cmml" xref="S3.SS2.p3.2.m2.2.2"><mtext id="S3.SS2.p3.2.m2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2">J</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.3c">S=\{\textnormal{Acc},\textnormal{F}_{1},\textnormal{J}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.3d">italic_S = { Acc , F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , J }</annotation></semantics></math>. To identify potential generalization problems, the benchmark also reports the worst case performance across all dataset (i.e. the minimum value for a metric across all datasets).</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S6.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle S_{avg}=\frac{1}{|\mathcal{D}|}\sum_{d\in\mathcal{D}}S_{d}," class="ltx_Math" display="inline" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><msub id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2" xref="S3.E1.m1.2.2.1.1.2.2.cmml">S</mi><mrow id="S3.E1.m1.2.2.1.1.2.3" xref="S3.E1.m1.2.2.1.1.2.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.2.3.2.cmml">a</mi><mo id="S3.E1.m1.2.2.1.1.2.3.1" xref="S3.E1.m1.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.2.3.3" xref="S3.E1.m1.2.2.1.1.2.3.3.cmml">v</mi><mo id="S3.E1.m1.2.2.1.1.2.3.1a" xref="S3.E1.m1.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.2.3.4" xref="S3.E1.m1.2.2.1.1.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml"><mstyle displaystyle="true" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mfrac id="S3.E1.m1.1.1a" xref="S3.E1.m1.1.1.cmml"><mn id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">1</mn><mrow id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.1.3.1" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">𝒟</mi><mo id="S3.E1.m1.1.1.1.3.2" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac></mstyle><mo id="S3.E1.m1.2.2.1.1.3.1" xref="S3.E1.m1.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.1.1.3.2" xref="S3.E1.m1.2.2.1.1.3.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.3.2.1.cmml"><munder id="S3.E1.m1.2.2.1.1.3.2.1a" xref="S3.E1.m1.2.2.1.1.3.2.1.cmml"><mo id="S3.E1.m1.2.2.1.1.3.2.1.2" movablelimits="false" xref="S3.E1.m1.2.2.1.1.3.2.1.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.1.1.3.2.1.3" xref="S3.E1.m1.2.2.1.1.3.2.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.3.2.1.3.2" xref="S3.E1.m1.2.2.1.1.3.2.1.3.2.cmml">d</mi><mo id="S3.E1.m1.2.2.1.1.3.2.1.3.1" xref="S3.E1.m1.2.2.1.1.3.2.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.3.2.1.3.3" xref="S3.E1.m1.2.2.1.1.3.2.1.3.3.cmml">𝒟</mi></mrow></munder></mstyle><msub id="S3.E1.m1.2.2.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.3.2.2.2" xref="S3.E1.m1.2.2.1.1.3.2.2.2.cmml">S</mi><mi id="S3.E1.m1.2.2.1.1.3.2.2.3" xref="S3.E1.m1.2.2.1.1.3.2.2.3.cmml">d</mi></msub></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"></eq><apply id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2">𝑆</ci><apply id="S3.E1.m1.2.2.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.3"><times id="S3.E1.m1.2.2.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.3.1"></times><ci id="S3.E1.m1.2.2.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.3.2">𝑎</ci><ci id="S3.E1.m1.2.2.1.1.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.3.3">𝑣</ci><ci id="S3.E1.m1.2.2.1.1.2.3.4.cmml" xref="S3.E1.m1.2.2.1.1.2.3.4">𝑔</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"><times id="S3.E1.m1.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3.1"></times><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><cn id="S3.E1.m1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.3">1</cn><apply id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.3"><abs id="S3.E1.m1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.3.1"></abs><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝒟</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2"><apply id="S3.E1.m1.2.2.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.3.2.1.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.2"></sum><apply id="S3.E1.m1.2.2.1.1.3.2.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.3"><in id="S3.E1.m1.2.2.1.1.3.2.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.3.1"></in><ci id="S3.E1.m1.2.2.1.1.3.2.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.3.2">𝑑</ci><ci id="S3.E1.m1.2.2.1.1.3.2.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.3.3">𝒟</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.3.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.2.2">𝑆</ci><ci id="S3.E1.m1.2.2.1.1.3.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.3.2.2.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\displaystyle S_{avg}=\frac{1}{|\mathcal{D}|}\sum_{d\in\mathcal{D}}S_{d},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_S start_POSTSUBSCRIPT italic_a italic_v italic_g end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG | caligraphic_D | end_ARG ∑ start_POSTSUBSCRIPT italic_d ∈ caligraphic_D end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle S_{wc}=\min_{d\in\mathcal{D}}S_{d}" class="ltx_Math" display="inline" id="S3.E1.m2.1"><semantics id="S3.E1.m2.1a"><mrow id="S3.E1.m2.1.1" xref="S3.E1.m2.1.1.cmml"><msub id="S3.E1.m2.1.1.2" xref="S3.E1.m2.1.1.2.cmml"><mi id="S3.E1.m2.1.1.2.2" xref="S3.E1.m2.1.1.2.2.cmml">S</mi><mrow id="S3.E1.m2.1.1.2.3" xref="S3.E1.m2.1.1.2.3.cmml"><mi id="S3.E1.m2.1.1.2.3.2" xref="S3.E1.m2.1.1.2.3.2.cmml">w</mi><mo id="S3.E1.m2.1.1.2.3.1" xref="S3.E1.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m2.1.1.2.3.3" xref="S3.E1.m2.1.1.2.3.3.cmml">c</mi></mrow></msub><mo id="S3.E1.m2.1.1.1" xref="S3.E1.m2.1.1.1.cmml">=</mo><mrow id="S3.E1.m2.1.1.3" xref="S3.E1.m2.1.1.3.cmml"><munder id="S3.E1.m2.1.1.3.1" xref="S3.E1.m2.1.1.3.1.cmml"><mi id="S3.E1.m2.1.1.3.1.2" xref="S3.E1.m2.1.1.3.1.2.cmml">min</mi><mrow id="S3.E1.m2.1.1.3.1.3" xref="S3.E1.m2.1.1.3.1.3.cmml"><mi id="S3.E1.m2.1.1.3.1.3.2" xref="S3.E1.m2.1.1.3.1.3.2.cmml">d</mi><mo id="S3.E1.m2.1.1.3.1.3.1" xref="S3.E1.m2.1.1.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m2.1.1.3.1.3.3" xref="S3.E1.m2.1.1.3.1.3.3.cmml">𝒟</mi></mrow></munder><mo id="S3.E1.m2.1.1.3a" lspace="0.167em" xref="S3.E1.m2.1.1.3.cmml">⁡</mo><msub id="S3.E1.m2.1.1.3.2" xref="S3.E1.m2.1.1.3.2.cmml"><mi id="S3.E1.m2.1.1.3.2.2" xref="S3.E1.m2.1.1.3.2.2.cmml">S</mi><mi id="S3.E1.m2.1.1.3.2.3" xref="S3.E1.m2.1.1.3.2.3.cmml">d</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m2.1b"><apply id="S3.E1.m2.1.1.cmml" xref="S3.E1.m2.1.1"><eq id="S3.E1.m2.1.1.1.cmml" xref="S3.E1.m2.1.1.1"></eq><apply id="S3.E1.m2.1.1.2.cmml" xref="S3.E1.m2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.2.1.cmml" xref="S3.E1.m2.1.1.2">subscript</csymbol><ci id="S3.E1.m2.1.1.2.2.cmml" xref="S3.E1.m2.1.1.2.2">𝑆</ci><apply id="S3.E1.m2.1.1.2.3.cmml" xref="S3.E1.m2.1.1.2.3"><times id="S3.E1.m2.1.1.2.3.1.cmml" xref="S3.E1.m2.1.1.2.3.1"></times><ci id="S3.E1.m2.1.1.2.3.2.cmml" xref="S3.E1.m2.1.1.2.3.2">𝑤</ci><ci id="S3.E1.m2.1.1.2.3.3.cmml" xref="S3.E1.m2.1.1.2.3.3">𝑐</ci></apply></apply><apply id="S3.E1.m2.1.1.3.cmml" xref="S3.E1.m2.1.1.3"><apply id="S3.E1.m2.1.1.3.1.cmml" xref="S3.E1.m2.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.3.1.1.cmml" xref="S3.E1.m2.1.1.3.1">subscript</csymbol><min id="S3.E1.m2.1.1.3.1.2.cmml" xref="S3.E1.m2.1.1.3.1.2"></min><apply id="S3.E1.m2.1.1.3.1.3.cmml" xref="S3.E1.m2.1.1.3.1.3"><in id="S3.E1.m2.1.1.3.1.3.1.cmml" xref="S3.E1.m2.1.1.3.1.3.1"></in><ci id="S3.E1.m2.1.1.3.1.3.2.cmml" xref="S3.E1.m2.1.1.3.1.3.2">𝑑</ci><ci id="S3.E1.m2.1.1.3.1.3.3.cmml" xref="S3.E1.m2.1.1.3.1.3.3">𝒟</ci></apply></apply><apply id="S3.E1.m2.1.1.3.2.cmml" xref="S3.E1.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.3.2.1.cmml" xref="S3.E1.m2.1.1.3.2">subscript</csymbol><ci id="S3.E1.m2.1.1.3.2.2.cmml" xref="S3.E1.m2.1.1.3.2.2">𝑆</ci><ci id="S3.E1.m2.1.1.3.2.3.cmml" xref="S3.E1.m2.1.1.3.2.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m2.1c">\displaystyle S_{wc}=\min_{d\in\mathcal{D}}S_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m2.1d">italic_S start_POSTSUBSCRIPT italic_w italic_c end_POSTSUBSCRIPT = roman_min start_POSTSUBSCRIPT italic_d ∈ caligraphic_D end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.3">These summary statistics will become even more important when more datasets become available for inclusion in the benchmark.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Benchmark guidelines</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The provided benchmark implementation is intended to facilitate the creation of comparable results across different research groups. There are a couple of benchmark guidelines that have to be followed by each user:</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.1">All</span> datasets and <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.2">all</span> metrics should be evaluated to avoid suspicion of cherry-picking.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">The intention is to evaluate a single approach on multiple datasets. Therefore, the <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.1">same</span> algorithm or the <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.2">same</span> model architecture should be used for <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.3">all</span> datasets.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">The model can be trained individually for each dataset.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">If different hyperparameters are used for different datasets, this should be stated explicitly.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1">Only train and validation data splits can be used for training and hyperparameter tuning. The test data should only be used once for the final evaluation.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="S3.I1.i6.p1">
<p class="ltx_p" id="S3.I1.i6.p1.1">If additional datasets are used for training or parameter tuning or pre-trained models are used, this should be stated explicitly.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="S3.I1.i7.p1">
<p class="ltx_p" id="S3.I1.i7.p1.1">We strongly encourage benchmark users to also provide information about the computational effort (runtime, memory, used hardware) and to share implementations and trained models.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Strong baselines</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We present two strong baselines. One based on a small and well regularized model that uses only the training data provided with the benchmark <span class="ltx_glossaryref" title="">HSI</span> dataset. And a second, larger model that is well suited to leverage additional data through initialization with pre-trained weights.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Models</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our baseline approaches build upon two different model architectures, U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib11" title="">11</a>]</cite> and <span class="ltx_glossaryref" title="">DL3+</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib12" title="">12</a>]</cite>. These where chosen as they were suitable for our experiments and because they represent well-established architectures for the given task.
The U-Net model implements an Encoder-Decoder-Architecture. In the encoder, the model first compresses data to a discriminative low-resolution feature map and then recovers the original resolution in the decoder, guided by skip-connections in intermediate layers.
In contrast to the original U-Net model we (1) use bilinear upsampling instead of transposed convolutions in the decoder to avoid checkerboard artifacts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib18" title="">18</a>]</cite>, (2) adapt the channel size of the input layer to allow the training of images with an arbitrary feature dimension, and (3) apply a combination of regularization techniques to account for small training set sizes. The following subsection <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.SS2" title="IV-B Using HS3-Bench for Hyperparameter Tuning ‣ IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a> will demonstrate how the HS3-Bench can be used for hyperparameter tuning of the resulting regularized U-Net (RU-Net).</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The <span class="ltx_glossaryref" title="">DL3+</span> model extends the DeeplabV3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib19" title="">19</a>]</cite> model. Both models use an <span class="ltx_glossaryref" title="">atrous spatial pyramid pooling (ASPP)</span> module to extract rich semantic features at multiple image resolutions without poooling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib12" title="">12</a>]</cite>. To combine this property with the advantage of Encoder-Decoder-based architectures, <span class="ltx_glossaryref" title="">DL3+</span> extends DeeplabV3 with a decoder module that guides the model in recovering the original image resolution with intermediate feature maps, allowing it to better recover small objects and object boundaries compared to its predecessor. For initial input processing we use a MobileNetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib20" title="">20</a>]</cite> backbone network. To train the model with images of arbitrary feature dimension, we introduce a <math alttext="1\times 1" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS1.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><cn id="S4.SS1.p2.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.2">1</cn><cn id="S4.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">1\times 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">1 × 1</annotation></semantics></math> convolutional layer as input layer that reduces the dimensionality to 3 and makes it compatible with the expected input dimension of the original model for RGB data.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Using HS3-Bench for Hyperparameter Tuning</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The proposed HS3-Bench can be used to derive model hyperparameters. As a demonstration, we used this for deriving a regularization configuration for RU-Net in order to reduce the risk of overfitting.
We considered <span class="ltx_glossaryref" title="">data augmentation (DA)</span>, <span class="ltx_glossaryref" title="">weight decay (WD)</span>, <span class="ltx_glossaryref" title="">class weighting (CW)</span>, <span class="ltx_glossaryref" title="">batch normalization (BN)</span>, and <span class="ltx_glossaryref" title="">dropout (DO)</span> as potential regularization techniques. We systematically tested different combinations and parameterizations by fitting the model parameters on the HS3-Bench training datasets and evaluated the trained models on the validation set to receive an estimation of the model performance on unseen data. By monitoring the average performance values we were able to identify hyperparameter settings that generalize well across all datasets.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Following this system, we identified <span class="ltx_glossaryref" title="">BN</span> as well as <span class="ltx_glossaryref" title="">DA</span> and <span class="ltx_glossaryref" title="">DO</span> with respective probabilities of 0.1 and 0.25 as best configuration. TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a> shows the resulting improvement on the HS3-Bench test data. A detailed discussion of the results from this table will follow in section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5" title="V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">V</span></a>. As an example, compared to regular U-Net the average Jaccard score improves by <math alttext="+4.32\%" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mo id="S4.SS2.p2.1.m1.1.1a" xref="S4.SS2.p2.1.m1.1.1.cmml">+</mo><mrow id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2.2" xref="S4.SS2.p2.1.m1.1.1.2.2.cmml">4.32</mn><mo id="S4.SS2.p2.1.m1.1.1.2.1" xref="S4.SS2.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><plus id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"></plus><apply id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1.2.1">percent</csymbol><cn id="S4.SS2.p2.1.m1.1.1.2.2.cmml" type="float" xref="S4.SS2.p2.1.m1.1.1.2.2">4.32</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">+4.32\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">+ 4.32 %</annotation></semantics></math></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Synthesizing (Pseudo-)RGB Images</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">It is common ground that in many deep learning applications, access to more data can provide substantial improvements. In driving scenarios, there are large amounts of RGB training images and pre-trained networks available. For example, <span class="ltx_glossaryref" title="">DL3+</span> uses a MobileNetV2 backbone network for which model weights pre-trained on ImageNet<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The pre-trained model weights provided by Pytorch were used: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pytorch.org/vision/stable/models.html" title="">https://pytorch.org/vision/stable/models.html</a></span></span></span> are publicly available.
To benefit from this additional information we can synthesize RGB images from hyperspectral images.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.8">We follow the simple approach of Ding et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite>, by manually selecting three bands from all spectral bands in the <span class="ltx_glossaryref" title="">HSIs</span> that resemble the red, green, and blue channels. We used channels <math alttext="(63,19,1)" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.3"><semantics id="S4.SS3.p2.1.m1.3a"><mrow id="S4.SS3.p2.1.m1.3.4.2" xref="S4.SS3.p2.1.m1.3.4.1.cmml"><mo id="S4.SS3.p2.1.m1.3.4.2.1" stretchy="false" xref="S4.SS3.p2.1.m1.3.4.1.cmml">(</mo><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">63</mn><mo id="S4.SS3.p2.1.m1.3.4.2.2" xref="S4.SS3.p2.1.m1.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.1.m1.2.2" xref="S4.SS3.p2.1.m1.2.2.cmml">19</mn><mo id="S4.SS3.p2.1.m1.3.4.2.3" xref="S4.SS3.p2.1.m1.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.1.m1.3.3" xref="S4.SS3.p2.1.m1.3.3.cmml">1</mn><mo id="S4.SS3.p2.1.m1.3.4.2.4" stretchy="false" xref="S4.SS3.p2.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.3b"><vector id="S4.SS3.p2.1.m1.3.4.1.cmml" xref="S4.SS3.p2.1.m1.3.4.2"><cn id="S4.SS3.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS3.p2.1.m1.1.1">63</cn><cn id="S4.SS3.p2.1.m1.2.2.cmml" type="integer" xref="S4.SS3.p2.1.m1.2.2">19</cn><cn id="S4.SS3.p2.1.m1.3.3.cmml" type="integer" xref="S4.SS3.p2.1.m1.3.3">1</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.3c">(63,19,1)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.3d">( 63 , 19 , 1 )</annotation></semantics></math>, <math alttext="(14,7,0)" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.3"><semantics id="S4.SS3.p2.2.m2.3a"><mrow id="S4.SS3.p2.2.m2.3.4.2" xref="S4.SS3.p2.2.m2.3.4.1.cmml"><mo id="S4.SS3.p2.2.m2.3.4.2.1" stretchy="false" xref="S4.SS3.p2.2.m2.3.4.1.cmml">(</mo><mn id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">14</mn><mo id="S4.SS3.p2.2.m2.3.4.2.2" xref="S4.SS3.p2.2.m2.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.2.m2.2.2" xref="S4.SS3.p2.2.m2.2.2.cmml">7</mn><mo id="S4.SS3.p2.2.m2.3.4.2.3" xref="S4.SS3.p2.2.m2.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.2.m2.3.3" xref="S4.SS3.p2.2.m2.3.3.cmml">0</mn><mo id="S4.SS3.p2.2.m2.3.4.2.4" stretchy="false" xref="S4.SS3.p2.2.m2.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.3b"><vector id="S4.SS3.p2.2.m2.3.4.1.cmml" xref="S4.SS3.p2.2.m2.3.4.2"><cn id="S4.SS3.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS3.p2.2.m2.1.1">14</cn><cn id="S4.SS3.p2.2.m2.2.2.cmml" type="integer" xref="S4.SS3.p2.2.m2.2.2">7</cn><cn id="S4.SS3.p2.2.m2.3.3.cmml" type="integer" xref="S4.SS3.p2.2.m2.3.3">0</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.3c">(14,7,0)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.3d">( 14 , 7 , 0 )</annotation></semantics></math> and <math alttext="(2,1,0)" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.3"><semantics id="S4.SS3.p2.3.m3.3a"><mrow id="S4.SS3.p2.3.m3.3.4.2" xref="S4.SS3.p2.3.m3.3.4.1.cmml"><mo id="S4.SS3.p2.3.m3.3.4.2.1" stretchy="false" xref="S4.SS3.p2.3.m3.3.4.1.cmml">(</mo><mn id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">2</mn><mo id="S4.SS3.p2.3.m3.3.4.2.2" xref="S4.SS3.p2.3.m3.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.3.m3.2.2" xref="S4.SS3.p2.3.m3.2.2.cmml">1</mn><mo id="S4.SS3.p2.3.m3.3.4.2.3" xref="S4.SS3.p2.3.m3.3.4.1.cmml">,</mo><mn id="S4.SS3.p2.3.m3.3.3" xref="S4.SS3.p2.3.m3.3.3.cmml">0</mn><mo id="S4.SS3.p2.3.m3.3.4.2.4" stretchy="false" xref="S4.SS3.p2.3.m3.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.3b"><vector id="S4.SS3.p2.3.m3.3.4.1.cmml" xref="S4.SS3.p2.3.m3.3.4.2"><cn id="S4.SS3.p2.3.m3.1.1.cmml" type="integer" xref="S4.SS3.p2.3.m3.1.1">2</cn><cn id="S4.SS3.p2.3.m3.2.2.cmml" type="integer" xref="S4.SS3.p2.3.m3.2.2">1</cn><cn id="S4.SS3.p2.3.m3.3.3.cmml" type="integer" xref="S4.SS3.p2.3.m3.3.3">0</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.3c">(2,1,0)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.3d">( 2 , 1 , 0 )</annotation></semantics></math> for <span class="ltx_glossaryref" title="">HCV2</span>, HyKo2 and HSI-Drive respectively. We scale all pixels <math alttext="\mathbf{p}\in\mathbb{R}^{3}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">𝐩</mi><mo id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml"><mi id="S4.SS3.p2.4.m4.1.1.3.2" xref="S4.SS3.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mn id="S4.SS3.p2.4.m4.1.1.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><in id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1"></in><ci id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">𝐩</ci><apply id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2">ℝ</ci><cn id="S4.SS3.p2.4.m4.1.1.3.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\mathbf{p}\in\mathbb{R}^{3}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">bold_p ∈ blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math> in the synthesized image according to the channel-specific min- and max-values <math alttext="\mathbf{p}_{min}" class="ltx_Math" display="inline" id="S4.SS3.p2.5.m5.1"><semantics id="S4.SS3.p2.5.m5.1a"><msub id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">𝐩</mi><mrow id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml"><mi id="S4.SS3.p2.5.m5.1.1.3.2" xref="S4.SS3.p2.5.m5.1.1.3.2.cmml">m</mi><mo id="S4.SS3.p2.5.m5.1.1.3.1" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS3.p2.5.m5.1.1.3.3" xref="S4.SS3.p2.5.m5.1.1.3.3.cmml">i</mi><mo id="S4.SS3.p2.5.m5.1.1.3.1a" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS3.p2.5.m5.1.1.3.4" xref="S4.SS3.p2.5.m5.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">𝐩</ci><apply id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3"><times id="S4.SS3.p2.5.m5.1.1.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1"></times><ci id="S4.SS3.p2.5.m5.1.1.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2">𝑚</ci><ci id="S4.SS3.p2.5.m5.1.1.3.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.3">𝑖</ci><ci id="S4.SS3.p2.5.m5.1.1.3.4.cmml" xref="S4.SS3.p2.5.m5.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">\mathbf{p}_{min}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.5.m5.1d">bold_p start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\mathbf{p}_{max}\in\mathbb{R}^{3}" class="ltx_Math" display="inline" id="S4.SS3.p2.6.m6.1"><semantics id="S4.SS3.p2.6.m6.1a"><mrow id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml"><msub id="S4.SS3.p2.6.m6.1.1.2" xref="S4.SS3.p2.6.m6.1.1.2.cmml"><mi id="S4.SS3.p2.6.m6.1.1.2.2" xref="S4.SS3.p2.6.m6.1.1.2.2.cmml">𝐩</mi><mrow id="S4.SS3.p2.6.m6.1.1.2.3" xref="S4.SS3.p2.6.m6.1.1.2.3.cmml"><mi id="S4.SS3.p2.6.m6.1.1.2.3.2" xref="S4.SS3.p2.6.m6.1.1.2.3.2.cmml">m</mi><mo id="S4.SS3.p2.6.m6.1.1.2.3.1" xref="S4.SS3.p2.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS3.p2.6.m6.1.1.2.3.3" xref="S4.SS3.p2.6.m6.1.1.2.3.3.cmml">a</mi><mo id="S4.SS3.p2.6.m6.1.1.2.3.1a" xref="S4.SS3.p2.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS3.p2.6.m6.1.1.2.3.4" xref="S4.SS3.p2.6.m6.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S4.SS3.p2.6.m6.1.1.1" xref="S4.SS3.p2.6.m6.1.1.1.cmml">∈</mo><msup id="S4.SS3.p2.6.m6.1.1.3" xref="S4.SS3.p2.6.m6.1.1.3.cmml"><mi id="S4.SS3.p2.6.m6.1.1.3.2" xref="S4.SS3.p2.6.m6.1.1.3.2.cmml">ℝ</mi><mn id="S4.SS3.p2.6.m6.1.1.3.3" xref="S4.SS3.p2.6.m6.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><apply id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"><in id="S4.SS3.p2.6.m6.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1"></in><apply id="S4.SS3.p2.6.m6.1.1.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.1.1.2.1.cmml" xref="S4.SS3.p2.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.6.m6.1.1.2.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2.2">𝐩</ci><apply id="S4.SS3.p2.6.m6.1.1.2.3.cmml" xref="S4.SS3.p2.6.m6.1.1.2.3"><times id="S4.SS3.p2.6.m6.1.1.2.3.1.cmml" xref="S4.SS3.p2.6.m6.1.1.2.3.1"></times><ci id="S4.SS3.p2.6.m6.1.1.2.3.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2.3.2">𝑚</ci><ci id="S4.SS3.p2.6.m6.1.1.2.3.3.cmml" xref="S4.SS3.p2.6.m6.1.1.2.3.3">𝑎</ci><ci id="S4.SS3.p2.6.m6.1.1.2.3.4.cmml" xref="S4.SS3.p2.6.m6.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S4.SS3.p2.6.m6.1.1.3.cmml" xref="S4.SS3.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.1.1.3.1.cmml" xref="S4.SS3.p2.6.m6.1.1.3">superscript</csymbol><ci id="S4.SS3.p2.6.m6.1.1.3.2.cmml" xref="S4.SS3.p2.6.m6.1.1.3.2">ℝ</ci><cn id="S4.SS3.p2.6.m6.1.1.3.3.cmml" type="integer" xref="S4.SS3.p2.6.m6.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">\mathbf{p}_{max}\in\mathbb{R}^{3}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.6.m6.1d">bold_p start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math> derived from the whole dataset. Hence, for each image pixel <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS3.p2.7.m7.1"><semantics id="S4.SS3.p2.7.m7.1a"><mi id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><ci id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.7.m7.1d">bold_p</annotation></semantics></math> and all images in the dataset we calculate the new pixel values <math alttext="\mathbf{p^{\prime}}" class="ltx_Math" display="inline" id="S4.SS3.p2.8.m8.1"><semantics id="S4.SS3.p2.8.m8.1a"><msup id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mi id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml">𝐩</mi><mo id="S4.SS3.p2.8.m8.1.1.3" xref="S4.SS3.p2.8.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">superscript</csymbol><ci id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2">𝐩</ci><ci id="S4.SS3.p2.8.m8.1.1.3.cmml" xref="S4.SS3.p2.8.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">\mathbf{p^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.8.m8.1d">bold_p start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math></p>
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{p^{\prime}}=(\mathbf{p}-\mathbf{p}_{min})/(\mathbf{p}_{max}-\mathbf{p}%
_{min})" class="ltx_Math" display="block" id="S4.E2.m1.2"><semantics id="S4.E2.m1.2a"><mrow id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml"><msup id="S4.E2.m1.2.2.4" xref="S4.E2.m1.2.2.4.cmml"><mi id="S4.E2.m1.2.2.4.2" xref="S4.E2.m1.2.2.4.2.cmml">𝐩</mi><mo id="S4.E2.m1.2.2.4.3" xref="S4.E2.m1.2.2.4.3.cmml">′</mo></msup><mo id="S4.E2.m1.2.2.3" xref="S4.E2.m1.2.2.3.cmml">=</mo><mrow id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml"><mrow id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.cmml">𝐩</mi><mo id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S4.E2.m1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.1.1.3.2.cmml">𝐩</mi><mrow id="S4.E2.m1.1.1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.3.3.2" xref="S4.E2.m1.1.1.1.1.1.1.3.3.2.cmml">m</mi><mo id="S4.E2.m1.1.1.1.1.1.1.3.3.1" xref="S4.E2.m1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.3.3" xref="S4.E2.m1.1.1.1.1.1.1.3.3.3.cmml">i</mi><mo id="S4.E2.m1.1.1.1.1.1.1.3.3.1a" xref="S4.E2.m1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.1.1.1.1.1.1.3.3.4" xref="S4.E2.m1.1.1.1.1.1.1.3.3.4.cmml">n</mi></mrow></msub></mrow><mo id="S4.E2.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E2.m1.2.2.2.3" xref="S4.E2.m1.2.2.2.3.cmml">/</mo><mrow id="S4.E2.m1.2.2.2.2.1" xref="S4.E2.m1.2.2.2.2.1.1.cmml"><mo id="S4.E2.m1.2.2.2.2.1.2" stretchy="false" xref="S4.E2.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S4.E2.m1.2.2.2.2.1.1" xref="S4.E2.m1.2.2.2.2.1.1.cmml"><msub id="S4.E2.m1.2.2.2.2.1.1.2" xref="S4.E2.m1.2.2.2.2.1.1.2.cmml"><mi id="S4.E2.m1.2.2.2.2.1.1.2.2" xref="S4.E2.m1.2.2.2.2.1.1.2.2.cmml">𝐩</mi><mrow id="S4.E2.m1.2.2.2.2.1.1.2.3" xref="S4.E2.m1.2.2.2.2.1.1.2.3.cmml"><mi id="S4.E2.m1.2.2.2.2.1.1.2.3.2" xref="S4.E2.m1.2.2.2.2.1.1.2.3.2.cmml">m</mi><mo id="S4.E2.m1.2.2.2.2.1.1.2.3.1" xref="S4.E2.m1.2.2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S4.E2.m1.2.2.2.2.1.1.2.3.3" xref="S4.E2.m1.2.2.2.2.1.1.2.3.3.cmml">a</mi><mo id="S4.E2.m1.2.2.2.2.1.1.2.3.1a" xref="S4.E2.m1.2.2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S4.E2.m1.2.2.2.2.1.1.2.3.4" xref="S4.E2.m1.2.2.2.2.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S4.E2.m1.2.2.2.2.1.1.1" xref="S4.E2.m1.2.2.2.2.1.1.1.cmml">−</mo><msub id="S4.E2.m1.2.2.2.2.1.1.3" xref="S4.E2.m1.2.2.2.2.1.1.3.cmml"><mi id="S4.E2.m1.2.2.2.2.1.1.3.2" xref="S4.E2.m1.2.2.2.2.1.1.3.2.cmml">𝐩</mi><mrow id="S4.E2.m1.2.2.2.2.1.1.3.3" xref="S4.E2.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S4.E2.m1.2.2.2.2.1.1.3.3.2" xref="S4.E2.m1.2.2.2.2.1.1.3.3.2.cmml">m</mi><mo id="S4.E2.m1.2.2.2.2.1.1.3.3.1" xref="S4.E2.m1.2.2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.2.2.2.2.1.1.3.3.3" xref="S4.E2.m1.2.2.2.2.1.1.3.3.3.cmml">i</mi><mo id="S4.E2.m1.2.2.2.2.1.1.3.3.1a" xref="S4.E2.m1.2.2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.2.2.2.2.1.1.3.3.4" xref="S4.E2.m1.2.2.2.2.1.1.3.3.4.cmml">n</mi></mrow></msub></mrow><mo id="S4.E2.m1.2.2.2.2.1.3" stretchy="false" xref="S4.E2.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.2b"><apply id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2"><eq id="S4.E2.m1.2.2.3.cmml" xref="S4.E2.m1.2.2.3"></eq><apply id="S4.E2.m1.2.2.4.cmml" xref="S4.E2.m1.2.2.4"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.4.1.cmml" xref="S4.E2.m1.2.2.4">superscript</csymbol><ci id="S4.E2.m1.2.2.4.2.cmml" xref="S4.E2.m1.2.2.4.2">𝐩</ci><ci id="S4.E2.m1.2.2.4.3.cmml" xref="S4.E2.m1.2.2.4.3">′</ci></apply><apply id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2"><divide id="S4.E2.m1.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.3"></divide><apply id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"><minus id="S4.E2.m1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1"></minus><ci id="S4.E2.m1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2">𝐩</ci><apply id="S4.E2.m1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.2">𝐩</ci><apply id="S4.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.3"><times id="S4.E2.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E2.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.3.2">𝑚</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.3.3">𝑖</ci><ci id="S4.E2.m1.1.1.1.1.1.1.3.3.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.3.4">𝑛</ci></apply></apply></apply><apply id="S4.E2.m1.2.2.2.2.1.1.cmml" xref="S4.E2.m1.2.2.2.2.1"><minus id="S4.E2.m1.2.2.2.2.1.1.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.1"></minus><apply id="S4.E2.m1.2.2.2.2.1.1.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.1.1.2.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2">subscript</csymbol><ci id="S4.E2.m1.2.2.2.2.1.1.2.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.2">𝐩</ci><apply id="S4.E2.m1.2.2.2.2.1.1.2.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.3"><times id="S4.E2.m1.2.2.2.2.1.1.2.3.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.3.1"></times><ci id="S4.E2.m1.2.2.2.2.1.1.2.3.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.3.2">𝑚</ci><ci id="S4.E2.m1.2.2.2.2.1.1.2.3.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.3.3">𝑎</ci><ci id="S4.E2.m1.2.2.2.2.1.1.2.3.4.cmml" xref="S4.E2.m1.2.2.2.2.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S4.E2.m1.2.2.2.2.1.1.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.1.1.3.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3">subscript</csymbol><ci id="S4.E2.m1.2.2.2.2.1.1.3.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.2">𝐩</ci><apply id="S4.E2.m1.2.2.2.2.1.1.3.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.3"><times id="S4.E2.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S4.E2.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.3.2">𝑚</ci><ci id="S4.E2.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.3.3">𝑖</ci><ci id="S4.E2.m1.2.2.2.2.1.1.3.3.4.cmml" xref="S4.E2.m1.2.2.2.2.1.1.3.3.4">𝑛</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.2c">\mathbf{p^{\prime}}=(\mathbf{p}-\mathbf{p}_{min})/(\mathbf{p}_{max}-\mathbf{p}%
_{min})</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.2d">bold_p start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( bold_p - bold_p start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT ) / ( bold_p start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT - bold_p start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">As HSI-Drive only covers the red and near-infrared spectrum, which does not allow the estimation of RGB images, we will refer to the synthesized images as <span class="ltx_glossaryref" title="">pseudo-RGB (pRGB)</span> images from now on. Example images are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.F3" title="Figure 3 ‣ IV-C Synthesizing (Pseudo-)RGB Images ‣ IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">3</span></a>. Note that this drastically reduces the data volume and feature dimensionality.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">As a special property, <span class="ltx_glossaryref" title="">HCV2</span> also provides images from an RGB camera together with the <span class="ltx_glossaryref" title="">HSI</span> data. The RGB images are synchronized and cropped to the same resolution as their <span class="ltx_glossaryref" title="">HSI</span> counterparts. The images were exactly registered such that pixels at the same image coordinates refer to the same object in world coordinates. However, in general such data is not available for <span class="ltx_glossaryref" title="">HSI</span> datasets.
When we use this data for comparison, we will apply the same normalization strategy from eq. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.E2" title="In IV-C Synthesizing (Pseudo-)RGB Images ‣ IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="322" id="S4.F3.g1" src="extracted/5860638/prgb-images.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples of <span class="ltx_glossaryref" title="">pRGB</span> images synthesized from <span class="ltx_glossaryref" title="">HSI</span> images for HyKo2 (top left), <span class="ltx_glossaryref" title="">HCV2</span> (top right), HSI-Drive (bottom left) and RGB images supplied together with <span class="ltx_glossaryref" title="">HCV2</span> (bottom right).</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Experiments &amp; Results</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we will use HS3-Bench to evaluate the performance of different algorithms and input data configurations for semantic segmentation on <span class="ltx_glossaryref" title="">HSI</span> data.
In section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS1" title="V-A Applying HS3-Bench for Comparison of Full-Spectrum HSI Data and Reduction to a Single Channel ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a>, we first train our baseline models on the <span class="ltx_glossaryref" title="">HSI</span> data and also evaluate the influence of dimensionality reduction on model performance. In section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS2" title="V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a> we compare the performance of models using (pseudo-)RGB images to those using full spectrum <span class="ltx_glossaryref" title="">HSI</span>.
Then, we quantify the performance improvement from pre-training on additional data in combination with (pseudo-)RGB data in section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS3" title="V-C Impact of Pretraining on Model Performance ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a>, followed by qualitative assessment of prediction results and a discussion of the improvement of the HS3-baseline models over the state of the art in sections <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS4" title="V-D Qualitative Evaluation ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS5" title="V-E Comparison to the State of the Art ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-E</span></span></a>.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Unless stated otherwise, we kept all hyperparameters constant. The parameters are shown in TABLE  <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T2" title="TABLE II ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">II</span></a>. We used cross-entropy loss for all of our experiments. All experiments were performed on a single Nvidia-A100 GPU with 40GB VRAM.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Fixed training parameters of all training runs for each dataset, unless otherwise specified for individual runs.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T2.12.13.1.1"><span class="ltx_text" id="S5.T2.12.13.1.1.1" style="font-size:80%;">Training Parameter</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.13.1.2"><span class="ltx_text" id="S5.T2.12.13.1.2.1" style="font-size:80%;">HyKo2-VIS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.13.1.3"><span class="ltx_glossaryref" style="font-size:80%;" title="">HCV2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.13.1.4"><span class="ltx_text" id="S5.T2.12.13.1.4.1" style="font-size:80%;">HSI-Drive</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.14.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.12.14.2.1"><span class="ltx_text" id="S5.T2.12.14.2.1.1" style="font-size:80%;">optimizer</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.12.14.2.2"><span class="ltx_text" id="S5.T2.12.14.2.2.1" style="font-size:80%;">AdamW</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.12.14.2.3"><span class="ltx_text" id="S5.T2.12.14.2.3.1" style="font-size:80%;">AdamW</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.12.14.2.4"><span class="ltx_text" id="S5.T2.12.14.2.4.1" style="font-size:80%;">AdamW</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.3.4"><span class="ltx_text" id="S5.T2.3.3.4.1" style="font-size:80%;">learning rate</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.1"><math alttext="10^{-3}" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><msup id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml"><mn id="S5.T2.1.1.1.m1.1.1.2" mathsize="80%" xref="S5.T2.1.1.1.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3.cmml"><mo id="S5.T2.1.1.1.m1.1.1.3a" mathsize="80%" xref="S5.T2.1.1.1.m1.1.1.3.cmml">−</mo><mn id="S5.T2.1.1.1.m1.1.1.3.2" mathsize="80%" xref="S5.T2.1.1.1.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">superscript</csymbol><cn id="S5.T2.1.1.1.m1.1.1.2.cmml" type="integer" xref="S5.T2.1.1.1.m1.1.1.2">10</cn><apply id="S5.T2.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.m1.1.1.3"><minus id="S5.T2.1.1.1.m1.1.1.3.1.cmml" xref="S5.T2.1.1.1.m1.1.1.3"></minus><cn id="S5.T2.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.1.1.1.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">10^{-3}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2"><math alttext="10^{-3}" class="ltx_Math" display="inline" id="S5.T2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.m1.1a"><msup id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml"><mn id="S5.T2.2.2.2.m1.1.1.2" mathsize="80%" xref="S5.T2.2.2.2.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.m1.1.1.3.cmml"><mo id="S5.T2.2.2.2.m1.1.1.3a" mathsize="80%" xref="S5.T2.2.2.2.m1.1.1.3.cmml">−</mo><mn id="S5.T2.2.2.2.m1.1.1.3.2" mathsize="80%" xref="S5.T2.2.2.2.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><apply id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.2.2.2.m1.1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">superscript</csymbol><cn id="S5.T2.2.2.2.m1.1.1.2.cmml" type="integer" xref="S5.T2.2.2.2.m1.1.1.2">10</cn><apply id="S5.T2.2.2.2.m1.1.1.3.cmml" xref="S5.T2.2.2.2.m1.1.1.3"><minus id="S5.T2.2.2.2.m1.1.1.3.1.cmml" xref="S5.T2.2.2.2.m1.1.1.3"></minus><cn id="S5.T2.2.2.2.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.2.2.2.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">10^{-3}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.m1.1d">10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3"><math alttext="10^{-3}" class="ltx_Math" display="inline" id="S5.T2.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.m1.1a"><msup id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml"><mn id="S5.T2.3.3.3.m1.1.1.2" mathsize="80%" xref="S5.T2.3.3.3.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.3.3.3.m1.1.1.3" xref="S5.T2.3.3.3.m1.1.1.3.cmml"><mo id="S5.T2.3.3.3.m1.1.1.3a" mathsize="80%" xref="S5.T2.3.3.3.m1.1.1.3.cmml">−</mo><mn id="S5.T2.3.3.3.m1.1.1.3.2" mathsize="80%" xref="S5.T2.3.3.3.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1">superscript</csymbol><cn id="S5.T2.3.3.3.m1.1.1.2.cmml" type="integer" xref="S5.T2.3.3.3.m1.1.1.2">10</cn><apply id="S5.T2.3.3.3.m1.1.1.3.cmml" xref="S5.T2.3.3.3.m1.1.1.3"><minus id="S5.T2.3.3.3.m1.1.1.3.1.cmml" xref="S5.T2.3.3.3.m1.1.1.3"></minus><cn id="S5.T2.3.3.3.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.3.3.3.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">10^{-3}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.m1.1d">10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.6.6.4"><span class="ltx_text" id="S5.T2.6.6.4.1" style="font-size:80%;">optimizer epsilon</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.1"><math alttext="10^{-8}" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1a"><msup id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><mn id="S5.T2.4.4.1.m1.1.1.2" mathsize="80%" xref="S5.T2.4.4.1.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3.cmml"><mo id="S5.T2.4.4.1.m1.1.1.3a" mathsize="80%" xref="S5.T2.4.4.1.m1.1.1.3.cmml">−</mo><mn id="S5.T2.4.4.1.m1.1.1.3.2" mathsize="80%" xref="S5.T2.4.4.1.m1.1.1.3.2.cmml">8</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">superscript</csymbol><cn id="S5.T2.4.4.1.m1.1.1.2.cmml" type="integer" xref="S5.T2.4.4.1.m1.1.1.2">10</cn><apply id="S5.T2.4.4.1.m1.1.1.3.cmml" xref="S5.T2.4.4.1.m1.1.1.3"><minus id="S5.T2.4.4.1.m1.1.1.3.1.cmml" xref="S5.T2.4.4.1.m1.1.1.3"></minus><cn id="S5.T2.4.4.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.4.4.1.m1.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">10^{-8}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1d">10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.2"><math alttext="10^{-4}" class="ltx_Math" display="inline" id="S5.T2.5.5.2.m1.1"><semantics id="S5.T2.5.5.2.m1.1a"><msup id="S5.T2.5.5.2.m1.1.1" xref="S5.T2.5.5.2.m1.1.1.cmml"><mn id="S5.T2.5.5.2.m1.1.1.2" mathsize="80%" xref="S5.T2.5.5.2.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.5.5.2.m1.1.1.3" xref="S5.T2.5.5.2.m1.1.1.3.cmml"><mo id="S5.T2.5.5.2.m1.1.1.3a" mathsize="80%" xref="S5.T2.5.5.2.m1.1.1.3.cmml">−</mo><mn id="S5.T2.5.5.2.m1.1.1.3.2" mathsize="80%" xref="S5.T2.5.5.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.2.m1.1b"><apply id="S5.T2.5.5.2.m1.1.1.cmml" xref="S5.T2.5.5.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.5.5.2.m1.1.1.1.cmml" xref="S5.T2.5.5.2.m1.1.1">superscript</csymbol><cn id="S5.T2.5.5.2.m1.1.1.2.cmml" type="integer" xref="S5.T2.5.5.2.m1.1.1.2">10</cn><apply id="S5.T2.5.5.2.m1.1.1.3.cmml" xref="S5.T2.5.5.2.m1.1.1.3"><minus id="S5.T2.5.5.2.m1.1.1.3.1.cmml" xref="S5.T2.5.5.2.m1.1.1.3"></minus><cn id="S5.T2.5.5.2.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.5.5.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.2.m1.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.2.m1.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.6.6.3"><math alttext="10^{-8}" class="ltx_Math" display="inline" id="S5.T2.6.6.3.m1.1"><semantics id="S5.T2.6.6.3.m1.1a"><msup id="S5.T2.6.6.3.m1.1.1" xref="S5.T2.6.6.3.m1.1.1.cmml"><mn id="S5.T2.6.6.3.m1.1.1.2" mathsize="80%" xref="S5.T2.6.6.3.m1.1.1.2.cmml">10</mn><mrow id="S5.T2.6.6.3.m1.1.1.3" xref="S5.T2.6.6.3.m1.1.1.3.cmml"><mo id="S5.T2.6.6.3.m1.1.1.3a" mathsize="80%" xref="S5.T2.6.6.3.m1.1.1.3.cmml">−</mo><mn id="S5.T2.6.6.3.m1.1.1.3.2" mathsize="80%" xref="S5.T2.6.6.3.m1.1.1.3.2.cmml">8</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.3.m1.1b"><apply id="S5.T2.6.6.3.m1.1.1.cmml" xref="S5.T2.6.6.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.6.6.3.m1.1.1.1.cmml" xref="S5.T2.6.6.3.m1.1.1">superscript</csymbol><cn id="S5.T2.6.6.3.m1.1.1.2.cmml" type="integer" xref="S5.T2.6.6.3.m1.1.1.2">10</cn><apply id="S5.T2.6.6.3.m1.1.1.3.cmml" xref="S5.T2.6.6.3.m1.1.1.3"><minus id="S5.T2.6.6.3.m1.1.1.3.1.cmml" xref="S5.T2.6.6.3.m1.1.1.3"></minus><cn id="S5.T2.6.6.3.m1.1.1.3.2.cmml" type="integer" xref="S5.T2.6.6.3.m1.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.3.m1.1c">10^{-8}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.3.m1.1d">10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.9.9.4"><span class="ltx_text" id="S5.T2.9.9.4.1" style="font-size:80%;">batch size</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.7.7.1"><math alttext="16" class="ltx_Math" display="inline" id="S5.T2.7.7.1.m1.1"><semantics id="S5.T2.7.7.1.m1.1a"><mn id="S5.T2.7.7.1.m1.1.1" mathsize="80%" xref="S5.T2.7.7.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.1.m1.1b"><cn id="S5.T2.7.7.1.m1.1.1.cmml" type="integer" xref="S5.T2.7.7.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.1.m1.1d">16</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.2"><math alttext="4" class="ltx_Math" display="inline" id="S5.T2.8.8.2.m1.1"><semantics id="S5.T2.8.8.2.m1.1a"><mn id="S5.T2.8.8.2.m1.1.1" mathsize="80%" xref="S5.T2.8.8.2.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.2.m1.1b"><cn id="S5.T2.8.8.2.m1.1.1.cmml" type="integer" xref="S5.T2.8.8.2.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.2.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.8.2.m1.1d">4</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.9.9.3"><math alttext="32" class="ltx_Math" display="inline" id="S5.T2.9.9.3.m1.1"><semantics id="S5.T2.9.9.3.m1.1a"><mn id="S5.T2.9.9.3.m1.1.1" mathsize="80%" xref="S5.T2.9.9.3.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.3.m1.1b"><cn id="S5.T2.9.9.3.m1.1.1.cmml" type="integer" xref="S5.T2.9.9.3.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.3.m1.1c">32</annotation><annotation encoding="application/x-llamapun" id="S5.T2.9.9.3.m1.1d">32</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.12.12.4"><span class="ltx_text" id="S5.T2.12.12.4.1" style="font-size:80%;">max epochs</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.10.10.1"><math alttext="500" class="ltx_Math" display="inline" id="S5.T2.10.10.1.m1.1"><semantics id="S5.T2.10.10.1.m1.1a"><mn id="S5.T2.10.10.1.m1.1.1" mathsize="80%" xref="S5.T2.10.10.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.1.m1.1b"><cn id="S5.T2.10.10.1.m1.1.1.cmml" type="integer" xref="S5.T2.10.10.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S5.T2.10.10.1.m1.1d">500</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.11.11.2"><math alttext="100" class="ltx_Math" display="inline" id="S5.T2.11.11.2.m1.1"><semantics id="S5.T2.11.11.2.m1.1a"><mn id="S5.T2.11.11.2.m1.1.1" mathsize="80%" xref="S5.T2.11.11.2.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.2.m1.1b"><cn id="S5.T2.11.11.2.m1.1.1.cmml" type="integer" xref="S5.T2.11.11.2.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.2.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="S5.T2.11.11.2.m1.1d">100</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.12.3"><math alttext="300" class="ltx_Math" display="inline" id="S5.T2.12.12.3.m1.1"><semantics id="S5.T2.12.12.3.m1.1a"><mn id="S5.T2.12.12.3.m1.1.1" mathsize="80%" xref="S5.T2.12.12.3.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.3.m1.1b"><cn id="S5.T2.12.12.3.m1.1.1.cmml" type="integer" xref="S5.T2.12.12.3.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.3.m1.1c">300</annotation><annotation encoding="application/x-llamapun" id="S5.T2.12.12.3.m1.1d">300</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.15.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.12.15.3.1"><span class="ltx_text" id="S5.T2.12.15.3.1.1" style="font-size:80%;">early stopping</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.12.15.3.2"><span class="ltx_text" id="S5.T2.12.15.3.2.1" style="font-size:80%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.15.3.3"><span class="ltx_text" id="S5.T2.12.15.3.3.1" style="font-size:80%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.12.15.3.4"><span class="ltx_text" id="S5.T2.12.15.3.4.1" style="font-size:80%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.16.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.12.16.4.1"><span class="ltx_text" id="S5.T2.12.16.4.1.1" style="font-size:80%;">loss</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.12.16.4.2"><span class="ltx_text" id="S5.T2.12.16.4.2.1" style="font-size:80%;">cross-entropy</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.12.16.4.3"><span class="ltx_text" id="S5.T2.12.16.4.3.1" style="font-size:80%;">cross-entropy</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.12.16.4.4"><span class="ltx_text" id="S5.T2.12.16.4.4.1" style="font-size:80%;">cross-entropy</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a> provides the main results from this paper.
The upper part provides results for the individual datasets, the lower part provides summary statistics across all datasets.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">Applying HS3-Bench for Comparison of Full-Spectrum <span class="ltx_glossaryref" title="">HSI</span> Data and Reduction to a Single Channel</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We applied the benchmark baseline models U-Net, RU-Net and <span class="ltx_glossaryref" title="">DL3+</span> from Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4" title="IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">IV</span></a> on different input data. For example, the entry HSI in the column Data indicates that all spectral bands are used.
As mentioned before, the results in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a> suggest that RU-Net generally performs better than U-Net.
Notably, this smaller model also performs better than the larger <span class="ltx_glossaryref" title="">DL3+</span> model in this comparison where no additional data is available.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Training a model with all spectral bands available in the benchmark datasets defines one extreme, another extreme is reducing the spectral information to a single feature channel with <span class="ltx_glossaryref" title="">principal component analysis (PCA)</span>, denoted as PCA1 in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a>. Surprisingly, as also depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.F4" title="Figure 4 ‣ V-A Applying HS3-Bench for Comparison of Full-Spectrum HSI Data and Reduction to a Single Channel ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">4</span></a>, the average performance of <span class="ltx_glossaryref" title="">DL3+</span> with PCA1 data compared to <span class="ltx_glossaryref" title="">HSI</span> data is only slightly worse. Further, the average performance of RU-Net with PCA1 is even better than with <span class="ltx_glossaryref" title="">HSI</span>. Looking at the individual datasets, we see that on <span class="ltx_glossaryref" title="">HCV2</span> both architectures benefit from PCA1. On HSI-Drive and HyKo2, RU-Net profits significantly on the former and has no significant effect on the latter, while the performance of <span class="ltx_glossaryref" title="">DL3+</span> is decreased in both cases. We suspect that because HyKo2 has only 16 spectral channels, much fewer than the 128 spectral channels of <span class="ltx_glossaryref" title="">HCV2</span>, models trained on the former are less affected by the curse of dimensionality, while models trained on the latter are not presented with enough data to produce a robust classifier.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S5.F4.1" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="S5.F4.1.g1" src="x2.png" width="830"/>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Average Jaccard score per model and data type.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Comparison of <span class="ltx_glossaryref" title="">HSI</span> and (Pseudo-)RGB Data</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">In this section we quantify the discrepancy in performance of models trained on <span class="ltx_glossaryref" title="">HSI</span> data and on <span class="ltx_glossaryref" title="">pRGB</span> data.
We synthesized <span class="ltx_glossaryref" title="">pRGB</span> images from <span class="ltx_glossaryref" title="">HSI</span> data, as described in section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4" title="IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">IV</span></a>, and used the same dataset splits to keep the class distribution constant in our experiments.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.2">We repeat the experiments from section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS1" title="V-A Applying HS3-Bench for Comparison of Full-Spectrum HSI Data and Reduction to a Single Channel ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a> with the synthesized <span class="ltx_glossaryref" title="">pRGB</span> images. Note that all information in the <span class="ltx_glossaryref" title="">pRGB</span> images was derived from <span class="ltx_glossaryref" title="">HSI</span>. We trained our baseline models from scratch and did not use pre-training. The results are also presented in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a>. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.F4" title="Figure 4 ‣ V-A Applying HS3-Bench for Comparison of Full-Spectrum HSI Data and Reduction to a Single Channel ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates that the average jaccard score of RU-Net with <span class="ltx_glossaryref" title="">pRGB</span> data improves by <math alttext="+3.66\%" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mo id="S5.SS2.p2.1.m1.1.1a" xref="S5.SS2.p2.1.m1.1.1.cmml">+</mo><mrow id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml"><mn id="S5.SS2.p2.1.m1.1.1.2.2" xref="S5.SS2.p2.1.m1.1.1.2.2.cmml">3.66</mn><mo id="S5.SS2.p2.1.m1.1.1.2.1" xref="S5.SS2.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><plus id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"></plus><apply id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2"><csymbol cd="latexml" id="S5.SS2.p2.1.m1.1.1.2.1.cmml" xref="S5.SS2.p2.1.m1.1.1.2.1">percent</csymbol><cn id="S5.SS2.p2.1.m1.1.1.2.2.cmml" type="float" xref="S5.SS2.p2.1.m1.1.1.2.2">3.66</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">+3.66\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">+ 3.66 %</annotation></semantics></math> and for <span class="ltx_glossaryref" title="">DL3+</span> by <math alttext="+1.54\%" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mo id="S5.SS2.p2.2.m2.1.1a" xref="S5.SS2.p2.2.m2.1.1.cmml">+</mo><mrow id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml"><mn id="S5.SS2.p2.2.m2.1.1.2.2" xref="S5.SS2.p2.2.m2.1.1.2.2.cmml">1.54</mn><mo id="S5.SS2.p2.2.m2.1.1.2.1" xref="S5.SS2.p2.2.m2.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><plus id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"></plus><apply id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2"><csymbol cd="latexml" id="S5.SS2.p2.2.m2.1.1.2.1.cmml" xref="S5.SS2.p2.2.m2.1.1.2.1">percent</csymbol><cn id="S5.SS2.p2.2.m2.1.1.2.2.cmml" type="float" xref="S5.SS2.p2.2.m2.1.1.2.2">1.54</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">+1.54\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">+ 1.54 %</annotation></semantics></math> over the performance of the same model trained on <span class="ltx_glossaryref" title="">HSI</span>. The improvement can mainly be traced back to HyKo2 and <span class="ltx_glossaryref" title="">HCV2</span>, HSI-Drive results improve only slightly. HSI-Drive covers only red and near-infrared channels so we could not select bands from the spectral intervals corresponding to RGB-wavelengths. Therefore, the results might be explained by suboptimal band selection during RGB image synthesis. In summary using <span class="ltx_glossaryref" title="">pRGB</span> data leads to an overall improvement in model performance.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Benchmark scores (%) on the HS3-Bench test data.</figcaption>
<p class="ltx_p ltx_align_center" id="S5.T3.4"><span class="ltx_text" id="S5.T3.4.4" style="font-size:80%;">. 

<span class="ltx_inline-block ltx_transformed_outer" id="S5.T3.4.4.4" style="width:433.6pt;height:915.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(12.1pt,-25.6pt) scale(1.05924348515787,1.05924348515787) ;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.4.4.4.4">
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.4.4.4.4.5.1">
<span class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.4.4.4.4.5.1.1"></span>
<span class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.4.4.4.4.5.1.2"></span>
<span class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.4.4.4.4.5.1.3"></span>
<span class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_4" id="S5.T3.4.4.4.4.5.1.4">Testing</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.4.5">Dataset</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.4.6">Approach</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.4.7">Data</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1.1.1.1"><math alttext="\textnormal{Acc}_{\mu}" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.1.1.1.m1.1a"><msub id="S5.T3.1.1.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.1.1.m1.1.1.cmml"><mtext id="S5.T3.1.1.1.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.1.1.1.m1.1.1.2a.cmml">Acc</mtext><mi id="S5.T3.1.1.1.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.1.1.1.m1.1.1.3.cmml">μ</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S5.T3.1.1.1.1.1.1.m1.1.1.2a.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.2"><mtext id="S5.T3.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.2">Acc</mtext></ci><ci id="S5.T3.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.3">𝜇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.1.m1.1c">\textnormal{Acc}_{\mu}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.1.1.m1.1d">Acc start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.2.2.2.2"><math alttext="\textnormal{Acc}_{M}" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.2.2.2.m1.1a"><msub id="S5.T3.2.2.2.2.2.2.m1.1.1" xref="S5.T3.2.2.2.2.2.2.m1.1.1.cmml"><mtext id="S5.T3.2.2.2.2.2.2.m1.1.1.2" xref="S5.T3.2.2.2.2.2.2.m1.1.1.2a.cmml">Acc</mtext><mi id="S5.T3.2.2.2.2.2.2.m1.1.1.3" xref="S5.T3.2.2.2.2.2.2.m1.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.2.2.m1.1b"><apply id="S5.T3.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1">subscript</csymbol><ci id="S5.T3.2.2.2.2.2.2.m1.1.1.2a.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1.2"><mtext id="S5.T3.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1.2">Acc</mtext></ci><ci id="S5.T3.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S5.T3.2.2.2.2.2.2.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.2.2.m1.1c">\textnormal{Acc}_{M}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.2.2.2.m1.1d">Acc start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.3.3.3.3.3.3"><math alttext="\textnormal{F}_{1_{M}}" class="ltx_Math" display="inline" id="S5.T3.3.3.3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.3.3.3.m1.1a"><msub id="S5.T3.3.3.3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.3.3.3.m1.1.1.cmml"><mtext id="S5.T3.3.3.3.3.3.3.m1.1.1.2" xref="S5.T3.3.3.3.3.3.3.m1.1.1.2a.cmml">F</mtext><msub id="S5.T3.3.3.3.3.3.3.m1.1.1.3" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3.cmml"><mn id="S5.T3.3.3.3.3.3.3.m1.1.1.3.2" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3.2.cmml">1</mn><mi id="S5.T3.3.3.3.3.3.3.m1.1.1.3.3" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3.3.cmml">M</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.3.3.m1.1b"><apply id="S5.T3.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.3.3.3.3.3.3.m1.1.1.1.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1">subscript</csymbol><ci id="S5.T3.3.3.3.3.3.3.m1.1.1.2a.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1.2"><mtext id="S5.T3.3.3.3.3.3.3.m1.1.1.2.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1.2">F</mtext></ci><apply id="S5.T3.3.3.3.3.3.3.m1.1.1.3.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.3.3.3.3.3.3.m1.1.1.3.1.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3">subscript</csymbol><cn id="S5.T3.3.3.3.3.3.3.m1.1.1.3.2.cmml" type="integer" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3.2">1</cn><ci id="S5.T3.3.3.3.3.3.3.m1.1.1.3.3.cmml" xref="S5.T3.3.3.3.3.3.3.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.3.3.m1.1c">\textnormal{F}_{1_{M}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.3.3.3.m1.1d">F start_POSTSUBSCRIPT 1 start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.4.4"><math alttext="\textnormal{J}_{M}" class="ltx_Math" display="inline" id="S5.T3.4.4.4.4.4.4.m1.1"><semantics id="S5.T3.4.4.4.4.4.4.m1.1a"><msub id="S5.T3.4.4.4.4.4.4.m1.1.1" xref="S5.T3.4.4.4.4.4.4.m1.1.1.cmml"><mtext id="S5.T3.4.4.4.4.4.4.m1.1.1.2" xref="S5.T3.4.4.4.4.4.4.m1.1.1.2a.cmml">J</mtext><mi id="S5.T3.4.4.4.4.4.4.m1.1.1.3" xref="S5.T3.4.4.4.4.4.4.m1.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.4.4.4.m1.1b"><apply id="S5.T3.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.4.4.4.4.4.4.m1.1.1.1.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1">subscript</csymbol><ci id="S5.T3.4.4.4.4.4.4.m1.1.1.2a.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1.2"><mtext id="S5.T3.4.4.4.4.4.4.m1.1.1.2.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1.2">J</mtext></ci><ci id="S5.T3.4.4.4.4.4.4.m1.1.1.3.cmml" xref="S5.T3.4.4.4.4.4.4.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.4.4.4.m1.1c">\textnormal{J}_{M}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.4.4.4.m1.1d">J start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.6.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.6.2.1"><span class="ltx_glossaryref" title="">HCV2</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.6.2.2">U-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.6.2.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.2.4">85.25</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.2.5">48.62</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.2.6">48.18</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.6.2.7">37.73</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.7.3">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.7.3.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.7.3.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.7.3.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.7.3.4">87.63</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.7.3.5">54.14</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.7.3.6">53.26</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.7.3.7">42.23</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.8.4">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.8.4.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.8.4.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.8.4.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.8.4.4">88.25</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.8.4.5">58.07</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.8.4.6">55.43</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.8.4.7">44.26</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.9.5">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.9.5.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.9.5.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.9.5.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.9.5.4">87.95</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.9.5.5">56.65</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.9.5.6">55.46</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.9.5.7">44.03</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.10.6">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.10.6.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.10.6.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.10.6.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.10.6.4">86.60</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.10.6.5">53.15</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.10.6.6">51.83</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.10.6.7">40.79</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.11.7">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.11.7.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.11.7.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.11.7.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.11.7.4">86.64</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.11.7.5">54.46</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.11.7.6">52.90</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.11.7.7">41.58</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.12.8">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.12.8.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.12.8.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.12.8.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.12.8.4">87.00</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.12.8.5">55.33</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.12.8.6">54.08</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.12.8.7">42.58</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.13.9">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.13.9.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.13.9.2"><span class="ltx_glossaryref" title="">DL3+</span> (BB)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.13.9.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.13.9.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.13.9.4.1">90.26</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.13.9.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.13.9.5.1">64.10</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.13.9.6"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.13.9.6.1">61.93</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.13.9.7"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.13.9.7.1">50.04</span></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.14.10">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.14.10.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.14.10.2">(<span class="ltx_glossaryref" title="">DL3+</span> (BB))<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text" id="footnote2.1.1.1" style="font-size:125%;">2</span></span><span class="ltx_text" id="footnote2.5" style="font-size:125%;">The result on RGB data is surrounded in parenthesis as the data was collected with an additional sensor (cf. Sec. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS2" style="font-size:125%;" title="V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a><span class="ltx_text" id="footnote2.6" style="font-size:125%;">). RGB data was only provided for </span><span class="ltx_glossaryref" style="font-size:125%;" title="">HCV2</span><span class="ltx_text" id="footnote2.7" style="font-size:125%;"> and therefore we could not calculate summary statistics.</span></span></span></span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.14.10.3">(RGB)</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.14.10.4">(91.22)</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.14.10.5">(65.87)</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.14.10.6">(63.33)</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.14.10.7">(52.11)</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.15.11">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.15.11.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.15.11.2"><span class="ltx_glossaryref" title="">DL3+</span> (PT)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.15.11.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.15.11.4">89.62</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.15.11.5">61.91</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.15.11.6">60.17</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.15.11.7">48.47</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.16.12">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.16.12.1">HyKo2</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.16.12.2">U-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.16.12.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.16.12.4">85.36</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.16.12.5">68.15</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.16.12.6">68.55</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.16.12.7">57.39</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.17.13">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.17.13.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.17.13.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.17.13.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.17.13.4">86.72</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.17.13.5">68.79</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.17.13.6">69.19</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.17.13.7">58.64</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.18.14">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.18.14.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.18.14.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.18.14.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.18.14.4">85.61</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.18.14.5">68.09</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.18.14.6">70.01</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.18.14.7">58.67</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.19.15">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.19.15.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.19.15.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.19.15.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.19.15.4">89.18</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.19.15.5">73.92</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.19.15.6">75.04</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.19.15.7">64.67</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.20.16">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.20.16.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.20.16.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.20.16.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.20.16.4">84.10</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.20.16.5">63.01</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.20.16.6">64.90</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.20.16.7">53.22</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.21.17">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.21.17.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.21.17.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.21.17.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.21.17.4">79.99</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.21.17.5">61.59</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.21.17.6">63.00</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.21.17.7">50.40</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.22.18">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.22.18.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.22.18.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.22.18.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.22.18.4">84.64</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.22.18.5">65.30</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.22.18.6">66.56</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.22.18.7">54.82</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.23.19">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.23.19.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.23.19.2"><span class="ltx_glossaryref" title="">DL3+</span> (BB)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.23.19.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.23.19.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.23.19.4.1">90.49</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.23.19.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.23.19.5.1">74.87</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.23.19.6"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.23.19.6.1">77.11</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.23.19.7"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.23.19.7.1">66.77</span></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.24.20">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.24.20.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.24.20.2"><span class="ltx_glossaryref" title="">DL3+</span> (PT)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.24.20.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.24.20.4">88.62</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.24.20.5">73.97</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.24.20.6">76.79</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.24.20.7">65.41</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.25.21">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.25.21.1">HSI-Drive</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.25.21.2">U-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.25.21.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.25.21.4">94.95</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.25.21.5">74.74</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.25.21.6">76.08</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.25.21.7">64.95</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.26.22">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.26.22.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.26.22.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.26.22.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.26.22.4">96.08</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.26.22.5">79.82</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.26.22.6">82.34</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.26.22.7">72.18</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.27.23">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.27.23.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.27.23.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.27.23.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.27.23.4">97.02</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.27.23.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.27.23.5.1">86.80</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.27.23.6"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.27.23.6.1">87.76</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.27.23.7"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.27.23.7.1">79.23</span></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.28.24">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.28.24.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.28.24.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.28.24.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.28.24.4">96.32</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.28.24.5">82.70</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.28.24.6">84.91</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.28.24.7">75.31</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.29.25">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.29.25.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.29.25.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.29.25.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.29.25.4">92.51</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.29.25.5">65.58</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.29.25.6">67.86</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.29.25.7">56.63</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.30.26">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.30.26.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.30.26.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.30.26.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.30.26.4">90.88</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.30.26.5">62.93</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.30.26.6">64.31</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.30.26.7">52.62</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.31.27">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.31.27.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.31.27.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.31.27.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.31.27.4">92.74</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.31.27.5">66.59</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.31.27.6">69.46</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.31.27.7">57.84</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.32.28">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.32.28.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.32.28.2"><span class="ltx_glossaryref" title="">DL3+</span> (BB)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.32.28.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.32.28.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.32.28.4.1">97.09</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.32.28.5">83.93</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.32.28.6">86.41</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.32.28.7">77.44</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.33.29">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.33.29.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.33.29.2"><span class="ltx_glossaryref" title="">DL3+</span> (PT)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.33.29.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.33.29.4">95.69</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.33.29.5">81.95</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.33.29.6">84.09</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.33.29.7">73.84</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.34.30">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T3.4.4.4.4.34.30.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.34.30.1.1">Average</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T3.4.4.4.4.34.30.2">U-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.4.4.4.4.34.30.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.4.4.4.34.30.4">88.52</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.4.4.4.34.30.5">63.84</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.4.4.4.34.30.6">64.27</span>
<span class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.4.4.4.34.30.7">53.36</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.35.31">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.35.31.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.35.31.1.1">Perf.</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.35.31.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.35.31.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.35.31.4">90.14</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.35.31.5">67.58</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.35.31.6">68.26</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.35.31.7">57.68</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.36.32">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.36.32.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.36.32.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.36.32.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.36.32.4">90.29</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.36.32.5">70.99</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.36.32.6">71.07</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.36.32.7">60.72</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.37.33">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.37.33.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.37.33.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.37.33.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.37.33.4">91.15</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.37.33.5">71.09</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.37.33.6">71.80</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.37.33.7">61.34</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.38.34">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.38.34.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.38.34.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.38.34.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.38.34.4">87.74</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.38.34.5">60.58</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.38.34.6">61.53</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.38.34.7">50.21</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.39.35">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.39.35.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.39.35.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.39.35.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.39.35.4">85.84</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.39.35.5">59.66</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.39.35.6">60.07</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.39.35.7">48.20</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.40.36">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.40.36.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.40.36.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.40.36.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.40.36.4">88.13</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.40.36.5">62.41</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.40.36.6">63.37</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.40.36.7">51.75</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.41.37">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.41.37.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.41.37.2"><span class="ltx_glossaryref" title="">DL3+</span> (BB)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.41.37.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.41.37.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.41.37.4.1">92.61</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.41.37.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.41.37.5.1">74.30</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.41.37.6"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.41.37.6.1">75.15</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.41.37.7"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.41.37.7.1">64.75</span></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.42.38">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.42.38.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.42.38.2"><span class="ltx_glossaryref" title="">DL3+</span> (PT)</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.42.38.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.42.38.4">91.31</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.42.38.5">72.61</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.42.38.6">73.68</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.42.38.7">62.57</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.43.39">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.43.39.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.43.39.1.1">Worst-Case</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.4.4.4.4.43.39.2">U-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.4.4.4.4.43.39.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.43.39.4">82.25</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.43.39.5">48.63</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.43.39.6">48.18</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4.4.43.39.7">37.73</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.44.40">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.44.40.1"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.44.40.1.1">Perf.</span></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.44.40.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.44.40.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.44.40.4">86.72</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.44.40.5">54.14</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.44.40.6">53.26</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.44.40.7">42.23</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.45.41">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.45.41.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.45.41.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.45.41.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.45.41.4">85.61</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.45.41.5">58.07</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.45.41.6">55.43</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.45.41.7">44.26</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.46.42">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.46.42.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.46.42.2">RU-Net</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.46.42.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.46.42.4">87.95</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.46.42.5">56.65</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.46.42.6">55.46</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.46.42.7">44.03</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.47.43">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.47.43.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.47.43.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.47.43.3"><span class="ltx_glossaryref" title="">HSI</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.47.43.4">84.10</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.47.43.5">53.15</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.47.43.6">51.83</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.47.43.7">40.79</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.48.44">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.48.44.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.48.44.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.48.44.3">PCA1</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.48.44.4">79.99</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.48.44.5">54.46</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.48.44.6">52.90</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.48.44.7">41.58</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.49.45">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.49.45.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.49.45.2"><span class="ltx_glossaryref" title="">DL3+</span></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.49.45.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.49.45.4">84.64</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.49.45.5">55.33</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.49.45.6">54.08</span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.49.45.7">42.58</span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.50.46">
<span class="ltx_td ltx_th ltx_th_row" id="S5.T3.4.4.4.4.50.46.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.4.4.50.46.2"><span class="ltx_glossaryref" title="">DL3+</span> BB</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S5.T3.4.4.4.4.50.46.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.50.46.4"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.50.46.4.1">90.26</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.50.46.5"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.50.46.5.1">64.10</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.50.46.6"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.50.46.6.1">61.93</span></span>
<span class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4.50.46.7"><span class="ltx_text ltx_font_bold" id="S5.T3.4.4.4.4.50.46.7.1">50.04</span></span></span>
<span class="ltx_tr" id="S5.T3.4.4.4.4.51.47">
<span class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.1"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.2"><span class="ltx_glossaryref" title="">DL3+</span> PT</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S5.T3.4.4.4.4.51.47.3"><span class="ltx_glossaryref" title="">pRGB</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.4">88.62</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.5">61.91</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.6">60.17</span>
<span class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S5.T3.4.4.4.4.51.47.7">48.47</span></span>
</span>
</span>
</span></span></span></p>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Impact of Pretraining on Model Performance</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">To investigate the potential benefit of pre-training on RGB data we compare the performance of the <span class="ltx_glossaryref" title="">DL3+</span> model on <span class="ltx_glossaryref" title="">pRGB</span> data without pre-training and with pre-training. In our first test, we intialize the backbone networks of <span class="ltx_glossaryref" title="">DL3+</span> with pre-trained weights (cf. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4" title="IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">IV</span></a>) and fine-tune the full model on our data. Then, to see how well information from similar domains can be transferred we initialize <span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.1">all</span> of our model parameters with model weights pre-trained on Cityscapes<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The model weights were downloaded from this repository: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/VainF/DeepLabV3Plus-Pytorch" title="">https://github.com/VainF/DeepLabV3Plus-Pytorch</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib7" title="">7</a>]</cite>. We only replaced the output layer, such that the number of predicted classes matched the number of classes of each dataset in HS3-Bench. In our second test <span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.2">all</span> model parameters were frozen, except the ones in the output layer to avoid adapting the models feature extraction to the new dataset.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">The result of using pre-trained weights and fine-tuning the full model are summarized in TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T3" title="TABLE III ‣ V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">III</span></a> denoted with BB. The average performance increased significantly, by around <math alttext="+7\%" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mo id="S5.SS3.p2.1.m1.1.1a" xref="S5.SS3.p2.1.m1.1.1.cmml">+</mo><mrow id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml"><mn id="S5.SS3.p2.1.m1.1.1.2.2" xref="S5.SS3.p2.1.m1.1.1.2.2.cmml">7</mn><mo id="S5.SS3.p2.1.m1.1.1.2.1" xref="S5.SS3.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><plus id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"></plus><apply id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.2.1.cmml" xref="S5.SS3.p2.1.m1.1.1.2.1">percent</csymbol><cn id="S5.SS3.p2.1.m1.1.1.2.2.cmml" type="integer" xref="S5.SS3.p2.1.m1.1.1.2.2">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">+7\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">+ 7 %</annotation></semantics></math> compared to the best model that does not use pre-trained weights. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.F5" title="Figure 5 ‣ V-C Impact of Pretraining on Model Performance ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">5</span></a> shows that the performance improvement compared to <span class="ltx_glossaryref" title="">pRGB</span> images without pre-training is most apparent in HSI-Drive. This is especially interesting, as HSI-Drive contains only spectral information from the red and the near-infrared spectrum. Hence, the synthesized images do not have the same distribution typically apparent in RGB images. This observeration indicates that the features extracted by the backbone model are general enough to be successfully applied to neighboring spectral domains.</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S5.F5.1" style="width:433.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="622" id="S5.F5.1.g1" src="x3.png" width="830"/>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Jaccard scores for <span class="ltx_glossaryref" title="">DL3+</span> on <span class="ltx_glossaryref" title="">pRGB</span> data per dataset without pre-training (<span class="ltx_glossaryref" title="">pRGB</span>), with pre-trained backbone and fine-tuning (<span class="ltx_glossaryref" title="">pRGB</span>-BB) and with pre-trained weights transferred from a similar domain, namely CityScapes (<span class="ltx_glossaryref" title="">pRGB</span>-PT). In the latter, all weights except for output-layer were frozen.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">In our second experiment on pre-training, fine-tuning only the output layer showed only slightly lower average performance than fine-tuning the full model. Nonetheless, the performance is still significantly better than all approaches that do not use pre-training, which shows that the feature extraction modules can be directly applied to similar domains.
When only considering <span class="ltx_glossaryref" title="">pRGB</span> data all results on each individual dataset improve with pre-training by a large margin, as depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.F5" title="Figure 5 ‣ V-C Impact of Pretraining on Model Performance ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">5</span></a>.
The strong improvements in model performance indicate that exploiting knowledge through pre-training is very effective. It has an even stronger relative effect than using <span class="ltx_glossaryref" title="">pRGB</span> data instead of full-spectrum <span class="ltx_glossaryref" title="">HSI</span>.
Further, the observation that models using <span class="ltx_glossaryref" title="">pRGB</span> data outperformed all models using full spectra, support that for driving scenarios introducing knowledge from related domains is more beneficial than adding additional spectral features for the available datasets.</p>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.2">Note that we used a very simple way of synthesizing <span class="ltx_glossaryref" title="">pRGB</span> images (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.SS3" title="IV-C Synthesizing (Pseudo-)RGB Images ‣ IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a>). The spectral bands are very narrow - especially in <span class="ltx_glossaryref" title="">HCV2</span>- which leads to lower signal intensities and in turn to noisy bands. The synthesized images show an unnatural color distribution (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S4.F3" title="Figure 3 ‣ IV-C Synthesizing (Pseudo-)RGB Images ‣ IV Strong baselines ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">3</span></a>), distinct from typical RGB-images.
To estimate the upper limit of model performance that can be expected with better RGB-image synthesis, we trained an additional model on the RGB images provided with <span class="ltx_glossaryref" title="">HCV2</span> (cf. section <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.SS2" title="V-B Comparison of HSI and (Pseudo-)RGB Data ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a>). We fine-tuned <span class="ltx_glossaryref" title="">DL3+</span> using hyperparameter settings from TABLE <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.T2" title="TABLE II ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">II</span></a> and a pre-trained MobileNetV2 backbone and achieved a Jaccard score of <math alttext="52.11\%" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mn id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2.cmml">52.11</mn><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1">percent</csymbol><cn id="S5.SS3.p4.1.m1.1.1.2.cmml" type="float" xref="S5.SS3.p4.1.m1.1.1.2">52.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">52.11\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.1.m1.1d">52.11 %</annotation></semantics></math> (<math alttext="+0.43\%" class="ltx_Math" display="inline" id="S5.SS3.p4.2.m2.1"><semantics id="S5.SS3.p4.2.m2.1a"><mrow id="S5.SS3.p4.2.m2.1.1" xref="S5.SS3.p4.2.m2.1.1.cmml"><mo id="S5.SS3.p4.2.m2.1.1a" xref="S5.SS3.p4.2.m2.1.1.cmml">+</mo><mrow id="S5.SS3.p4.2.m2.1.1.2" xref="S5.SS3.p4.2.m2.1.1.2.cmml"><mn id="S5.SS3.p4.2.m2.1.1.2.2" xref="S5.SS3.p4.2.m2.1.1.2.2.cmml">0.43</mn><mo id="S5.SS3.p4.2.m2.1.1.2.1" xref="S5.SS3.p4.2.m2.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.2.m2.1b"><apply id="S5.SS3.p4.2.m2.1.1.cmml" xref="S5.SS3.p4.2.m2.1.1"><plus id="S5.SS3.p4.2.m2.1.1.1.cmml" xref="S5.SS3.p4.2.m2.1.1"></plus><apply id="S5.SS3.p4.2.m2.1.1.2.cmml" xref="S5.SS3.p4.2.m2.1.1.2"><csymbol cd="latexml" id="S5.SS3.p4.2.m2.1.1.2.1.cmml" xref="S5.SS3.p4.2.m2.1.1.2.1">percent</csymbol><cn id="S5.SS3.p4.2.m2.1.1.2.2.cmml" type="float" xref="S5.SS3.p4.2.m2.1.1.2.2">0.43</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.2.m2.1c">+0.43\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.2.m2.1d">+ 0.43 %</annotation></semantics></math> as compared to the current state-of-the-art results that were published in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite>). Hence, we expect that with more sophisticated RGB image synthesis methods the results on all data sets are likely to improve.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">Qualitative Evaluation</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">To give a visual impression of the models segmentation performance, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#S5.F6" title="Figure 6 ‣ V-E Comparison to the State of the Art ‣ V Experiments &amp; Results ‣ HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios"><span class="ltx_text ltx_ref_tag">6</span></a> shows example inferences for each data set in HS3-Bench side by side. The top row shows ground-truth label maps, followed by inferences on <span class="ltx_glossaryref" title="">HSI</span> data, then <span class="ltx_glossaryref" title="">pRGB</span> and finally <span class="ltx_glossaryref" title="">pRGB</span> with pre-trained backbone. For inference we applied the model that showed the best average performance for the given data type or pre-training configuration consistently to all datasets. The best models are RU-Net for <span class="ltx_glossaryref" title="">HSI</span> and <span class="ltx_glossaryref" title="">pRGB</span> without pre-training (row 2 and 3) and fine-tuned <span class="ltx_glossaryref" title="">DL3+</span> with pre-trained backbone network (row 4). The example predictions support the impression of the statistical results. The predictions on <span class="ltx_glossaryref" title="">pRGB</span> data are less noisy than <span class="ltx_glossaryref" title="">HSI</span> and contours are more precise. The difference between row 3 and row 4 are subtle. It seems that object contours are a bit more precise for the pre-trained model and object surfaces are more homogeneous.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.5.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.6.2">Comparison to the State of the Art</span>
</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.4"><span class="ltx_glossaryref" title="">HCV2</span> was introduced in the context of a challenge for a workshop at ICCV 2021. The best reported results in the competition achieved a Jaccard score of <math alttext="51.4\%" class="ltx_Math" display="inline" id="S5.SS5.p1.1.m1.1"><semantics id="S5.SS5.p1.1.m1.1a"><mrow id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml"><mn id="S5.SS5.p1.1.m1.1.1.2" xref="S5.SS5.p1.1.m1.1.1.2.cmml">51.4</mn><mo id="S5.SS5.p1.1.m1.1.1.1" xref="S5.SS5.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><apply id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS5.p1.1.m1.1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS5.p1.1.m1.1.1.2.cmml" type="float" xref="S5.SS5.p1.1.m1.1.1.2">51.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">51.4\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.1.m1.1d">51.4 %</annotation></semantics></math>. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite> this result was raised to <math alttext="51.76\%" class="ltx_Math" display="inline" id="S5.SS5.p1.2.m2.1"><semantics id="S5.SS5.p1.2.m2.1a"><mrow id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml"><mn id="S5.SS5.p1.2.m2.1.1.2" xref="S5.SS5.p1.2.m2.1.1.2.cmml">51.76</mn><mo id="S5.SS5.p1.2.m2.1.1.1" xref="S5.SS5.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><apply id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p1.2.m2.1.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p1.2.m2.1.1.2.cmml" type="float" xref="S5.SS5.p1.2.m2.1.1.2">51.76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">51.76\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.2.m2.1d">51.76 %</annotation></semantics></math> by HRNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib21" title="">21</a>]</cite> that was fine-tuned on the RGB-images provided with <span class="ltx_glossaryref" title="">HCV2</span>. Our best pre-trained model on these RGB-images achieved a Jaccard score of <math alttext="52.11\%" class="ltx_Math" display="inline" id="S5.SS5.p1.3.m3.1"><semantics id="S5.SS5.p1.3.m3.1a"><mrow id="S5.SS5.p1.3.m3.1.1" xref="S5.SS5.p1.3.m3.1.1.cmml"><mn id="S5.SS5.p1.3.m3.1.1.2" xref="S5.SS5.p1.3.m3.1.1.2.cmml">52.11</mn><mo id="S5.SS5.p1.3.m3.1.1.1" xref="S5.SS5.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.3.m3.1b"><apply id="S5.SS5.p1.3.m3.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS5.p1.3.m3.1.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1.1">percent</csymbol><cn id="S5.SS5.p1.3.m3.1.1.2.cmml" type="float" xref="S5.SS5.p1.3.m3.1.1.2">52.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.3.m3.1c">52.11\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.3.m3.1d">52.11 %</annotation></semantics></math> (<math alttext="+0.43\%" class="ltx_Math" display="inline" id="S5.SS5.p1.4.m4.1"><semantics id="S5.SS5.p1.4.m4.1a"><mrow id="S5.SS5.p1.4.m4.1.1" xref="S5.SS5.p1.4.m4.1.1.cmml"><mo id="S5.SS5.p1.4.m4.1.1a" xref="S5.SS5.p1.4.m4.1.1.cmml">+</mo><mrow id="S5.SS5.p1.4.m4.1.1.2" xref="S5.SS5.p1.4.m4.1.1.2.cmml"><mn id="S5.SS5.p1.4.m4.1.1.2.2" xref="S5.SS5.p1.4.m4.1.1.2.2.cmml">0.43</mn><mo id="S5.SS5.p1.4.m4.1.1.2.1" xref="S5.SS5.p1.4.m4.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.4.m4.1b"><apply id="S5.SS5.p1.4.m4.1.1.cmml" xref="S5.SS5.p1.4.m4.1.1"><plus id="S5.SS5.p1.4.m4.1.1.1.cmml" xref="S5.SS5.p1.4.m4.1.1"></plus><apply id="S5.SS5.p1.4.m4.1.1.2.cmml" xref="S5.SS5.p1.4.m4.1.1.2"><csymbol cd="latexml" id="S5.SS5.p1.4.m4.1.1.2.1.cmml" xref="S5.SS5.p1.4.m4.1.1.2.1">percent</csymbol><cn id="S5.SS5.p1.4.m4.1.1.2.2.cmml" type="float" xref="S5.SS5.p1.4.m4.1.1.2.2">0.43</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.4.m4.1c">+0.43\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.4.m4.1d">+ 0.43 %</annotation></semantics></math> increase compared to the current state-of-the-art).</p>
</div>
<div class="ltx_para" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.5">Under the conditions, that no pre-training and only <span class="ltx_glossaryref" title="">HSI</span> data or data derived from <span class="ltx_glossaryref" title="">HSI</span> is used, the best listed model (FCN101 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib22" title="">22</a>]</cite>) in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite> achieved a Jaccard score of <math alttext="41.13\%" class="ltx_Math" display="inline" id="S5.SS5.p2.1.m1.1"><semantics id="S5.SS5.p2.1.m1.1a"><mrow id="S5.SS5.p2.1.m1.1.1" xref="S5.SS5.p2.1.m1.1.1.cmml"><mn id="S5.SS5.p2.1.m1.1.1.2" xref="S5.SS5.p2.1.m1.1.1.2.cmml">41.13</mn><mo id="S5.SS5.p2.1.m1.1.1.1" xref="S5.SS5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.1.m1.1b"><apply id="S5.SS5.p2.1.m1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS5.p2.1.m1.1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1.1">percent</csymbol><cn id="S5.SS5.p2.1.m1.1.1.2.cmml" type="float" xref="S5.SS5.p2.1.m1.1.1.2">41.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.1.m1.1c">41.13\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.1.m1.1d">41.13 %</annotation></semantics></math>. With RU-Net and <span class="ltx_glossaryref" title="">HSI</span> data we improved this result to <math alttext="42.23\%" class="ltx_Math" display="inline" id="S5.SS5.p2.2.m2.1"><semantics id="S5.SS5.p2.2.m2.1a"><mrow id="S5.SS5.p2.2.m2.1.1" xref="S5.SS5.p2.2.m2.1.1.cmml"><mn id="S5.SS5.p2.2.m2.1.1.2" xref="S5.SS5.p2.2.m2.1.1.2.cmml">42.23</mn><mo id="S5.SS5.p2.2.m2.1.1.1" xref="S5.SS5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.2.m2.1b"><apply id="S5.SS5.p2.2.m2.1.1.cmml" xref="S5.SS5.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p2.2.m2.1.1.1.cmml" xref="S5.SS5.p2.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p2.2.m2.1.1.2.cmml" type="float" xref="S5.SS5.p2.2.m2.1.1.2">42.23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.2.m2.1c">42.23\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.2.m2.1d">42.23 %</annotation></semantics></math> (<math alttext="+1.1\%" class="ltx_Math" display="inline" id="S5.SS5.p2.3.m3.1"><semantics id="S5.SS5.p2.3.m3.1a"><mrow id="S5.SS5.p2.3.m3.1.1" xref="S5.SS5.p2.3.m3.1.1.cmml"><mo id="S5.SS5.p2.3.m3.1.1a" xref="S5.SS5.p2.3.m3.1.1.cmml">+</mo><mrow id="S5.SS5.p2.3.m3.1.1.2" xref="S5.SS5.p2.3.m3.1.1.2.cmml"><mn id="S5.SS5.p2.3.m3.1.1.2.2" xref="S5.SS5.p2.3.m3.1.1.2.2.cmml">1.1</mn><mo id="S5.SS5.p2.3.m3.1.1.2.1" xref="S5.SS5.p2.3.m3.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.3.m3.1b"><apply id="S5.SS5.p2.3.m3.1.1.cmml" xref="S5.SS5.p2.3.m3.1.1"><plus id="S5.SS5.p2.3.m3.1.1.1.cmml" xref="S5.SS5.p2.3.m3.1.1"></plus><apply id="S5.SS5.p2.3.m3.1.1.2.cmml" xref="S5.SS5.p2.3.m3.1.1.2"><csymbol cd="latexml" id="S5.SS5.p2.3.m3.1.1.2.1.cmml" xref="S5.SS5.p2.3.m3.1.1.2.1">percent</csymbol><cn id="S5.SS5.p2.3.m3.1.1.2.2.cmml" type="float" xref="S5.SS5.p2.3.m3.1.1.2.2">1.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.3.m3.1c">+1.1\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.3.m3.1d">+ 1.1 %</annotation></semantics></math>) and with data derived from <span class="ltx_glossaryref" title="">HSI</span>, i. e. PCA1, the same model further improves to <math alttext="44.26\%" class="ltx_Math" display="inline" id="S5.SS5.p2.4.m4.1"><semantics id="S5.SS5.p2.4.m4.1a"><mrow id="S5.SS5.p2.4.m4.1.1" xref="S5.SS5.p2.4.m4.1.1.cmml"><mn id="S5.SS5.p2.4.m4.1.1.2" xref="S5.SS5.p2.4.m4.1.1.2.cmml">44.26</mn><mo id="S5.SS5.p2.4.m4.1.1.1" xref="S5.SS5.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.4.m4.1b"><apply id="S5.SS5.p2.4.m4.1.1.cmml" xref="S5.SS5.p2.4.m4.1.1"><csymbol cd="latexml" id="S5.SS5.p2.4.m4.1.1.1.cmml" xref="S5.SS5.p2.4.m4.1.1.1">percent</csymbol><cn id="S5.SS5.p2.4.m4.1.1.2.cmml" type="float" xref="S5.SS5.p2.4.m4.1.1.2">44.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.4.m4.1c">44.26\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.4.m4.1d">44.26 %</annotation></semantics></math> (<math alttext="+3.13\%" class="ltx_Math" display="inline" id="S5.SS5.p2.5.m5.1"><semantics id="S5.SS5.p2.5.m5.1a"><mrow id="S5.SS5.p2.5.m5.1.1" xref="S5.SS5.p2.5.m5.1.1.cmml"><mo id="S5.SS5.p2.5.m5.1.1a" xref="S5.SS5.p2.5.m5.1.1.cmml">+</mo><mrow id="S5.SS5.p2.5.m5.1.1.2" xref="S5.SS5.p2.5.m5.1.1.2.cmml"><mn id="S5.SS5.p2.5.m5.1.1.2.2" xref="S5.SS5.p2.5.m5.1.1.2.2.cmml">3.13</mn><mo id="S5.SS5.p2.5.m5.1.1.2.1" xref="S5.SS5.p2.5.m5.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.5.m5.1b"><apply id="S5.SS5.p2.5.m5.1.1.cmml" xref="S5.SS5.p2.5.m5.1.1"><plus id="S5.SS5.p2.5.m5.1.1.1.cmml" xref="S5.SS5.p2.5.m5.1.1"></plus><apply id="S5.SS5.p2.5.m5.1.1.2.cmml" xref="S5.SS5.p2.5.m5.1.1.2"><csymbol cd="latexml" id="S5.SS5.p2.5.m5.1.1.2.1.cmml" xref="S5.SS5.p2.5.m5.1.1.2.1">percent</csymbol><cn id="S5.SS5.p2.5.m5.1.1.2.2.cmml" type="float" xref="S5.SS5.p2.5.m5.1.1.2.2">3.13</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.5.m5.1c">+3.13\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.5.m5.1d">+ 3.13 %</annotation></semantics></math>).</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.1" style="width:108.4pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="451" id="S5.F6.1.g1" src="extracted/5860638/hcv_gt0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.2" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S5.F6.2.g1" src="extracted/5860638/hyko2_gt26.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.3" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="316" id="S5.F6.3.g1" src="extracted/5860638/hsidrive_gt0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.4" style="width:108.4pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="451" id="S5.F6.4.g1" src="extracted/5860638/hcv_pred0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.5" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S5.F6.5.g1" src="extracted/5860638/hyko2_pred26.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.6" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="316" id="S5.F6.6.g1" src="extracted/5860638/hsidrive_pred0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.7" style="width:108.4pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="451" id="S5.F6.7.g1" src="extracted/5860638/hcvprgb_pred0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.8" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S5.F6.8.g1" src="extracted/5860638/hyko2rgb_pred26.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.9" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="316" id="S5.F6.9.g1" src="extracted/5860638/hsidriveprgb_pred0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.10" style="width:108.4pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="451" id="S5.F6.10.g1" src="extracted/5860638/hcvprgb-bb_pred0.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.11" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S5.F6.11.g1" src="extracted/5860638/hyko2-bb_pred26.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.12" style="width:138.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="316" id="S5.F6.12.g1" src="extracted/5860638/hsidrive-bb_pred0.png" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Example inferences for <span class="ltx_glossaryref" title="">HCV2</span>, HyKo2 and HSI-Drive. The top row shows the ground-truth label map. Row 2 and 3 show inferences on <span class="ltx_glossaryref" title="">HSI</span> and <span class="ltx_glossaryref" title="">pRGB</span> data without pre-training, respectively.
The bottom row shows inferences with <span class="ltx_glossaryref" title="">pRGB</span> data with pre-training. We consistently used the models that showed best performance for the given data type, i. e. RU-Net(row 2 and 3) and <span class="ltx_glossaryref" title="">DL3+</span> with pretrained backbone (row 4).</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Summary</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper we presented HS3-Bench, a hyperspectral semantic segmentation benchmark for driving scenarios which is designed for systematic comparison of different models and algorithms. Based on this benchmark, we performed systematic evaluation of hyperspectral image representations, i. e. full spectrum, <span class="ltx_glossaryref" title="">PCA</span>-reduced spectrum and synthesized pseudo-RGB images as well as the impact of knowledge transfer through pre-trained weights.
We demonstrated the application of HS3-Bench by deriving a suitable configuration of regularization approaches to a U-Net model (RU-Net). In our experiments we used RU-Net as well as <span class="ltx_glossaryref" title="">DeeplabV3+ (DL3+)</span> with a MobileNetV2 backbone.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">We consider both models - RU-Net and <span class="ltx_glossaryref" title="">DL3+</span>- as strong baselines for HS3-Bench. Under the condition that only limited hyperspectral data is available the regularized U-Net with dimensionality reduction outperforms <span class="ltx_glossaryref" title="">DL3+</span> as well as the current state of the art model. However, if additional RGB data is available in the problem domain, <span class="ltx_glossaryref" title="">DL3+</span> with <span class="ltx_glossaryref" title="">pRGB</span> images synthesized from <span class="ltx_glossaryref" title="">HSI</span> data can effectively leverage the domain knowledge through pre-training and should be preferred. <span class="ltx_glossaryref" title="">DL3+</span> with a pre-trained backbone network fine-tuned on RGB data outperforms the previous state-of-the-art models using pre-trained weights as well.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Our results pose interesting questions for future research.
In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11205v1#bib.bib14" title="">14</a>]</cite> the authors state that their dual fusion network effectively utilizes knowledge from pre-trained RGB models and hyperspectral data. However, our results suggest that major improvements can be traced back to leveraging domain knowledge through pre-trained model parameters. Further, our experiments support that available learning-based models benefit more from leveraging additional RGB training data than from leveraging additional HSI channels.
We believe the proposed HS3-Bench can be a valuable tool to support research directions such as finding general backbone models for <span class="ltx_glossaryref" title="">HSI</span> data and models that better exploit all channel information in <span class="ltx_glossaryref" title="">HSI</span> data. Also, further investigation is required to identify the causes of the performance discrepancy between <span class="ltx_glossaryref" title="">HSI</span> and RGB.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y. Chen, P. Liu, J. Zhao, K. Huang, and Q. Yan, “Shallow-Guided
Transformer for Semantic Segmentation of Hyperspectral Remote Sensing
Imagery,” vol. 15, no. 13, p. 3366, 2023. [Online]. Available:
<a class="ltx_ref ltx_url" href="https://www.mdpi.com/2072-4292/15/13/3366" title="">https://www.mdpi.com/2072-4292/15/13/3366</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M. A. Calin, S. V. Parasca, D. Savastru, and D. Manea, “Hyperspectral imaging
in the medical field: Present and future,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Applied Spectroscopy
Reviews</em>, vol. 49, no. 6, pp. 435–447, 2014. [Online]. Available:
<a class="ltx_ref ltx_url" href="https://doi.org/10.1080/05704928.2013.838678" title="">https://doi.org/10.1080/05704928.2013.838678</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. Lu, P. D. Dao, J. Liu, Y. He, and J. Shang, “Recent advances of
hyperspectral imaging technology and applications in agriculture,”
<em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Remote Sensing</em>, vol. 12, no. 16, 2020. [Online]. Available:
<a class="ltx_ref ltx_url" href="https://www.mdpi.com/2072-4292/12/16/2659" title="">https://www.mdpi.com/2072-4292/12/16/2659</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
C. Winkens, F. Sattler, V. Adams, and D. Paulus, “Hyko: A spectral dataset for
scene understanding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">2017 IEEE International Conference on
Computer Vision Workshops (ICCVW)</em>.   Institute of Electrical and Electronics Engineers,, https://www.ieee.org/,
2017, pp. 254–261.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
K. Basterretxea, V. Martínez, J. Echanobe, J. Gutiérrez–Zaballa, and
I. Del Campo, “Hsi-drive: A dataset for the research of hyperspectral image
processing applied to autonomous driving systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">2021 IEEE
Intelligent Vehicles Symposium (IV)</em>, 2021, pp. 866–873.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Li, Y. Fu, S. Liang, Y. Zheng, L. Chen, Q. Shen, E. Huang, Y. Huang,
Y. Zhuang, Y. Li, D. Zhang, Y. Li, S. You, Y. Zheng, F. Lu, B. Shi, and R. T.
Tan, “HyperspectralCityV2.0,” 2021, last Accessed: 13.03.2024.
[Online]. Available:
<a class="ltx_ref ltx_url" href="https://pbdl-ws.github.io/pbdl2021/challenge/download.html" title="">https://pbdl-ws.github.io/pbdl2021/challenge/download.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson,
U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset for semantic
urban scene understanding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Alhaija, S. Mustikovela, L. Mescheder, A. Geiger, and C. Rother, “Augmented
reality meets computer vision: Efficient data generation for urban driving
scenes,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Journal of Computer Vision (IJCV)</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Gutiérrez-Zaballa, K. Basterretxea, J. Echanobe, M. Victoria Martínez, and
U. Martinez-Corral, “Hsi-drive v2.0: More data for new challenges in scene
understanding for autonomous driving,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">2023 IEEE Symposium Series
on Computational Intelligence (SSCI)</em>, 2023, pp. 207–214.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Lu, H. Liu, Y. Yao, S. Tao, Z. Tang, and J. Lu, “Hsi road: A hyper spectral
image dataset for road segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">2020 IEEE International
Conference on Multimedia and Expo (ICME)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for
biomedical image segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">International Conference on Medical
image computing and computer-assisted intervention</em>.   Springer, 2015, pp. 234–241.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L.-C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam, “Encoder-decoder
with atrous separable convolution for semantic image segmentation,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Computer Vision – ECCV 2018</em>, V. Ferrari, M. Hebert, C. Sminchisescu,
and Y. Weiss, Eds.   Cham: Springer
International Publishing, 2018, pp. 833–851.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Gutiérrez-Zaballa, K. Basterretxea, J. Echanobe, M. V.
Martínez, U. Martinez-Corral, Ó. Mata-Carballeira, and
I. del Campo, “On-chip hyperspectral image segmentation with fully
convolutional networks for scene understanding in autonomous driving,”
<em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">J. Syst. Archit.</em>, vol. 139, p. 102878, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
X. Ding, S. Gu, and J. Yang, “Dual fusion network for hyperspectral semantic
segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Image and Graphics</em>, H. Lu, W. Ouyang, H. Huang,
J. Lu, R. Liu, J. Dong, and M. Xu, Eds.   Cham: Springer Nature Switzerland, 2023, pp. 149–161.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2016, pp. 770–778.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Sokolova and G. Lapalme, “A systematic analysis of performance measures for
classification tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Information processing &amp; management</em>, vol. 45,
no. 4, pp. 427–437, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. Everingham, S. M. A. Eslami, L. V. Gool, C. K. I. Williams, J. M. Winn, and
A. Zisserman, “The pascal visual object classes challenge: A
retrospective,” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Int. J. Comput. Vis.</em>, vol. 111, no. 1, pp. 98–136,
2015. [Online]. Available: <a class="ltx_ref ltx_url" href="https://doi.org/10.1007/s11263-014-0733-5" title="">https://doi.org/10.1007/s11263-014-0733-5</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Z. Wojna, V. Ferrari, S. Guadarrama, N. Silberman, L.-C. Chen, A. Fathi, and
J. Uijlings, “The devil is in the decoder: Classification, regression and
gans,” <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International Journal of Computer Vision</em>, vol. 127, pp.
1694–1706, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam, “Rethinking atrous
convolution for semantic image segmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">ArXiv</em>, vol.
abs/1706.05587, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Sandler, A. G. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, “Mobilenetv2:
Inverted residuals and linear bottlenecks,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">2018 IEEE/CVF Conference
on Computer Vision and Pattern Recognition</em>, pp. 4510–4520, 2018. [Online].
Available: <a class="ltx_ref ltx_url" href="https://api.semanticscholar.org/CorpusID:4555207" title="">https://api.semanticscholar.org/CorpusID:4555207</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Wang, K. Sun, T. Cheng, B. Jiang, C. Deng, Y. Zhao, D. Liu, Y. Mu, M. Tan,
X. Wang, W. Liu, and B. Xiao, “Deep high-resolution representation learning
for visual recognition,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">IEEE Transactions on Pattern Analysis and
Machine Intelligence</em>, vol. 43, no. 10, pp. 3349–3364, oct 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for
semantic segmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">2015 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>.   Los
Alamitos, CA, USA: IEEE Computer Society, jun 2015, pp. 3431–3440.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 17 13:52:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
