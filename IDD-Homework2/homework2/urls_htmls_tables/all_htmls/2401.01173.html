<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.01173] En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data</title><meta property="og:description" content="We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars. Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise p…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.01173">

<!--Generated on Tue Feb 27 07:36:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">En3D: An Enhanced Generative Model for Sculpting 3D Humans from 
<br class="ltx_break">2D Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yifang Men<sup id="id11.9.id1" class="ltx_sup">1</sup>, Biwen Lei<sup id="id12.10.id2" class="ltx_sup">1</sup>, Yuan Yao<sup id="id13.11.id3" class="ltx_sup">1</sup>, Miaomiao Cui<sup id="id14.12.id4" class="ltx_sup">1</sup>, Zhouhui Lian<sup id="id15.13.id5" class="ltx_sup">2</sup>, Xuansong Xie<sup id="id16.14.id6" class="ltx_sup">1</sup> 
<br class="ltx_break"><sup id="id17.15.id7" class="ltx_sup"><span id="id17.15.id7.1" class="ltx_text" style="font-size:90%;">1</span></sup><span id="id18.16.id8" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Institute for Intelligent Computing, Alibaba Group</span> 
<br class="ltx_break"><sup id="id19.17.id9" class="ltx_sup"><span id="id19.17.id9.1" class="ltx_text" style="font-size:90%;">2</span></sup><span id="id20.18.id10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">Wangxuan Institute of Computer Technology, Peking University</span> 
<br class="ltx_break"><a target="_blank" href="https://menyifang.github.io/projects/En3D/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://menyifang.github.io/projects/En3D/index.html</a> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id21.id1" class="ltx_p">We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars. Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3D generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3D humans without relying on pre-existing 3D or 2D assets. To address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3D generative model from synthetic 2D data. During inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3D shapes. Specifically, En3D comprises three modules: a 3D generator that accurately models generalizable 3D humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical UV partitioning and a differentiable rasterizer. Experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity. We also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation.</p>
</div>
<div id="id10" class="ltx_logical-block">
<div id="id10.p1" class="ltx_para">
<img src="/html/2401.01173/assets/pic/teaser3.png" id="id9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="251" alt="[Uncaptioned image]">
</div>
<figure id="S0.F1" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.3.2" class="ltx_text" style="font-size:90%;">Given random noises or guided texts, our generative scheme can synthesize high-fidelity 3D human avatars that are visually realistic and geometrically accurate. These avatars can be seamlessly animated and easily edited. Our model is trained on 2D synthetic data without relying on any pre-existing 3D or 2D collections.
</span></figcaption>
</figure>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D human avatars play an important role in various applications of AR/VR such as video games, telepresence and virtual try-on.
Realistic human modeling is an essential task, and many valuable efforts have been made by leveraging neural implicit fields to learn high-quality articulated avatars
 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>.
However, these methods are directly learned from monocular videos or image sequences, where subjects are single individuals wearing specific garments, thus limiting their scalability.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Generative models learn a shared 3D representation to synthesize clothed humans with varying identities, clothing and poses. Traditional methods are typically trained on 3D datasets, which are limited and expensive to acquire. This data scarcity limits the model’s generalization ability and may lead to overfitting on small datasets. Recently, 3D-aware image synthesis methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> have demonstrated great potential in learning 3D generative models of rigid objects from 2D image collections.
Follow-up works show the feasibility of learning articulated humans from image collections driven by SMPL-based deformations, but only in limited quality and resolution. EVA3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> represents humans as a composition of multiple parts with NeRF representations.
AG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> incorporates an efficient articulation module to capture both body shape and cloth deformation. Nevertheless, there remains a noticeable gap between generated and real humans in terms of appearance and geometry. Moreover, their results are limited to specific views (i.e., frontal angles) and lack diversity (i.e., fashion images in similar skin tone, body shape, and age).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The aim of this paper is to propose a zero-shot 3D generative scheme that does not rely on any pre-existing 3D or 2D datasets, yet is capable of producing high-quality 3D humans that are visually realistic, geometrically accurate, and content-wise diverse. The generated avatars can be seamlessly animated and easily edited. An illustration is provided in Figure <a href="#S0.F1" title="Figure 1 ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
To address this challenging task, our proposed method inherits from 3D-aware human image synthesis and exhibits substantial distinctions based on several key insights.
Rethinking the nature of 3D-aware generative methods from 2D collections <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, they actually try to learn a generalizable and deformable 3D representation, whose 2D projections can meet the distribution of human images in corresponding views.
Thereby, it is crucial for accurate physical modeling between 3D objects and 2D projections. However, previous works typically leverage pre-existing 2D human images to estimate physical parameters (i.e., camera and body poses), which are inaccurate because of imprecise SMPL priors for highly-articulated humans. This inaccuracy limits the synthesis ability for realistic multi-view renderings. Second, these methods solely rely on discriminating 2D renderings, which is ambiguous and loose to capture inherent 3D shapes in detail, especially for intricate human anatomy.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address these limitations, we propose a novel generative scheme with two core designs.
Firstly, we introduce a meticulously-crafted workflow that implements accurate physical modeling to learn an enhanced 3D generative model from synthetic data. This is achieved by instantiating a 3D body scene and projecting the underlying 3D skeleton into 2D pose images using explicit camera parameters. These 2D pose images act as conditions to control a 2D diffusion model, synthesizing realistic human images from specific viewpoints. By leveraging synthetic view-balanced, diverse and structured human images, along with known physical parameters, we employ a 3D generator equipped with an enhanced renderer and discriminator to learn realistic appearance modeling.
Secondly, we improve the 3D shape quality by leveraging the gap between high-quality multi-view renderings and the coarse mesh produced by the 3D generative module. Specifically, we integrate an optimization module that utilizes multi-view normal constraints to
rapidly refine geometry details under supervision.
Additionally, we incorporate an explicit texturing module to ensure faithful UV texture maps. In contrast to previous works that rely on inaccurate physical settings and inadequate shape supervision, we rebuild the generative scheme from the ground up, resulting in comprehensive improvements in image quality, geometry accuracy, and content diversity.
In summary, our contributions are threefold:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present a zero-shot generative scheme that efficiently synthesizes high-quality 3D human avatars with visual realism, geometric accuracy and content diversity. These avatars can be seamlessly animated and easily edited, offering greater flexibility in their applications.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We develop a meticulously-crafted workflow to learn an enhanced generative model from synthesized human images that are balanced, diverse, and also possess known physical parameters. This leads to diverse 3D-aware human image synthesis with realistic appearance.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose the integration of optimization modules into the 3D generator, leveraging multi-view guidance to enhance both shape quality and texture fidelity, thus achieving realistic 3D human assets.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2401.01173/assets/pic/networks4.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.5.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.3.2.1" class="ltx_text" style="font-size:90%;">An overview of the proposed scheme, which consists of three modules: 3D generative modeling (3DGM), the geometric sculpting (GS) and the explicit texturing (ET). 3DGM using synthesized diverse, balanced and structured human image with accurate camera <math id="S1.F2.3.2.1.m1.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S1.F2.3.2.1.m1.1b"><mi id="S1.F2.3.2.1.m1.1.1" xref="S1.F2.3.2.1.m1.1.1.cmml">φ</mi><annotation-xml encoding="MathML-Content" id="S1.F2.3.2.1.m1.1c"><ci id="S1.F2.3.2.1.m1.1.1.cmml" xref="S1.F2.3.2.1.m1.1.1">𝜑</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.3.2.1.m1.1d">\varphi</annotation></semantics></math> to learn generalizable 3D humans with the triplane-based architecture. GS is integrated as an optimization module by utilizing multi-view normal constraints to refine and carve geometry details. ET utilizes UV partitioning and a differentiable rasterizer to disentangles explicit UV texture maps. Not only multi-view renderings but also realistic 3D models can be acquired for final results.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">3D Human Modeling.</span> Parametric models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite> serve as a common representation for 3D human modeling, they allows for robust control by deforming a template mesh with a series of low-dimensional parameters, but can only generate naked 3D humans. Similar ideas have been extended to model
clothed humans <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>, but geometric expressivity is restricted due to the fixed mesh topology.
Subsequent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> further introduce implicit surfaces to produce complex non-linear deformations of 3D bodies. Unfortunately, the aforementioned approaches all require 3D scans of various human poses for model fitting, which are difficult to acquire.
With the explosion of NeRF, valuable efforts have been made towards combining NeRF models with explicit human models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>.
Neural body <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> anchors a set of latent codes to the vertices of the SMPL model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> and transforms the spatial locations of the codes to the volume in the observation space.
HumanNeRF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> optimizes for a canonical, volumetric T-pose of the human with a motion field to map the non-rigid transformations. Nevertheless, these methods are learned directly from monocular videos or image sequences, where subjects are single individuals wearing specific garments, thus limiting their scalability.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Generative 3D-aware Image Synthesis.</span>
Recently, 3D-aware image synthesis methods have lifted image generation with explicit view control by integrating the 2D generative models  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite> with 3D representations, such as voxels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>, meshes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite> and points clouds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>.
GRAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite> and <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="\pi" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\pi</annotation></semantics></math>-GAN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> firstly integrate the implicit representation networks, i.e., NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite>, with differentiable volumetric rendering for 3D scene generation.
However, they have difficulties in training on high-resolution images due to the costly rendering process.
Subsequent works have sought to improve the efficiency and quality of such NeRF-based GANs, either by adopting a two-stage rendering process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> or a smart sampling strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>.
StyleSDF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite> combines a SDF-based volume renderer and a 2D StyleGAN network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite> for photorealistic image generation.
EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> introduces a superior triplane representation to leverage 2D CNN-based feature generators for efficient generalization over 3D spaces.
Although these methods demonstrate impressive quality in view-consistent image synthesis, they are limited to simplified rigid objects such as faces, cats and cars.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">To learn highly articulated humans from unstructured 2D images, recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite> integrate the deformation field to learn non-rigid deformations based on the body prior of estimated SMPL parameters.
EVA3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> represents humans as a composition of multiple parts with NeRF representations.
Instead of directly rendering the image from a 3D representation, 3DHumanGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite> uses an equivariant 2D generator modulated by 3D human body prior, which enables to establish one-to-many mapping from 3D geometry to synthesized textures from 2D images.
AG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> combines the 3D generator with an efficient articulation module to warp from canonical space into posed space via a learned continuous deformation field.
However, a gap still exists between the generated and real humans in terms of appearance, due to the imprecise priors from complex poses as well as the data biases from limited human poses and imbalanced viewing angles in the dataset.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method Description</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our goal is to develop a zero-shot 3D generative scheme that does not rely on any pre-existing 3D or 2D collections, yet is capable of producing high-quality 3D humans that are visually realistic, geometrically accurate and content-wise diverse to generalize to arbitrary humans.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">An overview of the proposed scheme is illustrated in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We build a sequential pipeline with the following three modules: the 3D generative modeling (3DGM), the geometric sculpting (GS) and the explicit texturing (ET).
The first module synthesizes view-balanced, structured and diverse human images with known camera parameters. Subsequently, it learns a 3D generative model from these synthetic data, focusing on realistic appearance modeling (Section <a href="#S3.SS1" title="3.1 3D generative modeling ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>). To overcome the inaccuracy of the 3D shape, the GS module is incorporated during the inference process. It optimizes a hybrid representation with multi-view normal constraints to carve intricate mesh details (Section <a href="#S3.SS2" title="3.2 Geometric sculpting ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). Additionally, the ET module is employed to disentangle explicit texture by utilizing semantical UV partitioning and a differentiable rasterizer (Section <a href="#S3.SS3" title="3.3 Explicit texturing ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>). By combining these modules, we are able to synthesize high-quality and faithful 3D human avatars by incorporating random noises or guided texts/images (Section <a href="#S3.SS4" title="3.4 Inference ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>3D generative modeling</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Without any 3D or 2D collections, we develop a synthesis-based flow to learn a 3D generative module from 2D synthetic data.
We start by instantiating a 3D scene through the projection of underlying 3D skeletons onto 2D pose images, utilizing accurate physical parameters (i.e., camera parameters).
Subsequently, the projected 2D pose images serve as conditions to control the 2D diffusion model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> for synthesizing view-balanced, diverse, and lifelike human images.
Finally, we employ a triplane-based generator with enhanced designs to learn a generalizable 3D representation from the synthetic data.
Details are described as follows.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.6" class="ltx_p"><span id="S3.SS1.p2.6.1" class="ltx_text ltx_font_bold">3D instantiation.</span>
Starting with a template body mesh (e.g., SMPL-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite>) positioned and posed in canonical space, we estimate the 3D joint locations <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{P}_{3d}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">𝒫</mi><mrow id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mn id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝒫</ci><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><times id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">3</cn><ci id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{P}_{3d}</annotation></semantics></math> by regressing them from interpolated vertices. We then project <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{P}_{3d}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">𝒫</mi><mrow id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mn id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.1.3.1" xref="S3.SS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝒫</ci><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><times id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3.1"></times><cn type="integer" id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">3</cn><ci id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathcal{P}_{3d}</annotation></semantics></math> onto 2D poses <math id="S3.SS1.p2.3.m3.5" class="ltx_Math" alttext="\mathcal{P}_{i},i=1,…,k" display="inline"><semantics id="S3.SS1.p2.3.m3.5a"><mrow id="S3.SS1.p2.3.m3.5.5.2" xref="S3.SS1.p2.3.m3.5.5.3.cmml"><mrow id="S3.SS1.p2.3.m3.4.4.1.1" xref="S3.SS1.p2.3.m3.4.4.1.1.cmml"><mrow id="S3.SS1.p2.3.m3.4.4.1.1.1.1" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.cmml"><msub id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.2" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.2.cmml">𝒫</mi><mi id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.3" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p2.3.m3.4.4.1.1.1.1.2" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.cmml">,</mo><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">i</mi></mrow><mo id="S3.SS1.p2.3.m3.4.4.1.1.2" xref="S3.SS1.p2.3.m3.4.4.1.1.2.cmml">=</mo><mn id="S3.SS1.p2.3.m3.4.4.1.1.3" xref="S3.SS1.p2.3.m3.4.4.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.p2.3.m3.5.5.2.3" xref="S3.SS1.p2.3.m3.5.5.3a.cmml">,</mo><mrow id="S3.SS1.p2.3.m3.5.5.2.2.2" xref="S3.SS1.p2.3.m3.5.5.2.2.1.cmml"><mi mathvariant="normal" id="S3.SS1.p2.3.m3.2.2" xref="S3.SS1.p2.3.m3.2.2.cmml">…</mi><mo id="S3.SS1.p2.3.m3.5.5.2.2.2.1" xref="S3.SS1.p2.3.m3.5.5.2.2.1.cmml">,</mo><mi id="S3.SS1.p2.3.m3.3.3" xref="S3.SS1.p2.3.m3.3.3.cmml">k</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.5b"><apply id="S3.SS1.p2.3.m3.5.5.3.cmml" xref="S3.SS1.p2.3.m3.5.5.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.5.5.3a.cmml" xref="S3.SS1.p2.3.m3.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p2.3.m3.4.4.1.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1"><eq id="S3.SS1.p2.3.m3.4.4.1.1.2.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.2"></eq><list id="S3.SS1.p2.3.m3.4.4.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1"><apply id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.2">𝒫</ci><ci id="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝑖</ci></list><cn type="integer" id="S3.SS1.p2.3.m3.4.4.1.1.3.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.3">1</cn></apply><list id="S3.SS1.p2.3.m3.5.5.2.2.1.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2"><ci id="S3.SS1.p2.3.m3.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2">…</ci><ci id="S3.SS1.p2.3.m3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3">𝑘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.5c">\mathcal{P}_{i},i=1,…,k</annotation></semantics></math> from <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathcal{K}</annotation></semantics></math> horizontally uniformly sampled viewpoints <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝜑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\varphi</annotation></semantics></math>. In this way, paired 2D pose images and their corresponding camera parameters <math id="S3.SS1.p2.6.m6.2" class="ltx_Math" alttext="\{\mathcal{P}_{i},\varphi_{i}\}" display="inline"><semantics id="S3.SS1.p2.6.m6.2a"><mrow id="S3.SS1.p2.6.m6.2.2.2" xref="S3.SS1.p2.6.m6.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.3" xref="S3.SS1.p2.6.m6.2.2.3.cmml">{</mo><msub id="S3.SS1.p2.6.m6.1.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m6.1.1.1.1.2" xref="S3.SS1.p2.6.m6.1.1.1.1.2.cmml">𝒫</mi><mi id="S3.SS1.p2.6.m6.1.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p2.6.m6.2.2.2.4" xref="S3.SS1.p2.6.m6.2.2.3.cmml">,</mo><msub id="S3.SS1.p2.6.m6.2.2.2.2" xref="S3.SS1.p2.6.m6.2.2.2.2.cmml"><mi id="S3.SS1.p2.6.m6.2.2.2.2.2" xref="S3.SS1.p2.6.m6.2.2.2.2.2.cmml">φ</mi><mi id="S3.SS1.p2.6.m6.2.2.2.2.3" xref="S3.SS1.p2.6.m6.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p2.6.m6.2.2.2.5" xref="S3.SS1.p2.6.m6.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.2b"><set id="S3.SS1.p2.6.m6.2.2.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2"><apply id="S3.SS1.p2.6.m6.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.2">𝒫</ci><ci id="S3.SS1.p2.6.m6.1.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.p2.6.m6.2.2.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.2.2.2.2.1.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.6.m6.2.2.2.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.2">𝜑</ci><ci id="S3.SS1.p2.6.m6.2.2.2.2.3.cmml" xref="S3.SS1.p2.6.m6.2.2.2.2.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.2c">\{\mathcal{P}_{i},\varphi_{i}\}</annotation></semantics></math> are formulated.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.15" class="ltx_p"><span id="S3.SS1.p3.15.1" class="ltx_text ltx_font_bold">Controlled 2D image synthesis.</span>
With the pose image <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{P}_{i}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">𝒫</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝒫</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{P}_{i}</annotation></semantics></math>, we feed it into off-the-shelf ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> as the pose condition to guide diffusion models  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> to synthesize human images in desired poses (i.e., views).
The text prompt <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">T</annotation></semantics></math> is also used for diverse contents. Given a prompt <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">T</annotation></semantics></math>, instead of generating a human image <math id="S3.SS1.p3.4.m4.2" class="ltx_Math" alttext="\mathcal{I}_{s}:\mathcal{I}_{s}=\mathcal{C}(\mathcal{P}_{i},T)" display="inline"><semantics id="S3.SS1.p3.4.m4.2a"><mrow id="S3.SS1.p3.4.m4.2.2" xref="S3.SS1.p3.4.m4.2.2.cmml"><msub id="S3.SS1.p3.4.m4.2.2.3" xref="S3.SS1.p3.4.m4.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.2.2.3.2" xref="S3.SS1.p3.4.m4.2.2.3.2.cmml">ℐ</mi><mi id="S3.SS1.p3.4.m4.2.2.3.3" xref="S3.SS1.p3.4.m4.2.2.3.3.cmml">s</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p3.4.m4.2.2.2" xref="S3.SS1.p3.4.m4.2.2.2.cmml">:</mo><mrow id="S3.SS1.p3.4.m4.2.2.1" xref="S3.SS1.p3.4.m4.2.2.1.cmml"><msub id="S3.SS1.p3.4.m4.2.2.1.3" xref="S3.SS1.p3.4.m4.2.2.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.2.2.1.3.2" xref="S3.SS1.p3.4.m4.2.2.1.3.2.cmml">ℐ</mi><mi id="S3.SS1.p3.4.m4.2.2.1.3.3" xref="S3.SS1.p3.4.m4.2.2.1.3.3.cmml">s</mi></msub><mo id="S3.SS1.p3.4.m4.2.2.1.2" xref="S3.SS1.p3.4.m4.2.2.1.2.cmml">=</mo><mrow id="S3.SS1.p3.4.m4.2.2.1.1" xref="S3.SS1.p3.4.m4.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.2.2.1.1.3" xref="S3.SS1.p3.4.m4.2.2.1.1.3.cmml">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.4.m4.2.2.1.1.2" xref="S3.SS1.p3.4.m4.2.2.1.1.2.cmml">​</mo><mrow id="S3.SS1.p3.4.m4.2.2.1.1.1.1" xref="S3.SS1.p3.4.m4.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p3.4.m4.2.2.1.1.1.1.2" xref="S3.SS1.p3.4.m4.2.2.1.1.1.2.cmml">(</mo><msub id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.2" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.2.cmml">𝒫</mi><mi id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.3" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p3.4.m4.2.2.1.1.1.1.3" xref="S3.SS1.p3.4.m4.2.2.1.1.1.2.cmml">,</mo><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">T</mi><mo stretchy="false" id="S3.SS1.p3.4.m4.2.2.1.1.1.1.4" xref="S3.SS1.p3.4.m4.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.2b"><apply id="S3.SS1.p3.4.m4.2.2.cmml" xref="S3.SS1.p3.4.m4.2.2"><ci id="S3.SS1.p3.4.m4.2.2.2.cmml" xref="S3.SS1.p3.4.m4.2.2.2">:</ci><apply id="S3.SS1.p3.4.m4.2.2.3.cmml" xref="S3.SS1.p3.4.m4.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.2.2.3.1.cmml" xref="S3.SS1.p3.4.m4.2.2.3">subscript</csymbol><ci id="S3.SS1.p3.4.m4.2.2.3.2.cmml" xref="S3.SS1.p3.4.m4.2.2.3.2">ℐ</ci><ci id="S3.SS1.p3.4.m4.2.2.3.3.cmml" xref="S3.SS1.p3.4.m4.2.2.3.3">𝑠</ci></apply><apply id="S3.SS1.p3.4.m4.2.2.1.cmml" xref="S3.SS1.p3.4.m4.2.2.1"><eq id="S3.SS1.p3.4.m4.2.2.1.2.cmml" xref="S3.SS1.p3.4.m4.2.2.1.2"></eq><apply id="S3.SS1.p3.4.m4.2.2.1.3.cmml" xref="S3.SS1.p3.4.m4.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.2.2.1.3.1.cmml" xref="S3.SS1.p3.4.m4.2.2.1.3">subscript</csymbol><ci id="S3.SS1.p3.4.m4.2.2.1.3.2.cmml" xref="S3.SS1.p3.4.m4.2.2.1.3.2">ℐ</ci><ci id="S3.SS1.p3.4.m4.2.2.1.3.3.cmml" xref="S3.SS1.p3.4.m4.2.2.1.3.3">𝑠</ci></apply><apply id="S3.SS1.p3.4.m4.2.2.1.1.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1"><times id="S3.SS1.p3.4.m4.2.2.1.1.2.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.2"></times><ci id="S3.SS1.p3.4.m4.2.2.1.1.3.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.3">𝒞</ci><interval closure="open" id="S3.SS1.p3.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1"><apply id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.2">𝒫</ci><ci id="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.4.m4.2.2.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝑇</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.2c">\mathcal{I}_{s}:\mathcal{I}_{s}=\mathcal{C}(\mathcal{P}_{i},T)</annotation></semantics></math> independently for each view <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="\varphi_{i}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">φ</mi><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">𝜑</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\varphi_{i}</annotation></semantics></math>, we horizontally concatenate <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">\mathcal{K}</annotation></semantics></math> pose images <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="\mathcal{P}_{i}\in R^{H\times W\times 3}" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><mrow id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml"><msub id="S3.SS1.p3.7.m7.1.1.2" xref="S3.SS1.p3.7.m7.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.7.m7.1.1.2.2" xref="S3.SS1.p3.7.m7.1.1.2.2.cmml">𝒫</mi><mi id="S3.SS1.p3.7.m7.1.1.2.3" xref="S3.SS1.p3.7.m7.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p3.7.m7.1.1.1" xref="S3.SS1.p3.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.7.m7.1.1.3" xref="S3.SS1.p3.7.m7.1.1.3.cmml"><mi id="S3.SS1.p3.7.m7.1.1.3.2" xref="S3.SS1.p3.7.m7.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p3.7.m7.1.1.3.3" xref="S3.SS1.p3.7.m7.1.1.3.3.cmml"><mi id="S3.SS1.p3.7.m7.1.1.3.3.2" xref="S3.SS1.p3.7.m7.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.7.m7.1.1.3.3.1" xref="S3.SS1.p3.7.m7.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p3.7.m7.1.1.3.3.3" xref="S3.SS1.p3.7.m7.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.7.m7.1.1.3.3.1a" xref="S3.SS1.p3.7.m7.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p3.7.m7.1.1.3.3.4" xref="S3.SS1.p3.7.m7.1.1.3.3.4.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><apply id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1"><in id="S3.SS1.p3.7.m7.1.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1.1"></in><apply id="S3.SS1.p3.7.m7.1.1.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.1.1.2.1.cmml" xref="S3.SS1.p3.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.7.m7.1.1.2.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2.2">𝒫</ci><ci id="S3.SS1.p3.7.m7.1.1.2.3.cmml" xref="S3.SS1.p3.7.m7.1.1.2.3">𝑖</ci></apply><apply id="S3.SS1.p3.7.m7.1.1.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.1.1.3.1.cmml" xref="S3.SS1.p3.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.7.m7.1.1.3.2.cmml" xref="S3.SS1.p3.7.m7.1.1.3.2">𝑅</ci><apply id="S3.SS1.p3.7.m7.1.1.3.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3.3"><times id="S3.SS1.p3.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p3.7.m7.1.1.3.3.1"></times><ci id="S3.SS1.p3.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p3.7.m7.1.1.3.3.2">𝐻</ci><ci id="S3.SS1.p3.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3.3.3">𝑊</ci><cn type="integer" id="S3.SS1.p3.7.m7.1.1.3.3.4.cmml" xref="S3.SS1.p3.7.m7.1.1.3.3.4">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">\mathcal{P}_{i}\in R^{H\times W\times 3}</annotation></semantics></math>, resulting in <math id="S3.SS1.p3.8.m8.1" class="ltx_Math" alttext="\mathcal{P}_{i}^{\prime}\in R^{H\times KW\times 3}" display="inline"><semantics id="S3.SS1.p3.8.m8.1a"><mrow id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml"><msubsup id="S3.SS1.p3.8.m8.1.1.2" xref="S3.SS1.p3.8.m8.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.8.m8.1.1.2.2.2" xref="S3.SS1.p3.8.m8.1.1.2.2.2.cmml">𝒫</mi><mi id="S3.SS1.p3.8.m8.1.1.2.2.3" xref="S3.SS1.p3.8.m8.1.1.2.2.3.cmml">i</mi><mo id="S3.SS1.p3.8.m8.1.1.2.3" xref="S3.SS1.p3.8.m8.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.SS1.p3.8.m8.1.1.1" xref="S3.SS1.p3.8.m8.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.8.m8.1.1.3" xref="S3.SS1.p3.8.m8.1.1.3.cmml"><mi id="S3.SS1.p3.8.m8.1.1.3.2" xref="S3.SS1.p3.8.m8.1.1.3.2.cmml">R</mi><mrow id="S3.SS1.p3.8.m8.1.1.3.3" xref="S3.SS1.p3.8.m8.1.1.3.3.cmml"><mrow id="S3.SS1.p3.8.m8.1.1.3.3.2" xref="S3.SS1.p3.8.m8.1.1.3.3.2.cmml"><mrow id="S3.SS1.p3.8.m8.1.1.3.3.2.2" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.cmml"><mi id="S3.SS1.p3.8.m8.1.1.3.3.2.2.2" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.8.m8.1.1.3.3.2.2.1" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.1.cmml">×</mo><mi id="S3.SS1.p3.8.m8.1.1.3.3.2.2.3" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.3.cmml">K</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.1.1.3.3.2.1" xref="S3.SS1.p3.8.m8.1.1.3.3.2.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.1.1.3.3.2.3" xref="S3.SS1.p3.8.m8.1.1.3.3.2.3.cmml">W</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.8.m8.1.1.3.3.1" xref="S3.SS1.p3.8.m8.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p3.8.m8.1.1.3.3.3" xref="S3.SS1.p3.8.m8.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><apply id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1"><in id="S3.SS1.p3.8.m8.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1"></in><apply id="S3.SS1.p3.8.m8.1.1.2.cmml" xref="S3.SS1.p3.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.2">superscript</csymbol><apply id="S3.SS1.p3.8.m8.1.1.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.2.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.8.m8.1.1.2.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.2.2.2">𝒫</ci><ci id="S3.SS1.p3.8.m8.1.1.2.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.2.2.3">𝑖</ci></apply><ci id="S3.SS1.p3.8.m8.1.1.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.2.3">′</ci></apply><apply id="S3.SS1.p3.8.m8.1.1.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.3.1.cmml" xref="S3.SS1.p3.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.8.m8.1.1.3.2.cmml" xref="S3.SS1.p3.8.m8.1.1.3.2">𝑅</ci><apply id="S3.SS1.p3.8.m8.1.1.3.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3"><times id="S3.SS1.p3.8.m8.1.1.3.3.1.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.1"></times><apply id="S3.SS1.p3.8.m8.1.1.3.3.2.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2"><times id="S3.SS1.p3.8.m8.1.1.3.3.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.1"></times><apply id="S3.SS1.p3.8.m8.1.1.3.3.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2"><times id="S3.SS1.p3.8.m8.1.1.3.3.2.2.1.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.1"></times><ci id="S3.SS1.p3.8.m8.1.1.3.3.2.2.2.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.2">𝐻</ci><ci id="S3.SS1.p3.8.m8.1.1.3.3.2.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.2.3">𝐾</ci></apply><ci id="S3.SS1.p3.8.m8.1.1.3.3.2.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.2.3">𝑊</ci></apply><cn type="integer" id="S3.SS1.p3.8.m8.1.1.3.3.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">\mathcal{P}_{i}^{\prime}\in R^{H\times KW\times 3}</annotation></semantics></math> and feed <math id="S3.SS1.p3.9.m9.1" class="ltx_Math" alttext="\mathcal{P}_{i}’" display="inline"><semantics id="S3.SS1.p3.9.m9.1a"><mrow id="S3.SS1.p3.9.m9.1.1" xref="S3.SS1.p3.9.m9.1.1.cmml"><msub id="S3.SS1.p3.9.m9.1.1.2" xref="S3.SS1.p3.9.m9.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.9.m9.1.1.2.2" xref="S3.SS1.p3.9.m9.1.1.2.2.cmml">𝒫</mi><mi id="S3.SS1.p3.9.m9.1.1.2.3" xref="S3.SS1.p3.9.m9.1.1.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p3.9.m9.1.1.1" xref="S3.SS1.p3.9.m9.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.p3.9.m9.1.1.3" xref="S3.SS1.p3.9.m9.1.1.3.cmml">’</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.1b"><apply id="S3.SS1.p3.9.m9.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1"><times id="S3.SS1.p3.9.m9.1.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1.1"></times><apply id="S3.SS1.p3.9.m9.1.1.2.cmml" xref="S3.SS1.p3.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.1.1.2.1.cmml" xref="S3.SS1.p3.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.9.m9.1.1.2.2.cmml" xref="S3.SS1.p3.9.m9.1.1.2.2">𝒫</ci><ci id="S3.SS1.p3.9.m9.1.1.2.3.cmml" xref="S3.SS1.p3.9.m9.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p3.9.m9.1.1.3.cmml" xref="S3.SS1.p3.9.m9.1.1.3">’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.1c">\mathcal{P}_{i}’</annotation></semantics></math> to <math id="S3.SS1.p3.10.m10.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS1.p3.10.m10.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.10.m10.1.1" xref="S3.SS1.p3.10.m10.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.10.m10.1b"><ci id="S3.SS1.p3.10.m10.1.1.cmml" xref="S3.SS1.p3.10.m10.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.10.m10.1c">\mathcal{C}</annotation></semantics></math>, along with a prompt hint of ‘multi-view’ in <math id="S3.SS1.p3.11.m11.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p3.11.m11.1a"><mi id="S3.SS1.p3.11.m11.1.1" xref="S3.SS1.p3.11.m11.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.11.m11.1b"><ci id="S3.SS1.p3.11.m11.1.1.cmml" xref="S3.SS1.p3.11.m11.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.11.m11.1c">T</annotation></semantics></math>. In this way, multi-view human images <math id="S3.SS1.p3.12.m12.1" class="ltx_Math" alttext="\mathcal{I}_{s}^{\prime}" display="inline"><semantics id="S3.SS1.p3.12.m12.1a"><msubsup id="S3.SS1.p3.12.m12.1.1" xref="S3.SS1.p3.12.m12.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.12.m12.1.1.2.2" xref="S3.SS1.p3.12.m12.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS1.p3.12.m12.1.1.2.3" xref="S3.SS1.p3.12.m12.1.1.2.3.cmml">s</mi><mo id="S3.SS1.p3.12.m12.1.1.3" xref="S3.SS1.p3.12.m12.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.12.m12.1b"><apply id="S3.SS1.p3.12.m12.1.1.cmml" xref="S3.SS1.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.12.m12.1.1.1.cmml" xref="S3.SS1.p3.12.m12.1.1">superscript</csymbol><apply id="S3.SS1.p3.12.m12.1.1.2.cmml" xref="S3.SS1.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.12.m12.1.1.2.1.cmml" xref="S3.SS1.p3.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p3.12.m12.1.1.2.2.cmml" xref="S3.SS1.p3.12.m12.1.1.2.2">ℐ</ci><ci id="S3.SS1.p3.12.m12.1.1.2.3.cmml" xref="S3.SS1.p3.12.m12.1.1.2.3">𝑠</ci></apply><ci id="S3.SS1.p3.12.m12.1.1.3.cmml" xref="S3.SS1.p3.12.m12.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.12.m12.1c">\mathcal{I}_{s}^{\prime}</annotation></semantics></math> are synthesized with roughly coherent appearance. We split <math id="S3.SS1.p3.13.m13.1" class="ltx_Math" alttext="\mathcal{I}_{s}^{\prime}" display="inline"><semantics id="S3.SS1.p3.13.m13.1a"><msubsup id="S3.SS1.p3.13.m13.1.1" xref="S3.SS1.p3.13.m13.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.13.m13.1.1.2.2" xref="S3.SS1.p3.13.m13.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS1.p3.13.m13.1.1.2.3" xref="S3.SS1.p3.13.m13.1.1.2.3.cmml">s</mi><mo id="S3.SS1.p3.13.m13.1.1.3" xref="S3.SS1.p3.13.m13.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.13.m13.1b"><apply id="S3.SS1.p3.13.m13.1.1.cmml" xref="S3.SS1.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.13.m13.1.1.1.cmml" xref="S3.SS1.p3.13.m13.1.1">superscript</csymbol><apply id="S3.SS1.p3.13.m13.1.1.2.cmml" xref="S3.SS1.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.13.m13.1.1.2.1.cmml" xref="S3.SS1.p3.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.p3.13.m13.1.1.2.2.cmml" xref="S3.SS1.p3.13.m13.1.1.2.2">ℐ</ci><ci id="S3.SS1.p3.13.m13.1.1.2.3.cmml" xref="S3.SS1.p3.13.m13.1.1.2.3">𝑠</ci></apply><ci id="S3.SS1.p3.13.m13.1.1.3.cmml" xref="S3.SS1.p3.13.m13.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.13.m13.1c">\mathcal{I}_{s}^{\prime}</annotation></semantics></math> to single view images <math id="S3.SS1.p3.14.m14.1" class="ltx_Math" alttext="\mathcal{I}_{\varphi}" display="inline"><semantics id="S3.SS1.p3.14.m14.1a"><msub id="S3.SS1.p3.14.m14.1.1" xref="S3.SS1.p3.14.m14.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.14.m14.1.1.2" xref="S3.SS1.p3.14.m14.1.1.2.cmml">ℐ</mi><mi id="S3.SS1.p3.14.m14.1.1.3" xref="S3.SS1.p3.14.m14.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.14.m14.1b"><apply id="S3.SS1.p3.14.m14.1.1.cmml" xref="S3.SS1.p3.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.14.m14.1.1.1.cmml" xref="S3.SS1.p3.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p3.14.m14.1.1.2.cmml" xref="S3.SS1.p3.14.m14.1.1.2">ℐ</ci><ci id="S3.SS1.p3.14.m14.1.1.3.cmml" xref="S3.SS1.p3.14.m14.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.14.m14.1c">\mathcal{I}_{\varphi}</annotation></semantics></math> under specific views <math id="S3.SS1.p3.15.m15.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS1.p3.15.m15.1a"><mi id="S3.SS1.p3.15.m15.1.1" xref="S3.SS1.p3.15.m15.1.1.cmml">φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.15.m15.1b"><ci id="S3.SS1.p3.15.m15.1.1.cmml" xref="S3.SS1.p3.15.m15.1.1">𝜑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.15.m15.1c">\varphi</annotation></semantics></math>.
This concatenation strategy facilitates the convergence of distributions in synthetic multi-views, thus easing the learning of common 3D representation meeting multi-view characteristics.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.4" class="ltx_p"><span id="S3.SS1.p4.4.1" class="ltx_text ltx_font_bold">Generalizable 3D representation learning.</span>
With synthetic data of paired <math id="S3.SS1.p4.1.m1.2" class="ltx_Math" alttext="\{\mathcal{I}_{\varphi},\varphi\}" display="inline"><semantics id="S3.SS1.p4.1.m1.2a"><mrow id="S3.SS1.p4.1.m1.2.2.1" xref="S3.SS1.p4.1.m1.2.2.2.cmml"><mo stretchy="false" id="S3.SS1.p4.1.m1.2.2.1.2" xref="S3.SS1.p4.1.m1.2.2.2.cmml">{</mo><msub id="S3.SS1.p4.1.m1.2.2.1.1" xref="S3.SS1.p4.1.m1.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.1.m1.2.2.1.1.2" xref="S3.SS1.p4.1.m1.2.2.1.1.2.cmml">ℐ</mi><mi id="S3.SS1.p4.1.m1.2.2.1.1.3" xref="S3.SS1.p4.1.m1.2.2.1.1.3.cmml">φ</mi></msub><mo id="S3.SS1.p4.1.m1.2.2.1.3" xref="S3.SS1.p4.1.m1.2.2.2.cmml">,</mo><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">φ</mi><mo stretchy="false" id="S3.SS1.p4.1.m1.2.2.1.4" xref="S3.SS1.p4.1.m1.2.2.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.2b"><set id="S3.SS1.p4.1.m1.2.2.2.cmml" xref="S3.SS1.p4.1.m1.2.2.1"><apply id="S3.SS1.p4.1.m1.2.2.1.1.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1.2">ℐ</ci><ci id="S3.SS1.p4.1.m1.2.2.1.1.3.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1.3">𝜑</ci></apply><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝜑</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.2c">\{\mathcal{I}_{\varphi},\varphi\}</annotation></semantics></math>, we learn the 3D generative module <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{G}_{3d}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><msub id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">𝒢</mi><mrow id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml"><mn id="S3.SS1.p4.2.m2.1.1.3.2" xref="S3.SS1.p4.2.m2.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p4.2.m2.1.1.3.1" xref="S3.SS1.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p4.2.m2.1.1.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">𝒢</ci><apply id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3"><times id="S3.SS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3.1"></times><cn type="integer" id="S3.SS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.2">3</cn><ci id="S3.SS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\mathcal{G}_{3d}</annotation></semantics></math> from them to produce diverse 3D-aware human images with realistic appearance.
Inspired by EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>,
we employ a triplane-based generator to produce a generalizable representation <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">\mathcal{T}</annotation></semantics></math> and introduce a patch-composed neural renderer to learn intricate human representation efficiently.
Specifically, instead of uniformly sampling 2D pixels on the image <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathcal{I}</annotation></semantics></math>, we decompose patches in the ROI region including human bodies, and only emit rays towards pixels in these patches.
The rays are rendered into RGB color with opacity values via volume rendering.
Based on the decomposed rule, we decode rendered colors to multiple patches and re-combine these patches for full feature images.
In this way, the representation is composed of effective human body parts, which directs the attention of the networks towards the human subject itself.
This design facilitates fine-grained local human learning while maintaining computational efficiency.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">For the training process, we employ two discriminators, one for RGB images and another for silhouettes, which yields better disentanglement of foreground objects with global geometry.
The training loss for this module <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="L_{3d}" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><msub id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml">L</mi><mrow id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml"><mn id="S3.SS1.p5.1.m1.1.1.3.2" xref="S3.SS1.p5.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p5.1.m1.1.1.3.1" xref="S3.SS1.p5.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p5.1.m1.1.1.3.3" xref="S3.SS1.p5.1.m1.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2">𝐿</ci><apply id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3"><times id="S3.SS1.p5.1.m1.1.1.3.1.cmml" xref="S3.SS1.p5.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS1.p5.1.m1.1.1.3.2.cmml" xref="S3.SS1.p5.1.m1.1.1.3.2">3</cn><ci id="S3.SS1.p5.1.m1.1.1.3.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">L_{3d}</annotation></semantics></math> consists of the two adversarial terms:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{3d}=\mathcal{L}_{adv}(\mathcal{D}_{rgb},\mathcal{G}_{3d})+\lambda_{s}\mathcal{L}_{adv}(\mathcal{D}_{mask},\mathcal{G}_{3d})," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.6" xref="S3.E1.m1.1.1.1.1.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.6.2" xref="S3.E1.m1.1.1.1.1.6.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.6.3" xref="S3.E1.m1.1.1.1.1.6.3.cmml"><mn id="S3.E1.m1.1.1.1.1.6.3.2" xref="S3.E1.m1.1.1.1.1.6.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.6.3.1" xref="S3.E1.m1.1.1.1.1.6.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.6.3.3" xref="S3.E1.m1.1.1.1.1.6.3.3.cmml">d</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mrow id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml"><msub id="S3.E1.m1.1.1.1.1.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.2.4.2" xref="S3.E1.m1.1.1.1.1.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.2.2.4.3" xref="S3.E1.m1.1.1.1.1.2.2.4.3.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.4.3.2" xref="S3.E1.m1.1.1.1.1.2.2.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.2.4.3.1" xref="S3.E1.m1.1.1.1.1.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.2.4.3.3" xref="S3.E1.m1.1.1.1.1.2.2.4.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.2.4.3.1a" xref="S3.E1.m1.1.1.1.1.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.2.4.3.4" xref="S3.E1.m1.1.1.1.1.2.2.4.3.4.cmml">v</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">​</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.4.cmml">b</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">,</mo><msub id="S3.E1.m1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml">𝒢</mi><mrow id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml"><mn id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.1" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.3.cmml">d</mi></mrow></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.2.5" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.4.5" xref="S3.E1.m1.1.1.1.1.4.5.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.4.4" xref="S3.E1.m1.1.1.1.1.4.4.cmml"><msub id="S3.E1.m1.1.1.1.1.4.4.4" xref="S3.E1.m1.1.1.1.1.4.4.4.cmml"><mi id="S3.E1.m1.1.1.1.1.4.4.4.2" xref="S3.E1.m1.1.1.1.1.4.4.4.2.cmml">λ</mi><mi id="S3.E1.m1.1.1.1.1.4.4.4.3" xref="S3.E1.m1.1.1.1.1.4.4.4.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.4.3" xref="S3.E1.m1.1.1.1.1.4.4.3.cmml">​</mo><msub id="S3.E1.m1.1.1.1.1.4.4.5" xref="S3.E1.m1.1.1.1.1.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.4.5.2" xref="S3.E1.m1.1.1.1.1.4.4.5.2.cmml">ℒ</mi><mrow id="S3.E1.m1.1.1.1.1.4.4.5.3" xref="S3.E1.m1.1.1.1.1.4.4.5.3.cmml"><mi id="S3.E1.m1.1.1.1.1.4.4.5.3.2" xref="S3.E1.m1.1.1.1.1.4.4.5.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.4.5.3.1" xref="S3.E1.m1.1.1.1.1.4.4.5.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.4.4.5.3.3" xref="S3.E1.m1.1.1.1.1.4.4.5.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.4.5.3.1a" xref="S3.E1.m1.1.1.1.1.4.4.5.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.4.4.5.3.4" xref="S3.E1.m1.1.1.1.1.4.4.5.3.4.cmml">v</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.4.3a" xref="S3.E1.m1.1.1.1.1.4.4.3.cmml">​</mo><mrow id="S3.E1.m1.1.1.1.1.4.4.2.2" xref="S3.E1.m1.1.1.1.1.4.4.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.4.4.2.2.3" xref="S3.E1.m1.1.1.1.1.4.4.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.3.3.1.1.1" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.cmml">𝒟</mi><mrow id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1a" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1b" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.5" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.5.cmml">k</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.4.4.2.2.4" xref="S3.E1.m1.1.1.1.1.4.4.2.3.cmml">,</mo><msub id="S3.E1.m1.1.1.1.1.4.4.2.2.2" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.4.2.2.2.2" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.2.cmml">𝒢</mi><mrow id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.cmml"><mn id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.2" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.1" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.3" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.3.cmml">d</mi></mrow></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.4.4.2.2.5" xref="S3.E1.m1.1.1.1.1.4.4.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5"></eq><apply id="S3.E1.m1.1.1.1.1.6.cmml" xref="S3.E1.m1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.6.1.cmml" xref="S3.E1.m1.1.1.1.1.6">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.6.2.cmml" xref="S3.E1.m1.1.1.1.1.6.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.6.3.cmml" xref="S3.E1.m1.1.1.1.1.6.3"><times id="S3.E1.m1.1.1.1.1.6.3.1.cmml" xref="S3.E1.m1.1.1.1.1.6.3.1"></times><cn type="integer" id="S3.E1.m1.1.1.1.1.6.3.2.cmml" xref="S3.E1.m1.1.1.1.1.6.3.2">3</cn><ci id="S3.E1.m1.1.1.1.1.6.3.3.cmml" xref="S3.E1.m1.1.1.1.1.6.3.3">𝑑</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><plus id="S3.E1.m1.1.1.1.1.4.5.cmml" xref="S3.E1.m1.1.1.1.1.4.5"></plus><apply id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2"><times id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3"></times><apply id="S3.E1.m1.1.1.1.1.2.2.4.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.4.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.4.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.2.2.4.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.3"><times id="S3.E1.m1.1.1.1.1.2.2.4.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.3.1"></times><ci id="S3.E1.m1.1.1.1.1.2.2.4.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.3.2">𝑎</ci><ci id="S3.E1.m1.1.1.1.1.2.2.4.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.3.3">𝑑</ci><ci id="S3.E1.m1.1.1.1.1.2.2.4.3.4.cmml" xref="S3.E1.m1.1.1.1.1.2.2.4.3.4">𝑣</ci></apply></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2">𝒟</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.2">𝑟</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.3">𝑔</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.4">𝑏</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2">𝒢</ci><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3"><times id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.1"></times><cn type="integer" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.2">3</cn><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.3">𝑑</ci></apply></apply></interval></apply><apply id="S3.E1.m1.1.1.1.1.4.4.cmml" xref="S3.E1.m1.1.1.1.1.4.4"><times id="S3.E1.m1.1.1.1.1.4.4.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.3"></times><apply id="S3.E1.m1.1.1.1.1.4.4.4.cmml" xref="S3.E1.m1.1.1.1.1.4.4.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.4.4.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.4.4.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.4.2">𝜆</ci><ci id="S3.E1.m1.1.1.1.1.4.4.4.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.4.3">𝑠</ci></apply><apply id="S3.E1.m1.1.1.1.1.4.4.5.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.4.5.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.4.5.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.2">ℒ</ci><apply id="S3.E1.m1.1.1.1.1.4.4.5.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.3"><times id="S3.E1.m1.1.1.1.1.4.4.5.3.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.3.1"></times><ci id="S3.E1.m1.1.1.1.1.4.4.5.3.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.3.2">𝑎</ci><ci id="S3.E1.m1.1.1.1.1.4.4.5.3.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.3.3">𝑑</ci><ci id="S3.E1.m1.1.1.1.1.4.4.5.3.4.cmml" xref="S3.E1.m1.1.1.1.1.4.4.5.3.4">𝑣</ci></apply></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.4.4.2.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2"><apply id="S3.E1.m1.1.1.1.1.3.3.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2">𝒟</ci><apply id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.2">𝑚</ci><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.3">𝑎</ci><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.4">𝑠</ci><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.5.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.5">𝑘</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.4.4.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.4.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.4.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.2">𝒢</ci><apply id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3"><times id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.1"></times><cn type="integer" id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.2">3</cn><ci id="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.2.2.3.3">𝑑</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}_{3d}=\mathcal{L}_{adv}(\mathcal{D}_{rgb},\mathcal{G}_{3d})+\lambda_{s}\mathcal{L}_{adv}(\mathcal{D}_{mask},\mathcal{G}_{3d}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p5.3" class="ltx_p">where <math id="S3.SS1.p5.2.m1.1" class="ltx_Math" alttext="\lambda_{s}" display="inline"><semantics id="S3.SS1.p5.2.m1.1a"><msub id="S3.SS1.p5.2.m1.1.1" xref="S3.SS1.p5.2.m1.1.1.cmml"><mi id="S3.SS1.p5.2.m1.1.1.2" xref="S3.SS1.p5.2.m1.1.1.2.cmml">λ</mi><mi id="S3.SS1.p5.2.m1.1.1.3" xref="S3.SS1.p5.2.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m1.1b"><apply id="S3.SS1.p5.2.m1.1.1.cmml" xref="S3.SS1.p5.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m1.1.1.1.cmml" xref="S3.SS1.p5.2.m1.1.1">subscript</csymbol><ci id="S3.SS1.p5.2.m1.1.1.2.cmml" xref="S3.SS1.p5.2.m1.1.1.2">𝜆</ci><ci id="S3.SS1.p5.2.m1.1.1.3.cmml" xref="S3.SS1.p5.2.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m1.1c">\lambda_{s}</annotation></semantics></math> denotes the weight of silhouette item. <math id="S3.SS1.p5.3.m2.1" class="ltx_Math" alttext="\mathcal{L}_{adv}" display="inline"><semantics id="S3.SS1.p5.3.m2.1a"><msub id="S3.SS1.p5.3.m2.1.1" xref="S3.SS1.p5.3.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.3.m2.1.1.2" xref="S3.SS1.p5.3.m2.1.1.2.cmml">ℒ</mi><mrow id="S3.SS1.p5.3.m2.1.1.3" xref="S3.SS1.p5.3.m2.1.1.3.cmml"><mi id="S3.SS1.p5.3.m2.1.1.3.2" xref="S3.SS1.p5.3.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.3.m2.1.1.3.1" xref="S3.SS1.p5.3.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p5.3.m2.1.1.3.3" xref="S3.SS1.p5.3.m2.1.1.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.3.m2.1.1.3.1a" xref="S3.SS1.p5.3.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p5.3.m2.1.1.3.4" xref="S3.SS1.p5.3.m2.1.1.3.4.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m2.1b"><apply id="S3.SS1.p5.3.m2.1.1.cmml" xref="S3.SS1.p5.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m2.1.1.1.cmml" xref="S3.SS1.p5.3.m2.1.1">subscript</csymbol><ci id="S3.SS1.p5.3.m2.1.1.2.cmml" xref="S3.SS1.p5.3.m2.1.1.2">ℒ</ci><apply id="S3.SS1.p5.3.m2.1.1.3.cmml" xref="S3.SS1.p5.3.m2.1.1.3"><times id="S3.SS1.p5.3.m2.1.1.3.1.cmml" xref="S3.SS1.p5.3.m2.1.1.3.1"></times><ci id="S3.SS1.p5.3.m2.1.1.3.2.cmml" xref="S3.SS1.p5.3.m2.1.1.3.2">𝑎</ci><ci id="S3.SS1.p5.3.m2.1.1.3.3.cmml" xref="S3.SS1.p5.3.m2.1.1.3.3">𝑑</ci><ci id="S3.SS1.p5.3.m2.1.1.3.4.cmml" xref="S3.SS1.p5.3.m2.1.1.3.4">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m2.1c">\mathcal{L}_{adv}</annotation></semantics></math> is computed by the non-saturating GAN loss with R1 regularization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.3" class="ltx_p">With the trained <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="\mathcal{G}_{3d}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><msub id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">𝒢</mi><mrow id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml"><mn id="S3.SS1.p6.1.m1.1.1.3.2" xref="S3.SS1.p6.1.m1.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p6.1.m1.1.1.3.1" xref="S3.SS1.p6.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p6.1.m1.1.1.3.3" xref="S3.SS1.p6.1.m1.1.1.3.3.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">𝒢</ci><apply id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3"><times id="S3.SS1.p6.1.m1.1.1.3.1.cmml" xref="S3.SS1.p6.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS1.p6.1.m1.1.1.3.2.cmml" xref="S3.SS1.p6.1.m1.1.1.3.2">3</cn><ci id="S3.SS1.p6.1.m1.1.1.3.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">\mathcal{G}_{3d}</annotation></semantics></math>, we can synthesize 3D-aware human images <math id="S3.SS1.p6.2.m2.1" class="ltx_Math" alttext="\mathcal{I}_{g}^{\varphi}" display="inline"><semantics id="S3.SS1.p6.2.m2.1a"><msubsup id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.2.m2.1.1.2.2" xref="S3.SS1.p6.2.m2.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS1.p6.2.m2.1.1.2.3" xref="S3.SS1.p6.2.m2.1.1.2.3.cmml">g</mi><mi id="S3.SS1.p6.2.m2.1.1.3" xref="S3.SS1.p6.2.m2.1.1.3.cmml">φ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><apply id="S3.SS1.p6.2.m2.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p6.2.m2.1.1.2.cmml" xref="S3.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.2.1.cmml" xref="S3.SS1.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p6.2.m2.1.1.2.2.cmml" xref="S3.SS1.p6.2.m2.1.1.2.2">ℐ</ci><ci id="S3.SS1.p6.2.m2.1.1.2.3.cmml" xref="S3.SS1.p6.2.m2.1.1.2.3">𝑔</ci></apply><ci id="S3.SS1.p6.2.m2.1.1.3.cmml" xref="S3.SS1.p6.2.m2.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.1c">\mathcal{I}_{g}^{\varphi}</annotation></semantics></math> with view control, and extract coarse 3D shapes <math id="S3.SS1.p6.3.m3.1" class="ltx_Math" alttext="\mathcal{M}_{c}" display="inline"><semantics id="S3.SS1.p6.3.m3.1a"><msub id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.3.m3.1.1.2" xref="S3.SS1.p6.3.m3.1.1.2.cmml">ℳ</mi><mi id="S3.SS1.p6.3.m3.1.1.3" xref="S3.SS1.p6.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><apply id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.3.m3.1.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p6.3.m3.1.1.2.cmml" xref="S3.SS1.p6.3.m3.1.1.2">ℳ</ci><ci id="S3.SS1.p6.3.m3.1.1.3.cmml" xref="S3.SS1.p6.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">\mathcal{M}_{c}</annotation></semantics></math> from the density field of neural renderer using the Marching Cubes algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Geometric sculpting</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our 3D generative module can produce high-quality and 3D-consistent human images in view controls.
However, its training solely relies on discriminations made using 2D renderings, which can result in inaccuracies in capturing the inherent geometry, especially for complex human bodies.
Therefore, we integrate the geometric sculpting, an optimization module leveraging geometric information from high-quality multi-views to carve surface details. Combined with a hybrid 3D representation and a differentiable rasterizer, it can rapidly enhance the shape quality within seconds.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.12" class="ltx_p"><span id="S3.SS2.p2.12.1" class="ltx_text ltx_font_bold">DMTET adaption.</span> Owing to the expressive ability of arbitrary topologies and computational efficiency with direct shape optimization, we employ DMTET as our 3D representation in this module and adapt it to the coarse mesh <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{M}_{c}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">ℳ</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ℳ</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{M}_{c}</annotation></semantics></math> via an initial fitting procedure. Specifically, we parameterize DMTET as an MLP network <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\Psi_{g}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">Ψ</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">Ψ</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\Psi_{g}</annotation></semantics></math> that learns to predict the SDF value <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="s(v_{i})" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">​</mo><mrow id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p2.3.m3.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml">v</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p2.3.m3.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><times id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2"></times><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">𝑠</ci><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2">𝑣</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">s(v_{i})</annotation></semantics></math> and the position offset <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\delta v_{i}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mrow id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">​</mo><msub id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml">v</mi><mi id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><times id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1"></times><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">𝛿</ci><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2">𝑣</ci><ci id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\delta v_{i}</annotation></semantics></math> for each vertex <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="v_{i}\in VT" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mrow id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><msub id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2.2" xref="S3.SS2.p2.5.m5.1.1.2.2.cmml">v</mi><mi id="S3.SS2.p2.5.m5.1.1.2.3" xref="S3.SS2.p2.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p2.5.m5.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.cmml">∈</mo><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><in id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1"></in><apply id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2.2">𝑣</ci><ci id="S3.SS2.p2.5.m5.1.1.2.3.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3">𝑖</ci></apply><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><times id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1"></times><ci id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">𝑉</ci><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">v_{i}\in VT</annotation></semantics></math> of the tetrahedral grid <math id="S3.SS2.p2.6.m6.2" class="ltx_Math" alttext="(VT,T)" display="inline"><semantics id="S3.SS2.p2.6.m6.2a"><mrow id="S3.SS2.p2.6.m6.2.2.1" xref="S3.SS2.p2.6.m6.2.2.2.cmml"><mo stretchy="false" id="S3.SS2.p2.6.m6.2.2.1.2" xref="S3.SS2.p2.6.m6.2.2.2.cmml">(</mo><mrow id="S3.SS2.p2.6.m6.2.2.1.1" xref="S3.SS2.p2.6.m6.2.2.1.1.cmml"><mi id="S3.SS2.p2.6.m6.2.2.1.1.2" xref="S3.SS2.p2.6.m6.2.2.1.1.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.6.m6.2.2.1.1.1" xref="S3.SS2.p2.6.m6.2.2.1.1.1.cmml">​</mo><mi id="S3.SS2.p2.6.m6.2.2.1.1.3" xref="S3.SS2.p2.6.m6.2.2.1.1.3.cmml">T</mi></mrow><mo id="S3.SS2.p2.6.m6.2.2.1.3" xref="S3.SS2.p2.6.m6.2.2.2.cmml">,</mo><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">T</mi><mo stretchy="false" id="S3.SS2.p2.6.m6.2.2.1.4" xref="S3.SS2.p2.6.m6.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.2b"><interval closure="open" id="S3.SS2.p2.6.m6.2.2.2.cmml" xref="S3.SS2.p2.6.m6.2.2.1"><apply id="S3.SS2.p2.6.m6.2.2.1.1.cmml" xref="S3.SS2.p2.6.m6.2.2.1.1"><times id="S3.SS2.p2.6.m6.2.2.1.1.1.cmml" xref="S3.SS2.p2.6.m6.2.2.1.1.1"></times><ci id="S3.SS2.p2.6.m6.2.2.1.1.2.cmml" xref="S3.SS2.p2.6.m6.2.2.1.1.2">𝑉</ci><ci id="S3.SS2.p2.6.m6.2.2.1.1.3.cmml" xref="S3.SS2.p2.6.m6.2.2.1.1.3">𝑇</ci></apply><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑇</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.2c">(VT,T)</annotation></semantics></math>. A point set <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="P=\{p_{i}\in R^{3}\}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><mrow id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">P</mi><mo id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.7.m7.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.1.1.1.1.2" xref="S3.SS2.p2.7.m7.1.1.1.2.cmml">{</mo><mrow id="S3.SS2.p2.7.m7.1.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.1.1.cmml"><msub id="S3.SS2.p2.7.m7.1.1.1.1.1.2" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p2.7.m7.1.1.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p2.7.m7.1.1.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.2.cmml">R</mi><mn id="S3.SS2.p2.7.m7.1.1.1.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.3.cmml">3</mn></msup></mrow><mo stretchy="false" id="S3.SS2.p2.7.m7.1.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><eq id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2"></eq><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">𝑃</ci><set id="S3.SS2.p2.7.m7.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1"><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1"><in id="S3.SS2.p2.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1"></in><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.2">𝑝</ci><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.2">𝑅</ci><cn type="integer" id="S3.SS2.p2.7.m7.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.3.3">3</cn></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">P=\{p_{i}\in R^{3}\}</annotation></semantics></math> is randomly sampled near <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="\mathcal{M}_{c}" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><msub id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml">ℳ</mi><mi id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2">ℳ</ci><ci id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">\mathcal{M}_{c}</annotation></semantics></math> and their SDF values <math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="SDF(p_{i})" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><mrow id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.3" xref="S3.SS2.p2.9.m9.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.1.1.2" xref="S3.SS2.p2.9.m9.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.9.m9.1.1.4" xref="S3.SS2.p2.9.m9.1.1.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.1.1.2a" xref="S3.SS2.p2.9.m9.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.9.m9.1.1.5" xref="S3.SS2.p2.9.m9.1.1.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.1.1.2b" xref="S3.SS2.p2.9.m9.1.1.2.cmml">​</mo><mrow id="S3.SS2.p2.9.m9.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.9.m9.1.1.1.1.2" xref="S3.SS2.p2.9.m9.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p2.9.m9.1.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.1.1.1.2" xref="S3.SS2.p2.9.m9.1.1.1.1.1.2.cmml">p</mi><mi id="S3.SS2.p2.9.m9.1.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p2.9.m9.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><apply id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1"><times id="S3.SS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.2"></times><ci id="S3.SS2.p2.9.m9.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3">𝑆</ci><ci id="S3.SS2.p2.9.m9.1.1.4.cmml" xref="S3.SS2.p2.9.m9.1.1.4">𝐷</ci><ci id="S3.SS2.p2.9.m9.1.1.5.cmml" xref="S3.SS2.p2.9.m9.1.1.5">𝐹</ci><apply id="S3.SS2.p2.9.m9.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.2">𝑝</ci><ci id="S3.SS2.p2.9.m9.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">SDF(p_{i})</annotation></semantics></math> can be pre-computed. We adapt the parameters <math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><mi id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">\psi</annotation></semantics></math> of <math id="S3.SS2.p2.11.m11.1" class="ltx_Math" alttext="\Psi_{g}" display="inline"><semantics id="S3.SS2.p2.11.m11.1a"><msub id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p2.11.m11.1.1.2" xref="S3.SS2.p2.11.m11.1.1.2.cmml">Ψ</mi><mi id="S3.SS2.p2.11.m11.1.1.3" xref="S3.SS2.p2.11.m11.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2">Ψ</ci><ci id="S3.SS2.p2.11.m11.1.1.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">\Psi_{g}</annotation></semantics></math> by fitting it to the SDF of <math id="S3.SS2.p2.12.m12.1" class="ltx_Math" alttext="\mathcal{M}_{c}" display="inline"><semantics id="S3.SS2.p2.12.m12.1a"><msub id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.12.m12.1.1.2" xref="S3.SS2.p2.12.m12.1.1.2.cmml">ℳ</mi><mi id="S3.SS2.p2.12.m12.1.1.3" xref="S3.SS2.p2.12.m12.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><apply id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.2.cmml" xref="S3.SS2.p2.12.m12.1.1.2">ℳ</ci><ci id="S3.SS2.p2.12.m12.1.1.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">\mathcal{M}_{c}</annotation></semantics></math>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\mathcal{L}_{ada}=\sum_{p_{i}\in P}||s(p_{i};\psi)-SDF(p_{i})||_{2}." display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.2" xref="S3.E2.m1.2.2.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.1" xref="S3.E2.m1.2.2.1.1.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.3.3.3" xref="S3.E2.m1.2.2.1.1.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.1a" xref="S3.E2.m1.2.2.1.1.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.3.3.4" xref="S3.E2.m1.2.2.1.1.3.3.4.cmml">a</mi></mrow></msub><mo rspace="0.111em" id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><munder id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E2.m1.2.2.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.2.3.cmml"><msub id="S3.E2.m1.2.2.1.1.1.2.3.2" xref="S3.E2.m1.2.2.1.1.1.2.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.2.3.2.2" xref="S3.E2.m1.2.2.1.1.1.2.3.2.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.1.2.3.2.3" xref="S3.E2.m1.2.2.1.1.1.2.3.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.2.3.1" xref="S3.E2.m1.2.2.1.1.1.2.3.1.cmml">∈</mo><mi id="S3.E2.m1.2.2.1.1.1.2.3.3" xref="S3.E2.m1.2.2.1.1.1.2.3.3.cmml">P</mi></mrow></munder><msub id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">ψ</mi><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2a" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.5" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2b" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><mo lspace="0em" id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">ℒ</ci><apply id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3"><times id="S3.E2.m1.2.2.1.1.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2">𝑎</ci><ci id="S3.E2.m1.2.2.1.1.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3">𝑑</ci><ci id="S3.E2.m1.2.2.1.1.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.3.4">𝑎</ci></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><apply id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2.2"></sum><apply id="S3.E2.m1.2.2.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3"><in id="S3.E2.m1.2.2.1.1.1.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.1"></in><apply id="S3.E2.m1.2.2.1.1.1.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.2.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.2.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.2.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.1.2.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.2.3">𝑖</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.2.3.3">𝑃</ci></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3"></minus><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.3">𝑠</ci><list id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝜓</ci></list></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2"></times><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3">𝑆</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.4">𝐷</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.5.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.5">𝐹</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.1.1.1.3">𝑖</ci></apply></apply></apply></apply><cn type="integer" id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\mathcal{L}_{ada}=\sum_{p_{i}\in P}||s(p_{i};\psi)-SDF(p_{i})||_{2}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.10" class="ltx_p"><span id="S3.SS2.p3.10.1" class="ltx_text ltx_font_bold">Geometry refinement.</span>
Using the adapted DMTET, we leverage the highly-detailed normal maps <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathcal{N}</annotation></semantics></math> derived from realistic multi-view images as a guidance to refine local surfaces.
To obtain the pseudo-GT normals <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{N_{\varphi}}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">𝒩</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝒩</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathcal{N_{\varphi}}</annotation></semantics></math>, we extract them from <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{I}_{g}^{\varphi}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><msubsup id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.3.m3.1.1.2.2" xref="S3.SS2.p3.3.m3.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS2.p3.3.m3.1.1.2.3" xref="S3.SS2.p3.3.m3.1.1.2.3.cmml">g</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">φ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2.2">ℐ</ci><ci id="S3.SS2.p3.3.m3.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.1.1.2.3">𝑔</ci></apply><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathcal{I}_{g}^{\varphi}</annotation></semantics></math> using a pre-trained normal estimator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>.
For the rendered normals <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{\hat{N}_{\varphi}}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mover accent="true" id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.4.m4.1.1.2.2" xref="S3.SS2.p3.4.m4.1.1.2.2.cmml">𝒩</mi><mo id="S3.SS2.p3.4.m4.1.1.2.1" xref="S3.SS2.p3.4.m4.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2"><ci id="S3.SS2.p3.4.m4.1.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1.2.1">^</ci><ci id="S3.SS2.p3.4.m4.1.1.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2.2">𝒩</ci></apply><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathcal{\hat{N}_{\varphi}}</annotation></semantics></math>, we extract the triangular mesh <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><msub id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">ℳ</mi><mrow id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.1.1.3.1" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.1.1.3.1a" xref="S3.SS2.p3.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.1.1.3.4" xref="S3.SS2.p3.5.m5.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ℳ</ci><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><times id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.1"></times><ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">𝑡</ci><ci id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3">𝑟</ci><ci id="S3.SS2.p3.5.m5.1.1.3.4.cmml" xref="S3.SS2.p3.5.m5.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathcal{M}_{tri}</annotation></semantics></math> from <math id="S3.SS2.p3.6.m6.2" class="ltx_Math" alttext="(VT,T)" display="inline"><semantics id="S3.SS2.p3.6.m6.2a"><mrow id="S3.SS2.p3.6.m6.2.2.1" xref="S3.SS2.p3.6.m6.2.2.2.cmml"><mo stretchy="false" id="S3.SS2.p3.6.m6.2.2.1.2" xref="S3.SS2.p3.6.m6.2.2.2.cmml">(</mo><mrow id="S3.SS2.p3.6.m6.2.2.1.1" xref="S3.SS2.p3.6.m6.2.2.1.1.cmml"><mi id="S3.SS2.p3.6.m6.2.2.1.1.2" xref="S3.SS2.p3.6.m6.2.2.1.1.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.2.2.1.1.1" xref="S3.SS2.p3.6.m6.2.2.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m6.2.2.1.1.3" xref="S3.SS2.p3.6.m6.2.2.1.1.3.cmml">T</mi></mrow><mo id="S3.SS2.p3.6.m6.2.2.1.3" xref="S3.SS2.p3.6.m6.2.2.2.cmml">,</mo><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">T</mi><mo stretchy="false" id="S3.SS2.p3.6.m6.2.2.1.4" xref="S3.SS2.p3.6.m6.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.2b"><interval closure="open" id="S3.SS2.p3.6.m6.2.2.2.cmml" xref="S3.SS2.p3.6.m6.2.2.1"><apply id="S3.SS2.p3.6.m6.2.2.1.1.cmml" xref="S3.SS2.p3.6.m6.2.2.1.1"><times id="S3.SS2.p3.6.m6.2.2.1.1.1.cmml" xref="S3.SS2.p3.6.m6.2.2.1.1.1"></times><ci id="S3.SS2.p3.6.m6.2.2.1.1.2.cmml" xref="S3.SS2.p3.6.m6.2.2.1.1.2">𝑉</ci><ci id="S3.SS2.p3.6.m6.2.2.1.1.3.cmml" xref="S3.SS2.p3.6.m6.2.2.1.1.3">𝑇</ci></apply><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝑇</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.2c">(VT,T)</annotation></semantics></math> using the Marching Tetrahedra (MT) layer in our current DMTET. By rendering the generated mesh <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">ℳ</mi><mrow id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml"><mi id="S3.SS2.p3.7.m7.1.1.3.2" xref="S3.SS2.p3.7.m7.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.7.m7.1.1.3.3" xref="S3.SS2.p3.7.m7.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1a" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.7.m7.1.1.3.4" xref="S3.SS2.p3.7.m7.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">ℳ</ci><apply id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3"><times id="S3.SS2.p3.7.m7.1.1.3.1.cmml" xref="S3.SS2.p3.7.m7.1.1.3.1"></times><ci id="S3.SS2.p3.7.m7.1.1.3.2.cmml" xref="S3.SS2.p3.7.m7.1.1.3.2">𝑡</ci><ci id="S3.SS2.p3.7.m7.1.1.3.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3.3">𝑟</ci><ci id="S3.SS2.p3.7.m7.1.1.3.4.cmml" xref="S3.SS2.p3.7.m7.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">\mathcal{M}_{tri}</annotation></semantics></math> with differentiable rasterization, we obtain the resulting normal map <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="\mathcal{\hat{N}_{\varphi}}" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><msub id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mover accent="true" id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.8.m8.1.1.2.2" xref="S3.SS2.p3.8.m8.1.1.2.2.cmml">𝒩</mi><mo id="S3.SS2.p3.8.m8.1.1.2.1" xref="S3.SS2.p3.8.m8.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">subscript</csymbol><apply id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2"><ci id="S3.SS2.p3.8.m8.1.1.2.1.cmml" xref="S3.SS2.p3.8.m8.1.1.2.1">^</ci><ci id="S3.SS2.p3.8.m8.1.1.2.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2.2">𝒩</ci></apply><ci id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">\mathcal{\hat{N}_{\varphi}}</annotation></semantics></math>.
To ensure holistic surface polishing that takes into account multi-view normals, we randomly sample camera poses <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><mi id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml">φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><ci id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">𝜑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">\varphi</annotation></semantics></math> that are uniformly distributed in space. We optimize the parameters of <math id="S3.SS2.p3.10.m10.1" class="ltx_Math" alttext="\Psi_{g}" display="inline"><semantics id="S3.SS2.p3.10.m10.1a"><msub id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p3.10.m10.1.1.2" xref="S3.SS2.p3.10.m10.1.1.2.cmml">Ψ</mi><mi id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m10.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2">Ψ</ci><ci id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">\Psi_{g}</annotation></semantics></math> using the normal loss, which is defined as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}_{norm}=||\mathcal{\hat{N}_{\varphi}}-\mathcal{N_{\varphi}}||_{2}." display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1a" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.4" xref="S3.E3.m1.1.1.1.1.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1b" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.5" xref="S3.E3.m1.1.1.1.1.3.3.5.cmml">m</mi></mrow></msub><mo id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">=</mo><msub id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝒩</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml">φ</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝒩</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml">φ</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo lspace="0em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"></eq><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">ℒ</ci><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><times id="S3.E3.m1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2">𝑛</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3">𝑜</ci><ci id="S3.E3.m1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.3.4">𝑟</ci><ci id="S3.E3.m1.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.1.1.1.1.3.3.5">𝑚</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2">𝒩</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3">𝜑</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2">𝒩</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3">𝜑</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\mathcal{L}_{norm}=||\mathcal{\hat{N}_{\varphi}}-\mathcal{N_{\varphi}}||_{2}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">After rapid optimization, the final triangular mesh <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">ℳ</mi><mrow id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1a" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p4.1.m1.1.1.3.4" xref="S3.SS2.p4.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">ℳ</ci><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><times id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.1"></times><ci id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">𝑡</ci><ci id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS2.p4.1.m1.1.1.3.4.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathcal{M}_{tri}</annotation></semantics></math> can be easily extracted from the MT layer.
If the hands exhibit noise, they can be optionally replaced with cleaner geometry hands from SMPL-X, benefiting from the alignment of the generated body in canonical space with the underlying template body.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Explicit texturing</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">With the final mesh, the explicit texturing module aims to disentangle a UV texture map from multi-view renderings <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{I}_{g}^{\varphi}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msubsup id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">g</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">φ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">ℐ</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">𝑔</ci></apply><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{I}_{g}^{\varphi}</annotation></semantics></math>.
This intuitive module not only facilitates the incorporation of high-fidelity textures but also enables various editing applications, as verified in Section <a href="#S4.SS4" title="4.4 Applications ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.10" class="ltx_p">Given the polished triangular mesh <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">ℳ</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1a" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.1.1.3.4" xref="S3.SS3.p2.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ℳ</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS3.p2.1.m1.1.1.3.4.cmml" xref="S3.SS3.p2.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathcal{M}_{tri}</annotation></semantics></math> and multi-views <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="{\mathcal{I}_{g}^{\varphi}}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msubsup id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.2.m2.1.1.2.2" xref="S3.SS3.p2.2.m2.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS3.p2.2.m2.1.1.2.3" xref="S3.SS3.p2.2.m2.1.1.2.3.cmml">g</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">φ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">superscript</csymbol><apply id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2.2">ℐ</ci><ci id="S3.SS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS3.p2.2.m2.1.1.2.3">𝑔</ci></apply><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">{\mathcal{I}_{g}^{\varphi}}</annotation></semantics></math>,
we model the explicit texture map <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">T</mi><mrow id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">𝑇</ci><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><times id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">𝑢</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">T_{uv}</annotation></semantics></math> of <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">ℳ</mi><mrow id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml"><mi id="S3.SS3.p2.4.m4.1.1.3.2" xref="S3.SS3.p2.4.m4.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.1.1.3.1" xref="S3.SS3.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.1.1.3.3" xref="S3.SS3.p2.4.m4.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.1.1.3.1a" xref="S3.SS3.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.1.1.3.4" xref="S3.SS3.p2.4.m4.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">ℳ</ci><apply id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3"><times id="S3.SS3.p2.4.m4.1.1.3.1.cmml" xref="S3.SS3.p2.4.m4.1.1.3.1"></times><ci id="S3.SS3.p2.4.m4.1.1.3.2.cmml" xref="S3.SS3.p2.4.m4.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.4.m4.1.1.3.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3">𝑟</ci><ci id="S3.SS3.p2.4.m4.1.1.3.4.cmml" xref="S3.SS3.p2.4.m4.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\mathcal{M}_{tri}</annotation></semantics></math> with a semantic UV partition and optimize <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><msub id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">T</mi><mrow id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml"><mi id="S3.SS3.p2.5.m5.1.1.3.2" xref="S3.SS3.p2.5.m5.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.1.3.1" xref="S3.SS3.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.1.3.3" xref="S3.SS3.p2.5.m5.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝑇</ci><apply id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3"><times id="S3.SS3.p2.5.m5.1.1.3.1.cmml" xref="S3.SS3.p2.5.m5.1.1.3.1"></times><ci id="S3.SS3.p2.5.m5.1.1.3.2.cmml" xref="S3.SS3.p2.5.m5.1.1.3.2">𝑢</ci><ci id="S3.SS3.p2.5.m5.1.1.3.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">T_{uv}</annotation></semantics></math> using a differentiable rasterizer <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><ci id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">\mathcal{R}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>.
Specifically, leveraging the canonical properties of synthesized bodies, we semantically split <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><msub id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">ℳ</mi><mrow id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml"><mi id="S3.SS3.p2.7.m7.1.1.3.2" xref="S3.SS3.p2.7.m7.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.3.1" xref="S3.SS3.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.3.3" xref="S3.SS3.p2.7.m7.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.3.1a" xref="S3.SS3.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.3.4" xref="S3.SS3.p2.7.m7.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">ℳ</ci><apply id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3"><times id="S3.SS3.p2.7.m7.1.1.3.1.cmml" xref="S3.SS3.p2.7.m7.1.1.3.1"></times><ci id="S3.SS3.p2.7.m7.1.1.3.2.cmml" xref="S3.SS3.p2.7.m7.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.7.m7.1.1.3.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3.3">𝑟</ci><ci id="S3.SS3.p2.7.m7.1.1.3.4.cmml" xref="S3.SS3.p2.7.m7.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">\mathcal{M}_{tri}</annotation></semantics></math> into <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><mi id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><ci id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">\gamma</annotation></semantics></math> components and rotate each component vertically, thus enabling effective UV projection for each component with cylinder unwarping.
We then combine the texture partitions together for the full texture <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><msub id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2" xref="S3.SS3.p2.9.m9.1.1.2.cmml">T</mi><mrow id="S3.SS3.p2.9.m9.1.1.3" xref="S3.SS3.p2.9.m9.1.1.3.cmml"><mi id="S3.SS3.p2.9.m9.1.1.3.2" xref="S3.SS3.p2.9.m9.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.9.m9.1.1.3.1" xref="S3.SS3.p2.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.9.m9.1.1.3.3" xref="S3.SS3.p2.9.m9.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2">𝑇</ci><apply id="S3.SS3.p2.9.m9.1.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3"><times id="S3.SS3.p2.9.m9.1.1.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1"></times><ci id="S3.SS3.p2.9.m9.1.1.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2">𝑢</ci><ci id="S3.SS3.p2.9.m9.1.1.3.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">T_{uv}</annotation></semantics></math>.
We optimize <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><msub id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml">T</mi><mrow id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml"><mi id="S3.SS3.p2.10.m10.1.1.3.2" xref="S3.SS3.p2.10.m10.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.3.1" xref="S3.SS3.p2.10.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.10.m10.1.1.3.3" xref="S3.SS3.p2.10.m10.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2">𝑇</ci><apply id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3"><times id="S3.SS3.p2.10.m10.1.1.3.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.1"></times><ci id="S3.SS3.p2.10.m10.1.1.3.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2">𝑢</ci><ci id="S3.SS3.p2.10.m10.1.1.3.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">T_{uv}</annotation></semantics></math> from a randomly initialized scratch using the texture loss, which consists of a multi-view reconstruction term and a total-variation (tv) term:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\mathcal{L}_{tex}=\mathcal{L}_{rec}+\lambda_{tv}\mathcal{L}_{tv}," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.2.cmml">ℒ</mi><mrow id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.3.2" xref="S3.E4.m1.1.1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.2.3.1" xref="S3.E4.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.2.3.3" xref="S3.E4.m1.1.1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.2.3.1a" xref="S3.E4.m1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.2.3.4" xref="S3.E4.m1.1.1.1.1.2.3.4.cmml">x</mi></mrow></msub><mo id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><msub id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml">ℒ</mi><mrow id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.1.1.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.2.3.1" xref="S3.E4.m1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.2.3.1a" xref="S3.E4.m1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.3.2.3.4" xref="S3.E4.m1.1.1.1.1.3.2.3.4.cmml">c</mi></mrow></msub><mo id="S3.E4.m1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml"><msub id="S3.E4.m1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.cmml">λ</mi><mrow id="S3.E4.m1.1.1.1.1.3.3.2.3" xref="S3.E4.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.2.3.1" xref="S3.E4.m1.1.1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.3.3.2.3.3" xref="S3.E4.m1.1.1.1.1.3.3.2.3.3.cmml">v</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.1" xref="S3.E4.m1.1.1.1.1.3.3.1.cmml">​</mo><msub id="S3.E4.m1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.3.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mrow id="S3.E4.m1.1.1.1.1.3.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.3.3.1" xref="S3.E4.m1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E4.m1.1.1.1.1.3.3.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.3.3.cmml">v</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"></eq><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2">ℒ</ci><apply id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3"><times id="S3.E4.m1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.3.1"></times><ci id="S3.E4.m1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E4.m1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3.3">𝑒</ci><ci id="S3.E4.m1.1.1.1.1.2.3.4.cmml" xref="S3.E4.m1.1.1.1.1.2.3.4">𝑥</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><plus id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1"></plus><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2">ℒ</ci><apply id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3"><times id="S3.E4.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.1"></times><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2">𝑟</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3">𝑒</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.4.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.4">𝑐</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3"><times id="S3.E4.m1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1"></times><apply id="S3.E4.m1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2">𝜆</ci><apply id="S3.E4.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.3"><times id="S3.E4.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.3.1"></times><ci id="S3.E4.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.3.2">𝑡</ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.3.3">𝑣</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.2">ℒ</ci><apply id="S3.E4.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3"><times id="S3.E4.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3.1"></times><ci id="S3.E4.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3.2">𝑡</ci><ci id="S3.E4.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3.3">𝑣</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L}_{tex}=\mathcal{L}_{rec}+\lambda_{tv}\mathcal{L}_{tv},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.11" class="ltx_p">where <math id="S3.SS3.p2.11.m1.1" class="ltx_Math" alttext="\lambda_{tv}" display="inline"><semantics id="S3.SS3.p2.11.m1.1a"><msub id="S3.SS3.p2.11.m1.1.1" xref="S3.SS3.p2.11.m1.1.1.cmml"><mi id="S3.SS3.p2.11.m1.1.1.2" xref="S3.SS3.p2.11.m1.1.1.2.cmml">λ</mi><mrow id="S3.SS3.p2.11.m1.1.1.3" xref="S3.SS3.p2.11.m1.1.1.3.cmml"><mi id="S3.SS3.p2.11.m1.1.1.3.2" xref="S3.SS3.p2.11.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m1.1.1.3.1" xref="S3.SS3.p2.11.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.11.m1.1.1.3.3" xref="S3.SS3.p2.11.m1.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m1.1b"><apply id="S3.SS3.p2.11.m1.1.1.cmml" xref="S3.SS3.p2.11.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m1.1.1.1.cmml" xref="S3.SS3.p2.11.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.11.m1.1.1.2.cmml" xref="S3.SS3.p2.11.m1.1.1.2">𝜆</ci><apply id="S3.SS3.p2.11.m1.1.1.3.cmml" xref="S3.SS3.p2.11.m1.1.1.3"><times id="S3.SS3.p2.11.m1.1.1.3.1.cmml" xref="S3.SS3.p2.11.m1.1.1.3.1"></times><ci id="S3.SS3.p2.11.m1.1.1.3.2.cmml" xref="S3.SS3.p2.11.m1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.11.m1.1.1.3.3.cmml" xref="S3.SS3.p2.11.m1.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m1.1c">\lambda_{tv}</annotation></semantics></math> denotes the weight of the tv loss.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.5" class="ltx_p"><span id="S3.SS3.p3.5.1" class="ltx_text ltx_font_bold">Multi-view guidance.</span>
To ensure comprehensive texturing in the 3D space, we render the color images <math id="S3.SS3.p3.1.m1.2" class="ltx_Math" alttext="\mathcal{R}(\mathcal{M}_{tri},\varphi)" display="inline"><semantics id="S3.SS3.p3.1.m1.2a"><mrow id="S3.SS3.p3.1.m1.2.2" xref="S3.SS3.p3.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.2.2.3" xref="S3.SS3.p3.1.m1.2.2.3.cmml">ℛ</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.2.2.2" xref="S3.SS3.p3.1.m1.2.2.2.cmml">​</mo><mrow id="S3.SS3.p3.1.m1.2.2.1.1" xref="S3.SS3.p3.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.1.m1.2.2.1.1.2" xref="S3.SS3.p3.1.m1.2.2.1.2.cmml">(</mo><msub id="S3.SS3.p3.1.m1.2.2.1.1.1" xref="S3.SS3.p3.1.m1.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.2.2.1.1.1.2" xref="S3.SS3.p3.1.m1.2.2.1.1.1.2.cmml">ℳ</mi><mrow id="S3.SS3.p3.1.m1.2.2.1.1.1.3" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.2.2.1.1.1.3.2" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.2.2.1.1.1.3.1" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.2.2.1.1.1.3.3" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.2.2.1.1.1.3.1a" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.2.2.1.1.1.3.4" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.4.cmml">i</mi></mrow></msub><mo id="S3.SS3.p3.1.m1.2.2.1.1.3" xref="S3.SS3.p3.1.m1.2.2.1.2.cmml">,</mo><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">φ</mi><mo stretchy="false" id="S3.SS3.p3.1.m1.2.2.1.1.4" xref="S3.SS3.p3.1.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.2b"><apply id="S3.SS3.p3.1.m1.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2"><times id="S3.SS3.p3.1.m1.2.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2.2"></times><ci id="S3.SS3.p3.1.m1.2.2.3.cmml" xref="S3.SS3.p3.1.m1.2.2.3">ℛ</ci><interval closure="open" id="S3.SS3.p3.1.m1.2.2.1.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1"><apply id="S3.SS3.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.2">ℳ</ci><apply id="S3.SS3.p3.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3"><times id="S3.SS3.p3.1.m1.2.2.1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.1"></times><ci id="S3.SS3.p3.1.m1.2.2.1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p3.1.m1.2.2.1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.3">𝑟</ci><ci id="S3.SS3.p3.1.m1.2.2.1.1.1.3.4.cmml" xref="S3.SS3.p3.1.m1.2.2.1.1.1.3.4">𝑖</ci></apply></apply><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">𝜑</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.2c">\mathcal{R}(\mathcal{M}_{tri},\varphi)</annotation></semantics></math> and silhouettes <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathcal{S}</annotation></semantics></math> using <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><ci id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">\mathcal{R}</annotation></semantics></math> and optimize <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">T</mi><mrow id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml"><mi id="S3.SS3.p3.4.m4.1.1.3.2" xref="S3.SS3.p3.4.m4.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.4.m4.1.1.3.1" xref="S3.SS3.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.4.m4.1.1.3.3" xref="S3.SS3.p3.4.m4.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝑇</ci><apply id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"><times id="S3.SS3.p3.4.m4.1.1.3.1.cmml" xref="S3.SS3.p3.4.m4.1.1.3.1"></times><ci id="S3.SS3.p3.4.m4.1.1.3.2.cmml" xref="S3.SS3.p3.4.m4.1.1.3.2">𝑢</ci><ci id="S3.SS3.p3.4.m4.1.1.3.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">T_{uv}</annotation></semantics></math> utilizing multi-view weighted guidance. Their pixel-alignment distances to the original multi-view renderings <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{I}_{g}^{\varphi}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><msubsup id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.5.m5.1.1.2.2" xref="S3.SS3.p3.5.m5.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS3.p3.5.m5.1.1.2.3" xref="S3.SS3.p3.5.m5.1.1.2.3.cmml">g</mi><mi id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml">φ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">superscript</csymbol><apply id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.2.1.cmml" xref="S3.SS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2.2">ℐ</ci><ci id="S3.SS3.p3.5.m5.1.1.2.3.cmml" xref="S3.SS3.p3.5.m5.1.1.2.3">𝑔</ci></apply><ci id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">\mathcal{I}_{g}^{\varphi}</annotation></semantics></math> are defined as the reconstruction loss:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.2" class="ltx_Math" alttext="\mathcal{L}_{rec}=\sum_{\varphi\in\Omega}w_{\varphi}||\mathcal{R}(\mathcal{M}_{tri},\varphi)\cdot\mathcal{S}-I_{g}^{\varphi}\cdot\mathcal{S}||_{2}," display="block"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.3" xref="S3.E5.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.3.2" xref="S3.E5.m1.2.2.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E5.m1.2.2.1.1.3.3" xref="S3.E5.m1.2.2.1.1.3.3.cmml"><mi id="S3.E5.m1.2.2.1.1.3.3.2" xref="S3.E5.m1.2.2.1.1.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.3.3.1" xref="S3.E5.m1.2.2.1.1.3.3.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.3.3.3" xref="S3.E5.m1.2.2.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.3.3.1a" xref="S3.E5.m1.2.2.1.1.3.3.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.3.3.4" xref="S3.E5.m1.2.2.1.1.3.3.4.cmml">c</mi></mrow></msub><mo rspace="0.111em" id="S3.E5.m1.2.2.1.1.2" xref="S3.E5.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.1.cmml"><munder id="S3.E5.m1.2.2.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E5.m1.2.2.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.2.2.cmml">∑</mo><mrow id="S3.E5.m1.2.2.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.2.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.2.3.2" xref="S3.E5.m1.2.2.1.1.1.2.3.2.cmml">φ</mi><mo id="S3.E5.m1.2.2.1.1.1.2.3.1" xref="S3.E5.m1.2.2.1.1.1.2.3.1.cmml">∈</mo><mi mathvariant="normal" id="S3.E5.m1.2.2.1.1.1.2.3.3" xref="S3.E5.m1.2.2.1.1.1.2.3.3.cmml">Ω</mi></mrow></munder><mrow id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.3.2.cmml">w</mi><mi id="S3.E5.m1.2.2.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.3.3.cmml">φ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.2.cmml">​</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">ℛ</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ℳ</mi><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml">i</mi></mrow></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">φ</mi><mo rspace="0.055em" stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">⋅</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">𝒮</mi></mrow><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><msubsup id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.2.cmml">I</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.3.cmml">g</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml">φ</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml">⋅</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml">𝒮</mi></mrow></mrow><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E5.m1.2.2.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1"><eq id="S3.E5.m1.2.2.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.2"></eq><apply id="S3.E5.m1.2.2.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.3.2">ℒ</ci><apply id="S3.E5.m1.2.2.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.3.3"><times id="S3.E5.m1.2.2.1.1.3.3.1.cmml" xref="S3.E5.m1.2.2.1.1.3.3.1"></times><ci id="S3.E5.m1.2.2.1.1.3.3.2.cmml" xref="S3.E5.m1.2.2.1.1.3.3.2">𝑟</ci><ci id="S3.E5.m1.2.2.1.1.3.3.3.cmml" xref="S3.E5.m1.2.2.1.1.3.3.3">𝑒</ci><ci id="S3.E5.m1.2.2.1.1.3.3.4.cmml" xref="S3.E5.m1.2.2.1.1.3.3.4">𝑐</ci></apply></apply><apply id="S3.E5.m1.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1"><apply id="S3.E5.m1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S3.E5.m1.2.2.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2.2"></sum><apply id="S3.E5.m1.2.2.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.2.3"><in id="S3.E5.m1.2.2.1.1.1.2.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.2.3.1"></in><ci id="S3.E5.m1.2.2.1.1.1.2.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2.3.2">𝜑</ci><ci id="S3.E5.m1.2.2.1.1.1.2.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.2.3.3">Ω</ci></apply></apply><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2"></times><apply id="S3.E5.m1.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3.2">𝑤</ci><ci id="S3.E5.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3.3">𝜑</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1"><minus id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1"><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2">⋅</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">ℛ</ci><interval closure="open" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ℳ</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4">𝑖</ci></apply></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝜑</ci></interval></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝒮</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3"><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.1">⋅</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2">superscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.2">𝐼</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.3">𝑔</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">𝜑</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3">𝒮</ci></apply></apply></apply><cn type="integer" id="S3.E5.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">\mathcal{L}_{rec}=\sum_{\varphi\in\Omega}w_{\varphi}||\mathcal{R}(\mathcal{M}_{tri},\varphi)\cdot\mathcal{S}-I_{g}^{\varphi}\cdot\mathcal{S}||_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.12" class="ltx_p">where <math id="S3.SS3.p3.6.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S3.SS3.p3.6.m1.1a"><mi mathvariant="normal" id="S3.SS3.p3.6.m1.1.1" xref="S3.SS3.p3.6.m1.1.1.cmml">Ω</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m1.1b"><ci id="S3.SS3.p3.6.m1.1.1.cmml" xref="S3.SS3.p3.6.m1.1.1">Ω</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m1.1c">\Omega</annotation></semantics></math> is the set of viewpoints <math id="S3.SS3.p3.7.m2.4" class="ltx_Math" alttext="\{\varphi_{i},i=1,...,k\}" display="inline"><semantics id="S3.SS3.p3.7.m2.4a"><mrow id="S3.SS3.p3.7.m2.4.4.1" xref="S3.SS3.p3.7.m2.4.4.2.cmml"><mo stretchy="false" id="S3.SS3.p3.7.m2.4.4.1.2" xref="S3.SS3.p3.7.m2.4.4.2.cmml">{</mo><mrow id="S3.SS3.p3.7.m2.4.4.1.1.2" xref="S3.SS3.p3.7.m2.4.4.1.1.3.cmml"><mrow id="S3.SS3.p3.7.m2.4.4.1.1.1.1" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.cmml"><mrow id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.2.cmml"><msub id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.2.cmml">φ</mi><mi id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.2" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.2.cmml">,</mo><mi id="S3.SS3.p3.7.m2.1.1" xref="S3.SS3.p3.7.m2.1.1.cmml">i</mi></mrow><mo id="S3.SS3.p3.7.m2.4.4.1.1.1.1.2" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.2.cmml">=</mo><mn id="S3.SS3.p3.7.m2.4.4.1.1.1.1.3" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS3.p3.7.m2.4.4.1.1.2.3" xref="S3.SS3.p3.7.m2.4.4.1.1.3a.cmml">,</mo><mrow id="S3.SS3.p3.7.m2.4.4.1.1.2.2.2" xref="S3.SS3.p3.7.m2.4.4.1.1.2.2.1.cmml"><mi mathvariant="normal" id="S3.SS3.p3.7.m2.2.2" xref="S3.SS3.p3.7.m2.2.2.cmml">…</mi><mo id="S3.SS3.p3.7.m2.4.4.1.1.2.2.2.1" xref="S3.SS3.p3.7.m2.4.4.1.1.2.2.1.cmml">,</mo><mi id="S3.SS3.p3.7.m2.3.3" xref="S3.SS3.p3.7.m2.3.3.cmml">k</mi></mrow></mrow><mo stretchy="false" id="S3.SS3.p3.7.m2.4.4.1.3" xref="S3.SS3.p3.7.m2.4.4.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m2.4b"><set id="S3.SS3.p3.7.m2.4.4.2.cmml" xref="S3.SS3.p3.7.m2.4.4.1"><apply id="S3.SS3.p3.7.m2.4.4.1.1.3.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m2.4.4.1.1.3a.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S3.SS3.p3.7.m2.4.4.1.1.1.1.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1"><eq id="S3.SS3.p3.7.m2.4.4.1.1.1.1.2.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.2"></eq><list id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1"><apply id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.2">𝜑</ci><ci id="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.SS3.p3.7.m2.1.1.cmml" xref="S3.SS3.p3.7.m2.1.1">𝑖</ci></list><cn type="integer" id="S3.SS3.p3.7.m2.4.4.1.1.1.1.3.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.1.1.3">1</cn></apply><list id="S3.SS3.p3.7.m2.4.4.1.1.2.2.1.cmml" xref="S3.SS3.p3.7.m2.4.4.1.1.2.2.2"><ci id="S3.SS3.p3.7.m2.2.2.cmml" xref="S3.SS3.p3.7.m2.2.2">…</ci><ci id="S3.SS3.p3.7.m2.3.3.cmml" xref="S3.SS3.p3.7.m2.3.3">𝑘</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m2.4c">\{\varphi_{i},i=1,...,k\}</annotation></semantics></math> and <math id="S3.SS3.p3.8.m3.1" class="ltx_Math" alttext="w_{\varphi}" display="inline"><semantics id="S3.SS3.p3.8.m3.1a"><msub id="S3.SS3.p3.8.m3.1.1" xref="S3.SS3.p3.8.m3.1.1.cmml"><mi id="S3.SS3.p3.8.m3.1.1.2" xref="S3.SS3.p3.8.m3.1.1.2.cmml">w</mi><mi id="S3.SS3.p3.8.m3.1.1.3" xref="S3.SS3.p3.8.m3.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m3.1b"><apply id="S3.SS3.p3.8.m3.1.1.cmml" xref="S3.SS3.p3.8.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m3.1.1.1.cmml" xref="S3.SS3.p3.8.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m3.1.1.2.cmml" xref="S3.SS3.p3.8.m3.1.1.2">𝑤</ci><ci id="S3.SS3.p3.8.m3.1.1.3.cmml" xref="S3.SS3.p3.8.m3.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m3.1c">w_{\varphi}</annotation></semantics></math> denotes weights of different views. <math id="S3.SS3.p3.9.m4.1" class="ltx_Math" alttext="w_{\varphi}" display="inline"><semantics id="S3.SS3.p3.9.m4.1a"><msub id="S3.SS3.p3.9.m4.1.1" xref="S3.SS3.p3.9.m4.1.1.cmml"><mi id="S3.SS3.p3.9.m4.1.1.2" xref="S3.SS3.p3.9.m4.1.1.2.cmml">w</mi><mi id="S3.SS3.p3.9.m4.1.1.3" xref="S3.SS3.p3.9.m4.1.1.3.cmml">φ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m4.1b"><apply id="S3.SS3.p3.9.m4.1.1.cmml" xref="S3.SS3.p3.9.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.9.m4.1.1.1.cmml" xref="S3.SS3.p3.9.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.9.m4.1.1.2.cmml" xref="S3.SS3.p3.9.m4.1.1.2">𝑤</ci><ci id="S3.SS3.p3.9.m4.1.1.3.cmml" xref="S3.SS3.p3.9.m4.1.1.3">𝜑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m4.1c">w_{\varphi}</annotation></semantics></math> equals to <math id="S3.SS3.p3.10.m5.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S3.SS3.p3.10.m5.1a"><mn id="S3.SS3.p3.10.m5.1.1" xref="S3.SS3.p3.10.m5.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m5.1b"><cn type="float" id="S3.SS3.p3.10.m5.1.1.cmml" xref="S3.SS3.p3.10.m5.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m5.1c">1.0</annotation></semantics></math> for <math id="S3.SS3.p3.11.m6.2" class="ltx_Math" alttext="\varphi\in\{front,back\}" display="inline"><semantics id="S3.SS3.p3.11.m6.2a"><mrow id="S3.SS3.p3.11.m6.2.2" xref="S3.SS3.p3.11.m6.2.2.cmml"><mi id="S3.SS3.p3.11.m6.2.2.4" xref="S3.SS3.p3.11.m6.2.2.4.cmml">φ</mi><mo id="S3.SS3.p3.11.m6.2.2.3" xref="S3.SS3.p3.11.m6.2.2.3.cmml">∈</mo><mrow id="S3.SS3.p3.11.m6.2.2.2.2" xref="S3.SS3.p3.11.m6.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p3.11.m6.2.2.2.2.3" xref="S3.SS3.p3.11.m6.2.2.2.3.cmml">{</mo><mrow id="S3.SS3.p3.11.m6.1.1.1.1.1" xref="S3.SS3.p3.11.m6.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.11.m6.1.1.1.1.1.2" xref="S3.SS3.p3.11.m6.1.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.1.1.1.1.1.1" xref="S3.SS3.p3.11.m6.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.1.1.1.1.1.3" xref="S3.SS3.p3.11.m6.1.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.1.1.1.1.1.1a" xref="S3.SS3.p3.11.m6.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.1.1.1.1.1.4" xref="S3.SS3.p3.11.m6.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.1.1.1.1.1.1b" xref="S3.SS3.p3.11.m6.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.1.1.1.1.1.5" xref="S3.SS3.p3.11.m6.1.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.1.1.1.1.1.1c" xref="S3.SS3.p3.11.m6.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.1.1.1.1.1.6" xref="S3.SS3.p3.11.m6.1.1.1.1.1.6.cmml">t</mi></mrow><mo id="S3.SS3.p3.11.m6.2.2.2.2.4" xref="S3.SS3.p3.11.m6.2.2.2.3.cmml">,</mo><mrow id="S3.SS3.p3.11.m6.2.2.2.2.2" xref="S3.SS3.p3.11.m6.2.2.2.2.2.cmml"><mi id="S3.SS3.p3.11.m6.2.2.2.2.2.2" xref="S3.SS3.p3.11.m6.2.2.2.2.2.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.2.2.2.2.2.1" xref="S3.SS3.p3.11.m6.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.2.2.2.2.2.3" xref="S3.SS3.p3.11.m6.2.2.2.2.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.2.2.2.2.2.1a" xref="S3.SS3.p3.11.m6.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.2.2.2.2.2.4" xref="S3.SS3.p3.11.m6.2.2.2.2.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.11.m6.2.2.2.2.2.1b" xref="S3.SS3.p3.11.m6.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.11.m6.2.2.2.2.2.5" xref="S3.SS3.p3.11.m6.2.2.2.2.2.5.cmml">k</mi></mrow><mo stretchy="false" id="S3.SS3.p3.11.m6.2.2.2.2.5" xref="S3.SS3.p3.11.m6.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m6.2b"><apply id="S3.SS3.p3.11.m6.2.2.cmml" xref="S3.SS3.p3.11.m6.2.2"><in id="S3.SS3.p3.11.m6.2.2.3.cmml" xref="S3.SS3.p3.11.m6.2.2.3"></in><ci id="S3.SS3.p3.11.m6.2.2.4.cmml" xref="S3.SS3.p3.11.m6.2.2.4">𝜑</ci><set id="S3.SS3.p3.11.m6.2.2.2.3.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2"><apply id="S3.SS3.p3.11.m6.1.1.1.1.1.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1"><times id="S3.SS3.p3.11.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.1"></times><ci id="S3.SS3.p3.11.m6.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.2">𝑓</ci><ci id="S3.SS3.p3.11.m6.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.3">𝑟</ci><ci id="S3.SS3.p3.11.m6.1.1.1.1.1.4.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.4">𝑜</ci><ci id="S3.SS3.p3.11.m6.1.1.1.1.1.5.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.5">𝑛</ci><ci id="S3.SS3.p3.11.m6.1.1.1.1.1.6.cmml" xref="S3.SS3.p3.11.m6.1.1.1.1.1.6">𝑡</ci></apply><apply id="S3.SS3.p3.11.m6.2.2.2.2.2.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2"><times id="S3.SS3.p3.11.m6.2.2.2.2.2.1.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2.1"></times><ci id="S3.SS3.p3.11.m6.2.2.2.2.2.2.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2.2">𝑏</ci><ci id="S3.SS3.p3.11.m6.2.2.2.2.2.3.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2.3">𝑎</ci><ci id="S3.SS3.p3.11.m6.2.2.2.2.2.4.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2.4">𝑐</ci><ci id="S3.SS3.p3.11.m6.2.2.2.2.2.5.cmml" xref="S3.SS3.p3.11.m6.2.2.2.2.2.5">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m6.2c">\varphi\in\{front,back\}</annotation></semantics></math> and <math id="S3.SS3.p3.12.m7.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.SS3.p3.12.m7.1a"><mn id="S3.SS3.p3.12.m7.1.1" xref="S3.SS3.p3.12.m7.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m7.1b"><cn type="float" id="S3.SS3.p3.12.m7.1.1.cmml" xref="S3.SS3.p3.12.m7.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m7.1c">0.2</annotation></semantics></math> otherwise.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.2" class="ltx_p"><span id="S3.SS3.p4.2.1" class="ltx_text ltx_font_bold">Smooth constraint.</span> To avoid abrupt variations and smooth the generated texture <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">T</mi><mrow id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml"><mi id="S3.SS3.p4.1.m1.1.1.3.2" xref="S3.SS3.p4.1.m1.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.1.1.3.1" xref="S3.SS3.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p4.1.m1.1.1.3.3" xref="S3.SS3.p4.1.m1.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝑇</ci><apply id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3"><times id="S3.SS3.p4.1.m1.1.1.3.1.cmml" xref="S3.SS3.p4.1.m1.1.1.3.1"></times><ci id="S3.SS3.p4.1.m1.1.1.3.2.cmml" xref="S3.SS3.p4.1.m1.1.1.3.2">𝑢</ci><ci id="S3.SS3.p4.1.m1.1.1.3.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">T_{uv}</annotation></semantics></math>, we utilize the total-variation loss <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{tv}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msub id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.2.m2.1.1.3.1" xref="S3.SS3.p4.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p4.2.m2.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">ℒ</ci><apply id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3"><times id="S3.SS3.p4.2.m2.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.3.1"></times><ci id="S3.SS3.p4.2.m2.1.1.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.3.2">𝑡</ci><ci id="S3.SS3.p4.2.m2.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\mathcal{L}_{tv}</annotation></semantics></math> which is computed by:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\mathcal{L}_{tv}=\frac{1}{h\times w\times c}||\nabla_{x}(T_{uv})+\nabla_{y}(T_{uv})||," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml">v</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mfrac id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml"><mn id="S3.E6.m1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.3.2.cmml">1</mn><mrow id="S3.E6.m1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.1.3.3.2.cmml">h</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.1.3.3.1.cmml">×</mo><mi id="S3.E6.m1.1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.1.3.3.3.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.3.3.1a" xref="S3.E6.m1.1.1.1.1.1.3.3.1.cmml">×</mo><mi id="S3.E6.m1.1.1.1.1.1.3.3.4" xref="S3.E6.m1.1.1.1.1.1.3.3.4.cmml">c</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml"><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">∇</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">x</mi></msub><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.2.cmml">T</mi><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.3.cmml">v</mi></mrow></msub><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.5" xref="S3.E6.m1.1.1.1.1.1.1.1.1.5.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml"><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.cmml"><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.2.cmml">∇</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.3.cmml">y</mi></msub><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml">(</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.2.cmml">T</mi><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.1.cmml">​</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.3.cmml">v</mi></mrow></msub><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></eq><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2">ℒ</ci><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">𝑡</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3">𝑣</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3"><divide id="S3.E6.m1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.3"></divide><cn type="integer" id="S3.E6.m1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.3.2">1</cn><apply id="S3.E6.m1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3.2">ℎ</ci><ci id="S3.E6.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3.3">𝑤</ci><ci id="S3.E6.m1.1.1.1.1.1.3.3.4.cmml" xref="S3.E6.m1.1.1.1.1.1.3.3.4">𝑐</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1"><plus id="S3.E6.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.5"></plus><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2"><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2">∇</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑥</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.2">𝑇</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3"><times id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.1"></times><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.2">𝑢</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.2.1.3.3">𝑣</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2"><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.2">∇</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.1.3">𝑦</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.2">𝑇</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3"><times id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.1"></times><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.2">𝑢</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.2.1.3.3">𝑣</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{L}_{tv}=\frac{1}{h\times w\times c}||\nabla_{x}(T_{uv})+\nabla_{y}(T_{uv})||,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p4.4" class="ltx_p">where <math id="S3.SS3.p4.3.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p4.3.m1.1a"><mi id="S3.SS3.p4.3.m1.1.1" xref="S3.SS3.p4.3.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m1.1b"><ci id="S3.SS3.p4.3.m1.1.1.cmml" xref="S3.SS3.p4.3.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m1.1c">x</annotation></semantics></math> and <math id="S3.SS3.p4.4.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.p4.4.m2.1a"><mi id="S3.SS3.p4.4.m2.1.1" xref="S3.SS3.p4.4.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m2.1b"><ci id="S3.SS3.p4.4.m2.1.1.cmml" xref="S3.SS3.p4.4.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m2.1c">y</annotation></semantics></math> denote horizontal and vertical directions.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2401.01173/assets/pic/infer1.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="261" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">The visualized flowchart of our method that synthesize textured 3D human avatars from input noises, texts or images.</span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Inference</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Built upon the above modules, we can generate high-quality 3D human avatars from either random noises or guided inputs such as texts or images.
The flowchart for this process is shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Explicit texturing ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
For input noises, we can easily obtain the final results by sequentially using the 3DGM, GS and ET modules. For text-guided synthesis, we first convert the text into a structured image using our controlled diffusion <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{C}</annotation></semantics></math>, and then inverse it to the latent space using PTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite>.
Specially, the GS and ET modules provide an interface that accurately reflects viewed modifications in the final 3D objects. As a result, we utilize the guided image to replace the corresponding view image, which results in improved fidelity in terms of geometry and texture.
The same process is applied for input images as guided images.
</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2401.01173/assets/pic/synthesis_23_2.png" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="418" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.5.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2.1" class="ltx_text" style="font-size:90%;">Results of synthesized 3D human avatars at <math id="S4.F4.3.2.1.m1.1" class="ltx_Math" alttext="512^{2}" display="inline"><semantics id="S4.F4.3.2.1.m1.1b"><msup id="S4.F4.3.2.1.m1.1.1" xref="S4.F4.3.2.1.m1.1.1.cmml"><mn id="S4.F4.3.2.1.m1.1.1.2" xref="S4.F4.3.2.1.m1.1.1.2.cmml">512</mn><mn id="S4.F4.3.2.1.m1.1.1.3" xref="S4.F4.3.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.F4.3.2.1.m1.1c"><apply id="S4.F4.3.2.1.m1.1.1.cmml" xref="S4.F4.3.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.3.2.1.m1.1.1.1.cmml" xref="S4.F4.3.2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.F4.3.2.1.m1.1.1.2.cmml" xref="S4.F4.3.2.1.m1.1.1.2">512</cn><cn type="integer" id="S4.F4.3.2.1.m1.1.1.3.cmml" xref="S4.F4.3.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.2.1.m1.1d">512^{2}</annotation></semantics></math>. </span></figcaption>
</figure>
<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.17" class="ltx_p"><span id="S4.p1.17.1" class="ltx_text ltx_font_bold">Implementation details.</span>
Our process begins by training the 3D generative module (3DGM) on synthetic data. During inference, we integrate the geometric sculpting (GS) and explicit texturing (ET) as optimization modules.
For 3DGM, we normalize the template body to the <math id="S4.p1.1.m1.2" class="ltx_Math" alttext="(0,1)" display="inline"><semantics id="S4.p1.1.m1.2a"><mrow id="S4.p1.1.m1.2.3.2" xref="S4.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.p1.1.m1.2.3.2.1" xref="S4.p1.1.m1.2.3.1.cmml">(</mo><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">0</mn><mo id="S4.p1.1.m1.2.3.2.2" xref="S4.p1.1.m1.2.3.1.cmml">,</mo><mn id="S4.p1.1.m1.2.2" xref="S4.p1.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S4.p1.1.m1.2.3.2.3" xref="S4.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.2b"><interval closure="open" id="S4.p1.1.m1.2.3.1.cmml" xref="S4.p1.1.m1.2.3.2"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">0</cn><cn type="integer" id="S4.p1.1.m1.2.2.cmml" xref="S4.p1.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.2c">(0,1)</annotation></semantics></math> space and place its center at the origin of the world coordinate system.
We sample <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="7(\mathcal{K}=7)" display="inline"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mn id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml">7</mn><mo lspace="0em" rspace="0em" id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">​</mo><mrow id="S4.p1.2.m2.1.1.1.1" xref="S4.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.p1.2.m2.1.1.1.1.2" xref="S4.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.p1.2.m2.1.1.1.1.1" xref="S4.p1.2.m2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p1.2.m2.1.1.1.1.1.2" xref="S4.p1.2.m2.1.1.1.1.1.2.cmml">𝒦</mi><mo id="S4.p1.2.m2.1.1.1.1.1.1" xref="S4.p1.2.m2.1.1.1.1.1.1.cmml">=</mo><mn id="S4.p1.2.m2.1.1.1.1.1.3" xref="S4.p1.2.m2.1.1.1.1.1.3.cmml">7</mn></mrow><mo stretchy="false" id="S4.p1.2.m2.1.1.1.1.3" xref="S4.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><times id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2"></times><cn type="integer" id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3">7</cn><apply id="S4.p1.2.m2.1.1.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1.1"><eq id="S4.p1.2.m2.1.1.1.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1.1.1.1"></eq><ci id="S4.p1.2.m2.1.1.1.1.1.2.cmml" xref="S4.p1.2.m2.1.1.1.1.1.2">𝒦</ci><cn type="integer" id="S4.p1.2.m2.1.1.1.1.1.3.cmml" xref="S4.p1.2.m2.1.1.1.1.1.3">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">7(\mathcal{K}=7)</annotation></semantics></math> viewpoints uniformly from the horizontal plane, ranging from <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="0^{\circ}" display="inline"><semantics id="S4.p1.3.m3.1a"><msup id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml"><mn id="S4.p1.3.m3.1.1.2" xref="S4.p1.3.m3.1.1.2.cmml">0</mn><mo id="S4.p1.3.m3.1.1.3" xref="S4.p1.3.m3.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><apply id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p1.3.m3.1.1.1.cmml" xref="S4.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.p1.3.m3.1.1.2.cmml" xref="S4.p1.3.m3.1.1.2">0</cn><compose id="S4.p1.3.m3.1.1.3.cmml" xref="S4.p1.3.m3.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">0^{\circ}</annotation></semantics></math> to <math id="S4.p1.4.m4.1" class="ltx_Math" alttext="180^{\circ}" display="inline"><semantics id="S4.p1.4.m4.1a"><msup id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml"><mn id="S4.p1.4.m4.1.1.2" xref="S4.p1.4.m4.1.1.2.cmml">180</mn><mo id="S4.p1.4.m4.1.1.3" xref="S4.p1.4.m4.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><apply id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p1.4.m4.1.1.1.cmml" xref="S4.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S4.p1.4.m4.1.1.2.cmml" xref="S4.p1.4.m4.1.1.2">180</cn><compose id="S4.p1.4.m4.1.1.3.cmml" xref="S4.p1.4.m4.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">180^{\circ}</annotation></semantics></math> (front to back), with a camera radius of <math id="S4.p1.5.m5.1" class="ltx_Math" alttext="2.7" display="inline"><semantics id="S4.p1.5.m5.1a"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">2.7</mn><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><cn type="float" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">2.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">2.7</annotation></semantics></math>.
For each viewpoint, we generate <math id="S4.p1.6.m6.1" class="ltx_Math" alttext="100K" display="inline"><semantics id="S4.p1.6.m6.1a"><mrow id="S4.p1.6.m6.1.1" xref="S4.p1.6.m6.1.1.cmml"><mn id="S4.p1.6.m6.1.1.2" xref="S4.p1.6.m6.1.1.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S4.p1.6.m6.1.1.1" xref="S4.p1.6.m6.1.1.1.cmml">​</mo><mi id="S4.p1.6.m6.1.1.3" xref="S4.p1.6.m6.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.6.m6.1b"><apply id="S4.p1.6.m6.1.1.cmml" xref="S4.p1.6.m6.1.1"><times id="S4.p1.6.m6.1.1.1.cmml" xref="S4.p1.6.m6.1.1.1"></times><cn type="integer" id="S4.p1.6.m6.1.1.2.cmml" xref="S4.p1.6.m6.1.1.2">100</cn><ci id="S4.p1.6.m6.1.1.3.cmml" xref="S4.p1.6.m6.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.6.m6.1c">100K</annotation></semantics></math> images using the corresponding pose image.
To ensure diverse synthesis, we use detailed descriptions of age, gender, ethnicity, hairstyle, facial features, and clothing, leveraging a vast word bank.
To cover <math id="S4.p1.7.m7.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.p1.7.m7.1a"><msup id="S4.p1.7.m7.1.1" xref="S4.p1.7.m7.1.1.cmml"><mn id="S4.p1.7.m7.1.1.2" xref="S4.p1.7.m7.1.1.2.cmml">360</mn><mo id="S4.p1.7.m7.1.1.3" xref="S4.p1.7.m7.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p1.7.m7.1b"><apply id="S4.p1.7.m7.1.1.cmml" xref="S4.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.p1.7.m7.1.1.1.cmml" xref="S4.p1.7.m7.1.1">superscript</csymbol><cn type="integer" id="S4.p1.7.m7.1.1.2.cmml" xref="S4.p1.7.m7.1.1.2">360</cn><compose id="S4.p1.7.m7.1.1.3.cmml" xref="S4.p1.7.m7.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.7.m7.1c">360^{\circ}</annotation></semantics></math> views, we horizontally flip the synthesized images and obtain 1.4 million human images at a resolution of <math id="S4.p1.8.m8.1" class="ltx_Math" alttext="512^{2}" display="inline"><semantics id="S4.p1.8.m8.1a"><msup id="S4.p1.8.m8.1.1" xref="S4.p1.8.m8.1.1.cmml"><mn id="S4.p1.8.m8.1.1.2" xref="S4.p1.8.m8.1.1.2.cmml">512</mn><mn id="S4.p1.8.m8.1.1.3" xref="S4.p1.8.m8.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.p1.8.m8.1b"><apply id="S4.p1.8.m8.1.1.cmml" xref="S4.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.p1.8.m8.1.1.1.cmml" xref="S4.p1.8.m8.1.1">superscript</csymbol><cn type="integer" id="S4.p1.8.m8.1.1.2.cmml" xref="S4.p1.8.m8.1.1.2">512</cn><cn type="integer" id="S4.p1.8.m8.1.1.3.cmml" xref="S4.p1.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.8.m8.1c">512^{2}</annotation></semantics></math> in total.
We train the 3DGM for about 2.5M iterations with a batch size of <math id="S4.p1.9.m9.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.p1.9.m9.1a"><mn id="S4.p1.9.m9.1.1" xref="S4.p1.9.m9.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.p1.9.m9.1b"><cn type="integer" id="S4.p1.9.m9.1.1.cmml" xref="S4.p1.9.m9.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.9.m9.1c">32</annotation></semantics></math>, using two discriminators with a learning rate of <math id="S4.p1.10.m10.1" class="ltx_Math" alttext="0.002" display="inline"><semantics id="S4.p1.10.m10.1a"><mn id="S4.p1.10.m10.1.1" xref="S4.p1.10.m10.1.1.cmml">0.002</mn><annotation-xml encoding="MathML-Content" id="S4.p1.10.m10.1b"><cn type="float" id="S4.p1.10.m10.1.1.cmml" xref="S4.p1.10.m10.1.1">0.002</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.10.m10.1c">0.002</annotation></semantics></math> and a generator learning rate of 0.0025. The training takes 8 days on 8 NVIDIA Tesla-V100.
For GS, we optimize <math id="S4.p1.11.m11.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S4.p1.11.m11.1a"><mi id="S4.p1.11.m11.1.1" xref="S4.p1.11.m11.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S4.p1.11.m11.1b"><ci id="S4.p1.11.m11.1.1.cmml" xref="S4.p1.11.m11.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.11.m11.1c">\psi</annotation></semantics></math> for 400 iterations for DMTET adaption and 100 iterations for surface carving (taking about 15s in total on 1 NVIDIA RTX 3090 GPU). For ET, we set <math id="S4.p1.12.m12.1" class="ltx_Math" alttext="\lambda_{uv}=1" display="inline"><semantics id="S4.p1.12.m12.1a"><mrow id="S4.p1.12.m12.1.1" xref="S4.p1.12.m12.1.1.cmml"><msub id="S4.p1.12.m12.1.1.2" xref="S4.p1.12.m12.1.1.2.cmml"><mi id="S4.p1.12.m12.1.1.2.2" xref="S4.p1.12.m12.1.1.2.2.cmml">λ</mi><mrow id="S4.p1.12.m12.1.1.2.3" xref="S4.p1.12.m12.1.1.2.3.cmml"><mi id="S4.p1.12.m12.1.1.2.3.2" xref="S4.p1.12.m12.1.1.2.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.p1.12.m12.1.1.2.3.1" xref="S4.p1.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S4.p1.12.m12.1.1.2.3.3" xref="S4.p1.12.m12.1.1.2.3.3.cmml">v</mi></mrow></msub><mo id="S4.p1.12.m12.1.1.1" xref="S4.p1.12.m12.1.1.1.cmml">=</mo><mn id="S4.p1.12.m12.1.1.3" xref="S4.p1.12.m12.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.12.m12.1b"><apply id="S4.p1.12.m12.1.1.cmml" xref="S4.p1.12.m12.1.1"><eq id="S4.p1.12.m12.1.1.1.cmml" xref="S4.p1.12.m12.1.1.1"></eq><apply id="S4.p1.12.m12.1.1.2.cmml" xref="S4.p1.12.m12.1.1.2"><csymbol cd="ambiguous" id="S4.p1.12.m12.1.1.2.1.cmml" xref="S4.p1.12.m12.1.1.2">subscript</csymbol><ci id="S4.p1.12.m12.1.1.2.2.cmml" xref="S4.p1.12.m12.1.1.2.2">𝜆</ci><apply id="S4.p1.12.m12.1.1.2.3.cmml" xref="S4.p1.12.m12.1.1.2.3"><times id="S4.p1.12.m12.1.1.2.3.1.cmml" xref="S4.p1.12.m12.1.1.2.3.1"></times><ci id="S4.p1.12.m12.1.1.2.3.2.cmml" xref="S4.p1.12.m12.1.1.2.3.2">𝑢</ci><ci id="S4.p1.12.m12.1.1.2.3.3.cmml" xref="S4.p1.12.m12.1.1.2.3.3">𝑣</ci></apply></apply><cn type="integer" id="S4.p1.12.m12.1.1.3.cmml" xref="S4.p1.12.m12.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.12.m12.1c">\lambda_{uv}=1</annotation></semantics></math> and optimize <math id="S4.p1.13.m13.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S4.p1.13.m13.1a"><msub id="S4.p1.13.m13.1.1" xref="S4.p1.13.m13.1.1.cmml"><mi id="S4.p1.13.m13.1.1.2" xref="S4.p1.13.m13.1.1.2.cmml">T</mi><mrow id="S4.p1.13.m13.1.1.3" xref="S4.p1.13.m13.1.1.3.cmml"><mi id="S4.p1.13.m13.1.1.3.2" xref="S4.p1.13.m13.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.p1.13.m13.1.1.3.1" xref="S4.p1.13.m13.1.1.3.1.cmml">​</mo><mi id="S4.p1.13.m13.1.1.3.3" xref="S4.p1.13.m13.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p1.13.m13.1b"><apply id="S4.p1.13.m13.1.1.cmml" xref="S4.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.p1.13.m13.1.1.1.cmml" xref="S4.p1.13.m13.1.1">subscript</csymbol><ci id="S4.p1.13.m13.1.1.2.cmml" xref="S4.p1.13.m13.1.1.2">𝑇</ci><apply id="S4.p1.13.m13.1.1.3.cmml" xref="S4.p1.13.m13.1.1.3"><times id="S4.p1.13.m13.1.1.3.1.cmml" xref="S4.p1.13.m13.1.1.3.1"></times><ci id="S4.p1.13.m13.1.1.3.2.cmml" xref="S4.p1.13.m13.1.1.3.2">𝑢</ci><ci id="S4.p1.13.m13.1.1.3.3.cmml" xref="S4.p1.13.m13.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.13.m13.1c">T_{uv}</annotation></semantics></math> for 500 iterations (around 10 seconds).
We split <math id="S4.p1.14.m14.1" class="ltx_Math" alttext="\mathcal{M}_{tri}" display="inline"><semantics id="S4.p1.14.m14.1a"><msub id="S4.p1.14.m14.1.1" xref="S4.p1.14.m14.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p1.14.m14.1.1.2" xref="S4.p1.14.m14.1.1.2.cmml">ℳ</mi><mrow id="S4.p1.14.m14.1.1.3" xref="S4.p1.14.m14.1.1.3.cmml"><mi id="S4.p1.14.m14.1.1.3.2" xref="S4.p1.14.m14.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.p1.14.m14.1.1.3.1" xref="S4.p1.14.m14.1.1.3.1.cmml">​</mo><mi id="S4.p1.14.m14.1.1.3.3" xref="S4.p1.14.m14.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p1.14.m14.1.1.3.1a" xref="S4.p1.14.m14.1.1.3.1.cmml">​</mo><mi id="S4.p1.14.m14.1.1.3.4" xref="S4.p1.14.m14.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p1.14.m14.1b"><apply id="S4.p1.14.m14.1.1.cmml" xref="S4.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S4.p1.14.m14.1.1.1.cmml" xref="S4.p1.14.m14.1.1">subscript</csymbol><ci id="S4.p1.14.m14.1.1.2.cmml" xref="S4.p1.14.m14.1.1.2">ℳ</ci><apply id="S4.p1.14.m14.1.1.3.cmml" xref="S4.p1.14.m14.1.1.3"><times id="S4.p1.14.m14.1.1.3.1.cmml" xref="S4.p1.14.m14.1.1.3.1"></times><ci id="S4.p1.14.m14.1.1.3.2.cmml" xref="S4.p1.14.m14.1.1.3.2">𝑡</ci><ci id="S4.p1.14.m14.1.1.3.3.cmml" xref="S4.p1.14.m14.1.1.3.3">𝑟</ci><ci id="S4.p1.14.m14.1.1.3.4.cmml" xref="S4.p1.14.m14.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.14.m14.1c">\mathcal{M}_{tri}</annotation></semantics></math> into <math id="S4.p1.15.m15.1" class="ltx_Math" alttext="5(\gamma=5)" display="inline"><semantics id="S4.p1.15.m15.1a"><mrow id="S4.p1.15.m15.1.1" xref="S4.p1.15.m15.1.1.cmml"><mn id="S4.p1.15.m15.1.1.3" xref="S4.p1.15.m15.1.1.3.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.p1.15.m15.1.1.2" xref="S4.p1.15.m15.1.1.2.cmml">​</mo><mrow id="S4.p1.15.m15.1.1.1.1" xref="S4.p1.15.m15.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.p1.15.m15.1.1.1.1.2" xref="S4.p1.15.m15.1.1.1.1.1.cmml">(</mo><mrow id="S4.p1.15.m15.1.1.1.1.1" xref="S4.p1.15.m15.1.1.1.1.1.cmml"><mi id="S4.p1.15.m15.1.1.1.1.1.2" xref="S4.p1.15.m15.1.1.1.1.1.2.cmml">γ</mi><mo id="S4.p1.15.m15.1.1.1.1.1.1" xref="S4.p1.15.m15.1.1.1.1.1.1.cmml">=</mo><mn id="S4.p1.15.m15.1.1.1.1.1.3" xref="S4.p1.15.m15.1.1.1.1.1.3.cmml">5</mn></mrow><mo stretchy="false" id="S4.p1.15.m15.1.1.1.1.3" xref="S4.p1.15.m15.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.15.m15.1b"><apply id="S4.p1.15.m15.1.1.cmml" xref="S4.p1.15.m15.1.1"><times id="S4.p1.15.m15.1.1.2.cmml" xref="S4.p1.15.m15.1.1.2"></times><cn type="integer" id="S4.p1.15.m15.1.1.3.cmml" xref="S4.p1.15.m15.1.1.3">5</cn><apply id="S4.p1.15.m15.1.1.1.1.1.cmml" xref="S4.p1.15.m15.1.1.1.1"><eq id="S4.p1.15.m15.1.1.1.1.1.1.cmml" xref="S4.p1.15.m15.1.1.1.1.1.1"></eq><ci id="S4.p1.15.m15.1.1.1.1.1.2.cmml" xref="S4.p1.15.m15.1.1.1.1.1.2">𝛾</ci><cn type="integer" id="S4.p1.15.m15.1.1.1.1.1.3.cmml" xref="S4.p1.15.m15.1.1.1.1.1.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.15.m15.1c">5(\gamma=5)</annotation></semantics></math> body parts (i.e., trunk, left/right arm/leg) with cylinder UV unwarping. We use the Adam optimizer with learning rates of 0.01 and 0.001 for <math id="S4.p1.16.m16.1" class="ltx_Math" alttext="\Psi_{g}" display="inline"><semantics id="S4.p1.16.m16.1a"><msub id="S4.p1.16.m16.1.1" xref="S4.p1.16.m16.1.1.cmml"><mi mathvariant="normal" id="S4.p1.16.m16.1.1.2" xref="S4.p1.16.m16.1.1.2.cmml">Ψ</mi><mi id="S4.p1.16.m16.1.1.3" xref="S4.p1.16.m16.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p1.16.m16.1b"><apply id="S4.p1.16.m16.1.1.cmml" xref="S4.p1.16.m16.1.1"><csymbol cd="ambiguous" id="S4.p1.16.m16.1.1.1.cmml" xref="S4.p1.16.m16.1.1">subscript</csymbol><ci id="S4.p1.16.m16.1.1.2.cmml" xref="S4.p1.16.m16.1.1.2">Ψ</ci><ci id="S4.p1.16.m16.1.1.3.cmml" xref="S4.p1.16.m16.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.16.m16.1c">\Psi_{g}</annotation></semantics></math> and <math id="S4.p1.17.m17.1" class="ltx_Math" alttext="T_{uv}" display="inline"><semantics id="S4.p1.17.m17.1a"><msub id="S4.p1.17.m17.1.1" xref="S4.p1.17.m17.1.1.cmml"><mi id="S4.p1.17.m17.1.1.2" xref="S4.p1.17.m17.1.1.2.cmml">T</mi><mrow id="S4.p1.17.m17.1.1.3" xref="S4.p1.17.m17.1.1.3.cmml"><mi id="S4.p1.17.m17.1.1.3.2" xref="S4.p1.17.m17.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.p1.17.m17.1.1.3.1" xref="S4.p1.17.m17.1.1.3.1.cmml">​</mo><mi id="S4.p1.17.m17.1.1.3.3" xref="S4.p1.17.m17.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p1.17.m17.1b"><apply id="S4.p1.17.m17.1.1.cmml" xref="S4.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S4.p1.17.m17.1.1.1.cmml" xref="S4.p1.17.m17.1.1">subscript</csymbol><ci id="S4.p1.17.m17.1.1.2.cmml" xref="S4.p1.17.m17.1.1.2">𝑇</ci><apply id="S4.p1.17.m17.1.1.3.cmml" xref="S4.p1.17.m17.1.1.3"><times id="S4.p1.17.m17.1.1.3.1.cmml" xref="S4.p1.17.m17.1.1.3.1"></times><ci id="S4.p1.17.m17.1.1.3.2.cmml" xref="S4.p1.17.m17.1.1.3.2">𝑢</ci><ci id="S4.p1.17.m17.1.1.3.3.cmml" xref="S4.p1.17.m17.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.17.m17.1c">T_{uv}</annotation></semantics></math>, respectively.
Detailed network architectures can be found in the supplemental materials (Suppl).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>3D human generation</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> showcases several 3D human avatars synthesized by our pipeline, highlighting the image quality, geometry accuracy, and diverse outputs achieved through our method. Additionally, we explore the interpolation of the latent conditions to yield smooth transitions in appearance, leveraging the smooth latent space learned by our generative model.
For more synthesized examples and interpolation results, please refer to the Suppl.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2401.01173/assets/pic/compare7.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="370" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">Qualitative comparison with three state-of-the-art methods: EVA3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, AG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> and EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparisons</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.3" class="ltx_p"><span id="S4.SS2.p1.3.1" class="ltx_text ltx_font_bold">Qualitative comparison.</span>
In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1 3D human generation ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we compare our method with three baselines: EVA3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> and AG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, which are state-of-the-art methods for generating 3D humans from 2D images, and EG3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>, which serves as the foundational backbone of our method.
The results of first two methods are produced by directly using source codes and trained models released by authors. We train EG3D using our synthetic images with estimated cameras from scratch. As we can see, EVA3D fails to produce <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">360</mn><mo id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">360</cn><compose id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">360^{\circ}</annotation></semantics></math> humans with reasonable back inferring. AG3D and EG3D are able to generate <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">360</mn><mo id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">360</cn><compose id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">360^{\circ}</annotation></semantics></math> renderings but both struggle with photorealism and capturing detailed shapes.
Our method synthesizes not only higher-quality, view-consistent <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msup id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">360</mn><mo id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">360</cn><compose id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">360^{\circ}</annotation></semantics></math> images but also higher-fidelity 3D geometry with intricate details, such as irregular dresses and haircuts.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.6.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.7.2" class="ltx_text" style="font-size:90%;">Quantitative evaluation using FID, IS-360, normal accuracy (Normal) and identity consistency (ID).
</span></figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.4" class="ltx_tr">
<th id="S4.T1.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.4.5.1" class="ltx_text" style="font-size:90%;">Method</span></th>
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.1.1.1.1" class="ltx_text" style="font-size:90%;">FID </span><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.2.2.2.1" class="ltx_text" style="font-size:90%;">IS-360 </span><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.3.3.3.1" class="ltx_text" style="font-size:90%;">Normal </span><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.4.4.4.1" class="ltx_text" style="font-size:90%;">ID</span><math id="S4.T1.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.4.4.4.m1.1.1" xref="S4.T1.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.5.1" class="ltx_tr">
<td id="S4.T1.4.5.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T1.4.5.1.1.1" class="ltx_text" style="font-size:90%;">EVA3D </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.5.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a><span id="S4.T1.4.5.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.5.1.2.1" class="ltx_text" style="font-size:90%;">15.91</span></td>
<td id="S4.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.5.1.3.1" class="ltx_text" style="font-size:90%;">3.19</span></td>
<td id="S4.T1.4.5.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.5.1.4.1" class="ltx_text" style="font-size:90%;">30.81</span></td>
<td id="S4.T1.4.5.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.5.1.5.1" class="ltx_text" style="font-size:90%;">0.72</span></td>
</tr>
<tr id="S4.T1.4.6.2" class="ltx_tr">
<td id="S4.T1.4.6.2.1" class="ltx_td ltx_align_center">
<span id="S4.T1.4.6.2.1.1" class="ltx_text" style="font-size:90%;">AG3D </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.6.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a><span id="S4.T1.4.6.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.6.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.2.2.1" class="ltx_text" style="font-size:90%;">10.93</span></td>
<td id="S4.T1.4.6.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.2.3.1" class="ltx_text" style="font-size:90%;">3.28</span></td>
<td id="S4.T1.4.6.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.2.4.1" class="ltx_text" style="font-size:90%;">20.83</span></td>
<td id="S4.T1.4.6.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.2.5.1" class="ltx_text" style="font-size:90%;">0.69</span></td>
</tr>
<tr id="S4.T1.4.7.3" class="ltx_tr">
<td id="S4.T1.4.7.3.1" class="ltx_td ltx_align_center">
<span id="S4.T1.4.7.3.1.1" class="ltx_text" style="font-size:90%;">EG3D </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.7.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a><span id="S4.T1.4.7.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.7.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.3.2.1" class="ltx_text" style="font-size:90%;">7.48</span></td>
<td id="S4.T1.4.7.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.3.3.1" class="ltx_text" style="font-size:90%;">3.26</span></td>
<td id="S4.T1.4.7.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.3.4.1" class="ltx_text" style="font-size:90%;">12.74</span></td>
<td id="S4.T1.4.7.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.3.5.1" class="ltx_text" style="font-size:90%;">0.71</span></td>
</tr>
<tr id="S4.T1.4.8.4" class="ltx_tr">
<td id="S4.T1.4.8.4.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.8.4.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S4.T1.4.8.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.8.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2.73</span></td>
<td id="S4.T1.4.8.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.8.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.43</span></td>
<td id="S4.T1.4.8.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.8.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">5.62</span></td>
<td id="S4.T1.4.8.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.8.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.74</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.3" class="ltx_p"><span id="S4.SS2.p2.3.1" class="ltx_text ltx_font_bold">Quantitative comparison.</span>
Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Comparisons ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides quantitative results comparing our method against the baselines. We measure image quality with Frechet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> and Inception Score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> for <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msup id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">360</mn><mo id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">360</cn><compose id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">360^{\circ}</annotation></semantics></math> views (IS-360).
FID measures the visual similarity and distribution discrepancy between 50k generated images and all real images. IS-360 focuses on the self-realism of generated images in <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msup id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mn id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">360</mn><mo id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">360</cn><compose id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">360^{\circ}</annotation></semantics></math> views.
For shape evaluation, we compute FID between rendered normals and pseudo-GT normal maps (Normal), following AG3D. The FID and Normal scores of EVA3D and AG3D are directly fetched from their reports.
Additionally, we access the multi-view facial identity consistency using the ID metric introduced by EG3D.
Our method demonstrates significant improvements in FID and Normal, bringing the generative human model to a new level of realistic <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="360^{\circ}" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><msup id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mn id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">360</mn><mo id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">360</cn><compose id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">360^{\circ}</annotation></semantics></math> renderings with delicate geometry while also maintaining state-of-the-art view consistency.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation study</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_bold">Synthesis flow and patch-composed rendering.</span>
We assess the impact of our carefully designed synthesis flow by training a model with synthetic images but with camera and pose parameters estimated by SMPLify-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> (w/o SYN-P). As Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Ablation study ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows, the model w/o SYN-P results in worse FID and IS-360 scores, indicating that the synthesis flow contributes to more accurate physical parameters for realistic appearance modeling. By utilizing patch-composed rendering (PCR), the networks focus more on the human region, leading to more realistic results.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.5.2" class="ltx_text" style="font-size:90%;">
Results of models trained by replacing physical parameters with estimated ones (w/o SYN-P) or removing patch-composed rendering (w/o PCR).
</span></figcaption>
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.3.1" class="ltx_tr">
<th id="S4.T2.2.3.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.2.3.1.2.1" class="ltx_text" style="font-size:90%;">Ours</span></th>
<th id="S4.T2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.2.3.1.3.1" class="ltx_text" style="font-size:90%;">Ours-w/o SYN-P</span></th>
<th id="S4.T2.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.2.3.1.4.1" class="ltx_text" style="font-size:90%;">Ours-w/o PCR</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">
<span id="S4.T2.1.1.1.1" class="ltx_text" style="font-size:90%;">FID </span><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2.73</span></td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.3.1" class="ltx_text" style="font-size:90%;">4.28</span></td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.4.1" class="ltx_text" style="font-size:90%;">3.26</span></td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">
<span id="S4.T2.2.2.1.1" class="ltx_text" style="font-size:90%;">IS-360 </span><math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.2.2.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><ci id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>
</th>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.43</span></td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.2.3.1" class="ltx_text" style="font-size:90%;">3.31</span></td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.2.4.1" class="ltx_text" style="font-size:90%;">3.35</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2401.01173/assets/pic/ab_geo1.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="255" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;">Effects of the GS module to carve fine-grained surfaces. </span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Geometry sculpting module (GS).</span>
We demonstrate the importance of this module by visualizing the meshes before and after its implementation.
Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Ablation study ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (b) shows that the preceding module yields a coarse mesh due to the complex human anatomy and the challenges posed by decomposing ambiguous 3D shapes from 2D images.
The GS module utilizes high-quality multi-view outputs and employs a more flexible hybrid representation to create expressive humans with arbitrary topologies.
It learns from pixel-level surface supervision, leading to a significant improvement in shape quality, characterized by smooth surfaces and intricate outfits (Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Ablation study ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (c)).</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2401.01173/assets/pic/ab_tex1.png" id="S4.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.4.2" class="ltx_text" style="font-size:90%;">Effects of the ET module for guided synthesis.</span></figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Explicit texturing module (ET).</span>
This intuitive module not only extracts the explicit UV texture for complete 3D assets but also enables high-fidelity results for image guided synthesis. Following the flowchart in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Explicit texturing ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we compare the results produced with and without this module. Our method without ET directly generates implicit renderings through PTI inversion, as shown in Figure <a href="#S4.F7" title="Figure 7 ‣ 4.3 Ablation study ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (b). While it successfully preserves global identity, it struggles to synthesize highly faithful local textures (e.g., floral patterns). The ET module offers a convenient and efficient way to directly interact with the 3D representation, enabling the production of high-fidelity 3D humans with more consistent content including exquisite local patterns (Figure <a href="#S4.F7" title="Figure 7 ‣ 4.3 Ablation study ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (a, c)).</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Applications</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Avatar animation.</span>
All avatars produced by our method are in a canonical body pose and aligned to an underlying 3D skeleton extracted from SMPL-X. This alignment allows for easy animation and the generation of motion videos, as demonstrated in Figure <a href="#S0.F1" title="Figure 1 ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Suppl.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">Texture doodle and local editing.</span>
Our approach benefits from explicitly disentangled geometry and texture, enabling flexible editing capabilities. Following the flowchart of text or image guided synthesis (Section <a href="#S3.SS4" title="3.4 Inference ‣ 3 Method Description ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>), users can paint any pattern or add text to a guided image. These modifications can be transferred to 3D human models by inputting modified views into the texture module (e.g., painting the text ’hey’ on a jacket as shown in Figure <a href="#S0.F1" title="Figure 1 ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (d)). Our approach also allows for clothing editing by simultaneously injecting edited guide images with desired clothing into the GS and ET modules (e.g., changing a jacket and jeans to bodysuits in Figure <a href="#S0.F1" title="Figure 1 ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (e)). More results can be found in Suppl.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para ltx_noindent">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Content-style free adaption. </span>
Our proposed scheme is versatile and can be extended to generate various types of contents (e.g., portrait heads ) and styles (e.g., Disney cartoon characters). To achieve this, we fine-tune our model using synthetic images from these domains, allowing for flexible adaptation. We showcase the results in Figure <a href="#S4.F8" title="Figure 8 ‣ 4.4 Applications ‣ 4 Experimental Results ‣ En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. More results and other discussions (e.g., limitations, negative impact, etc.) can be found in Suppl.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2401.01173/assets/pic/extension.png" id="S4.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.4.2" class="ltx_text" style="font-size:90%;">Results synthesized by adapting our method to various styles (e.g., Disney cartoon characters) or contents (e.g., portrait heads).</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We introduced En3D, a novel generative scheme for sculpting 3D humans from 2D synthetic data.
This method overcomes limitations in existing 3D or 2D collections and significantly enhances the image quality, geometry accuracy, and content diversity of
generative 3D humans.
En3D comprises a 3D generative module that learns generalizable 3D humans from synthetic 2D data with accurate physical modeling, and two optimization modules to carve intricate shape details and disentangle explicit UV textures with high fidelity, respectively.
Experimental results validated the superiority and effectiveness of our method. We also demonstated the flexibility of our generated avatars for animation and editing, as well as the scalability of our approach for synthesizing portraits and Disney characters. We believe that our solution could provide invaluable human assets for the 3D vision community.
Furthermore, it holds potential for use in common 3D object synthesis tasks.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We would like to thank Mengyang Feng and Jinlin Liu for their technical support on guided 2D image synthesis.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Achlioptas et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">
Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">Learning representations and generative models for 3d point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib1.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on machine learning</em><span id="bib.bib1.11.3" class="ltx_text" style="font-size:90%;">, pages 40–49.
PMLR, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Alldieck et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Thiemo Alldieck, Marcus Magnor, Weipeng Xu, Christian Theobalt, and Gerard
Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Video based reconstruction of 3d people models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:90%;">, pages 8387–8397, 2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">An et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Sizhe An, Hongyi Xu, Yichun Shi, Guoxian Song, Umit Y. Ogras, and Linjie Luo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Panohead: Geometry-aware 3d full-head synthesis in 360deg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:90%;">, pages 20950–20959, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Anguelov et al. [2005]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
Dragomir Anguelov, Praveen Srinivasan, Daphne Koller, Sebastian Thrun, Jim
Rodgers, and James Davis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Scape: shape completion and animation of people.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib4.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM SIGGRAPH 2005 Papers</em><span id="bib.bib4.11.3" class="ltx_text" style="font-size:90%;">, pages 408–416. 2005.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Chan et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, and Gordon Wetzstein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">pi-gan: Periodic implicit generative adversarial networks for
3d-aware image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib5.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib5.11.3" class="ltx_text" style="font-size:90%;">, pages 5799–5809, 2021.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Chan et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini
De Mello, Orazio Gallo, Leonidas J Guibas, Jonathan Tremblay, Sameh Khamis,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">Efficient geometry-aware 3d generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib6.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib6.11.3" class="ltx_text" style="font-size:90%;">, pages 16123–16133, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Chen et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
Xu Chen, Tianjian Jiang, Jie Song, Jinlong Yang, Michael J Black, Andreas
Geiger, and Otmar Hilliges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">gdna: Towards generative detailed neural avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib7.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib7.11.3" class="ltx_text" style="font-size:90%;">, pages 20427–20437, 2022.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Deng et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Yu Deng, Jiaolong Yang, Jianfeng Xiang, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Gram: Generative radiance manifolds for 3d-aware image generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, pages 10673–10683, 2022.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Dong et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Zijian Dong, Chen Guo, Jie Song, Xu Chen, Andreas Geiger, and Otmar Hilliges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">Pina: Learning a personalized implicit neural avatar from a single
rgb-d video sequence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib9.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib9.11.3" class="ltx_text" style="font-size:90%;">, pages 20470–20480, 2022.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Dong et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Zijian Dong, Xu Chen, Jinlong Yang, Michael J Black, Otmar Hilliges, and
Andreas Geiger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">Ag3d: Learning to generate 3d avatars from 2d image collections.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib10.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2305.02312</em><span id="bib.bib10.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Feng et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
Yao Feng, Jinlong Yang, Marc Pollefeys, Michael J Black, and Timo Bolkart.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Capturing and animation of body and clothing from monocular video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib11.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">SIGGRAPH Asia 2022 Conference Papers</em><span id="bib.bib11.11.3" class="ltx_text" style="font-size:90%;">, pages 1–9, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Fu et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">
Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Chen Qian, Chen Change Loy,
Wayne Wu, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">Stylegan-human: A data-centric odyssey of human generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib12.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib12.11.3" class="ltx_text" style="font-size:90%;">, pages 1–19.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Goodfellow et al. [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib13.10.2" class="ltx_text" style="font-size:90%;">, 27, 2014.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Gu et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Jiatao Gu, Lingjie Liu, Peng Wang, and Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Stylenerf: A style-based 3d-aware generator for high-resolution image
synthesis.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib14.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.08985</em><span id="bib.bib14.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">He et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
Honglin He, Zhuoqian Yang, Shikai Li, Bo Dai, and Wayne Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">Orthoplanes: A novel representation for better 3d-awareness of gans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib15.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib15.11.3" class="ltx_text" style="font-size:90%;">, pages 22996–23007, 2023.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Henzler et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
Philipp Henzler, Niloy J Mitra, and Tobias Ritschel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Escaping plato’s cave: 3d shape from adversarial rendering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib16.11.3" class="ltx_text" style="font-size:90%;">, pages 9984–9993, 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Heusel et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
Hochreiter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">Gans trained by a two time-scale update rule converge to a local nash
equilibrium.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib17.10.2" class="ltx_text" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Hong et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Fangzhou Hong, Zhaoxi Chen, Yushi Lan, Liang Pan, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Eva3d: Compositional 3d human generation from 2d image collections.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2210.04888</em><span id="bib.bib18.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Jiang et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
Suyi Jiang, Haoran Jiang, Ziyu Wang, Haimin Luo, Wenzheng Chen, and Lan Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Humangen: Generating human radiance fields with explicit priors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, pages 12543–12554, 2023.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Jo et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
Kyungmin Jo, Wonjoon Jin, Jaegul Choo, Hyunjoon Lee, and Sunghyun Cho.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">3d-aware generative model for improved side-view image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib20.11.3" class="ltx_text" style="font-size:90%;">, pages 22862–22872, 2023.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Joo et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Hanbyul Joo, Tomas Simon, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Total capture: A 3d deformation model for tracking faces, hands, and
bodies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib21.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib21.11.3" class="ltx_text" style="font-size:90%;">, pages 8320–8329, 2018.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Kanazawa et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, Michael J Black, David W Jacobs, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">End-to-end recovery of human shape and pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib22.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</em><span id="bib.bib22.11.3" class="ltx_text" style="font-size:90%;">, pages 7122–7131, 2018.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Karras et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Samuli Laine, and Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">A style-based generator architecture for generative adversarial
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib23.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib23.11.3" class="ltx_text" style="font-size:90%;">, pages 4401–4410, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Karras et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Analyzing and improving the image quality of stylegan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib24.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib24.11.3" class="ltx_text" style="font-size:90%;">, pages 8110–8119, 2020.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Karras et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Miika Aittala, Samuli Laine, Erik Härkönen, Janne
Hellsten, Jaakko Lehtinen, and Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">Alias-free generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib25.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib25.10.2" class="ltx_text" style="font-size:90%;">,
34:852–863, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Laine et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Samuli Laine, Janne Hellsten, Tero Karras, Yeongho Seol, Jaakko Lehtinen, and
Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Modular primitives for high-performance differentiable rendering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib26.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics (TOG)</em><span id="bib.bib26.10.2" class="ltx_text" style="font-size:90%;">, 39(6):1–14, 2020.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Li et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Ruihui Li, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and Pheng-Ann Heng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">Pu-gan: a point cloud upsampling adversarial network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on
computer vision</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:90%;">, pages 7203–7212, 2019.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Liao et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Yiyi Liao, Katja Schwarz, Lars Mescheder, and Andreas Geiger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">Towards unsupervised learning of generative models for 3d
controllable image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib28.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib28.11.3" class="ltx_text" style="font-size:90%;">, pages 5871–5880, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Lingjie Liu, Marc Habermann, Viktor Rudnev, Kripasindhu Sarkar, Jiatao Gu, and
Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Neural actor: Neural free-view synthesis of human actors with pose
control.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib29.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM transactions on graphics (TOG)</em><span id="bib.bib29.10.2" class="ltx_text" style="font-size:90%;">, 40(6):1–16, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Loper et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J
Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">Smpl: A skinned multi-person linear model.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib30.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics</em><span id="bib.bib30.10.2" class="ltx_text" style="font-size:90%;">, 34(6), 2015.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.4.4.1" class="ltx_text" style="font-size:90%;">Lorensen and Cline [1998]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.6.1" class="ltx_text" style="font-size:90%;">
William E Lorensen and Harvey E Cline.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">Marching cubes: A high resolution 3d surface construction algorithm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib31.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Seminal graphics: pioneering efforts that shaped the field</em><span id="bib.bib31.10.3" class="ltx_text" style="font-size:90%;">,
pages 347–353. 1998.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Ma et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
Qianli Ma, Jinlong Yang, Anurag Ranjan, Sergi Pujades, Gerard Pons-Moll, Siyu
Tang, and Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Learning to dress 3d people in generative clothing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib32.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib32.11.3" class="ltx_text" style="font-size:90%;">, pages 6469–6478, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Mescheder et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text" style="font-size:90%;">Which training methods for gans do actually converge?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib33.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on machine learning</em><span id="bib.bib33.11.3" class="ltx_text" style="font-size:90%;">, pages
3481–3490. PMLR, 2018.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Mildenhall et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">
Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi
Ramamoorthi, and Ren Ng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text" style="font-size:90%;">Nerf: Representing scenes as neural radiance fields for view
synthesis.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib34.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Communications of the ACM</em><span id="bib.bib34.10.2" class="ltx_text" style="font-size:90%;">, 65(1):99–106,
2021.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Nguyen-Phuoc et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang
Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">Hologan: Unsupervised learning of 3d representations from natural
images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib35.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib35.11.3" class="ltx_text" style="font-size:90%;">, pages 7588–7597, 2019.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Nguyen-Phuoc et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">
Thu H Nguyen-Phuoc, Christian Richardt, Long Mai, Yongliang Yang, and Niloy
Mitra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">Blockgan: Learning 3d object-aware scene representations from
unlabelled images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib36.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib36.10.2" class="ltx_text" style="font-size:90%;">,
33:6767–6778, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.4.4.1" class="ltx_text" style="font-size:90%;">Niemeyer and Geiger [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">
Michael Niemeyer and Andreas Geiger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">Giraffe: Representing scenes as compositional generative neural
feature fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib37.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib37.10.3" class="ltx_text" style="font-size:90%;">, pages 11453–11464, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Niemeyer et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">
Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text" style="font-size:90%;">Differentiable volumetric rendering: Learning implicit 3d
representations without 3d supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib38.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib38.11.3" class="ltx_text" style="font-size:90%;">, pages 3504–3515, 2020.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Or-El et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
Roy Or-El, Xuan Luo, Mengyi Shan, Eli Shechtman, Jeong Joon Park, and Ira
Kemelmacher-Shlizerman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">Stylesdf: High-resolution 3d-consistent image and geometry
generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib39.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib39.11.3" class="ltx_text" style="font-size:90%;">, pages 13503–13513, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Osman et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">
Ahmed AA Osman, Timo Bolkart, and Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">Star: Sparse trained articulated human body regressor.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib40.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2020: 16th European Conference,
Glasgow, UK, August 23–28, 2020, Proceedings, Part VI 16</em><span id="bib.bib40.11.3" class="ltx_text" style="font-size:90%;">, pages 598–613.
Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Palafox et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">
Pablo Palafox, Aljaž Božič, Justus Thies, Matthias
Nießner, and Angela Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">Npms: Neural parametric models for 3d deformable shapes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib41.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib41.11.3" class="ltx_text" style="font-size:90%;">, pages 12695–12705, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Park et al. [2019a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">
Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
Lovegrove.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">Deepsdf: Learning continuous signed distance functions for shape
representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib42.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib42.11.3" class="ltx_text" style="font-size:90%;">, pages 165–174, 2019a.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Park et al. [2019b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">Semantic image synthesis with spatially-adaptive normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib43.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib43.11.3" class="ltx_text" style="font-size:90%;">, pages 2337–2346, 2019b.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Pavlakos et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA
Osman, Dimitrios Tzionas, and Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">Expressive body capture: 3d hands, face, and body from a single
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib44.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib44.11.3" class="ltx_text" style="font-size:90%;">, pages 10975–10985, 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Peng et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
Sida Peng, Yuanqing Zhang, Yinghao Xu, Qianqian Wang, Qing Shuai, Hujun Bao,
and Xiaowei Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">Neural body: Implicit neural representations with structured latent
codes for novel view synthesis of dynamic humans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib45.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib45.11.3" class="ltx_text" style="font-size:90%;">, pages 9054–9063, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Roich et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">
Daniel Roich, Ron Mokady, Amit H Bermano, and Daniel Cohen-Or.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">Pivotal tuning for latent-based editing of real images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib46.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on graphics (TOG)</em><span id="bib.bib46.10.2" class="ltx_text" style="font-size:90%;">, 42(1):1–13, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Rombach et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn
Ommer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">High-resolution image synthesis with latent diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib47.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em><span id="bib.bib47.11.3" class="ltx_text" style="font-size:90%;">, pages 10684–10695, 2022.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Salimans et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
Xi Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">Improved techniques for training gans.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib48.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib48.10.2" class="ltx_text" style="font-size:90%;">, 29, 2016.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Schwarz et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">
Katja Schwarz, Yiyi Liao, Michael Niemeyer, and Andreas Geiger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">Graf: Generative radiance fields for 3d-aware image synthesis.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib49.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">,
33:20154–20166, 2020.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Szabó et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">
Attila Szabó, Givi Meishvili, and Paolo Favaro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.8.1" class="ltx_text" style="font-size:90%;">Unsupervised generative 3d shape learning from natural images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib50.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.00287</em><span id="bib.bib50.10.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Wang et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:90%;">
Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping
Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text" style="font-size:90%;">Neus: Learning neural implicit surfaces by volume rendering for
multi-view reconstruction.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib51.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.10689</em><span id="bib.bib51.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Weng et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">
Chung-Yi Weng, Brian Curless, Pratul P Srinivasan, Jonathan T Barron, and Ira
Kemelmacher-Shlizerman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:90%;">Humannerf: Free-viewpoint rendering of moving people from monocular
video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib52.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision
and pattern Recognition</em><span id="bib.bib52.11.3" class="ltx_text" style="font-size:90%;">, pages 16210–16220, 2022.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">Wu et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:90%;">
Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">Learning a probabilistic latent space of object shapes via 3d
generative-adversarial modeling.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib53.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib53.10.2" class="ltx_text" style="font-size:90%;">, 29, 2016.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:90%;">Xiu et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:90%;">
Yuliang Xiu, Jinlong Yang, Dimitrios Tzionas, and Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.8.1" class="ltx_text" style="font-size:90%;">Icon: Implicit clothed humans obtained from normals.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib54.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em><span id="bib.bib54.11.3" class="ltx_text" style="font-size:90%;">, pages 13286–13296. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.5.5.1" class="ltx_text" style="font-size:90%;">Xue et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:90%;">
Yang Xue, Yuheng Li, Krishna Kumar Singh, and Yong Jae Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.8.1" class="ltx_text" style="font-size:90%;">Giraffe hd: A high-resolution 3d-aware generative model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib55.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib55.11.3" class="ltx_text" style="font-size:90%;">, pages 18440–18449, 2022.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">Yang et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:90%;">
Zhuoqian Yang, Shikai Li, Wayne Wu, and Bo Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:90%;">3dhumangan: 3d-aware human image generation with 3d pose mapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib56.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib56.11.3" class="ltx_text" style="font-size:90%;">, pages 23008–23019, 2023.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Yariv et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text" style="font-size:90%;">
Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text" style="font-size:90%;">Volume rendering of neural implicit surfaces.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib57.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib57.10.2" class="ltx_text" style="font-size:90%;">,
34:4805–4815, 2021.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.5.5.1" class="ltx_text" style="font-size:90%;">Zhang et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text" style="font-size:90%;">
Jianfeng Zhang, Zihang Jiang, Dingdong Yang, Hongyi Xu, Yichun Shi, Guoxian
Song, Zhongcong Xu, Xinchao Wang, and Jiashi Feng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.8.1" class="ltx_text" style="font-size:90%;">Avatargen: a 3d generative model for animatable human avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib58.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib58.11.3" class="ltx_text" style="font-size:90%;">, pages 668–685.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text" style="font-size:90%;">Zhang et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text" style="font-size:90%;">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.8.1" class="ltx_text" style="font-size:90%;">Adding conditional control to text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib59.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em><span id="bib.bib59.11.3" class="ltx_text" style="font-size:90%;">, pages 3836–3847, 2023.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.5.5.1" class="ltx_text" style="font-size:90%;">Zhou et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text" style="font-size:90%;">
Peng Zhou, Lingxi Xie, Bingbing Ni, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text" style="font-size:90%;">Cips-3d: A 3d-aware generator of gans based on
conditionally-independent pixel synthesis.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib60.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.09788</em><span id="bib.bib60.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.5.5.1" class="ltx_text" style="font-size:90%;">Zhu et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.7.1" class="ltx_text" style="font-size:90%;">
Peihao Zhu, Rameen Abdal, Yipeng Qin, and Peter Wonka.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.8.1" class="ltx_text" style="font-size:90%;">Sean: Image synthesis with semantic region-adaptive normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib61.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib61.11.3" class="ltx_text" style="font-size:90%;">, pages 5104–5113, 2020.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.01172" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.01173" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.01173">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.01173" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.01174" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 07:36:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
