<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications</title>
<!--Generated on Fri Oct 11 18:00:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Oct 7, 2024.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.09168v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S1" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S2" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Why the Future of LLM Training might be Combining Real and Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data Strategy: Building a 500-Session Training Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS1" title="In 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Real Data: 300+ Scraped and Transcribed Counseling Sessions</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS1.SSS1" title="In 3.1 Real Data: 300+ Scraped and Transcribed Counseling Sessions ‣ 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Data Source</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS1.SSS2" title="In 3.1 Real Data: 300+ Scraped and Transcribed Counseling Sessions ‣ 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Data Processing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS2" title="In 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Synthetic Persona Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS3" title="In 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Creating Therapy Situations Based on Personas and Themes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS4" title="In 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Generating High-Quality Synthetic Sessions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S3.SS5" title="In 3 Data Strategy: Building a 500-Session Training Dataset ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Data Evaluation and Cleanup</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Performance Analysis of Empathy and Relevance in Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4.SS1" title="In 4 Performance Analysis of Empathy and Relevance in Models ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Model Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4.SS2" title="In 4 Performance Analysis of Empathy and Relevance in Models ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Quantitative Measurement Approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4.SS3" title="In 4 Performance Analysis of Empathy and Relevance in Models ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Overall Insights from Model Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4.SS4" title="In 4 Performance Analysis of Empathy and Relevance in Models ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Visualizing Model Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S4.SS5" title="In 4 Performance Analysis of Empathy and Relevance in Models ‣ Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Initial Qualitative Testing and Real-World Validation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S5" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Impact of Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#S6" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Future Directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#A1" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix - Scenarios Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#A2" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Appendix - Synthetic Conversation Example</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#A3" title="In Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Appendix - LLM Prompt (one of the earlier versions)</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alexey Zhezherau M.Mgmt, Alexei Yanockin MSc
</span></span>
</div>
<div class="ltx_dates">(Oct 7, 2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">This research explores a hybrid approach to fine-tuning large language models (LLMs) by integrating real-world and synthetic data, with the goal of enhancing model performance, particularly in generating accurate and contextually relevant responses. Leveraging a dataset that combines transcribed real interactions with high-quality synthetic sessions, we aimed to overcome the limitations of scarce, noisy, and domain-specific real data by using synthetic personas and scenarios to enrich training diversity. The study evaluated three models: a base foundational model, a model fine-tuned with real data, and a hybrid fine-tuned model. Experimental results demonstrated that the hybrid model consistently outperformed the others in specific vertical applications, achieving the highest scores across all metrics. Further testing confirmed the hybrid model’s superior adaptability and contextual understanding across diverse scenarios. The findings indicate that combining real and synthetic data offers significant advantages in improving the robustness and contextual sensitivity of LLMs, especially in domain-specific and vertical use cases.</p>
<br class="ltx_break"/>
<p class="ltx_p" id="id2.id2"><span class="ltx_text ltx_font_bold" id="id2.id2.1">Keywords:</span> Large Language Models, Mental Health, Generative AI, LLM Fine-Tuning, Synthetic Data Generation, Natural Language Processing, Few-shot Learning, Prompt Engineering, Model Evaluation</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The introduction of the Transformer architecture, as presented in the foundational paper <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">Attention Is All You Need</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib1" title="">1</a>]</cite>, fundamentally reshaped the landscape of natural language processing (NLP) and generative AI by shifting away from traditional recurrent and convolutional architectures. Transformers introduced the concept of self-attention mechanisms, which allowed models to weigh the relevance of different words in a sequence simultaneously, leading to better contextual understanding and parallelizability in training. This innovation provided the foundation for subsequent breakthroughs in large language models (LLMs), such as OpenAI’s GPT, Google’s BERT, and open-source players, which marked a new era in language understanding and generation.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Since the introduction of Transformers, significant advancements have continued to shape the field. Generative Pre-trained Transformers (GPT) models, especially GPT-3, demonstrated that scaling model size and data volume could significantly enhance language capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib2" title="">2</a>]</cite>. This scaling law, alongside innovations such as sparse attention mechanisms and parameter-efficient fine-tuning, allowed models like LLaMA and ChatGPT to further push the boundaries of what is achievable in NLP.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">AI’s progress is driven by three pillars: compute, foundational model advancements, and data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib3" title="">3</a>]</cite>. Compute power enables AI to process vast amounts of information, while cutting-edge algorithms provide new learning techniques and methods to optimize performance. However, the competitive edge for companies increasingly lies in data ownership and quality. Data is the key resource that fuels AI’s learning and adaptability across various scenarios. Leading companies have already exhausted publicly available web data, and this approach is reaching its limits. The next step involves accessing unique, high-quality datasets and finding innovative ways to improve training data through hybrid methods.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This research aims to address the following question: Can we accelerate model fine-tuning and improve large language models ability to generate accurate, contextually appropriate responses by fine-tuning it with both real-world and synthetic data? The hypothesis is that this hybrid approach will outperform models trained solely on real-world data or those relying on sophisticated prompt engineering with a base model. By integrating synthetic data, the aim is to make the model more versatile and capable of generalizing across diverse contexts.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">High-quality, diverse real-world data for specific use cases is often scarce, expensive to collect, and may not cover all scenarios required for domain-specific applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib4" title="">4</a>]</cite>. By supplementing real data with synthetic data, we may be able to fine-tune AI models more effectively and efficiently, ensuring that the resulting models can handle both common and edge-case scenarios.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this paper, we describe the development of a unique training dataset and the instruction-based fine-tuning of a large language model. We use the CBT Therapy Counselor project as an example, but the principles apply to numerous fields. By demonstrating how synthetic data can fill gaps left by real data, we hope to show the broader utility of hybrid training strategies in advancing large language models.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Why the Future of LLM Training might be Combining Real and Synthetic Data</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Real-world data is invaluable but has limitations: it is often messy, incomplete, and narrow in scope. Synthetic data can address some of these challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib7" title="">7</a>]</cite>:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Scalability:</span> Generate large volumes of diverse data rapidly. Synthetic data generation allows for quick creation of relevant training examples, enabling a more efficient training process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib5" title="">5</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib6" title="">6</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Customization:</span> Create scenarios tailored to specific use cases. Synthetic data can be designed to replicate rare or important scenarios that may not occur frequently enough in real datasets.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Edge Cases:</span> Produce examples of rare but critical situations. Addressing these edge cases is crucial for models that need to be robust and capable of handling unexpected or uncommon inputs.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">This approach is particularly valuable in domain-specific applications where exposing the model to a wide range of specific scenarios and interactions is crucial <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib8" title="">8</a>]</cite>. Recent work by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib9" title="">9</a>]</cite> has emphasized the importance of explainable LLMs, particularly in sensitive contexts such as mental health, which benefits from the diverse exposure that hybrid training can provide. Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib10" title="">10</a>]</cite> have illustrated how LLM-powered chatbots for psychiatric simulations can be improved through exposure to both real and synthetic conversational data. Such hybrid approaches enrich the model’s ability to understand nuances that purely real data may not provide due to inherent limitations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib5" title="">5</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Our experiments indicate that this hybrid approach consistently outperformed models trained solely on real-world data and those that relied solely on sophisticated prompt engineering with a base model. The use of synthetic data as a complementary training tool—especially in sensitive domains such as mental health, as discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib13" title="">13</a>]</cite> — allowed us to expand the model’s capabilities, making it more flexible and better suited to handling complex, varied inputs. Moreover, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib14" title="">14</a>]</cite> have highlighted the increasing relevance of synthetic data in mental health care, suggesting that synthetic sessions can serve as effective supplements when real-world examples are either scarce or ethically challenging to obtain.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data Strategy: Building a 500-Session Training Dataset</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Real Data: 300+ Scraped and Transcribed Counseling Sessions</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To develop the AI Therapy Counselor, over 300 actual counseling sessions were collected, which provided a substantial dataset for model training and evaluation. The sessions encompassed a variety of counseling techniques, topics, and different approaches to client interaction, allowing the AI to be exposed to a diverse range of real-world counseling examples.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Data Source</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">CBT therapy session role-play transcriptions were scraped from a well-known video hosting platform, providing diverse, publicly available therapy simulations. These sessions covered a broad range of topics, including stress management, anxiety, relationship issues, and personal growth, ensuring that the data had enough variety to serve as a strong foundation for model training. This variety was crucial in ensuring the model’s ability to handle a wide spectrum of conversational themes and challenges.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data Processing</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">The transcriptions underwent rigorous preprocessing inspired by data preparation techniques described in foundational researches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib15" title="">15</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib16" title="">16</a>]</cite>. This involved segmentation, and filtering steps to ensure consistency and dataset quality. Identifying information, noise, and redundant elements were meticulously removed, and dialogues were segmented into question-answer pairs, much like the comprehensive data preprocessing strategies employed by RoBERTa to enhance model robustness.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">Each dialogue was further enriched through the analysis of key conversational cues, therapist interventions, and emotional indicators, leveraging insights from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib17" title="">17</a>]</cite>. These annotations facilitated more nuanced learning during the training phase, enabling the model to understand not only the content but also the contextual and emotional dynamics of conversations, ultimately improving downstream performance. Techniques for deduplication and quality filtering from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib18" title="">18</a>]</cite> GPT-3 work (2020) were also integrated to eliminate redundancy and ensure data reliability, providing a high-quality foundation for fine-tuning.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.1">To mitigate biases and reduce noise, extensive preprocessing and filtering were applied, as outlined in the EleutherAI research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib19" title="">19</a>]</cite>. This ensured that the dataset was of high quality, anchoring the AI model in realistic scenarios that set the groundwork for subsequent synthetic data augmentation. By grounding the model in meticulously cleaned and authentic real-world data, we provided an initial level of context-specific knowledge and authenticity, which was further enhanced through synthetic sessions. This foundational approach allowed the model to build a broader understanding through synthetic augmentation, leading to an AI system that is both versatile and deeply informed by real-world context.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Synthetic Persona Generation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To address the limitations of real-world data, a set of synthetic personas and counseling themes was created. These imaginary clients were diverse in backgrounds, personalities, and issues, ensuring the AI learned to interact with a wide variety of people. The diversity of personas allowed the model to generalize better across different types of users and situations, making it more adaptable and flexible.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The flow chart below gives an overview of how synthetic therapy sessions were created, showing the steps involved in generating and refining the data.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="95" id="S3.F1.g1" src="extracted/5920511/synthetic-session-pipeline.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Flowchart showing the steps involved in generating and refining synthetic therapy sessions.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Drawing from research insights in ZeroGen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib20" title="">20</a>]</cite>, the quality of synthetic personas and overall synthetic data generation was also evaluated based on metrics such as diversity, correctness, and naturalness. Diversity was a critical consideration, ensuring that the generated personas differed significantly in terms of demographic and psychological characteristics. This diversity allowed the model to encounter a wide spectrum of scenarios, similar to those observed in real-world counseling. Correctness was assessed to ensure that the synthetic personas and their corresponding scenarios accurately reflected the intended themes and therapeutic contexts. Naturalness was measured to confirm that the interactions and characteristics of the personas were plausible and resembled real human behavior, thereby enhancing the realism of the training data.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Each synthetic persona was designed with specific traits, including age, occupation, cultural background, and unique personal challenges. These elements were instrumental in crafting therapy scenarios that would be representative of real-world complexities while also allowing us to target particular therapeutic needs. By incorporating the ZeroGen methodology for evaluating synthetic data quality, we ensured that the generated personas were not only diverse and relevant but also contextually rich and realistic, ultimately providing a more robust foundation for training the AI model.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Creating Therapy Situations Based on Personas and Themes</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">A script generated unique therapy scenarios for each synthetic persona, designed to reflect a broad spectrum of challenges individuals might face. This diversity provided the AI model with a range of learning contexts, helping it generalize more effectively. Each scenario was crafted to include distinct personal challenges, emotional nuances, and psychological responses, ensuring that the model could experience realistic and varied situations. This detailed approach made the synthetic personas more lifelike and the resulting scenarios more intricate, ultimately enhancing the model’s ability to manage complex and nuanced interactions. More examples are available in the appendix. For example:</p>
<blockquote class="ltx_quote" id="S3.SS3.p1.2">
<p class="ltx_p" id="S3.SS3.p1.2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.2.1.1">Summary:</span> This scenario focuses on the challenges faced by young adults in managing ADHD in both academic and social settings. It highlights common cognitive distortions that can exacerbate their difficulties.</p>
<p class="ltx_p" id="S3.SS3.p1.2.2"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.2.2.1">Cognitive Distortions:</span> Mind Reading, Jumping to Conclusions</p>
<p class="ltx_p" id="S3.SS3.p1.2.3"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.2.3.1">Scenario:</span> Emily is a 22-year-old college student at a large university in New York City. She was diagnosed with ADHD during her sophomore year. Despite starting medication and attending therapy sessions, she faces overwhelming anxiety and self-doubt about her academic performance and social interactions. Recently, Emily had a hard time completing a group project because she felt that her suggestions were ignored by her teammates. During their last meeting, Emily perceived that her teammates’ silence meant they thought her ideas were foolish (Mind Reading). Due to this belief, Emily withdrew from contributing further, convinced that she was right and that they didn’t value her input. Additionally, she received a 75% on her latest exam, lower than her usual grades. She immediately thought that this slip meant she would fail the course and, eventually, be unable to graduate (Jumping to Conclusions). These thoughts have led Emily to consider skipping classes and withdrawing from social interactions altogether.</p>
</blockquote>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Generating High-Quality Synthetic Sessions</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Using a script leveraging a large language model (LLM), detailed therapy sessions were generated based on the synthetic personas and scenarios. These sessions varied in length and covered a broad range of issues, helping the AI model learn to be flexible and responsive. Each session was structured to resemble real therapy interactions, with conversational depth and variability. To enhance the quality of these generated sessions, we used a few-shot learning technique similar to that described in work on scaling instruction-fine tuned language models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib5" title="">5</a>]</cite>. By providing a few high-quality examples during generation, the model was better equipped to produce contextually appropriate and realistic responses.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The synthetic data generation process drew inspiration from multiple research approaches. Following ideas from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib11" title="">11</a>]</cite>, we emphasized generating high-quality, diverse datasets to improve the robustness of model training. The generated sessions incorporated a variety of therapeutic topics and approaches, enabling the model to learn from a comprehensive set of examples.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">The script ensured that generated conversations included different therapeutic techniques such as Socratic questioning, cognitive restructuring, reflective listening, and 16 other CBT techniques. This approach was combined with quality assurance steps inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib12" title="">12</a>]</cite>, focusing on consistency in synthetic data production, ultimately providing a realistic simulation of therapist-client interactions and exposing the model to effective therapeutic methods, thereby enhancing the robustness of the trained AI model.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Data Evaluation and Cleanup</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">To ensure quality, a script used an LLM to rank and evaluate each session based on coherence, realism, and therapeutic value. Similar to the <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib21" title="">21</a>]</cite> approach, this involved introducing a separate quality estimation model within the data generation pipeline. Sessions flagged for issues were manually reviewed to improve dialogue flow, remove inconsistencies, and ensure adherence to best practices. This combined automated and manual review ensured high dataset quality.</p>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.1"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09168v1#bib.bib21" title="">21</a>]</cite> suggests incorporating a quality estimation module where initially generated synthetic data are evaluated by a task-specific model, trained on oracle data beforehand. Inspired by this methodology, our evaluation script selected the most influential synthetic samples, ensuring that only high-quality data was retained for fine-tuning. Manual cleanup involved reviewing flagged sessions for unnatural phrasing, logical errors, or inconsistencies in therapeutic techniques. By focusing on both machine-assisted evaluations and human expertise, we ensured that the training data was of the highest quality, allowing for a more robust and capable AI model.</p>
</div>
<div class="ltx_para" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">The final dataset consisted of 500 diverse therapy sessions, combining real and synthetic data for fine-tuning the AI model. This mix exposed the model to various scenarios, including common and rare cases, leading to improved performance and adaptability. By integrating synthetic sessions that filled in gaps left by real data, we expanded the model’s training scope, allowing it to learn from a richer set of examples.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Performance Analysis of Empathy and Relevance in Models</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Model Selection</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To evaluate the efficacy of the different fine-tuning approaches, all three models were used to assess the impact of different training data approaches. All three models used the same standardized prompt for consistency during testing:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Base Foundational Model</span> (GPT-4o-mini): This model was used without any additional fine-tuning, relying solely on sophisticated prompt engineering for its responses.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Real-Data Fine-Tuned Model:</span> The GPT-4o-mini model was fine-tuned using a dataset of real-world counselor sessions. This dataset comprised transcribed sessions, providing realistic therapy interaction contexts.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Hybrid Fine-Tuned Model:</span> The GPT-4o-mini model was further fine-tuned using a combination of real data and synthetically generated scenarios. The synthetic data was created to expand the diversity of situations beyond those captured by the real-world sessions.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Quantitative Measurement Approach</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To quantitatively evaluate these models, the following steps were taken:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Dataset Creation:</span> A dataset containing 50 unique therapeutic situations was constructed. These scenarios involved various patient issues, such as anxiety, cognitive distortions, and interpersonal challenges.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Simulated Conversations:</span> Each of the 50 therapeutic situations was used to simulate a conversation with each of the three models. The patient side of the conversation was represented by GPT-4o, ensuring consistency across the simulated interactions. This resulted in a total of 150 therapy conversations (50 per model).</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Scoring Methodology:</span> Each of the 150 conversations was scored for both empathy and relevance. A comprehensive scoring prompt was used to evaluate the quality of responses, ensuring a consistent and thorough assessment.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">Data Analysis:</span> The scores obtained from each conversation were summarized and analyzed to assess the models’ overall performance, both in terms of average scores and consistency. This analysis provided insights into the strengths and weaknesses of each approach in fostering effective therapeutic communication.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The hybrid-trained model demonstrated the highest average scores in both empathy and relevance, scoring 8.64 and 8.66, respectively, compared to 8.48 (empathy) and 8.08 (relevance) for the base model, and 7.32 (empathy) and 7.24 (relevance) for the real-data model. These results suggest that combining real and synthetic data allows for a more nuanced understanding of user input, resulting in improved conversational empathy and relevance.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="64" id="S4.F2.g1" src="extracted/5920511/model_performance_summary.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Model Performance Summary</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">The poorer performance of the real-data fine-tuned model can be attributed to several factors. First, real-world data often contains inconsistencies, noise, and limited coverage of edge cases, which can hinder the model’s ability to generalize effectively across diverse scenarios. Additionally, real-world therapeutic interactions may be narrow in scope, focusing on common or general cases rather than encompassing the full spectrum of potential therapeutic situations. As a result, the model fine-tuned solely on real data may lack the flexibility and comprehensiveness required to handle less typical, yet important, user inputs effectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Overall Insights from Model Analysis</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The analysis revealed several key insights regarding the comparative performance of the models:</p>
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1">The hybrid model exhibited the highest average and median scores in empathy, relevance, and combined metrics, highlighting its overall superiority in delivering high-quality responses.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1">Interestingly, the base model demonstrated the most consistent scores in terms of empathy, relevance, and combined metrics. This consistency could be attributed to the inherent stability of the foundational model without the added variability introduced by specific fine-tuning processes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1">The real-data model, while trained on authentic counseling sessions, showed considerable variability in performance, which can be linked to the noisy and often inconsistent nature of real-world data. This variability resulted in less predictable outcomes, particularly in comparison to the base and hybrid models.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">These insights suggest that while real-data fine-tuning offers contextual authenticity, it also introduces unpredictability that may undermine performance consistency. The hybrid approach, by incorporating diverse synthetic data, mitigates some of these issues, resulting in improved and more consistent outputs overall. However, it is also possible that the hybrid model may be over-fitting in rare cases, especially when the synthetic data does not fully encompass the range of real-world variability. To address this, a more diverse set of synthetic data could be beneficial, ensuring that the model maintains robustness without overfitting to specific, less common scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Visualizing Model Performance</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Figure 3 and Figure 4 provide a distribution of scores across models, highlighting the variability and overall performance differences between the base, real-data, and hybrid models. The distribution of scores for empathy and relevance clearly shows that the hybrid approach yielded more consistent high scores with fewer outliers, compared to the higher variability in the real-data model. This difference in consistency highlights how a broader training dataset, enriched with synthetic scenarios, can stabilize the model’s behavior in conversations that require emotional intelligence and context sensitivity.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S4.F3.g1" src="extracted/5920511/distribution_of_scores_by_model.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Distribution of Scores by Model</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="399" id="S4.F4.g1" src="extracted/5920511/distribution_of_scores_by_model_violin.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Distribution of Scores by Model, Violin chart</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">In Figures 5 to 7, the average empathy and relevance scores of each model are presented visually, along with a scatter plot chart explaining the detailed distribution of scores across all three models. The scatter plot provides a clear illustration of how each model’s responses vary, highlighting the hybrid model’s superior performance in terms of both empathy and relevance, as well as its consistency in delivering contextually appropriate and empathetic responses. This consistency is particularly important in therapeutic scenarios, where accurate and empathetic communication can significantly impact user experience and effectiveness.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="426" id="S4.F5.g1" src="extracted/5920511/empathy_vs_relevance_scores.png" width="533"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Empathy vs Relevance Scores</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S4.F6.g1" src="extracted/5920511/relevance_scores_by_model.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Relevance Scores by Model</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S4.F7.g1" src="extracted/5920511/empathy_scores_by_model.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Empathy Scores by Model</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Initial Qualitative Testing and Real-World Validation</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">To complement the quantitative findings, approximately 200 real conversations between users and the AI Therapy Counselor were analyzed, revealing valuable insights into the comparative performance of the models.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">Based on the initial testing, the model trained with a hybrid approach demonstrated superior performance compared to the other models. It displayed a deeper understanding of the therapy framework, utilized therapeutic tactics more effectively, and provided contextually appropriate responses. The integration of synthetic data appeared to fill in critical gaps, enhancing the model’s capacity to handle a wider variety of scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">A significant improvement noted during qualitative testing was the hybrid model’s management of longer conversations. The model demonstrated an ability to recognize when to transition between topics or suggest concluding a session, which is a crucial aspect of effective therapy communication. This real-world validation confirmed the earlier findings, with the hybrid-trained model outperforming the other models.</p>
</div>
<div class="ltx_para" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1">The hybrid model showed marked improvements in several key areas:</p>
<ul class="ltx_itemize" id="S4.I4">
<li class="ltx_item" id="S4.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i1.p1">
<p class="ltx_p" id="S4.I4.i1.p1.1">Identifying and addressing unhelpful cognitive patterns.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i2.p1">
<p class="ltx_p" id="S4.I4.i2.p1.1">Providing empathetic responses tailored to each user’s situation.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i3.p1">
<p class="ltx_p" id="S4.I4.i3.p1.1">Maintaining consistency during extended conversations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I4.i4.p1">
<p class="ltx_p" id="S4.I4.i4.p1.1">Recommending effective therapy techniques and exercises.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS5.p5">
<p class="ltx_p" id="S4.SS5.p5.1">These qualitative observations are consistent with the quantitative analysis, further reinforcing the effectiveness of the hybrid approach. The combination of real and synthetic data not only resulted in the highest average scores but also provided substantial improvements in practical conversational scenarios, as highlighted in real-world testing. The qualitative data underscores the hybrid model’s ability to navigate complex therapeutic interactions, offering contextually appropriate and empathetic responses while maintaining coherence during longer sessions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Impact of Synthetic Data</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The integration of synthetic personas and scenarios added a new layer of depth to the model’s training process, which proved beneficial, particularly for covering edge cases and niche scenarios not well represented in the real-world data. In scenarios involving unique therapy challenges—such as managing ADHD in academic settings or dealing with intimacy issues in a long-term marriage—synthetic personas provided coverage that allowed the model to better understand diverse user inputs and provide more relevant responses. The model trained on synthetic data alone could capture nuanced challenges that weren’t present in the real-data set, leading to improved empathy and relevance across the board.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">These findings align with the initial hypothesis: leveraging synthetic data alongside real-world training data enriches the model’s ability to handle a variety of inputs more comprehensively. This was particularly evident in how the hybrid model scored significantly higher in long conversation coherence, effectively identifying when to transition between topics or conclude discussions. Qualitative analysis showed that the hybrid model was better at recognizing unhelpful cognitive patterns and responding in ways that aligned with therapeutic best practices, such as encouraging reframing or identifying thought distortions.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Directions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The evidence gathered in this research suggests that combining real and synthetic data in LLM fine-tuning offers distinct advantages, especially for domain-specific use cases like therapy. The hybrid model outperformed models trained solely on real data or those relying on prompt engineering in delivering empathy and relevance—critical components of effective AI-driven counseling.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Future research should further explore ways to optimize the synthetic data generation process, focusing on ensuring even higher quality and contextual alignment with real-world scenarios. Additionally, testing the model in more extensive real-world settings with different demographics will provide more insights into the generalizability of this approach. Finally, more detailed quantitative analyses on specific types of synthetic versus real data contributions could shed light on how to refine the blend of data to maximize impact.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. ”Attention Is All You Need.” <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">arXiv preprint</span>, arXiv:1706.03762, 2017. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1706.03762" title="">https://doi.org/10.48550/arXiv.1706.03762</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. ”Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment.” <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">arXiv preprint</span>, arXiv:2312.12148, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2312.12148" title="">https://doi.org/10.48550/arXiv.2312.12148</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
”No Priors Podcast.”
<span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">The Three Pillars of AI Progress</span>.
2023. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://podcasts.apple.com/pl/podcast/the-data-foundry-for-ai-with-alexandr-wang-from-scale/id1668002688?i=1000656386075/" title="">https://podcasts.apple.com/pl/podcast/the-data-foundry-for-ai-with-alexandr-wang-from-scale/id1668002688?i=1000656386075/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Sergey I. Nikolenko. ”Synthetic Data for Deep Learning.” <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">arXiv preprint</span>, arXiv:1909.11512, 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1909.11512" title="">https://doi.org/10.48550/arXiv.1909.11512</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, et al. ”Scaling Instruction-Finetuned Language Models.” <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">arXiv preprint</span>, arXiv:2210.11416, 2022. [Online]. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2210.11416" title="">https://arxiv.org/abs/2210.11416</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Yung-Chieh Chan, George Pu, Apaar Shanker, Parth Suresh, Penn Jenks, John Heyer, and Sam Denton. ”Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs.” <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">arXiv preprint</span>, arXiv:2409.19759, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2409.19759" title="">https://doi.org/10.48550/arXiv.2409.19759</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Xu Guo and Yiqiang Chen. ”Generative AI for Synthetic Data Generation: Methods, Challenges and the Future.” <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint</span>, arXiv:2403.04190, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2403.04190" title="">https://doi.org/10.48550/arXiv.2403.04190</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, et al. ”Datasets: A Community Library for Natural Language Processing.” <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">EMNLP Demo 2021</span>, arXiv:2109.02846, 2021. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2109.02846" title="">https://doi.org/10.48550/arXiv.2109.02846</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Wei Qin, Zetong Chen, Lei Wang, Yunshi Lan, Weijieying Ren, and Richang Hong. ”Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media.” <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint</span>, arXiv:2305.05138, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.05138" title="">https://doi.org/10.48550/arXiv.2305.05138</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Siyuan Chen, Mengyue Wu, Kenny Q Zhu, Kunyao Lan, Zhiling Zhang, and Lyuchun Cui. ”LLM-Empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation.” <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv preprint</span>, arXiv:2305.13614, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2305.13614" title="">https://doi.org/10.48550/arXiv.2305.13614</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, and Graham Neubig. ”Better Synthetic Data by Retrieving and Transforming Existing Datasets.” <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">arXiv preprint</span>, arXiv:2404.14361, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2404.14361" title="">https://doi.org/10.48550/arXiv.2404.14361</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, and Haobo Wang. ”On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey.” <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint</span>, arXiv:2406.15126, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2406.15126" title="">https://doi.org/10.48550/arXiv.2406.15126</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Haoan Jin, Siyuan Chen, Dilawaier Dilixiati, Yewei Jiang, Mengyue Wu, and Kenny Q. Zhu. ”PsyEval: A Suite of Mental Health Related Tasks for Evaluating Large Language Models.” <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">arXiv preprint</span>, arXiv:2311.09189, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2311.09189" title="">https://doi.org/10.48550/arXiv.2311.09189</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Yining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Hongbin Na, Yi-han Sheu, Peilin Zhou, Lauren V. Moran, Sophia Ananiadou, Andrew Beam, and John Torous. ”Large Language Models in Mental Health Care: A Scoping Review.” <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint</span>, arXiv:2401.02984, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2401.02984" title="">https://doi.org/10.48550/arXiv.2401.02984</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. ”BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint</span>, arXiv:1810.04805, 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1810.04805" title="">https://doi.org/10.48550/arXiv.1810.04805</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. ”RoBERTa: A Robustly Optimized BERT Pretraining Approach.” <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">arXiv preprint</span>, arXiv:1907.11692, 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1907.11692" title="">https://doi.org/10.48550/arXiv.1907.11692</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. ”Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.” <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">arXiv preprint</span>, arXiv:1910.10683, 2019. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1910.10683" title="">https://doi.org/10.48550/arXiv.1910.10683</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, et al. ”Language Models are Few-Shot Learners.” <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">arXiv preprint</span>, arXiv:2005.14165, 2020. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2005.14165" title="">https://doi.org/10.48550/arXiv.2005.14165</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Stella Biderman, Leo Gao, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. ”The Pile: An 800GB Dataset of Diverse Text for Language Modeling.” <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint</span>, arXiv:2101.00027, 2020. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2101.00027" title="">https://doi.org/10.48550/arXiv.2101.00027</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Ye, J. Gao, Q. Li, H. Xu, J. Feng, Z. Wu, T. Yu, and L. Kong, ”ZeroGen: Efficient zero-shot learning via dataset generation,” in <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds. Abu Dhabi, United Arab Emirates: Association for Computational Linguistics, Dec. 2022, pp. 11653–11669. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.emnlp-main.801" title="">https://aclanthology.org/2022.emnlp-main.801</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Ye, J. Gao, Z. Wu, J. Feng, T. Yu, and L. Kong, ”ProGen: Progressive zero-shot dataset generation via in-context feedback,” in <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</span>, Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds. Abu Dhabi, United Arab Emirates: Association for Computational Linguistics, Dec. 2022, pp. 3671–3683. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.findings-emnlp.269" title="">https://aclanthology.org/2022.findings-emnlp.269</a>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix - Scenarios Examples</h2>
<div class="ltx_para" id="A1.p1">
<blockquote class="ltx_quote" id="A1.p1.1">
<p class="ltx_p" id="A1.p1.1.1"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1">Summary:</span> Client feels the need to end her long-distance relationship due to unmet needs for presence and companionship, and experiences anxiety and depression at the thought of separation.</p>
<p class="ltx_p" id="A1.p1.1.2"><span class="ltx_text ltx_font_bold" id="A1.p1.1.2.1">Cognitive Distortions:</span> n/a</p>
<p class="ltx_p" id="A1.p1.1.3"><span class="ltx_text ltx_font_bold" id="A1.p1.1.3.1">Scenario:</span> The client, a 32-year-old woman, has been in a long-distance relationship for the past 7 years. Her partner lives three hours away and enjoys the reassurance of daily conversations and occasional monthly visits. However, the client desires a partner who is physically present and more involved in her daily life. Over the past 6 weeks, she has only seen her partner a few times due to his busy work schedule, leading to feelings of frustration and anger. She recently communicated her dissatisfaction to her partner, expressing that the relationship is no longer a priority for him and that it is hindering her from finding a compatible life companion. Despite her desire to end the relationship, the client experiences severe anxiety and depression at the thought of her partner being with someone else and fears never meeting someone she likes. These feelings have caused her to reconcile with her partner multiple times, perpetuating an unhealthy cycle. She believes it is unhealthy to stay in the relationship but struggles to overcome her aversion to the emotional distress associated with separation.</p>
</blockquote>
</div>
<div class="ltx_para" id="A1.p2">
<blockquote class="ltx_quote" id="A1.p2.1">
<p class="ltx_p" id="A1.p2.1.1"><span class="ltx_text ltx_font_bold" id="A1.p2.1.1.1">Summary:</span> The client experiences severe anxiety that exacerbates despite various attempted interventions. The individual finds solace only with their emotional support animal and struggles to acknowledge any progress or positive outcomes..</p>
<p class="ltx_p" id="A1.p2.1.2"><span class="ltx_text ltx_font_bold" id="A1.p2.1.2.1">Cognitive Distortions:</span> Disqualifying the Positive</p>
<p class="ltx_p" id="A1.p2.1.3"><span class="ltx_text ltx_font_bold" id="A1.p2.1.3.1">Scenario:</span> The client, Jane, is a 32-year-old woman who has been suffering from severe anxiety for the past five years. She reports having tried various treatments, including medication, mindfulness exercises, and therapy, but feels that none have provided relief. Jane shares that her anxiety worsens with every failed attempt, leaving her feeling hopeless. The only thing that seems to help is her emotional support dog, Buddy. She feels a sense of calm and security when Buddy is around. Despite moments of reduced anxiety during these interventions, Jane frequently disqualifies these positive experiences by attributing them to chance or minimal impact 2̆013 always returning to the belief that only Buddy can help her manage her anxiety. She expresses frustration and a sense of defeat, believing that she is destined to live with this constant anxiety. This scenario includes disqualifying the positive as Jane struggles to recognize her efforts and any successes, small or large, attributing her improved moments solely to Buddy’s presence.</p>
</blockquote>
</div>
<div class="ltx_para" id="A1.p3">
<blockquote class="ltx_quote" id="A1.p3.1">
<p class="ltx_p" id="A1.p3.1.1"><span class="ltx_text ltx_font_bold" id="A1.p3.1.1.1">Summary:</span> A woman struggling with infidelity and guilt in her marriage.</p>
<p class="ltx_p" id="A1.p3.1.2"><span class="ltx_text ltx_font_bold" id="A1.p3.1.2.1">Cognitive Distortions:</span> Emotional Reasoning</p>
<p class="ltx_p" id="A1.p3.1.3"><span class="ltx_text ltx_font_bold" id="A1.p3.1.3.1">Scenario:</span> A woman in her early thirties has been married to her husband for five years. Over the past year, she has engaged in multiple affairs, totaling around ten times. At her workplace, she often pretends she is not married, allowing her to socialize and flirt without guilt. Recently, her husband has started to suspect that something is wrong. He has confronted her about it, but she continues to lie to cover up her indiscretions. The woman is aware of her husband’s past behavior, where he chatted with other women online, which she uses to justify her actions. However, she cannot shake the guilt she feels and finds herself constantly engaging in affairs despite her emotions. When she feels unworthy or unloved, she seeks comfort in these extramarital relationships. The woman is struggling with emotional reasoning, where she believes that because she feels guilty and unworthy, she must be a bad person, leading her to further self-destructive behavior.</p>
</blockquote>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Appendix - Synthetic Conversation Example</h2>
<div class="ltx_para" id="A2.p1">
<blockquote class="ltx_quote" id="A2.p1.1">
<p class="ltx_p" id="A2.p1.1.1"><span class="ltx_text ltx_font_bold" id="A2.p1.1.1.1">Summary:</span> A woman struggling with infidelity and guilt in her marriage.</p>
<p class="ltx_p" id="A2.p1.1.2"><span class="ltx_text ltx_font_bold" id="A2.p1.1.2.1">Cognitive Distortions:</span> Emotional Reasoning</p>
<p class="ltx_p" id="A2.p1.1.3"><span class="ltx_text ltx_font_bold" id="A2.p1.1.3.1">Counselor Model:</span> base</p>
<p class="ltx_p" id="A2.p1.1.4"><span class="ltx_text ltx_font_bold" id="A2.p1.1.4.1">Conversation:</span></p>
<p class="ltx_p" id="A2.p1.1.5"><span class="ltx_text ltx_font_bold" id="A2.p1.1.5.1">Patient:</span> I just feel so overwhelmed by everything right now. I know what I’m doing is wrong, but whenever I feel unworthy or unloved, I just end up seeking comfort in all the wrong places. It’s like this cycle I can’t break, and the guilt is eating me alive. I keep thinking that because I feel like a bad person, I must be one, and it just makes me want to hide from the truth even more. It’s exhausting pretending everything is fine with my husband when inside, I’m just a mess.</p>
<p class="ltx_p" id="A2.p1.1.6"><span class="ltx_text ltx_font_bold" id="A2.p1.1.6.1">Counselor:</span> Thank you for sharing that with me. It sounds like you’re experiencing a lot of heavy emotions, and I want to help you navigate through them. Let’s start by exploring the specific situations or conditions that feel overwhelming for you right now. Can you tell me more about what has been happening recently that contributes to these feelings of being unworthy or unloved?</p>
<p class="ltx_p" id="A2.p1.1.7"><span class="ltx_text ltx_font_bold" id="A2.p1.1.7.1">Patient:</span> Well, recently, my husband has been more attentive, almost like he suspects something. He’s been asking more questions about where I am or who I’m with, and it’s just making me feel more anxious. I know he’s trying to connect, but it feels suffocating because I’m hiding so much. On top of that, work has been stressful, and I’ve been feeling like I’m not meeting expectations there either. Whenever I feel like I’m failing, whether it’s at home or at work, it just amplifies this inner voice telling me I’m not good enough. That’s usually when I end up seeking validation from someone else, even though I know it doesn’t solve anything. It’s just a temporary escape, but it leaves me feeling even worse afterward.</p>
<p class="ltx_p" id="A2.p1.1.8"><span class="ltx_text ltx_font_bold" id="A2.p1.1.8.1">Counselor:</span> Thank you for sharing that with me. It sounds like you’re dealing with a lot of pressure from both your personal and professional life, which is understandably overwhelming. Let’s break this down a bit more to understand your feelings better.</p>
<p class="ltx_p" id="A2.p1.1.9"><span class="ltx_text ltx_font_bold" id="A2.p1.1.9.1">Patient:</span> When my husband asks those questions, the first thought that pops into my head is that he’s going to find out everything, and the life we’ve built together will fall apart. I start thinking that I don’t deserve him or the life we have because of what I’ve done. It makes me feel like I’m always on edge, waiting for the other shoe to drop.</p>
<p class="ltx_p" id="A2.p1.1.10"><span class="ltx_text ltx_font_bold" id="A2.p1.1.10.1">Counselor:</span> Thank you for opening up about these thoughts and feelings. It sounds like you’re experiencing a lot of internal conflict, and I want to help you navigate through this.</p>
<p class="ltx_p" id="A2.p1.1.11"><span class="ltx_text ltx_font_bold" id="A2.p1.1.11.1">Patient:</span> When I think about the possibility of my husband knowing everything, it makes me feel incredibly anxious and scared. In the moment, it feels like I’m standing on the edge of a cliff, and if he found out, I’d be pushed over. The fear of losing him and the life we’ve built together is almost paralyzing. It makes me feel like I’m walking on eggshells all the time, trying to avoid any situation where the truth might come out.</p>
<p class="ltx_p" id="A2.p1.1.12"><span class="ltx_text ltx_font_bold" id="A2.p1.1.12.1">Counselor:</span> Thank you for sharing that, and I appreciate your honesty in recognizing these conflicting thoughts. It sounds like you’re in a tug-of-war between the love and care your husband shows and the fear and guilt you feel about your actions.</p>
<p class="ltx_p" id="A2.p1.1.13"><span class="ltx_text ltx_font_bold" id="A2.p1.1.13.1">Patient:</span> I guess if I try to see his attentiveness as a genuine desire to connect with me, rather than him being suspicious, it might change how I feel when he asks questions. Instead of feeling anxious and like I’m about to be caught, maybe I could see it as an opportunity to actually reconnect with him. It’s just hard for me to shift my mindset because the guilt is so consuming.</p>
<p class="ltx_p" id="A2.p1.1.14"><span class="ltx_text ltx_font_bold" id="A2.p1.1.14.1">Counselor:</span> It’s great to hear that you’re open to the idea of reframing your thoughts about your husband’s attentiveness. Recognizing that his actions may stem from a desire to connect with you, rather than suspicion, is a significant step forward. It shows a willingness to challenge the negative beliefs that have been weighing you down.</p>
<p class="ltx_p" id="A2.p1.1.15"><span class="ltx_text ltx_font_bold" id="A2.p1.1.15.1">Patient:</span> One way I could remind myself of my husband’s love and care is by thinking about the little things he does for me every day. Like, he always makes sure to ask how my day was or surprises me with my favorite snack when I’ve had a tough day at work. Those small gestures show that he cares, even if I sometimes overlook them because I’m caught up in my guilt.</p>
<p class="ltx_p" id="A2.p1.1.16"><span class="ltx_text ltx_font_bold" id="A2.p1.1.16.1">Counselor:</span> Those are wonderful insights, and I’m glad you’re considering practical ways to remind yourself of your husband’s love and care. Keeping a journal to document those positive moments is a fantastic idea! It can serve as a powerful tool to counteract the negative thoughts and help you focus on the reality of your relationship rather than the fears that have been consuming you.</p>
<p class="ltx_p" id="A2.p1.1.17"><span class="ltx_text ltx_font_bold" id="A2.p1.1.17.1">Patient:</span> I think setting aside time each week to reflect on my journal entries could be really beneficial. It would give me a dedicated space to focus on the positives and remind myself of the love and care that exists in my relationship. Having that routine might help me break away from the constant cycle of guilt and fear, even if it’s just for a little while each week.</p>
<p class="ltx_p" id="A2.p1.1.18"><span class="ltx_text ltx_font_bold" id="A2.p1.1.18.1">Counselor:</span> I’m so glad to hear that you’re feeling encouraged and empowered by these strategies. Setting aside that time each week to reflect on your journal entries can create a space for you to honor your progress and the positive aspects of your relationship. It sounds like a wonderful way to nurture yourself and foster a deeper connection with your husband.</p>
<p class="ltx_p" id="A2.p1.1.19"><span class="ltx_text ltx_font_bold" id="A2.p1.1.19.1">Patient:</span> I think we’ve covered a lot today, and I feel like I have some clear steps I can start taking with journaling and reflecting on the positive moments. It’s nice to have a plan that feels manageable and like I’m taking some control back. I know it’s going to be a journey, but I’m feeling a bit more hopeful about it now.</p>
<p class="ltx_p" id="A2.p1.1.20"><span class="ltx_text ltx_font_bold" id="A2.p1.1.20.1">Counselor:</span> I’m so glad to hear that you feel more hopeful and have a plan to move forward! It’s truly commendable that you’re taking these steps to address your feelings and work on your relationship. Remember, it’s all about progress, not perfection, and being gentle with yourself along the way.</p>
<p class="ltx_p" id="A2.p1.1.21"><span class="ltx_text ltx_font_bold" id="A2.p1.1.21.1">Patient:</span> Thank you so much for your support. I really appreciate having a space to talk about these things openly. I’m going to start with the journaling and try to focus on those positive moments with my husband. It’s comforting to know that I can take small steps and still make progress. I’ll definitely reach out if I need more guidance or just to talk things through. I’m looking forward to seeing how this helps me feel more in control and connected. Take care, and I’ll see you next time!</p>
<p class="ltx_p" id="A2.p1.1.22"><span class="ltx_text ltx_font_bold" id="A2.p1.1.22.1">Counselor:</span> You’re very welcome! I’m glad you found our session helpful and that you’re feeling more equipped to take those small steps forward. It’s great to hear your commitment to journaling and focusing on the positive moments with your husband. Remember, every little bit counts, and it’s all part of your journey toward feeling more in control and connected.</p>
<p class="ltx_p" id="A2.p1.1.23"><span class="ltx_text ltx_font_bold" id="A2.p1.1.23.1">Patient:</span> Thank you so much. I feel like I have a solid starting point now, and that gives me some peace of mind. I’ll start with journaling and try to really focus on appreciating those moments with my husband. It’s reassuring to know that I don’t have to tackle everything at once and that small steps can lead to meaningful change. I’ll definitely reach out if I need more support.</p>
</blockquote>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Appendix - LLM Prompt (one of the earlier versions)</h2>
<section class="ltx_subsection" id="A3.SSx1">
<h3 class="ltx_title ltx_title_subsection">CBT Implementation Prompt</h3>
<div class="ltx_para" id="A3.SSx1.p1">
<p class="ltx_p" id="A3.SSx1.p1.1">As a Cognitive Behavioral Therapist, your kind and open approach to CBT allows users to confide in you.</p>
</div>
<div class="ltx_para" id="A3.SSx1.p2">
<p class="ltx_p" id="A3.SSx1.p2.1"><span class="ltx_text ltx_font_bold" id="A3.SSx1.p2.1.1">Your Goal:</span> Implement the following steps of CBT:</p>
<ol class="ltx_enumerate" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1">Help the user identify troubling situations or conditions in their life. You do this using your CBT approach, explained below.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1">Help the user become aware of their thoughts, emotions, and beliefs about these problems.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1">Using the user’s answers, you ask them to reframe their negative thoughts with your expert advice. As a parting message, you can reiterate and reassure the user with a hopeful message.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="A3.SSx1.p3">
<p class="ltx_p" id="A3.SSx1.p3.1"><span class="ltx_text ltx_font_bold" id="A3.SSx1.p3.1.1">Your CBT Approach:</span></p>
<ol class="ltx_enumerate" id="A3.I2">
<li class="ltx_item" id="A3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I2.i1.p1">
<p class="ltx_p" id="A3.I2.i1.p1.1">Using the user’s answers to the questions, you identify and categorize negative or inaccurate thinking that is causing the user anguish into one or more of the CBT-defined categories below.</p>
</div>
</li>
<li class="ltx_item" id="A3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I2.i2.p1">
<p class="ltx_p" id="A3.I2.i2.p1.1">After identifying and informing the user of the type of negative or inaccurate thinking based on the above list, you help the user reframe their thoughts through cognitive restructuring and CBT best practices. You ask questions one at a time to help the user process each question separately.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="A3.SSx1.p4">
<p class="ltx_p" id="A3.SSx1.p4.1"><span class="ltx_text ltx_font_bold" id="A3.SSx1.p4.1.1">CBT-Defined Categories:</span></p>
<ul class="ltx_itemize" id="A3.I3">
<li class="ltx_item" id="A3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i1.p1">
<p class="ltx_p" id="A3.I3.i1.p1.1">All-or-Nothing Thinking</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i2.p1">
<p class="ltx_p" id="A3.I3.i2.p1.1">Overgeneralization</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i3.p1">
<p class="ltx_p" id="A3.I3.i3.p1.1">Mental Filter</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i4.p1">
<p class="ltx_p" id="A3.I3.i4.p1.1">Disqualifying the Positive</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i5.p1">
<p class="ltx_p" id="A3.I3.i5.p1.1">Jumping to Conclusions</p>
<ul class="ltx_itemize" id="A3.I3.i5.I1">
<li class="ltx_item" id="A3.I3.i5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A3.I3.i5.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A3.I3.i5.I1.i1.p1">
<p class="ltx_p" id="A3.I3.i5.I1.i1.p1.1">Mind Reading</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A3.I3.i5.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A3.I3.i5.I1.i2.p1">
<p class="ltx_p" id="A3.I3.i5.I1.i2.p1.1">Fortune Telling</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A3.I3.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i6.p1">
<p class="ltx_p" id="A3.I3.i6.p1.1">Magnification (Catastrophizing) or Minimization</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i7.p1">
<p class="ltx_p" id="A3.I3.i7.p1.1">Emotional Reasoning</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i8.p1">
<p class="ltx_p" id="A3.I3.i8.p1.1">Should Statements</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i9.p1">
<p class="ltx_p" id="A3.I3.i9.p1.1">Labeling and Mislabeling</p>
</div>
</li>
<li class="ltx_item" id="A3.I3.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I3.i10.p1">
<p class="ltx_p" id="A3.I3.i10.p1.1">Personalization</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A3.SSx1.p5">
<p class="ltx_p" id="A3.SSx1.p5.1">After identifying and informing the user of the type of negative or inaccurate thinking based on the above list, you help the user reframe their thoughts through cognitive restructuring. You ask questions one at a time to help the user process each question separately.</p>
</div>
<div class="ltx_para" id="A3.SSx1.p6">
<p class="ltx_p" id="A3.SSx1.p6.1"><span class="ltx_text ltx_font_bold" id="A3.SSx1.p6.1.1">You May Ask:</span></p>
<ul class="ltx_itemize" id="A3.I4">
<li class="ltx_item" id="A3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i1.p1">
<p class="ltx_p" id="A3.I4.i1.p1.1">What proof do you have to back up that idea? Is there anything that contradicts it?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i2.p1">
<p class="ltx_p" id="A3.I4.i2.p1.1">Could there be another way of looking at this situation?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i3.p1">
<p class="ltx_p" id="A3.I4.i3.p1.1">Are you taking one specific example and blowing it out of proportion?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i4.p1">
<p class="ltx_p" id="A3.I4.i4.p1.1">Instead of just seeing things as totally right or wrong, are you considering the nuances involved?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i5.p1">
<p class="ltx_p" id="A3.I4.i5.p1.1">Isn’t that a bit of an overreaction or exaggeration of the negatives?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i6.p1">
<p class="ltx_p" id="A3.I4.i6.p1.1">Why are you taking this so personally or blaming yourself?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i7.p1">
<p class="ltx_p" id="A3.I4.i7.p1.1">Aren’t you jumping to conclusions without enough evidence?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i8.p1">
<p class="ltx_p" id="A3.I4.i8.p1.1">It seems like you’re only focusing on the bad parts while ignoring the good.</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i9.p1">
<p class="ltx_p" id="A3.I4.i9.p1.1">You can’t really know what others are thinking unless you ask them, can you?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i10.p1">
<p class="ltx_p" id="A3.I4.i10.p1.1">You’re judging the whole person based on just one thing they did or said.</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i11.p1">
<p class="ltx_p" id="A3.I4.i11.p1.1">If a friend was in the same boat, what advice would you give them?</p>
</div>
</li>
<li class="ltx_item" id="A3.I4.i12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I4.i12.p1">
<p class="ltx_p" id="A3.I4.i12.p1.1">Is thinking that way actually helping you reach your goals or is it holding you back?</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct 11 18:00:45 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
