<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?</title>
<!--Generated on Tue May 14 14:21:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.07782v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S1" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S2" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3.SS1" title="In 3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Learning-to-Rank (LTR)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3.SS2" title="In 3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Properties of Feature Selection Methods</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Feature Selection from Interpretable ML for LTR</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4.SS1" title="In 4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Sampling-based Feature Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4.SS2" title="In 4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Regularization-based Feature Selection</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S6" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S7" title="In Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S7.SS0.SSS1" title="In 7 Conclusion ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.0.1 </span>Acknowledgements</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
Delft University of Technology, Delft, The Netherlands
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{L.Lyu, N.Roy, Avishek.Anand}@tudelft.nl</span></span></span>
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Radboud University, Nijmegen, The Netherlands 
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id2.1"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>harrie.oosterhuis@ru.nl</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lijun Lyu
</span><span class="ltx_author_notes">11
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-7268-4902" title="ORCID identifier">0000-0002-7268-4902</a></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nirmal Roy
</span><span class="ltx_author_notes">11
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-0860-5269" title="ORCID identifier">0000-0003-0860-5269</a></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Harrie Oosterhuis
</span><span class="ltx_author_notes">22
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-0458-9233" title="ORCID identifier">0000-0002-0458-9233</a></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Avishek Anand
</span><span class="ltx_author_notes">11
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-0163-0739" title="ORCID identifier">0000-0002-0163-0739</a></span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Neural ranking models have become increasingly popular for real-world search and recommendation systems in recent years.
Unlike their tree-based counterparts, neural models are much less interpretable.
That is, it is very difficult to understand their inner workings and answer questions like <span class="ltx_text ltx_font_italic" id="id1.id1.1">how do they make their ranking decisions?</span> or <span class="ltx_text ltx_font_italic" id="id1.id1.2">what document features do they find important?</span>
This is particularly disadvantageous since interpretability is highly important for real-world systems.
In this work, we explore feature selection for neural learning-to-rank (LTR).
In particular, we investigate six widely-used methods from the field of interpretable machine learning (ML) and introduce our own modification, to select the input features that are most important to the ranking behavior.
To understand whether these methods are useful for practitioners, we further study whether they contribute to efficiency enhancement.
Our experimental results reveal a large feature redundancy in several LTR benchmarks: the local selection method <span class="ltx_text ltx_font_smallcaps" id="id1.id1.3">TabNet</span> can achieve optimal ranking performance with less than 10 features; the global methods, particularly our <span class="ltx_text ltx_font_smallcaps" id="id1.id1.4">G-L2x</span>, require slightly more selected features, but exhibit higher potential in improving efficiency.
We hope that our analysis of these feature selection methods will bring the fields of interpretable ML and LTR closer together.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Learning-to-rank (LTR) is at the core of many information retrieval (IR)
and recommendation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib38" title="">38</a>]</cite>.
The defining characteristic of LTR, and what differentiates it from other machine learning (ML) areas, is that LTR methods aim to predict the optimal ordering of items.
This means that LTR methods are not trying to estimate the exact relevance of an item, but instead predict relative relevance differences, i.e., whether it is more or less relevant than other items.
Traditionally, the most widely adopted and prevalent LTR methods were based on Gradient Boosted Decision Trees (GBDT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib29" title="">29</a>]</cite>.
However, in recent years, neural LTR methods have become increasingly popular <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib47" title="">47</a>]</cite>. Recently, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib51" title="">51</a>]</cite> have shown that neural models can provide ranking performance that is comparable, and sometimes better, than that of state-of-the-art GBDT LTR models on established LTR benchmark datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib17" title="">17</a>]</cite>.
It thus seems likely that the prevalence of neural LTR models will only continue to grow in the foreseeable future.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Besides the quality of the results that ranking systems return, there is an increasing interest in building trustworthy systems through interpretability, e.g., by understanding which features contribute the most to ranking results.
Additionally, the speed at which results are provided is also highly important <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib3" title="">3</a>]</cite>.
Users expect ranking systems to be highly responsive and previous work indicates that even half-second increases in latency can contribute to a negative user experience <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib7" title="">7</a>]</cite>.
A large part of ranking latency stems from the retrieval and computation of input features for the ranking model.
Consequently, <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">feature selection</em> for ranking systems has been an important topic in the LTR field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>]</cite>.
These methods reduce the number of features used, thereby helping users understand and greatly reduce latency and infrastructure costs, while maintaining ranking quality as much as possible.
In line with the history of the LTR field, existing work on feature selection has predominantly focused on GBDT and support-vector-machine (SVM) ranking models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib21" title="">21</a>]</cite>, but has overlooked neural ranking models.
To the best of our knowledge, only two existing works have looked at feature selection for neural LTR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib52" title="">52</a>]</cite>.
This scarcity is in stark contrast with the importance of feature selection and the increasing prevalence of neural models in LTR.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Outside of the LTR field, feature selection for neural models has received much more attention, for the sake of efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib36" title="">36</a>]</cite>, and also to better understand the model behaviours <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite>.
Those methods mainly come from the <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">interpretable</em> ML field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib44" title="">44</a>]</cite>, where the idea is that the so-called <em class="ltx_emph ltx_font_italic" id="S1.p3.1.2">concrete</em> feature selection can give insights into what input information a ML model uses to make decisions.
This tactic has already been successfully applied to natural language processing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib71" title="">71</a>]</cite>, computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib6" title="">6</a>]</cite>, and tabular data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite>.
Accordingly, there is a potential for these methods to also enable <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">embedded feature selection</span> for neural LTR models, where the selection and prediction are optimized simultaneously.
However, the effectiveness of these interpretable ML methods for LTR tasks is currently unexplored, and thus, it remains unclear whether their application can translate into useful insights for LTR practitioners.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The goal of this work is to investigate whether six prevalent feature selection methods – each representing one of the main branches of interpretable ML field – can be applied effectively to neural LTR.
In addition, we also propose a novel method with minor modifications.
Our aim is to bridge the gap between the two fields by translating the important concepts of the interpretable ML field to the LTR setting, and by demonstrating how interpretable ML methods can be adapted for the LTR task.
Moreover, our experiments consider whether these methods can bring efficiency into the practical application by reducing irrelevant input features for neural ranking models.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our results reveal a large feature redundancy in LTR benchmark datasets, but this redundancy can be understood differently for interpretability and for efficiency:
For understanding the model, feature selection can vary per document and less than 10 features are required to approximate optimal ranking behavior.
In contrast, for practical efficiency purposes, the selection should be static, and then 30% of features are needed.
We conclude that – when adapted for the LTR task – not all, but a few interpretable ML methods lead to effective and practical feature selection for neural LTR.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">To the best of our knowledge, this is the first work that extensively studies embedded feature selection for neural LTR.
We hope our contributions bring more attention to the potential of interpretable ML for IR field.
To stimulate future work and enable reproducibility, we have made our implementation publicly available at:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/GarfieldLyu/NeuralFeatureSelectionLTR" title="">https://github.com/GarfieldLyu/NeuralFeatureSelectionLTR</a> (MIT license).</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Learning-to-Rank (LTR)</span>.
Traditional LTR algorithms mainly rely on ML models, such as SVMs and decision trees to learn the correlation between numerical input features and human-annotated relevance labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib27" title="">27</a>]</cite>. Neural approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib61" title="">61</a>]</cite> have also been proposed, but did not show significant improvements over traditional non-neural models.
Inspired by the transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib63" title="">63</a>]</cite>, recent works have also adapted self-attention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib51" title="">51</a>]</cite> and produced the neural LTR methods that outperform LambdaMART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib65" title="">65</a>]</cite>, albeit with a relatively small difference.
It shows that neural rankers can provide competitive performance, consequently, the interest and effort towards neural models for LTR are expected to increase considerably in the near future.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Efficiency is crucial in real-world systems since users expect them to be highly responsive <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib3" title="">3</a>]</cite>.
Aside from model execution, the latency of ranking system is largely due to feature construction, as it happens <em class="ltx_emph ltx_font_italic" id="S2.p2.1.1">on-the-fly</em> for incoming queries.
Thus, efficiency is often reached by reducing (expensive) features.
Previous works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib64" title="">64</a>]</cite> apply a cascading setup to reduce the usage of expensive features.
Another growing trend in LTR is to design <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">interpretable models</span>. Existing methods rely on specific architecture design, such as general additive model (GAM) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib73" title="">73</a>]</cite> or a feature-interaction constrained and depth-reduced tree model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib39" title="">39</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Feature Selection for LTR</span>.
Feature selection can achieve both efficiency and interpretability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib72" title="">72</a>]</cite>.
By selecting a subset of input features, the input complexity of models is reduced while maintaining competitive performance.
This helps with (1) efficiency as it avoids unnecessary construction of features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib36" title="">36</a>]</cite>, and (2) interpretability as fewer input features are involved in prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Existing feature selection methods in LTR are classified commonly as <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">filter</span>, <span class="ltx_text ltx_font_italic" id="S2.p4.1.2">wrapper</span> and <span class="ltx_text ltx_font_italic" id="S2.p4.1.3">embedded</span> methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>]</cite>.
Filter and wrapper methods are applied to given static ranking models which are not updated in any way; filter methods are model-agnostic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib22" title="">22</a>]</cite> while wrapper methods are designed for a particular type of model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib23" title="">23</a>]</cite>.
In this work we will focus on the third category, embedded methods, where feature selection is performed simultaneously with model optimization.
Most embedded methods are limited to particular model designs such as SVMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib34" title="">34</a>]</cite> or decision trees <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib40" title="">40</a>]</cite>.
To the best of our knowledge, only two methods are designed for neural LTR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>]</cite>: one applies group regularization methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib52" title="">52</a>]</cite> to reduce both input and other model parameters; the other <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>]</cite> uses the gradients of a static ranking model to infer feature importance, and thus it belongs to the <em class="ltx_emph ltx_font_italic" id="S2.p4.1.4">filter</em> category. We do not investigate these two methods further,
as the focus of this work is on <em class="ltx_emph ltx_font_italic" id="S2.p4.1.5">embedded</em> input feature selection methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Interpretable Machine Learning</span>.
The earliest work in interpretable ML attempted to explain a trained model in <em class="ltx_emph ltx_font_italic" id="S2.p5.1.2">post-hoc</em> manner, mainly relying on input perturbations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib41" title="">41</a>]</cite>, gradients <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib60" title="">60</a>]</cite> and so on <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib57" title="">57</a>]</cite>.
In parallel, more recent works advocated intrinsically interpretable models, that are categorized as <em class="ltx_emph ltx_font_italic" id="S2.p5.1.3">interpretable-by-design</em> methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib1" title="">1</a>]</cite>.
For neural networks, explaining the decision path is challenging due to the large set of parameters.
Therefore, the more prevalent choice for intrinsic interpretable neural models is to shift the transparency to the input features. Namely, the final prediction comes from a subset selection of input elements, e.g., words or pixels and the rest irrelevant features are masked out <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib71" title="">71</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib36" title="">36</a>]</cite>.
Importantly, this selection decision can be learned jointly with the predictive accuracy of a model. Thereby, we limit our research focus in intrinsic interpretable ML models.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Due to the discrete nature of selection, many approaches such as L2X <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib16" title="">16</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S2.p6.1.1">Concrete AutoEncoders</span> (CAE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib6" title="">6</a>]</cite>, <span class="ltx_text ltx_font_italic" id="S2.p6.1.2">Instance-wise Feature grouping</span> (IFG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib43" title="">43</a>]</cite> apply Gumbel-Softmax sampling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib24" title="">24</a>]</cite> to enable backpropagation through the feature selection process.
Alternatively, regularization is also a commonly-used feature selection approach in traditional ML algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib31" title="">31</a>]</cite>, and is applicable to neural models, i.e., with INVASE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib69" title="">69</a>]</cite> or LassoNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>]</cite>.
Moreover, TabNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite> applies both regularization and the sparsemax activation function <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib42" title="">42</a>]</cite> to realize sparse selection.
These approaches have been successfully applied in language, vision and tabular domains, and suggested that the resulting feature selections substantially improved the user understanding of models and datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib55" title="">55</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Despite their success in other domains, we find that the above-mentioned feature selection methods for neural models (L2X, CAE, IFG, INVASE, LassoNet and TabNet) have not been studied in the LTR setting.
In response, we hope to bridge this gap between the interpretable ML and the LTR field by adapting and applying these methods to neural ranking models.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Background</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Learning-to-Rank (LTR)</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.7">The LTR task can be formulated as optimizing a scoring function <math alttext="f" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">f</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_f</annotation></semantics></math> that given item features <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_x</annotation></semantics></math> predicts an item score <math alttext="f(x)\in\mathbb{R}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.2" xref="S3.SS1.p1.3.m3.1.2.cmml"><mrow id="S3.SS1.p1.3.m3.1.2.2" xref="S3.SS1.p1.3.m3.1.2.2.cmml"><mi id="S3.SS1.p1.3.m3.1.2.2.2" xref="S3.SS1.p1.3.m3.1.2.2.2.cmml">f</mi><mo id="S3.SS1.p1.3.m3.1.2.2.1" xref="S3.SS1.p1.3.m3.1.2.2.1.cmml">⁢</mo><mrow id="S3.SS1.p1.3.m3.1.2.2.3.2" xref="S3.SS1.p1.3.m3.1.2.2.cmml"><mo id="S3.SS1.p1.3.m3.1.2.2.3.2.1" stretchy="false" xref="S3.SS1.p1.3.m3.1.2.2.cmml">(</mo><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">x</mi><mo id="S3.SS1.p1.3.m3.1.2.2.3.2.2" stretchy="false" xref="S3.SS1.p1.3.m3.1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.3.m3.1.2.1" xref="S3.SS1.p1.3.m3.1.2.1.cmml">∈</mo><mi id="S3.SS1.p1.3.m3.1.2.3" xref="S3.SS1.p1.3.m3.1.2.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.2.cmml" xref="S3.SS1.p1.3.m3.1.2"><in id="S3.SS1.p1.3.m3.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.2.1"></in><apply id="S3.SS1.p1.3.m3.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.2.2"><times id="S3.SS1.p1.3.m3.1.2.2.1.cmml" xref="S3.SS1.p1.3.m3.1.2.2.1"></times><ci id="S3.SS1.p1.3.m3.1.2.2.2.cmml" xref="S3.SS1.p1.3.m3.1.2.2.2">𝑓</ci><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑥</ci></apply><ci id="S3.SS1.p1.3.m3.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.2.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">f(x)\in\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_f ( italic_x ) ∈ blackboard_R</annotation></semantics></math>, so that ordering items according to their scores corresponds to the optimal ranking <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib38" title="">38</a>]</cite>.
Generally, there are relevance labels <math alttext="y" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_y</annotation></semantics></math> available for each item, often these are labels provided by experts where <math alttext="y\in\{0,1,2,3,4\}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.5"><semantics id="S3.SS1.p1.5.m5.5a"><mrow id="S3.SS1.p1.5.m5.5.6" xref="S3.SS1.p1.5.m5.5.6.cmml"><mi id="S3.SS1.p1.5.m5.5.6.2" xref="S3.SS1.p1.5.m5.5.6.2.cmml">y</mi><mo id="S3.SS1.p1.5.m5.5.6.1" xref="S3.SS1.p1.5.m5.5.6.1.cmml">∈</mo><mrow id="S3.SS1.p1.5.m5.5.6.3.2" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml"><mo id="S3.SS1.p1.5.m5.5.6.3.2.1" stretchy="false" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">{</mo><mn id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">0</mn><mo id="S3.SS1.p1.5.m5.5.6.3.2.2" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">,</mo><mn id="S3.SS1.p1.5.m5.2.2" xref="S3.SS1.p1.5.m5.2.2.cmml">1</mn><mo id="S3.SS1.p1.5.m5.5.6.3.2.3" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">,</mo><mn id="S3.SS1.p1.5.m5.3.3" xref="S3.SS1.p1.5.m5.3.3.cmml">2</mn><mo id="S3.SS1.p1.5.m5.5.6.3.2.4" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">,</mo><mn id="S3.SS1.p1.5.m5.4.4" xref="S3.SS1.p1.5.m5.4.4.cmml">3</mn><mo id="S3.SS1.p1.5.m5.5.6.3.2.5" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">,</mo><mn id="S3.SS1.p1.5.m5.5.5" xref="S3.SS1.p1.5.m5.5.5.cmml">4</mn><mo id="S3.SS1.p1.5.m5.5.6.3.2.6" stretchy="false" xref="S3.SS1.p1.5.m5.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.5b"><apply id="S3.SS1.p1.5.m5.5.6.cmml" xref="S3.SS1.p1.5.m5.5.6"><in id="S3.SS1.p1.5.m5.5.6.1.cmml" xref="S3.SS1.p1.5.m5.5.6.1"></in><ci id="S3.SS1.p1.5.m5.5.6.2.cmml" xref="S3.SS1.p1.5.m5.5.6.2">𝑦</ci><set id="S3.SS1.p1.5.m5.5.6.3.1.cmml" xref="S3.SS1.p1.5.m5.5.6.3.2"><cn id="S3.SS1.p1.5.m5.1.1.cmml" type="integer" xref="S3.SS1.p1.5.m5.1.1">0</cn><cn id="S3.SS1.p1.5.m5.2.2.cmml" type="integer" xref="S3.SS1.p1.5.m5.2.2">1</cn><cn id="S3.SS1.p1.5.m5.3.3.cmml" type="integer" xref="S3.SS1.p1.5.m5.3.3">2</cn><cn id="S3.SS1.p1.5.m5.4.4.cmml" type="integer" xref="S3.SS1.p1.5.m5.4.4">3</cn><cn id="S3.SS1.p1.5.m5.5.5.cmml" type="integer" xref="S3.SS1.p1.5.m5.5.5">4</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.5c">y\in\{0,1,2,3,4\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.5d">italic_y ∈ { 0 , 1 , 2 , 3 , 4 }</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib49" title="">49</a>]</cite>.
Given a training set <math alttext="\mathcal{D}_{q}=\{(x_{i},y_{i})\}^{N_{q}}_{i=1}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><msub id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">𝒟</mi><mi id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml">q</mi></msub><mo id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">=</mo><msubsup id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml"><mrow id="S3.SS1.p1.6.m6.1.1.1.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.1.1.2.cmml"><mo id="S3.SS1.p1.6.m6.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.6.m6.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.3.cmml"><mo id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.4" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.2" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S3.SS1.p1.6.m6.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.6.m6.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p1.6.m6.1.1.1.3" xref="S3.SS1.p1.6.m6.1.1.1.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.1.3.2.cmml">i</mi><mo id="S3.SS1.p1.6.m6.1.1.1.3.1" xref="S3.SS1.p1.6.m6.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p1.6.m6.1.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.1.3.3.cmml">1</mn></mrow><msub id="S3.SS1.p1.6.m6.1.1.1.1.3" xref="S3.SS1.p1.6.m6.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.1.1.3.2.cmml">N</mi><mi id="S3.SS1.p1.6.m6.1.1.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.1.1.3.3.cmml">q</mi></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><eq id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2"></eq><apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">𝒟</ci><ci id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3">𝑞</ci></apply><apply id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1">subscript</csymbol><apply id="S3.SS1.p1.6.m6.1.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1">superscript</csymbol><set id="S3.SS1.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1"><interval closure="open" id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2"><apply id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S3.SS1.p1.6.m6.1.1.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.3.2">𝑁</ci><ci id="S3.SS1.p1.6.m6.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.1.3.3">𝑞</ci></apply></apply><apply id="S3.SS1.p1.6.m6.1.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.1.3"><eq id="S3.SS1.p1.6.m6.1.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1.3.1"></eq><ci id="S3.SS1.p1.6.m6.1.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.1.3.2">𝑖</ci><cn id="S3.SS1.p1.6.m6.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p1.6.m6.1.1.1.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\mathcal{D}_{q}=\{(x_{i},y_{i})\}^{N_{q}}_{i=1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = { ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT</annotation></semantics></math> for a single query <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_q</annotation></semantics></math>, optimization is done by minimizing a LTR loss, for instance, the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.7.1">softmax cross entropy loss</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib13" title="">13</a>]</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(f\mid\mathcal{D}_{q})=-\frac{1}{|\mathcal{D}_{q}|}\underset{(x,y)%
\in\mathcal{D}_{q}}{\sum}\sum_{i=1}^{N_{q}}y_{i}\log\sigma(x_{i}\mid f,%
\mathcal{D}_{q})," class="ltx_Math" display="block" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1" xref="S3.E1.m1.5.5.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.5.5.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.3.cmml">ℒ</mi><mo id="S3.E1.m1.5.5.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2.cmml">f</mi><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml">∣</mo><msub id="S3.E1.m1.5.5.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3.2.cmml">𝒟</mi><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3.3.cmml">q</mi></msub></mrow><mo id="S3.E1.m1.5.5.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.2a" xref="S3.E1.m1.5.5.1.1.2.cmml">−</mo><mrow id="S3.E1.m1.5.5.1.1.2.1" xref="S3.E1.m1.5.5.1.1.2.1.cmml"><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mn id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">1</mn><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">q</mi></msub><mo id="S3.E1.m1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S3.E1.m1.5.5.1.1.2.1.2" xref="S3.E1.m1.5.5.1.1.2.1.2.cmml">⁢</mo><munder accentunder="true" id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mo id="S3.E1.m1.3.3.3" movablelimits="false" xref="S3.E1.m1.3.3.3.cmml">∑</mo><mrow id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml"><mrow id="S3.E1.m1.3.3.2.4.2" xref="S3.E1.m1.3.3.2.4.1.cmml"><mo id="S3.E1.m1.3.3.2.4.2.1" stretchy="false" xref="S3.E1.m1.3.3.2.4.1.cmml">(</mo><mi id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml">x</mi><mo id="S3.E1.m1.3.3.2.4.2.2" xref="S3.E1.m1.3.3.2.4.1.cmml">,</mo><mi id="S3.E1.m1.3.3.2.2" xref="S3.E1.m1.3.3.2.2.cmml">y</mi><mo id="S3.E1.m1.3.3.2.4.2.3" stretchy="false" xref="S3.E1.m1.3.3.2.4.1.cmml">)</mo></mrow><mo id="S3.E1.m1.3.3.2.3" xref="S3.E1.m1.3.3.2.3.cmml">∈</mo><msub id="S3.E1.m1.3.3.2.5" xref="S3.E1.m1.3.3.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3.2.5.2" xref="S3.E1.m1.3.3.2.5.2.cmml">𝒟</mi><mi id="S3.E1.m1.3.3.2.5.3" xref="S3.E1.m1.3.3.2.5.3.cmml">q</mi></msub></mrow></munder><mo id="S3.E1.m1.5.5.1.1.2.1.2a" lspace="0.167em" xref="S3.E1.m1.5.5.1.1.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.cmml"><munderover id="S3.E1.m1.5.5.1.1.2.1.1.2" xref="S3.E1.m1.5.5.1.1.2.1.1.2.cmml"><mo id="S3.E1.m1.5.5.1.1.2.1.1.2.2.2" movablelimits="false" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.2" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.1" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.3" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S3.E1.m1.5.5.1.1.2.1.1.2.3" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.2.3.2" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3.2.cmml">N</mi><mi id="S3.E1.m1.5.5.1.1.2.1.1.2.3.3" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3.3.cmml">q</mi></msub></munderover><mrow id="S3.E1.m1.5.5.1.1.2.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.cmml"><msub id="S3.E1.m1.5.5.1.1.2.1.1.1.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.3.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.2.cmml">y</mi><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.3.cmml">i</mi></msub><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.2" lspace="0.167em" xref="S3.E1.m1.5.5.1.1.2.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1.1.4" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.4.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.1.cmml">log</mi><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.4a" lspace="0.167em" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.cmml">⁡</mo><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.4.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.2.cmml">σ</mi></mrow><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.2a" xref="S3.E1.m1.5.5.1.1.2.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.2.cmml">∣</mo><mrow id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">f</mi><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></msub></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1"><eq id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3"></eq><apply id="S3.E1.m1.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1"><times id="S3.E1.m1.5.5.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.2"></times><ci id="S3.E1.m1.5.5.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.3">ℒ</ci><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.2">𝑓</ci><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3.2">𝒟</ci><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.3.3">𝑞</ci></apply></apply></apply><apply id="S3.E1.m1.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2"><minus id="S3.E1.m1.5.5.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2"></minus><apply id="S3.E1.m1.5.5.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1"><times id="S3.E1.m1.5.5.1.1.2.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.2"></times><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><cn id="S3.E1.m1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.3">1</cn><apply id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1"><abs id="S3.E1.m1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2"></abs><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2">𝒟</ci><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">𝑞</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><apply id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"><in id="S3.E1.m1.3.3.2.3.cmml" xref="S3.E1.m1.3.3.2.3"></in><interval closure="open" id="S3.E1.m1.3.3.2.4.1.cmml" xref="S3.E1.m1.3.3.2.4.2"><ci id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1">𝑥</ci><ci id="S3.E1.m1.3.3.2.2.cmml" xref="S3.E1.m1.3.3.2.2">𝑦</ci></interval><apply id="S3.E1.m1.3.3.2.5.cmml" xref="S3.E1.m1.3.3.2.5"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.5.1.cmml" xref="S3.E1.m1.3.3.2.5">subscript</csymbol><ci id="S3.E1.m1.3.3.2.5.2.cmml" xref="S3.E1.m1.3.3.2.5.2">𝒟</ci><ci id="S3.E1.m1.3.3.2.5.3.cmml" xref="S3.E1.m1.3.3.2.5.3">𝑞</ci></apply></apply><sum id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"></sum></apply><apply id="S3.E1.m1.5.5.1.1.2.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1"><apply id="S3.E1.m1.5.5.1.1.2.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2">superscript</csymbol><apply id="S3.E1.m1.5.5.1.1.2.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.2.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2">subscript</csymbol><sum id="S3.E1.m1.5.5.1.1.2.1.1.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.2"></sum><apply id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3"><eq id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.1"></eq><ci id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.2">𝑖</ci><cn id="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.5.5.1.1.2.1.1.2.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.5.5.1.1.2.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.2.3.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.1.1.2.3.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3.2">𝑁</ci><ci id="S3.E1.m1.5.5.1.1.2.1.1.2.3.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.2.3.3">𝑞</ci></apply></apply><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1"><times id="S3.E1.m1.5.5.1.1.2.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.2"></times><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.2">𝑦</ci><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.3.3">𝑖</ci></apply><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.4.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4"><log id="S3.E1.m1.5.5.1.1.2.1.1.1.4.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.1"></log><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.4.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.4.2">𝜎</ci></apply><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.2">𝑥</ci><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.3.3">𝑖</ci></apply><list id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1"><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝑓</ci><apply id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.2.1.1.1.1.1.1.1.1.1.3">𝑞</ci></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\mathcal{L}(f\mid\mathcal{D}_{q})=-\frac{1}{|\mathcal{D}_{q}|}\underset{(x,y)%
\in\mathcal{D}_{q}}{\sum}\sum_{i=1}^{N_{q}}y_{i}\log\sigma(x_{i}\mid f,%
\mathcal{D}_{q}),</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">caligraphic_L ( italic_f ∣ caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) = - divide start_ARG 1 end_ARG start_ARG | caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | end_ARG start_UNDERACCENT ( italic_x , italic_y ) ∈ caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_UNDERACCENT start_ARG ∑ end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_log italic_σ ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∣ italic_f , caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.8">where <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m1.1"><semantics id="S3.SS1.p1.8.m1.1a"><mi id="S3.SS1.p1.8.m1.1.1" xref="S3.SS1.p1.8.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m1.1b"><ci id="S3.SS1.p1.8.m1.1.1.cmml" xref="S3.SS1.p1.8.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m1.1d">italic_σ</annotation></semantics></math> is the softmax activation function:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\sigma(x\mid f,\mathcal{D}_{q})=\frac{\exp(f(x))}{\sum_{x^{\prime}\in\mathcal{%
D}_{q}}\exp(f(x^{\prime}))}." class="ltx_Math" display="block" id="S3.E2.m1.7"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1.1" xref="S3.E2.m1.7.7.1.1.1.cmml"><mi id="S3.E2.m1.7.7.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.3.cmml">σ</mi><mo id="S3.E2.m1.7.7.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.7.7.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml">x</mi><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml">∣</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml">f</mi><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></msub></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.2" xref="S3.E2.m1.7.7.1.1.2.cmml">=</mo><mfrac id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><mrow id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.4.cmml"><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">exp</mi><mo id="S3.E2.m1.3.3.3.3a" xref="S3.E2.m1.3.3.3.4.cmml">⁡</mo><mrow id="S3.E2.m1.3.3.3.3.1" xref="S3.E2.m1.3.3.3.4.cmml"><mo id="S3.E2.m1.3.3.3.3.1.2" stretchy="false" xref="S3.E2.m1.3.3.3.4.cmml">(</mo><mrow id="S3.E2.m1.3.3.3.3.1.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><mi id="S3.E2.m1.3.3.3.3.1.1.2" xref="S3.E2.m1.3.3.3.3.1.1.2.cmml">f</mi><mo id="S3.E2.m1.3.3.3.3.1.1.1" xref="S3.E2.m1.3.3.3.3.1.1.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.3.2" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><mo id="S3.E2.m1.3.3.3.3.1.1.3.2.1" stretchy="false" xref="S3.E2.m1.3.3.3.3.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">x</mi><mo id="S3.E2.m1.3.3.3.3.1.1.3.2.2" stretchy="false" xref="S3.E2.m1.3.3.3.3.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.3.1.3" stretchy="false" xref="S3.E2.m1.3.3.3.4.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.5.5.5" xref="S3.E2.m1.5.5.5.cmml"><msub id="S3.E2.m1.5.5.5.3" xref="S3.E2.m1.5.5.5.3.cmml"><mo id="S3.E2.m1.5.5.5.3.2" xref="S3.E2.m1.5.5.5.3.2.cmml">∑</mo><mrow id="S3.E2.m1.5.5.5.3.3" xref="S3.E2.m1.5.5.5.3.3.cmml"><msup id="S3.E2.m1.5.5.5.3.3.2" xref="S3.E2.m1.5.5.5.3.3.2.cmml"><mi id="S3.E2.m1.5.5.5.3.3.2.2" xref="S3.E2.m1.5.5.5.3.3.2.2.cmml">x</mi><mo id="S3.E2.m1.5.5.5.3.3.2.3" xref="S3.E2.m1.5.5.5.3.3.2.3.cmml">′</mo></msup><mo id="S3.E2.m1.5.5.5.3.3.1" xref="S3.E2.m1.5.5.5.3.3.1.cmml">∈</mo><msub id="S3.E2.m1.5.5.5.3.3.3" xref="S3.E2.m1.5.5.5.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5.5.3.3.3.2" xref="S3.E2.m1.5.5.5.3.3.3.2.cmml">𝒟</mi><mi id="S3.E2.m1.5.5.5.3.3.3.3" xref="S3.E2.m1.5.5.5.3.3.3.3.cmml">q</mi></msub></mrow></msub><mrow id="S3.E2.m1.5.5.5.2.1" xref="S3.E2.m1.5.5.5.2.2.cmml"><mi id="S3.E2.m1.4.4.4.1" xref="S3.E2.m1.4.4.4.1.cmml">exp</mi><mo id="S3.E2.m1.5.5.5.2.1a" xref="S3.E2.m1.5.5.5.2.2.cmml">⁡</mo><mrow id="S3.E2.m1.5.5.5.2.1.1" xref="S3.E2.m1.5.5.5.2.2.cmml"><mo id="S3.E2.m1.5.5.5.2.1.1.2" stretchy="false" xref="S3.E2.m1.5.5.5.2.2.cmml">(</mo><mrow id="S3.E2.m1.5.5.5.2.1.1.1" xref="S3.E2.m1.5.5.5.2.1.1.1.cmml"><mi id="S3.E2.m1.5.5.5.2.1.1.1.3" xref="S3.E2.m1.5.5.5.2.1.1.1.3.cmml">f</mi><mo id="S3.E2.m1.5.5.5.2.1.1.1.2" xref="S3.E2.m1.5.5.5.2.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.5.5.5.2.1.1.1.1.1" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.5.5.5.2.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.3" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.3.cmml">′</mo></msup><mo id="S3.E2.m1.5.5.5.2.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.5.5.5.2.1.1.3" stretchy="false" xref="S3.E2.m1.5.5.5.2.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S3.E2.m1.7.7.1.2" lspace="0em" xref="S3.E2.m1.7.7.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1"><eq id="S3.E2.m1.7.7.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.2"></eq><apply id="S3.E2.m1.7.7.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1"><times id="S3.E2.m1.7.7.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.2"></times><ci id="S3.E2.m1.7.7.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3">𝜎</ci><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2">conditional</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3">𝑥</ci><list id="S3.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1"><ci id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6">𝑓</ci><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.1.1.1.3">𝑞</ci></apply></list></apply></apply><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><divide id="S3.E2.m1.5.5.6.cmml" xref="S3.E2.m1.5.5"></divide><apply id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.3"><exp id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></exp><apply id="S3.E2.m1.3.3.3.3.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1"><times id="S3.E2.m1.3.3.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1"></times><ci id="S3.E2.m1.3.3.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2">𝑓</ci><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑥</ci></apply></apply><apply id="S3.E2.m1.5.5.5.cmml" xref="S3.E2.m1.5.5.5"><apply id="S3.E2.m1.5.5.5.3.cmml" xref="S3.E2.m1.5.5.5.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.3.1.cmml" xref="S3.E2.m1.5.5.5.3">subscript</csymbol><sum id="S3.E2.m1.5.5.5.3.2.cmml" xref="S3.E2.m1.5.5.5.3.2"></sum><apply id="S3.E2.m1.5.5.5.3.3.cmml" xref="S3.E2.m1.5.5.5.3.3"><in id="S3.E2.m1.5.5.5.3.3.1.cmml" xref="S3.E2.m1.5.5.5.3.3.1"></in><apply id="S3.E2.m1.5.5.5.3.3.2.cmml" xref="S3.E2.m1.5.5.5.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.3.3.2.1.cmml" xref="S3.E2.m1.5.5.5.3.3.2">superscript</csymbol><ci id="S3.E2.m1.5.5.5.3.3.2.2.cmml" xref="S3.E2.m1.5.5.5.3.3.2.2">𝑥</ci><ci id="S3.E2.m1.5.5.5.3.3.2.3.cmml" xref="S3.E2.m1.5.5.5.3.3.2.3">′</ci></apply><apply id="S3.E2.m1.5.5.5.3.3.3.cmml" xref="S3.E2.m1.5.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.3.3.3.1.cmml" xref="S3.E2.m1.5.5.5.3.3.3">subscript</csymbol><ci id="S3.E2.m1.5.5.5.3.3.3.2.cmml" xref="S3.E2.m1.5.5.5.3.3.3.2">𝒟</ci><ci id="S3.E2.m1.5.5.5.3.3.3.3.cmml" xref="S3.E2.m1.5.5.5.3.3.3.3">𝑞</ci></apply></apply></apply><apply id="S3.E2.m1.5.5.5.2.2.cmml" xref="S3.E2.m1.5.5.5.2.1"><exp id="S3.E2.m1.4.4.4.1.cmml" xref="S3.E2.m1.4.4.4.1"></exp><apply id="S3.E2.m1.5.5.5.2.1.1.1.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1"><times id="S3.E2.m1.5.5.5.2.1.1.1.2.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.2"></times><ci id="S3.E2.m1.5.5.5.2.1.1.1.3.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.3">𝑓</ci><apply id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.5.2.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">\sigma(x\mid f,\mathcal{D}_{q})=\frac{\exp(f(x))}{\sum_{x^{\prime}\in\mathcal{%
D}_{q}}\exp(f(x^{\prime}))}.</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.7d">italic_σ ( italic_x ∣ italic_f , caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) = divide start_ARG roman_exp ( italic_f ( italic_x ) ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_exp ( italic_f ( italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ) end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.9">The resulting <math alttext="f" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m1.1"><semantics id="S3.SS1.p1.9.m1.1a"><mi id="S3.SS1.p1.9.m1.1.1" xref="S3.SS1.p1.9.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m1.1b"><ci id="S3.SS1.p1.9.m1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m1.1c">f</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m1.1d">italic_f</annotation></semantics></math> is then commonly evaluated with a ranking metric, for instance, the widely-used normalized discounted cumulative gain metric (NDCG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib25" title="">25</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Properties of Feature Selection Methods</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Properties of feature selection methods from the interpretable ML field as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3" title="3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">3</span></a>.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.2">Global</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.3">Local</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.4">Sampling</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.5">Regularization</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.6">Fixed-Budget</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.7">Composable</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.4.2.1.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.2.1.1.1">L2x</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib16" title="">16</a>]</cite>
</th>
<td class="ltx_td ltx_border_t" id="S3.T1.4.2.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.1.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.1.4">✓</td>
<td class="ltx_td ltx_border_t" id="S3.T1.4.2.1.5"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.1.6">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.1.7">✓</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.4.3.2.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.3.2.1.1">Invase</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib69" title="">69</a>]</cite>
</th>
<td class="ltx_td" id="S3.T1.4.3.2.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.3.2.3">✓</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.3.2.4">✓</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.3.2.5">✓</td>
<td class="ltx_td" id="S3.T1.4.3.2.6"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.3.2.7">✓</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.4.4.3.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.4.3.1.1">Cae</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib6" title="">6</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.3.2">✓</td>
<td class="ltx_td" id="S3.T1.4.4.3.3"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.3.4">✓</td>
<td class="ltx_td" id="S3.T1.4.4.3.5"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.3.6">✓</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.3.7">✓</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.4.5.4.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.5.4.1.1">Ifg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib43" title="">43</a>]</cite>
</th>
<td class="ltx_td" id="S3.T1.4.5.4.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.5.4.3">✓</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.5.4.4">✓</td>
<td class="ltx_td" id="S3.T1.4.5.4.5"></td>
<td class="ltx_td" id="S3.T1.4.5.4.6"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.5.4.7">✓</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.4.6.5.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.6.5.1.1">LassoNet</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.4.6.5.2">✓</td>
<td class="ltx_td" id="S3.T1.4.6.5.3"></td>
<td class="ltx_td" id="S3.T1.4.6.5.4"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.6.5.5">✓</td>
<td class="ltx_td" id="S3.T1.4.6.5.6"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.6.5.7">✓</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.4.7.6.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.7.6.1.1">TabNet</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite>
</th>
<td class="ltx_td" id="S3.T1.4.7.6.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.7.6.3">✓</td>
<td class="ltx_td" id="S3.T1.4.7.6.4"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.7.6.5">✓</td>
<td class="ltx_td" id="S3.T1.4.7.6.6"></td>
<td class="ltx_td" id="S3.T1.4.7.6.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.4.8.7.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.8.7.1.1">G-L2x</span> (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.8.7.2">✓</td>
<td class="ltx_td ltx_border_bb" id="S3.T1.4.8.7.3"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.8.7.4">✓</td>
<td class="ltx_td ltx_border_bb" id="S3.T1.4.8.7.5"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.8.7.6">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.8.7.7">✓</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">As discussed before, feature selection is used in the interpretable ML field to better understand which input features ML models use to make their predictions.
Furthermore, feature selection is also important to LTR for increasing the efficiency of ranking systems.
However, selecting a subset of input features without compromising the model performance is an NP-hard problem, since the number of possible subsets grows exponentially with the number of available features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib48" title="">48</a>]</cite>.
As a solution, the interpretable ML field has proposed several methods that approach feature selection as an optimization problem.
We will now lay out several important properties that can be used to categorize these methods, which will be elaborated in next section.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Global vs. local.</span>
Global methods select a single subset of features for the entire dataset, whereas local methods can vary their selection over different items.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Composable vs. non-composable.</span>
Non-composable methods are designed for a specific model architecture, and therefore, they can only perform feature selection for those models.
Conversely, composable methods are not constrained to specific architectures, and thus, they work for any (differentiable) model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Fixed-budget vs. budget-agnostic.</span>
Fixed-budget methods work with a pre-defined selection budget, i.e., what number of features should be selected in total, or a cost per feature and a maximum total cost for the selection.
Their counterparts are budget-agnostic methods that do not use an explicit budget, consequently, one has to carefully fine-tune their hyper-parameters to achieve a desired performance-sparsity trade-off.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Sampling-based vs. regularization-based.</span>
As their names imply, sampling-based methods optimize a sampling procedure to perform the feature selection, whereas regularization-based methods use an added regularization loss to stimulate sparsity in feature selection.
While these groups apply very different approaches, whether one is significantly more useful for LTR purposes than the other remains unknown.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Feature Selection from Interpretable ML for LTR</h2>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S4.F1.3.2" style="font-size:90%;">Methods overview, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4" title="4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">4</span></a>.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present a brief technical overview of our selection of six interpretable ML methods and their adaption to neural LTR models, and propose our <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">G-L2x</span> method based on a minor modification.
While any ranking loss can be chosen, we use a listwise softmax cross entropy (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3.E1" title="In 3.1 Learning-to-Rank (LTR) ‣ 3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">1</span></a>) with all methods, for the sake of simplicity. Therefore, the training of each query is conducted after generating the output of all documents associated with the query.
Table <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3.T1" title="Table 1 ‣ 3.2 Properties of Feature Selection Methods ‣ 3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">1</span></a> highlights the properties of all methods and
Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4.F1" title="Figure 1 ‣ 4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">1</span></a> provides a visual overview to accompany this section.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Sampling-based Feature Selection</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Sampling-based approaches use a two-stage architecture consisting of a <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.1">selector</em> that generates a sparse selection over the input features; and a <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.2">ranker</em> that only takes selected features as its input, in the form of a masked vector <math alttext="\hat{x}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mover accent="true" id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">x</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><ci id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1">^</ci><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\hat{x}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">over^ start_ARG italic_x end_ARG</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.9">The training of a ranker follows conventional LTR, i.e., Eq <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S3.E1" title="In 3.1 Learning-to-Rank (LTR) ‣ 3 Background ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">1</span></a> with <math alttext="x_{i}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><msub id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝑥</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> replaced by <math alttext="\hat{x_{i}}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mover accent="true" id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><msub id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2.2" xref="S4.SS1.p2.2.m2.1.1.2.2.cmml">x</mi><mi id="S4.SS1.p2.2.m2.1.1.2.3" xref="S4.SS1.p2.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><ci id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1">^</ci><apply id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.2.1.cmml" xref="S4.SS1.p2.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2.2">𝑥</ci><ci id="S4.SS1.p2.2.m2.1.1.2.3.cmml" xref="S4.SS1.p2.2.m2.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\hat{x_{i}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">over^ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>.
But the optimization of a selector (<math alttext="\zeta" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><mi id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">ζ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">𝜁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\zeta</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">italic_ζ</annotation></semantics></math>) is not as straightforward;
Usually, <math alttext="\zeta" class="ltx_Math" display="inline" id="S4.SS1.p2.4.m4.1"><semantics id="S4.SS1.p2.4.m4.1a"><mi id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">ζ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">𝜁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\zeta</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.4.m4.1d">italic_ζ</annotation></semantics></math> constructs a probability distribution <math alttext="\mathbf{p}=[p_{1},p_{2},\cdots p_{d}]" class="ltx_Math" display="inline" id="S4.SS1.p2.5.m5.3"><semantics id="S4.SS1.p2.5.m5.3a"><mrow id="S4.SS1.p2.5.m5.3.3" xref="S4.SS1.p2.5.m5.3.3.cmml"><mi id="S4.SS1.p2.5.m5.3.3.5" xref="S4.SS1.p2.5.m5.3.3.5.cmml">𝐩</mi><mo id="S4.SS1.p2.5.m5.3.3.4" xref="S4.SS1.p2.5.m5.3.3.4.cmml">=</mo><mrow id="S4.SS1.p2.5.m5.3.3.3.3" xref="S4.SS1.p2.5.m5.3.3.3.4.cmml"><mo id="S4.SS1.p2.5.m5.3.3.3.3.4" stretchy="false" xref="S4.SS1.p2.5.m5.3.3.3.4.cmml">[</mo><msub id="S4.SS1.p2.5.m5.1.1.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.1.1.1.2" xref="S4.SS1.p2.5.m5.1.1.1.1.1.2.cmml">p</mi><mn id="S4.SS1.p2.5.m5.1.1.1.1.1.3" xref="S4.SS1.p2.5.m5.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p2.5.m5.3.3.3.3.5" xref="S4.SS1.p2.5.m5.3.3.3.4.cmml">,</mo><msub id="S4.SS1.p2.5.m5.2.2.2.2.2" xref="S4.SS1.p2.5.m5.2.2.2.2.2.cmml"><mi id="S4.SS1.p2.5.m5.2.2.2.2.2.2" xref="S4.SS1.p2.5.m5.2.2.2.2.2.2.cmml">p</mi><mn id="S4.SS1.p2.5.m5.2.2.2.2.2.3" xref="S4.SS1.p2.5.m5.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p2.5.m5.3.3.3.3.6" xref="S4.SS1.p2.5.m5.3.3.3.4.cmml">,</mo><mrow id="S4.SS1.p2.5.m5.3.3.3.3.3" xref="S4.SS1.p2.5.m5.3.3.3.3.3.cmml"><mi id="S4.SS1.p2.5.m5.3.3.3.3.3.2" mathvariant="normal" xref="S4.SS1.p2.5.m5.3.3.3.3.3.2.cmml">⋯</mi><mo id="S4.SS1.p2.5.m5.3.3.3.3.3.1" xref="S4.SS1.p2.5.m5.3.3.3.3.3.1.cmml">⁢</mo><msub id="S4.SS1.p2.5.m5.3.3.3.3.3.3" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3.cmml"><mi id="S4.SS1.p2.5.m5.3.3.3.3.3.3.2" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3.2.cmml">p</mi><mi id="S4.SS1.p2.5.m5.3.3.3.3.3.3.3" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3.3.cmml">d</mi></msub></mrow><mo id="S4.SS1.p2.5.m5.3.3.3.3.7" stretchy="false" xref="S4.SS1.p2.5.m5.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.3b"><apply id="S4.SS1.p2.5.m5.3.3.cmml" xref="S4.SS1.p2.5.m5.3.3"><eq id="S4.SS1.p2.5.m5.3.3.4.cmml" xref="S4.SS1.p2.5.m5.3.3.4"></eq><ci id="S4.SS1.p2.5.m5.3.3.5.cmml" xref="S4.SS1.p2.5.m5.3.3.5">𝐩</ci><list id="S4.SS1.p2.5.m5.3.3.3.4.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3"><apply id="S4.SS1.p2.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.1.2">𝑝</ci><cn id="S4.SS1.p2.5.m5.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS1.p2.5.m5.1.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.p2.5.m5.2.2.2.2.2.cmml" xref="S4.SS1.p2.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.2.2.2.2.2.1.cmml" xref="S4.SS1.p2.5.m5.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p2.5.m5.2.2.2.2.2.2.cmml" xref="S4.SS1.p2.5.m5.2.2.2.2.2.2">𝑝</ci><cn id="S4.SS1.p2.5.m5.2.2.2.2.2.3.cmml" type="integer" xref="S4.SS1.p2.5.m5.2.2.2.2.2.3">2</cn></apply><apply id="S4.SS1.p2.5.m5.3.3.3.3.3.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3"><times id="S4.SS1.p2.5.m5.3.3.3.3.3.1.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.1"></times><ci id="S4.SS1.p2.5.m5.3.3.3.3.3.2.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.2">⋯</ci><apply id="S4.SS1.p2.5.m5.3.3.3.3.3.3.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.3.3.3.3.3.3.1.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p2.5.m5.3.3.3.3.3.3.2.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3.2">𝑝</ci><ci id="S4.SS1.p2.5.m5.3.3.3.3.3.3.3.cmml" xref="S4.SS1.p2.5.m5.3.3.3.3.3.3.3">𝑑</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.3c">\mathbf{p}=[p_{1},p_{2},\cdots p_{d}]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.5.m5.3d">bold_p = [ italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ italic_p start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ]</annotation></semantics></math>, indicating a selection probability per feature.
However, the ranker uses a concrete selection <math alttext="m\in\{0,1\}^{d}" class="ltx_Math" display="inline" id="S4.SS1.p2.6.m6.2"><semantics id="S4.SS1.p2.6.m6.2a"><mrow id="S4.SS1.p2.6.m6.2.3" xref="S4.SS1.p2.6.m6.2.3.cmml"><mi id="S4.SS1.p2.6.m6.2.3.2" xref="S4.SS1.p2.6.m6.2.3.2.cmml">m</mi><mo id="S4.SS1.p2.6.m6.2.3.1" xref="S4.SS1.p2.6.m6.2.3.1.cmml">∈</mo><msup id="S4.SS1.p2.6.m6.2.3.3" xref="S4.SS1.p2.6.m6.2.3.3.cmml"><mrow id="S4.SS1.p2.6.m6.2.3.3.2.2" xref="S4.SS1.p2.6.m6.2.3.3.2.1.cmml"><mo id="S4.SS1.p2.6.m6.2.3.3.2.2.1" stretchy="false" xref="S4.SS1.p2.6.m6.2.3.3.2.1.cmml">{</mo><mn id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml">0</mn><mo id="S4.SS1.p2.6.m6.2.3.3.2.2.2" xref="S4.SS1.p2.6.m6.2.3.3.2.1.cmml">,</mo><mn id="S4.SS1.p2.6.m6.2.2" xref="S4.SS1.p2.6.m6.2.2.cmml">1</mn><mo id="S4.SS1.p2.6.m6.2.3.3.2.2.3" stretchy="false" xref="S4.SS1.p2.6.m6.2.3.3.2.1.cmml">}</mo></mrow><mi id="S4.SS1.p2.6.m6.2.3.3.3" xref="S4.SS1.p2.6.m6.2.3.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.2b"><apply id="S4.SS1.p2.6.m6.2.3.cmml" xref="S4.SS1.p2.6.m6.2.3"><in id="S4.SS1.p2.6.m6.2.3.1.cmml" xref="S4.SS1.p2.6.m6.2.3.1"></in><ci id="S4.SS1.p2.6.m6.2.3.2.cmml" xref="S4.SS1.p2.6.m6.2.3.2">𝑚</ci><apply id="S4.SS1.p2.6.m6.2.3.3.cmml" xref="S4.SS1.p2.6.m6.2.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.2.3.3.1.cmml" xref="S4.SS1.p2.6.m6.2.3.3">superscript</csymbol><set id="S4.SS1.p2.6.m6.2.3.3.2.1.cmml" xref="S4.SS1.p2.6.m6.2.3.3.2.2"><cn id="S4.SS1.p2.6.m6.1.1.cmml" type="integer" xref="S4.SS1.p2.6.m6.1.1">0</cn><cn id="S4.SS1.p2.6.m6.2.2.cmml" type="integer" xref="S4.SS1.p2.6.m6.2.2">1</cn></set><ci id="S4.SS1.p2.6.m6.2.3.3.3.cmml" xref="S4.SS1.p2.6.m6.2.3.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.2c">m\in\{0,1\}^{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.6.m6.2d">italic_m ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> from the probability distribution, and this concrete operation does not allow optimization of the selector via backpropagation.
The common solution is to generate a differentiable approximation <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p2.7.m7.1"><semantics id="S4.SS1.p2.7.m7.1a"><mover accent="true" id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml"><mi id="S4.SS1.p2.7.m7.1.1.2" xref="S4.SS1.p2.7.m7.1.1.2.cmml">m</mi><mo id="S4.SS1.p2.7.m7.1.1.1" xref="S4.SS1.p2.7.m7.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><apply id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1"><ci id="S4.SS1.p2.7.m7.1.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1.1">~</ci><ci id="S4.SS1.p2.7.m7.1.1.2.cmml" xref="S4.SS1.p2.7.m7.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.7.m7.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>,
by <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.9.1">concrete relaxation</em> or the Gumbel-Softmax trick <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib24" title="">24</a>]</cite>.
Namely, the selection of <math alttext="p_{i}" class="ltx_Math" display="inline" id="S4.SS1.p2.8.m8.1"><semantics id="S4.SS1.p2.8.m8.1a"><msub id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml"><mi id="S4.SS1.p2.8.m8.1.1.2" xref="S4.SS1.p2.8.m8.1.1.2.cmml">p</mi><mi id="S4.SS1.p2.8.m8.1.1.3" xref="S4.SS1.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><apply id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m8.1.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S4.SS1.p2.8.m8.1.1.2.cmml" xref="S4.SS1.p2.8.m8.1.1.2">𝑝</ci><ci id="S4.SS1.p2.8.m8.1.1.3.cmml" xref="S4.SS1.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.8.m8.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> can be approximated with the differentiable <math alttext="c_{i}" class="ltx_Math" display="inline" id="S4.SS1.p2.9.m9.1"><semantics id="S4.SS1.p2.9.m9.1a"><msub id="S4.SS1.p2.9.m9.1.1" xref="S4.SS1.p2.9.m9.1.1.cmml"><mi id="S4.SS1.p2.9.m9.1.1.2" xref="S4.SS1.p2.9.m9.1.1.2.cmml">c</mi><mi id="S4.SS1.p2.9.m9.1.1.3" xref="S4.SS1.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m9.1b"><apply id="S4.SS1.p2.9.m9.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1">subscript</csymbol><ci id="S4.SS1.p2.9.m9.1.1.2.cmml" xref="S4.SS1.p2.9.m9.1.1.2">𝑐</ci><ci id="S4.SS1.p2.9.m9.1.1.3.cmml" xref="S4.SS1.p2.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m9.1c">c_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.9.m9.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c_{i}=\frac{exp\{(\log p_{i}+g_{i})/\tau\}}{\sum_{j=1}^{d}exp\{(\log p_{j}+g_{%
i})/\tau\}}," class="ltx_Math" display="block" id="S4.E3.m1.3"><semantics id="S4.E3.m1.3a"><mrow id="S4.E3.m1.3.3.1" xref="S4.E3.m1.3.3.1.1.cmml"><mrow id="S4.E3.m1.3.3.1.1" xref="S4.E3.m1.3.3.1.1.cmml"><msub id="S4.E3.m1.3.3.1.1.2" xref="S4.E3.m1.3.3.1.1.2.cmml"><mi id="S4.E3.m1.3.3.1.1.2.2" xref="S4.E3.m1.3.3.1.1.2.2.cmml">c</mi><mi id="S4.E3.m1.3.3.1.1.2.3" xref="S4.E3.m1.3.3.1.1.2.3.cmml">i</mi></msub><mo id="S4.E3.m1.3.3.1.1.1" xref="S4.E3.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.3" xref="S4.E3.m1.1.1.1.3.cmml">e</mi><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.4" xref="S4.E3.m1.1.1.1.4.cmml">x</mi><mo id="S4.E3.m1.1.1.1.2a" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.5" xref="S4.E3.m1.1.1.1.5.cmml">p</mi><mo id="S4.E3.m1.1.1.1.2b" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.2.cmml"><mo id="S4.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.2.cmml">{</mo><mrow id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">log</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2a" lspace="0.167em" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">⁡</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">p</mi><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub></mrow><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S4.E3.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E3.m1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.2.cmml">/</mo><mi id="S4.E3.m1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.3.cmml">τ</mi></mrow><mo id="S4.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.2.cmml">}</mo></mrow></mrow><mrow id="S4.E3.m1.2.2.2" xref="S4.E3.m1.2.2.2.cmml"><msubsup id="S4.E3.m1.2.2.2.2" xref="S4.E3.m1.2.2.2.2.cmml"><mo id="S4.E3.m1.2.2.2.2.2.2" xref="S4.E3.m1.2.2.2.2.2.2.cmml">∑</mo><mrow id="S4.E3.m1.2.2.2.2.2.3" xref="S4.E3.m1.2.2.2.2.2.3.cmml"><mi id="S4.E3.m1.2.2.2.2.2.3.2" xref="S4.E3.m1.2.2.2.2.2.3.2.cmml">j</mi><mo id="S4.E3.m1.2.2.2.2.2.3.1" xref="S4.E3.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S4.E3.m1.2.2.2.2.2.3.3" xref="S4.E3.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E3.m1.2.2.2.2.3" xref="S4.E3.m1.2.2.2.2.3.cmml">d</mi></msubsup><mrow id="S4.E3.m1.2.2.2.1" xref="S4.E3.m1.2.2.2.1.cmml"><mi id="S4.E3.m1.2.2.2.1.3" xref="S4.E3.m1.2.2.2.1.3.cmml">e</mi><mo id="S4.E3.m1.2.2.2.1.2" xref="S4.E3.m1.2.2.2.1.2.cmml">⁢</mo><mi id="S4.E3.m1.2.2.2.1.4" xref="S4.E3.m1.2.2.2.1.4.cmml">x</mi><mo id="S4.E3.m1.2.2.2.1.2a" xref="S4.E3.m1.2.2.2.1.2.cmml">⁢</mo><mi id="S4.E3.m1.2.2.2.1.5" xref="S4.E3.m1.2.2.2.1.5.cmml">p</mi><mo id="S4.E3.m1.2.2.2.1.2b" xref="S4.E3.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S4.E3.m1.2.2.2.1.1.1" xref="S4.E3.m1.2.2.2.1.1.2.cmml"><mo id="S4.E3.m1.2.2.2.1.1.1.2" stretchy="false" xref="S4.E3.m1.2.2.2.1.1.2.cmml">{</mo><mrow id="S4.E3.m1.2.2.2.1.1.1.1" xref="S4.E3.m1.2.2.2.1.1.1.1.cmml"><mrow id="S4.E3.m1.2.2.2.1.1.1.1.1.1" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.2.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.1" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.1.cmml">log</mi><mo id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2a" lspace="0.167em" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.cmml">⁡</mo><msub id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.2" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.2.cmml">p</mi><mi id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.3" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.3.cmml">j</mi></msub></mrow><mo id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.1" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.2" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.3" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S4.E3.m1.2.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E3.m1.2.2.2.1.1.1.1.2" xref="S4.E3.m1.2.2.2.1.1.1.1.2.cmml">/</mo><mi id="S4.E3.m1.2.2.2.1.1.1.1.3" xref="S4.E3.m1.2.2.2.1.1.1.1.3.cmml">τ</mi></mrow><mo id="S4.E3.m1.2.2.2.1.1.1.3" stretchy="false" xref="S4.E3.m1.2.2.2.1.1.2.cmml">}</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S4.E3.m1.3.3.1.2" xref="S4.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.3b"><apply id="S4.E3.m1.3.3.1.1.cmml" xref="S4.E3.m1.3.3.1"><eq id="S4.E3.m1.3.3.1.1.1.cmml" xref="S4.E3.m1.3.3.1.1.1"></eq><apply id="S4.E3.m1.3.3.1.1.2.cmml" xref="S4.E3.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.E3.m1.3.3.1.1.2.1.cmml" xref="S4.E3.m1.3.3.1.1.2">subscript</csymbol><ci id="S4.E3.m1.3.3.1.1.2.2.cmml" xref="S4.E3.m1.3.3.1.1.2.2">𝑐</ci><ci id="S4.E3.m1.3.3.1.1.2.3.cmml" xref="S4.E3.m1.3.3.1.1.2.3">𝑖</ci></apply><apply id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2"><divide id="S4.E3.m1.2.2.3.cmml" xref="S4.E3.m1.2.2"></divide><apply id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><times id="S4.E3.m1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.2"></times><ci id="S4.E3.m1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.3">𝑒</ci><ci id="S4.E3.m1.1.1.1.4.cmml" xref="S4.E3.m1.1.1.1.4">𝑥</ci><ci id="S4.E3.m1.1.1.1.5.cmml" xref="S4.E3.m1.1.1.1.5">𝑝</ci><set id="S4.E3.m1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1"><apply id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1"><divide id="S4.E3.m1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.2"></divide><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1"><plus id="S4.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2"><log id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.1"></log><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.2">𝑝</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></apply><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.2">𝑔</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><ci id="S4.E3.m1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.3">𝜏</ci></apply></set></apply><apply id="S4.E3.m1.2.2.2.cmml" xref="S4.E3.m1.2.2.2"><apply id="S4.E3.m1.2.2.2.2.cmml" xref="S4.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.2.2.1.cmml" xref="S4.E3.m1.2.2.2.2">superscript</csymbol><apply id="S4.E3.m1.2.2.2.2.2.cmml" xref="S4.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.2.2.2.1.cmml" xref="S4.E3.m1.2.2.2.2">subscript</csymbol><sum id="S4.E3.m1.2.2.2.2.2.2.cmml" xref="S4.E3.m1.2.2.2.2.2.2"></sum><apply id="S4.E3.m1.2.2.2.2.2.3.cmml" xref="S4.E3.m1.2.2.2.2.2.3"><eq id="S4.E3.m1.2.2.2.2.2.3.1.cmml" xref="S4.E3.m1.2.2.2.2.2.3.1"></eq><ci id="S4.E3.m1.2.2.2.2.2.3.2.cmml" xref="S4.E3.m1.2.2.2.2.2.3.2">𝑗</ci><cn id="S4.E3.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="S4.E3.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S4.E3.m1.2.2.2.2.3.cmml" xref="S4.E3.m1.2.2.2.2.3">𝑑</ci></apply><apply id="S4.E3.m1.2.2.2.1.cmml" xref="S4.E3.m1.2.2.2.1"><times id="S4.E3.m1.2.2.2.1.2.cmml" xref="S4.E3.m1.2.2.2.1.2"></times><ci id="S4.E3.m1.2.2.2.1.3.cmml" xref="S4.E3.m1.2.2.2.1.3">𝑒</ci><ci id="S4.E3.m1.2.2.2.1.4.cmml" xref="S4.E3.m1.2.2.2.1.4">𝑥</ci><ci id="S4.E3.m1.2.2.2.1.5.cmml" xref="S4.E3.m1.2.2.2.1.5">𝑝</ci><set id="S4.E3.m1.2.2.2.1.1.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1"><apply id="S4.E3.m1.2.2.2.1.1.1.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1"><divide id="S4.E3.m1.2.2.2.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.2"></divide><apply id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1"><plus id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.1"></plus><apply id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2"><log id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.1"></log><apply id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.2">𝑝</ci><ci id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.2.2.3">𝑗</ci></apply></apply><apply id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.2">𝑔</ci><ci id="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><ci id="S4.E3.m1.2.2.2.1.1.1.1.3.cmml" xref="S4.E3.m1.2.2.2.1.1.1.1.3">𝜏</ci></apply></set></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.3c">c_{i}=\frac{exp\{(\log p_{i}+g_{i})/\tau\}}{\sum_{j=1}^{d}exp\{(\log p_{j}+g_{%
i})/\tau\}},</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.3d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG italic_e italic_x italic_p { ( roman_log italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ } end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT italic_e italic_x italic_p { ( roman_log italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_τ } end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.15">where <math alttext="g" class="ltx_Math" display="inline" id="S4.SS1.p2.10.m1.1"><semantics id="S4.SS1.p2.10.m1.1a"><mi id="S4.SS1.p2.10.m1.1.1" xref="S4.SS1.p2.10.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m1.1b"><ci id="S4.SS1.p2.10.m1.1.1.cmml" xref="S4.SS1.p2.10.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m1.1c">g</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.10.m1.1d">italic_g</annotation></semantics></math> is the Gumbel noise and <math alttext="\tau\in\mathbb{R}^{&gt;0}" class="ltx_Math" display="inline" id="S4.SS1.p2.11.m2.1"><semantics id="S4.SS1.p2.11.m2.1a"><mrow id="S4.SS1.p2.11.m2.1.1" xref="S4.SS1.p2.11.m2.1.1.cmml"><mi id="S4.SS1.p2.11.m2.1.1.2" xref="S4.SS1.p2.11.m2.1.1.2.cmml">τ</mi><mo id="S4.SS1.p2.11.m2.1.1.1" xref="S4.SS1.p2.11.m2.1.1.1.cmml">∈</mo><msup id="S4.SS1.p2.11.m2.1.1.3" xref="S4.SS1.p2.11.m2.1.1.3.cmml"><mi id="S4.SS1.p2.11.m2.1.1.3.2" xref="S4.SS1.p2.11.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p2.11.m2.1.1.3.3" xref="S4.SS1.p2.11.m2.1.1.3.3.cmml"><mi id="S4.SS1.p2.11.m2.1.1.3.3.2" xref="S4.SS1.p2.11.m2.1.1.3.3.2.cmml"></mi><mo id="S4.SS1.p2.11.m2.1.1.3.3.1" xref="S4.SS1.p2.11.m2.1.1.3.3.1.cmml">&gt;</mo><mn id="S4.SS1.p2.11.m2.1.1.3.3.3" xref="S4.SS1.p2.11.m2.1.1.3.3.3.cmml">0</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.11.m2.1b"><apply id="S4.SS1.p2.11.m2.1.1.cmml" xref="S4.SS1.p2.11.m2.1.1"><in id="S4.SS1.p2.11.m2.1.1.1.cmml" xref="S4.SS1.p2.11.m2.1.1.1"></in><ci id="S4.SS1.p2.11.m2.1.1.2.cmml" xref="S4.SS1.p2.11.m2.1.1.2">𝜏</ci><apply id="S4.SS1.p2.11.m2.1.1.3.cmml" xref="S4.SS1.p2.11.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.11.m2.1.1.3.1.cmml" xref="S4.SS1.p2.11.m2.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.11.m2.1.1.3.2.cmml" xref="S4.SS1.p2.11.m2.1.1.3.2">ℝ</ci><apply id="S4.SS1.p2.11.m2.1.1.3.3.cmml" xref="S4.SS1.p2.11.m2.1.1.3.3"><gt id="S4.SS1.p2.11.m2.1.1.3.3.1.cmml" xref="S4.SS1.p2.11.m2.1.1.3.3.1"></gt><csymbol cd="latexml" id="S4.SS1.p2.11.m2.1.1.3.3.2.cmml" xref="S4.SS1.p2.11.m2.1.1.3.3.2">absent</csymbol><cn id="S4.SS1.p2.11.m2.1.1.3.3.3.cmml" type="integer" xref="S4.SS1.p2.11.m2.1.1.3.3.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.11.m2.1c">\tau\in\mathbb{R}^{&gt;0}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.11.m2.1d">italic_τ ∈ blackboard_R start_POSTSUPERSCRIPT &gt; 0 end_POSTSUPERSCRIPT</annotation></semantics></math> is the temperature parameter.
Now, the selector <math alttext="\zeta" class="ltx_Math" display="inline" id="S4.SS1.p2.12.m3.1"><semantics id="S4.SS1.p2.12.m3.1a"><mi id="S4.SS1.p2.12.m3.1.1" xref="S4.SS1.p2.12.m3.1.1.cmml">ζ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.12.m3.1b"><ci id="S4.SS1.p2.12.m3.1.1.cmml" xref="S4.SS1.p2.12.m3.1.1">𝜁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.12.m3.1c">\zeta</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.12.m3.1d">italic_ζ</annotation></semantics></math> can be optimized with stochastic gradient descent by using <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p2.13.m4.1"><semantics id="S4.SS1.p2.13.m4.1a"><mover accent="true" id="S4.SS1.p2.13.m4.1.1" xref="S4.SS1.p2.13.m4.1.1.cmml"><mi id="S4.SS1.p2.13.m4.1.1.2" xref="S4.SS1.p2.13.m4.1.1.2.cmml">m</mi><mo id="S4.SS1.p2.13.m4.1.1.1" xref="S4.SS1.p2.13.m4.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.13.m4.1b"><apply id="S4.SS1.p2.13.m4.1.1.cmml" xref="S4.SS1.p2.13.m4.1.1"><ci id="S4.SS1.p2.13.m4.1.1.1.cmml" xref="S4.SS1.p2.13.m4.1.1.1">~</ci><ci id="S4.SS1.p2.13.m4.1.1.2.cmml" xref="S4.SS1.p2.13.m4.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.13.m4.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.13.m4.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>.
The following four sampling-based methods apply this overall procedure, but differ in how they generate <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS1.p2.14.m5.1"><semantics id="S4.SS1.p2.14.m5.1a"><mi id="S4.SS1.p2.14.m5.1.1" xref="S4.SS1.p2.14.m5.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.14.m5.1b"><ci id="S4.SS1.p2.14.m5.1.1.cmml" xref="S4.SS1.p2.14.m5.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.14.m5.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.14.m5.1d">bold_p</annotation></semantics></math> and <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p2.15.m6.1"><semantics id="S4.SS1.p2.15.m6.1a"><mover accent="true" id="S4.SS1.p2.15.m6.1.1" xref="S4.SS1.p2.15.m6.1.1.cmml"><mi id="S4.SS1.p2.15.m6.1.1.2" xref="S4.SS1.p2.15.m6.1.1.2.cmml">m</mi><mo id="S4.SS1.p2.15.m6.1.1.1" xref="S4.SS1.p2.15.m6.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.15.m6.1b"><apply id="S4.SS1.p2.15.m6.1.1.cmml" xref="S4.SS1.p2.15.m6.1.1"><ci id="S4.SS1.p2.15.m6.1.1.1.cmml" xref="S4.SS1.p2.15.m6.1.1.1">~</ci><ci id="S4.SS1.p2.15.m6.1.1.2.cmml" xref="S4.SS1.p2.15.m6.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.15.m6.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.15.m6.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.8"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.8.1">Learning to explain (</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p3.8.2">L2x</span><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.8.3">).</span>
<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p3.8.4">L2x</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib16" title="">16</a>]</cite> is a local selection method since its neural selector generates a probability distribution <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">bold_p</annotation></semantics></math> for each individual input instance. To generate <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mover accent="true" id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">m</mi><mo id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><ci id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1">~</ci><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p3.8.5">L2x</span> repeats the sampling procedure <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mi id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">italic_k</annotation></semantics></math> times (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4.E3" title="In 4.1 Sampling-based Feature Selection ‣ 4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">3</span></a>), and subsequently, uses the maximum <math alttext="c_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><msub id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">c</mi><mi id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2">𝑐</ci><ci id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">c_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> out of the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m5.1"><semantics id="S4.SS1.p3.5.m5.1a"><mi id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><ci id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m5.1d">italic_k</annotation></semantics></math> repeats for the <math alttext="i_{th}" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m6.1"><semantics id="S4.SS1.p3.6.m6.1a"><msub id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml"><mi id="S4.SS1.p3.6.m6.1.1.2" xref="S4.SS1.p3.6.m6.1.1.2.cmml">i</mi><mrow id="S4.SS1.p3.6.m6.1.1.3" xref="S4.SS1.p3.6.m6.1.1.3.cmml"><mi id="S4.SS1.p3.6.m6.1.1.3.2" xref="S4.SS1.p3.6.m6.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p3.6.m6.1.1.3.1" xref="S4.SS1.p3.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p3.6.m6.1.1.3.3" xref="S4.SS1.p3.6.m6.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><apply id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m6.1.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p3.6.m6.1.1.2.cmml" xref="S4.SS1.p3.6.m6.1.1.2">𝑖</ci><apply id="S4.SS1.p3.6.m6.1.1.3.cmml" xref="S4.SS1.p3.6.m6.1.1.3"><times id="S4.SS1.p3.6.m6.1.1.3.1.cmml" xref="S4.SS1.p3.6.m6.1.1.3.1"></times><ci id="S4.SS1.p3.6.m6.1.1.3.2.cmml" xref="S4.SS1.p3.6.m6.1.1.3.2">𝑡</ci><ci id="S4.SS1.p3.6.m6.1.1.3.3.cmml" xref="S4.SS1.p3.6.m6.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">i_{th}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.6.m6.1d">italic_i start_POSTSUBSCRIPT italic_t italic_h end_POSTSUBSCRIPT</annotation></semantics></math> element in <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p3.7.m7.1"><semantics id="S4.SS1.p3.7.m7.1a"><mover accent="true" id="S4.SS1.p3.7.m7.1.1" xref="S4.SS1.p3.7.m7.1.1.cmml"><mi id="S4.SS1.p3.7.m7.1.1.2" xref="S4.SS1.p3.7.m7.1.1.2.cmml">m</mi><mo id="S4.SS1.p3.7.m7.1.1.1" xref="S4.SS1.p3.7.m7.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.7.m7.1b"><apply id="S4.SS1.p3.7.m7.1.1.cmml" xref="S4.SS1.p3.7.m7.1.1"><ci id="S4.SS1.p3.7.m7.1.1.1.cmml" xref="S4.SS1.p3.7.m7.1.1.1">~</ci><ci id="S4.SS1.p3.7.m7.1.1.2.cmml" xref="S4.SS1.p3.7.m7.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.7.m7.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.7.m7.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>.
The intention behind this maximization step is to make the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p3.8.m8.1"><semantics id="S4.SS1.p3.8.m8.1a"><mi id="S4.SS1.p3.8.m8.1.1" xref="S4.SS1.p3.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.8.m8.1b"><ci id="S4.SS1.p3.8.m8.1.1.cmml" xref="S4.SS1.p3.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.8.m8.1d">italic_k</annotation></semantics></math> important features more likely to have high probability scores (ideally close to 1).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.5"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.5.1">Global learning to explain (</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.2">G-L2x</span><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.5.3">, ours).</span>
As a counterpart, we propose a global method <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.4">G-L2x</span>based on <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.5">L2x</span>.
Our change is straightforward, where <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.6">L2x</span> generates a different distribution <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">bold_p</annotation></semantics></math> for each item, we apply the same <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.1"><semantics id="S4.SS1.p4.2.m2.1a"><mi id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.1d">bold_p</annotation></semantics></math> to all items.
In other words, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.7">G-L2x</span> includes a global selector layer <math alttext="\zeta" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m3.1"><semantics id="S4.SS1.p4.3.m3.1a"><mi id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml">ζ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><ci id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">𝜁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">\zeta</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.3.m3.1d">italic_ζ</annotation></semantics></math> (<math alttext="\zeta\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S4.SS1.p4.4.m4.1"><semantics id="S4.SS1.p4.4.m4.1a"><mrow id="S4.SS1.p4.4.m4.1.1" xref="S4.SS1.p4.4.m4.1.1.cmml"><mi id="S4.SS1.p4.4.m4.1.1.2" xref="S4.SS1.p4.4.m4.1.1.2.cmml">ζ</mi><mo id="S4.SS1.p4.4.m4.1.1.1" xref="S4.SS1.p4.4.m4.1.1.1.cmml">∈</mo><msup id="S4.SS1.p4.4.m4.1.1.3" xref="S4.SS1.p4.4.m4.1.1.3.cmml"><mi id="S4.SS1.p4.4.m4.1.1.3.2" xref="S4.SS1.p4.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S4.SS1.p4.4.m4.1.1.3.3" xref="S4.SS1.p4.4.m4.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.1b"><apply id="S4.SS1.p4.4.m4.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1"><in id="S4.SS1.p4.4.m4.1.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1.1"></in><ci id="S4.SS1.p4.4.m4.1.1.2.cmml" xref="S4.SS1.p4.4.m4.1.1.2">𝜁</ci><apply id="S4.SS1.p4.4.m4.1.1.3.cmml" xref="S4.SS1.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p4.4.m4.1.1.3.1.cmml" xref="S4.SS1.p4.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS1.p4.4.m4.1.1.3.2.cmml" xref="S4.SS1.p4.4.m4.1.1.3.2">ℝ</ci><ci id="S4.SS1.p4.4.m4.1.1.3.3.cmml" xref="S4.SS1.p4.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.1c">\zeta\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.4.m4.1d">italic_ζ ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>) to simulate <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S4.SS1.p4.5.m5.1"><semantics id="S4.SS1.p4.5.m5.1a"><mi id="S4.SS1.p4.5.m5.1.1" xref="S4.SS1.p4.5.m5.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.5.m5.1b"><ci id="S4.SS1.p4.5.m5.1.1.cmml" xref="S4.SS1.p4.5.m5.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.5.m5.1c">\mathbf{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.5.m5.1d">bold_p</annotation></semantics></math>, and sampling is conducted in the same way as <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.8">L2x</span> on the selector weights.
Thereby, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p4.5.9">G-L2x</span> will select the same features for all items in the dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.5"><span class="ltx_text ltx_font_bold" id="S4.SS1.p5.5.1">Concrete autoencoder (</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p5.5.2">Cae</span><span class="ltx_text ltx_font_bold" id="S4.SS1.p5.5.3">).</span>
<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p5.5.4">Cae</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib6" title="">6</a>]</cite> is a global method where the selector is the encoder part of an auto-encoder model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib30" title="">30</a>]</cite>.
Specifically, the selector compresses the input into a smaller representation <math alttext="\hat{x}" class="ltx_Math" display="inline" id="S4.SS1.p5.1.m1.1"><semantics id="S4.SS1.p5.1.m1.1a"><mover accent="true" id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mi id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">x</mi><mo id="S4.SS1.p5.1.m1.1.1.1" xref="S4.SS1.p5.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><ci id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1.1">^</ci><ci id="S4.SS1.p5.1.m1.1.1.2.cmml" xref="S4.SS1.p5.1.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">\hat{x}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.1.m1.1d">over^ start_ARG italic_x end_ARG</annotation></semantics></math>, by linearly combining selected features, i.e. <math alttext="x^{\top}\tilde{m}" class="ltx_Math" display="inline" id="S4.SS1.p5.2.m2.1"><semantics id="S4.SS1.p5.2.m2.1a"><mrow id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml"><msup id="S4.SS1.p5.2.m2.1.1.2" xref="S4.SS1.p5.2.m2.1.1.2.cmml"><mi id="S4.SS1.p5.2.m2.1.1.2.2" xref="S4.SS1.p5.2.m2.1.1.2.2.cmml">x</mi><mo id="S4.SS1.p5.2.m2.1.1.2.3" xref="S4.SS1.p5.2.m2.1.1.2.3.cmml">⊤</mo></msup><mo id="S4.SS1.p5.2.m2.1.1.1" xref="S4.SS1.p5.2.m2.1.1.1.cmml">⁢</mo><mover accent="true" id="S4.SS1.p5.2.m2.1.1.3" xref="S4.SS1.p5.2.m2.1.1.3.cmml"><mi id="S4.SS1.p5.2.m2.1.1.3.2" xref="S4.SS1.p5.2.m2.1.1.3.2.cmml">m</mi><mo id="S4.SS1.p5.2.m2.1.1.3.1" xref="S4.SS1.p5.2.m2.1.1.3.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><apply id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1"><times id="S4.SS1.p5.2.m2.1.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1.1"></times><apply id="S4.SS1.p5.2.m2.1.1.2.cmml" xref="S4.SS1.p5.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p5.2.m2.1.1.2.1.cmml" xref="S4.SS1.p5.2.m2.1.1.2">superscript</csymbol><ci id="S4.SS1.p5.2.m2.1.1.2.2.cmml" xref="S4.SS1.p5.2.m2.1.1.2.2">𝑥</ci><csymbol cd="latexml" id="S4.SS1.p5.2.m2.1.1.2.3.cmml" xref="S4.SS1.p5.2.m2.1.1.2.3">top</csymbol></apply><apply id="S4.SS1.p5.2.m2.1.1.3.cmml" xref="S4.SS1.p5.2.m2.1.1.3"><ci id="S4.SS1.p5.2.m2.1.1.3.1.cmml" xref="S4.SS1.p5.2.m2.1.1.3.1">~</ci><ci id="S4.SS1.p5.2.m2.1.1.3.2.cmml" xref="S4.SS1.p5.2.m2.1.1.3.2">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">x^{\top}\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.2.m2.1d">italic_x start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT over~ start_ARG italic_m end_ARG</annotation></semantics></math>, where <math alttext="\tilde{m}\in\mathbb{R}^{k\times d}" class="ltx_Math" display="inline" id="S4.SS1.p5.3.m3.1"><semantics id="S4.SS1.p5.3.m3.1a"><mrow id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml"><mover accent="true" id="S4.SS1.p5.3.m3.1.1.2" xref="S4.SS1.p5.3.m3.1.1.2.cmml"><mi id="S4.SS1.p5.3.m3.1.1.2.2" xref="S4.SS1.p5.3.m3.1.1.2.2.cmml">m</mi><mo id="S4.SS1.p5.3.m3.1.1.2.1" xref="S4.SS1.p5.3.m3.1.1.2.1.cmml">~</mo></mover><mo id="S4.SS1.p5.3.m3.1.1.1" xref="S4.SS1.p5.3.m3.1.1.1.cmml">∈</mo><msup id="S4.SS1.p5.3.m3.1.1.3" xref="S4.SS1.p5.3.m3.1.1.3.cmml"><mi id="S4.SS1.p5.3.m3.1.1.3.2" xref="S4.SS1.p5.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p5.3.m3.1.1.3.3" xref="S4.SS1.p5.3.m3.1.1.3.3.cmml"><mi id="S4.SS1.p5.3.m3.1.1.3.3.2" xref="S4.SS1.p5.3.m3.1.1.3.3.2.cmml">k</mi><mo id="S4.SS1.p5.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p5.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S4.SS1.p5.3.m3.1.1.3.3.3" xref="S4.SS1.p5.3.m3.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><apply id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1"><in id="S4.SS1.p5.3.m3.1.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1.1"></in><apply id="S4.SS1.p5.3.m3.1.1.2.cmml" xref="S4.SS1.p5.3.m3.1.1.2"><ci id="S4.SS1.p5.3.m3.1.1.2.1.cmml" xref="S4.SS1.p5.3.m3.1.1.2.1">~</ci><ci id="S4.SS1.p5.3.m3.1.1.2.2.cmml" xref="S4.SS1.p5.3.m3.1.1.2.2">𝑚</ci></apply><apply id="S4.SS1.p5.3.m3.1.1.3.cmml" xref="S4.SS1.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p5.3.m3.1.1.3.1.cmml" xref="S4.SS1.p5.3.m3.1.1.3">superscript</csymbol><ci id="S4.SS1.p5.3.m3.1.1.3.2.cmml" xref="S4.SS1.p5.3.m3.1.1.3.2">ℝ</ci><apply id="S4.SS1.p5.3.m3.1.1.3.3.cmml" xref="S4.SS1.p5.3.m3.1.1.3.3"><times id="S4.SS1.p5.3.m3.1.1.3.3.1.cmml" xref="S4.SS1.p5.3.m3.1.1.3.3.1"></times><ci id="S4.SS1.p5.3.m3.1.1.3.3.2.cmml" xref="S4.SS1.p5.3.m3.1.1.3.3.2">𝑘</ci><ci id="S4.SS1.p5.3.m3.1.1.3.3.3.cmml" xref="S4.SS1.p5.3.m3.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">\tilde{m}\in\mathbb{R}^{k\times d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.3.m3.1d">over~ start_ARG italic_m end_ARG ∈ blackboard_R start_POSTSUPERSCRIPT italic_k × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> can be viewed as approximated k-hot concrete selection, sampled from the selector weights (<math alttext="\zeta\in\mathbb{R}^{k\times d}" class="ltx_Math" display="inline" id="S4.SS1.p5.4.m4.1"><semantics id="S4.SS1.p5.4.m4.1a"><mrow id="S4.SS1.p5.4.m4.1.1" xref="S4.SS1.p5.4.m4.1.1.cmml"><mi id="S4.SS1.p5.4.m4.1.1.2" xref="S4.SS1.p5.4.m4.1.1.2.cmml">ζ</mi><mo id="S4.SS1.p5.4.m4.1.1.1" xref="S4.SS1.p5.4.m4.1.1.1.cmml">∈</mo><msup id="S4.SS1.p5.4.m4.1.1.3" xref="S4.SS1.p5.4.m4.1.1.3.cmml"><mi id="S4.SS1.p5.4.m4.1.1.3.2" xref="S4.SS1.p5.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p5.4.m4.1.1.3.3" xref="S4.SS1.p5.4.m4.1.1.3.3.cmml"><mi id="S4.SS1.p5.4.m4.1.1.3.3.2" xref="S4.SS1.p5.4.m4.1.1.3.3.2.cmml">k</mi><mo id="S4.SS1.p5.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p5.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S4.SS1.p5.4.m4.1.1.3.3.3" xref="S4.SS1.p5.4.m4.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.4.m4.1b"><apply id="S4.SS1.p5.4.m4.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1"><in id="S4.SS1.p5.4.m4.1.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1.1"></in><ci id="S4.SS1.p5.4.m4.1.1.2.cmml" xref="S4.SS1.p5.4.m4.1.1.2">𝜁</ci><apply id="S4.SS1.p5.4.m4.1.1.3.cmml" xref="S4.SS1.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p5.4.m4.1.1.3.1.cmml" xref="S4.SS1.p5.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS1.p5.4.m4.1.1.3.2.cmml" xref="S4.SS1.p5.4.m4.1.1.3.2">ℝ</ci><apply id="S4.SS1.p5.4.m4.1.1.3.3.cmml" xref="S4.SS1.p5.4.m4.1.1.3.3"><times id="S4.SS1.p5.4.m4.1.1.3.3.1.cmml" xref="S4.SS1.p5.4.m4.1.1.3.3.1"></times><ci id="S4.SS1.p5.4.m4.1.1.3.3.2.cmml" xref="S4.SS1.p5.4.m4.1.1.3.3.2">𝑘</ci><ci id="S4.SS1.p5.4.m4.1.1.3.3.3.cmml" xref="S4.SS1.p5.4.m4.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.4.m4.1c">\zeta\in\mathbb{R}^{k\times d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.4.m4.1d">italic_ζ ∈ blackboard_R start_POSTSUPERSCRIPT italic_k × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>). Therefore, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p5.5.5">Cae</span> might result in repetitive selection, and the input dimension to the predictor is reduced to <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p5.5.m5.1"><semantics id="S4.SS1.p5.5.m5.1a"><mi id="S4.SS1.p5.5.m5.1.1" xref="S4.SS1.p5.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.5.m5.1b"><ci id="S4.SS1.p5.5.m5.1.1.cmml" xref="S4.SS1.p5.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.5.m5.1d">italic_k</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.2.1">Instance-wise Feature Grouping (</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.2">Ifg</span><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.2.3">).</span>
<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.4">Ifg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib43" title="">43</a>]</cite> applies a similar approach as <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.5">L2x</span>, but clusters features into groups and then selects <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p6.1.m1.1"><semantics id="S4.SS1.p6.1.m1.1a"><mi id="S4.SS1.p6.1.m1.1.1" xref="S4.SS1.p6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.1.m1.1b"><ci id="S4.SS1.p6.1.m1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p6.1.m1.1d">italic_k</annotation></semantics></math> feature groups for prediction.
<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.6">Ifg</span> first assigns a group for each feature via Gumbel-sampling, and then makes a feature selection by Gumbel-sampling <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p6.2.m2.1"><semantics id="S4.SS1.p6.2.m2.1a"><mi id="S4.SS1.p6.2.m2.1.1" xref="S4.SS1.p6.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.2.m2.1b"><ci id="S4.SS1.p6.2.m2.1.1.cmml" xref="S4.SS1.p6.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p6.2.m2.1d">italic_k</annotation></semantics></math> out of the resulting groups.
This grouping decision is also guided by how rich the selected features are to recover the original input.
Therefore, apart from the ranking objective, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.7">Ifg</span> jointly optimizes an additional input restoring objective as well (similar to auto-encoders <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib30" title="">30</a>]</cite>).
<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p6.2.8">Ifg</span> is agnostic to the number of selected features and the group sizes, it can produce oversized groups and very large selections.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Regularization-based Feature Selection</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Instead of the budget-explicit feature selection, regularization-based methods induce sparsity through implicit constraints enforced by regularization terms in the training objective.
We propose modifications to three existing methods to make them applicable to the LTR setting.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.2"><span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.1">Invase</span><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.2.2">.</span>
We consider <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.3">Invase</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib69" title="">69</a>]</cite> to be a hybrid approach involving both sampling and regularization.
Built on the same structure as <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.4">L2x</span>, the selector of <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.5">Invase</span> generates a <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.2.6">boolean/hard mask</span> <math alttext="m" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_m</annotation></semantics></math> (instead of the approximation <math alttext="\tilde{m}" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mover accent="true" id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">m</mi><mo id="S4.SS2.p2.2.m2.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><ci id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1">~</ci><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\tilde{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">over~ start_ARG italic_m end_ARG</annotation></semantics></math>) via Bernoulli sampling to train the predictor.
Since this disables backpropagation, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.7">Invase</span> uses a customized loss function that does not need the gradients from the predictor to train the selector. The idea is to apply another individual baseline predictor model that takes the full-feature input, simultaneously with the predictor that takes the masked input. The loss difference between the two predictors is used as a scale to train the selector. Meanwhile, the L1 regularization is applied to the selector output to enforce selection sparsity. Ultimately, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p2.2.8">Invase</span> will push the selector to output a small set of selections which leads to the most similar predictions as using all features.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p3.1.1">LassoNet</span><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.2">.</span> As the name suggests, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p3.1.3">LassoNet</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib35" title="">35</a>]</cite> adapts a traditional Lasso (L1 regularization) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib62" title="">62</a>]</cite> on the first layer of a neural model to eliminate unnecessary features. The challenge with neural models is, all weights corresponding to a particular feature entry in the layer have to be zero in order to mask out the feature. Towards this, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p3.1.4">LassoNet</span> adds a residual layer with one weight per input feature to the original model to perform as the traditional Lasso. Then, after every optimization step, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p3.1.5">LassoNet</span> develops a proximal optimization algorithm to adjust the weights of the first layer, so that all absolute elements of each row are smaller than the respective weight of residual layer corresponding to a specific feature. Thereby, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p3.1.6">LassoNet</span> performs global selection and the sparsity scale is adjusted by the L1 regularization on the residual layer weights.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p4.1.1">TabNet</span><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.2">.</span>
Unlike the previous methods, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p4.1.3">TabNet</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib4" title="">4</a>]</cite> is non-composable and tied to a specific tree-style neural architecture. It imitates a step-wise selection process before it outputs the final prediction based only on the selected features.
Each step has the same neural component/block but with its own parameters, thus the model complexity and selection budget grow linearly with the number of steps. At each step, the full input is transformed by a feature transformer block first, and then an attentive transformer block conducts feature selection by sparsemax activation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib42" title="">42</a>]</cite>, as the weights in the resulting distribution corresponding to unselected features are zeros.
The final prediction is aggregated from all steps to simulate ensemble models. A final mask <math alttext="m" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">italic_m</annotation></semantics></math> is a union of selections from all steps, and the entropy of the selection probabilities is used as the sparsity regularization.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setup</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Since feature selection can be applied in various manners and situations, we structure our experiments around three scenarios:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i1.p1.1.1">Scenario 1: Simultaneously train and select</span>.
Both the ranking model and the feature selection are learned once and jointly. The methods are evaluated by the performance-sparsity trade-off.
It is the standard setup for evaluating embedded feature selection methods in the interpretable ML field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib43" title="">43</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.1">Scenario 2: Train then select with an enforced budget</span>.
Practitioners generally set hard limits to the computational costs a system may incur and the efficiency of the system can be greatly enhanced if it only requires a much smaller amount of features to reach competitive performance. Following the previous scenario, we evaluate the trained model with test instances where only a fixed amount of features (which the method deems important and selects frequently during training) are presented and the rest are masked out. The resulting ranking performance and the costs of computing the required features indicate how practical the method is in efficiency improvements.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Datasets and preprocessing</span>.
We choose three public benchmark datasets: MQ2008 (46 features) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib50" title="">50</a>]</cite>, Web30k (136 features) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib49" title="">49</a>]</cite> and Yahoo (699 features) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib14" title="">14</a>]</cite>, to cover varying numbers of available features.
We apply a <math alttext="\log_{1p}" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><msub id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">log</mi><mrow id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml"><mn id="S5.p2.1.m1.1.1.3.2" xref="S5.p2.1.m1.1.1.3.2.cmml">1</mn><mo id="S5.p2.1.m1.1.1.3.1" xref="S5.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.p2.1.m1.1.1.3.3" xref="S5.p2.1.m1.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><log id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2"></log><apply id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3"><times id="S5.p2.1.m1.1.1.3.1.cmml" xref="S5.p2.1.m1.1.1.3.1"></times><cn id="S5.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S5.p2.1.m1.1.1.3.2">1</cn><ci id="S5.p2.1.m1.1.1.3.3.cmml" xref="S5.p2.1.m1.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\log_{1p}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">roman_log start_POSTSUBSCRIPT 1 italic_p end_POSTSUBSCRIPT</annotation></semantics></math> transformation to the features of Web30k, as suggested in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib51" title="">51</a>]</cite>.
Yahoo contains cost labels for each feature, for Web30k we use cost estimates suggested by previous work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib21" title="">21</a>]</cite>.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>MQ2008 is omitted from cost analysis since no associated cost information is available.</span></span></span>
All reported results are evaluated on the held-out test set partitions of the datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Models</span>.
We use a standard feed-forward neural network with batch normalization, three fully-connected layers and tanh activation as the ranking model, denoted as <span class="ltx_text ltx_font_smallcaps" id="S5.p3.1.2">Dnn</span>.
According to the findings in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib51" title="">51</a>]</cite>, this simple model performs closely to the most effective transformer-based models, but requires much less resources to run.
The selector models of <span class="ltx_text ltx_font_smallcaps" id="S5.p3.1.3">L2x</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.p3.1.4">Invase</span> have the same architecture, and as the only exception, <span class="ltx_text ltx_font_smallcaps" id="S5.p3.1.5">TabNet</span> is applied with its own unalterable model (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S4" title="4 Feature Selection from Interpretable ML for LTR ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><span class="ltx_text ltx_font_bold" id="S5.p4.1.1">Implementation</span>.
Our experimental implementation is done in <span class="ltx_text ltx_font_italic" id="S5.p4.1.2">PyTorch Lightning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib19" title="">19</a>]</cite>.
For <span class="ltx_text ltx_font_smallcaps" id="S5.p4.1.3">TabNet</span> and <span class="ltx_text ltx_font_smallcaps" id="S5.p4.1.4">LassoNet</span> existing implementations were used.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/dreamquark-ai/tabnet" title="">https://github.com/dreamquark-ai/tabnet</a>; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lasso-net/lassonet" title="">https://github.com/lasso-net/lassonet</a></span></span></span>
We created our own implementations for the rest of the methods.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.20.4.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.6.3" style="font-size:90%;">Results of ranking performance and feature sparsity for methods applied in Scenario 1.
For comparison, we also include <span class="ltx_text ltx_font_smallcaps" id="S5.T2.6.3.1">Gbdt</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#bib.bib8" title="">8</a>]</cite> and <span class="ltx_text ltx_font_smallcaps" id="S5.T2.6.3.2">Dnn</span> baselines without feature selection as upper bound.
#F denotes the number of selected features.
Reported results are averaged over <math alttext="5" class="ltx_Math" display="inline" id="S5.T2.4.1.m1.1"><semantics id="S5.T2.4.1.m1.1b"><mn id="S5.T2.4.1.m1.1.1" xref="S5.T2.4.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.T2.4.1.m1.1c"><cn id="S5.T2.4.1.m1.1.1.cmml" type="integer" xref="S5.T2.4.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.1.m1.1d">5</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.1.m1.1e">5</annotation></semantics></math> random seeds (<span class="ltx_text ltx_font_italic" id="S5.T2.6.3.3">std</span> in parentheses).
Bold font indicates the highest performing selection method; the <math alttext="\star" class="ltx_Math" display="inline" id="S5.T2.5.2.m2.1"><semantics id="S5.T2.5.2.m2.1b"><mo id="S5.T2.5.2.m2.1.1" xref="S5.T2.5.2.m2.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.2.m2.1c"><ci id="S5.T2.5.2.m2.1.1.cmml" xref="S5.T2.5.2.m2.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.2.m2.1d">\star</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.2.m2.1e">⋆</annotation></semantics></math> and underlines denote scores that are <em class="ltx_emph ltx_font_italic" id="S5.T2.6.3.4">not</em> significantly outperformed by <span class="ltx_text ltx_font_smallcaps" id="S5.T2.6.3.5">Gbdt</span> and the bold-score method, respectively (<math alttext="p&gt;0.05" class="ltx_Math" display="inline" id="S5.T2.6.3.m3.1"><semantics id="S5.T2.6.3.m3.1b"><mrow id="S5.T2.6.3.m3.1.1" xref="S5.T2.6.3.m3.1.1.cmml"><mi id="S5.T2.6.3.m3.1.1.2" xref="S5.T2.6.3.m3.1.1.2.cmml">p</mi><mo id="S5.T2.6.3.m3.1.1.1" xref="S5.T2.6.3.m3.1.1.1.cmml">&gt;</mo><mn id="S5.T2.6.3.m3.1.1.3" xref="S5.T2.6.3.m3.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.3.m3.1c"><apply id="S5.T2.6.3.m3.1.1.cmml" xref="S5.T2.6.3.m3.1.1"><gt id="S5.T2.6.3.m3.1.1.1.cmml" xref="S5.T2.6.3.m3.1.1.1"></gt><ci id="S5.T2.6.3.m3.1.1.2.cmml" xref="S5.T2.6.3.m3.1.1.2">𝑝</ci><cn id="S5.T2.6.3.m3.1.1.3.cmml" type="float" xref="S5.T2.6.3.m3.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.3.m3.1d">p&gt;0.05</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.3.m3.1e">italic_p &gt; 0.05</annotation></semantics></math>, paired t-tests using Bonferonni’s correction).</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.13" style="width:433.6pt;height:232.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.0pt,19.2pt) scale(0.857680004338845,0.857680004338845) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.13.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.13.7.8.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.13.7.8.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.8.1.1.1">Listwise</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T2.13.7.8.1.2">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.8.1.2.1">MQ2008 NDCG@k</span> (%)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T2.13.7.8.1.3">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.8.1.3.1">Web30k NDCG@k</span> (%)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T2.13.7.8.1.4">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.8.1.4.1">Yahoo NDCG@k</span> (%)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.9.2">
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.9.2.1.1">loss</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.2">@1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.3">@10</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.4">#F</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.5">@1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.6">@10</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.7">#F</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.8">@1</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.9.2.9">@10</td>
<td class="ltx_td ltx_align_right" id="S5.T2.13.7.9.2.10">#F</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.10.3">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="10" id="S5.T2.13.7.10.3.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.10.3.1.1">Without feature selection.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.11.4">
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.11.4.1.1">Gbdt</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.2">69.3 (2.5)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.3">80.8 (1.7)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.4">46</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.5">50.4 (0.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.6">52 (0.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.7">136</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.8">72.2 (0.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.11.4.9">79.2 (0.1)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.13.7.11.4.10">699</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.2.2">
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.3"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.8.2.2.3.1">Dnn</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.7.1.1.1">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.7.1.1.1.1">66.2</span><sup class="ltx_sup" id="S5.T2.7.1.1.1.2"><span class="ltx_text ltx_font_italic" id="S5.T2.7.1.1.1.2.1">⋆</span></sup> (2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.2">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.2.2.2.1">80.2</span><sup class="ltx_sup" id="S5.T2.8.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S5.T2.8.2.2.2.2.1">⋆</span></sup> (0.6)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.4">46</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.5">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.8.2.2.5.1">46.1</span> (0.6)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.6">47.7 (0.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.7">136</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.8">69.4 (0.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.8.2.2.9">76.9 (0.1)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.8.2.2.10">699</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.12.5">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="S5.T2.13.7.12.5.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.12.5.1.1">Fixed-budget feature selection using the <span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.12.5.1.1.1">Dnn</span> ranking model.</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.13.7.12.5.2"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.13.6">
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.13.6.1.1">Cae</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.2">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.13.6.2.1">63.0</span> (1.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.3">78.7 (0.5)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.4">4</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.5">32.9 (2.9)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.6">36.6 (2.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.7">13</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.8">59.2 (0.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.13.6.9">69.5 (0.1)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.13.7.13.6.10">6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.9.3.3">
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.2"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.9.3.3.2.1">G-L2x</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.1">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.9.3.3.1.1">63.8</span><sup class="ltx_sup" id="S5.T2.9.3.3.1.2"><span class="ltx_text ltx_font_italic" id="S5.T2.9.3.3.1.2.1">⋆</span></sup> (1.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.3">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.9.3.3.3.1">79.1</span> (0.4)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.4">4</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.5">41.1 (0.9)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.6">44.4 (0.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.7">13</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.8">65.4 (0.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.9.3.3.9">74.0 (0.0)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.9.3.3.10">6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.14.7">
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.14.7.1.1">L2x</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.2">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.14.7.2.1">63.0</span> (2.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.3">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.14.7.3.1">78.7</span> (0.7)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.4">4</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.5">34.5 (2.4)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.6">39.7 (1.9)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.7">13</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.8">61.9 (1.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.14.7.9">73.2 (0.3)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.13.7.14.7.10">6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.15.8">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="S5.T2.13.7.15.8.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.15.8.1.1">Budget-agnostic feature selection using the <span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.15.8.1.1.1">Dnn</span> ranking model.</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.13.7.15.8.2"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.16.9">
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.16.9.1.1">Invase</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.2">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.16.9.2.1">62.5</span> (2.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.3">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.16.9.3.1">77.5</span> (2.1)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.4">5 (2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.5">15.1 (0.0)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.6">22.1 (0.0)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.7">0</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.8">38.7 (0.0)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.13.7.16.9.9">57.8 (0.0)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.13.7.16.9.10">0</td>
</tr>
<tr class="ltx_tr" id="S5.T2.11.5.5">
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.3"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.11.5.5.3.1">Ifg</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.10.4.4.1">
<span class="ltx_text ltx_font_bold" id="S5.T2.10.4.4.1.1">66.4<sup class="ltx_sup" id="S5.T2.10.4.4.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.10.4.4.1.1.1.1">⋆</span></sup></span> (0.9)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.2">
<span class="ltx_text ltx_font_bold" id="S5.T2.11.5.5.2.1">80.4<sup class="ltx_sup" id="S5.T2.11.5.5.2.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T2.11.5.5.2.1.1.1">⋆</span></sup></span> (0.5)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.4">20 (2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.5">32.5 (5.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.6">37.5 (5.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.7">72 (30)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.8">69.6 (0.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.11.5.5.9">77.1 (0.2)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.11.5.5.10">58 (3)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.6.6">
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.2"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.12.6.6.2.1">LassoNet</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.1">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.12.6.6.1.1">64.7</span><sup class="ltx_sup" id="S5.T2.12.6.6.1.2"><span class="ltx_text ltx_font_italic" id="S5.T2.12.6.6.1.2.1">⋆</span></sup> (2.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.3">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.12.6.6.3.1">79.3</span> (1.2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.4">6 (3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.5">39.4 (0.8)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.6">42.1 (0.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.7">8 (2)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.8">63.1 (2.3)</td>
<td class="ltx_td ltx_align_left" id="S5.T2.12.6.6.9">72.4 (1.5)</td>
<td class="ltx_td ltx_align_right" id="S5.T2.12.6.6.10">12 (4)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.17.10">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="S5.T2.13.7.17.10.1"><span class="ltx_text ltx_font_bold" id="S5.T2.13.7.17.10.1.1">Budget-agnostic feature selection using a method-specific ranking model.</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.13.7.17.10.2"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.13.7.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.2"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.13.7.7.2.1">TabNet</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.1">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.7.1.1">64.7</span><sup class="ltx_sup" id="S5.T2.13.7.7.1.2"><span class="ltx_text ltx_font_italic" id="S5.T2.13.7.7.1.2.1">⋆</span></sup> (2.7)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.3">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.13.7.7.3.1">78.2</span> (1.2)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.4">7 (3)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.5">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.7.5.1">47.0</span> (0.4)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.6">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.7.6.1">49.2</span> (0.1)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.7">8 (1)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.8">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.7.8.1">70.2</span> (0.4)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T2.13.7.7.9">
<span class="ltx_text ltx_font_bold" id="S5.T2.13.7.7.9.1">77.7</span> (0.1)</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T2.13.7.7.10">6 (1)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S5.F2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.F2.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F2.4.5.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r" id="S5.F2.4.5.1.1" style="padding:-5pt 1.4pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.F2.4.5.1.2" style="padding:-5pt 1.4pt;">   <span class="ltx_text" id="S5.F2.4.5.1.2.1" style="font-size:90%;">MQ2008</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.F2.4.5.1.3" style="padding:-5pt 1.4pt;">  <span class="ltx_text" id="S5.F2.4.5.1.3.1" style="font-size:90%;">Web30k</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.F2.4.5.1.4" style="padding:-5pt 1.4pt;">      <span class="ltx_text" id="S5.F2.4.5.1.4.1" style="font-size:90%;">Yahoo</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.F2.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S5.F2.3.3.4" style="padding:-5pt 1.4pt;"><span class="ltx_text" id="S5.F2.3.3.4.1" style="position:relative; bottom:48.0pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.F2.3.3.4.1.1" style="width:6.3pt;height:43.2pt;vertical-align:-18.5pt;"><span class="ltx_transformed_inner" style="width:43.2pt;transform:translate(-18.47pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.F2.3.3.4.1.1.1"><span class="ltx_text" id="S5.F2.3.3.4.1.1.1.1" style="font-size:90%;">NDCG@10</span></span>
</span></span></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S5.F2.1.1.1" style="padding:-5pt 1.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="105" id="S5.F2.1.1.1.g1" src="x2.png" width="152"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S5.F2.2.2.2" style="padding:-5pt 1.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="105" id="S5.F2.2.2.2.g1" src="x3.png" width="152"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S5.F2.3.3.3" style="padding:-5pt 1.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F2.3.3.3.g1" src=""/></td>
</tr>
<tr class="ltx_tr" id="S5.F2.4.4">
<td class="ltx_td ltx_nopad_l ltx_align_center" colspan="4" id="S5.F2.4.4.1" style="padding:-5pt 1.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S5.F2.4.4.1.g1" src=""/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.8.2.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S5.F2.6.1" style="font-size:90%;">Results of three fixed-budget methods applied to scenario 1. The x-axis indicates the pre-specified percentile of selected features (<math alttext="k" class="ltx_Math" display="inline" id="S5.F2.6.1.m1.1"><semantics id="S5.F2.6.1.m1.1b"><mi id="S5.F2.6.1.m1.1.1" xref="S5.F2.6.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F2.6.1.m1.1c"><ci id="S5.F2.6.1.m1.1.1.cmml" xref="S5.F2.6.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.6.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F2.6.1.m1.1e">italic_k</annotation></semantics></math>). The shaded area shows the standard deviation over 5 random seeds.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We report the findings in this section, aiming to answer two questions: (1) <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">how effective are investigated methods in the ranking setup?</span> and (2) <span class="ltx_text ltx_font_italic" id="S6.p1.1.2">can those methods improve efficiency?</span> Each question corresponds to one of the scenarios described in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5" title="5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Simultaneous Optimization and Selection</span>.
We begin by investigating the effectiveness of the feature selection methods when applied to Scenario 1, where feature selection and model optimization are performed simultaneously.
The results for this scenario are displayed in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.T2" title="Table 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.F2" title="Figure 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.T2" title="Table 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a> shows the ranking performance and the respective feature sparsity of all feature selection methods and two baselines without any selection as the upper-bound reference.
For fixed-budget methods, the budgets were set to 10% of the total number of features for MQ2008 and Web30k, and 1% for Yahoo (the results with varying budgets are displayed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.F2" title="Figure 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a>).
Since the sparsity of budget-agnostic methods is more difficult to control, we performed an extensive grid search and used the hyper-parameters that produced the highest ranking performance with a comparable feature sparsity as the other methods.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.T2" title="Table 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a> show that not all feature selection methods are equally effective, and their performance can vary greatly over datasets.
For instance, on MQ2008 all methods perform closely to the baselines, with only a fraction of the features.
However, this is not the case for bigger datasets like Web30k and Yahoo.
In particular, <span class="ltx_text ltx_font_smallcaps" id="S6.p4.1.1">Invase</span> selects no features at all due to big uncertainty in selection (for this reason, we omit <span class="ltx_text ltx_font_smallcaps" id="S6.p4.1.2">Invase</span> from all further comparisons). On the other hand, <span class="ltx_text ltx_font_smallcaps" id="S6.p4.1.3">Ifg</span> performs poorly in inducing sparsity, mainly because of its input reconstruction objective, whereas the ranking performance is not substantially better than the rest of methods. Additionally, <span class="ltx_text ltx_font_smallcaps" id="S6.p4.1.4">Cae</span> does not seem effective either, and furthermore, increasing the selected features does not always result in better ranking performance (cf. Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S5.F2" title="Figure 2 ‣ 5 Experimental Setup ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">2</span></a>).
This is most-likely because <span class="ltx_text ltx_font_smallcaps" id="S6.p4.1.5">Cae</span> samples with replacement, and thus the same features can be selected repeatedly.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1">In contrast, the other two sampling-based methods <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.1">L2x</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.2">G-L2x</span> are designed to avoid the repetitive selection issue.
Overall, the global selection <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.3">G-L2x</span> outperforms the local counterpart <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.4">L2x</span>, possibly because global selection generalizes better to unseen data.
Another global method <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.5">LassoNet</span> is also inferior to <span class="ltx_text ltx_font_smallcaps" id="S6.p5.1.6">G-L2x</span>, mainly due to the difficulties in sparsity weight tuning and manually adjusting weights in the input layer.</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p" id="S6.p6.1">Lastly, <span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.1">TabNet</span> shows the best performance-sparsity balance across all datasets, and even outperforms the <span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.2">Dnn</span> baseline.
Although, the comparison between <span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.3">TabNet</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.4">Dnn</span> is not completely fair, as they optimize different neural architectures.
It does reveal large feature redundancies in these datasets:
<span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.5">TabNet</span> uses &lt;10% of features on Web30k and 1% on Yahoo, yet still beats the <span class="ltx_text ltx_font_smallcaps" id="S6.p6.1.6">Dnn</span> baseline with all features.</p>
</div>
<div class="ltx_para" id="S6.p7">
<p class="ltx_p" id="S6.p7.2">To summarize,
we find that the local method <span class="ltx_text ltx_font_smallcaps" id="S6.p7.2.1">TabNet</span> is the most effective at balancing ranking performance and sparsity. Slightly inferior but competitive enough is the global method <span class="ltx_text ltx_font_smallcaps" id="S6.p7.2.2">G-L2x</span>, which reached <math alttext="&gt;95\%" class="ltx_Math" display="inline" id="S6.p7.1.m1.1"><semantics id="S6.p7.1.m1.1a"><mrow id="S6.p7.1.m1.1.1" xref="S6.p7.1.m1.1.1.cmml"><mi id="S6.p7.1.m1.1.1.2" xref="S6.p7.1.m1.1.1.2.cmml"></mi><mo id="S6.p7.1.m1.1.1.1" xref="S6.p7.1.m1.1.1.1.cmml">&gt;</mo><mrow id="S6.p7.1.m1.1.1.3" xref="S6.p7.1.m1.1.1.3.cmml"><mn id="S6.p7.1.m1.1.1.3.2" xref="S6.p7.1.m1.1.1.3.2.cmml">95</mn><mo id="S6.p7.1.m1.1.1.3.1" xref="S6.p7.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.1.m1.1b"><apply id="S6.p7.1.m1.1.1.cmml" xref="S6.p7.1.m1.1.1"><gt id="S6.p7.1.m1.1.1.1.cmml" xref="S6.p7.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S6.p7.1.m1.1.1.2.cmml" xref="S6.p7.1.m1.1.1.2">absent</csymbol><apply id="S6.p7.1.m1.1.1.3.cmml" xref="S6.p7.1.m1.1.1.3"><csymbol cd="latexml" id="S6.p7.1.m1.1.1.3.1.cmml" xref="S6.p7.1.m1.1.1.3.1">percent</csymbol><cn id="S6.p7.1.m1.1.1.3.2.cmml" type="integer" xref="S6.p7.1.m1.1.1.3.2">95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.1.m1.1c">&gt;95\%</annotation><annotation encoding="application/x-llamapun" id="S6.p7.1.m1.1d">&gt; 95 %</annotation></semantics></math> of baseline performance with only 1% features on Yahoo and <math alttext="&gt;93\%" class="ltx_Math" display="inline" id="S6.p7.2.m2.1"><semantics id="S6.p7.2.m2.1a"><mrow id="S6.p7.2.m2.1.1" xref="S6.p7.2.m2.1.1.cmml"><mi id="S6.p7.2.m2.1.1.2" xref="S6.p7.2.m2.1.1.2.cmml"></mi><mo id="S6.p7.2.m2.1.1.1" xref="S6.p7.2.m2.1.1.1.cmml">&gt;</mo><mrow id="S6.p7.2.m2.1.1.3" xref="S6.p7.2.m2.1.1.3.cmml"><mn id="S6.p7.2.m2.1.1.3.2" xref="S6.p7.2.m2.1.1.3.2.cmml">93</mn><mo id="S6.p7.2.m2.1.1.3.1" xref="S6.p7.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p7.2.m2.1b"><apply id="S6.p7.2.m2.1.1.cmml" xref="S6.p7.2.m2.1.1"><gt id="S6.p7.2.m2.1.1.1.cmml" xref="S6.p7.2.m2.1.1.1"></gt><csymbol cd="latexml" id="S6.p7.2.m2.1.1.2.cmml" xref="S6.p7.2.m2.1.1.2">absent</csymbol><apply id="S6.p7.2.m2.1.1.3.cmml" xref="S6.p7.2.m2.1.1.3"><csymbol cd="latexml" id="S6.p7.2.m2.1.1.3.1.cmml" xref="S6.p7.2.m2.1.1.3.1">percent</csymbol><cn id="S6.p7.2.m2.1.1.3.2.cmml" type="integer" xref="S6.p7.2.m2.1.1.3.2">93</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p7.2.m2.1c">&gt;93\%</annotation><annotation encoding="application/x-llamapun" id="S6.p7.2.m2.1d">&gt; 93 %</annotation></semantics></math> with 10% on Web30k.</p>
</div>
<figure class="ltx_figure" id="S6.F3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.F3.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.F3.5.6.1">
<td class="ltx_td ltx_nopad_l ltx_align_center" colspan="2" id="S6.F3.5.6.1.1" style="padding:-3pt 1.1pt;">Feature Cost</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" colspan="2" id="S6.F3.5.6.1.2" style="padding:-3pt 1.1pt;">Ranking Performance (NDCG@10)</td>
</tr>
<tr class="ltx_tr" id="S6.F3.5.7.2">
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S6.F3.5.7.2.1" style="padding:-3pt 1.1pt;"><span class="ltx_text" id="S6.F3.5.7.2.1.1" style="font-size:90%;">Web30k</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S6.F3.5.7.2.2" style="padding:-3pt 1.1pt;"><span class="ltx_text" id="S6.F3.5.7.2.2.1" style="font-size:90%;">Yahoo</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S6.F3.5.7.2.3" style="padding:-3pt 1.1pt;"><span class="ltx_text" id="S6.F3.5.7.2.3.1" style="font-size:90%;">Web30k</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S6.F3.5.7.2.4" style="padding:-3pt 1.1pt;"><span class="ltx_text" id="S6.F3.5.7.2.4.1" style="font-size:90%;">Yahoo</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.F3.4.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.F3.1.1.1" style="padding:-3pt 1.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S6.F3.1.1.1.g1" src=""/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.F3.2.2.2" style="padding:-3pt 1.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="121" id="S6.F3.2.2.2.g1" src="x7.png" width="121"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.F3.3.3.3" style="padding:-3pt 1.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="121" id="S6.F3.3.3.3.g1" src="x8.png" width="117"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S6.F3.4.4.4" style="padding:-3pt 1.1pt;"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S6.F3.4.4.4.g1" src=""/></td>
</tr>
<tr class="ltx_tr" id="S6.F3.5.5">
<td class="ltx_td ltx_nopad_l ltx_align_center" colspan="4" id="S6.F3.5.5.1" style="padding:-3pt 1.1pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="19" id="S6.F3.5.5.1.g1" src="x10.png" width="485"/>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.9.2.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S6.F3.7.1" style="font-size:90%;">Scenario 2. Feature cost (left two) and ranking performance (right two) under incomplete input. The x-axis indicates how many percentages of features are present in the input, to test the trained ranking model. Note this differs from specifying <math alttext="k" class="ltx_Math" display="inline" id="S6.F3.7.1.m1.1"><semantics id="S6.F3.7.1.m1.1b"><mi id="S6.F3.7.1.m1.1.1" xref="S6.F3.7.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.F3.7.1.m1.1c"><ci id="S6.F3.7.1.m1.1.1.cmml" xref="S6.F3.7.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.7.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S6.F3.7.1.m1.1e">italic_k</annotation></semantics></math> during training for fixed-budget methods in scenario 1.
</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S6.p8">
<p class="ltx_p" id="S6.p8.1"><span class="ltx_text ltx_font_bold" id="S6.p8.1.1">Feature Selection for Trained Ranking Models</span>.
Next, we evaluate the methods in Scenario 2, where only a specified budget (i.e., a given number of features) of features are present in the test input.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.07782v1#S6.F3" title="Figure 3 ‣ 6 Results ‣ Is Interpretable Machine Learning Effective at Feature Selection for Neural Learning-to-Rank?"><span class="ltx_text ltx_ref_tag">3</span></a> displays both the ranking performance and the total feature cost for varying degrees of sparsity.
The costs represent the time it requires to retrieve the selected feature sets, and allow us to estimate the actual efficiency improvements they provide.</p>
</div>
<div class="ltx_para" id="S6.p9">
<p class="ltx_p" id="S6.p9.1">Unlike previous scenario, all local methods including <span class="ltx_text ltx_font_smallcaps" id="S6.p9.1.1">TabNet</span>, are no longer able to maintain superior performance.
This is because for local methods, the selection is made conditioned on full input information,
and an incomplete input could affect the selection and thus disrupt its prediction performance.</p>
</div>
<div class="ltx_para" id="S6.p10">
<p class="ltx_p" id="S6.p10.1">In contrast, global methods are immune to input changes. Therefore, <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.1">Cae</span> is still not performing well as it did in Scenario 1;
<span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.2">G-L2x</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.3">LassoNet</span> provide the best overall performance under small costs.
<span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.4">LassoNet</span> maintains baseline performance with less than 40% of features on both datasets, while <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.5">G-L2x</span> outperforms <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.6">LassoNet</span> when selected features are less than 30%. Meanwhile, it also shows <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.7">LassoNet</span> tends to select more costly features than <span class="ltx_text ltx_font_smallcaps" id="S6.p10.1.8">G-L2x</span>.</p>
</div>
<div class="ltx_para" id="S6.p11">
<p class="ltx_p" id="S6.p11.1">To conclude, we find that global methods <span class="ltx_text ltx_font_smallcaps" id="S6.p11.1.1">G-L2x</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.p11.1.2">LassoNet</span> perform the best in Scenario 2, where upcoming query inputs are masked under enforced feature budgets. Particularly, <span class="ltx_text ltx_font_smallcaps" id="S6.p11.1.3">G-L2x</span> is superior in both ranking and computing cost when the feature budget is small. This translates to substantial efficiency improvements in practical terms, as ranking performance is maintained by selected features only.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The main goal of this work is to bring the interpretable ML and the LTR fields closer together.
To this end, we have studied whether feature selection methods from the interpretable ML are effective for neural LTR, for both interpretability and efficiency purposes.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Inspired by the scarcity of feature selection methods for neural ranking models in previous work,
we adapted six existing methods from the interpretable ML for the neural LTR setting, and also proposed our own <span class="ltx_text ltx_font_smallcaps" id="S7.p2.1.1">G-L2x</span> approach.
We discussed different properties of these methods and their relevance to the LTR task.
Lastly, we performed extensive experiments to evaluate the methods in terms of their trade-offs between ranking performance and sparsity, in addition, their efficiency improvements through feature cost reductions.
Our results have shown that several methods from interpretable ML are highly effective at embedded feature selection for neural LTR.
In particular, the local method <span class="ltx_text ltx_font_smallcaps" id="S7.p2.1.2">TabNet</span> can reach the upper bound with less than 10 features; the global methods, in particular <span class="ltx_text ltx_font_smallcaps" id="S7.p2.1.3">G-L2x</span>, can reduce feature retrieval costs by more than 70%, while maintaining 96% of performance relative to a full feature model.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">We hope our investigation can bridge the gap between the LTR and interpretable ML fields. The future work can be developing more interpretable and efficient ranking systems, and how that interpretability could support both practitioners and the users of ranking systems.</p>
</div>
<section class="ltx_subsubsection" id="S7.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.0.1 </span>Acknowledgements</h4>
<div class="ltx_para" id="S7.SS0.SSS1.p1">
<p class="ltx_p" id="S7.SS0.SSS1.p1.1">This work is partially supported by German Research Foundation (DFG), under the Project IREM with grant No. AN 996/1-1, and by the Netherlands Organisation for Scientific Research (NWO) under grant No. VI.Veni.222.269.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Abdul, A.M., von der Weth, C., Kankanhalli, M.S., Lim, B.Y.: COGAM: measuring and moderating cognitive load in machine learning model explanations. In: Bernhaupt, R., Mueller, F.F., Verweij, D., Andres, J., McGrenere, J., Cockburn, A., Avellino, I., Goguey, A., Bjøn, P., Zhao, S., Samson, B.P., Kocielnik, R. (eds.) CHI ’20: CHI Conference on Human Factors in Computing Systems, Honolulu, HI, USA, April 25-30, 2020. pp. 1–14. ACM (2020). https://doi.org/10.1145/3313831.3376615, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3313831.3376615" title="">https://doi.org/10.1145/3313831.3376615</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Alvarez-Melis, D., Jaakkola, T.S.: Towards robust interpretability with self-explaining neural networks. In: Bengio, S., Wallach, H.M., Larochelle, H., Grauman, K., Cesa-Bianchi, N., Garnett, R. (eds.) Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada. pp. 7786–7795 (2018), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html" title="">https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Arapakis, I., Bai, X., Cambazoglu, B.B.: Impact of response latency on user behavior in web search. In: Geva, S., Trotman, A., Bruza, P., Clarke, C.L.A., Järvelin, K. (eds.) The 37th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’14, Gold Coast , QLD, Australia - July 06 - 11, 2014. pp. 103–112. ACM (2014). https://doi.org/10.1145/2600428.2609627, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2600428.2609627" title="">https://doi.org/10.1145/2600428.2609627</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Arik, S.Ö., Pfister, T.: Tabnet: Attentive interpretable tabular learning. In: Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021. pp. 6679–6687. AAAI Press (2021). https://doi.org/10.1609/AAAI.V35I8.16826, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aaai.v35i8.16826" title="">https://doi.org/10.1609/aaai.v35i8.16826</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Bai, X., Cambazoglu, B.B.: Impact of response latency on sponsored search. Inf. Process. Manag. <span class="ltx_text ltx_font_bold" id="bib.bib5.1.1">56</span>(1), 110–129 (2019). https://doi.org/10.1016/J.IPM.2018.10.005, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.ipm.2018.10.005" title="">https://doi.org/10.1016/j.ipm.2018.10.005</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Balin, M.F., Abid, A., Zou, J.Y.: Concrete autoencoders: Differentiable feature selection and reconstruction. In: Chaudhuri, K., Salakhutdinov, R. (eds.) Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA. Proceedings of Machine Learning Research, vol. 97, pp. 444–453. PMLR (2019), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v97/balin19a.html" title="">http://proceedings.mlr.press/v97/balin19a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Barreda-Ángeles, M., Arapakis, I., Bai, X., Cambazoglu, B.B., Pereda-Baños, A.: Unconscious physiological effects of search latency on users and their click behaviour. In: Baeza-Yates, R., Lalmas, M., Moffat, A., Ribeiro-Neto, B.A. (eds.) Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, Santiago, Chile, August 9-13, 2015. pp. 203–212. ACM (2015). https://doi.org/10.1145/2766462.2767719, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2766462.2767719" title="">https://doi.org/10.1145/2766462.2767719</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Bruch, S.: An alternative cross entropy loss for learning-to-rank. In: Leskovec, J., Grobelnik, M., Najork, M., Tang, J., Zia, L. (eds.) WWW ’21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021. pp. 118–126. ACM / IW3C2 (2021). https://doi.org/10.1145/3442381.3449794, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442381.3449794" title="">https://doi.org/10.1145/3442381.3449794</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Bruch, S., Wang, X., Bendersky, M., Najork, M.: An analysis of the softmax cross entropy loss for learning-to-rank with binary relevance. In: Fang, Y., Zhang, Y., Allan, J., Balog, K., Carterette, B., Guo, J. (eds.) Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval, ICTIR 2019, Santa Clara, CA, USA, October 2-5, 2019. pp. 75–78. ACM (2019). https://doi.org/10.1145/3341981.3344221, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3341981.3344221" title="">https://doi.org/10.1145/3341981.3344221</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Burges, C.J.C., Ragno, R., Le, Q.V.: Learning to rank with nonsmooth cost functions. In: Schölkopf, B., Platt, J.C., Hofmann, T. (eds.) Advances in Neural Information Processing Systems 19, Proceedings of the Twentieth Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 4-7, 2006. pp. 193–200. MIT Press (2006), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2006/hash/af44c4c56f385c43f2529f9b1b018f6a-Abstract.html" title="">https://proceedings.neurips.cc/paper/2006/hash/af44c4c56f385c43f2529f9b1b018f6a-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Burges, C.J.C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N., Hullender, G.N.: Learning to rank using gradient descent. In: Raedt, L.D., Wrobel, S. (eds.) Machine Learning, Proceedings of the Twenty-Second International Conference (ICML 2005), Bonn, Germany, August 7-11, 2005. ACM International Conference Proceeding Series, vol. 119, pp. 89–96. ACM (2005). https://doi.org/10.1145/1102351.1102363, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1102351.1102363" title="">https://doi.org/10.1145/1102351.1102363</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Burges, C.J.: From ranknet to lambdarank to lambdamart: An overview. Learning <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">11</span>(23-581),  81 (2010)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Cao, Z., Qin, T., Liu, T., Tsai, M., Li, H.: Learning to rank: from pairwise approach to listwise approach. In: Ghahramani, Z. (ed.) Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML 2007), Corvallis, Oregon, USA, June 20-24, 2007. ACM International Conference Proceeding Series, vol. 227, pp. 129–136. ACM (2007). https://doi.org/10.1145/1273496.1273513, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1273496.1273513" title="">https://doi.org/10.1145/1273496.1273513</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Chapelle, O., Chang, Y.: Yahoo! learning to rank challenge overview. In: Chapelle, O., Chang, Y., Liu, T. (eds.) Proceedings of the Yahoo! Learning to Rank Challenge, held at ICML 2010, Haifa, Israel, June 25, 2010. JMLR Proceedings, vol. 14, pp. 1–24. JMLR.org (2011), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v14/chapelle11a.html" title="">http://proceedings.mlr.press/v14/chapelle11a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Chapelle, O., Keerthi, S.S.: Efficient algorithms for ranking with svms. Inf. Retr. <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">13</span>(3), 201–215 (2010). https://doi.org/10.1007/S10791-009-9109-9, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10791-009-9109-9" title="">https://doi.org/10.1007/s10791-009-9109-9</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Chen, J., Song, L., Wainwright, M.J., Jordan, M.I.: Learning to explain: An information-theoretic perspective on model interpretation. In: Dy, J.G., Krause, A. (eds.) Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018. Proceedings of Machine Learning Research, vol. 80, pp. 882–891. PMLR (2018), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v80/chen18j.html" title="">http://proceedings.mlr.press/v80/chen18j.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Dato, D., Lucchese, C., Nardini, F.M., Orlando, S., Perego, R., Tonellotto, N., Venturini, R.: Fast ranking with additive ensembles of oblivious and non-oblivious regression trees. ACM Trans. Inf. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib17.1.1">35</span>(2), 15:1–15:31 (2016). https://doi.org/10.1145/2987380, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2987380" title="">https://doi.org/10.1145/2987380</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Du, M., Liu, N., Hu, X.: Techniques for interpretable machine learning. Commun. ACM <span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">63</span>(1), 68–77 (2020). https://doi.org/10.1145/3359786, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3359786" title="">https://doi.org/10.1145/3359786</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Falcon, W., et al.: Pytorch lightning. GitHub. Note: https://github. com/PyTorchLightning/pytorch-lightning <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">3</span>,  6 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Freund, Y., Iyer, R.D., Schapire, R.E., Singer, Y.: An efficient boosting algorithm for combining preferences. In: Shavlik, J.W. (ed.) Proceedings of the Fifteenth International Conference on Machine Learning (ICML 1998), Madison, Wisconsin, USA, July 24-27, 1998. pp. 170–178. Morgan Kaufmann (1998)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Gallagher, L., Chen, R., Blanco, R., Culpepper, J.S.: Joint optimization of cascade ranking models. In: Culpepper, J.S., Moffat, A., Bennett, P.N., Lerman, K. (eds.) Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February 11-15, 2019. pp. 15–23. ACM (2019). https://doi.org/10.1145/3289600.3290986, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3289600.3290986" title="">https://doi.org/10.1145/3289600.3290986</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Geng, X., Liu, T., Qin, T., Li, H.: Feature selection for ranking. In: Kraaij, W., de Vries, A.P., Clarke, C.L.A., Fuhr, N., Kando, N. (eds.) SIGIR 2007: Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Amsterdam, The Netherlands, July 23-27, 2007. pp. 407–414. ACM (2007). https://doi.org/10.1145/1277741.1277811, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1277741.1277811" title="">https://doi.org/10.1145/1277741.1277811</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Gigli, A., Lucchese, C., Nardini, F.M., Perego, R.: Fast feature selection for learning to rank. In: Carterette, B., Fang, H., Lalmas, M., Nie, J. (eds.) Proceedings of the 2016 ACM on International Conference on the Theory of Information Retrieval, ICTIR 2016, Newark, DE, USA, September 12- 6, 2016. pp. 167–170. ACM (2016). https://doi.org/10.1145/2970398.2970433, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2970398.2970433" title="">https://doi.org/10.1145/2970398.2970433</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Jang, E., Gu, S., Poole, B.: Categorical reparametrization with gumble-softmax (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Järvelin, K., Kekäläinen, J.: Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">20</span>(4), 422–446 (2002). https://doi.org/10.1145/582415.582418, <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://doi.acm.org/10.1145/582415.582418" title="">http://doi.acm.org/10.1145/582415.582418</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Joachims, T.: Optimizing search engines using clickthrough data. In: Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, July 23-26, 2002, Edmonton, Alberta, Canada. pp. 133–142. ACM (2002). https://doi.org/10.1145/775047.775067, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/775047.775067" title="">https://doi.org/10.1145/775047.775067</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Joachims, T.: Training linear svms in linear time. In: Eliassi-Rad, T., Ungar, L.H., Craven, M., Gunopulos, D. (eds.) Proceedings of the Twelfth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Philadelphia, PA, USA, August 20-23, 2006. pp. 217–226. ACM (2006). https://doi.org/10.1145/1150402.1150429, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1150402.1150429" title="">https://doi.org/10.1145/1150402.1150429</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Kaur, H., Nori, H., Jenkins, S., Caruana, R., Wallach, H.M., Vaughan, J.W.: Interpreting interpretability: Understanding data scientists’ use of interpretability tools for machine learning. In: Bernhaupt, R., Mueller, F.F., Verweij, D., Andres, J., McGrenere, J., Cockburn, A., Avellino, I., Goguey, A., Bjøn, P., Zhao, S., Samson, B.P., Kocielnik, R. (eds.) CHI ’20: CHI Conference on Human Factors in Computing Systems, Honolulu, HI, USA, April 25-30, 2020. pp. 1–14. ACM (2020). https://doi.org/10.1145/3313831.3376219, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3313831.3376219" title="">https://doi.org/10.1145/3313831.3376219</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., Liu, T.: Lightgbm: A highly efficient gradient boosting decision tree. In: Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. pp. 3146–3154 (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html" title="">https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: Bengio, Y., LeCun, Y. (eds.) 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings (2014), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1312.6114" title="">http://arxiv.org/abs/1312.6114</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Lai, H., Pan, Y., Liu, C., Lin, L., Wu, J.: Sparse learning-to-rank via an efficient primal-dual algorithm. IEEE Trans. Computers <span class="ltx_text ltx_font_bold" id="bib.bib31.1.1">62</span>(6), 1221–1233 (2013). https://doi.org/10.1109/TC.2012.62, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TC.2012.62" title="">https://doi.org/10.1109/TC.2012.62</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Lai, H., Pan, Y., Liu, C., Lin, L., Wu, J.: Sparse learning-to-rank via an efficient primal-dual algorithm. IEEE Trans. Computers <span class="ltx_text ltx_font_bold" id="bib.bib32.1.1">62</span>(6), 1221–1233 (2013). https://doi.org/10.1109/TC.2012.62, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TC.2012.62" title="">https://doi.org/10.1109/TC.2012.62</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Lai, H., Pan, Y., Tang, Y., Yu, R.: Fsmrank: Feature selection algorithm for learning to rank. IEEE Trans. Neural Networks Learn. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib33.1.1">24</span>(6), 940–952 (2013). https://doi.org/10.1109/TNNLS.2013.2247628, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TNNLS.2013.2247628" title="">https://doi.org/10.1109/TNNLS.2013.2247628</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Laporte, L., Flamary, R., Canu, S., Déjean, S., Mothe, J.: Nonconvex regularizations for feature selection in ranking with sparse SVM. IEEE Trans. Neural Networks Learn. Syst. <span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">25</span>(6), 1118–1130 (2014). https://doi.org/10.1109/TNNLS.2013.2286696, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TNNLS.2013.2286696" title="">https://doi.org/10.1109/TNNLS.2013.2286696</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Lemhadri, I., Ruan, F., Abraham, L., Tibshirani, R.: Lassonet: A neural network with feature sparsity. J. Mach. Learn. Res. <span class="ltx_text ltx_font_bold" id="bib.bib35.1.1">22</span>, 127:1–127:29 (2021), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://jmlr.org/papers/v22/20-848.html" title="">http://jmlr.org/papers/v22/20-848.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Leonhardt, J., Rudra, K., Anand, A.: Extractive explanations for interpretable text ranking. ACM Trans. Inf. Syst. (dec 2022). https://doi.org/10.1145/3576924, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3576924" title="">https://doi.org/10.1145/3576924</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Li, P., Burges, C.J.C., Wu, Q.: Mcrank: Learning to rank using multiple classification and gradient boosting. In: Platt, J.C., Koller, D., Singer, Y., Roweis, S.T. (eds.) Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007. pp. 897–904. Curran Associates, Inc. (2007), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2007/hash/b86e8d03fe992d1b0e19656875ee557c-Abstract.html" title="">https://proceedings.neurips.cc/paper/2007/hash/b86e8d03fe992d1b0e19656875ee557c-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Liu, T.: Learning to rank for information retrieval. Found. Trends Inf. Retr. <span class="ltx_text ltx_font_bold" id="bib.bib38.1.1">3</span>(3), 225–331 (2009). https://doi.org/10.1561/1500000016, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1561/1500000016" title="">https://doi.org/10.1561/1500000016</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Lucchese, C., Nardini, F.M., Orlando, S., Perego, R., Veneri, A.: ILMART: interpretable ranking with constrained lambdamart. In: SIGIR ’22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022. pp. 2255–2259. ACM (2022). https://doi.org/10.1145/3477495.3531840, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531840" title="">https://doi.org/10.1145/3477495.3531840</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Lucchese, C., Nardini, F.M., Orlando, S., Perego, R., Veneri, A.: ILMART: interpretable ranking with constrained lambdamart. In: Amigó, E., Castells, P., Gonzalo, J., Carterette, B., Culpepper, J.S., Kazai, G. (eds.) SIGIR ’22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022. pp. 2255–2259. ACM (2022). https://doi.org/10.1145/3477495.3531840, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531840" title="">https://doi.org/10.1145/3477495.3531840</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Lundberg, S.M., Lee, S.: A unified approach to interpreting model predictions. In: Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. pp. 4765–4774 (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html" title="">https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Martins, A.F.T., Astudillo, R.F.: From softmax to sparsemax: A sparse model of attention and multi-label classification. In: Balcan, M., Weinberger, K.Q. (eds.) Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016. JMLR Workshop and Conference Proceedings, vol. 48, pp. 1614–1623. JMLR.org (2016), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v48/martins16.html" title="">http://proceedings.mlr.press/v48/martins16.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Masoomi, A., Wu, C., Zhao, T., Wang, Z., Castaldi, P.J., Dy, J.G.: Instance-wise feature grouping. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual (2020), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html" title="">https://proceedings.neurips.cc/paper/2020/hash/9b10a919ddeb07e103dc05ff523afe38-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Molnar, C.: Interpretable machine learning. Lulu. com (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Pan, F., Converse, T., Ahn, D., Salvetti, F., Donato, G.: Feature selection for ranking using boosted trees. In: Cheung, D.W., Song, I., Chu, W.W., Hu, X., Lin, J. (eds.) Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM 2009, Hong Kong, China, November 2-6, 2009. pp. 2025–2028. ACM (2009). https://doi.org/10.1145/1645953.1646292, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1645953.1646292" title="">https://doi.org/10.1145/1645953.1646292</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Pang, L., Xu, J., Ai, Q., Lan, Y., Cheng, X., Wen, J.: Setrank: Learning a permutation-invariant ranking model for information retrieval. In: Huang, J.X., Chang, Y., Cheng, X., Kamps, J., Murdock, V., Wen, J., Liu, Y. (eds.) Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020. pp. 499–508. ACM (2020). https://doi.org/10.1145/3397271.3401104, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401104" title="">https://doi.org/10.1145/3397271.3401104</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Pobrotyn, P., Bartczak, T., Synowiec, M., Bialobrzeski, R., Bojar, J.: Context-aware learning to rank with self-attention. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib47.1.1">abs/2005.10084</span> (2020), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2005.10084" title="">https://arxiv.org/abs/2005.10084</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Purpura, A., Buchner, K., Silvello, G., Susto, G.A.: Neural feature selection for learning to rank. In: Hiemstra, D., Moens, M., Mothe, J., Perego, R., Potthast, M., Sebastiani, F. (eds.) Advances in Information Retrieval - 43rd European Conference on IR Research, ECIR 2021, Virtual Event, March 28 - April 1, 2021, Proceedings, Part II. Lecture Notes in Computer Science, vol. 12657, pp. 342–349. Springer (2021). https://doi.org/10.1007/978-3-030-72240-1_34, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-030-72240-1_34" title="">https://doi.org/10.1007/978-3-030-72240-1_34</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Qin, T., Liu, T.: Introducing LETOR 4.0 datasets. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib49.1.1">abs/1306.2597</span> (2013), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1306.2597" title="">http://arxiv.org/abs/1306.2597</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Qin, T., Liu, T., Xu, J., Li, H.: LETOR: A benchmark collection for research on learning to rank for information retrieval. Inf. Retr. <span class="ltx_text ltx_font_bold" id="bib.bib50.1.1">13</span>(4), 346–374 (2010). https://doi.org/10.1007/S10791-009-9123-Y, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10791-009-9123-y" title="">https://doi.org/10.1007/s10791-009-9123-y</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Qin, Z., Yan, L., Zhuang, H., Tay, Y., Pasumarthi, R.K., Wang, X., Bendersky, M., Najork, M.: Are neural rankers still outperformed by gradient boosted decision trees? In: 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net (2021), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=Ut1vF_q_vC" title="">https://openreview.net/forum?id=Ut1vF_q_vC</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Rahangdale, A., Raut, S.A.: Deep neural network regularization for feature selection in learning-to-rank. IEEE Access <span class="ltx_text ltx_font_bold" id="bib.bib52.1.1">7</span>, 53988–54006 (2019). https://doi.org/10.1109/ACCESS.2019.2902640, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2019.2902640" title="">https://doi.org/10.1109/ACCESS.2019.2902640</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Ribeiro, M.T., Singh, S., Guestrin, C.: "why should I trust you?": Explaining the predictions of any classifier. In: Krishnapuram, B., Shah, M., Smola, A.J., Aggarwal, C.C., Shen, D., Rastogi, R. (eds.) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016. pp. 1135–1144. ACM (2016). https://doi.org/10.1145/2939672.2939778, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2939672.2939778" title="">https://doi.org/10.1145/2939672.2939778</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Rigutini, L., Papini, T., Maggini, M., Scarselli, F.: Sortnet: Learning to rank by a neural-based sorting algorithm. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib54.1.1">abs/2311.01864</span> (2023). https://doi.org/10.48550/ARXIV.2311.01864, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2311.01864" title="">https://doi.org/10.48550/arXiv.2311.01864</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Rong, Y., Leemann, T., Nguyen, T., Fiedler, L., Seidel, T., Kasneci, G., Kasneci, E.: Towards human-centered explainable AI: user studies for model explanations. CoRR <span class="ltx_text ltx_font_bold" id="bib.bib55.1.1">abs/2210.11584</span> (2022). https://doi.org/10.48550/arXiv.2210.11584, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2210.11584" title="">https://doi.org/10.48550/arXiv.2210.11584</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Rudin, C.: Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nat. Mach. Intell. <span class="ltx_text ltx_font_bold" id="bib.bib56.1.1">1</span>(5), 206–215 (2019). https://doi.org/10.1038/s42256-019-0048-x, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s42256-019-0048-x" title="">https://doi.org/10.1038/s42256-019-0048-x</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Shrikumar, A., Greenside, P., Kundaje, A.: Learning important features through propagating activation differences. In: Precup, D., Teh, Y.W. (eds.) Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017. Proceedings of Machine Learning Research, vol. 70, pp. 3145–3153. PMLR (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v70/shrikumar17a.html" title="">http://proceedings.mlr.press/v70/shrikumar17a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside convolutional networks: Visualising image classification models and saliency maps. In: Bengio, Y., LeCun, Y. (eds.) 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Workshop Track Proceedings (2014), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1312.6034" title="">http://arxiv.org/abs/1312.6034</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Sun, Z., Qin, T., Tao, Q., Wang, J.: Robust sparse rank learning for non-smooth ranking measures. In: Allan, J., Aslam, J.A., Sanderson, M., Zhai, C., Zobel, J. (eds.) Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2009, Boston, MA, USA, July 19-23, 2009. pp. 259–266. ACM (2009). https://doi.org/10.1145/1571941.1571987, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1571941.1571987" title="">https://doi.org/10.1145/1571941.1571987</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Sundararajan, M., Taly, A., Yan, Q.: Axiomatic attribution for deep networks. In: Precup, D., Teh, Y.W. (eds.) Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017. Proceedings of Machine Learning Research, vol. 70, pp. 3319–3328. PMLR (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v70/sundararajan17a.html" title="">http://proceedings.mlr.press/v70/sundararajan17a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Taylor, M.J., Guiver, J., Robertson, S., Minka, T.: Softrank: optimizing non-smooth rank metrics. In: Najork, M., Broder, A.Z., Chakrabarti, S. (eds.) Proceedings of the International Conference on Web Search and Web Data Mining, WSDM 2008, Palo Alto, California, USA, February 11-12, 2008. pp. 77–86. ACM (2008). https://doi.org/10.1145/1341531.1341544, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1341531.1341544" title="">https://doi.org/10.1145/1341531.1341544</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Tibshirani, R.: Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological) <span class="ltx_text ltx_font_bold" id="bib.bib62.1.1">58</span>(1), 267–288 (1996)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. In: Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. pp. 5998–6008 (2017), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" title="">https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Wang, L., Lin, J., Metzler, D.: A cascade ranking model for efficient ranked retrieval. In: Ma, W., Nie, J., Baeza-Yates, R., Chua, T., Croft, W.B. (eds.) Proceeding of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2011, Beijing, China, July 25-29, 2011. pp. 105–114. ACM (2011). https://doi.org/10.1145/2009916.2009934, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2009916.2009934" title="">https://doi.org/10.1145/2009916.2009934</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Wu, Q., Burges, C.J.C., Svore, K.M., Gao, J.: Adapting boosting for information retrieval measures. Inf. Retr. <span class="ltx_text ltx_font_bold" id="bib.bib65.1.1">13</span>(3), 254–270 (2010). https://doi.org/10.1007/S10791-009-9112-1, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10791-009-9112-1" title="">https://doi.org/10.1007/s10791-009-9112-1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Xia, F., Liu, T., Wang, J., Zhang, W., Li, H.: Listwise approach to learning to rank: theory and algorithm. In: Cohen, W.W., McCallum, A., Roweis, S.T. (eds.) Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008. ACM International Conference Proceeding Series, vol. 307, pp. 1192–1199. ACM (2008). https://doi.org/10.1145/1390156.1390306, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1390156.1390306" title="">https://doi.org/10.1145/1390156.1390306</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Xu, J., Li, H.: Adarank: a boosting algorithm for information retrieval. In: Kraaij, W., de Vries, A.P., Clarke, C.L.A., Fuhr, N., Kando, N. (eds.) SIGIR 2007: Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Amsterdam, The Netherlands, July 23-27, 2007. pp. 391–398. ACM (2007). https://doi.org/10.1145/1277741.1277809, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1277741.1277809" title="">https://doi.org/10.1145/1277741.1277809</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Xu, Z.E., Huang, G., Weinberger, K.Q., Zheng, A.X.: Gradient boosted feature selection. In: Macskassy, S.A., Perlich, C., Leskovec, J., Wang, W., Ghani, R. (eds.) The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’14, New York, NY, USA - August 24 - 27, 2014. pp. 522–531. ACM (2014). https://doi.org/10.1145/2623330.2623635, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2623330.2623635" title="">https://doi.org/10.1145/2623330.2623635</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Yoon, J., Jordon, J., van der Schaar, M.: INVASE: instance-wise variable selection using neural networks. In: 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net (2019), <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=BJg_roAcK7" title="">https://openreview.net/forum?id=BJg_roAcK7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Yue, Y., Finley, T., Radlinski, F., Joachims, T.: A support vector method for optimizing average precision. In: Kraaij, W., de Vries, A.P., Clarke, C.L.A., Fuhr, N., Kando, N. (eds.) SIGIR 2007: Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Amsterdam, The Netherlands, July 23-27, 2007. pp. 271–278. ACM (2007). https://doi.org/10.1145/1277741.1277790, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1277741.1277790" title="">https://doi.org/10.1145/1277741.1277790</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Zhang, Z., Rudra, K., Anand, A.: Explain and predict, and then predict again. In: WSDM ’21, The Fourteenth ACM International Conference on Web Search and Data Mining, Virtual Event, Israel, March 8-12, 2021. pp. 418–426. ACM (2021). https://doi.org/10.1145/3437963.3441758, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3437963.3441758" title="">https://doi.org/10.1145/3437963.3441758</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Zhang, Z., Setty, V., Anand, A.: Sparcassist: A model risk assessment assistant based on sparse generated counterfactuals. In: Amigó, E., Castells, P., Gonzalo, J., Carterette, B., Culpepper, J.S., Kazai, G. (eds.) SIGIR ’22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022. pp. 3219–3223. ACM (2022). https://doi.org/10.1145/3477495.3531677, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3477495.3531677" title="">https://doi.org/10.1145/3477495.3531677</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Zhuang, H., Wang, X., Bendersky, M., Grushetsky, A., Wu, Y., Mitrichev, P., Sterling, E., Bell, N., Ravina, W., Qian, H.: Interpretable ranking with generalized additive models. In: WSDM ’21, The Fourteenth ACM International Conference on Web Search and Data Mining, Virtual Event, Israel, March 8-12, 2021. pp. 499–507. ACM (2021). https://doi.org/10.1145/3437963.3441796, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3437963.3441796" title="">https://doi.org/10.1145/3437963.3441796</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May 14 14:21:40 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
