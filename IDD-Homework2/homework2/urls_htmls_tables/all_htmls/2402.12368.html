<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.12368] A synthetic data approach for domain generalization of NLI models</title><meta property="og:description" content="Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfu…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A synthetic data approach for domain generalization of NLI models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A synthetic data approach for domain generalization of NLI models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.12368">

<!--Generated on Tue Mar  5 19:04:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">A synthetic data approach for domain generalization of NLI models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohammad Javad Hosseini<sup id="id9.7.id1" class="ltx_sup"><span id="id9.7.id1.1" class="ltx_text ltx_font_italic">1∗</span></sup>  Andrey Petrov<sup id="id10.8.id2" class="ltx_sup"><span id="id10.8.id2.1" class="ltx_text ltx_font_italic">1</span></sup>  Alex Fabrikant<sup id="id11.9.id3" class="ltx_sup"><span id="id11.9.id3.1" class="ltx_text ltx_font_italic">1</span></sup>  Annie Louis<sup id="id12.10.id4" class="ltx_sup"><span id="id12.10.id4.1" class="ltx_text ltx_font_italic">2∗</span></sup> 
<br class="ltx_break"><sup id="id13.11.id5" class="ltx_sup"><span id="id13.11.id5.1" class="ltx_text ltx_font_italic">1</span></sup>Google Research  <sup id="id14.12.id6" class="ltx_sup"><span id="id14.12.id6.1" class="ltx_text ltx_font_italic">2</span></sup>Google Deepmind 
<br class="ltx_break"><span id="id15.13.id7" class="ltx_text ltx_font_typewriter">{javadh,apetrov,fabrikant,annielouis}@google.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.2" class="ltx_p">Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfulness of model-generated text. There are several large scale NLI datasets
today, and models have improved greatly by hill-climbing on these collections. Yet their realistic performance on out-of-distribution/domain data is less well-understood. We present an in-depth exploration of the problem of domain generalization of NLI models. We demonstrate a new approach for generating synthetic NLI data in diverse domains and lengths, so far not covered by existing training sets. The resulting examples have meaningful premises,
the hypotheses are formed in creative ways rather than simple edits to a few premise tokens, and the labels have high accuracy.
We show that models trained on this data (<math id="id7.1.m1.1" class="ltx_Math" alttext="685" display="inline"><semantics id="id7.1.m1.1a"><mn id="id7.1.m1.1.1" xref="id7.1.m1.1.1.cmml">685</mn><annotation-xml encoding="MathML-Content" id="id7.1.m1.1b"><cn type="integer" id="id7.1.m1.1.1.cmml" xref="id7.1.m1.1.1">685</cn></annotation-xml><annotation encoding="application/x-tex" id="id7.1.m1.1c">685</annotation></semantics></math>K synthetic examples) have the best generalization to completely new downstream test settings. On the TRUE benchmark, a T5-small model trained with our data improves around <math id="id8.2.m2.1" class="ltx_Math" alttext="7\%" display="inline"><semantics id="id8.2.m2.1a"><mrow id="id8.2.m2.1.1" xref="id8.2.m2.1.1.cmml"><mn id="id8.2.m2.1.1.2" xref="id8.2.m2.1.1.2.cmml">7</mn><mo id="id8.2.m2.1.1.1" xref="id8.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id8.2.m2.1b"><apply id="id8.2.m2.1.1.cmml" xref="id8.2.m2.1.1"><csymbol cd="latexml" id="id8.2.m2.1.1.1.cmml" xref="id8.2.m2.1.1.1">percent</csymbol><cn type="integer" id="id8.2.m2.1.1.2.cmml" xref="id8.2.m2.1.1.2">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.2.m2.1c">7\%</annotation></semantics></math> on average compared to training on the best alternative dataset. The improvements are more pronounced for smaller models, while still meaningful on a T5 XXL model. We also demonstrate gains on test sets when in-domain training data is augmented with our domain-general synthetic data.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.6" class="ltx_block ltx_align_bottom">
<p id="p1.6.7" class="ltx_p"><span id="p1.6.7.1" class="ltx_text ltx_font_bold">A synthetic data approach for domain generalization of NLI models</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.6.6" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.6.6.6" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.6.6.6.6" class="ltx_tabular ltx_align_top">
<span id="p1.4.4.4.4.4" class="ltx_tr">
<span id="p1.4.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="p1.4.4.4.4.4.4.4" class="ltx_text ltx_font_bold">Mohammad Javad Hosseini<sup id="p1.4.4.4.4.4.4.4.1" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1∗</span></sup>  Andrey Petrov<sup id="p1.4.4.4.4.4.4.4.2" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>  Alex Fabrikant<sup id="p1.4.4.4.4.4.4.4.3" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>  Annie Louis<sup id="p1.4.4.4.4.4.4.4.4" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.4.1" class="ltx_text ltx_font_medium ltx_font_italic">2∗</span></sup></span></span></span>
<span id="p1.6.6.6.6.6" class="ltx_tr">
<span id="p1.6.6.6.6.6.2" class="ltx_td ltx_align_center"><sup id="p1.6.6.6.6.6.2.1" class="ltx_sup"><span id="p1.6.6.6.6.6.2.1.1" class="ltx_text ltx_font_italic">1</span></sup>Google Research  <sup id="p1.6.6.6.6.6.2.2" class="ltx_sup"><span id="p1.6.6.6.6.6.2.2.1" class="ltx_text ltx_font_italic">2</span></sup>Google Deepmind</span></span>
<span id="p1.6.6.6.6.7" class="ltx_tr">
<span id="p1.6.6.6.6.7.1" class="ltx_td ltx_align_center"><span id="p1.6.6.6.6.7.1.1" class="ltx_text ltx_font_typewriter">{javadh,apetrov,fabrikant,annielouis}@google.com</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Over the past decade, NLI tasks have been critical for benchmarking the representation strengths of our language models. Today, the accuracy on the oft-reported Multi-NLI <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> (MNLI) dataset has reached above 92%<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://gluebenchmark.com/leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gluebenchmark.com/leaderboard</a></span></span></span> and supersedes human-level performance <cite class="ltx_cite ltx_citemacro_cite">Nangia and Bowman (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>. Simultaneously, the practical applications of NLI models has gathered immense attention in fact-checking and source attribution of LLM outputs <cite class="ltx_cite ltx_citemacro_cite">Honovich et al. (<a href="#bib.bib15" title="" class="ltx_ref">2022</a>); Rashkin et al. (<a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>. For such downstream tasks, model generalization to new domains and data-distributions is critical. We present a method of synthetic data generation to create a <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">general</em> dataset with varied but balanced distribution of premise lengths, domains of text, and NLI labels (Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), and demonstrate improved accuracy with the new data.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.1.1.1.1.1" class="ltx_text"></span> <span id="S1.T1.1.1.1.1.1.2" class="ltx_text">
<span id="S1.T1.1.1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.1.1.1.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Domain = essay</span></span></span>
</span></span><span id="S1.T1.1.1.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.2" class="ltx_tr">
<td id="S1.T1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.2.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.2.1.1.1.1" class="ltx_text" style="color:#008080;">P: This book does a great job of putting all the different approaches under one roof, so that you can see what other researchers are doing and how they do it.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.3" class="ltx_tr">
<td id="S1.T1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S1.T1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.3.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.3.1.1.1.1" class="ltx_text" style="color:#FF0000;">H: The book covers different research approaches in a single place so you can compare them.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.4" class="ltx_tr">
<td id="S1.T1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S1.T1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.4.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.4.1.1.1.1" class="ltx_text" style="color:#0000FF;">L: entailment</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.5" class="ltx_tr">
<td id="S1.T1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.5.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.5.1.1.1.1" class="ltx_text"></span> <span id="S1.T1.1.5.1.1.1.2" class="ltx_text">
<span id="S1.T1.1.5.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.5.1.1.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.5.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.5.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Domain = reddit title</span></span></span>
</span></span><span id="S1.T1.1.5.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.6" class="ltx_tr">
<td id="S1.T1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.6.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.6.1.1.1.1" class="ltx_text" style="color:#008080;">P: TIL the difference between "literally" and "figuratively". It was so easy to learn, I literally did a backflip.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.7" class="ltx_tr">
<td id="S1.T1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S1.T1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.7.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.7.1.1.1.1" class="ltx_text" style="color:#FF0000;">H: I did not bother learning the difference between "literally" and "figuratively".</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.8" class="ltx_tr">
<td id="S1.T1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S1.T1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.8.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.8.1.1.1.1" class="ltx_text" style="color:#0000FF;">L: contradiction</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.9" class="ltx_tr">
<td id="S1.T1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.9.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.9.1.1.1.1" class="ltx_text"></span> <span id="S1.T1.1.9.1.1.1.2" class="ltx_text">
<span id="S1.T1.1.9.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.9.1.1.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.9.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.9.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Domain = story for kids</span></span></span>
</span></span><span id="S1.T1.1.9.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.10" class="ltx_tr">
<td id="S1.T1.1.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.10.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.10.1.1.1.1" class="ltx_text" style="color:#008080;">P: Once upon a time, there was a very special young lady named Cinderella. Her stepmother and stepsisters were very mean to her. But she continued to be kind and helpful.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.11" class="ltx_tr">
<td id="S1.T1.1.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S1.T1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.11.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.11.1.1.1.1" class="ltx_text" style="color:#FF0000;">H: Cinderella was very kind to everyone.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.1.12" class="ltx_tr">
<td id="S1.T1.1.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r">
<span id="S1.T1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.12.1.1.1" class="ltx_p" style="width:403.3pt;"><span id="S1.T1.1.12.1.1.1.1" class="ltx_text" style="color:#0000FF;">L: neutral</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>NLI examples in our synthetic data.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">MNLI was a first effort to create a multi-domain NLI <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">training</em> dataset with examples from 5 genres spanning fiction, formal texts and conversations, and with single-sentence premise/hypothesis texts. Today, the use of models trained from such datasets has expanded well past routine benchmarking into a variety of practical tasks. In downstream problems involving web-scale LLMs, such as fact-checking of social media text, the domains and texts are clearly more diverse. Yet, as a field, we have not fully explored the distribution-general abilities of our models for downstream semantic tasks beyond NLI itself. There are many other NLI training sets: ANLI <cite class="ltx_cite ltx_citemacro_cite">Nie et al. (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> for harder reasoning going beyond stylistic elements, and WANLI <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> that generates synthetic examples through worker and AI collaboration and which replicate complex reasoning patterns.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To complement these efforts, we explore
the opportunity for <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">synthetic high-quality datasets to adapt NLI models for zero-shot use in downstream applications across new and unseen text domains</span>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our generation covers nearly 40 realistic and distinct domains, ranging from reviews, social media comments, to legal texts, also with varying lengths of the premise text. Our technique employs a chain of LLM tasks tuned to generate high quality, creative premise-hypothesis pairs together with a 3-way NLI label (<span id="S1.p4.1.1" class="ltx_text ltx_font_italic">entailment</span>, <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">contradiction</span>, or <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">neutral</span> <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite>). A first step generates domain names, the second produces premises of different lengths in these domains, and the final LLM call produces hypotheses and labels conditioned on each premise. We demonstrate how this approaches creates data with a balanced distribution of domains, labels, and premise lengths.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.2" class="ltx_p">We fine-tune NLI models on this synthetic data corpus, and present their accuracy on the TRUE factual consistency benchmark <cite class="ltx_cite ltx_citemacro_cite">Honovich et al. (<a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>, consisting of 11 tasks unseen by our data and other training sets. We show that our <em id="S1.p5.2.1" class="ltx_emph ltx_font_italic">general data</em>-trained models obtain state-of-the-art NLI performance and single-handedly outperform models trained on MNLI, ANLI, or WANLI with around <math id="S1.p5.1.m1.1" class="ltx_Math" alttext="7\%" display="inline"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mn id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">7</mn><mo id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><csymbol cd="latexml" id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.p5.1.m1.1.1.2.cmml" xref="S1.p5.1.m1.1.1.2">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">7\%</annotation></semantics></math> improvement over the best alternative for T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> small models. The gap is lower but still around <math id="S1.p5.2.m2.1" class="ltx_Math" alttext="2\%" display="inline"><semantics id="S1.p5.2.m2.1a"><mrow id="S1.p5.2.m2.1.1" xref="S1.p5.2.m2.1.1.cmml"><mn id="S1.p5.2.m2.1.1.2" xref="S1.p5.2.m2.1.1.2.cmml">2</mn><mo id="S1.p5.2.m2.1.1.1" xref="S1.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><apply id="S1.p5.2.m2.1.1.cmml" xref="S1.p5.2.m2.1.1"><csymbol cd="latexml" id="S1.p5.2.m2.1.1.1.cmml" xref="S1.p5.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S1.p5.2.m2.1.1.2.cmml" xref="S1.p5.2.m2.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">2\%</annotation></semantics></math> for T5 XXL model size.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our main contribution is thus that the <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">general</em> synthetic data approach improves the generalization power of NLI models, especially when small models and fast inference is key. We further show that, while in-distribution performance is hard to beat for tasks with in-distribution training data, our synthetic data can still improve in-distribution performance when used to augment the training data for models with sufficient capacity.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2402.12368/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="423" height="133" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Generating the <em id="S1.F1.2.1" class="ltx_emph ltx_font_italic">General-</em>NLI examples.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We describe various ways of creating NLI data, and why models should generalize beyond the data.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Human annotation of NLI examples.</span> The major datasets
available today were created via costly, time consuming annotation tasks,
and significant human effort.
Standardly, the annotation <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib4" title="" class="ltx_ref">2015a</a>); Williams et al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> starts with a premise sentence
taken verbatim from different sources. Annotators are asked to write a hypothesis sentence that is
entailed, contradicted, or is neutral to the premise. This writing task is complex for humans, and it is well-known that the collected examples often have undesired stylistic artifacts, for example, the
hypotheses alone being
highly predictive of the label <cite class="ltx_cite ltx_citemacro_cite">Gururangan et al. (<a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite>.
Later efforts have focused on improving the quality of examples by including
model adversaries into the annotation rounds <cite class="ltx_cite ltx_citemacro_cite">Nie et al. (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The diversity in genre in these datasets depends on the sources from which the premises are drawn.
The SNLI dataset contains image captions <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib5" title="" class="ltx_ref">2015b</a>)</cite>. The MNLI dataset <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> has 10 domains from the Open American National
Corpus (OANC)<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://anc.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://anc.org/</a></span></span></span>,
only 5 of which are used for training. The ANLI dataset <cite class="ltx_cite ltx_citemacro_cite">Nie et al. (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> contains text from Wikipedia, news, fiction, formal spoken text, and causal or procedural text. In this way, their domain coverage is limited by the chosen corpora and licensing constraints. For example, none of these datasets contain reviews, forum discussions, and science texts, domains which are prevalent and important in applications.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Understandably, different sources and methods of
data collection produces training examples of a certain style and distribution.
The generalization of these NLI sets to fully new settings is an interesting problem <cite class="ltx_cite ltx_citemacro_cite">Adila and Kang (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite>, yet
less explored. Our work aims to shed some insights here.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Domain generalization.</span> This problem of training/test mismatch receives less importance during development
since models are trained and evaluated on splits of the same dataset. But real world applications of these models cannot assume that the test data matches the training distribution. Models need to be adapted to individual test domains using domain adaptation, or alternatively one could train domain-general models which work well on multiple unseen domains or distributions. We focus on this problem of domain generalization.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">There is a large body on work on how training and optimization of models can be
adapted for better generalization <cite class="ltx_cite ltx_citemacro_cite">Muandet et al. (<a href="#bib.bib21" title="" class="ltx_ref">2013</a>); Wang et al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>. Another well-known
approach, especially in computer vision, is to augment the training data to increase its diversity and reduce model overfitting <cite class="ltx_cite ltx_citemacro_cite">Tobin et al. (<a href="#bib.bib31" title="" class="ltx_ref">2017</a>); Rahman et al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>); Zhou et al. (<a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>.
In this work, we explore the usefulness of synthetic data generation for the domain-generalization of NLI models.</p>
</div>
<div id="S2.p7" class="ltx_para ltx_noindent">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text ltx_font_bold">Synthetic NLI data generation.</span> Today’s LLMs have opened up the possibility of synthetic data to aid many NLP tasks <cite class="ltx_cite ltx_citemacro_cite">Puri et al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>); He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>); Agrawal et al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>); Li et al. (<a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>.
For NLI, synthetic data has been used for different goals:
augmenting small training sets and adding <em id="S2.p7.1.2" class="ltx_emph ltx_font_italic">in-domain</em>
examples for self-training <cite class="ltx_cite ltx_citemacro_cite">Vu et al. (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>); He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>, and increasing the size of harder
examples <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>. Most of these methods prompt LLMs with
sequences of premise-hypothesis sentence pairs.
The pairs are then labelled by a teacher model.
<cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> specialize the generation towards complex linguistic and reasoning
patterns in
existing datasets. We employ synthetic data to improve the diversity
and balance of training data along the dimensions of domain, premise length,
and label skew.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Synthesizing a <em id="S3.1.1" class="ltx_emph ltx_font_italic">General</em>-NLI Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We aim to generate NLI examples in different domains, and with premises of varied lengths.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Longer hypotheses are not of interest typically. A hypothesis is entailed if hypothesis is true given the premise. Long hypotheses are less likely to contain precise entailment and contradiction relations, with some exceptions such as summaries.</span></span></span></p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Generating synthetic examples for NLI is in fact a challenging problem. The goal is to produce a pair of texts, which exemplify the reasoning behind different NLI labels. But for the data to be useful, these texts must have creative content and language, and require reasoning. Prior approaches <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>); Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> generate the
premise and hypothesis sentences as a single sequence,
followed by annotating the label using a teacher model or human raters. Instead, to achieve maximum control over multiple dimensions: genre, length, and different NLI labels, we
generate this dataset in two steps: (i) enumerate diverse domains and generate premises in those domains (Section <a href="#S3.SS1" title="3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), (ii) generate hypotheses and labels given the premises (Section <a href="#S3.SS2" title="3.2 Generating hypotheses and labels ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an overall view into the LLMs tasks we use for generating our data.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Generating premises with varied lengths in multiple domains</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Going beyond distinctions based on the source of a text, it is hard to define the boundaries of a domain in a strict manner. Properties of a text differ along many dimensions: its genre (e.g., news, poetry, or fiction), topic (e.g. politics, science), and the platform or venue for the content, either spoken or written (e.g., reddit, email, image captions, or telephone conversations).
We adopt a practical perspective, and consider all these distinctions as the latent features leading to differences between text collections.
It is in fact well-known that stylistic variations in NLI datasets impact generalization <cite class="ltx_cite ltx_citemacro_cite">Belinkov et al. (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>); Adila and Kang (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">So we do not start with predefined domains. Rather, we first build a text-generation model which generates triples of domain name, text length, and text in the domain. The resulting texts from different domains are collected into our premise set. We build this model using few-shot prompting of FLAN-PaLM2 L (Unicorn)
model <cite class="ltx_cite ltx_citemacro_cite">Google and et al. (<a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Available from <a target="_blank" href="https://ai.google.dev/tutorials/python_quickstart" title="" class="ltx_ref ltx_href">https://developers.generativeai.google</a>.</span></span></span> using texts from a few seed domains. We draw 18 in-prompt examples of varied lengths from 8 domains (<span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">news headlines</span>, <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic">news</span>, <span id="S3.SS1.p2.1.3" class="ltx_text ltx_font_italic">shopping reviews</span>, <span id="S3.SS1.p2.1.4" class="ltx_text ltx_font_italic">wikipedia</span>, <span id="S3.SS1.p2.1.5" class="ltx_text ltx_font_italic">movie reviews</span>, <span id="S3.SS1.p2.1.6" class="ltx_text ltx_font_italic">place reviews</span>, <span id="S3.SS1.p2.1.7" class="ltx_text ltx_font_italic">twitter</span> and <span id="S3.SS1.p2.1.8" class="ltx_text ltx_font_italic">reddit post</span>). The example texts are taken
from public websites with a few edits if needed.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>This includes news websites (BBC) for <span id="footnote5.1" class="ltx_text ltx_font_italic">news</span> and <span id="footnote5.2" class="ltx_text ltx_font_italic">news headlines</span>, e-commerce and review websites (eBay and thetechoutlook.com) for <span id="footnote5.3" class="ltx_text ltx_font_italic">shopping reviews</span>, Wikipedia, Google Play for <span id="footnote5.4" class="ltx_text ltx_font_italic">movie reviews</span>, citymaps.uk and top-rated.online websites for <span id="footnote5.5" class="ltx_text ltx_font_italic">place reviews</span>, X (Twitter) and Reddit.</span></span></span> We provide the full list of seed examples in Appendix <a href="#A1" title="Appendix A Seed Examples for Prompting ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. We also select these texts to be of different lengths.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows our prompt. The length category is set to either <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">short</span> for single sentences and <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">paragraph</span> for longer texts. We sample from this model, with a temperature of 1 to get creative <em id="S3.SS1.p3.1.3" class="ltx_emph ltx_font_italic">new domains</em> and texts. Ideally, these samples would directly be useful as premises (with domain and length labels). However, these samples were skewed towards certain domains, e.g., certain types of forums, which neither correspond to real word distributions of web-text, nor serve the purpose of a general model. So we first identify new domains generated by the model. We examined the <em id="S3.SS1.p3.1.4" class="ltx_emph ltx_font_italic">new</em> domains generated in about 1000 samples. Some generated domains were closely related to, or paraphrases of, each other; e.g. both <em id="S3.SS1.p3.1.5" class="ltx_emph ltx_font_italic">travel forums</em> and <em id="S3.SS1.p3.1.6" class="ltx_emph ltx_font_italic">US travel forums</em> were generated. Others were rare or noisy. So we manually selected 38 diverse domains including the seed domain names (Table <a href="#S3.T2" title="Table 2 ‣ 3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">We then generate balanced samples in these domains, and for the length labels (short, paragraph). We use the same prompt as in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, but substitute a new domain and length category of interest to it, to generate a text with those properties. This simple text generation model produced high quality and creative texts in different domains. We use these texts as the <em id="S3.SS1.p4.1.1" class="ltx_emph ltx_font_italic">premises</em> in our data.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2402.12368/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="454" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The prompt used to generate new domains. We use the same prompt, add a domain and length category of interest (either <span id="S3.F2.3.1" class="ltx_text ltx_font_italic">short</span> or <span id="S3.F2.4.2" class="ltx_text ltx_font_italic">paragraph</span>), and add “text: {” at the end. We take the output up to the first “}” as the generated domain or text.</figcaption>
</figure>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1" class="ltx_p" style="width:199.2pt;">ads, blog post, book reviews, casual dialog, chat message, email, essay, fans forum, forum post, google play reviews, government documents, legal, legal document, medical, movie plot, movie reviews, news, news comments, news headlines, phone conversation, place reviews, quora, recipe, reddit comment, reddit title, research paper abstract, scientific article, shopping reviews, song lyrics, sports news, story for kids, student forum, student papers, support forum, travel guides, twitter, wikipedia, youtube comments</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Our final list of domains for data generation.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Generating hypotheses and labels</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We now discuss how we attach hypotheses and labels to our premises to generate complete NLI examples, i.e., (premise, hypothesis, label) triples.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We train LLMs to leverage existing NLI datasets, and learn the task of writing hypotheses for given premises.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Our model conditions on a premise to generate a (hypothesis, label) pair. We generate the label automatically (and accurately, details in next section), and do not need an additional human/teacher labelling step.
This model is trained via prompt-tuning of FLAN-PaLM 540B <cite class="ltx_cite ltx_citemacro_cite">Chowdhery et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>); Chung et al. (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>
on the training split of the MNLI dataset. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Generating hypotheses and labels ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows our prompt with has examples for the three NLI labels with definitions similar to the MNLI annotation guidelines <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">We used prompt-tuning <cite class="ltx_cite ltx_citemacro_cite">Lester et al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, in lieu of fine-tuning, for two reasons: a) With prompt-tuning, only a few embeddings are updated (100 in our experiments) leading to efficient training, and b) prompt-tuning provides regularization and avoids memorization of the training set details.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>See details of our prompt-tuning hyper-parameters in Appendix <a href="#A2" title="Appendix B Hyper-parameter details ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</span></span></span> Using this model, we perform inference once on each of the premises obtained from Section <a href="#S3.SS1" title="3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>We discard examples if a) the generated text for hypothesis-premise pair is mis-formatted, or b) the generated labels are not among <span id="footnote7.1" class="ltx_text ltx_font_italic">entailment</span>, <span id="footnote7.2" class="ltx_text ltx_font_italic">neutral</span>, and <span id="footnote7.3" class="ltx_text ltx_font_italic">contradiction</span>. Such errors account for less than <math id="footnote7.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="footnote7.m1.1b"><mn id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><cn type="integer" id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">1</annotation></semantics></math>% of the generated data.</span></span></span>
We note that large models and regularization were important for creative generation of hypotheses. A T5 XL model (3B parameters) fine-tuned on the same task lead to examples with poor creativity and low utility for training. In many cases, the synthetic hypothesis was a subset of the premise (entailment) or had some simple modifications (e.g., negation) to introduce contradiction.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2402.12368/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="454" height="73" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The instruction used for training and inference of the (hypothesis, label) generator model.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>The final <em id="S3.SS3.1.1" class="ltx_emph ltx_font_italic">general</em> dataset</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.10" class="ltx_p">We generated (premise, hypothesis, label) triples in the <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="38" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mn id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">38</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><cn type="integer" id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">38</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">38</annotation></semantics></math> domains (from Section <a href="#S3.SS1" title="3.1 Generating premises with varied lengths in multiple domains ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), and for two length categories (<span id="S3.SS3.p1.10.1" class="ltx_text ltx_font_italic">short</span> and <span id="S3.SS3.p1.10.2" class="ltx_text ltx_font_italic">paragraph</span>). The final dataset contains <math id="S3.SS3.p1.2.m2.2" class="ltx_Math" alttext="684,929" display="inline"><semantics id="S3.SS3.p1.2.m2.2a"><mrow id="S3.SS3.p1.2.m2.2.3.2" xref="S3.SS3.p1.2.m2.2.3.1.cmml"><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">684</mn><mo id="S3.SS3.p1.2.m2.2.3.2.1" xref="S3.SS3.p1.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.2.2" xref="S3.SS3.p1.2.m2.2.2.cmml">929</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.2b"><list id="S3.SS3.p1.2.m2.2.3.1.cmml" xref="S3.SS3.p1.2.m2.2.3.2"><cn type="integer" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">684</cn><cn type="integer" id="S3.SS3.p1.2.m2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2">929</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.2c">684,929</annotation></semantics></math> examples. We hold-out <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mn id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><cn type="integer" id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">500</annotation></semantics></math> examples for creating a human annotated test set, and split the rest into training, development, and test splits. Table <a href="#S3.T3" title="Table 3 ‣ 3.3 The final general dataset ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the data size and label distributions in each split. The number of examples from each label is relatively balanced (<math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="35.4" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mn id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">35.4</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><cn type="float" id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">35.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">35.4</annotation></semantics></math>% entailment, <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="31.1" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mn id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">31.1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><cn type="float" id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">31.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">31.1</annotation></semantics></math>% contradiction, and <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="33.5" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mn id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">33.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><cn type="float" id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">33.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">33.5</annotation></semantics></math>% neutral). This is unlike the existing partially synthetic NLI datasets <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>. Our generation is also balanced with respect to the premise length and domain by design (we sample examples in a stratified manner). The average number of words per <em id="S3.SS3.p1.10.3" class="ltx_emph ltx_font_italic">short</em> premise is <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><mn id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><cn type="integer" id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">21</annotation></semantics></math>, and <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mn id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><cn type="integer" id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">60</annotation></semantics></math> for <em id="S3.SS3.p1.10.4" class="ltx_emph ltx_font_italic">paragraph</em> length. The average number of words in hypotheses is mostly uniform, <math id="S3.SS3.p1.9.m9.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS3.p1.9.m9.1a"><mn id="S3.SS3.p1.9.m9.1.1" xref="S3.SS3.p1.9.m9.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m9.1b"><cn type="integer" id="S3.SS3.p1.9.m9.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m9.1c">10</annotation></semantics></math> and <math id="S3.SS3.p1.10.m10.1" class="ltx_Math" alttext="12" display="inline"><semantics id="S3.SS3.p1.10.m10.1a"><mn id="S3.SS3.p1.10.m10.1.1" xref="S3.SS3.p1.10.m10.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m10.1b"><cn type="integer" id="S3.SS3.p1.10.m10.1.1.cmml" xref="S3.SS3.p1.10.m10.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m10.1c">12</annotation></semantics></math> for <em id="S3.SS3.p1.10.5" class="ltx_emph ltx_font_italic">short</em> and <em id="S3.SS3.p1.10.6" class="ltx_emph ltx_font_italic">paragraph</em> length premises.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Table <a href="#S3.T4" title="Table 4 ‣ 3.3 The final general dataset ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows a few examples from our data.<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We list additional examples in Table <a href="#A3.T10" title="Table 10 ‣ Appendix C Additional Examples from Synthetic General Data ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> (Appendix <a href="#A3" title="Appendix C Additional Examples from Synthetic General Data ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>).</span></span></span> The premises come from different domains and are diverse in form and topic.
Hypotheses are relevant to the premise and are creative in contrast to slightly modifying the premise and/or taking a subset of it. These attributes are unlike our observations with smaller and less powerful language models such as T5 XL (Section <a href="#S3.SS2" title="3.2 Generating hypotheses and labels ‣ 3 Synthesizing a General-NLI Dataset ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). In our experiments, we empirically demonstrate the impact of this data for training.
We note that the idea here is to generate diverse data in different domains. It is possible that some of these examples are not factual, but the truth of the hypothesis is checked against the premise, not any background knowledge.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.5.1" class="ltx_tr">
<td id="S3.T3.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.1.1.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T3.5.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Split</span></span>
</span>
</td>
<td id="S3.T3.5.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.1.2.1.1" class="ltx_p" style="width:52.0pt;"><span id="S3.T3.5.1.2.1.1.1" class="ltx_text ltx_font_smallcaps">Size</span></span>
</span>
</td>
<td id="S3.T3.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.1.3.1.1" class="ltx_p" style="width:221.1pt;"><span id="S3.T3.5.1.3.1.1.1" class="ltx_text ltx_font_smallcaps"># Labels (E/C/N)</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.5.2" class="ltx_tr">
<td id="S3.T3.5.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.2.1.1.1" class="ltx_p" style="width:86.7pt;">All</span>
</span>
</td>
<td id="S3.T3.5.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.2.2.1.1" class="ltx_p" style="width:52.0pt;">684,929</span>
</span>
</td>
<td id="S3.T3.5.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.2.3.1.1" class="ltx_p" style="width:221.1pt;">242,154 / 212,950 / 229,325</span>
</span>
</td>
</tr>
<tr id="S3.T3.5.3" class="ltx_tr">
<td id="S3.T3.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.3.1.1.1" class="ltx_p" style="width:86.7pt;">Train</span>
</span>
</td>
<td id="S3.T3.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.3.2.1.1" class="ltx_p" style="width:52.0pt;">670,739</span>
</span>
</td>
<td id="S3.T3.5.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.3.3.1.1" class="ltx_p" style="width:221.1pt;">237,325 / 208,676 / 224,738</span>
</span>
</td>
</tr>
<tr id="S3.T3.5.4" class="ltx_tr">
<td id="S3.T3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.4.1.1.1" class="ltx_p" style="width:86.7pt;">Dev</span>
</span>
</td>
<td id="S3.T3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.4.2.1.1" class="ltx_p" style="width:52.0pt;">6,845</span>
</span>
</td>
<td id="S3.T3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.4.3.1.1" class="ltx_p" style="width:221.1pt;">2,453 / 2,146 / 2,246</span>
</span>
</td>
</tr>
<tr id="S3.T3.5.5" class="ltx_tr">
<td id="S3.T3.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.1.1.1" class="ltx_p" style="width:86.7pt;">Test</span>
</span>
</td>
<td id="S3.T3.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.2.1.1" class="ltx_p" style="width:52.0pt;">6,845</span>
</span>
</td>
<td id="S3.T3.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.3.1.1" class="ltx_p" style="width:221.1pt;">2,376 / 2,128 / 2,341</span>
</span>
</td>
</tr>
<tr id="S3.T3.5.6" class="ltx_tr">
<td id="S3.T3.5.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.5.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.6.1.1.1" class="ltx_p" style="width:86.7pt;">Human annotated test</span>
</span>
</td>
<td id="S3.T3.5.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T3.5.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.6.2.1.1" class="ltx_p" style="width:52.0pt;">490</span>
</span>
</td>
<td id="S3.T3.5.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T3.5.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.6.3.1.1" class="ltx_p" style="width:221.1pt;">181 / 155 / 154</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Different splits of our <em id="S3.T3.8.1" class="ltx_emph ltx_font_italic">general</em>-data. <em id="S3.T3.9.2" class="ltx_emph ltx_font_italic">Human annotated test</em> are 490 (out of 500) examples where at least <math id="S3.T3.3.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.3.m1.1b"><mn id="S3.T3.3.m1.1.1" xref="S3.T3.3.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.3.m1.1c"><cn type="integer" id="S3.T3.3.m1.1.1.cmml" xref="S3.T3.3.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.m1.1d">2</annotation></semantics></math> out of <math id="S3.T3.4.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T3.4.m2.1b"><mn id="S3.T3.4.m2.1.1" xref="S3.T3.4.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T3.4.m2.1c"><cn type="integer" id="S3.T3.4.m2.1.1.cmml" xref="S3.T3.4.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.m2.1d">3</annotation></semantics></math> annotators have agreed on the label.
</figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T4.1.1" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.1.1.1" class="ltx_p" style="width:47.7pt;"><span id="S3.T4.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Domain and Length</span></span>
</span>
</td>
<td id="S3.T4.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="S3.T4.1.1.2.1.1.1" class="ltx_text ltx_font_smallcaps">Premise</span></span>
</span>
</td>
<td id="S3.T4.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.3.1.1" class="ltx_p" style="width:86.7pt;"><span id="S3.T4.1.1.3.1.1.1" class="ltx_text ltx_font_smallcaps">Hypothesis</span></span>
</span>
</td>
<td id="S3.T4.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.4.1.1" class="ltx_p" style="width:43.4pt;"><span id="S3.T4.1.1.4.1.1.1" class="ltx_text ltx_font_smallcaps">Label</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.1.2" class="ltx_tr">
<td id="S3.T4.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T4.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.1.1.1" class="ltx_p" style="width:47.7pt;">travel guides / short</span>
</span>
</td>
<td id="S3.T4.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="S3.T4.1.2.2.1.1.1" class="ltx_text ltx_font_bold">This charming boutique offers 43 rooms and suites in the heart of historic St John’s</span>, and is the perfect base for exploring Antigua’s rich history</span>
</span>
</td>
<td id="S3.T4.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.3.1.1" class="ltx_p" style="width:86.7pt;">The boutique is located right in the middle of the historic area.</span>
</span>
</td>
<td id="S3.T4.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.4.1.1" class="ltx_p" style="width:43.4pt;">entailment</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.3" class="ltx_tr">
<td id="S3.T4.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T4.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.1.1.1" class="ltx_p" style="width:47.7pt;">support forum / short</span>
</span>
</td>
<td id="S3.T4.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="S3.T4.1.3.2.1.1.1" class="ltx_text ltx_font_bold">I’ll be posting a video with the solution</span> once my phone finishes resetting.</span>
</span>
</td>
<td id="S3.T4.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.3.1.1" class="ltx_p" style="width:86.7pt;">I’ve already solved the problem.</span>
</span>
</td>
<td id="S3.T4.1.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.4.1.1" class="ltx_p" style="width:43.4pt;">neutral</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.4" class="ltx_tr">
<td id="S3.T4.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T4.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.1.1.1" class="ltx_p" style="width:47.7pt;">legal document / paragraph</span>
</span>
</td>
<td id="S3.T4.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T4.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.2.1.1" class="ltx_p" style="width:190.8pt;">This Agreement will bind and inure to the benefit of both parties hereto and their respective personal representatives, heirs, successors, and permitted assigns. <span id="S3.T4.1.4.2.1.1.1" class="ltx_text ltx_font_bold">Any attempt by any party hereto to assign, sell or otherwise transfer all or part of his or her rights or obligations under this Agreement, other than as provided herein, will be null and void</span>, notwithstanding the existence of any provision of law to the contrary.</span>
</span>
</td>
<td id="S3.T4.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T4.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.3.1.1" class="ltx_p" style="width:86.7pt;">This agreement allows for any party to reassign their rights and obligations.</span>
</span>
</td>
<td id="S3.T4.1.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T4.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.4.1.1" class="ltx_p" style="width:43.4pt;">contradiction</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Synthetic examples from our data. We show examples with different domains, length categories, and labels. The most relevant part of the premise is bolded manually for ease of reading.</figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We also performed a human annotation experiment to
a) to understand the accuracy of labels on our generated examples, and
b) create a curated high-accuracy multi-domain test set for evaluation.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.7" class="ltx_p">Each of the <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mn id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><cn type="integer" id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">500</annotation></semantics></math> generated examples was annotated with an NLI label by three of the paper’s authors. Note that the examples were taken verbatim from the models, and are not revised by the annotators. The average Cohen’s <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\kappa</annotation></semantics></math> score between annotators is <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="67.97\%" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mrow id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mn id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml">67.97</mn><mo id="S3.SS3.p4.3.m3.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><csymbol cd="latexml" id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">67.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">67.97\%</annotation></semantics></math>, indicating substantial agreement.
A majority label (<math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><mn id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><cn type="integer" id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">2</annotation></semantics></math> out of <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><mn id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><cn type="integer" id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">3</annotation></semantics></math> annotators) was obtained in 490 examples, and we use these as a human-annotated test set. We also identified a subset, called <em id="S3.SS3.p4.7.1" class="ltx_emph ltx_font_italic">unanimous</em>, where all annotators agreed on the labels (<math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="344" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><mn id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml">344</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><cn type="integer" id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">344</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">344</annotation></semantics></math>/<math id="S3.SS3.p4.7.m7.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.SS3.p4.7.m7.1a"><mn id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><cn type="integer" id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">500</annotation></semantics></math>).</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.5" class="ltx_p">We also measured the accuracy of synthetic labels from our model against the <em id="S3.SS3.p5.5.1" class="ltx_emph ltx_font_italic">majority</em> and <em id="S3.SS3.p5.5.2" class="ltx_emph ltx_font_italic">unanimous</em> labels from human annotators. Model labels have high accuracy with <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="80.41\%" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mn id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">80.41</mn><mo id="S3.SS3.p5.1.m1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">80.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">80.41\%</annotation></semantics></math> against majority and <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="89.53\%" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><mrow id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><mn id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">89.53</mn><mo id="S3.SS3.p5.2.m2.1.1.1" xref="S3.SS3.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><csymbol cd="latexml" id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">89.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">89.53\%</annotation></semantics></math> on the <em id="S3.SS3.p5.5.3" class="ltx_emph ltx_font_italic">unanimous</em> examples. The <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><mi id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><ci id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">\kappa</annotation></semantics></math> coefficient between model labels and majority and unanimous subsets is also high (<math id="S3.SS3.p5.4.m4.1" class="ltx_Math" alttext="70.53\%" display="inline"><semantics id="S3.SS3.p5.4.m4.1a"><mrow id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml"><mn id="S3.SS3.p5.4.m4.1.1.2" xref="S3.SS3.p5.4.m4.1.1.2.cmml">70.53</mn><mo id="S3.SS3.p5.4.m4.1.1.1" xref="S3.SS3.p5.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.1b"><apply id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1"><csymbol cd="latexml" id="S3.SS3.p5.4.m4.1.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.4.m4.1.1.2.cmml" xref="S3.SS3.p5.4.m4.1.1.2">70.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.1c">70.53\%</annotation></semantics></math> and <math id="S3.SS3.p5.5.m5.1" class="ltx_Math" alttext="84.17\%" display="inline"><semantics id="S3.SS3.p5.5.m5.1a"><mrow id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml"><mn id="S3.SS3.p5.5.m5.1.1.2" xref="S3.SS3.p5.5.m5.1.1.2.cmml">84.17</mn><mo id="S3.SS3.p5.5.m5.1.1.1" xref="S3.SS3.p5.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.1b"><apply id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1"><csymbol cd="latexml" id="S3.SS3.p5.5.m5.1.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.5.m5.1.1.2.cmml" xref="S3.SS3.p5.5.m5.1.1.2">84.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">84.17\%</annotation></semantics></math> respectively).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We explore the strengths of our <em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">general</em>-dataset (GNLI for brevity), by examining the model predictions on data unseen during training.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.3" class="ltx_p">We compare models trained on our data with those trained on other large NLI training sets. We choose three such sources: the MNLI dataset (<math id="S4.p2.1.m1.1" class="ltx_Math" alttext="392" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">392</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="integer" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">392</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">392</annotation></semantics></math>K training examples), ANLI (<math id="S4.p2.2.m2.1" class="ltx_Math" alttext="162" display="inline"><semantics id="S4.p2.2.m2.1a"><mn id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">162</mn><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><cn type="integer" id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">162</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">162</annotation></semantics></math>K) with examples that are harder for MNLI trained models, and WANLI (<math id="S4.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.p2.3.m3.1a"><mn id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><cn type="integer" id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">10</annotation></semantics></math>2K), a dataset created by machine-human collaboration.
We note that all of these datasets are collected with a similar methodology, i.e., given a premise (and optionally a label), annotators (or LLMs) write a hypothesis. The final label is then manually assigned to the example (if not given as input). In addition, WANLI and GNLI have used MNLI exemplars
(few-shot or supervised learning) for data generation. So these datasets would have similar properties in theory.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">For all these sources, we trained T5 models <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> as a standard test bed, and explore models of different sizes: small (60M), large (770M), and XXL (11B). We trained on the respective training splits, and tune hyper-parameters on the corresponding validation sets. For WANLI which does not contain a validation split, we used the MNLI validation data. We also trained models on the combination of GNLI and other datasets. For these combined models, we tuned hyper-parameters based on the classification accuracy on the development set of GNLI.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>See hyper-parameter details in Appendix <a href="#A2" title="Appendix B Hyper-parameter details ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</span></span></span></p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">We train two classifiers for each model size (e.g., T5 XXL) and training data (e.g., ANLI): a 3-way classifier with all the three labels, and a binary classifier. For the binary case, we convert each NLI dataset into a binary dataset with entailment and non-entailment (neutral and contradiction) labels. We use the binary classifiers and 3-way classifiers for factual consistency evaluation and NLI benchmarks, respectively.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.3.1.1" class="ltx_p">FRANK</span>
</span>
</td>
<td id="S4.T5.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.4.1.1" class="ltx_p">QAGS C</span>
</span>
</td>
<td id="S4.T5.1.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.5.1.1" class="ltx_p">QAGS X</span>
</span>
</td>
<td id="S4.T5.1.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.6.1.1" class="ltx_p">MNBM</span>
</span>
</td>
<td id="S4.T5.1.1.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.7.1.1" class="ltx_p">Summ Eval</span>
</span>
</td>
<td id="S4.T5.1.1.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.8.1.1" class="ltx_p">BEGIN</span>
</span>
</td>
<td id="S4.T5.1.1.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.9.1.1" class="ltx_p">Dial Fact</span>
</span>
</td>
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.1.1" class="ltx_p">Q<sup id="S4.T5.1.1.1.1.1.1" class="ltx_sup">2</sup></span>
</span>
</td>
<td id="S4.T5.1.1.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.10.1.1" class="ltx_p">PAWS</span>
</span>
</td>
<td id="S4.T5.1.1.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.11.1.1" class="ltx_p">FEVER</span>
</span>
</td>
<td id="S4.T5.1.1.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.12.1.1" class="ltx_p">Vitamin C</span>
</span>
</td>
<td id="S4.T5.1.1.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.1.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.13.1.1" class="ltx_p">Avg</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.2" class="ltx_tr">
<td id="S4.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="13"><span id="S4.T5.1.2.1.1" class="ltx_text ltx_font_smallcaps"> T5 small</span>
</td>
</tr>
<tr id="S4.T5.1.3" class="ltx_tr">
<td id="S4.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">MNLI</td>
<td id="S4.T5.1.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.1.1" class="ltx_p">49.62</span>
</span>
</td>
<td id="S4.T5.1.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.3.1.1" class="ltx_p">37.76</span>
</span>
</td>
<td id="S4.T5.1.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.4.1.1" class="ltx_p">58.30</span>
</span>
</td>
<td id="S4.T5.1.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.5.1.1" class="ltx_p">70.30</span>
</span>
</td>
<td id="S4.T5.1.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.6.1.1" class="ltx_p">45.97</span>
</span>
</td>
<td id="S4.T5.1.3.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.7.1.1" class="ltx_p">80.77</span>
</span>
</td>
<td id="S4.T5.1.3.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.8.1.1" class="ltx_p">76.10</span>
</span>
</td>
<td id="S4.T5.1.3.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.9.1.1" class="ltx_p">68.40</span>
</span>
</td>
<td id="S4.T5.1.3.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.10.1.1" class="ltx_p">51.68</span>
</span>
</td>
<td id="S4.T5.1.3.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.11.1.1" class="ltx_p">89.33</span>
</span>
</td>
<td id="S4.T5.1.3.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.12.1.1" class="ltx_p">70.10</span>
</span>
</td>
<td id="S4.T5.1.3.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.3.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.13.1.1" class="ltx_p">63.48</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.4" class="ltx_tr">
<td id="S4.T5.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">ANLI</td>
<td id="S4.T5.1.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.2.1.1" class="ltx_p">50.95</span>
</span>
</td>
<td id="S4.T5.1.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.1.1" class="ltx_p">54.64</span>
</span>
</td>
<td id="S4.T5.1.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.4.1.1" class="ltx_p">44.70</span>
</span>
</td>
<td id="S4.T5.1.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.5.1.1" class="ltx_p">53.99</span>
</span>
</td>
<td id="S4.T5.1.4.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.6.1.1" class="ltx_p">51.34</span>
</span>
</td>
<td id="S4.T5.1.4.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.7.1.1" class="ltx_p">57.66</span>
</span>
</td>
<td id="S4.T5.1.4.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.8.1.1" class="ltx_p">55.39</span>
</span>
</td>
<td id="S4.T5.1.4.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.9.1.1" class="ltx_p">45.02</span>
</span>
</td>
<td id="S4.T5.1.4.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.10.1.1" class="ltx_p">47.09</span>
</span>
</td>
<td id="S4.T5.1.4.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.11.1.1" class="ltx_p">55.24</span>
</span>
</td>
<td id="S4.T5.1.4.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.12.1.1" class="ltx_p">53.50</span>
</span>
</td>
<td id="S4.T5.1.4.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.4.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.13.1.1" class="ltx_p">51.77</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.5" class="ltx_tr">
<td id="S4.T5.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">WANLI</td>
<td id="S4.T5.1.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.2.1.1" class="ltx_p">57.99</span>
</span>
</td>
<td id="S4.T5.1.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.3.1.1" class="ltx_p">54.14</span>
</span>
</td>
<td id="S4.T5.1.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.1.1" class="ltx_p">70.21</span>
</span>
</td>
<td id="S4.T5.1.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.5.1.1" class="ltx_p">69.90</span>
</span>
</td>
<td id="S4.T5.1.5.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.6.1.1" class="ltx_p">48.98</span>
</span>
</td>
<td id="S4.T5.1.5.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.7.1.1" class="ltx_p">65.79</span>
</span>
</td>
<td id="S4.T5.1.5.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.8.1.1" class="ltx_p">77.62</span>
</span>
</td>
<td id="S4.T5.1.5.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.9.1.1" class="ltx_p">68.97</span>
</span>
</td>
<td id="S4.T5.1.5.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.10.1.1" class="ltx_p">51.51</span>
</span>
</td>
<td id="S4.T5.1.5.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.11.1.1" class="ltx_p">84.35</span>
</span>
</td>
<td id="S4.T5.1.5.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.12.1.1" class="ltx_p">67.85</span>
</span>
</td>
<td id="S4.T5.1.5.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.5.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.13.1.1" class="ltx_p">65.21</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.6" class="ltx_tr">
<td id="S4.T5.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">GNLI</td>
<td id="S4.T5.1.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.2.1.1" class="ltx_p"><span id="S4.T5.1.6.2.1.1.1" class="ltx_text ltx_font_bold">67.32</span></span>
</span>
</td>
<td id="S4.T5.1.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.3.1.1" class="ltx_p"><span id="S4.T5.1.6.3.1.1.1" class="ltx_text ltx_font_bold">60.22</span></span>
</span>
</td>
<td id="S4.T5.1.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.4.1.1" class="ltx_p"><span id="S4.T5.1.6.4.1.1.1" class="ltx_text ltx_font_bold">72.39</span></span>
</span>
</td>
<td id="S4.T5.1.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.1.1" class="ltx_p"><span id="S4.T5.1.6.5.1.1.1" class="ltx_text ltx_font_bold">76.91</span></span>
</span>
</td>
<td id="S4.T5.1.6.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.6.1.1" class="ltx_p"><span id="S4.T5.1.6.6.1.1.1" class="ltx_text ltx_font_bold">56.29</span></span>
</span>
</td>
<td id="S4.T5.1.6.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.7.1.1" class="ltx_p"><span id="S4.T5.1.6.7.1.1.1" class="ltx_text ltx_font_bold">82.21</span></span>
</span>
</td>
<td id="S4.T5.1.6.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.8.1.1" class="ltx_p"><span id="S4.T5.1.6.8.1.1.1" class="ltx_text ltx_font_bold">81.23</span></span>
</span>
</td>
<td id="S4.T5.1.6.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.9.1.1" class="ltx_p"><span id="S4.T5.1.6.9.1.1.1" class="ltx_text ltx_font_bold">72.10</span></span>
</span>
</td>
<td id="S4.T5.1.6.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.10.1.1" class="ltx_p"><span id="S4.T5.1.6.10.1.1.1" class="ltx_text ltx_font_bold">57.33</span></span>
</span>
</td>
<td id="S4.T5.1.6.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.11.1.1" class="ltx_p"><span id="S4.T5.1.6.11.1.1.1" class="ltx_text ltx_font_bold">90.54</span></span>
</span>
</td>
<td id="S4.T5.1.6.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.12.1.1" class="ltx_p"><span id="S4.T5.1.6.12.1.1.1" class="ltx_text ltx_font_bold">76.11</span></span>
</span>
</td>
<td id="S4.T5.1.6.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.6.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.13.1.1" class="ltx_p"><span id="S4.T5.1.6.13.1.1.1" class="ltx_text ltx_font_bold">72.06</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.7" class="ltx_tr">
<td id="S4.T5.1.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="13"><span id="S4.T5.1.7.1.1" class="ltx_text ltx_font_smallcaps"> T5 large</span>
</td>
</tr>
<tr id="S4.T5.1.8" class="ltx_tr">
<td id="S4.T5.1.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">MNLI</td>
<td id="S4.T5.1.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.2.1.1" class="ltx_p">79.15</span>
</span>
</td>
<td id="S4.T5.1.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.3.1.1" class="ltx_p">58.13</span>
</span>
</td>
<td id="S4.T5.1.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.4.1.1" class="ltx_p">79.56</span>
</span>
</td>
<td id="S4.T5.1.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.5.1.1" class="ltx_p">79.27</span>
</span>
</td>
<td id="S4.T5.1.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.6.1.1" class="ltx_p">61.59</span>
</span>
</td>
<td id="S4.T5.1.8.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.7.1.1" class="ltx_p">82.13</span>
</span>
</td>
<td id="S4.T5.1.8.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.8.1.1" class="ltx_p">87.65</span>
</span>
</td>
<td id="S4.T5.1.8.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.9.1.1" class="ltx_p">77.32</span>
</span>
</td>
<td id="S4.T5.1.8.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.10.1.1" class="ltx_p">75.82</span>
</span>
</td>
<td id="S4.T5.1.8.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.11.1.1" class="ltx_p">93.97</span>
</span>
</td>
<td id="S4.T5.1.8.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.12.1.1" class="ltx_p">81.60</span>
</span>
</td>
<td id="S4.T5.1.8.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.8.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.13.1.1" class="ltx_p">77.84</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.9" class="ltx_tr">
<td id="S4.T5.1.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">ANLI</td>
<td id="S4.T5.1.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.2.1.1" class="ltx_p">81.78</span>
</span>
</td>
<td id="S4.T5.1.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.3.1.1" class="ltx_p">74.69</span>
</span>
</td>
<td id="S4.T5.1.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.4.1.1" class="ltx_p">81.81</span>
</span>
</td>
<td id="S4.T5.1.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.5.1.1" class="ltx_p">75.49</span>
</span>
</td>
<td id="S4.T5.1.9.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.6.1.1" class="ltx_p">71.60</span>
</span>
</td>
<td id="S4.T5.1.9.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.7.1.1" class="ltx_p">78.21</span>
</span>
</td>
<td id="S4.T5.1.9.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.8.1.1" class="ltx_p">85.63</span>
</span>
</td>
<td id="S4.T5.1.9.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.9.1.1" class="ltx_p">78.43</span>
</span>
</td>
<td id="S4.T5.1.9.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.10.1.1" class="ltx_p"><span id="S4.T5.1.9.10.1.1.1" class="ltx_text ltx_font_bold">84.72</span></span>
</span>
</td>
<td id="S4.T5.1.9.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.11.1.1" class="ltx_p">94.03</span>
</span>
</td>
<td id="S4.T5.1.9.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.12.1.1" class="ltx_p"><span id="S4.T5.1.9.12.1.1.1" class="ltx_text ltx_font_bold">89.63</span></span>
</span>
</td>
<td id="S4.T5.1.9.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.9.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.9.13.1.1" class="ltx_p">81.46</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.10" class="ltx_tr">
<td id="S4.T5.1.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">WANLI</td>
<td id="S4.T5.1.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.2.1.1" class="ltx_p">80.31</span>
</span>
</td>
<td id="S4.T5.1.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.3.1.1" class="ltx_p">74.46</span>
</span>
</td>
<td id="S4.T5.1.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.4.1.1" class="ltx_p">70.11</span>
</span>
</td>
<td id="S4.T5.1.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.5.1.1" class="ltx_p">67.70</span>
</span>
</td>
<td id="S4.T5.1.10.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.6.1.1" class="ltx_p">72.86</span>
</span>
</td>
<td id="S4.T5.1.10.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.7.1.1" class="ltx_p">80.37</span>
</span>
</td>
<td id="S4.T5.1.10.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.8.1.1" class="ltx_p"><span id="S4.T5.1.10.8.1.1.1" class="ltx_text ltx_font_bold">89.15</span></span>
</span>
</td>
<td id="S4.T5.1.10.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.9.1.1" class="ltx_p"><span id="S4.T5.1.10.9.1.1.1" class="ltx_text ltx_font_bold">82.16</span></span>
</span>
</td>
<td id="S4.T5.1.10.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.10.1.1" class="ltx_p">83.17</span>
</span>
</td>
<td id="S4.T5.1.10.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.11.1.1" class="ltx_p">93.82</span>
</span>
</td>
<td id="S4.T5.1.10.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.12.1.1" class="ltx_p">82.79</span>
</span>
</td>
<td id="S4.T5.1.10.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.10.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.10.13.1.1" class="ltx_p">79.72</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.11" class="ltx_tr">
<td id="S4.T5.1.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">GNLI</td>
<td id="S4.T5.1.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.2.1.1" class="ltx_p"><span id="S4.T5.1.11.2.1.1.1" class="ltx_text ltx_font_bold">90.14</span></span>
</span>
</td>
<td id="S4.T5.1.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.3.1.1" class="ltx_p"><span id="S4.T5.1.11.3.1.1.1" class="ltx_text ltx_font_bold">81.33</span></span>
</span>
</td>
<td id="S4.T5.1.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.4.1.1" class="ltx_p"><span id="S4.T5.1.11.4.1.1.1" class="ltx_text ltx_font_bold">84.02</span></span>
</span>
</td>
<td id="S4.T5.1.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.5.1.1" class="ltx_p"><span id="S4.T5.1.11.5.1.1.1" class="ltx_text ltx_font_bold">79.49</span></span>
</span>
</td>
<td id="S4.T5.1.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.6.1.1" class="ltx_p"><span id="S4.T5.1.11.6.1.1.1" class="ltx_text ltx_font_bold">79.75</span></span>
</span>
</td>
<td id="S4.T5.1.11.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.7.1.1" class="ltx_p"><span id="S4.T5.1.11.7.1.1.1" class="ltx_text ltx_font_bold">83.45</span></span>
</span>
</td>
<td id="S4.T5.1.11.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.8.1.1" class="ltx_p">88.76</span>
</span>
</td>
<td id="S4.T5.1.11.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.9.1.1" class="ltx_p">79.77</span>
</span>
</td>
<td id="S4.T5.1.11.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.10.1.1" class="ltx_p">84.63</span>
</span>
</td>
<td id="S4.T5.1.11.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.11.1.1" class="ltx_p"><span id="S4.T5.1.11.11.1.1.1" class="ltx_text ltx_font_bold">94.73</span></span>
</span>
</td>
<td id="S4.T5.1.11.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.12.1.1" class="ltx_p">85.86</span>
</span>
</td>
<td id="S4.T5.1.11.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.11.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.11.13.1.1" class="ltx_p"><span id="S4.T5.1.11.13.1.1.1" class="ltx_text ltx_font_bold">84.72</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.12" class="ltx_tr">
<td id="S4.T5.1.12.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="13"><span id="S4.T5.1.12.1.1" class="ltx_text ltx_font_smallcaps"> T5 xxl</span>
</td>
</tr>
<tr id="S4.T5.1.13" class="ltx_tr">
<td id="S4.T5.1.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">MNLI</td>
<td id="S4.T5.1.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.2.1.1" class="ltx_p">88.18</span>
</span>
</td>
<td id="S4.T5.1.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.3.1.1" class="ltx_p">79.03</span>
</span>
</td>
<td id="S4.T5.1.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.4.1.1" class="ltx_p">83.07</span>
</span>
</td>
<td id="S4.T5.1.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.5.1.1" class="ltx_p">78.31</span>
</span>
</td>
<td id="S4.T5.1.13.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.6.1.1" class="ltx_p">72.35</span>
</span>
</td>
<td id="S4.T5.1.13.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.7.1.1" class="ltx_p">81.76</span>
</span>
</td>
<td id="S4.T5.1.13.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.8.1.1" class="ltx_p">88.32</span>
</span>
</td>
<td id="S4.T5.1.13.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.9.1.1" class="ltx_p">76.84</span>
</span>
</td>
<td id="S4.T5.1.13.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.10.1.1" class="ltx_p">83.11</span>
</span>
</td>
<td id="S4.T5.1.13.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.11.1.1" class="ltx_p">95.13</span>
</span>
</td>
<td id="S4.T5.1.13.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.12.1.1" class="ltx_p">84.58</span>
</span>
</td>
<td id="S4.T5.1.13.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.13.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.13.13.1.1" class="ltx_p">82.79</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.14" class="ltx_tr">
<td id="S4.T5.1.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">ANLI</td>
<td id="S4.T5.1.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.2.1.1" class="ltx_p">87.90</span>
</span>
</td>
<td id="S4.T5.1.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.3.1.1" class="ltx_p">82.08</span>
</span>
</td>
<td id="S4.T5.1.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.4.1.1" class="ltx_p">84.68</span>
</span>
</td>
<td id="S4.T5.1.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.5.1.1" class="ltx_p">76.41</span>
</span>
</td>
<td id="S4.T5.1.14.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.6.1.1" class="ltx_p">75.79</span>
</span>
</td>
<td id="S4.T5.1.14.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.7.1.1" class="ltx_p">79.77</span>
</span>
</td>
<td id="S4.T5.1.14.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.8.1.1" class="ltx_p">81.06</span>
</span>
</td>
<td id="S4.T5.1.14.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.9.1.1" class="ltx_p">74.68</span>
</span>
</td>
<td id="S4.T5.1.14.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.10.1.1" class="ltx_p">86.35</span>
</span>
</td>
<td id="S4.T5.1.14.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.11.1.1" class="ltx_p">93.46</span>
</span>
</td>
<td id="S4.T5.1.14.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.12.1.1" class="ltx_p"><span id="S4.T5.1.14.12.1.1.1" class="ltx_text ltx_font_bold">90.59</span></span>
</span>
</td>
<td id="S4.T5.1.14.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.14.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.14.13.1.1" class="ltx_p">82.98</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.15" class="ltx_tr">
<td id="S4.T5.1.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">WANLI</td>
<td id="S4.T5.1.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.2.1.1" class="ltx_p">88.59</span>
</span>
</td>
<td id="S4.T5.1.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.3.1.1" class="ltx_p">72.18</span>
</span>
</td>
<td id="S4.T5.1.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.4.1.1" class="ltx_p">82.85</span>
</span>
</td>
<td id="S4.T5.1.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.5.1.1" class="ltx_p">73.29</span>
</span>
</td>
<td id="S4.T5.1.15.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.6.1.1" class="ltx_p">74.61</span>
</span>
</td>
<td id="S4.T5.1.15.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.7.1.1" class="ltx_p">82.47</span>
</span>
</td>
<td id="S4.T5.1.15.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.8.1.1" class="ltx_p"><span id="S4.T5.1.15.8.1.1.1" class="ltx_text ltx_font_bold">92.40</span></span>
</span>
</td>
<td id="S4.T5.1.15.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.9.1.1" class="ltx_p"><span id="S4.T5.1.15.9.1.1.1" class="ltx_text ltx_font_bold">84.88</span></span>
</span>
</td>
<td id="S4.T5.1.15.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.10.1.1" class="ltx_p"><span id="S4.T5.1.15.10.1.1.1" class="ltx_text ltx_font_bold">87.29</span></span>
</span>
</td>
<td id="S4.T5.1.15.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.11.1.1" class="ltx_p">94.97</span>
</span>
</td>
<td id="S4.T5.1.15.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.12.1.1" class="ltx_p">87.38</span>
</span>
</td>
<td id="S4.T5.1.15.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.15.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.15.13.1.1" class="ltx_p">83.72</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.16" class="ltx_tr">
<td id="S4.T5.1.16.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">GNLI</td>
<td id="S4.T5.1.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.2.1.1" class="ltx_p"><span id="S4.T5.1.16.2.1.1.1" class="ltx_text ltx_font_bold">91.38</span></span>
</span>
</td>
<td id="S4.T5.1.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.3.1.1" class="ltx_p"><span id="S4.T5.1.16.3.1.1.1" class="ltx_text ltx_font_bold">85.48</span></span>
</span>
</td>
<td id="S4.T5.1.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.4.1.1" class="ltx_p"><span id="S4.T5.1.16.4.1.1.1" class="ltx_text ltx_font_bold">87.03</span></span>
</span>
</td>
<td id="S4.T5.1.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.5.1.1" class="ltx_p"><span id="S4.T5.1.16.5.1.1.1" class="ltx_text ltx_font_bold">79.97</span></span>
</span>
</td>
<td id="S4.T5.1.16.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.6.1.1" class="ltx_p"><span id="S4.T5.1.16.6.1.1.1" class="ltx_text ltx_font_bold">79.28</span></span>
</span>
</td>
<td id="S4.T5.1.16.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.7.1.1" class="ltx_p"><span id="S4.T5.1.16.7.1.1.1" class="ltx_text ltx_font_bold">84.00</span></span>
</span>
</td>
<td id="S4.T5.1.16.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.8.1.1" class="ltx_p">88.57</span>
</span>
</td>
<td id="S4.T5.1.16.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.9.1.1" class="ltx_p">77.40</span>
</span>
</td>
<td id="S4.T5.1.16.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.10.1.1" class="ltx_p">87.10</span>
</span>
</td>
<td id="S4.T5.1.16.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.11.1.1" class="ltx_p"><span id="S4.T5.1.16.11.1.1.1" class="ltx_text ltx_font_bold">95.34</span></span>
</span>
</td>
<td id="S4.T5.1.16.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.12.1.1" class="ltx_p">87.69</span>
</span>
</td>
<td id="S4.T5.1.16.13" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:26.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T5.1.16.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.16.13.1.1" class="ltx_p"><span id="S4.T5.1.16.13.1.1.1" class="ltx_text ltx_font_bold">85.75</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>
Evaluation of multiple trained models on the TRUE benchmark.
Results are split into three blocks based on the LM size
(T5 small, T5 large, and T5 XXL). We report average AUC-ROC results on all the datasets (expressed as percentages). The best result for each model size and dataset is bolded.
</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Performance on unseen factual consistency benchmarks</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We first test different models on
data unseen by all of them. We use the TRUE benchmark, a collection of 11 evaluation datasets that contain human annotations for factual consistency in diverse tasks. The tasks include: A) <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">abstractive summarization</span>: FRANK <cite class="ltx_cite ltx_citemacro_cite">Pagnoni et al. (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>, SummEval <cite class="ltx_cite ltx_citemacro_cite">Fabbri et al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>, MNBM <cite class="ltx_cite ltx_citemacro_cite">Maynez et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>, <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>, QAGS-CNNDM <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>, and QAGS-XSum <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>. B) <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_bold">dialogue generation</span>: BEGIN <cite class="ltx_cite ltx_citemacro_cite">Dziri et al. (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>, Q<sup id="S4.SS1.p1.1.3" class="ltx_sup">2</sup> <cite class="ltx_cite ltx_citemacro_cite">Honovich et al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>, and DialFact <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite>. C) <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_bold">fact verification</span>: FEVER <cite class="ltx_cite ltx_citemacro_cite">Thorne et al. (<a href="#bib.bib30" title="" class="ltx_ref">2018</a>)</cite>, and VitaminC <cite class="ltx_cite ltx_citemacro_cite">Schuster et al. (<a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite>. D) <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_bold">paraphrase detection</span>: PAWS <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite>. The benchmark standardizes the above datasets by converting all annotations to binary labels corresponding to whether the entire text is factuality consistent w.r.t the grounding text or not.
This task is a downstream application of NLI models and importantly, the data in this benchmark was not created using the same protocol as NLI benchmarks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4 Experiments ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the results of the models we trained. Following previous work, we report the Receiver Operating Characteristic Area Under the Curve (ROC AUC) for binary detection of inconsistent examples. GNLI outperforms MNLI on all datasets across model sizes showing that it has much stronger generalization. On average, GNLI outperforms MNLI for T5-small trained models by a <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="8.58\%" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">8.58</mn><mo id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">8.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">8.58\%</annotation></semantics></math> margin, T5-large trained models by <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="6.88\%" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mn id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">6.88</mn><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">6.88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">6.88\%</annotation></semantics></math>, and T5-XXL trained models by <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="2.96\%" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mn id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">2.96</mn><mo id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">2.96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">2.96\%</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.5" class="ltx_p">To the best of our knowledge, the previously reported best NLI model on the TRUE benchmark was T5 XXL trained on ANLI <cite class="ltx_cite ltx_citemacro_cite">Honovich et al. (<a href="#bib.bib15" title="" class="ltx_ref">2022</a>); Gekhman et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>. GNLI obtains <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="6.85\%" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">6.85</mn><mo id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">6.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">6.85\%</annotation></semantics></math> improvement on average over the best alternative for T5 small (WANLI), <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="3.26\%" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mn id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">3.26</mn><mo id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">3.26</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">3.26\%</annotation></semantics></math> for T5 large (ANLI), and <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="2.03\%" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mn id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">2.03</mn><mo id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">2.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">2.03\%</annotation></semantics></math> for T5 XXL (WANLI). Therefore, GNLI obtains a new state-of-the-art result on TRUE, outperforming other models with large margins on average and on almost all of the individual test sets within TRUE. We note that <cite class="ltx_cite ltx_citemacro_citet">Gekhman et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite> have recently proposed a synthetic dataset, called TrueTeacher, for the task of factual consistency detection. They used summarization models to condense CNN/DM articles, and labelled the document-summary pair with FLAN-PaLM 540B <cite class="ltx_cite ltx_citemacro_cite">Chowdhery et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> based NLI model. Models trained on the TrueTeacher outperformed ANLI ones. We trained a T5 XXL on the TrueTeacher data and observed better performance compared to GNLI as well (<math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="88.06\%" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mn id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">88.06</mn><mo id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2">88.06</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">88.06\%</annotation></semantics></math> vs <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="85.75\%" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><mrow id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mn id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">85.75</mn><mo id="S4.SS1.p3.5.m5.1.1.1" xref="S4.SS1.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><csymbol cd="latexml" id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">85.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">85.75\%</annotation></semantics></math> on average). This is expected since TrueTeacher is collected directly for the task of factual consistency detection and makes only the binary distinction.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2402.12368/assets/images/synthetic_plot.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="260" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Accuracy of different T5 models when trained on different number of training examples from GNLI. Each plot has the results on one evaluation set.</figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T6.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.1.1.1" class="ltx_p">Train / Eval</span>
</span>
</td>
<td id="S4.T6.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.2.1.1" class="ltx_p">MNLI</span>
</span>
</td>
<td id="S4.T6.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.3.1.1" class="ltx_p">ANLI</span>
</span>
</td>
<td id="S4.T6.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.4.1.1" class="ltx_p">WANLI</span>
</span>
</td>
<td id="S4.T6.1.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.5.1.1" class="ltx_p">GNLI Human</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.2" class="ltx_tr">
<td id="S4.T6.1.2.1" class="ltx_td ltx_align_center ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="5"><span id="S4.T6.1.2.1.1" class="ltx_text ltx_font_smallcaps"> T5 small</span>
</td>
</tr>
<tr id="S4.T6.1.3" class="ltx_tr">
<td id="S4.T6.1.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.1.1.1" class="ltx_p">MNLI</span>
</span>
</td>
<td id="S4.T6.1.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.2.1.1" class="ltx_p"><span id="S4.T6.1.3.2.1.1.1" class="ltx_text ltx_font_bold">83.37</span></span>
</span>
</td>
<td id="S4.T6.1.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.3.1.1" class="ltx_p">31.34</span>
</span>
</td>
<td id="S4.T6.1.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.4.1.1" class="ltx_p">56.52</span>
</span>
</td>
<td id="S4.T6.1.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.5.1.1" class="ltx_p">75.31</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.4" class="ltx_tr">
<td id="S4.T6.1.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.1.1.1" class="ltx_p">ANLI</span>
</span>
</td>
<td id="S4.T6.1.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.2.1.1" class="ltx_p">70.35</span>
</span>
</td>
<td id="S4.T6.1.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.3.1.1" class="ltx_p"><span id="S4.T6.1.4.3.1.1.1" class="ltx_text ltx_font_bold">48.31</span></span>
</span>
</td>
<td id="S4.T6.1.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.4.1.1" class="ltx_p">52.70</span>
</span>
</td>
<td id="S4.T6.1.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.5.1.1" class="ltx_p">67.14</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.5" class="ltx_tr">
<td id="S4.T6.1.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.1.1.1" class="ltx_p">WANLI</span>
</span>
</td>
<td id="S4.T6.1.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.2.1.1" class="ltx_p">60.40</span>
</span>
</td>
<td id="S4.T6.1.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.3.1.1" class="ltx_p">36.41</span>
</span>
</td>
<td id="S4.T6.1.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.4.1.1" class="ltx_p"><span id="S4.T6.1.5.4.1.1.1" class="ltx_text ltx_font_bold">72.60</span></span>
</span>
</td>
<td id="S4.T6.1.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.5.1.1" class="ltx_p">57.76</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.6" class="ltx_tr">
<td id="S4.T6.1.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.1.1.1" class="ltx_p">GNLI</span>
</span>
</td>
<td id="S4.T6.1.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.2.1.1" class="ltx_p">82.18</span>
</span>
</td>
<td id="S4.T6.1.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.3.1.1" class="ltx_p">33.00</span>
</span>
</td>
<td id="S4.T6.1.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.4.1.1" class="ltx_p">56.56</span>
</span>
</td>
<td id="S4.T6.1.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.5.1.1" class="ltx_p"><span id="S4.T6.1.6.5.1.1.1" class="ltx_text ltx_font_bold">77.14</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.7" class="ltx_tr">
<td id="S4.T6.1.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.1.1.1" class="ltx_p">MNLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.2.1.1" class="ltx_p">82.66</span>
</span>
</td>
<td id="S4.T6.1.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.3.1.1" class="ltx_p">30.94</span>
</span>
</td>
<td id="S4.T6.1.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.4.1.1" class="ltx_p">55.82</span>
</span>
</td>
<td id="S4.T6.1.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.5.1.1" class="ltx_p"><span id="S4.T6.1.7.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">77.76</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.8" class="ltx_tr">
<td id="S4.T6.1.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.1.1.1" class="ltx_p">ANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.2.1.1" class="ltx_p"><span id="S4.T6.1.8.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">72.89</span></span>
</span>
</td>
<td id="S4.T6.1.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.3.1.1" class="ltx_p">37.94</span>
</span>
</td>
<td id="S4.T6.1.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.4.1.1" class="ltx_p">48.65</span>
</span>
</td>
<td id="S4.T6.1.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.5.1.1" class="ltx_p"><span id="S4.T6.1.8.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">69.80</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.9" class="ltx_tr">
<td id="S4.T6.1.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.1.1.1" class="ltx_p">WANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.2.1.1" class="ltx_p"><span id="S4.T6.1.9.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">78.02</span></span>
</span>
</td>
<td id="S4.T6.1.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.3.1.1" class="ltx_p">34.87</span>
</span>
</td>
<td id="S4.T6.1.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.4.1.1" class="ltx_p"><span id="S4.T6.1.9.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">86.69</span></span>
</span>
</td>
<td id="S4.T6.1.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.5.1.1" class="ltx_p"><span id="S4.T6.1.9.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">76.53</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.10" class="ltx_tr">
<td id="S4.T6.1.10.1" class="ltx_td ltx_align_center ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="5"><span id="S4.T6.1.10.1.1" class="ltx_text ltx_font_smallcaps"> T5 large</span>
</td>
</tr>
<tr id="S4.T6.1.11" class="ltx_tr">
<td id="S4.T6.1.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.1.1.1" class="ltx_p">MNLI</span>
</span>
</td>
<td id="S4.T6.1.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.2.1.1" class="ltx_p"><span id="S4.T6.1.11.2.1.1.1" class="ltx_text ltx_font_bold">90.83</span></span>
</span>
</td>
<td id="S4.T6.1.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.3.1.1" class="ltx_p">40.22</span>
</span>
</td>
<td id="S4.T6.1.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.4.1.1" class="ltx_p">63.58</span>
</span>
</td>
<td id="S4.T6.1.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.5.1.1" class="ltx_p">82.24</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.12" class="ltx_tr">
<td id="S4.T6.1.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.1.1.1" class="ltx_p">ANLI</span>
</span>
</td>
<td id="S4.T6.1.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.2.1.1" class="ltx_p">86.87</span>
</span>
</td>
<td id="S4.T6.1.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.3.1.1" class="ltx_p"><span id="S4.T6.1.12.3.1.1.1" class="ltx_text ltx_font_bold">63.62</span></span>
</span>
</td>
<td id="S4.T6.1.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.4.1.1" class="ltx_p">63.70</span>
</span>
</td>
<td id="S4.T6.1.12.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.5.1.1" class="ltx_p">81.22</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.13" class="ltx_tr">
<td id="S4.T6.1.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.1.1.1" class="ltx_p">WANLI</span>
</span>
</td>
<td id="S4.T6.1.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.2.1.1" class="ltx_p">81.10</span>
</span>
</td>
<td id="S4.T6.1.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.3.1.1" class="ltx_p">48.03</span>
</span>
</td>
<td id="S4.T6.1.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.4.1.1" class="ltx_p"><span id="S4.T6.1.13.4.1.1.1" class="ltx_text ltx_font_bold">92.08</span></span>
</span>
</td>
<td id="S4.T6.1.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.5.1.1" class="ltx_p">77.14</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.14" class="ltx_tr">
<td id="S4.T6.1.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.1.1.1" class="ltx_p">GNLI</span>
</span>
</td>
<td id="S4.T6.1.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.2.1.1" class="ltx_p">90.61</span>
</span>
</td>
<td id="S4.T6.1.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.3.1.1" class="ltx_p">45.72</span>
</span>
</td>
<td id="S4.T6.1.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.4.1.1" class="ltx_p">65.10</span>
</span>
</td>
<td id="S4.T6.1.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.5.1.1" class="ltx_p"><span id="S4.T6.1.14.5.1.1.1" class="ltx_text ltx_font_bold">83.67</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.15" class="ltx_tr">
<td id="S4.T6.1.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.1.1.1" class="ltx_p">MNLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.2.1.1" class="ltx_p"><span id="S4.T6.1.15.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">91.04</span></span>
</span>
</td>
<td id="S4.T6.1.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.3.1.1" class="ltx_p"><span id="S4.T6.1.15.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">44.94</span></span>
</span>
</td>
<td id="S4.T6.1.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.4.1.1" class="ltx_p"><span id="S4.T6.1.15.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">65.54</span></span>
</span>
</td>
<td id="S4.T6.1.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.5.1.1" class="ltx_p"><span id="S4.T6.1.15.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">82.45</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.16" class="ltx_tr">
<td id="S4.T6.1.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.1.1.1" class="ltx_p">ANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.2.1.1" class="ltx_p"><span id="S4.T6.1.16.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">90.61</span></span>
</span>
</td>
<td id="S4.T6.1.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.3.1.1" class="ltx_p"><span id="S4.T6.1.16.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">63.69</span></span>
</span>
</td>
<td id="S4.T6.1.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.4.1.1" class="ltx_p"><span id="S4.T6.1.16.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">65.03</span></span>
</span>
</td>
<td id="S4.T6.1.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.5.1.1" class="ltx_p"><span id="S4.T6.1.16.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">83.67</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.17" class="ltx_tr">
<td id="S4.T6.1.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.1.1.1" class="ltx_p">WANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.2.1.1" class="ltx_p"><span id="S4.T6.1.17.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">87.80</span></span>
</span>
</td>
<td id="S4.T6.1.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.3.1.1" class="ltx_p"><span id="S4.T6.1.17.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">48.34</span></span>
</span>
</td>
<td id="S4.T6.1.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.4.1.1" class="ltx_p"><span id="S4.T6.1.17.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">96.84</span></span>
</span>
</td>
<td id="S4.T6.1.17.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.5.1.1" class="ltx_p"><span id="S4.T6.1.17.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">83.88</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.18" class="ltx_tr">
<td id="S4.T6.1.18.1" class="ltx_td ltx_align_center ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="5"><span id="S4.T6.1.18.1.1" class="ltx_text ltx_font_smallcaps"> T5 xxl</span>
</td>
</tr>
<tr id="S4.T6.1.19" class="ltx_tr">
<td id="S4.T6.1.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.1.1.1" class="ltx_p">MNLI</span>
</span>
</td>
<td id="S4.T6.1.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.2.1.1" class="ltx_p"><span id="S4.T6.1.19.2.1.1.1" class="ltx_text ltx_font_bold">92.11</span></span>
</span>
</td>
<td id="S4.T6.1.19.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.3.1.1" class="ltx_p">55.44</span>
</span>
</td>
<td id="S4.T6.1.19.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.4.1.1" class="ltx_p">65.92</span>
</span>
</td>
<td id="S4.T6.1.19.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.5.1.1" class="ltx_p"><span id="S4.T6.1.19.5.1.1.1" class="ltx_text ltx_font_bold">83.27</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.20" class="ltx_tr">
<td id="S4.T6.1.20.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.1.1.1" class="ltx_p">ANLI</span>
</span>
</td>
<td id="S4.T6.1.20.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.2.1.1" class="ltx_p">90.01</span>
</span>
</td>
<td id="S4.T6.1.20.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.3.1.1" class="ltx_p"><span id="S4.T6.1.20.3.1.1.1" class="ltx_text ltx_font_bold">73.37</span></span>
</span>
</td>
<td id="S4.T6.1.20.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.4.1.1" class="ltx_p">67.04</span>
</span>
</td>
<td id="S4.T6.1.20.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.5.1.1" class="ltx_p">82.86</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.21" class="ltx_tr">
<td id="S4.T6.1.21.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.1.1.1" class="ltx_p">WANLI</span>
</span>
</td>
<td id="S4.T6.1.21.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.2.1.1" class="ltx_p">84.61</span>
</span>
</td>
<td id="S4.T6.1.21.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.3.1.1" class="ltx_p">60.00</span>
</span>
</td>
<td id="S4.T6.1.21.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.4.1.1" class="ltx_p"><span id="S4.T6.1.21.4.1.1.1" class="ltx_text ltx_font_bold">86.46</span></span>
</span>
</td>
<td id="S4.T6.1.21.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.5.1.1" class="ltx_p">81.84</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.22" class="ltx_tr">
<td id="S4.T6.1.22.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.1.1.1" class="ltx_p">GNLI</span>
</span>
</td>
<td id="S4.T6.1.22.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.2.1.1" class="ltx_p">91.77</span>
</span>
</td>
<td id="S4.T6.1.22.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.3.1.1" class="ltx_p">57.87</span>
</span>
</td>
<td id="S4.T6.1.22.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.4.1.1" class="ltx_p">65.43</span>
</span>
</td>
<td id="S4.T6.1.22.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.5.1.1" class="ltx_p">82.65</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.23" class="ltx_tr">
<td id="S4.T6.1.23.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.1.1.1" class="ltx_p">MNLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.23.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.2.1.1" class="ltx_p"><span id="S4.T6.1.23.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">92.13</span></span>
</span>
</td>
<td id="S4.T6.1.23.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.3.1.1" class="ltx_p"><span id="S4.T6.1.23.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">55.94</span></span>
</span>
</td>
<td id="S4.T6.1.23.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.4.1.1" class="ltx_p"><span id="S4.T6.1.23.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">67.06</span></span>
</span>
</td>
<td id="S4.T6.1.23.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.5.1.1" class="ltx_p"><span id="S4.T6.1.23.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">84.08</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.24" class="ltx_tr">
<td id="S4.T6.1.24.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.1.1.1" class="ltx_p">ANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.24.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.2.1.1" class="ltx_p"><span id="S4.T6.1.24.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">91.96</span></span>
</span>
</td>
<td id="S4.T6.1.24.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.3.1.1" class="ltx_p">72.94</span>
</span>
</td>
<td id="S4.T6.1.24.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.4.1.1" class="ltx_p">66.26</span>
</span>
</td>
<td id="S4.T6.1.24.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.5.1.1" class="ltx_p"><span id="S4.T6.1.24.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">84.08</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.25" class="ltx_tr">
<td id="S4.T6.1.25.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r" style="width:117.1pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.1.1.1" class="ltx_p">WANLI + GNLI</span>
</span>
</td>
<td id="S4.T6.1.25.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.2.1.1" class="ltx_p"><span id="S4.T6.1.25.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">90.34</span></span>
</span>
</td>
<td id="S4.T6.1.25.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.3.1.1" class="ltx_p"><span id="S4.T6.1.25.3.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">60.19</span></span>
</span>
</td>
<td id="S4.T6.1.25.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.4.1.1" class="ltx_p"><span id="S4.T6.1.25.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">87.90</span></span>
</span>
</td>
<td id="S4.T6.1.25.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:52.0pt;padding-left:2.5pt;padding-right:2.5pt;">
<span id="S4.T6.1.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.5.1.1" class="ltx_p"><span id="S4.T6.1.25.5.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">84.69</span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>
Performance on NLI benchmarks (accuracy percentage). The models were trained on the respective datasets and tested on all their own and other datasets’ test (or validation) sets. Results are split into three blocks based on the LM size (T5 small,
large, T5 XXL). We also report the results of combining GNLI with MNLI,
ANLI, and WANLI. We bold the highest accuracy per model size and evaluation dataset, for models trained on the single datasets. For each combined training set (GNLI + X) and model size, if the result is better than the original dataset (X), the number is underlined.
</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Cross-dataset performance on NLI benchmarks</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We now examine the models on test sets available with large NLI collections (or validation sets in the absence of test data with labels (MNLI and ANLI)). In this case, at least one model has been trained on data from the same test distribution. Here we seek to understand how general our current datasets are and we also include GNLI in this analysis.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 ‣ 4.1 Performance on unseen factual consistency benchmarks ‣ 4 Experiments ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the results. While all these datasets have been created with the aim of being domain-general, we see that generally the training data distribution makes a huge difference. The best test numbers are usually obtained by training on the corresponding training sets. For example, the best MNLI numbers are obtained with a model that is trained on MNLI. Note that the GNLI dataset (while including a component that is trained on MNLI) does not include the MNLI examples. These results indicate that the style and properties of different NLI test sets are still rather specific to the individual NLI dataset, and a large dataset with the same type of examples performs best on the corresponding test set.
However, the GNLI dataset is as accurate as MNLI on these test sets, even without the explicit addition of MNLI examples.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">We also trained models on all datasets combined with GNLI. We note that in most cases (except for T5 small), the combined datasets have at least some modest improvements over the original datasets (underline numbers in the table).
We speculate that T5 small’s model capacity is not high enough to capture all the information in the combined datasets, but once the model capacity increases, we generally see improvements by adding GNLI to the other NLI datasets.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>How much data is needed for successful training?</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.3" class="ltx_p">GNLI is generated synthetically which is a more efficient and cheaper process compared to crowd-annotated data. It is possible to generate as many examples as necessary, and it is unknown in advance how many examples are needed to get a good performance. On the other hand, generating large sets of examples uses more computing resources. In this section, we study the effect of training data size on evaluation accuracy. We sample <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">N</annotation></semantics></math> thousand number of synthetic training examples from GNLI, where <math id="S4.SS3.p1.2.m2.9" class="ltx_Math" alttext="N\in\{1,2,5,10,50,100,300,392,671\}" display="inline"><semantics id="S4.SS3.p1.2.m2.9a"><mrow id="S4.SS3.p1.2.m2.9.10" xref="S4.SS3.p1.2.m2.9.10.cmml"><mi id="S4.SS3.p1.2.m2.9.10.2" xref="S4.SS3.p1.2.m2.9.10.2.cmml">N</mi><mo id="S4.SS3.p1.2.m2.9.10.1" xref="S4.SS3.p1.2.m2.9.10.1.cmml">∈</mo><mrow id="S4.SS3.p1.2.m2.9.10.3.2" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml"><mo stretchy="false" id="S4.SS3.p1.2.m2.9.10.3.2.1" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">{</mo><mn id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">1</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.2" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.2.2" xref="S4.SS3.p1.2.m2.2.2.cmml">2</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.3" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.3.3" xref="S4.SS3.p1.2.m2.3.3.cmml">5</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.4" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.4.4" xref="S4.SS3.p1.2.m2.4.4.cmml">10</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.5" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.5.5" xref="S4.SS3.p1.2.m2.5.5.cmml">50</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.6" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.6.6" xref="S4.SS3.p1.2.m2.6.6.cmml">100</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.7" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.7.7" xref="S4.SS3.p1.2.m2.7.7.cmml">300</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.8" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.8.8" xref="S4.SS3.p1.2.m2.8.8.cmml">392</mn><mo id="S4.SS3.p1.2.m2.9.10.3.2.9" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">,</mo><mn id="S4.SS3.p1.2.m2.9.9" xref="S4.SS3.p1.2.m2.9.9.cmml">671</mn><mo stretchy="false" id="S4.SS3.p1.2.m2.9.10.3.2.10" xref="S4.SS3.p1.2.m2.9.10.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.9b"><apply id="S4.SS3.p1.2.m2.9.10.cmml" xref="S4.SS3.p1.2.m2.9.10"><in id="S4.SS3.p1.2.m2.9.10.1.cmml" xref="S4.SS3.p1.2.m2.9.10.1"></in><ci id="S4.SS3.p1.2.m2.9.10.2.cmml" xref="S4.SS3.p1.2.m2.9.10.2">𝑁</ci><set id="S4.SS3.p1.2.m2.9.10.3.1.cmml" xref="S4.SS3.p1.2.m2.9.10.3.2"><cn type="integer" id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">1</cn><cn type="integer" id="S4.SS3.p1.2.m2.2.2.cmml" xref="S4.SS3.p1.2.m2.2.2">2</cn><cn type="integer" id="S4.SS3.p1.2.m2.3.3.cmml" xref="S4.SS3.p1.2.m2.3.3">5</cn><cn type="integer" id="S4.SS3.p1.2.m2.4.4.cmml" xref="S4.SS3.p1.2.m2.4.4">10</cn><cn type="integer" id="S4.SS3.p1.2.m2.5.5.cmml" xref="S4.SS3.p1.2.m2.5.5">50</cn><cn type="integer" id="S4.SS3.p1.2.m2.6.6.cmml" xref="S4.SS3.p1.2.m2.6.6">100</cn><cn type="integer" id="S4.SS3.p1.2.m2.7.7.cmml" xref="S4.SS3.p1.2.m2.7.7">300</cn><cn type="integer" id="S4.SS3.p1.2.m2.8.8.cmml" xref="S4.SS3.p1.2.m2.8.8">392</cn><cn type="integer" id="S4.SS3.p1.2.m2.9.9.cmml" xref="S4.SS3.p1.2.m2.9.9">671</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.9c">N\in\{1,2,5,10,50,100,300,392,671\}</annotation></semantics></math> (<math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="671" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mn id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">671</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><cn type="integer" id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">671</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">671</annotation></semantics></math>K is the full GNLI dataset). We then train T5 models on all these sample sizes.
We then evaluate the trained models on different NLI datasets. The evaluation is on validation sets from MNLI and ANLI, and WANLI and GNLI (synthetic) test sets.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.3" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1 Performance on unseen factual consistency benchmarks ‣ 4 Experiments ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the results. We observe that in most cases (model sizes and evaluation sets), at least around <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">300</annotation></semantics></math>K examples is needed to get a decent performance. We also explicitly tested GNLI with <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="392" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mn id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">392</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><cn type="integer" id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">392</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">392</annotation></semantics></math>K which is the same size as MNLI. In all cases, GNLI <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="392" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mn id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">392</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><cn type="integer" id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">392</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">392</annotation></semantics></math>K has a very similar accuracy to the full dataset. We also observed similar trends for the TRUE benchmark.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">A decade of increasingly useful NLI benchmarks and datasets have been instrumental in improving LLMs for various tasks. We have presented a new exploration of how the data distribution of each data source still impacts downstream performance on new examples. We proposed a synthetic data approach to mitigate these effects with examples balanced for domain, length and labels. We show that, by drawing on an LLM’s parametric knowledge of a broad range of domains, such synthetic data enables us to both train significantly more domain-general NLI models, and to improve intrinsic NLI model performance on in-domain test data by augmenting in-domain training data.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We do not release the synthetic <em id="S6.p1.1.1" class="ltx_emph ltx_font_italic">general</em> NLI data with our paper. However, our method for generating them can be replicated with access to an LLM, either to directly reproduce our results or to apply our approach to other domains, text lengths, and/or training set sizes of interest. Our process for generation requires multiple LLM tasks which uses more compute than a single stage one. But we note that the data is of high linguistic quality with this method. At the same time, the generated premises could potentially contain fictional information, and should not be used for training models that learn facts from data. We have applied our approach to generalize only one dataset (MNLI) which is in English. While we obtain positive results, the results on other datasets, and for other languages remain an empirical question.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adila and Kang (2022)</span>
<span class="ltx_bibblock">
Dyah Adila and Dongyeop Kang. 2022.

</span>
<span class="ltx_bibblock">Understanding out-of-distribution: A perspective of data dynamics.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">I (Still) Can’t Believe It’s Not Better! Workshop at NeurIPS
2021</em>, pages 1–8. PMLR.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al. (2023)</span>
<span class="ltx_bibblock">
Priyanka Agrawal, Chris Alberti, Fantine Huot, Joshua Maynez, Ji Ma, Sebastian
Ruder, Kuzman Ganchev, Dipanjan Das, and Mirella Lapata. 2023.

</span>
<span class="ltx_bibblock">Qameleon: Multilingual qa with only 5 examples.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
11:1754.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belinkov et al. (2019)</span>
<span class="ltx_bibblock">
Yonatan Belinkov, Adam Poliak, Stuart M. Shieber, Benjamin Van Durme, and
Alexander M. Rush. 2019.

</span>
<span class="ltx_bibblock">Don’t take the premise for granted: Mitigating artifacts in natural
language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Conference of the Association for
Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2,
2019, Volume 1: Long Papers</em>, pages 877–891.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et al. (2015a)</span>
<span class="ltx_bibblock">
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.
2015a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D15-1075" title="" class="ltx_ref ltx_href">A large annotated
corpus for learning natural language inference</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 632–642, Lisbon, Portugal. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et al. (2015b)</span>
<span class="ltx_bibblock">
Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning.
2015b.

</span>
<span class="ltx_bibblock">A large annotated corpus for learning natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing, EMNLP 2015</em>, pages 632–642. Association for Computational
Linguistics (ACL).

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al. (2023)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian
Gehrmann, et al. 2023.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 24(240):1–113.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2022)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, pages arXiv–2210.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dziri et al. (2022)</span>
<span class="ltx_bibblock">
Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter. 2022.

</span>
<span class="ltx_bibblock">Evaluating attribution in dialogue systems: The begin benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
10:1066–1083.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabbri et al. (2021)</span>
<span class="ltx_bibblock">
Alexander R Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong,
Richard Socher, and Dragomir Radev. 2021.

</span>
<span class="ltx_bibblock">Summeval: Re-evaluating summarization evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
9:391–409.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gekhman et al. (2023)</span>
<span class="ltx_bibblock">
Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, and Idan Szpektor.
2023.

</span>
<span class="ltx_bibblock">Trueteacher: Learning factual consistency evaluation with large
language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11171</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google and et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil Google and, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry
Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey,
Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang,
Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin
Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang,
Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha,
James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng,
Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément
Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz,
Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus
Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari,
Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui,
Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao
Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine
Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek
Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma
Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John
Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek,
Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker
Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee
Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon
Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang,
Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan
Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,
Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.10403" title="" class="ltx_ref ltx_href">Palm 2 technical report</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2022)</span>
<span class="ltx_bibblock">
Prakhar Gupta, Chien-Sheng Wu, Wenhao Liu, and Caiming Xiong. 2022.

</span>
<span class="ltx_bibblock">Dialfact: A benchmark for fact-checking in dialogue.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3785–3801.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et al. (2018)</span>
<span class="ltx_bibblock">
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
and Noah A. Smith. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N18-2017" title="" class="ltx_ref ltx_href">Annotation artifacts in
natural language inference data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pages 107–112, New Orleans,
Louisiana. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2022)</span>
<span class="ltx_bibblock">
Xuanli He, Islam Nassar, Jamie Kiros, Gholamreza Haffari, and Mohammad Norouzi.
2022.

</span>
<span class="ltx_bibblock">Generate, Annotate, and Learn: NLP with Synthetic Text.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
10:826–842.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et al. (2022)</span>
<span class="ltx_bibblock">
Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy,
Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi
Matias. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.naacl-main.287" title="" class="ltx_ref ltx_href">TRUE:
Re-evaluating factual consistency evaluation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 3905–3920, Seattle, United States. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et al. (2021)</span>
<span class="ltx_bibblock">
Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, and Omri
Abend. 2021.

</span>
<span class="ltx_bibblock">Q2:: Evaluating factual consistency in knowledge-grounded dialogues
via question generation and question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 7856–7870.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lester et al. (2021)</span>
<span class="ltx_bibblock">
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.243" title="" class="ltx_ref ltx_href">The power of
scale for parameter-efficient prompt tuning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 3045–3059, Online and Punta Cana,
Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming Yin. 2023.

</span>
<span class="ltx_bibblock">Synthetic data generation with large language models for text
classification: Potential and limitations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in
Natural Language Processing</em>, pages 10443–10461.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah A Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Wanli: Worker and ai collaboration for natural language inference
dataset creation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2022</em>, pages 6826–6847.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maynez et al. (2020)</span>
<span class="ltx_bibblock">
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020.

</span>
<span class="ltx_bibblock">On faithfulness and factuality in abstractive summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 1906–1919.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muandet et al. (2013)</span>
<span class="ltx_bibblock">
Krikamol Muandet, David Balduzzi, and Bernhard Schölkopf. 2013.

</span>
<span class="ltx_bibblock">Domain generalization via invariant feature representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th International Conference on Machine
Learning</em>, volume 28 of <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>,
pages 10–18. PMLR.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nangia and Bowman (2019)</span>
<span class="ltx_bibblock">
Nikita Nangia and Samuel Bowman. 2019.

</span>
<span class="ltx_bibblock">Human vs. muppet: A conservative estimate of human performance on the
glue benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4566–4575.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nie et al. (2019)</span>
<span class="ltx_bibblock">
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe
Kiela. 2019.

</span>
<span class="ltx_bibblock">Adversarial nli: A new benchmark for natural language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.14599</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pagnoni et al. (2021)</span>
<span class="ltx_bibblock">
Artidoro Pagnoni, Vidhisha Balachandran, and Yulia Tsvetkov. 2021.

</span>
<span class="ltx_bibblock">Understanding factuality in abstractive summarization with frank: A
benchmark for factuality metrics.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 4812–4829.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puri et al. (2020)</span>
<span class="ltx_bibblock">
Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, and Bryan Catanzaro.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.468" title="" class="ltx_ref ltx_href">Training
question answering models from synthetic data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 5811–5826, Online. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, 21(1):5485–5551.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rahman et al. (2019)</span>
<span class="ltx_bibblock">
Mohammad Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, and Sridha
Sridharan. 2019.

</span>
<span class="ltx_bibblock">Multi-component image translation for deep domain generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Winter Conference on Applications of Computer
Vision (WACV)</em>, pages 579–588.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rashkin et al. (2023)</span>
<span class="ltx_bibblock">
Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Lora Aroyo, Michael Collins,
Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, and David Reitter.
2023.

</span>
<span class="ltx_bibblock">Measuring Attribution in Natural Language Generation Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>, 49(4):777–840.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuster et al. (2021)</span>
<span class="ltx_bibblock">
Tal Schuster, Adam Fisch, and Regina Barzilay. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.52" title="" class="ltx_ref ltx_href">Get your
vitamin C! robust fact verification with contrastive evidence</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</em>, pages 624–643, Online. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thorne et al. (2018)</span>
<span class="ltx_bibblock">
James Thorne, Andreas Vlachos, Oana Cocarascu, Christos Christodoulopoulos, and
Arpit Mittal. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W18-5501" title="" class="ltx_ref ltx_href">The fact extraction and
VERification (FEVER) shared task</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Fact Extraction and
VERification (FEVER)</em>, pages 1–9, Brussels, Belgium. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tobin et al. (2017)</span>
<span class="ltx_bibblock">
Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and
Pieter Abbeel. 2017.

</span>
<span class="ltx_bibblock">Domain randomization for transferring deep neural networks from
simulation to the real world.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">2017 IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS)</em>, pages 23–30.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu et al. (2021)</span>
<span class="ltx_bibblock">
Tu Vu, Minh-Thang Luong, Quoc Le, Grady Simon, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.462" title="" class="ltx_ref ltx_href">STraTA:
Self-training with task augmentation for better few-shot learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 5715–5731, Online and Punta Cana,
Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
Alex Wang, Kyunghyun Cho, and Mike Lewis. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.450" title="" class="ltx_ref ltx_href">Asking and
answering questions to evaluate the factual consistency of summaries</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 5008–5020, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, and Tao Qin. 2021.

</span>
<span class="ltx_bibblock">Generalizing to unseen domains: A survey on domain generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirtieth International Joint Conference
on Artificial Intelligence, IJCAI-21</em>, pages 4627–4635. International
Joint Conferences on Artificial Intelligence Organization.

</span>
<span class="ltx_bibblock">Survey Track.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et al. (2018)</span>
<span class="ltx_bibblock">
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.

</span>
<span class="ltx_bibblock">A broad-coverage challenge corpus for sentence understanding through
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1112–1122.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Yuan Zhang, Jason Baldridge, and Luheng He. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1131" title="" class="ltx_ref ltx_href">PAWS: Paraphrase
adversaries from word scrambling</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 1298–1308,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2020)</span>
<span class="ltx_bibblock">
Kaiyang Zhou, Yongxin Yang, Timothy Hospedales, and Tao Xiang. 2020.

</span>
<span class="ltx_bibblock">Learning to generate novel domains for domain generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Computer Vision – ECCV 2020</em>, pages 561–578, Cham.
Springer International Publishing.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Seed Examples for Prompting</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">We provide the seed examples for prompting FLAN-PaLM2 L (Unicorn) to generate premises in Table <a href="#A1.T7" title="Table 7 ‣ Appendix A Seed Examples for Prompting ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="A1.T7" class="ltx_table">
<table id="A1.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T7.1.2" class="ltx_tr">
<td id="A1.T7.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.2.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="A1.T7.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Domain</span></span>
</span>
</td>
<td id="A1.T7.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.2.2.1.1" class="ltx_p" style="width:43.4pt;"><span id="A1.T7.1.2.2.1.1.1" class="ltx_text ltx_font_bold">Length</span></span>
</span>
</td>
<td id="A1.T7.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.2.3.1.1" class="ltx_p" style="width:333.9pt;"><span id="A1.T7.1.2.3.1.1.1" class="ltx_text ltx_font_bold">Text</span></span>
</span>
</td>
</tr>
<tr id="A1.T7.1.3" class="ltx_tr">
<td id="A1.T7.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.3.1.1.1" class="ltx_p" style="width:43.4pt;">news headlines</span>
</span>
</td>
<td id="A1.T7.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.3.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.3.3.1.1" class="ltx_p" style="width:333.9pt;">Congress approves debt deal, averting a US default</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.4" class="ltx_tr">
<td id="A1.T7.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.4.1.1.1" class="ltx_p" style="width:43.4pt;">news headlines</span>
</span>
</td>
<td id="A1.T7.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.4.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.4.3.1.1" class="ltx_p" style="width:333.9pt;">Man airlifted to hospital from Skye beauty spot</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.5" class="ltx_tr">
<td id="A1.T7.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.5.1.1.1" class="ltx_p" style="width:43.4pt;">news</span>
</span>
</td>
<td id="A1.T7.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.5.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.5.3.1.1" class="ltx_p" style="width:333.9pt;">Expectations were set high by the WSC concerning what the event would do for upcoming Indian entrepreneurs.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.6" class="ltx_tr">
<td id="A1.T7.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.6.1.1.1" class="ltx_p" style="width:43.4pt;">news</span>
</span>
</td>
<td id="A1.T7.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.6.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.6.3.1.1" class="ltx_p" style="width:333.9pt;">But despite high promises, it didn’t take long for the first day of the convention to be plunged into chaos.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.7" class="ltx_tr">
<td id="A1.T7.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.7.1.1.1" class="ltx_p" style="width:43.4pt;">shopping reviews</span>
</span>
</td>
<td id="A1.T7.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.7.2.1.1" class="ltx_p" style="width:43.4pt;">paragraph</span>
</span>
</td>
<td id="A1.T7.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.7.3.1.1" class="ltx_p" style="width:333.9pt;">Good value for the seventy eight dollars that I paid for it. easy to change the filter. Quite on high. Haven’t had it long enough to say how well it filters the air but I can see lint and dust on the filter pre screen. And I’ve only had it nine days I think. Love that I can turn the lights off.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.8" class="ltx_tr">
<td id="A1.T7.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.8.1.1.1" class="ltx_p" style="width:43.4pt;">shopping reviews</span>
</span>
</td>
<td id="A1.T7.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.8.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.8.3.1.1" class="ltx_p" style="width:333.9pt;">my first impressions are that’s the Google Pixel 7 is a nice phone, BUT not as good as the moto g power in terms of ease of use and functionality.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.9" class="ltx_tr">
<td id="A1.T7.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.9.1.1.1" class="ltx_p" style="width:43.4pt;">shopping reviews</span>
</span>
</td>
<td id="A1.T7.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.9.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.9.3.1.1" class="ltx_p" style="width:333.9pt;">Battery has yet to be determined on the Pixel, but from a full charge, I’m down to 56% after 2 hours of use.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.10" class="ltx_tr">
<td id="A1.T7.1.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.10.1.1.1" class="ltx_p" style="width:43.4pt;">wikipedia</span>
</span>
</td>
<td id="A1.T7.1.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.10.2.1.1" class="ltx_p" style="width:43.4pt;">paragraph</span>
</span>
</td>
<td id="A1.T7.1.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.10.3.1.1" class="ltx_p" style="width:333.9pt;">Alfred was baptised by Frederick Cornwallis, Archbishop of Canterbury, in the Great Council Chamber at St James’s Palace on 21 October 1780. His godparents were his elder siblings George, Prince of Wales; Prince Frederick; and Charlotte, Princess Royal. Alfred was a delicate child.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.11" class="ltx_tr">
<td id="A1.T7.1.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.11.1.1.1" class="ltx_p" style="width:43.4pt;">wikipedia</span>
</span>
</td>
<td id="A1.T7.1.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.11.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.11.3.1.1" class="ltx_p" style="width:333.9pt;">The premise of Two Hundred Rabbits was based on a dream that author Lonzo Anderson had after reading a French folk tale.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.12" class="ltx_tr">
<td id="A1.T7.1.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.12.1.1.1" class="ltx_p" style="width:43.4pt;">movie reviews</span>
</span>
</td>
<td id="A1.T7.1.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.12.2.1.1" class="ltx_p" style="width:43.4pt;">paragraph</span>
</span>
</td>
<td id="A1.T7.1.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.12.3.1.1" class="ltx_p" style="width:333.9pt;">As usual, James Cameron shows us his creative genius. The story is very different from the first, and I don’t want to give out any story until you’ve seen it. It is worth watching, and if you own the first it is also worth buying. My only complaint, and it is BIG, is it turns out to only be in 480p resolution…not even 1080p or 4K. It looks good if you play it in YouTube, but still. It should be in 4K.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.13" class="ltx_tr">
<td id="A1.T7.1.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.13.1.1.1" class="ltx_p" style="width:43.4pt;">movie reviews</span>
</span>
</td>
<td id="A1.T7.1.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.13.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.13.3.1.1" class="ltx_p" style="width:333.9pt;">The actor portraying Mr. Darcy had no concept of the kind of man Darcy is or his nature.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.14" class="ltx_tr">
<td id="A1.T7.1.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.14.1.1.1" class="ltx_p" style="width:43.4pt;">place reviews</span>
</span>
</td>
<td id="A1.T7.1.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.14.2.1.1" class="ltx_p" style="width:43.4pt;">paragraph</span>
</span>
</td>
<td id="A1.T7.1.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.14.3.1.1" class="ltx_p" style="width:333.9pt;">Beautiful space which is nicely a bit secluded from the hussle at coal drop but still easy to reach. Wines were excellent, cheeses delicious, food great, and cocktails outstanding. Folks were kind and professional. Crowd was elegant but relaxed. 
<br class="ltx_break">
<br class="ltx_break">Amazed they just opened three days ago, they operate like they have been at it forever. Loved every minute!</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.15" class="ltx_tr">
<td id="A1.T7.1.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.15.1.1.1" class="ltx_p" style="width:43.4pt;">place reviews</span>
</span>
</td>
<td id="A1.T7.1.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.15.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.15.3.1.1" class="ltx_p" style="width:333.9pt;">The steep stairs need to be negotiated with caution especially after indulging in bout of revelry.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.16" class="ltx_tr">
<td id="A1.T7.1.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.16.1.1.1" class="ltx_p" style="width:43.4pt;">place reviews</span>
</span>
</td>
<td id="A1.T7.1.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.16.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.16.3.1.1" class="ltx_p" style="width:333.9pt;">I waited an hour. The doctor was terribly stressed. She didn’t answer questions.</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.1" class="ltx_tr">
<td id="A1.T7.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.1.2.1.1" class="ltx_p" style="width:43.4pt;">twitter</span>
</span>
</td>
<td id="A1.T7.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.1.3.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.1.1.1.1" class="ltx_p" style="width:333.9pt;">Sevilla is <span id="A1.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Red and White</span> <math id="A1.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\heartsuit" display="inline"><semantics id="A1.T7.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T7.1.1.1.1.1.m1.1.1" xref="A1.T7.1.1.1.1.1.m1.1.1.cmml">♡</mi><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.1.1.m1.1b"><ci id="A1.T7.1.1.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.1.1.m1.1.1">♡</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.1.1.m1.1c">\heartsuit</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A1.T7.1.17" class="ltx_tr">
<td id="A1.T7.1.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.17.1.1.1" class="ltx_p" style="width:43.4pt;">twitter</span>
</span>
</td>
<td id="A1.T7.1.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.17.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.17.3.1.1" class="ltx_p" style="width:333.9pt;">Lil X just asked if there are police cats, since there are police dogs :))</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.18" class="ltx_tr">
<td id="A1.T7.1.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.18.1.1.1" class="ltx_p" style="width:43.4pt;">reddit post</span>
</span>
</td>
<td id="A1.T7.1.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.18.2.1.1" class="ltx_p" style="width:43.4pt;">paragraph</span>
</span>
</td>
<td id="A1.T7.1.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.18.3.1.1" class="ltx_p" style="width:333.9pt;">Hey there everyone! I often see people asking where to start when getting into prog metal, so I thought instead of answering every one of them individually I’d make a list. I’m not going into too much depth because otherwise this will become endless, but I’ll try to give a brief explanation of all styles I’m going over. So let’s get started!</span>
</span>
</td>
</tr>
<tr id="A1.T7.1.19" class="ltx_tr">
<td id="A1.T7.1.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.19.1.1.1" class="ltx_p" style="width:43.4pt;">reddit post</span>
</span>
</td>
<td id="A1.T7.1.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.19.2.1.1" class="ltx_p" style="width:43.4pt;">short</span>
</span>
</td>
<td id="A1.T7.1.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A1.T7.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T7.1.19.3.1.1" class="ltx_p" style="width:333.9pt;">I am someone who hates doing laundry.</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Seed Examples for Prompting.</figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Hyper-parameter details</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.6" class="ltx_p">For prompt-tuning of the <em id="A2.p1.6.1" class="ltx_emph ltx_font_italic">Anonymous</em> LLM, we used an input length and output length of <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A2.p1.1.m1.1a"><mn id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><cn type="integer" id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">512</annotation></semantics></math>. We tuned <math id="A2.p1.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="A2.p1.2.m2.1a"><mn id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><cn type="integer" id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">100</annotation></semantics></math> prompt embeddings and used them during inference. We used a learning rate of <math id="A2.p1.3.m3.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="A2.p1.3.m3.1a"><mn id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.1b"><cn type="float" id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.1c">0.3</annotation></semantics></math> and did not use dropout. We trained with a batch size of <math id="A2.p1.4.m4.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A2.p1.4.m4.1a"><mn id="A2.p1.4.m4.1.1" xref="A2.p1.4.m4.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A2.p1.4.m4.1b"><cn type="integer" id="A2.p1.4.m4.1.1.cmml" xref="A2.p1.4.m4.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.4.m4.1c">16</annotation></semantics></math> for <math id="A2.p1.5.m5.2" class="ltx_Math" alttext="24,544" display="inline"><semantics id="A2.p1.5.m5.2a"><mrow id="A2.p1.5.m5.2.3.2" xref="A2.p1.5.m5.2.3.1.cmml"><mn id="A2.p1.5.m5.1.1" xref="A2.p1.5.m5.1.1.cmml">24</mn><mo id="A2.p1.5.m5.2.3.2.1" xref="A2.p1.5.m5.2.3.1.cmml">,</mo><mn id="A2.p1.5.m5.2.2" xref="A2.p1.5.m5.2.2.cmml">544</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.5.m5.2b"><list id="A2.p1.5.m5.2.3.1.cmml" xref="A2.p1.5.m5.2.3.2"><cn type="integer" id="A2.p1.5.m5.1.1.cmml" xref="A2.p1.5.m5.1.1">24</cn><cn type="integer" id="A2.p1.5.m5.2.2.cmml" xref="A2.p1.5.m5.2.2">544</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.5.m5.2c">24,544</annotation></semantics></math> steps that is equivalent to one epoch on the MNLI dataset with <math id="A2.p1.6.m6.2" class="ltx_Math" alttext="392,702" display="inline"><semantics id="A2.p1.6.m6.2a"><mrow id="A2.p1.6.m6.2.3.2" xref="A2.p1.6.m6.2.3.1.cmml"><mn id="A2.p1.6.m6.1.1" xref="A2.p1.6.m6.1.1.cmml">392</mn><mo id="A2.p1.6.m6.2.3.2.1" xref="A2.p1.6.m6.2.3.1.cmml">,</mo><mn id="A2.p1.6.m6.2.2" xref="A2.p1.6.m6.2.2.cmml">702</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.6.m6.2b"><list id="A2.p1.6.m6.2.3.1.cmml" xref="A2.p1.6.m6.2.3.2"><cn type="integer" id="A2.p1.6.m6.1.1.cmml" xref="A2.p1.6.m6.1.1">392</cn><cn type="integer" id="A2.p1.6.m6.2.2.cmml" xref="A2.p1.6.m6.2.2">702</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.6.m6.2c">392,702</annotation></semantics></math> training examples.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.8" class="ltx_p">For training T5 models (both binary and 3-way), we tuned learning rates <math id="A2.p2.1.m1.3" class="ltx_Math" alttext="\in\{5e-4,1e-4,5e-5\}" display="inline"><semantics id="A2.p2.1.m1.3a"><mrow id="A2.p2.1.m1.3.3" xref="A2.p2.1.m1.3.3.cmml"><mi id="A2.p2.1.m1.3.3.5" xref="A2.p2.1.m1.3.3.5.cmml"></mi><mo id="A2.p2.1.m1.3.3.4" xref="A2.p2.1.m1.3.3.4.cmml">∈</mo><mrow id="A2.p2.1.m1.3.3.3.3" xref="A2.p2.1.m1.3.3.3.4.cmml"><mo stretchy="false" id="A2.p2.1.m1.3.3.3.3.4" xref="A2.p2.1.m1.3.3.3.4.cmml">{</mo><mrow id="A2.p2.1.m1.1.1.1.1.1" xref="A2.p2.1.m1.1.1.1.1.1.cmml"><mrow id="A2.p2.1.m1.1.1.1.1.1.2" xref="A2.p2.1.m1.1.1.1.1.1.2.cmml"><mn id="A2.p2.1.m1.1.1.1.1.1.2.2" xref="A2.p2.1.m1.1.1.1.1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A2.p2.1.m1.1.1.1.1.1.2.1" xref="A2.p2.1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="A2.p2.1.m1.1.1.1.1.1.2.3" xref="A2.p2.1.m1.1.1.1.1.1.2.3.cmml">e</mi></mrow><mo id="A2.p2.1.m1.1.1.1.1.1.1" xref="A2.p2.1.m1.1.1.1.1.1.1.cmml">−</mo><mn id="A2.p2.1.m1.1.1.1.1.1.3" xref="A2.p2.1.m1.1.1.1.1.1.3.cmml">4</mn></mrow><mo id="A2.p2.1.m1.3.3.3.3.5" xref="A2.p2.1.m1.3.3.3.4.cmml">,</mo><mrow id="A2.p2.1.m1.2.2.2.2.2" xref="A2.p2.1.m1.2.2.2.2.2.cmml"><mrow id="A2.p2.1.m1.2.2.2.2.2.2" xref="A2.p2.1.m1.2.2.2.2.2.2.cmml"><mn id="A2.p2.1.m1.2.2.2.2.2.2.2" xref="A2.p2.1.m1.2.2.2.2.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A2.p2.1.m1.2.2.2.2.2.2.1" xref="A2.p2.1.m1.2.2.2.2.2.2.1.cmml">​</mo><mi id="A2.p2.1.m1.2.2.2.2.2.2.3" xref="A2.p2.1.m1.2.2.2.2.2.2.3.cmml">e</mi></mrow><mo id="A2.p2.1.m1.2.2.2.2.2.1" xref="A2.p2.1.m1.2.2.2.2.2.1.cmml">−</mo><mn id="A2.p2.1.m1.2.2.2.2.2.3" xref="A2.p2.1.m1.2.2.2.2.2.3.cmml">4</mn></mrow><mo id="A2.p2.1.m1.3.3.3.3.6" xref="A2.p2.1.m1.3.3.3.4.cmml">,</mo><mrow id="A2.p2.1.m1.3.3.3.3.3" xref="A2.p2.1.m1.3.3.3.3.3.cmml"><mrow id="A2.p2.1.m1.3.3.3.3.3.2" xref="A2.p2.1.m1.3.3.3.3.3.2.cmml"><mn id="A2.p2.1.m1.3.3.3.3.3.2.2" xref="A2.p2.1.m1.3.3.3.3.3.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A2.p2.1.m1.3.3.3.3.3.2.1" xref="A2.p2.1.m1.3.3.3.3.3.2.1.cmml">​</mo><mi id="A2.p2.1.m1.3.3.3.3.3.2.3" xref="A2.p2.1.m1.3.3.3.3.3.2.3.cmml">e</mi></mrow><mo id="A2.p2.1.m1.3.3.3.3.3.1" xref="A2.p2.1.m1.3.3.3.3.3.1.cmml">−</mo><mn id="A2.p2.1.m1.3.3.3.3.3.3" xref="A2.p2.1.m1.3.3.3.3.3.3.cmml">5</mn></mrow><mo stretchy="false" id="A2.p2.1.m1.3.3.3.3.7" xref="A2.p2.1.m1.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.3b"><apply id="A2.p2.1.m1.3.3.cmml" xref="A2.p2.1.m1.3.3"><in id="A2.p2.1.m1.3.3.4.cmml" xref="A2.p2.1.m1.3.3.4"></in><csymbol cd="latexml" id="A2.p2.1.m1.3.3.5.cmml" xref="A2.p2.1.m1.3.3.5">absent</csymbol><set id="A2.p2.1.m1.3.3.3.4.cmml" xref="A2.p2.1.m1.3.3.3.3"><apply id="A2.p2.1.m1.1.1.1.1.1.cmml" xref="A2.p2.1.m1.1.1.1.1.1"><minus id="A2.p2.1.m1.1.1.1.1.1.1.cmml" xref="A2.p2.1.m1.1.1.1.1.1.1"></minus><apply id="A2.p2.1.m1.1.1.1.1.1.2.cmml" xref="A2.p2.1.m1.1.1.1.1.1.2"><times id="A2.p2.1.m1.1.1.1.1.1.2.1.cmml" xref="A2.p2.1.m1.1.1.1.1.1.2.1"></times><cn type="integer" id="A2.p2.1.m1.1.1.1.1.1.2.2.cmml" xref="A2.p2.1.m1.1.1.1.1.1.2.2">5</cn><ci id="A2.p2.1.m1.1.1.1.1.1.2.3.cmml" xref="A2.p2.1.m1.1.1.1.1.1.2.3">𝑒</ci></apply><cn type="integer" id="A2.p2.1.m1.1.1.1.1.1.3.cmml" xref="A2.p2.1.m1.1.1.1.1.1.3">4</cn></apply><apply id="A2.p2.1.m1.2.2.2.2.2.cmml" xref="A2.p2.1.m1.2.2.2.2.2"><minus id="A2.p2.1.m1.2.2.2.2.2.1.cmml" xref="A2.p2.1.m1.2.2.2.2.2.1"></minus><apply id="A2.p2.1.m1.2.2.2.2.2.2.cmml" xref="A2.p2.1.m1.2.2.2.2.2.2"><times id="A2.p2.1.m1.2.2.2.2.2.2.1.cmml" xref="A2.p2.1.m1.2.2.2.2.2.2.1"></times><cn type="integer" id="A2.p2.1.m1.2.2.2.2.2.2.2.cmml" xref="A2.p2.1.m1.2.2.2.2.2.2.2">1</cn><ci id="A2.p2.1.m1.2.2.2.2.2.2.3.cmml" xref="A2.p2.1.m1.2.2.2.2.2.2.3">𝑒</ci></apply><cn type="integer" id="A2.p2.1.m1.2.2.2.2.2.3.cmml" xref="A2.p2.1.m1.2.2.2.2.2.3">4</cn></apply><apply id="A2.p2.1.m1.3.3.3.3.3.cmml" xref="A2.p2.1.m1.3.3.3.3.3"><minus id="A2.p2.1.m1.3.3.3.3.3.1.cmml" xref="A2.p2.1.m1.3.3.3.3.3.1"></minus><apply id="A2.p2.1.m1.3.3.3.3.3.2.cmml" xref="A2.p2.1.m1.3.3.3.3.3.2"><times id="A2.p2.1.m1.3.3.3.3.3.2.1.cmml" xref="A2.p2.1.m1.3.3.3.3.3.2.1"></times><cn type="integer" id="A2.p2.1.m1.3.3.3.3.3.2.2.cmml" xref="A2.p2.1.m1.3.3.3.3.3.2.2">5</cn><ci id="A2.p2.1.m1.3.3.3.3.3.2.3.cmml" xref="A2.p2.1.m1.3.3.3.3.3.2.3">𝑒</ci></apply><cn type="integer" id="A2.p2.1.m1.3.3.3.3.3.3.cmml" xref="A2.p2.1.m1.3.3.3.3.3.3">5</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.3c">\in\{5e-4,1e-4,5e-5\}</annotation></semantics></math> and fine-tuned with batch size of <math id="A2.p2.2.m2.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A2.p2.2.m2.1a"><mn id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><cn type="integer" id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">32</annotation></semantics></math> for <math id="A2.p2.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="A2.p2.3.m3.1a"><mn id="A2.p2.3.m3.1.1" xref="A2.p2.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A2.p2.3.m3.1b"><cn type="integer" id="A2.p2.3.m3.1.1.cmml" xref="A2.p2.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.3.m3.1c">50</annotation></semantics></math>K steps. We checkpoint every <math id="A2.p2.4.m4.1" class="ltx_Math" alttext="1K" display="inline"><semantics id="A2.p2.4.m4.1a"><mrow id="A2.p2.4.m4.1.1" xref="A2.p2.4.m4.1.1.cmml"><mn id="A2.p2.4.m4.1.1.2" xref="A2.p2.4.m4.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A2.p2.4.m4.1.1.1" xref="A2.p2.4.m4.1.1.1.cmml">​</mo><mi id="A2.p2.4.m4.1.1.3" xref="A2.p2.4.m4.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.4.m4.1b"><apply id="A2.p2.4.m4.1.1.cmml" xref="A2.p2.4.m4.1.1"><times id="A2.p2.4.m4.1.1.1.cmml" xref="A2.p2.4.m4.1.1.1"></times><cn type="integer" id="A2.p2.4.m4.1.1.2.cmml" xref="A2.p2.4.m4.1.1.2">1</cn><ci id="A2.p2.4.m4.1.1.3.cmml" xref="A2.p2.4.m4.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.4.m4.1c">1K</annotation></semantics></math> steps for early stopping. We use a dropout rate of <math id="A2.p2.5.m5.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A2.p2.5.m5.1a"><mn id="A2.p2.5.m5.1.1" xref="A2.p2.5.m5.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A2.p2.5.m5.1b"><cn type="float" id="A2.p2.5.m5.1.1.cmml" xref="A2.p2.5.m5.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.5.m5.1c">0.1</annotation></semantics></math>. We trained with an input length of <math id="A2.p2.6.m6.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A2.p2.6.m6.1a"><mn id="A2.p2.6.m6.1.1" xref="A2.p2.6.m6.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A2.p2.6.m6.1b"><cn type="integer" id="A2.p2.6.m6.1.1.cmml" xref="A2.p2.6.m6.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.6.m6.1c">512</annotation></semantics></math>. During inference for factual consistency evaluation (Section <a href="#S4.SS1" title="4.1 Performance on unseen factual consistency benchmarks ‣ 4 Experiments ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and NLI benchmarks (Section <a href="#S4.SS2" title="4.2 Cross-dataset performance on NLI benchmarks ‣ 4 Experiments ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>), we used an input length of <math id="A2.p2.7.m7.1" class="ltx_Math" alttext="1024" display="inline"><semantics id="A2.p2.7.m7.1a"><mn id="A2.p2.7.m7.1.1" xref="A2.p2.7.m7.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="A2.p2.7.m7.1b"><cn type="integer" id="A2.p2.7.m7.1.1.cmml" xref="A2.p2.7.m7.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.7.m7.1c">1024</annotation></semantics></math> and <math id="A2.p2.8.m8.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A2.p2.8.m8.1a"><mn id="A2.p2.8.m8.1.1" xref="A2.p2.8.m8.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A2.p2.8.m8.1b"><cn type="integer" id="A2.p2.8.m8.1.1.cmml" xref="A2.p2.8.m8.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.8.m8.1c">512</annotation></semantics></math> respectively.</p>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">We report the best selected hyper-parameters for T5 binary and 3-way models in Table <a href="#A2.T8" title="Table 8 ‣ Appendix B Hyper-parameter details ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> and Table <a href="#A2.T9" title="Table 9 ‣ Appendix B Hyper-parameter details ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A2.T8" class="ltx_table">
<table id="A2.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T8.1.1" class="ltx_tr">
<td id="A2.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.1.1.1" class="ltx_text ltx_font_bold">Dataset/Model</span></td>
<td id="A2.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.1.2.1" class="ltx_text ltx_font_bold">T5 small</span></td>
<td id="A2.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.1.3.1" class="ltx_text ltx_font_bold">T5 large</span></td>
<td id="A2.T8.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.1.4.1" class="ltx_text ltx_font_bold">T5 XXL</span></td>
</tr>
<tr id="A2.T8.1.2" class="ltx_tr">
<td id="A2.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.2.1.1" class="ltx_text ltx_font_bold">MNLI</span></td>
<td id="A2.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=40K</td>
<td id="A2.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T8.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=15K</td>
</tr>
<tr id="A2.T8.1.3" class="ltx_tr">
<td id="A2.T8.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.3.1.1" class="ltx_text ltx_font_bold">ANLI</span></td>
<td id="A2.T8.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=5K</td>
<td id="A2.T8.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=20K</td>
<td id="A2.T8.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=40K</td>
</tr>
<tr id="A2.T8.1.4" class="ltx_tr">
<td id="A2.T8.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.4.1.1" class="ltx_text ltx_font_bold">WANLI</span></td>
<td id="A2.T8.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=15K</td>
<td id="A2.T8.1.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T8.1.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=1e-4, steps=50K</td>
</tr>
<tr id="A2.T8.1.5" class="ltx_tr">
<td id="A2.T8.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.5.1.1" class="ltx_text ltx_font_bold">GNLI</span></td>
<td id="A2.T8.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=40K</td>
<td id="A2.T8.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=20K</td>
<td id="A2.T8.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=40K</td>
</tr>
<tr id="A2.T8.1.6" class="ltx_tr">
<td id="A2.T8.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.6.1.1" class="ltx_text ltx_font_bold">MNLI + GNLI</span></td>
<td id="A2.T8.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=20K</td>
<td id="A2.T8.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=35K</td>
<td id="A2.T8.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=25K</td>
</tr>
<tr id="A2.T8.1.7" class="ltx_tr">
<td id="A2.T8.1.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.7.1.1" class="ltx_text ltx_font_bold">ANLI + GNLI</span></td>
<td id="A2.T8.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=50K</td>
<td id="A2.T8.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=20K</td>
<td id="A2.T8.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=50K</td>
</tr>
<tr id="A2.T8.1.8" class="ltx_tr">
<td id="A2.T8.1.8.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T8.1.8.1.1" class="ltx_text ltx_font_bold">WANLI + GNLI</span></td>
<td id="A2.T8.1.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=45K</td>
<td id="A2.T8.1.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=30K</td>
<td id="A2.T8.1.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=50K</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Best selected hyper-parameters for T5 binary models. We report learning rates (lr) and the number of steps.</figcaption>
</figure>
<figure id="A2.T9" class="ltx_table">
<table id="A2.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T9.1.1" class="ltx_tr">
<td id="A2.T9.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td id="A2.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.1.2.1" class="ltx_text ltx_font_bold">T5 small</span></td>
<td id="A2.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.1.3.1" class="ltx_text ltx_font_bold">T5 large</span></td>
<td id="A2.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.1.4.1" class="ltx_text ltx_font_bold">T5 XXL</span></td>
</tr>
<tr id="A2.T9.1.2" class="ltx_tr">
<td id="A2.T9.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.2.1.1" class="ltx_text ltx_font_bold">MNLI</span></td>
<td id="A2.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=40K</td>
<td id="A2.T9.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T9.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=35K</td>
</tr>
<tr id="A2.T9.1.3" class="ltx_tr">
<td id="A2.T9.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.3.1.1" class="ltx_text ltx_font_bold">ANLI</span></td>
<td id="A2.T9.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=45K</td>
<td id="A2.T9.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T9.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=15K</td>
</tr>
<tr id="A2.T9.1.4" class="ltx_tr">
<td id="A2.T9.1.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.4.1.1" class="ltx_text ltx_font_bold">WANLI</span></td>
<td id="A2.T9.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T9.1.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=10K</td>
<td id="A2.T9.1.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=15K</td>
</tr>
<tr id="A2.T9.1.5" class="ltx_tr">
<td id="A2.T9.1.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.5.1.1" class="ltx_text ltx_font_bold">GNLI</span></td>
<td id="A2.T9.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=50K</td>
<td id="A2.T9.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=15K</td>
<td id="A2.T9.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=35K</td>
</tr>
<tr id="A2.T9.1.6" class="ltx_tr">
<td id="A2.T9.1.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.6.1.1" class="ltx_text ltx_font_bold">MNLI + GNLI</span></td>
<td id="A2.T9.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=25K</td>
<td id="A2.T9.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=45K</td>
<td id="A2.T9.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=45K</td>
</tr>
<tr id="A2.T9.1.7" class="ltx_tr">
<td id="A2.T9.1.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.7.1.1" class="ltx_text ltx_font_bold">ANLI + GNLI</span></td>
<td id="A2.T9.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=05K</td>
<td id="A2.T9.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=45K</td>
<td id="A2.T9.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=45K</td>
</tr>
<tr id="A2.T9.1.8" class="ltx_tr">
<td id="A2.T9.1.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A2.T9.1.8.1.1" class="ltx_text ltx_font_bold">WANLI + GNLI</span></td>
<td id="A2.T9.1.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=50K</td>
<td id="A2.T9.1.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-4, steps=35K</td>
<td id="A2.T9.1.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">lr=5e-5, steps=35K</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Best selected hyper-parameters for T5 3-way classification models. We report learning rates (lr) and the number of steps.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Examples from Synthetic <em id="A3.1.1" class="ltx_emph ltx_font_italic">General</em> Data</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We provide 3 synthetic examples in Table <a href="#A3.T10" title="Table 10 ‣ Appendix C Additional Examples from Synthetic General Data ‣ A synthetic data approach for domain generalization of NLI models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="A3.T10" class="ltx_table">
<table id="A3.T10.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A3.T10.1.1" class="ltx_tr">
<td id="A3.T10.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="A3.T10.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Domain and Length</span></span>
</span>
</td>
<td id="A3.T10.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="A3.T10.1.1.2.1.1.1" class="ltx_text ltx_font_smallcaps">Premise</span></span>
</span>
</td>
<td id="A3.T10.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.3.1.1" class="ltx_p" style="width:86.7pt;"><span id="A3.T10.1.1.3.1.1.1" class="ltx_text ltx_font_smallcaps">Hypothesis</span></span>
</span>
</td>
<td id="A3.T10.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.4.1.1" class="ltx_p" style="width:43.4pt;"><span id="A3.T10.1.1.4.1.1.1" class="ltx_text ltx_font_smallcaps">Label</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.1.2" class="ltx_tr">
<td id="A3.T10.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.2.1.1.1" class="ltx_p" style="width:43.4pt;">phone conversation / short</span>
</span>
</td>
<td id="A3.T10.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.2.2.1.1" class="ltx_p" style="width:190.8pt;">A. What’s better for us for dinner tonight, Italian or Indian? B. Well, Italian is cheaper, but <span id="A3.T10.1.2.2.1.1.1" class="ltx_text ltx_font_bold">Indian is quicker to order</span>.</span>
</span>
</td>
<td id="A3.T10.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.2.3.1.1" class="ltx_p" style="width:86.7pt;">Ordering Indian food takes a long time but it is better.</span>
</span>
</td>
<td id="A3.T10.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.2.4.1.1" class="ltx_p" style="width:43.4pt;">contradiction</span>
</span>
</td>
</tr>
<tr id="A3.T10.1.3" class="ltx_tr">
<td id="A3.T10.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.3.1.1.1" class="ltx_p" style="width:43.4pt;">essay /short</span>
</span>
</td>
<td id="A3.T10.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.3.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="A3.T10.1.3.2.1.1.1" class="ltx_text ltx_font_bold">The first three days of the trip were fantastic.</span> I had a blast with my friends.</span>
</span>
</td>
<td id="A3.T10.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.3.3.1.1" class="ltx_p" style="width:86.7pt;">The first three days of the trip were fantastic; the rest was horrible.</span>
</span>
</td>
<td id="A3.T10.1.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.3.4.1.1" class="ltx_p" style="width:43.4pt;">neutral</span>
</span>
</td>
</tr>
<tr id="A3.T10.1.4" class="ltx_tr">
<td id="A3.T10.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.4.1.1.1" class="ltx_p" style="width:43.4pt;">place reviews / short</span>
</span>
</td>
<td id="A3.T10.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.4.2.1.1" class="ltx_p" style="width:190.8pt;"><span id="A3.T10.1.4.2.1.1.1" class="ltx_text ltx_font_bold">The food was fine</span> but there was only one couple serving that night and it was very busy.</span>
</span>
</td>
<td id="A3.T10.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.4.3.1.1" class="ltx_p" style="width:86.7pt;">The food tasted like it had been in the microwave for too long.</span>
</span>
</td>
<td id="A3.T10.1.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">
<span id="A3.T10.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.4.4.1.1" class="ltx_p" style="width:43.4pt;">contradiction</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Synthetic examples from our synthetic data. We show examples with different domains, length categories, and labels. The most relevant part of the premise is bolded manually for ease of reading.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.12367" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.12368" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.12368">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.12368" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.12369" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 19:04:51 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
