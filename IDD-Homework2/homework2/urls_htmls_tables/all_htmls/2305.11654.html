<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.11654] Contextual Client Selection for Federated Learning in Vehicular Networks</title><meta property="og:description" content="Machine learning (ML) has revolutionized transportation systems, enabling autonomous driving and smart traffic services. Federated learning (FL) overcomes privacy constraints by training ML models in distributed system‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Contextual Client Selection for Federated Learning in Vehicular Networks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Contextual Client Selection for Federated Learning in Vehicular Networks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.11654">

<!--Generated on Mon Feb 26 20:47:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">Contextual Client Selection 
<br class="ltx_break">for Federated Learning in Vehicular Networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rui Song<sup id="id11.11.id1" class="ltx_sup"><span id="id11.11.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Lingjuan Lyu<sup id="id12.12.id2" class="ltx_sup"><span id="id12.12.id2.1" class="ltx_text ltx_font_italic">3</span></sup>, Wei Jiang<sup id="id13.13.id3" class="ltx_sup"><span id="id13.13.id3.1" class="ltx_text ltx_font_italic">4</span></sup>, Andreas Festag<sup id="id14.14.id4" class="ltx_sup"><span id="id14.14.id4.1" class="ltx_text ltx_font_italic">1,5</span></sup> and Alois Knoll<sup id="id15.15.id5" class="ltx_sup"><span id="id15.15.id5.1" class="ltx_text ltx_font_italic">2</span></sup>
</span><span class="ltx_author_notes">This work was supported by the German Federal Ministry for Digital and Transport (BMVI) in the projects ‚ÄúKIVI ‚Äì KI im Verkehr Ingolstadt‚Äù and ‚Äù5GoIng ‚Äì 5G Innovation Concept Ingolstadt‚Äù.<sup id="id16.16.id1" class="ltx_sup"><span id="id16.16.id1.1" class="ltx_text ltx_font_italic">1</span></sup>Rui Song and Andreas Festag are with Fraunhofer Institute for Transportation and Infrastructure Systems IVI, Ingolstadt, Germany, e-mail:
<span id="id17.17.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{rui.song, andreas.festag}@ivi.fraunhofer.de</span>.<sup id="id18.18.id1" class="ltx_sup"><span id="id18.18.id1.1" class="ltx_text ltx_font_italic">2</span></sup>Rui Song and Alois Knoll are with Technical University of Munich, Robotics, Artificial Intelligence and Real-Time Systems, Garching, Germany, e-mail:¬†<span id="id19.19.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">rui.song@tum.de, knoll@in.tum.de</span>.<sup id="id20.20.id1" class="ltx_sup"><span id="id20.20.id1.1" class="ltx_text ltx_font_italic">3</span></sup>Lingjuan¬†Lyu is with Sony AI, Tokyo, Japan, <span id="id21.21.id2" class="ltx_text">e-mail:</span>¬†<span id="id22.22.id3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">lingjuan.lv@sony.com</span>.<sup id="id23.23.id1" class="ltx_sup"><span id="id23.23.id1.1" class="ltx_text ltx_font_italic">4</span></sup>Wei¬†Jiang is with German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany, e-mail:¬†<span id="id24.24.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">wei.jiang@dfki.de</span>.<sup id="id25.25.id1" class="ltx_sup"><span id="id25.25.id1.1" class="ltx_text ltx_font_italic">5</span></sup>Andreas Festag is with Technische Hochschule Ingolstadt, CARISSMA Institute for Electric, COnnected, and Secure Mobility (C-ECOS), Ingolstadt, Germany, e-mail:¬†<span id="id26.26.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">andreas.festag@carissma.eu</span>.</span></span>
</div>

<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">V2X-Boosted Federated Learning for Cooperative Intelligent Transportation Systems with Contextual Client Selection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rui Song<sup id="id11.11.id1" class="ltx_sup"><span id="id11.11.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Lingjuan Lyu<sup id="id12.12.id2" class="ltx_sup"><span id="id12.12.id2.1" class="ltx_text ltx_font_italic">3</span></sup>, Wei Jiang<sup id="id13.13.id3" class="ltx_sup"><span id="id13.13.id3.1" class="ltx_text ltx_font_italic">4</span></sup>, Andreas Festag<sup id="id14.14.id4" class="ltx_sup"><span id="id14.14.id4.1" class="ltx_text ltx_font_italic">1,5</span></sup> and Alois Knoll<sup id="id15.15.id5" class="ltx_sup"><span id="id15.15.id5.1" class="ltx_text ltx_font_italic">2</span></sup>
</span><span class="ltx_author_notes">This work was supported by the German Federal Ministry for Digital and Transport (BMVI) in the projects ‚ÄúKIVI ‚Äì KI im Verkehr Ingolstadt‚Äù and ‚Äù5GoIng ‚Äì 5G Innovation Concept Ingolstadt‚Äù.<sup id="id16.16.id1" class="ltx_sup"><span id="id16.16.id1.1" class="ltx_text ltx_font_italic">1</span></sup>Rui Song and Andreas Festag are with Fraunhofer Institute for Transportation and Infrastructure Systems IVI, Ingolstadt, Germany, e-mail:
<span id="id17.17.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{rui.song, andreas.festag}@ivi.fraunhofer.de</span>.<sup id="id18.18.id1" class="ltx_sup"><span id="id18.18.id1.1" class="ltx_text ltx_font_italic">2</span></sup>Rui Song and Alois Knoll are with Technical University of Munich, Robotics, Artificial Intelligence and Real-Time Systems, Garching, Germany, e-mail:¬†<span id="id19.19.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">rui.song@tum.de, knoll@in.tum.de</span>.<sup id="id20.20.id1" class="ltx_sup"><span id="id20.20.id1.1" class="ltx_text ltx_font_italic">3</span></sup>Lingjuan¬†Lyu is with Sony AI, Tokyo, Japan, <span id="id21.21.id2" class="ltx_text">e-mail:</span>¬†<span id="id22.22.id3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">lingjuan.lv@sony.com</span>.<sup id="id23.23.id1" class="ltx_sup"><span id="id23.23.id1.1" class="ltx_text ltx_font_italic">4</span></sup>Wei¬†Jiang is with German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany, e-mail:¬†<span id="id24.24.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">wei.jiang@dfki.de</span>.<sup id="id25.25.id1" class="ltx_sup"><span id="id25.25.id1.1" class="ltx_text ltx_font_italic">5</span></sup>Andreas Festag is with Technische Hochschule Ingolstadt, CARISSMA Institute for Electric, COnnected, and Secure Mobility (C-ECOS), Ingolstadt, Germany, e-mail:¬†<span id="id26.26.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">andreas.festag@carissma.eu</span>.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id27.id1" class="ltx_p">Machine learning (ML) has revolutionized transportation systems, enabling autonomous driving and smart traffic services. Federated learning (FL) overcomes privacy constraints by training ML models in distributed systems, exchanging model parameters instead of raw data. However, the dynamic states of connected vehicles affect the network connection quality and influence the FL performance. To tackle this challenge, we propose a contextual client selection pipeline that uses Vehicle-to-Everything (V2X) messages to select clients based on the predicted communication latency. The pipeline includes: (i)¬†fusing V2X messages, (ii)¬†predicting future traffic topology, (iii)¬†pre-clustering clients based on local data distribution similarity, and (iv)¬†selecting clients with minimal latency for future model aggregation. Experiments show that our pipeline outperforms baselines on various datasets, particularly in non-iid settings.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Machine learning (ML), a subfield of artificial intelligence, focuses on developing learning algorithms and inference models that enable digital systems to make decisions and predictions in terms of the knowledge learned from data. Over the past years, ML-based approaches exhibited great potential to revolutionize various scientific, engineering, economic, and cultural fields with outstanding technological advancements such as Google AlphaGo and Open AI‚Äôs ChatGPT. In the filed of road transportation, ML is possible to empower numerous new applications for realizing Intelligent Transportation System (ITS), e.g., environmental perception, road traffic flow optimization, and trajectory planning, which can significantly enhance the safety and efficiency of transportation systems¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, a new ITS concept referred to as Cooperative
Intelligent Transportation System (C-ITS) attacked a lot
of interests from both academia and industry¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In C-ITS, the cooperation between two or more ITS sub-systems
(personal, vehicle, roadside and central) offers better quality and an enhanced service level, compared to that of the conventional ITS. As illustrated in Fig.¬†<a href="#S1.F1" title="Figure 1 ‚Ä£ I Introduction ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, road participants ‚Äì- specifically, connected automated vehicles (CAVs) ‚Äì- can share information with one another through vehicle-to-everything (V2X) networks, which encompass vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), vehicle-to-network(V2N), and infrastructure-to-network (I2N).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The European standards for C-ITS define several types of V2X messages to facilitate decentralized information sharing. Specifically, for cooperative awareness and perception, dedicated message types ‚Äì the Cooperative Awareness Message (CAM) and the Collective Perception Message (CPM)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>European Telecommunications Standards Institute (ETSI) <a target="_blank" href="http://etsi.org/standards" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://etsi.org/standards</a>, specifically EN 302 637-2 for the cooperative awareness service and TS 103 324 for the collective perception service.</span></span></span> ‚Äì are periodically exchanged among CAVs and with roadside infrastructure<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. By sending and receiving V2X messages, enriched and improved environmental data of road traffic can be made available within vehicular networks.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2305.11654/assets/figures/vehicular_networks.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of vehicular networks in C-ITS, including vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), vehicle-to-network (V2N), and infrastructure-to-network (I2N) communication.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In centralized model training using ML, CAV clients transmit data to a centralized system through vehicle-to-network communications. This process can generate an enormous volume of data, potentially exceeding the network‚Äôs capacity. Moreover, data collected from CAV clients for ML model training cannot be directly shared due to privacy concerns. Differing from conventional ML, federated learning (FL) trains ML models using data from distributed systems, such as devices or clients, without centralizing the data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. In FL, connected clients share a model trained on their local data with a server, which aggregates the local models and updates the global model. The updated global model is then shared back with the clients. This process is repeated for a sufficient number of communication rounds until FL converges.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The deployment of 5G-V2X vehicular networks has further facilitated the use of FL in C-ITS by providing higher data rates and greater reliability for data exchange. This allows for the training of larger ML models for C-ITS applications and services, such as¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Although FL has great potential to preserve privacy and utilize a broader range of data resources¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, the employment of FL in C-ITS has to address major challenges due to heterogeneity in data and networks, which can not only limit the performance but also lead to FL failures.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Data heterogeneity.</span> Data across clients is non-iid (non-identically independently distributed), resulting from various sensor types, combinations, poses, road scenes, traffic scenarios, climate and weather conditions, and more.</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Network heterogeneity.</span> The diverse connection qualities of clients can slow down model sharing and cause communication delays for global model aggregation, which impedes the FL process.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">To address these challenges and enhance the application of FL in C-ITS, we propose a novel FL framework. The main idea is to select clients for upcoming communication rounds based on (<em id="S1.p8.1.1" class="ltx_emph ltx_font_italic">i</em>) the prediction of connection qualities in the context of road traffic status and (<em id="S1.p8.1.2" class="ltx_emph ltx_font_italic">ii</em>) the similarity of local data distribution in clients.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background and Related Work</span>
</h2>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2305.11654/assets/figures/client_selection_system_v2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="260" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Contextual client selection pipeline: (<span id="S2.F2.5.1" class="ltx_text ltx_font_bold">1</span>)¬†V2X message fusion; (<span id="S2.F2.6.2" class="ltx_text ltx_font_bold">2</span>)¬†Road traffic topology graph (RTTG) prediction; (<span id="S2.F2.7.3" class="ltx_text ltx_font_bold">3</span>)¬†Data-level client grouping; (<span id="S2.F2.8.4" class="ltx_text ltx_font_bold">4</span>)¬†Network-level client selection.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We discuss greedy and gossip client selection in FL, data- and network-based strategies, and FL in vehicular networks considering road traffic features.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Greedy and gossip client selection.</span>
FL, initially proposed by McMahan et al.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, suffers from the straggler effect due to varying connection qualities¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Greedy client selection includes all clients in each communication round, while gossip (stochastic greedy) selection randomly selects connected clients. Both strategies struggle to avoid the straggler effect.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Network-based client selection.</span>
Strategies focusing on network quality¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> reduce the straggler effect but aren‚Äôt specifically designed for vehicular networks with dynamic connection qualities and high-priority traffic services. Inspired by¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, we optimize client selection by predicting communication latency in vehicular networks.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Data-based client selection.</span>
Client selection based on data distribution tackles heterogeneity. The approaches in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> consider data heterogeneity but overlook network parameters. Our work addresses both data distribution and network quality in vehicular networks. A comparison of the client selection paradigms is shown in Tab.¬†<a href="#S6.T2" title="TABLE II ‚Ä£ VI Appendix ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Framework</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">contextual client selection</em> framework is illustrated in Fig.¬†<a href="#S2.F2" title="Figure 2 ‚Ä£ II Background and Related Work ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, comprising V2X information sharing, traffic topology prediction, data-level client clustering, and network-level client clustering.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">V2X message fusion.</span>
We first fuse V2X messages. Continuously receiving CAM and CPM enables dynamic road maps with traffic object states. Road-side infrastructure collects and forwards V2X messages to a server via V2I and I2N networks. The server filters and fuses messages, obtaining traffic object states, such as position, speed, and acceleration. Fused results form an road traffic topology graph (RTTG), with each CAV characterized by a node with attributes. The RTTG digitizes C-ITS and recreates vehicular networks virtually.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">RTTG prediction.</span>
We predict future RTTGs. After V2X message fusion, we initialize a prediction instance for each CAV to estimate its trajectory. Predicted trajectories build future RTTGs. Predicted RTTGs integrate with digital C-ITS, providing possible connection quality for each CAV. We simulate networks in digital twin and calculate FL communication latency based on predictive transport scenarios.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Data-level client grouping.</span>
We cluster clients into groups considering data heterogeneity. Our goal is to group clients with similar data distribution, ensuring each subset represents the whole group‚Äôs data features. We observe model updates, considering gradient similarity as a data similarity criterion¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. We group clients based on model parameter similarity. Clients must report gradient updates before a deadline for inclusion in data-level client grouping. After grouping, each subset represents its cluster. Selecting at least one client per cluster ensures satisfactory training performance.</p>
</div>
<div id="S3.p5" class="ltx_para ltx_noindent">
<p id="S3.p5.3" class="ltx_p"><span id="S3.p5.3.2" class="ltx_text ltx_font_bold">Network-level client election.</span>
We elect clients in each group based on contextual communication latency. Using predicted RTTG latency, we determine efficient client contributions for upcoming communication rounds. We employ the <em id="S3.p5.1.1" class="ltx_emph ltx_font_italic">Fast-<math id="S3.p5.1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.p5.1.1.m1.1a"><mi id="S3.p5.1.1.m1.1.1" xref="S3.p5.1.1.m1.1.1.cmml">Œ≥</mi><annotation-xml encoding="MathML-Content" id="S3.p5.1.1.m1.1b"><ci id="S3.p5.1.1.m1.1.1.cmml" xref="S3.p5.1.1.m1.1.1">ùõæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.1.m1.1c">\gamma</annotation></semantics></math></em> rule, selecting the <math id="S3.p5.2.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.p5.2.m1.1a"><mi id="S3.p5.2.m1.1.1" xref="S3.p5.2.m1.1.1.cmml">Œ≥</mi><annotation-xml encoding="MathML-Content" id="S3.p5.2.m1.1b"><ci id="S3.p5.2.m1.1.1.cmml" xref="S3.p5.2.m1.1.1">ùõæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m1.1c">\gamma</annotation></semantics></math> clients with the lowest communication delay (<math id="S3.p5.3.m2.1" class="ltx_Math" alttext="0&lt;\gamma&lt;1" display="inline"><semantics id="S3.p5.3.m2.1a"><mrow id="S3.p5.3.m2.1.1" xref="S3.p5.3.m2.1.1.cmml"><mn id="S3.p5.3.m2.1.1.2" xref="S3.p5.3.m2.1.1.2.cmml">0</mn><mo id="S3.p5.3.m2.1.1.3" xref="S3.p5.3.m2.1.1.3.cmml">&lt;</mo><mi id="S3.p5.3.m2.1.1.4" xref="S3.p5.3.m2.1.1.4.cmml">Œ≥</mi><mo id="S3.p5.3.m2.1.1.5" xref="S3.p5.3.m2.1.1.5.cmml">&lt;</mo><mn id="S3.p5.3.m2.1.1.6" xref="S3.p5.3.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.3.m2.1b"><apply id="S3.p5.3.m2.1.1.cmml" xref="S3.p5.3.m2.1.1"><and id="S3.p5.3.m2.1.1a.cmml" xref="S3.p5.3.m2.1.1"></and><apply id="S3.p5.3.m2.1.1b.cmml" xref="S3.p5.3.m2.1.1"><lt id="S3.p5.3.m2.1.1.3.cmml" xref="S3.p5.3.m2.1.1.3"></lt><cn type="integer" id="S3.p5.3.m2.1.1.2.cmml" xref="S3.p5.3.m2.1.1.2">0</cn><ci id="S3.p5.3.m2.1.1.4.cmml" xref="S3.p5.3.m2.1.1.4">ùõæ</ci></apply><apply id="S3.p5.3.m2.1.1c.cmml" xref="S3.p5.3.m2.1.1"><lt id="S3.p5.3.m2.1.1.5.cmml" xref="S3.p5.3.m2.1.1.5"></lt><share href="#S3.p5.3.m2.1.1.4.cmml" id="S3.p5.3.m2.1.1d.cmml" xref="S3.p5.3.m2.1.1"></share><cn type="integer" id="S3.p5.3.m2.1.1.6.cmml" xref="S3.p5.3.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m2.1c">0&lt;\gamma&lt;1</annotation></semantics></math>) per cluster.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Through these stages, representative clients with minimal contextual communication latency are chosen for model aggregation. This process increases FL communication efficiency by optimizing communication rounds and round duration. De-selected clients save computational resources by not training models locally.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Performance evaluation</span>
</h2>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2305.11654/assets/figures/cifar10-MNIST-res_v3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>FL training performance (testing accuracy changes over time in seconds) using various client selection strategies on non-iid MNIST (left), CIFAR-10 (middle) and SVHN (right) data distributed in 100¬†clients.</figcaption>
</figure>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Required time to reach 0.5 of test accuracy using various paradigms of client selection strategies with decreasing connection rate (CR).</figcaption>
<table id="S4.T1.10" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.10.11" class="ltx_tr">
<td id="S4.T1.10.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:14.2pt;">
<span id="S4.T1.10.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.11.1.1.1" class="ltx_p"><span id="S4.T1.10.11.1.1.1.1" class="ltx_text ltx_font_bold">CR</span></span>
</span>
</td>
<td id="S4.T1.10.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.10.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.11.2.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T1.10.11.2.1.1.1" class="ltx_text ltx_font_bold">Strategy</span></span>
</span>
</td>
<td id="S4.T1.10.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.10.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.11.3.1.1" class="ltx_p" style="width:51.2pt;"><span id="S4.T1.10.11.3.1.1.1" class="ltx_text ltx_font_bold">Time (s)</span></span>
</span>
</td>
<td id="S4.T1.10.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.10.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.11.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T1.10.11.4.1.1.1" class="ltx_text ltx_font_bold">Reduction rate</span></span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:14.2pt;">
<span id="S4.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.1.1" class="ltx_p" style="width:56.9pt;">Gossip</span>
</span>
</td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.1.1" class="ltx_p" style="width:51.2pt;">3‚Äâ891.14</span>
</span>
</td>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.1" class="ltx_p" style="width:56.9pt;">1<math id="S4.T1.1.1.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.m1.1b"><times id="S4.T1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S4.T1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.1.1" class="ltx_p">1.0</span>
</span>
</td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.3.1.1" class="ltx_p" style="width:56.9pt;">Data-based</span>
</span>
</td>
<td id="S4.T1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.4.1.1" class="ltx_p" style="width:51.2pt;">213.50</span>
</span>
</td>
<td id="S4.T1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.1.1.1" class="ltx_p" style="width:56.9pt;">18.23<math id="S4.T1.2.2.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.2.2.1.1.1.m1.1a"><mo id="S4.T1.2.2.1.1.1.m1.1.1" xref="S4.T1.2.2.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.1.1.m1.1b"><times id="S4.T1.2.2.1.1.1.m1.1.1.cmml" xref="S4.T1.2.2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;"></td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.3.1.1" class="ltx_p" style="width:56.9pt;">Network-based</span>
</span>
</td>
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.4.1.1" class="ltx_p" style="width:51.2pt;">620.47</span>
</span>
</td>
<td id="S4.T1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.1.1.1" class="ltx_p" style="width:56.9pt;">6.27<math id="S4.T1.3.3.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.3.3.1.1.1.m1.1a"><mo id="S4.T1.3.3.1.1.1.m1.1.1" xref="S4.T1.3.3.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.1.1.m1.1b"><times id="S4.T1.3.3.1.1.1.m1.1.1.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.4.4" class="ltx_tr">
<td id="S4.T1.4.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;"></td>
<td id="S4.T1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.3.1.1" class="ltx_p" style="width:56.9pt;">Contextual</span>
</span>
</td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.4.1.1" class="ltx_p" style="width:51.2pt;">l93.77</span>
</span>
</td>
<td id="S4.T1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.4.4.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">20.08<math id="S4.T1.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.4.4.1.1.1.1.m1.1a"><mo id="S4.T1.4.4.1.1.1.1.m1.1.1" xref="S4.T1.4.4.1.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.1.1.1.m1.1b"><times id="S4.T1.4.4.1.1.1.1.m1.1.1.cmml" xref="S4.T1.4.4.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.1.1.1.m1.1c">\times</annotation></semantics></math></span></span>
</span>
</td>
</tr>
<tr id="S4.T1.5.5" class="ltx_tr">
<td id="S4.T1.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S4.T1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.2.1.1" class="ltx_p">0.5</span>
</span>
</td>
<td id="S4.T1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.3.1.1" class="ltx_p" style="width:56.9pt;">Data-based</span>
</span>
</td>
<td id="S4.T1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.4.1.1" class="ltx_p" style="width:51.2pt;">2‚Äâ446.75</span>
</span>
</td>
<td id="S4.T1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.1.1.1" class="ltx_p" style="width:56.9pt;">1.59<math id="S4.T1.5.5.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.5.5.1.1.1.m1.1a"><mo id="S4.T1.5.5.1.1.1.m1.1.1" xref="S4.T1.5.5.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.1.1.m1.1b"><times id="S4.T1.5.5.1.1.1.m1.1.1.cmml" xref="S4.T1.5.5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.6.6" class="ltx_tr">
<td id="S4.T1.6.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;"></td>
<td id="S4.T1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.3.1.1" class="ltx_p" style="width:56.9pt;">Network-based</span>
</span>
</td>
<td id="S4.T1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.4.1.1" class="ltx_p" style="width:51.2pt;">690.29</span>
</span>
</td>
<td id="S4.T1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.1.1.1" class="ltx_p" style="width:56.9pt;">5.64<math id="S4.T1.6.6.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.6.6.1.1.1.m1.1a"><mo id="S4.T1.6.6.1.1.1.m1.1.1" xref="S4.T1.6.6.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.1.1.1.m1.1b"><times id="S4.T1.6.6.1.1.1.m1.1.1.cmml" xref="S4.T1.6.6.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.7.7" class="ltx_tr">
<td id="S4.T1.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;"></td>
<td id="S4.T1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.3.1.1" class="ltx_p" style="width:56.9pt;">Contextual</span>
</span>
</td>
<td id="S4.T1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.4.1.1" class="ltx_p" style="width:51.2pt;">l79.54</span>
</span>
</td>
<td id="S4.T1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.7.7.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">21.67<math id="S4.T1.7.7.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.7.7.1.1.1.1.m1.1a"><mo id="S4.T1.7.7.1.1.1.1.m1.1.1" xref="S4.T1.7.7.1.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.1.1.1.m1.1b"><times id="S4.T1.7.7.1.1.1.1.m1.1.1.cmml" xref="S4.T1.7.7.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.1.1.1.m1.1c">\times</annotation></semantics></math></span></span>
</span>
</td>
</tr>
<tr id="S4.T1.8.8" class="ltx_tr">
<td id="S4.T1.8.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S4.T1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.2.1.1" class="ltx_p">0.2</span>
</span>
</td>
<td id="S4.T1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.3.1.1" class="ltx_p" style="width:56.9pt;">Data-based</span>
</span>
</td>
<td id="S4.T1.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.4.1.1" class="ltx_p" style="width:51.2pt;">2‚Äâ563.20</span>
</span>
</td>
<td id="S4.T1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.1.1.1" class="ltx_p" style="width:56.9pt;">1.52<math id="S4.T1.8.8.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.8.8.1.1.1.m1.1a"><mo id="S4.T1.8.8.1.1.1.m1.1.1" xref="S4.T1.8.8.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.1.1.1.m1.1b"><times id="S4.T1.8.8.1.1.1.m1.1.1.cmml" xref="S4.T1.8.8.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.9.9" class="ltx_tr">
<td id="S4.T1.9.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;"></td>
<td id="S4.T1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.9.9.3.1.1" class="ltx_p" style="width:56.9pt;">Network-based</span>
</span>
</td>
<td id="S4.T1.9.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.9.9.4.1.1" class="ltx_p" style="width:51.2pt;">634.12</span>
</span>
</td>
<td id="S4.T1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.9.9.1.1.1" class="ltx_p" style="width:56.9pt;">6.14<math id="S4.T1.9.9.1.1.1.m1.1" class="ltx_align_left" alttext="\times" display="inline"><semantics id="S4.T1.9.9.1.1.1.m1.1a"><mo id="S4.T1.9.9.1.1.1.m1.1.1" xref="S4.T1.9.9.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.1.1.1.m1.1b"><times id="S4.T1.9.9.1.1.1.m1.1.1.cmml" xref="S4.T1.9.9.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T1.10.10" class="ltx_tr">
<td id="S4.T1.10.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:14.2pt;"></td>
<td id="S4.T1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.10.3.1.1" class="ltx_p" style="width:56.9pt;">Contextual</span>
</span>
</td>
<td id="S4.T1.10.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T1.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.10.4.1.1" class="ltx_p" style="width:51.2pt;">l86.47</span>
</span>
</td>
<td id="S4.T1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.10.10.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T1.10.10.1.1.1.1" class="ltx_text ltx_font_bold">20.87<math id="S4.T1.10.10.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.10.10.1.1.1.1.m1.1a"><mo id="S4.T1.10.10.1.1.1.1.m1.1.1" xref="S4.T1.10.10.1.1.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.1.1.1.1.m1.1b"><times id="S4.T1.10.10.1.1.1.1.m1.1.1.cmml" xref="S4.T1.10.10.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.1.1.1.1.m1.1c">\times</annotation></semantics></math></span></span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">We implement and demonstrate FL with our pipeline as well as other four baselines, i.e. greedy, gossip, data-based and network-based client selection strategy, on a computer cluster with 4<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><times id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\times</annotation></semantics></math>¬†NVIDIA-A100-PCIE-40GB GPUs and 4<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><times id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\times</annotation></semantics></math>¬†32-Core-AMD-EPYC-7513 CPUs. The environment is a Linux system with Pytorch 1.8.1 and Cuda 11.1.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Experiment setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We conduct the experimental evaluation by training models on three widely used open datasets MNIST¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, <span id="S4.SS1.p1.1.1" class="ltx_text">CIFAR-10</span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and SVHN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> distributed into 100 CAV clients in non-iid setting.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In our default non-iid setting, each client owns only 2 out of 10 classes.</span></span></span></p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We compare our pipeline with four other client selection strategies as baselines, i.e., greedy, gossip, data-based and network-based, as described in Sec.¬†<a href="#S2" title="II Background and Related Work ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. The learning rate is 0.001 and the batch size is 64. The number of the local epochs is set as 3 for training on MNIST, and 1 for training on CIFAR-10 and SVHN, respectively. Except the greedy strategy (all clients are selected in each communication round), the general selection rate for FL clients is defined as 10%, i.e. around 10 clients are selected in each communication round.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Performance results</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We show the general performance of FL with contextual client selection for training models on three datasets distributed in 100¬†vehicle clients with respect to default non-iid setting. We train deep learning models with different sizes on MNIST, CIFAR-10 and SVHN as FL tasks. As the experimental results in Fig.¬†<a href="#S4.F3" title="Figure 3 ‚Ä£ IV Performance evaluation ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> show for all three tasks, FL with our contextual client selection can outperform the other four baselines. Generally, the FL with contextual client selection can achieve remarkable higher test accuracy than the other four strategies. Even though the network-based strategy allows the ML-model to be trained to a comparable test accuracy on SVHN, the contextual client selection results showcases much more stable convergence, as the data heterogeneity across CAVs are taken into account.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We conduct the experiments with various connection rates and evaluate the performance of FL. We take the required time to reach 0.5 of test accuracy for FL with gossip client selection as a baseline, and evaluate the time reduction rate of FL with other strategies. As the comparison results show in Tab.¬†<a href="#S4.T1" title="TABLE I ‚Ä£ IV Performance evaluation ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, FL with contextual client selection always needs less time than other two strategies at each connection rate. The time reduction rates are robustly over 20<math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mo id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><times id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\times</annotation></semantics></math> even when only 20% of clients are connected in networks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we reviewed the existing client selection strategies for FL and introduced a novel four-stage V2X-Boosted FL pipeline for C-ITS.
The approach tackles both data and network heterogeneity in vehicular networks, boosting communication efficiency by reducing the number of communication rounds and shortening the time required for each round.
Compared to other strategies, FL with contextual client selection achieves higher accuracy and more stable convergence performance by leveraging V2X messages disseminated in vehicular networks. Future work will further consider the analytical model of communication networks and conduct more validation in traffic scenario data, such as¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y.¬†Hu <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúCollaboration helps camera overtake LiDAR in 3D
detection,‚Äù in <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2023, doi:¬†10.48550/arXiv.2303.13560.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R.¬†Xu, H.¬†Xiang, Z.¬†Tu, X.¬†Xia, M.-H. Yang, and J.¬†Ma, ‚ÄúV2X-ViT:
Vehicle-to-everything cooperative perception with vision transformer,‚Äù in
<em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV 2022)</em>, 2022,
doi:¬†10.1007/978-3-031-19842-7_7.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y.¬†Li, Q.¬†Fang, J.¬†Bai, S.¬†Chen, F.¬†Juefei-Xu, and C.¬†Feng, ‚ÄúAmong us:
Adversarially robust collaborative perception by consensus,‚Äù <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2303.09495</em>, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Z.¬†Lei, S.¬†Ren, Y.¬†Hu, W.¬†Zhang, and S.¬†Chen, ‚ÄúLatency-aware collaborative
perception,‚Äù in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (EECCV</em>, 2022,
doi:¬†10.1007/978-3-031-19824-3_19.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R.¬†Xu <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúCoBEVT: Cooperative bird‚Äôs eye view semantic
segmentation with sparse transformers,‚Äù in <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">Conference on Robot
Learning (CoRL)</em>, 2022, doi:¬†10.48550/arXiv.2207.02202.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
K.¬†Sj√∂berg, P.¬†Andres, T.¬†Buburuzan, and A.¬†Brakemeier, ‚ÄúCooperative
Intelligent Transport Systems in Europe: Current deployment status
and outlook,‚Äù <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Vehicular Technology Magazine</em>, vol.¬†12, no.¬†2, pp.
89‚Äì97, 2017, doi:¬†10.1109/MVT.2017.2670018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G.¬†Thandavarayan, M. Sepulcre, and J.¬†Gozalvez, ‚ÄúGeneration of
cooperative perception messages for connected and automated vehicles,‚Äù
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Vehicular Technology</em>, vol.¬†69, no.¬†12, pp.
16‚Äâ336‚Äì16‚Äâ341, 2020, doi:¬†10.1109/TVT.2020.3036165.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
R.¬†Yu and P.¬†Li, ‚ÄúToward resource-efficient federated learning in mobile edge
computing,‚Äù <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol.¬†35, no.¬†1, pp. 148‚Äì155, 2021,
doi:¬†10.1109/MNET.011.2000295.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y.¬†Li <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúVoxFormer: Sparse voxel transformer for camera-based
3D semantic scene completion,‚Äù in <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">IEEE/CVF Computer Vision and
Pattern Recognition Conference (CVPR)</em>, 2023, doi:¬†10.48550/arXiv.2302.12251.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.¬†Li, J.¬†Zhang, D.¬†Ma, Y.¬†Wang, and C.¬†Feng, ‚ÄúMulti-robot scene completion:
Towards task-agnostic collaborative perception,‚Äù in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Conference on
Robot Learning</em>.¬†¬†¬†PMLR, 2023, pp.
2062‚Äì2072, url:¬†<a target="_blank" href="https://proceedings.mlr.press/v205/li23e/li23e.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v205/li23e/li23e.pdf</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y.¬†Hu, S.¬†Fang, Z.¬†Lei, Z.¬†Yiqi, and C.¬†Siheng, ‚ÄúWhere2comm:
Communication-efficient collaborative perception via spatial confidence
maps,‚Äù in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Conference on Neural Information Processing Systems
(NeurIPS)</em>, 2022, doi:¬†10.48550/arXiv.2209.12836.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J.¬†Posner, L.¬†Tseng, M.¬†Aloqaily, and Y.¬†Jararweh, ‚ÄúFederated learning in
vehicular networks: Opportunities and solutions,‚Äù <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>,
vol.¬†35, no.¬†2, pp. 152‚Äì159, 2021, doi:¬†10.1109/MNET.011.2000430.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
B.¬†McMahan, E.¬†Moore, D.¬†Ramage, S.¬†Hampson, and B.¬†A. y¬†Arcas,
‚ÄúCommunication-efficient learning of deep networks from decentralized
data,‚Äù in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.¬†¬†¬†PMLR, 2017, pp. 1273‚Äì1282,
url¬†<a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf</a>,.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J.¬†Jin, J.¬†Ren, Y.¬†Zhou, L.¬†Lyu, J.¬†Liu, and D.¬†Dou, ‚ÄúAccelerated federated
learning with decoupled adaptive optimization,‚Äù in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning</em>.¬†¬†¬†PMLR,
2022, pp. 10‚Äâ298‚Äì10‚Äâ322.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T.¬†Nishio and R.¬†Yonetani, ‚ÄúClient selection for federated learning with
heterogeneous resources in mobile edge,‚Äù in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International
Conference on Communications (ICC)</em>, 2019, pp. 1‚Äì7,
doi:¬†10.1109/ICC.2019.8761315.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S.¬†AbdulRahman, H.¬†Tout, A.¬†Mourad, and C.¬†Talhi, ‚ÄúFedMCCS: Multicriteria
client selection model for optimal iot federated learning,‚Äù <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE
Internet of Things Journal</em>, vol.¬†8, no.¬†6, pp. 4723‚Äì4735, 2020,
doi:¬†10.1109/JIOT.2020.3028742.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M.¬†Chahoud, S.¬†Otoum, and A.¬†Mourad, ‚ÄúOn the feasibility of federated learning
towards on-demand client deployment at the edge,‚Äù <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Information
Processing &amp; Management</em>, vol.¬†60, no.¬†1, p.¬†10, 2023,
doi:¬†10.1016/j.ipm.2022.103150.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J.¬†Xu and H.¬†Wang, ‚ÄúClient selection and bandwidth allocation in wireless
federated learning networks: A long-term perspective,‚Äù <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol.¬†20, no.¬†2, pp. 1188‚Äì1200,
2020, doi:¬†10.1109/TWC.2020.3031503.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y.¬†Fu <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúDigital twin based network latency prediction in
vehicular networks,‚Äù <em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic">MDPI Electronics</em>, vol.¬†11, no.¬†14, p.¬†21, 2022,
doi:¬†10.3390/electronics11142217.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D.¬†Yin <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúGradient diversity: a key ingredient for scalable
distributed learning,‚Äù in <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">International Conference on Artificial
Intelligence and Statistics</em>.¬†¬†¬†PMLR,
2018, pp. 1998‚Äì2007,
url¬†<a target="_blank" href="http://proceedings.mlr.press/v84/yin18a/yin18a.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v84/yin18a/yin18a.pdf</a>,.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
W.¬†Zhang, X.¬†Wang, P.¬†Zhou, W.¬†Wu, and X.¬†Zhang, ‚ÄúClient selection for
federated learning with non-IID data in mobile edge computing,‚Äù <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol.¬†9, pp. 24‚Äâ462‚Äì24‚Äâ474, 2021,
doi:¬†10.1109/ACCESS.2021.3056919.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y.¬†J. Cho, J.¬†Wang, and G.¬†Joshi, ‚ÄúTowards understanding biased client
selection in federated learning,‚Äù in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on
Artificial Intelligence and Statistics</em>.¬†¬†¬†PMLR, 2022, pp. 10‚Äâ351‚Äì10‚Äâ375,
url:¬†<a target="_blank" href="https://proceedings.mlr.press/v151/jee-cho22a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v151/jee-cho22a.html</a>,.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
S.¬†K. Shyn, D.¬†Kim, and K.¬†Kim, ‚ÄúEmpirical measurement of client contribution
for federated learning with data size diversification,‚Äù <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol.¬†10, pp. 118‚Äâ563‚Äì118‚Äâ574, 2022, doi:¬†10.1109/ACCESS.2022.3210950.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
R.¬†Balakrishnan, T.¬†Li, T.¬†Zhou, N.¬†Himayat, V.¬†Smith, and J.¬†Bilmes, ‚ÄúDiverse
client selection for federated learning via submodular maximization,‚Äù in
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021, p.¬†18,
url:¬†<a target="_blank" href="https://openreview.net/forum?id=nwKXyFvaUm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=nwKXyFvaUm</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
G.¬†Shen, D.¬†Gao, D.¬†Song, X.¬†Zhou, S.¬†Pan, W.¬†Lou, F.¬†Zhou <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>,
‚ÄúFast heterogeneous federated learning with hybrid client selection,‚Äù
<em id="bib.bib25.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.05135</em>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y.¬†LeCun, C.¬†Cortes, and C.¬†Burges, ‚ÄúMNIST handwritten digit database,‚Äù ATT
Labs, Tech. Rep., 2010, url:¬†<a target="_blank" href="http://yann.lecun.com/exdb/mnist" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://yann.lecun.com/exdb/mnist</a>,.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A.¬†Krizhevsky, ‚ÄúLearning multiple layers of features from tiny images,‚Äù
University of Toronto, Tech. Rep., 2009,
url¬†<a target="_blank" href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf</a>,.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y.¬†Netzer <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúReading digits in natural images with unsupervised
feature learning,‚Äù in <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">Workshop on Deep Learning and Unsupervised
Feature Learning (NIPS)</em>, 2011.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
R.¬†Xu, H.¬†Xiang, X.¬†Xia, X.¬†Han, J.¬†Li, and J.¬†Ma, ‚ÄúOPV2V: An open benchmark
dataset and fusion pipeline for perception with vehicle-to-vehicle
communication,‚Äù in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2022 International Conference on Robotics and
Automation (ICRA)</em>.¬†¬†¬†IEEE, 2022, pp.
2583‚Äì2589, doi:¬†10.1109/ICRA46639.2022.9812038.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y.¬†Li <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúV2X-Sim: Multi-agent collaborative perception dataset
and benchmark for autonomous driving,‚Äù <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">IEEE Robotics and Automation
Letters</em>, vol.¬†7, no.¬†4, pp. 10‚Äâ914‚Äì10‚Äâ921, 2022,
doi:¬†10.1109/LRA.2022.3192802.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
R.¬†Xu <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúV2v4real: A real-world large-scale dataset for
vehicle-to-vehicle cooperative perception,‚Äù in <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">The IEEE/CVF Computer
Vision and Pattern Recognition Conference (CVPR)</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Appendix</span>
</h2>

<figure id="S6.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Comparison of various paradigms of client selection strategies.</figcaption>
<table id="S6.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T2.1.1" class="ltx_tr">
<td id="S6.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Greedy</span></span>
</span>
</td>
<td id="S6.T2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Gossip</span></span>
</span>
</td>
<td id="S6.T2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T2.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Data-based</span></span>
</span>
</td>
<td id="S6.T2.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.4.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T2.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Network-based</span></span>
</span>
</td>
<td id="S6.T2.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.1.5.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T2.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Contextual (ours)</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.1.2" class="ltx_tr">
<td id="S6.T2.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.2.1.1.1" class="ltx_p" style="width:85.4pt;">
All clients should be selected in each FL communication round.</span>
</span>
</td>
<td id="S6.T2.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.2.2.1.1" class="ltx_p" style="width:85.4pt;">A random subset of all connected clients is selected in each FL communication round.</span>
</span>
</td>
<td id="S6.T2.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.2.3.1.1" class="ltx_p" style="width:85.4pt;">Clients are selected according to the similarity of local data distribution.</span>
</span>
</td>
<td id="S6.T2.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.2.4.1.1" class="ltx_p" style="width:85.4pt;">Clients are selected according to the connection quality and availability in networks.</span>
</span>
</td>
<td id="S6.T2.1.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.1.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.1.2.5.1.1" class="ltx_p" style="width:85.4pt;">Clients are selected in consideration of both data and network heterogeneity.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2305.11654/assets/figures/performance_under_niid.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Test accuracy of FL with baselines and contextual client selection on CIFAR-10 data distributed in different class ratio in each client.</figcaption>
</figure>
<div id="S6.p1" class="ltx_para">
<p id="S6.p1.2" class="ltx_p">We also demonstrate various client selection strategies under different class ratio in each client to evaluate the performance in non-iid settings. We consider a scenario for training a ML-model with 100¬†CAVs for three minutes. Note that the class ratio 100% indicates iid setting. As Fig.¬†<a href="#S6.F4" title="Figure 4 ‚Ä£ VI Appendix ‚Ä£ Contextual Client Selection for Federated Learning in Vehicular Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows, the pure network-based strategy can make the test accuracy of FL higher than others, because the data heterogeneity is not needed to be considered under ideal iid settings. However, in non-iid settings, the contextual client selection enhances FL and leads to a better test accuracy than other strategies. For instances, when the class ratio is 20%, it achieves 2.85<math id="S6.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.p1.1.m1.1a"><mo id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><times id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\times</annotation></semantics></math> test accuracy compared to a pure data-based and 1.67<math id="S6.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.p1.2.m2.1a"><mo id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><times id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">\times</annotation></semantics></math> to a pure network-based client selection strategy. Even in extremely non-iid setting with only 1 class in each client, the contextual client selection can reach 38% test accuracy within three minutes, while the FL with network- or data-based strategies cannot converge.

</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.11653" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.11654" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.11654">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.11654" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.11655" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 20:47:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
