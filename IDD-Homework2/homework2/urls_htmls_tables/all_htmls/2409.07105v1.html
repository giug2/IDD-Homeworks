<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis</title>
<!--Generated on Tue Sep 10 23:57:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
input-output model,  literature analysis,  mixed-initiative system,  unobtrusive visualization recommendation,  user study
" lang="en" name="keywords"/>
<base href="/html/2409.07105v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S1" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S2" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_font_smallcaps">Background</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S2.SS1" title="In 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span><span class="ltx_text ltx_font_italic">VPSA - Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S2.SS2" title="In 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span><span class="ltx_text ltx_font_italic">Meta Design Study</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S2.SS3" title="In 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span><span class="ltx_text ltx_font_italic">Related Work</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_smallcaps">VPSA Meta Design Study</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.SS1" title="In 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span><span class="ltx_text ltx_font_italic">Method ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" style="font-size:80%;border-color: #000000;">L1</span> )</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.SS2" title="In 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span><span class="ltx_text ltx_font_italic">Requirement Analysis ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" style="font-size:80%;border-color: #000000;">L2</span> )</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.SS3" title="In 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span><span class="ltx_text ltx_font_italic">Visualization Design Space ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" style="font-size:80%;border-color: #000000;">L3</span> )</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.SS4" title="In 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span><span class="ltx_text ltx_font_italic">VisRec Strategy ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" style="font-size:80%;border-color: #000000;">L4</span> )</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S4" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_font_smallcaps">RSVP System</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S4.SS1" title="In 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span><span class="ltx_text ltx_font_italic">Walk-through</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S4.SS2" title="In 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span><span class="ltx_text ltx_font_italic">Technical Aspects</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S4.SS3" title="In 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span><span class="ltx_text ltx_font_italic">Qualitative Result Inspection (QRI)</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S5" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span><span class="ltx_text ltx_font_smallcaps">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S5.SS1" title="In 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span><span class="ltx_text ltx_font_italic">Usability Study: Edge Detection Algorithm</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S5.SS2" title="In 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span><span class="ltx_text ltx_font_italic">Case Study I: Crystal Powder Diffraction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S5.SS3" title="In 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span><span class="ltx_text ltx_font_italic">Case Study II: Lighting Design Optimization</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S6" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S6.SS1" title="In 6 Discussion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span><span class="ltx_text ltx_font_italic">Findings</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S6.SS2" title="In 6 Discussion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span><span class="ltx_text ltx_font_italic">Further Design Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S6.SS3" title="In 6 Discussion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span><span class="ltx_text ltx_font_italic">Limitations and Future Work</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S7" title="In RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<img alt="[Uncaptioned image]" class="ltx_graphics ltx_missing ltx_missing_image" id="p1.g1" src=""/>
</div>
<figure class="ltx_figure" id="S0.F1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.8.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.9.2" style="font-size:90%;">Overview of our overall process to design a mixed-initiative system that provides domain scientists with the opportunity to perform VPSA without the need for a visualization expert. We conducted a <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.1">Meta Design Study</span> by surveying existing VPSA literature and extracting relevant information.
This procedure allowed us to analyze <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.2">requirements</span>, extract a <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.3">visualization design space</span>, and devise a <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.4">task-oriented VisRec strategy</span>.
We implemented our findings in RSVP, the <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.5">Rapid Suggestive Visualization Prototyping</span> system.
It enables domain scientists to rapidly create and experiment with visualization dashboards tailored to their specific models and data.
We externally <span class="ltx_text ltx_font_italic" id="S0.F1.9.2.6">evaluated</span> RSVP’s efficiency through a usability study and a real-world case study.
<br class="ltx_break"/></span></figcaption>
</figure>
<h1 class="ltx_title ltx_title_document">RSVP for VPSA : A Meta Design Study on 
<br class="ltx_break"/>Rapid Suggestive Visualization Prototyping
<br class="ltx_break"/>for Visual Parameter Space Analysis</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Manfred Klaffenboeck,
Michael Gleicher,
Johannes Sorger,
Michael Wimmer,
and Torsten Möller
</span><span class="ltx_author_notes">M. Klaffenboeck and M. Wimmer are with the Institute of Visual Computing and Human Centered Technology at TU Wien, Austria; Email: {lastname}@cg.tuwien.ac.at.
<br class="ltx_break"/>J. Sorger was with the Complexity Science Hub, Vienna, Austria.
<br class="ltx_break"/>M. Gleicher is with the
Department of Computer Sciences at the University of Wisconsin - Madison.
Email: gleicher@cs.wisc.edu
<br class="ltx_break"/>T. Möller is with the Faculty of Computer Science at the University of Vienna and the Research Network Data Science at Uni Wien. Email: torsten.moeller@univie.ac.atManuscript received April 30, 2023; revised February 1, 2024.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id6.id1">Visual Parameter Space Analysis (VPSA) enables domain scientists to explore input-output relationships of computational models.
Existing VPSA applications often feature multi-view visualizations designed by visualization experts for a specific scenario, making it hard for domain scientists to adapt them to their problems without professional help.
We present RSVP, the Rapid Suggestive Visualization Prototyping system encoding VPSA knowledge to enable domain scientists to prototype custom visualization dashboards tailored to their specific needs.
The system implements a task-oriented, multi-view visualization recommendation strategy over a visualization design space optimized for VPSA to guide users in meeting their analytical demands.
We derived the VPSA knowledge implemented in the system by conducting an extensive meta design study over the body of work on VPSA.
We show how this process <span class="ltx_text" id="id6.id1.1" style="color:#000000;">can</span> be used to perform a data and task abstraction, extract a common visualization design space, and derive a task-oriented VisRec strategy.
User studies indicate that the system is user-friendly and can uncover novel insights.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
input-output model, literature analysis, mixed-initiative system, unobtrusive visualization recommendation, user study

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The use of input-output-oriented models is ubiquitous in modern research, spanning problem domains from climate research<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib2" title="">2</a>]</cite> to complex engineering tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib4" title="">4</a>]</cite>, from parametric design problems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib6" title="">6</a>]</cite> to machine learning and deep learning<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib8" title="">8</a>]</cite>.
To comprehensively understand a model’s behavior, it is crucial to go beyond mere trial and error testing of parameter configurations.
A more holistic approach performed by some domain experts is to systematically sample the model, relating those sampled input parameters to the respective results and analyzing them together visually.
This process is known as <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">Visual Parameter Space Analysis (VPSA)</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">VPSA provides powerful means for scientists to investigate the behavior of complex models under different conditions and reveal patterns and relationships inherent in the model that might otherwise stay hidden.
It can aid domain scientists in identifying optimal parameter settings, exploring the underlying model uncertainty in different regions, and finding model boundaries for input parameterizations based on their corresponding outputs.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite promising evidence of its usefulness<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>, VPSA has not been adopted by the broader research community as a general problem-solving strategy.
A reason for this might be the lack of a visualization tool that allows domain experts to apply this type of visual analysis to their input-output models.
VPSA applications designed to solve high-level problems often comprise multiple visualizations capable of performing multi-dimensional analysis.
Designing such a multi-view visualization with its various tradeoffs often exceeds the visualization knowledge of domain scientists.
In some cases, domain scientists and visualization experts collaborate in design studies to develop customized solutions for specific problems.
However, this process requires time, resources, and mutual interest, which may exclude users seeking to utilize VPSA for less significant problems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib10" title="">10</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We introduce a mixed initiative system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib11" title="">11</a>]</cite> called RSVP (<span class="ltx_text ltx_font_italic" id="S1.p4.1.1">Rapid Suggestive Visualization Prototyping)</span> which encodes VPSA knowledge and guides users in designing visualization dashboards for their data and needs.
To gather and implement the necessary knowledge, we developed a meta-design strategy to extract tacit knowledge from VPSA papers and transform it into explicit knowledge<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib12" title="">12</a>]</cite>.
We refer to this approach as a <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">meta design study</span>.
The study yielded a comprehensive requirement analysis, a VPSA-specific visualization design space, and a visualization recommendation (VisRec) strategy for creating multi-view dashboards to solve typical VPSA tasks.
RSVP implements these findings, making an otherwise complex and time-consuming task actionable and comprehensible for non-visualization experts.
The system aims to be focused, transparent, and to promote learning to <span class="ltx_text ltx_font_italic" id="S1.p4.1.3">minimize the cost</span> of using it and <span class="ltx_text ltx_font_italic" id="S1.p4.1.4">build trust</span> in it – two factors we identified as latent needs of domain scientists when adopting a new visualization system.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p5.1.1">Outline &amp; Contributions:</span> Our overall approach is illustrated in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S0.F1" title="Figure 1 ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>.
We introduce important concepts and related work (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2" title="2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 2</span></a>), followed by our main contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We devised and conducted a <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.I1.i1.p1.1.1">Meta Design Study</span> over the body of knowledge on VPSA, complementing and extending previous work in the field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.
The artifacts from this process include a <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.2">comprehensive VPSA requirement analysis</span>, an <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.3">expressive VPSA visualization design space</span>, and a <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.4">practical VisRec strategy</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3" title="3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 3</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">The <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.I1.i2.p1.1.1">Rapid Suggestive Visualization Prototyping (RSVP)</span> system, which incorporates the design knowledge from the meta-design study into a user-friendly drag-and-drop interface for creating multi-view dashboards
(<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4" title="4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 4</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">A <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.I1.i3.p1.1.1">multi-faceted evaluation</span>, which includes a <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.2">qualitative result inspection</span> (QRI, (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.SS3" title="4.3 Qualitative Result Inspection (QRI) ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 4.3</span></a>)), a <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.3">usability study</span>, and <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.4">two real-world case studies</span> ((<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5" title="5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 5</span></a>)) to demonstrate the validity and efficacy of our approach.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We discuss findings, design aspects, limitations, and future research opportunities in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S6" title="6 Discussion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 6</span></a> and present our conclusion in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S7" title="7 Conclusion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 7</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Background</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">First, we introduce VPSA using a practical example.
Next, we define the term <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">meta design study</span> and discuss <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">domain experts</span> as a general user group.
Finally, we will review related work on visualization recommendation, exploration, and construction tools.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span class="ltx_text ltx_font_italic" id="S2.SS1.1.1">VPSA - Introduction</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="color:#000000;">VPSA is a general approach to perform input-output-oriented, multi-dimenional analysis. </span> The overall VPSA workflow is presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2" title="Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.
<span class="ltx_text" id="S2.SS1.p1.1.2" style="color:#000000;">We use a well-known edge detection algorithm<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib13" title="">13</a>]</cite> as a <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.2.1">running example</span> to introduce important VPSA concepts and terminology.</span> <span class="ltx_text" id="S2.SS1.p1.1.3" style="color:#000000;">We opted to use a generic image to avoid potential domain complexities. However, image segmentation, similar to the one presented, is often necessary in biological<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib14" title="">14</a>]</cite> and medical applications<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib15" title="">15</a>]</cite>, as well as in material sciences<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib16" title="">16</a>]</cite>.</span> </p>
</div>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel" id="S2.F2.12">
<figure class="ltx_figure ltx_align_center" id="S2.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S2.F2.sf1.g1" src="extracted/5846816/figures/VPSA-intro/VPSA-Intro-Part1.001.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S2.F2.sf1.3.2" style="font-size:90%;">Practical Dataflow Example</span></figcaption>
</figure>
<figure class="ltx_figure ltx_align_center" id="S2.F2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S2.F2.1.g1" src="extracted/5846816/figures/VPSA-intro/VPSA-Intro-Arrows.002.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;">sample</figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S2.F2.sf2.g1" src="extracted/5846816/figures/VPSA-intro/VPSA-Part2.001.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S2.F2.sf2.3.2" style="font-size:90%;">Sampled data</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F2.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S2.F2.2.g1" src="extracted/5846816/figures/VPSA-intro/VPSA-Intro-Arrows.002.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;">analyze</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S2.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S2.F2.sf3.g1" src="extracted/5846816/figures/VPSA-intro/VPSA-Intro-Part3.001.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S2.F2.sf3.3.2" style="font-size:90%;">Interactive VPSA Session</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.14.5.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.10.4" style="font-size:90%;">
Overview of the VPSA workflow.
(a) depicts the dataflow model for VPSA, using an edge detection algorithm as a practical example.
The model gets run multiple times using some kind of sampling strategy.
The
<span class="ltx_text ltx_inline-block" id="S2.F2.7.1.1" style="width:34.6pt;position:relative; bottom:-3.8pt;"><svg height="10.93" overflow="visible" version="1.1" width="166.81"><g transform="translate(0,10.93) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#74AF7C" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.7.1.1.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-21.14,-5.37)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">inputs </text></g></g></g></svg></span>,
<span class="ltx_text ltx_inline-block" id="S2.F2.8.2.2" style="width:65.6pt;position:relative; bottom:-3.8pt;"><svg height="11.07" overflow="visible" version="1.1" width="209.73"><g transform="translate(0,11.07) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E8B454" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.8.2.2.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-42.6,-5.53)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">direct outputs </text></g></g></g></svg></span>,
<span class="ltx_text ltx_inline-block" id="S2.F2.9.3.3" style="width:71.6pt;position:relative; bottom:-3.8pt;"><svg height="11.07" overflow="visible" version="1.1" width="218.04"><g transform="translate(0,11.07) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E59F94" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.9.3.3.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-46.75,-5.53)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">derived outputs </text></g></g></g></svg></span>,
and resulting
<span class="ltx_text ltx_inline-block" id="S2.F2.10.4.4" style="width:73.1pt;position:relative; bottom:-3.8pt;"><svg height="11.07" overflow="visible" version="1.1" width="220.08"><g transform="translate(0,11.07) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#3E8CF6" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S2.F2.10.4.4.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-47.77,-5.53)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">complex objects </text></g></g></g></svg></span>
(shades of blue)
from this process are gathered and stored in a data structure, such as a data table
(b),
which serves as the data source for the visual analysis process (c).
<span class="ltx_text" id="S2.F2.10.4.5" style="color:#000000;">The colors used for the visualizations in (c) are designed to match the colors in (a) and (b) in order to show the main data variable they are trying to encode.</span> </span></figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.4"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.SS1.p2.4.1" style="color:#000000;">Running Example:</span> 
The edge detection model <span class="ltx_text" id="S2.SS1.p2.4.2" style="color:#000000;">(see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2.sf1" title="2(a) ‣ Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2(a)</span></a>)</span> takes the unsegmented image and three numerical parameters (<span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.3">low</span>, <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.4">high</span>, <math alttext="\sigma" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_σ</annotation></semantics></math>) for internal thresholds as inputs.
It outputs a binary contour outline (<span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.5">co</span>) and two statistical parameters (<span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.6">sep</span> and <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.7">wep</span>).
For analytical purposes, the contour outline gets transformed into a 1D projection and compared to the same projection of a hand-drawn <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.4.8">”Ground Truth”</span> image, resulting in the difference between these two transformed contour outlines (<math alttext="\Delta_{tco}" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><msub id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2" mathvariant="normal" xref="S2.SS1.p2.2.m2.1.1.2.cmml">Δ</mi><mrow id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3.cmml"><mi id="S2.SS1.p2.2.m2.1.1.3.2" xref="S2.SS1.p2.2.m2.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p2.2.m2.1.1.3.1" xref="S2.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.p2.2.m2.1.1.3.3" xref="S2.SS1.p2.2.m2.1.1.3.3.cmml">c</mi><mo id="S2.SS1.p2.2.m2.1.1.3.1a" xref="S2.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.p2.2.m2.1.1.3.4" xref="S2.SS1.p2.2.m2.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2">Δ</ci><apply id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3"><times id="S2.SS1.p2.2.m2.1.1.3.1.cmml" xref="S2.SS1.p2.2.m2.1.1.3.1"></times><ci id="S2.SS1.p2.2.m2.1.1.3.2.cmml" xref="S2.SS1.p2.2.m2.1.1.3.2">𝑡</ci><ci id="S2.SS1.p2.2.m2.1.1.3.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3.3">𝑐</ci><ci id="S2.SS1.p2.2.m2.1.1.3.4.cmml" xref="S2.SS1.p2.2.m2.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">\Delta_{tco}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">roman_Δ start_POSTSUBSCRIPT italic_t italic_c italic_o end_POSTSUBSCRIPT</annotation></semantics></math>).
The Goodness-of-Fit between the contour outline and the ground truth (<math alttext="\chi^{2}_{co}" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.1"><semantics id="S2.SS1.p2.3.m3.1a"><msubsup id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mi id="S2.SS1.p2.3.m3.1.1.2.2" xref="S2.SS1.p2.3.m3.1.1.2.2.cmml">χ</mi><mrow id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3.cmml"><mi id="S2.SS1.p2.3.m3.1.1.3.2" xref="S2.SS1.p2.3.m3.1.1.3.2.cmml">c</mi><mo id="S2.SS1.p2.3.m3.1.1.3.1" xref="S2.SS1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.p2.3.m3.1.1.3.3" xref="S2.SS1.p2.3.m3.1.1.3.3.cmml">o</mi></mrow><mn id="S2.SS1.p2.3.m3.1.1.2.3" xref="S2.SS1.p2.3.m3.1.1.2.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">subscript</csymbol><apply id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.1.2.1.cmml" xref="S2.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S2.SS1.p2.3.m3.1.1.2.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2.2">𝜒</ci><cn id="S2.SS1.p2.3.m3.1.1.2.3.cmml" type="integer" xref="S2.SS1.p2.3.m3.1.1.2.3">2</cn></apply><apply id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3"><times id="S2.SS1.p2.3.m3.1.1.3.1.cmml" xref="S2.SS1.p2.3.m3.1.1.3.1"></times><ci id="S2.SS1.p2.3.m3.1.1.3.2.cmml" xref="S2.SS1.p2.3.m3.1.1.3.2">𝑐</ci><ci id="S2.SS1.p2.3.m3.1.1.3.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\chi^{2}_{co}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.3.m3.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT</annotation></semantics></math>) and between their respective 1D projections (<math alttext="\chi^{2}_{\Delta_{tco}}" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1"><semantics id="S2.SS1.p2.4.m4.1a"><msubsup id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml"><mi id="S2.SS1.p2.4.m4.1.1.2.2" xref="S2.SS1.p2.4.m4.1.1.2.2.cmml">χ</mi><msub id="S2.SS1.p2.4.m4.1.1.3" xref="S2.SS1.p2.4.m4.1.1.3.cmml"><mi id="S2.SS1.p2.4.m4.1.1.3.2" mathvariant="normal" xref="S2.SS1.p2.4.m4.1.1.3.2.cmml">Δ</mi><mrow id="S2.SS1.p2.4.m4.1.1.3.3" xref="S2.SS1.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS1.p2.4.m4.1.1.3.3.2" xref="S2.SS1.p2.4.m4.1.1.3.3.2.cmml">t</mi><mo id="S2.SS1.p2.4.m4.1.1.3.3.1" xref="S2.SS1.p2.4.m4.1.1.3.3.1.cmml">⁢</mo><mi id="S2.SS1.p2.4.m4.1.1.3.3.3" xref="S2.SS1.p2.4.m4.1.1.3.3.3.cmml">c</mi><mo id="S2.SS1.p2.4.m4.1.1.3.3.1a" xref="S2.SS1.p2.4.m4.1.1.3.3.1.cmml">⁢</mo><mi id="S2.SS1.p2.4.m4.1.1.3.3.4" xref="S2.SS1.p2.4.m4.1.1.3.3.4.cmml">o</mi></mrow></msub><mn id="S2.SS1.p2.4.m4.1.1.2.3" xref="S2.SS1.p2.4.m4.1.1.2.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">subscript</csymbol><apply id="S2.SS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.2.1.cmml" xref="S2.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.2.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2.2">𝜒</ci><cn id="S2.SS1.p2.4.m4.1.1.2.3.cmml" type="integer" xref="S2.SS1.p2.4.m4.1.1.2.3">2</cn></apply><apply id="S2.SS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.3.1.cmml" xref="S2.SS1.p2.4.m4.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.3.2.cmml" xref="S2.SS1.p2.4.m4.1.1.3.2">Δ</ci><apply id="S2.SS1.p2.4.m4.1.1.3.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3"><times id="S2.SS1.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.1"></times><ci id="S2.SS1.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.2">𝑡</ci><ci id="S2.SS1.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.3">𝑐</ci><ci id="S2.SS1.p2.4.m4.1.1.3.3.4.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.4">𝑜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">\chi^{2}_{\Delta_{tco}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.4.m4.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Δ start_POSTSUBSCRIPT italic_t italic_c italic_o end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math>) is measured using Pearson’s Chi-square test.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S2.SS1.p3.1.1" style="color:#000000;">Concepts and Terminology:</span> <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2.sf1" title="2(a) ‣ Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2(a)</span></a> is organized <span class="ltx_text" id="S2.SS1.p3.1.2" style="color:#000000;">in the form of</span> the <span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.3">data flow model</span> for VPSA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.
The three input parameters are control parameters (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.4">In<sub class="ltx_sub" id="S2.SS1.p3.1.4.1">CP</sub></em>), which the user can directly manipulate. The ”Original Image” is an environmental parameter (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.5">In<sub class="ltx_sub" id="S2.SS1.p3.1.5.1">EP</sub></em>), often outside the user’s direct control, meaning if a specific image needs to be segmented, it cannot be freely exchanged for another.
The segmented image (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.6">co</em>) and the statistical parameters (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.7">sep</em> and <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.8">wep</em>) are direct outputs (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.9">Out<sub class="ltx_sub" id="S2.SS1.p3.1.9.1">dir</sub></em>). These may need further processing for analytical efficiency, resulting in derived outputs (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.10">Out<sub class="ltx_sub" id="S2.SS1.p3.1.10.1">der</sub></em>). This example illustrates how VPSA handles various data types, classified broadly into <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.11">multi-dimensional/multi-variate (MDMV)</span> and <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.12">complex objects</span>. In our example, all numerical parameters are MDMV, while the segmented image (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.13">co</em>) and its transformed 1D-representation (<math alttext="\Delta_{tco}" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><msub id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" mathvariant="normal" xref="S2.SS1.p3.1.m1.1.1.2.cmml">Δ</mi><mrow id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml"><mi id="S2.SS1.p3.1.m1.1.1.3.2" xref="S2.SS1.p3.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p3.1.m1.1.1.3.1" xref="S2.SS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.p3.1.m1.1.1.3.3" xref="S2.SS1.p3.1.m1.1.1.3.3.cmml">c</mi><mo id="S2.SS1.p3.1.m1.1.1.3.1a" xref="S2.SS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.p3.1.m1.1.1.3.4" xref="S2.SS1.p3.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">Δ</ci><apply id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3"><times id="S2.SS1.p3.1.m1.1.1.3.1.cmml" xref="S2.SS1.p3.1.m1.1.1.3.1"></times><ci id="S2.SS1.p3.1.m1.1.1.3.2.cmml" xref="S2.SS1.p3.1.m1.1.1.3.2">𝑡</ci><ci id="S2.SS1.p3.1.m1.1.1.3.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3.3">𝑐</ci><ci id="S2.SS1.p3.1.m1.1.1.3.4.cmml" xref="S2.SS1.p3.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\Delta_{tco}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_t italic_c italic_o end_POSTSUBSCRIPT</annotation></semantics></math>) are examples of complex objects
A complex object is a semantic unit that can not be described with a single quantitative/ordinal/categorical variable without losing information.
Control parameters affect the segmentation process and require adjustment for the desired model output. A non-VPSA approach achieves this through trial-and-error, where the user adjusts parameters after inspecting unsatisfactory results. VPSA replaces this tedious (manual sampling) process by using (systematic) <span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.14">sampling</span> to vary control parameters.
<span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.15">Regular</span> or <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.16">stochastic</span> sampling is often used for this purpose, and the corresponding inputs and outputs are stored in a single data table (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2.sf2" title="2(b) ‣ Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2(b)</span></a>).
The columns of the data table reprise the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.17">dimensions</em> to be analyzed, and each row represents the inputs and outputs of a single <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.1.18">run</em>.
Data organized in such a way can then be analyzed visually (like in the example dashboard in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2.sf3" title="2(c) ‣ Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2(c)</span></a>).
Users adopting VPSA typically aim to perform a certain set of <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.19">analysis tasks</span>, such as finding optimal parameterizations, identifying potential outliers, or partitioning the data.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.T1" title="TABLE I ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Table I</span></a> provides an overview of typical VPSA tasks, as outlined by Sedlmair et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.
Please note that the colors used to classify the individual tasks are different from the colors used for inputs and outputs in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2" title="Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.
To perform these tasks, VPSA users need to navigate a multi-dimensional problem space.
The most common <span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.20">navigation strategy</span> is the <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.21">global-to-local approach</span>, where users start with an overview of the data and then explore details.
Less commonly used strategies include the <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.22">local-to-global</span> approach, where users start with a specific sample point and explore alternatives, and the <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.23">steering</span> approach, where users adjust parameters during simulation runtime.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.8.1.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S2.T1.9.2" style="font-size:90%;">List of typical VPSA-Tasks according to the conceptual framework by Sedlmair at al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite></span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T1.6">
<tr class="ltx_tr" id="S2.T1.6.7">
<td class="ltx_td ltx_align_center" colspan="2" id="S2.T1.6.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.6.7.1.1">Task</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.6.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.6.7.2.1">
<span class="ltx_p" id="S2.T1.6.7.2.1.1" style="width:260.2pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.6.7.2.1.1.1">Description</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Optimzation</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.1.1.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.1.1.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.3.1.1" style="width:260.2pt;">Find the best parameter setting</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2">
<td class="ltx_td ltx_align_right" id="S2.T1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Fitting</td>
<td class="ltx_td ltx_align_left" id="S2.T1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.2.2.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.2.2.1.1.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.2.2.3.1">
<span class="ltx_p" id="S2.T1.2.2.3.1.1" style="width:260.2pt;">Find where actual model data occurs</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.3.3">
<td class="ltx_td ltx_align_right" id="S2.T1.3.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Uncertainty</td>
<td class="ltx_td ltx_align_left" id="S2.T1.3.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.3.3.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.3.3.1.1.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.3.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.3.3.3.1">
<span class="ltx_p" id="S2.T1.3.3.3.1.1" style="width:260.2pt;">Determine the reliability of the output</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.4">
<td class="ltx_td ltx_align_right" id="S2.T1.4.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Outliers</td>
<td class="ltx_td ltx_align_left" id="S2.T1.4.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.4.4.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.4.4.1.1.g1" src="extracted/5846816/figures/task_labels/Tout.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.4.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.4.4.3.1">
<span class="ltx_p" id="S2.T1.4.4.3.1.1" style="width:260.2pt;">Find odd or special outputs</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.5.5">
<td class="ltx_td ltx_align_right" id="S2.T1.5.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Sensitivity</td>
<td class="ltx_td ltx_align_left" id="S2.T1.5.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.5.5.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.5.5.1.1.g1" src="extracted/5846816/figures/task_labels/Tsens.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.5.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.5.5.3.1">
<span class="ltx_p" id="S2.T1.5.5.3.1.1" style="width:260.2pt;">Identify input regions with high or low impact on the output</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.6">
<td class="ltx_td ltx_align_right" id="S2.T1.6.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Partitioning</td>
<td class="ltx_td ltx_align_left" id="S2.T1.6.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S2.T1.6.6.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S2.T1.6.6.1.1.g1" src="extracted/5846816/figures/task_labels/Tpart.png" width="30"/></span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.6.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.6.6.3.1">
<span class="ltx_p" id="S2.T1.6.6.3.1.1" style="width:260.2pt;">Identify different types of model behavior</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span class="ltx_text ltx_font_italic" id="S2.SS2.1.1">Meta Design Study</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Traditional design studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib10" title="">10</a>]</cite> and data-driven design studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib17" title="">17</a>]</cite> require the early collaboration with domain scientists to gather domain knowledge.
In contrast, we apply a design approach that synthesizes this kind of information from written reports of existing design studies.
Since this strategy shares many similarities with <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">meta analysis<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S2.SS2.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib18" title="">18</a><span class="ltx_text ltx_font_upright" id="S2.SS2.p1.1.1.2.2">]</span></cite></span>, we call this a <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.2">meta design study</span>.
A meta design study is suitable when the goal is to develop a more general tool that serves the needs of a wider group of users within a certain problem domain.

A meta design study offers a principled approach to performing requirements analysis and extracting a visualization design space from analyzed applications and reports.
Additionally, it provides a mechanism for deriving a data and task-oriented visualization recommendation strategy over the extracted design space.
Practical details will be further explained in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3" title="3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 3</span></a>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text" id="S2.SS2.p2.1.1" style="color:#000000;">Meta design studies follow</span> Munzner’s nested model for visualization design<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib19" title="">19</a>]</cite> in a top-down manner<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib20" title="">20</a>]</cite>:
Gathering and analyzing the papers is learning about the <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.2">domain situation</em> <span class="ltx_text ltx_font_sansserif ltx_framed ltx_framed_rectangle" id="S2.SS2.p2.1.3" style="font-size:80%;border-color: #000000;">L1</span>.
The requirement extraction process includes <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.4">data and task abstraction</span> <span class="ltx_text ltx_font_sansserif ltx_framed ltx_framed_rectangle" id="S2.SS2.p2.1.5" style="font-size:80%;border-color: #000000;">L2</span>.
Extracting the visualization design space from the literature is acquiring knowledge about <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.6">visual encoding idioms</span> <span class="ltx_text ltx_font_sansserif ltx_framed ltx_framed_rectangle" id="S2.SS2.p2.1.7" style="font-size:80%;border-color: #000000;">L3</span>,
and deriving a visualization recommendation strategy over the visualization design space operates on an <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.8">algorithmic level</span> <span class="ltx_text ltx_font_sansserif ltx_framed ltx_framed_rectangle" id="S2.SS2.p2.1.9" style="font-size:80%;border-color: #000000;">L4</span>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text" id="S2.SS2.p3.1.1" style="color:#000000;">Since there is no immediate interaction with <span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1.1">domain scientists</span>, we extract general knowledge about this user group from existing literature in a similar fashion.</span> Several sources <span class="ltx_text" id="S2.SS2.p3.1.2" style="color:#000000;">state</span> that domain experts often have little time and prefer visualizations capable of providing immediate data insights<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib22" title="">22</a>]</cite>.
<span class="ltx_text" id="S2.SS2.p3.1.3" style="color:#000000;">Somewhat contrary to this statement, domain scientists also seem to want to explore their various options <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib24" title="">24</a>]</cite>.</span> It is beneficial for domain scientists to use familiar data when learning about unknown visualizations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib26" title="">26</a>]</cite>.
Unlike casual users, domain scientists analyze visualizations in a more structured way<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib27" title="">27</a>]</cite>, and they are skilled in transferring their domain knowledge from familiar to unfamiliar visualizations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib28" title="">28</a>]</cite>.
Furthermore, showing transitions from simple to more complex visualizations fosters an understanding of the latter<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib29" title="">29</a>]</cite>.
However, domain scientists are a heterogeneous user group with different backgrounds, interests, and levels of visualization literacy, which is why they should be treated similarly to visualization novices<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib31" title="">31</a>]</cite>.
From a high-level perspective, these guidelines try to <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS2.p3.1.4">minimize the cost</em><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib32" title="">32</a>]</cite> of using a visualization tool.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Furthermore, domain experts do not like being told what the (supposedly) best solution is without being able to explore alternative options <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib4" title="">4</a>]</cite>.
We interpret this behavior as a <span class="ltx_text" id="S2.SS2.p4.1.1" style="color:#000000;">necessity</span> for those experts to build a high enough <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS2.p4.1.2">level of trust</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib33" title="">33</a>]</cite> in a proposed solution.
We deem this a crucial factor when designing a general-purpose tool intended to be used by domain scientists that utilizes a recommendation strategy.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span><span class="ltx_text ltx_font_italic" id="S2.SS3.1.1">Related Work</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">In this section, we present related work in terms of visualization recommendation, exploration, and construction.
<br class="ltx_break"/>
<br class="ltx_break"/>
<span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.1">Visualization Recommendation (VisRec)</span> is a versatile and extensively researched field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib34" title="">34</a>]</cite>. Here, we provide background information on various aspects of VisRec that are important for our further discussion.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1" style="color:#000000;">Data-oriented VisRec:</span> APT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib35" title="">35</a>]</cite> was amongst the first tools to provide visualization recommendations.
It recommended visualizations based on their <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.2">expressiveness</span> (how well does it show the data and only the data) and their (perceptual) <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.3">effectiveness</span>.
Although the underlying rules may have been reviewed and refined since then, the basic principles of expressiveness and effectiveness are still vital in modern data-oriented visualization recommendation approaches (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib38" title="">38</a>]</cite>).
However, basing recommendations mainly on expressiveness and perceptual effectiveness has its limits and does not necessarily help in solving specific tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib39" title="">39</a>]</cite>.
Our VisRec strategy implicitly covers expressiveness and effectiveness but also takes the task-based effectiveness of visualizations into account.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1" style="color:#000000;">Task-oriented VisRec:<span class="ltx_text ltx_font_medium" id="S2.SS3.p3.1.1.1"> </span></span> Early work in task-oriented VisRec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib43" title="">43</a>]</cite> focused on creating composited graphics for <span class="ltx_text ltx_font_italic" id="S2.SS3.p3.1.2">presentational</span> purposes and did not necessarily help overcome analytical gaps<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib44" title="">44</a>]</cite>.
Our work focuses on visualizations and strategies for <span class="ltx_text ltx_font_italic" id="S2.SS3.p3.1.3">exploratory</span> and <span class="ltx_text ltx_font_italic" id="S2.SS3.p3.1.4">confirmatory</span> data analysis.
Modern insight-oriented<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib46" title="">46</a>]</cite> or task-oriented <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib47" title="">47</a>]</cite> VisRec systems support a wide range of analytical tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib44" title="">44</a>]</cite>.
Interestingly, their general VisRec approach is strikingly similar.
Each task is either associated with a fixed visualization or with visual features that are supposed to support this task.
However, the process of finding visualizations / visual features best supporting the respective tasks in the mentioned papers is not explicitly reported.
Draco<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib38" title="">38</a>]</cite> can learn weights to incorporate task-oriented efficiency in the recommendations.
Unfortunately, this requires an extensive corpus of labeled training data in the form of ranked examples, even for learning only a minimal number of very general tasks.
Furthermore, Draco only supports MDMV visualizations.
Our VisRec approach bases its task-oriented recommendations on visual features which we extracted from the meta design study.
Additionally, our approach can not only handle MDMV visualizations but also complex object visualizations.</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS3.p4.1.1" style="color:#000000;">Multi-view VisRec:</em> Solving high-level analysis tasks often requires the combination of multiple visualizations into a coherent whole.
VizDeck<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib48" title="">48</a>]</cite> allows for combining recommended visualizations from different sources into a dashboard, but it does not provide any guidance on how to combine them effectively.
DeepEye<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib49" title="">49</a>]</cite> and MultiVision<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib50" title="">50</a>]</cite> recommend combinations for multi-view visualizations, but their focus is on general-purpose dashboards and less on solving specific analysis tasks.</p>
</div>
<div class="ltx_para" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS3.p5.1.1">Transparency and Explainability in VisRec:</em> The importance of explanations in recommender systems is well established<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib51" title="">51</a>]</cite> – a fact often ignored in VisRec systems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib52" title="">52</a>]</cite>.
Some systems (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib49" title="">49</a>]</cite>) report the internal ranking scores to the users, but those most likely have no meaning to them.
KG4Vis<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib54" title="">54</a>]</cite>
manages to explain why a visualization was recommended but is currently limited to visualizations encoding a maximum of two attributes.
Our literature-based observations for task-based efficiency follow generally accepted visualization design rules and can be easily communicated to the users.</p>
</div>
<div class="ltx_para" id="S2.SS3.p6">
<p class="ltx_p" id="S2.SS3.p6.1"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="S2.SS3.p6.1.1">VisRec Knowledge Encoding:</em>
Various methods exist for encoding VisRec knowledge, including machine<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib55" title="">55</a>]</cite> or deep learning<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib49" title="">49</a>]</cite> for rule acquisition, knowledge graphs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib55" title="">55</a>]</cite>, constraint-based rule definition with answer set programming <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib38" title="">38</a>]</cite>, and ontologies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib58" title="">58</a>]</cite>.
Classical approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib41" title="">41</a>]</cite> employ hard-coded rules, an approach also taken by CompassQL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib36" title="">36</a>]</cite>, the recommendation strategy behind Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib37" title="">37</a>]</cite>.
For simplicity, VisRec rules encoded in RSVP are currently also hard-coded.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.SS3.p6.1.2">Visualization Exploration: </span>
<em class="ltx_emph ltx_font_italic" id="S2.SS3.p6.1.3">Spreadsheet-like interfaces</em> for visualization exploration <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib60" title="">60</a>]</cite> have been used to perform parameter space exploration and present the results to the user<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib61" title="">61</a>]</cite>.
Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib37" title="">37</a>]</cite> leverages visualization recommendations to present the user with a single optimal solution for a given data state.
One can argue, though, that it is important to present the same data through different perspectives, so the user can understand the data better, avoid possible misconceptions<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib62" title="">62</a>]</cite>, and foster the learning of unknown or less familiar visualizations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib63" title="">63</a>]</cite>.
Van den Elzen<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib63" title="">63</a>]</cite> proposed an interface combining small multiples and large singles to show variations of the current state space via various visual mappings.
We build upon this idea to combine parameter space exploration with an unobtrusive visualization recommendation strategy for coordinated multiple views.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.SS3.p6.1.4">Multi-view Visualization Construction:</span>

Improvise<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib64" title="">64</a>]</cite>, ComVis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib65" title="">65</a>]</cite>, and Visplore<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib66" title="">66</a>]</cite> are frameworks that allow creating applications suited for VPSA, but all of them require at least some level of programming, and they do not immediately encode visualization knowledge for domain experts.
Keshif <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib67" title="">67</a>]</cite> is a tool aimed at visualization novices to perform data exploration via multi-view applications.
It favors aggregated views to explore big data tables.
The analysis of input-output models, however, often requires a focus on visualizations where the individual items are directly encoded and not abstracted away<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib4" title="">4</a>]</cite>.
Tableau<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib69" title="">69</a>]</cite>
provides various visualizations suitable for VPSA but has limited support for complex objects and lacks sufficient guidance for choosing visualizations capable of solving high-level VPSA tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">VPSA Meta Design Study</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section outlines the procedure and outputs of our <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">meta design study</span>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span class="ltx_text ltx_font_italic" id="S3.SS1.1.1">Method ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" id="S3.SS1.1.1.1" style="font-size:80%;border-color: #000000;">L1</span> )</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We began by creating a <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">coding table</span>, a common strategy often used in social and business research to quantitatively analyze large text corpora<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib70" title="">70</a>]</cite>.
Initially, we coded the twenty-one papers Sedlmair et al. used to derive the conceptual VPSA framework<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.
After that, we extended this literature corpus of practical VPSA applications using a four-step strategy.
First, we searched research databases using the query “visual parameter space analysis.”
Second, we looked for papers that directly referenced the work by Sedlmair et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>.
Third, we examined the references of all papers found in the first two steps.
Lastly, we searched for papers that referenced works in our current pool but did not cite the work by Sedlmair et al.
In this manner, we identified twenty-four supplementary papers that fulfilled our selection criteria, resulting in a cumulative total of forty-five papers.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text" id="S3.SS1.p2.1.1" style="color:#000000;">Our analysis revealed the need to categorize the applications described in those papers according to the following aspects:
the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.1">tasks</span> an application aimed to address, the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.2">sampling strategy</span> employed, the visualizations incorporated in an application, the number of <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.3">dimensions</span> encoded by each visualization, the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.4">encoding channels</span> utilized in a specific visualization, and whether a visualization represented <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.5">inputs</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.6">outputs</span>, or <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1.7">both</span>.
At least two authors coded each paper, and the findings were discussed with the entire group.</span>
The supplemental material contains the list of forty-five papers and the <span class="ltx_text" id="S3.SS1.p2.1.2" style="color:#000000;">populated</span> coding table, as well as a discussion of how our approach aligns with Furniss’s<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib71" title="">71</a>]</cite> five stages of Grounded Theory.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">While the applications discussed in those papers may be domain-agnostic in several cases, the main application examples presented can be classified into the following categories: Engineering &amp; Material Sciences (16/45), Arts &amp; Design (10/45), and Biology &amp; Medical Domain (10/45). The remaining examples fall into the categories of Operations Research (2/45), Climate &amp; Geo-Science (3/45), and Machine Learning (2/45). Two analyzed applications dealt with generic datasets and could not be classified accordingly.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span class="ltx_text ltx_font_italic" id="S3.SS2.1.1">Requirement Analysis ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" id="S3.SS2.1.1.1" style="font-size:80%;border-color: #000000;">L2</span> )</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1"><span class="ltx_text" id="S3.SS2.p1.1.1" style="color:#000000;">In <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.SS2" title="2.2 Meta Design Study ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 2.2</span></a>), we identified <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1.1">Cost</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1.2">Trust</em> as two pivotal factors for the successful adoption of the proposed system by domain experts.</span> <span class="ltx_text" id="S3.SS2.p1.1.2" style="color:#000000;">They</span> form the basis for <span class="ltx_text" id="S3.SS2.p1.1.3" style="color:#000000;">our</span> <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.4">Key Goals</span>, namely that the system must impose <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p1.1.5">Low Cost (Key-I)</em> on the user regarding time and cognitive effort<span class="ltx_text" id="S3.SS2.p1.1.6" style="color:#000000;">, and the</span> user must gain <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p1.1.7">High Trust (Key-II)</em> in the system and the general VPSA method.
In order to achieve those key goals, we derive a set of <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.8">Design Goals</span> and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.9">Requirements</span>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1" style="color:#000000;">Design Goals: <span class="ltx_text ltx_font_medium" id="S3.SS2.p2.1.1.1">Aligning with the design guidelines for domain experts by Wong et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib30" title="">30</a>]</cite>, we determined four design goals.</span></span> The visualization design space must be <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.2">simple yet expressive (DG-1)</em> in order to solve high-level problems but not overwhelm visualization novices.
A strategy to lower Cost and increase Trust is to <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.3">activate domain knowledge (DG-2)</em> which, for instance, can be achieved by including visualization options a domain expert most likely knows and showing them with familiar data.
In order to improve Cost and Trust further, the system has to <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.4">promote learning (DG-3)</em>, e.g., by including explanations and providing means so users can transfer existing visualization knowledge to more advanced visualization techniques.
Last but not least, a crucial factor in gaining Trust is to <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p2.1.5">provide transparency (DG-4)</em>, especially in terms of why a specific visualization was recommended to achieve a particular high-level task.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1" style="color:#000000;">System Requirements: <span class="ltx_text ltx_font_medium" id="S3.SS2.p3.1.1.1"> in order to support those Design Goals, we derived several requirements from the individual requirement analysis outlined in the papers of the meta design study.</span></span> One requirement is that the system has to be <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p3.1.2">easy to set up (Req-1)</em> in terms of installation and initial data preparation.
Another requirement we often found was that some kind of <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p3.1.3">overview (Req-2)</em> is necessary to understand the analyzed model better.
Further, an application must provide means to <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p3.1.4">navigate a multi-dimensional parameter space (Req-3)</em> to explore the input-output relations of the model interactively.
The remaining generalizable requirements can be described as a variation or a detailed description to support one or several of the <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p3.1.5">analysis tasks (Req-4)</em> outlined in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.T1" title="TABLE I ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Table I</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Constraints</span>:
RSVP will provide <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.2">no sampling support (Con-1)</em>. We assume that users are capable of sampling their model, at least by using random or Cartesian grid sampling.
Most applications we researched focused on visualization solutions that provided multiple interconnected views to study a few hundred runs.
For that reason, the tool should be capable of providing solutions for <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.3">no more than a couple of hundred runs (Con-2)</em>.
For a single run, some models can output a series of complex objects, e.g., time-varied images.
We focus on visualizing single complex objects per run, i.e. <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.4">no series of complex objects (Con-3</em><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.5">)</span> need to be supported.
Further, integrating models for direct re-sampling (also known as integrated sampling<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>) is an often complicated and error-prone procedure.
Therefore, the tool will offer <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.6">no direct model interface (Con-4)</em>.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.1"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.1.g1" src=""/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.fig1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.F3.fig1.1">
<tr class="ltx_tr" id="S3.F3.fig1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.F3.fig1.1.1.1" rowspan="7"><span class="ltx_text" id="S3.F3.fig1.1.1.1.1" style="font-size:80%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.F3.fig1.1.1.1.1.1" style="width:5.5pt;height:29.5pt;vertical-align:-12.0pt;"><span class="ltx_transformed_inner" style="width:29.4pt;transform:translate(-11.99pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.F3.fig1.1.1.1.1.1.1">MDMV</span>
</span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.1.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.1.2.1" style="font-size:80%;">Scatterplot</em></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.1.3">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.1.3.1" style="font-size:80%;">SP</em><span class="ltx_rule" style="width:0.0pt;height:9.0pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.2">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.2.1">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.2.1.1" style="font-size:80%;">(weighted)</em><span class="ltx_text" id="S3.F3.fig1.1.2.1.2" style="font-size:80%;"> </span><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.2.1.3" style="font-size:80%;">Density Contourplot</em>
</td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.2.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.2.2.1" style="font-size:80%;">wDCP</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.3">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.3.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.3.1.1" style="font-size:80%;">Scatterplot Matrix</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.3.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.3.2.1" style="font-size:80%;">SPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.4">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.4.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.4.1.1" style="font-size:80%;">reduced SPLOM</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.4.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.4.2.1" style="font-size:80%;">rSPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.5">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.5.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.5.1.1" style="font-size:80%;">Point Scales</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.5.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.5.2.1" style="font-size:80%;">PSc</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.6">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.6.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.6.1.1" style="font-size:80%;">Parallel Coordinates</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.6.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.6.2.1" style="font-size:80%;">PC</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.7">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.7.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.7.1.1" style="font-size:80%;">Histogram</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.7.2">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.7.2.1" style="font-size:80%;">Hist</em><span class="ltx_rule" style="width:0.0pt;height:0.0pt;position:relative; bottom:-4.8pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.F3.fig1.1.8.1"><span class="ltx_text ltx_font_bold" id="S3.F3.fig1.1.8.1.1" style="font-size:80%;">Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.8.2"><span class="ltx_text ltx_font_bold" id="S3.F3.fig1.1.8.2.1" style="font-size:80%;">Visualization Options</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.8.3">
<span class="ltx_text ltx_font_bold" id="S3.F3.fig1.1.8.3.1" style="font-size:80%;">Abbr</span><span class="ltx_text" id="S3.F3.fig1.1.8.3.2" style="font-size:80%;">. </span><span class="ltx_rule" style="width:0.0pt;height:9.0pt;background:black;display:inline-block;"></span><span class="ltx_rule" style="width:0.0pt;height:0.0pt;position:relative; bottom:-4.8pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.9">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.F3.fig1.1.9.1" rowspan="6"><span class="ltx_text" id="S3.F3.fig1.1.9.1.1" style="font-size:80%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.F3.fig1.1.9.1.1.1" style="width:7.1pt;height:57.4pt;vertical-align:-26.7pt;"><span class="ltx_transformed_inner" style="width:57.3pt;transform:translate(-25.11pt,2.33pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.F3.fig1.1.9.1.1.1.1">Complex Object</span>
</span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.9.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.9.2.1" style="font-size:80%;">1D - Linegraph</em></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.9.3">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.9.3.1" style="font-size:80%;">1D-Line</em><span class="ltx_rule" style="width:0.0pt;height:9.0pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.10">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.10.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.10.1.1" style="font-size:80%;">1D - Boxplot</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.10.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.10.2.1" style="font-size:80%;">1D-Box</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.11">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.11.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.11.1.1" style="font-size:80%;">1D - Cumulative Histogram</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.11.2">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.11.2.1" style="font-size:80%;">1D-Hist</em><span class="ltx_rule" style="width:0.0pt;height:0.0pt;position:relative; bottom:-4.8pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.12">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.12.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.12.1.1" style="font-size:80%;">2D - Gridview</em></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.F3.fig1.1.12.2">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.12.2.1" style="font-size:80%;">2D-Grid</em><span class="ltx_rule" style="width:0.0pt;height:9.0pt;background:black;display:inline-block;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.13">
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.13.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.13.1.1" style="font-size:80%;">2D - Juxtapositioned views</em></td>
<td class="ltx_td ltx_align_left" id="S3.F3.fig1.1.13.2"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.13.2.1" style="font-size:80%;">2D-Jux</em></td>
</tr>
<tr class="ltx_tr" id="S3.F3.fig1.1.14">
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.F3.fig1.1.14.1"><em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.14.1.1" style="font-size:80%;">2D - Superpositioned views</em></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.F3.fig1.1.14.2">
<em class="ltx_emph ltx_font_italic" id="S3.F3.fig1.1.14.2.1" style="font-size:80%;">2D-Sup</em><span class="ltx_rule" style="width:0.0pt;height:0.0pt;position:relative; bottom:-4.8pt;background:black;display:inline-block;"></span>
</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.2"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F3.2.g1" src=""/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.4.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.5.2" style="font-size:90%;">Overview of the Visualization Design Space, split into multi-dimensional/multi-variate (MDMV) visualizations, and complex object visualization.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span class="ltx_text ltx_font_italic" id="S3.SS3.1.1">Visualization Design Space ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" id="S3.SS3.1.1.1" style="font-size:80%;border-color: #000000;">L3</span> )</span>
</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.2.1.1" style="font-size:90%;">TABLE II</span>: </span><span class="ltx_text" id="S3.T2.3.2" style="font-size:90%;">Overview of the VisRec-strategy for the VPSA design space</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel" id="S3.T2.st1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.st1.6">
<tr class="ltx_tr" id="S3.T2.st1.6.7">
<td class="ltx_td ltx_align_center" id="S3.T2.st1.6.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Task</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.6.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Strategy</td>
<td class="ltx_td ltx_align_center" colspan="2" id="S3.T2.st1.6.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">MDMV</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.6.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">Complex Object</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.st1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.1.1.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.1.1.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.st1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Overview</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.st1.1.1.3" rowspan="3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.1.1.3.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.T2.st1.1.1.3.1.1" style="width:36.0pt;height:52.2pt;vertical-align:-8.1pt;"><span class="ltx_transformed_inner" style="width:52.1pt;transform:translate(-8.06pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.T2.st1.1.1.3.1.1.1"><span class="ltx_text" id="S3.T2.st1.1.1.3.1.1.1.1"></span> <span class="ltx_text" id="S3.T2.st1.1.1.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.st1.1.1.3.1.1.1.2.1">
<span class="ltx_tr" id="S3.T2.st1.1.1.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.st1.1.1.3.1.1.1.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Channel-</span></span>
<span class="ltx_tr" id="S3.T2.st1.1.1.3.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.st1.1.1.3.1.1.1.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">based</span></span>
</span></span> <span class="ltx_text" id="S3.T2.st1.1.1.3.1.1.1.3"></span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.st1.1.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.1.1.4.1">Spatial</span> expressivity</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.st1.1.1.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st1.1.1.5.1">1D-Line</em>, <em class="ltx_emph ltx_font_italic" id="S3.T2.st1.1.1.5.2">2D-Grid</em>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.2.2">
<td class="ltx_td ltx_align_left" id="S3.T2.st1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.2.2.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.2.2.1.1.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Affiliation</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">Overview + <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.2.2.3.1">Color</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.2.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st1.2.2.4.1">2D-Jux</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.3.3">
<td class="ltx_td ltx_align_left" id="S3.T2.st1.3.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.3.3.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.3.3.1.1.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.3.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Attenuation</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.3.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">Overview + <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.3.3.3.1">Brightness</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.3.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st1.3.3.4.1">1D-Box</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.4.4">
<td class="ltx_td ltx_align_left" id="S3.T2.st1.4.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.4.4.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.4.4.1.1.g1" src="extracted/5846816/figures/task_labels/Tout.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.4.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Separation</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.4.4.3" rowspan="3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.4.4.3.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.T2.st1.4.4.3.1.1" style="width:36.0pt;height:39.4pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="width:39.4pt;transform:translate(-1.68pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.T2.st1.4.4.3.1.1.1"><span class="ltx_text" id="S3.T2.st1.4.4.3.1.1.1.1"></span> <span class="ltx_text" id="S3.T2.st1.4.4.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.st1.4.4.3.1.1.1.2.1">
<span class="ltx_tr" id="S3.T2.st1.4.4.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.st1.4.4.3.1.1.1.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Mark-</span></span>
<span class="ltx_tr" id="S3.T2.st1.4.4.3.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.st1.4.4.3.1.1.1.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">based</span></span>
</span></span> <span class="ltx_text" id="S3.T2.st1.4.4.3.1.1.1.3"></span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.4.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.4.4.4.1">Point</span>-based (0D-mark)</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.4.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">(<em class="ltx_emph ltx_font_italic" id="S3.T2.st1.4.4.5.1">1D-Line</em>)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.5.5">
<td class="ltx_td ltx_align_left" id="S3.T2.st1.5.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.5.5.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.5.5.1.1.g1" src="extracted/5846816/figures/task_labels/Tsens.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.5.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Con-/Divergence</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.5.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.5.5.3.1">Line</span>-based (1D-mark)</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.5.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st1.5.5.4.1">1D-Hist</em>, <em class="ltx_emph ltx_font_italic" id="S3.T2.st1.5.5.4.2">2D-Sup</em>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st1.6.6">
<td class="ltx_td ltx_align_left" id="S3.T2.st1.6.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text" id="S3.T2.st1.6.6.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.T2.st1.6.6.1.1.g1" src="extracted/5846816/figures/task_labels/Tpart.png" width="30"/></span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.6.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Summarization</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.st1.6.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.st1.6.6.3.1">Area</span>-based (2D-mark)</td>
<td class="ltx_td ltx_align_left" id="S3.T2.st1.6.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st1.6.6.4.1">2D-Grid<sup class="ltx_sup" id="S3.T2.st1.6.6.4.1.1"> (-)</sup></em></td>
</tr>
</table>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.st1.8.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.T2.st1.9.2" style="font-size:90%;">high-level overview of the task-oriented VisRec strategy</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel" id="S3.T2.st2">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.st2.2">
<tr class="ltx_tr" id="S3.T2.st2.2.1">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Dims#</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.1.2.1">In<sub class="ltx_sub" id="S3.T2.st2.2.1.2.1.1">CP</sub></em><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.1.2.2">-Reg</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.1.3.1">In<sub class="ltx_sub" id="S3.T2.st2.2.1.3.1.1">CP</sub></em><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.1.3.2">-Stoch</em>; <em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.1.3.3">Out<sub class="ltx_sub" id="S3.T2.st2.2.1.3.3.1">dir,der</sub></em>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.st2.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.2.1.1">(1)</em></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.st2.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">(<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.2.2.1">PSc</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.2.2.2">Hist</em>)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.st2.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">(<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.2.3.1">PSc</em>)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.3.2.1">wDCP</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.3.2.2">Hist</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.3.3.1">SP</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.4.2.1">SPLOM</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.4.2.2">wDCP</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.4.2.3">Hist</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.4.3.1">SPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.5.2.1">PC</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.5.2.2">wDCP</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.5.2.3">Hist</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.5.3.1">(r)SPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.6.2.1">PC</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.6.2.2">wDCP</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.6.2.3">Hist</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.6.3.1">rSPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.7.2.1">PC</em>+<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.7.2.2">Hist</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.7.3.1">rSPLOM</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">7-9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.8.2.1">PC</em></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.8.3.1">PC</em></td>
</tr>
<tr class="ltx_tr" id="S3.T2.st2.2.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">10+</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">(<em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.9.2.1">PC</em>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.st2.2.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><em class="ltx_emph ltx_font_italic" id="S3.T2.st2.2.9.3.1">PSc</em></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.st2.3.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S3.T2.st2.4.2" style="font-size:90%;">Spatial expressivity</span></figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text" id="S3.SS3.p1.1.1" style="color:#000000;">We derived a common design space meeting the requirements of <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1.1">DG-1</span> by reviewing the findings from the content coding stage and extracting visualizations that appeared in at least two different applications.</span>
An overview of the visualization options in the resulting design space is presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F3" title="Figure 3 ‣ 3.2 Requirement Analysis ( L2 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>.
<span class="ltx_text" id="S3.SS3.p1.1.2" style="color:#000000;">However, not every visualization fitting the previous criterion ended up in the final design space.
For instance, we found four occurrences of Heatmaps, three Density Plots, and two Contour Line Plots.
We combined those into <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2.1">(weighted) Density Contour Plots</span> (<em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.2.2">wDCP</em>) since Heatmaps would have required a dense grid sampling strategy which we wanted to avoid (Con-1).
As previously outlined, data analyzed in VPSA typically consists of <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2.3">scalar parameter values</span> and often <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2.4">complex objects</span>, which cannot be described with a single variable without losing information.
Therefore, the design space is conceptually split into <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2.5">multi-dimensional, multi-variate (MDMV)</span> visualizations and <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2.6">complex objects</span> visualization options.
The final design space includes three 1D and three 2D complex object visualizations.
It is noteworthy that several reviewed applications included a detailed view of a 3D object.
However, these views were typically associated with a unique research contribution, thus making them uncommon by definition.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span class="ltx_text ltx_font_italic" id="S3.SS4.1.1">VisRec Strategy ( <span class="ltx_text ltx_font_sansserif ltx_font_upright ltx_framed ltx_framed_rectangle" id="S3.SS4.1.1.1" style="font-size:80%;border-color: #000000;">L4</span> )</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The coding table described in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.SS1" title="3.1 Method ( L1 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 3.1</span></a> provides the basis for our proposed VisRec strategy.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F4" title="Figure 4 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 4</span></a> shows a visually enhanced example of that table.
Each row represents an application and columns represent visualization options (MDMV and complex objects), tasks, and the underlying sampling strategy used to generate the runs.
The latter two form an <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.1">evaluation space<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S3.SS4.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib72" title="">72</a><span class="ltx_text ltx_font_upright" id="S3.SS4.p1.1.1.2.2">]</span></cite></span> over the visualization design space.
This setup enables filtering for applications that address specific tasks and discovering the visualizations and settings they employ to accomplish their objectives.
<span class="ltx_text" id="S3.SS4.p1.1.2" style="color:#000000;">A rigorous analysis of the papers in the meta design study and the subsequent content coding enabled us to derive the rules for the VisRec strategy summarized in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.T2.st1" title="II(a) ‣ TABLE II ‣ 3.3 Visualization Design Space ( L3 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">II(a)</span></a>.</span> Our findings indicate that each task has a unique and fundamental problem-solving approach, regardless of the underlying data type. In the following paragraphs, we will present these approaches and provide further insights into our research.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.12.6.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.10.5" style="font-size:90%;">A visually enhanced representation of the coding table.
For the current filter criteria <span class="ltx_text" id="S3.F4.6.1.1" style="position:relative; bottom:-2.7pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F4.6.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="27"/></span> and <span class="ltx_text" id="S3.F4.7.2.2" style="position:relative; bottom:-1.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="25" id="S3.F4.7.2.2.g1" src="x6.png" width="236"/></span>, applications #1 and #2 are filtered out.
Markers in MDMV visualization columns (white headers) contain information about how many dimensions were encoded (S)patially, if they encoded (C)olor or (B)rightness, and if they encoded
<span class="ltx_text ltx_inline-block" id="S3.F4.8.3.3" style="width:34.6pt;position:relative; bottom:-3.8pt;"><svg height="10.93" overflow="visible" version="1.1" width="166.81"><g transform="translate(0,10.93) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#74AF7C" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.8.3.3.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-21.14,-5.37)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">inputs </text></g></g></g></svg></span>,
<span class="ltx_text ltx_inline-block" id="S3.F4.9.4.4" style="width:65.6pt;position:relative; bottom:-3.8pt;"><svg height="11.07" overflow="visible" version="1.1" width="209.73"><g transform="translate(0,11.07) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E8B454" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.9.4.4.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-42.6,-5.53)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">direct outputs </text></g></g></g></svg></span>,
or <span class="ltx_text ltx_inline-block" id="S3.F4.10.5.5" style="width:71.6pt;position:relative; bottom:-3.8pt;"><svg height="11.07" overflow="visible" version="1.1" width="218.04"><g transform="translate(0,11.07) scale(1,-1)"><g class="makebox" transform="translate(-62.27,-4.25)"><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E59F94" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,8.4405700844057) scale(1, -1)"><foreignobject height="8.4405700844057" overflow="visible" width="62.266500622665"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S3.F4.10.5.5.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-46.75,-5.53)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">derived outputs </text></g></g></g></svg></span>.
</span></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F5.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F5.32.13.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F5.24.12" style="font-size:90%;">Left:<span class="ltx_text ltx_font_medium" id="S3.F5.22.10.10"> Overview of RSVP system for VPSA. <span class="ltx_text ltx_font_italic" id="S3.F5.22.10.10.11">System left</span>: Data-Selection Panel <span class="ltx_text" id="S3.F5.13.1.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.13.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="27"/></span>.
Dimensional markers in the data panel <span class="ltx_text" id="S3.F5.14.2.2.2" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="30" id="S3.F5.14.2.2.2.g1" src="x13.png" width="5"/></span> represent the user-provided CSV data.
Those markers can be dragged into the channel fields in the selection panel <span class="ltx_text" id="S3.F5.15.3.3.3" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="30" id="S3.F5.15.3.3.3.g1" src="x14.png" width="5"/></span>, where white MDMV markers change their underlying colors. <span class="ltx_text ltx_font_italic" id="S3.F5.22.10.10.12">System center</span>: the Overview Area <span class="ltx_text" id="S3.F5.16.4.4.4" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.16.4.4.4.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="27"/></span> displays all available visualizations from the design space with user-selected data. The colors used in the visualizations match the marker colors in the selection panel.
<span class="ltx_text ltx_font_italic" id="S3.F5.22.10.10.13">System top-right</span>: the VisRec Interface <span class="ltx_text" id="S3.F5.17.5.5.5" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.17.5.5.5.g1" src="extracted/5846816/figures/teaser_labels/VRI.png" width="27"/></span> is comprised of several components.
Selecting tasks in the taskbar <span class="ltx_text" id="S3.F5.18.6.6.6" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="30" id="S3.F5.18.6.6.6.g1" src="x15.png" width="5"/></span> opens the guidance panel <span class="ltx_text" id="S3.F5.19.7.7.7" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="30" id="S3.F5.19.7.7.7.g1" src="x16.png" width="5"/></span> and injects recommendations directly into the overview area <span class="ltx_text" id="S3.F5.20.8.8.8" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.20.8.8.8.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="27"/></span> and the selection panel <span class="ltx_text" id="S3.F5.21.9.9.9" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="30" id="S3.F5.21.9.9.9.g1" src="x17.png" width="5"/></span> in the form of colored frames.
<span class="ltx_text ltx_font_italic" id="S3.F5.22.10.10.14">System bottom:</span> the Visualization Dashboard <span class="ltx_text" id="S3.F5.22.10.10.10" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.22.10.10.10.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="27"/></span> enables users to perform interactive data analysis. Visualizations can be copied from the overview area into the dashboard.
<br class="ltx_break"/></span>Right:<span class="ltx_text ltx_font_medium" id="S3.F5.24.12.12"> Dashboard instances <span class="ltx_text" id="S3.F5.23.11.11.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.23.11.11.1.g1" src="extracted/5846816/figures/teaser_labels/Ex1.png" width="27"/></span> - <span class="ltx_text" id="S3.F5.24.12.12.2" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S3.F5.24.12.12.2.g1" src="extracted/5846816/figures/teaser_labels/Ex3.png" width="27"/></span> showcase examples created from different data sets in RSVP within minutes. </span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.2">Achieving <span class="ltx_text ltx_font_italic" id="S3.SS4.p2.2.3">optimization</span> (<span class="ltx_text" id="S3.SS4.p2.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p2.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>) requires providing the best possible overview of objects and parameters. Therefore, without an objective function, the requirement for overview (Req-2) is not just a general feature but a necessity for optimization.
In the context of MDMV, providing an overview means offering as much information about the data as possible while considering visual clutter, data occlusion, and cognitive overload.
Based on the Mackinlay criteria<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib35" title="">35</a>]</cite>, we refer to the strategy of presenting spatial information clearly and concisely as “spatial expressivity” (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.T2.st2" title="II(b) ‣ TABLE II ‣ 3.3 Visualization Design Space ( L3 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">II(b)</span></a> for a summary of its high-level rules).
Providing an overview of complex objects is typically accomplished through overplotted function graphs (1D) or presenting options in a grid layout (2D).
Optimization often forms the basis for other, more specific tasks, which extend <span class="ltx_text" id="S3.SS4.p2.2.2" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p2.2.2.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>’s overview with additional visual features or views.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">Affiliating solutions is the primary approach for <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.2">fitting</span> tasks (<span class="ltx_text" id="S3.SS4.p3.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p3.1.1.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span>).
The color channel is often used to represent the output of an objective function to establish connections between different MDMV visualizations.
When dealing with 2D objects, we discerned a preference for juxtaposed comparison views.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.4">When <span class="ltx_text ltx_font_italic" id="S3.SS4.p4.4.5">uncertainty</span> (<span class="ltx_text" id="S3.SS4.p4.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p4.1.1.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span>) was quantified by a numerical parameter, the color channel was used to display it, preferably using black or white at opposite ends of the spectrum<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib73" title="">73</a>]</cite>.
If the color channel was already used for other purposes, the opacity channel was used instead<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib74" title="">74</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib75" title="">75</a>]</cite>.
If the underlying distribution was available as a 1D object, selected items were displayed as Boxplots<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib77" title="">77</a>]</cite>.
Both <span class="ltx_text" id="S3.SS4.p4.2.2" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p4.2.2.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span> and <span class="ltx_text" id="S3.SS4.p4.3.3" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p4.3.3.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span> worked typically on top of visualizations suggested by <span class="ltx_text" id="S3.SS4.p4.4.4" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p4.4.4.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">To visually distinguish <span class="ltx_text ltx_font_italic" id="S3.SS4.p5.1.2">outliers</span> (<span class="ltx_text" id="S3.SS4.p5.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p5.1.1.g1" src="extracted/5846816/figures/task_labels/Tout.png" width="30"/></span>) from other data points, visualizations often used the smallest available marks for a given data type. This technique helped separate outliers from the rest of the data.
Six applications out of eight supporting this task used Scatterplots or Scatterplot Matrices (0D-mark) for MDMV visualizations (the remaining two<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib1" title="">1</a>]</cite> using bespoke visualizations), and four applications out of five encoding 1D objects used overplotted Linegraphs (1D-mark).</p>
</div>
<div class="ltx_para" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.1">In <span class="ltx_text ltx_font_italic" id="S3.SS4.p6.1.2">sensitivity</span> tasks (<span class="ltx_text" id="S3.SS4.p6.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p6.1.1.g1" src="extracted/5846816/figures/task_labels/Tsens.png" width="30"/></span>), the objective is to identify parameter settings with either low or high impact on model outputs.
Line-based visualizations help identify converging (dense) or diverging (sparse) sections, which makes Density Contour Plots and Parallel Coordinates the recommended choices for MDMV visualizations.
Linegraphs are effective for identifying local sensitivities in 1D objects, while Cumulative Histograms can help in finding global thresholds.
Superpositioned views support determining sensitive regions for selected 2D objects.</p>
</div>
<div class="ltx_para" id="S3.SS4.p7">
<p class="ltx_p" id="S3.SS4.p7.1">The <span class="ltx_text ltx_font_italic" id="S3.SS4.p7.1.2">partitioning</span> task (<span class="ltx_text" id="S3.SS4.p7.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p7.1.1.g1" src="extracted/5846816/figures/task_labels/Tpart.png" width="30"/></span>) tries to identify different types of model behavior, especially when there is no objective function to guide the analysis.
The key is to find boundaries that separate groups that behave similarly.
Histograms are commonly used because they abstract away details and help to focus on the bigger picture.
When analyzing 2D objects, a Grid Layout showing elements within a selected range but hiding filtered ones can achieve a similar effect while still providing detailed information about the individual items.</p>
</div>
<div class="ltx_para" id="S3.SS4.p8">
<p class="ltx_p" id="S3.SS4.p8.6">From a high-level perspective, our findings suggest that tasks
<span class="ltx_text" id="S3.SS4.p8.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>,
<span class="ltx_text" id="S3.SS4.p8.2.2" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.2.2.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span>, and
<span class="ltx_text" id="S3.SS4.p8.3.3" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.3.3.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span> involve encoding specific <span class="ltx_text ltx_font_italic" id="S3.SS4.p8.6.7">channels</span>, whereas addressing
<span class="ltx_text" id="S3.SS4.p8.4.4" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.4.4.g1" src="extracted/5846816/figures/task_labels/Tout.png" width="30"/></span>,
<span class="ltx_text" id="S3.SS4.p8.5.5" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.5.5.g1" src="extracted/5846816/figures/task_labels/Tsens.png" width="30"/></span>, and
<span class="ltx_text" id="S3.SS4.p8.6.6" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S3.SS4.p8.6.6.g1" src="extracted/5846816/figures/task_labels/Tpart.png" width="30"/></span> requires selecting appropriate <span class="ltx_text ltx_font_italic" id="S3.SS4.p8.6.8">marks</span>.
Within the context of our research, the specific marks and channels were even distinct for the various analysis tasks
(see MDMV-column in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.T2.st1" title="II(a) ‣ TABLE II ‣ 3.3 Visualization Design Space ( L3 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">II(a)</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">RSVP System</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">Rapid Suggestive Visualization Prototyping</span> (RSVP) system is a practical implementation of the findings from the meta design study.
In this section, we present a walk-through of the RSVP system, provide some technical details, and offer a qualitative result inspection about how the system aligns with previously outlined design goals and requirements.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span class="ltx_text ltx_font_italic" id="S4.SS1.1.1">Walk-through</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.4"><span class="ltx_text" id="S4.SS1.p1.4.5" style="color:#000000;">RSVP enables users without specific visualizations or programming skills to design dashboards tailored to their specific data and needs regarding VPSA.
The user interface tightly integrates an overview of available visualization options with an unobtrusive recommendation strategy to foster transparency and learnability.</span> <span class="ltx_text" id="S4.SS1.p1.4.6" style="color:#000000;">RSVP consists of four main components, as outlined in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>:</span> the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.4.7">Data-Selection Panel</span> <span class="ltx_text" id="S4.SS1.p1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p1.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="30"/></span>, the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.4.8">Overview Area</span> <span class="ltx_text" id="S4.SS1.p1.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p1.2.2.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span>, the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.4.9">VisRec Interface</span> <span class="ltx_text" id="S4.SS1.p1.3.3" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p1.3.3.g1" src="extracted/5846816/figures/teaser_labels/VRI.png" width="30"/></span>, and the <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.4.10">Visualization Dashboard</span> <span class="ltx_text" id="S4.SS1.p1.4.4" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p1.4.4.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span>.
These components are shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 5</span></a> and will be described in detail in the following sections.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">DATA-SELECTION PANEL <span class="ltx_text" id="S4.SS1.p2.1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p2.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="30"/></span></span> :
Data gets loaded in a simple CSV format directly into the textfield in the data panel <span class="ltx_text" id="S4.SS1.p2.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p2.2.2.g1" src="x18.png" width="6"/></span>.
The header must contain the names of the dimensions, and rows contain the details about the individual runs, namely the parameter settings and the results.
Once loaded, data dimensions are represented in the form of draggable markers (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F6" title="Figure 6 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 6</span></a>).
The color of a marker represents the underlying data type.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="407" id="S4.F6.g1" src="x19.png" width="1136"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.6.3.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.4.2" style="font-size:90%;">The Data-Selection Panel <span class="ltx_text" id="S4.F6.3.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S4.F6.3.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="27"/></span> and parts of the Overview Area <span class="ltx_text" id="S4.F6.4.2.2" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S4.F6.4.2.2.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="27"/></span>. Dimension is actively moved into the Color field. The interactive switch for the Scatterplots x-axis shows the three available dimensions from Spatial field (S1). </span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">RSVP detects three different data types: numerical parameters (scalar values, white), 1D objects (arrays, blue), and 2D objects (links to image files, dark blue).</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">The markers can be dragged and dropped into channel fields in the adjacent selection panel.
Available channels for direct data encoding are spatial, color, and opacity (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.SS3" title="3.3 Visualization Design Space ( L3 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 3.3</span></a>).
RSVP offers two spatial channel fields, S1 and S2, so MDMV visualizations split along
inputs
and
outputs
can be displayed simultaneously in the overview area using small multiples displays (SMDs).
MDMV markers, when placed into channel fields, adjust their color to correspond with their appearance in the overview area, enhancing orientation.
Complex object markers must be positioned within the object field to be visible in the overview area.
</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.3">Please note that the colors utilized in Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S2.F2" title="Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.F4" title="Figure 4 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">4</span></a> are selected to align with the colors employed in the RSVP system for markers in channel fields
Spatial S1, Spatial S2, and Color.
These fields are frequently used to represent <span class="ltx_text ltx_inline-block" id="S4.SS1.p5.1.1" style="width:37.9pt;position:relative; bottom:-3.9pt;"><svg height="12.15" overflow="visible" version="1.1" width="185.34"><g transform="translate(0,12.15) scale(1,-1)"><g class="makebox" transform="translate(-69.19,-4.73)"><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#74AF7C" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.1.1.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-23.48,-5.97)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">inputs </text></g></g></g></svg></span>, <span class="ltx_text ltx_inline-block" id="S4.SS1.p5.2.2" style="width:72.4pt;position:relative; bottom:-3.9pt;"><svg height="12.3" overflow="visible" version="1.1" width="233.04"><g transform="translate(0,12.3) scale(1,-1)"><g class="makebox" transform="translate(-69.19,-4.73)"><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E8B454" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.2.2.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-47.33,-6.15)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">direct outputs </text></g></g></g></svg></span>, and <span class="ltx_text ltx_inline-block" id="S4.SS1.p5.3.3" style="width:79.1pt;position:relative; bottom:-3.9pt;"><svg height="12.3" overflow="visible" version="1.1" width="242.26"><g transform="translate(0,12.3) scale(1,-1)"><g class="makebox" transform="translate(-69.19,-4.73)"><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.1.1.1">\@setfpsbit</span></foreignobject></g><text color="#E59F94" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.2.2.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.2.2.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.2.2.2.3">\@setfpsbit</span></foreignobject></g>8</text></g><g transform="translate(0,0)"><g transform="translate(0,9.4091600940916) scale(1, -1)"><foreignobject height="9.4091600940916" overflow="visible" width="69.18500069185"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.3.3.1">\@setfpsbit</span></foreignobject></g><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">2<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.4.4.2.1">\@setfpsbit</span></foreignobject></g>4<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.4.4.2.2">\@setfpsbit</span></foreignobject></g>1<g transform="translate(0,1.383700013837) scale(1, -1)"><foreignobject height="1.383700013837" overflow="visible" width="1.383700013837"><span class="ltx_ERROR undefined" id="S4.SS1.p5.3.3.1.pic1.4.4.2.3">\@setfpsbit</span></foreignobject></g>8</text></g></g><g class="makebox" transform="translate(-51.95,-6.15)"><g transform="translate(-0.69,0)"><text color="#FFFFFF" fill="black" transform="scale(1, -1)" x="0" y="0">derived outputs </text></g></g></g></svg></span>, respectively.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.1">OVERVIEW AREA <span class="ltx_text" id="S4.SS1.p6.1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p6.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span></span> : displays all visualizations from the design space (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F3" title="Figure 3 ‣ 3.2 Requirement Analysis ( L2 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>) in a 2-dimensional layout, directly encoding user-provided data from the selection panel <span class="ltx_text" id="S4.SS1.p6.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p6.2.2.g1" src="x20.png" width="6"/></span>.
The top area contains MDMV visualizations, and the bottom displays complex object visualizations.
With the exception of Histograms, MDMV visualization options consist of a Small Multiple Display (SMD) and a detail view <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib63" title="">63</a>]</cite>.
Selecting a small multiple will load the according data settings in the detail view for this visualization.
The SMDs show subsets and combinations of user-selected dimensions that could not be presented simultaneously otherwise.
The layout of the SMDs tries to follow the same rules for all the visualization options incorporating it, depicted in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F7" title="Figure 7 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 7</span></a>.
Each view in a particular column encodes the same spatial dimensions.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F7.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.7.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S4.F7.8.2" style="font-size:90%;">The SMD behavior using Parallel Coordinates as an example. The dark boxes indicate the numbers of encoded dimensions.
Configurations <span class="ltx_text" id="S4.F7.8.2.1" style="color:#FFFFFF;background-color:#808080;">4</span> and <span class="ltx_text" id="S4.F7.8.2.2" style="color:#FFFFFF;background-color:#808080;">5</span> highlight the differences for the (S1+S2)-columns.
Configs <span class="ltx_text" id="S4.F7.8.2.3" style="color:#FFFFFF;background-color:#808080;">7a</span> and <span class="ltx_text" id="S4.F7.8.2.4" style="color:#FFFFFF;background-color:#808080;">7b</span> encode seven dimensions slightly differently, resulting in additional rows.
Configuration <span class="ltx_text" id="S4.F7.8.2.5" style="color:#FFFFFF;background-color:#808080;"> 8 </span> is displayed with the according detail view for the currently selected small multiple.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">The first column encodes dimensions from the first spatial field (S1), and the second column from the second spatial field (S2).
The third column encodes the combination of both spatial fields (S1+S2) (see the highlights in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F7" title="Figure 7 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 7</span></a> configurations <span class="ltx_text" id="S4.SS1.p7.1.1" style="color:#FFFFFF;background-color:#808080;">4</span> and <span class="ltx_text" id="S4.SS1.p7.1.2" style="color:#FFFFFF;background-color:#808080;">5</span> for an example).
Our literature analysis did not reveal an instance where inputs and outputs were combined into a single <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.3">(r)SPLOM</span>.
Therefore, <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.4">SPLOM</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.5">rSPLOM</span> do not provide a third column to avoid unnecessary rendering overhead.
The first row in the SMD encodes spatial fields only, where the various small multiples are displayed with categorical colors that link them visually to the underlying spatial fields in the selection panel.
Additional rows encode the selections for the color and opacity channels.
If either channel gets encoded more than once, multiple additional rows will be displayed (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F7" title="Figure 7 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 7</span></a>, configurations <span class="ltx_text" id="S4.SS1.p7.1.6" style="color:#FFFFFF;background-color:#808080;">6</span> through <span class="ltx_text" id="S4.SS1.p7.1.7" style="color:#FFFFFF;background-color:#808080;"> 8 </span> show this particular behavior for different encodings).</p>
</div>
<div class="ltx_para" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.1">If a visualization can only display some of the dimensions from the selection panel, interactive switches will appear so the user can adapt them during analysis.
Examples of such situations include cases where <span class="ltx_text ltx_font_italic" id="S4.SS1.p8.1.2">SP</span> or <span class="ltx_text ltx_font_italic" id="S4.SS1.p8.1.3">wDCP</span> have to encode three or more spatial dimensions (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F6" title="Figure 6 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 6</span></a>), or any visualization has to encode more than one dimension with the color or opacity channel (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F9" title="Figure 9 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 9</span></a>).
A panel at the top of <span class="ltx_text" id="S4.SS1.p8.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p8.1.1.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span> allows for global adjustments of the visualizations, like the number of pre-selected data points in the overview for comparison purposes or the color scheme for dimensions encoded in the color channel.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S4.SS1.p9">
<p class="ltx_p" id="S4.SS1.p9.6"><span class="ltx_text ltx_font_bold" id="S4.SS1.p9.1.1">VISREC INTERFACE <span class="ltx_text" id="S4.SS1.p9.1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p9.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/VRI.png" width="30"/></span></span> : consists of the <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.6.7">taskbar</span> <span class="ltx_text" id="S4.SS1.p9.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p9.2.2.g1" src="x22.png" width="6"/></span> and the <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.6.8">guidance panel</span> <span class="ltx_text" id="S4.SS1.p9.3.3" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p9.3.3.g1" src="x23.png" width="6"/></span>, and spans over the <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.6.9">overview area</span> <span class="ltx_text" id="S4.SS1.p9.4.4" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p9.4.4.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span> and the <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.6.10">selection panel</span> <span class="ltx_text" id="S4.SS1.p9.5.5" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p9.5.5.g1" src="x24.png" width="6"/></span>.
RSVP can provide recommendations for up to four tasks simultaneously.
When seeking VisRec guidance, <span class="ltx_text" id="S4.SS1.p9.6.6" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p9.6.6.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span> is automatically selected, as it typically serves as the foundation for other tasks.
Each task is associated with a unique categorical color (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.T1" title="TABLE I ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Table I</span></a>), which makes it possible to track the recommendations for a specific task across the different sections.</p>
</div>
<div class="ltx_para" id="S4.SS1.p10">
<p class="ltx_p" id="S4.SS1.p10.6">The taskbar <span class="ltx_text" id="S4.SS1.p10.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p10.1.1.g1" src="x25.png" width="6"/></span> in the top right shows the tasks for which users can seek recommendations.
Hovering over a specific task provides a brief explanation about it.
Selecting one of the tasks triggers the recommendation process.
Recommendations are provided as colored frames around the visualization types and single instances in the small multiples in the overview area <span class="ltx_text" id="S4.SS1.p10.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p10.2.2.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span>.
For tasks optimization <span class="ltx_text" id="S4.SS1.p10.3.3" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p10.3.3.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>, fitting <span class="ltx_text" id="S4.SS1.p10.4.4" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p10.4.4.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span>, and uncertainty <span class="ltx_text" id="S4.SS1.p10.5.5" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p10.5.5.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span>, dimensions have to be encoded according to the channels supporting the respective tasks (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.T2.st1" title="II(a) ‣ TABLE II ‣ 3.3 Visualization Design Space ( L3 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">II(a)</span></a>).
RSVP frames the channel fields in the selection panel <span class="ltx_text" id="S4.SS1.p10.6.6" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p10.6.6.g1" src="x26.png" width="6"/></span> with the respective task color and provides context information on which kind of dimensions are supposed to be encoded (<span class="ltx_text ltx_font_italic" id="S4.SS1.p10.6.7">inputs</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p10.6.8">outputs</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p10.6.9">derived</span> values and values <span class="ltx_text ltx_font_italic" id="S4.SS1.p10.6.10">quantifying uncertainty</span>).</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F8.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S4.F8.3.2" style="font-size:90%;">Complementary view showing the complex objects for the recommendations in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p11">
<p class="ltx_p" id="S4.SS1.p11.2">The Guidance Panel <span class="ltx_text" id="S4.SS1.p11.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS1.p11.1.1.g1" src="x28.png" width="6"/></span> provides helpful additional information regarding the recommendations.
It consists of three parts.
On top is a list of the recommended visualization types.
This list links to the respective options in the Overview Area <span class="ltx_text" id="S4.SS1.p11.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p11.2.2.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span>.
The middle section contains explanations and background information on how recommended visualizations are supposed to support respective tasks.
At the bottom are hints on how to interact with the visualization dashboard to solve these tasks.</p>
</div>
<div class="ltx_para" id="S4.SS1.p12">
<p class="ltx_p" id="S4.SS1.p12.4">Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#S4.F8" title="Figure 8 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">8</span></a> show an example recommendation for tasks <span class="ltx_text" id="S4.SS1.p12.1.1" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p12.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="30"/></span>, <span class="ltx_text" id="S4.SS1.p12.2.2" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p12.2.2.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="30"/></span>, <span class="ltx_text" id="S4.SS1.p12.3.3" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p12.3.3.g1" src="extracted/5846816/figures/task_labels/Tunc.png" width="30"/></span>, and <span class="ltx_text" id="S4.SS1.p12.4.4" style="position:relative; bottom:-3.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p12.4.4.g1" src="extracted/5846816/figures/task_labels/Tout.png" width="30"/></span>.
Further examples for recommendations are provided in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.SS2" title="5.2 Case Study I: Crystal Powder Diffraction ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 5.2</span></a>, the supplemental material, and the accompanying video.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S4.SS1.p13">
<p class="ltx_p" id="S4.SS1.p13.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p13.1.1">VISUALIZATION DASHBOARD <span class="ltx_text" id="S4.SS1.p13.1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p13.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span> :</span> visualizations can be copied from the Overview Area <span class="ltx_text" id="S4.SS1.p13.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p13.2.2.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span> into the Visualization Dashboard <span class="ltx_text" id="S4.SS1.p13.3.3" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS1.p13.3.3.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span>.
The dashboard allows the combination of an arbitrary number of visualizations to perform multi-view analysis.
Individual visualizations can even be combined into more complex ones.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F9" title="Figure 9 ‣ 4.1 Walk-through ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 9</span></a> shows an example where Point Scales, Histograms, and interactive sliders are combined into parallel histograms.
A slider appears for each dimension loaded into the dashboard, providing a consistent way of filtering data points across all visualizations.
The color of the slider matches the color of the dimension in the selection panel.
Selecting a single data point within a visualization will also highlight the same element in all the other visualizations in the dashboard.</p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F9.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F9.6.2.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S4.F9.2.1" style="font-size:90%;">Visualization Dashboard <span class="ltx_text" id="S4.F9.2.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S4.F9.2.1.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="27"/></span> example in <em class="ltx_emph ltx_font_italic" id="S4.F9.2.1.2">edit</em>-mode with the single-view editor (right) opened for the <span class="ltx_text ltx_font_italic" id="S4.F9.2.1.3">Point Scales</span> used in the parallel histograms (green). </span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p14">
<p class="ltx_p" id="S4.SS1.p14.1">The dashboard offers two modes, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p14.1.1">edit</em> and <em class="ltx_emph ltx_font_italic" id="S4.SS1.p14.1.2">analyze</em>.
In <span class="ltx_text ltx_font_italic" id="S4.SS1.p14.1.3">edit</span>-mode, hovering over a visualization or slider reveals a context menu that allows for manipulating this particular element, like moving, resizing, or changing its attributes.
The attributes can be edited via the single-view editor.
When in <span class="ltx_text ltx_font_italic" id="S4.SS1.p14.1.4">analyze mode</span>, dashboard design and attributes can not be changed, and the user can focus on analyzing the dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span class="ltx_text ltx_font_italic" id="S4.SS2.1.1">Technical Aspects</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">RSVP is a single-page web application built with standard web technologies (HTML, CSS, JavaScript).
It operates without a backend; all computations occur within the browser.
The application leverages several helper libraries for various tasks, including parsing CSV data<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.papaparse.com" title="">https://www.papaparse.com</a></span></span></span>, rendering HTML templates<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://underscorejs.org" title="">https://underscorejs.org</a></span></span></span>, enabling drag-and-drop functionality<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bevacqua.github.io/dragula/" title="">https://bevacqua.github.io/dragula/</a></span></span></span> in the data selection panel <span class="ltx_text" id="S4.SS2.p1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS2.p1.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="30"/></span>, and implementing dragging and resizing<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://interactjs.io" title="">https://interactjs.io</a></span></span></span> as well as the data sliders<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://refreshless.com/nouislider/" title="">https://refreshless.com/nouislider/</a></span></span></span> in the visualization dashboard <span class="ltx_text" id="S4.SS2.p1.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS2.p1.2.2.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span>.
MDMV visualizations and 1D complex object visualizations are generated using the Vega visualization toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib79" title="">79</a>]</cite>, while 2D complex objects are implemented using plain HTML and CSS.
The recommendation algorithm is designed as a series of cascading rules, following a similar approach outlined in BOZ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib41" title="">41</a>]</cite>.
Further technical details about the implementation of the VisRec strategy can be found in the supplemental material.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span class="ltx_text ltx_font_italic" id="S4.SS3.1.1">Qualitative Result Inspection (QRI)</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In this section, we provide the rationales of how our proposed solution fulfills the requirements and design goals outlined in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.SS2" title="3.2 Requirement Analysis ( L2 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 3.2</span></a>.
The two Key Goals <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">Low Cost (Key-I)</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.2">High Trust (Key-II)</span> will be discussed in more detail in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S6.SS1" title="6.1 Findings ‣ 6 Discussion ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 6.1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.2" style="color:#000000;">Easy setup (Req-1):</span> RSVP is a web application <span class="ltx_text" id="S4.SS3.p2.1.3" style="color:#000000;">that can be used without an account.</span> It requires a simple CSV file as input, which can be created with any modern spreadsheet software.
Further, the system does not require a specific sampling strategy, but the user can choose the most feasible one.
In the dashboard <span class="ltx_text" id="S4.SS3.p2.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS3.p2.1.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span>, visualizations and sliders for filtering can be arranged and resized via drag-and-drop.
All these aspects ensure an <span class="ltx_text" id="S4.SS3.p2.1.4" style="color:#000000;">easy setup</span> for the user.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.5"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.5.6" style="color:#000000;">Overview (Req-2): </span> RSVP provides an overview of basically all elements associated with user interaction.
It shows the user-provided data dimensions in the data panel <span class="ltx_text" id="S4.SS3.p3.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS3.p3.1.1.g1" src="x30.png" width="6"/></span> and all encodable channels in the selection panel <span class="ltx_text" id="S4.SS3.p3.2.2" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS3.p3.2.2.g1" src="x31.png" width="6"/></span>.
The taskbar <span class="ltx_text" id="S4.SS3.p3.3.3" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="33" id="S4.SS3.p3.3.3.g1" src="x32.png" width="6"/></span> presents the available analysis tasks, and the overview area <span class="ltx_text" id="S4.SS3.p3.4.4" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS3.p3.4.4.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="30"/></span> shows all the available visualizations <span class="ltx_text" id="S4.SS3.p3.5.7" style="color:#000000;">directly encoding data</span> .
This enables a quick overview of the parameters and complex objects from many different perspectives.
Visualizations offered by RSVP are extracted from applications mainly featuring <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.5.8">global-to-local</span> navigation strategies.
<span class="ltx_text" id="S4.SS3.p3.5.5" style="color:#000000;">Hence, visualization dashboards <span class="ltx_text" id="S4.SS3.p3.5.5.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS3.p3.5.5.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span> composed of these visualization options feature an initial overview of the data by design. </span></p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.2" style="color:#000000;">Navigating Parameter Space (Req-3): </span> Available operations for navigation during an analytical session <span class="ltx_text" id="S4.SS3.p4.1.1" style="color:#000000;">in the visualization dashboard <span class="ltx_text" id="S4.SS3.p4.1.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S4.SS3.p4.1.1.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span></span> are filtering, zoom, and selection of individual runs, therefore following Shneiderman’s information-seeking mantra (“Overview first, zoom and filter, then details-on-demand”)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib80" title="">80</a>]</cite>.
To navigate the design space, the system presents MDMV visualizations in small multiples and large singles, akin to the design of van den Elzen and van Wijk <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib63" title="">63</a>]</cite> for visualization exploration.
RSVP supports the user in navigating the vast design space by suggesting appropriate visualizations to solve user-defined high-level tasks.
This support also includes suggestions for navigating the parameter space by indicating to the user how to encode the various dimensions in the parameter space for visual exploration.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1" style="color:#000000;">Analytical Task Support (Req-4):</span> RSVP supports domain scientists in solving analytical tasks by indicating which visualizations to choose and how to encode them.
It further informs the users how to interact within the dashboard to achieve those tasks.</p>
</div>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p6.1.1" style="color:#000000;">Simple yet expressive (DG-1): </span> Our approach focused on creating a design space that balances simplicity for novice users with the expressiveness needed for complex analytical tasks.
Instead of favoring complicated special purpose views, our approach focuses on finding common and likely easier-to-understand visualization options, which can further be composed into complex multi-view visualizations, supporting specific, high-level tasks.</p>
</div>
<div class="ltx_para" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p7.1.1">Activate Domain Knowledge (DG-2):</span>
Practical recommendations for activating domain knowledge are using terminology and visualizations familiar to users<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib30" title="">30</a>]</cite>.
Since RSVP is domain-agnostic, it avoids using domain-specific terminology in labels or explanations.
However, users are likely familiar with the terminology used in the data they provide.
Moreover, the dimensions and data points are likely meaningful to them.
The key idea is that the data will initially help improve understanding of the various visualizations.
RSVP presents all available visualizations immediately encoded with the user-provided data.
This might not only improve understanding but seeing the data through different lenses of multiple visualizations might provide immediate insights or raise exciting questions<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib81" title="">81</a>]</cite>.
Since several provided visualizations (like scatterplots, histograms, and line charts) are the subject of teaching within the K-12 curriculum<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib82" title="">82</a>]</cite>, users are likely familiar with at least some of them.</p>
</div>
<div class="ltx_para" id="S4.SS3.p8">
<p class="ltx_p" id="S4.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p8.1.1">Promote Learning (DG-3)</span>:
RSVP promotes learning about new visualizations by positioning similar visualization options closer together in the overview area and encoding them directly with user-provided data.
The idea is to make it easier for users to spot and compare similarities and differences between known and previously unknown visualizations.
It should also improve the understanding of familiar visualizations in the context of the current problem.
Furthermore, to make learning about visualizations even more accessible, the complexity of each visualization is initially reduced and then revealed progressively<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib29" title="">29</a>]</cite> when additional dimensions get added.
As presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.F10" title="Figure 10 ‣ 4.3 Qualitative Result Inspection (QRI) ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 10</span></a>, when only a single dimension is encoded (visualizations requiring at least two spatial dimensions encode the same dimension on both axes), several MDMV-visualization options look very similar.
Adding a second dimension shows how previously similar visualizations begin to differ from each other.
Adding a third dimension further distinguishes visualizations capable of spatially encoding more than two dimensions (like SPLOM or PC).
After each step, the users can familiarize themselves with the more complicated visualizations.
To avoid misunderstandings caused by non-self-descriptive tasks, our system explains each task when hovering over them in the taskbar. Additionally, RSVP explains to users why recommended visualizations are supposed to support specific tasks.</p>
</div>
<figure class="ltx_figure" id="S4.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="372" id="S4.F10.g1" src="x33.png" width="1172"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F10.4.2.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" id="S4.F10.2.1" style="font-size:90%;">
RSVP promotes learning by adjacency and progressive reveal.
Columns show which visualizations are adjacent in the Visualization Overview <span class="ltx_text" id="S4.F10.2.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S4.F10.2.1.1.g1" src="extracted/5846816/figures/teaser_labels/OVA.png" width="27"/></span> (the arrows on top show further adjacencies in the 2-dimensional layout) and how they are supposed to show similarities and differences between adjacent visualizations.
Rows show how the complexity of visualizations is progressively revealed when adding more dimensions.
</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p9">
<p class="ltx_p" id="S4.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p9.1.1">Provide Transparency (DG-4):</span> These explanations are not only helpful for learning but additionally provide transparency and should ultimately support building trust in the system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib33" title="">33</a>]</cite>.
Recommendations are presented in a non-obtrusive way.
RSVP presents all available visualizations for a given datatype and highlights recommended ones (a guidance strategy known as “orientation”)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib83" title="">83</a>]</cite>.
This approach allows users to draw conclusions about recommended visualizations and make alternative decisions if necessary.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Evaluation</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The three most prevalent evaluation strategies we found in the meta design study, reflecting general evaluation trends in the visualization community<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib84" title="">84</a>]</cite>, are <span class="ltx_text ltx_font_italic" id="S5.p1.1.1" style="color:#000000;">case studies</span> , <span class="ltx_text ltx_font_italic" id="S5.p1.1.2" style="color:#000000;">usability studies</span> , and <span class="ltx_text ltx_font_italic" id="S5.p1.1.3">qualitative result inspections (QRI</span>)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib85" title="">85</a>]</cite>.
The latter we already discussed in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S4.SS3" title="4.3 Qualitative Result Inspection (QRI) ‣ 4 RSVP System ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">subsection 4.3</span></a>.
In this section, we will present the results of a usability study and two real-world case studies from different problem domains utilizing RSVP.
Additionally, the supplemental material presents and discusses another case study that was conducted using an earlier prototype of RSVP.
</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span class="ltx_text ltx_font_italic" id="S5.SS1.1.1">Usability Study: Edge Detection Algorithm</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">For this study, we recruited four undergraduate students majoring in media informatics and two graduate students specializing in computer graphics.
Our choice for the number of study participants is based on recommendations for determining the sample size for usability tests<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib87" title="">87</a>]</cite>.
The recruits, four males and two females, were between 21 and 36 years old (<math alttext="\mu=25.83,\sigma=5.01" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.2"><semantics id="S5.SS1.p1.1.m1.2a"><mrow id="S5.SS1.p1.1.m1.2.2.2" xref="S5.SS1.p1.1.m1.2.2.3.cmml"><mrow id="S5.SS1.p1.1.m1.1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S5.SS1.p1.1.m1.1.1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.1.1.2.cmml">μ</mi><mo id="S5.SS1.p1.1.m1.1.1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.1.m1.1.1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.1.1.3.cmml">25.83</mn></mrow><mo id="S5.SS1.p1.1.m1.2.2.2.3" xref="S5.SS1.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="S5.SS1.p1.1.m1.2.2.2.2" xref="S5.SS1.p1.1.m1.2.2.2.2.cmml"><mi id="S5.SS1.p1.1.m1.2.2.2.2.2" xref="S5.SS1.p1.1.m1.2.2.2.2.2.cmml">σ</mi><mo id="S5.SS1.p1.1.m1.2.2.2.2.1" xref="S5.SS1.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S5.SS1.p1.1.m1.2.2.2.2.3" xref="S5.SS1.p1.1.m1.2.2.2.2.3.cmml">5.01</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.2b"><apply id="S5.SS1.p1.1.m1.2.2.3.cmml" xref="S5.SS1.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.2.2.3a.cmml" xref="S5.SS1.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S5.SS1.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1"><eq id="S5.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.1"></eq><ci id="S5.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.1.1.2">𝜇</ci><cn id="S5.SS1.p1.1.m1.1.1.1.1.3.cmml" type="float" xref="S5.SS1.p1.1.m1.1.1.1.1.3">25.83</cn></apply><apply id="S5.SS1.p1.1.m1.2.2.2.2.cmml" xref="S5.SS1.p1.1.m1.2.2.2.2"><eq id="S5.SS1.p1.1.m1.2.2.2.2.1.cmml" xref="S5.SS1.p1.1.m1.2.2.2.2.1"></eq><ci id="S5.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S5.SS1.p1.1.m1.2.2.2.2.2">𝜎</ci><cn id="S5.SS1.p1.1.m1.2.2.2.2.3.cmml" type="float" xref="S5.SS1.p1.1.m1.2.2.2.2.3">5.01</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.2c">\mu=25.83,\sigma=5.01</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.2d">italic_μ = 25.83 , italic_σ = 5.01</annotation></semantics></math>).
The rationale for recruiting these users stems from the potential benefits they could gain from using a tool like RSVP.
They frequently interact with diverse computational models, where understanding the connections between inputs and outputs is crucial for fostering learning and comprehension.
However, such problems do not warrant the collaboration with a visualization expert in order to perform a design study.
Participants had to analyze data sets generated from the edge detection algorithm used in the running example, utilizing the same generic image in order to avoid domain complexity.
Nonetheless, the problem of creating a contour outline of an image finds application in many different areas (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2" title="2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">section 2</span></a>).</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text" id="S5.SS1.p2.1.2" style="color:#000000;">Sessions were conducted online via Zoom using a hosted version of RSVP.
Each session took 60 minutes.
The participants received a five-minute introduction to VPSA and a five-minute tutorial on how to use RSVP.
Afterward, they had ten minutes to explore RSVP’s various functions and ask questions.
The primary analysis session took thirty minutes, during which participants had to create dashboards to analyze three increasingly complex data sets.
Each dataset was introduced briefly at the start of each iteration and came with a challenge that participants needed to address within ten minutes.</span>
The challenges were (1) identifying optimal parameterizations for the data set, (2) determining sensitive areas and which dimensions influenced them, and (3) comparing and evaluating the quality of different objective functions.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 5</span></a> - <span class="ltx_text" id="S5.SS1.p2.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S5.SS1.p2.1.1.g1" src="extracted/5846816/figures/teaser_labels/Ex1.png" width="30"/></span> shows an example dashboard created during an analysis session.
The nature of the questions was open-ended, which means there were no right or wrong answers.
Instead, at the end of each iteration, the users had to rate their confidence in their findings on a five-point Likert scale (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.T3" title="TABLE III ‣ 5.1 Usability Study: Edge Detection Algorithm ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Table III</span></a>), which is a common evaluation approach in such open-ended settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib88" title="">88</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.5.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S5.T3.6.2" style="font-size:90%;">Confidence ratings of the study participants, ranging from <em class="ltx_emph ltx_font_italic" id="S5.T3.6.2.1">not confident at all</em>
(1) to <em class="ltx_emph ltx_font_italic" id="S5.T3.6.2.2">very confident</em> (5)</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
<tr class="ltx_tr" id="S5.T3.1.1">
<td class="ltx_td" id="S5.T3.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.3.1">P1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.4.1">P2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.5.1">P3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.6.1">P4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.7.1">P5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.8.1">P6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><math alttext="\varnothing" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><mi id="S5.T3.1.1.1.m1.1.1" mathvariant="normal" xref="S5.T3.1.1.1.m1.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><emptyset id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\varnothing</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">∅</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.1">Challenge 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.8" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3">
<td class="ltx_td ltx_align_left" id="S5.T3.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.3.1.1">Challenge 2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">3</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.8" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4">
<td class="ltx_td ltx_align_left" id="S5.T3.1.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.4.1.1">Challenge 3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.8" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.833</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5">
<td class="ltx_td ltx_border_t" id="S5.T3.1.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.2.1">4.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.3.1">4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.4.1">4.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.5.1">4.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.6.1">3.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.7.1">4.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.5.8" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.1.5.8.1">4.277</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">During the final interview, we asked the participants to fill out a <em class="ltx_emph ltx_font_italic" id="S5.SS1.p3.1.1">System Usability Scale</em> (SUS) survey <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib89" title="">89</a>]</cite>, a well-known and widely adopted approach to measuring the usability of a system.
An abbreviated version of the questions, along with the answers given by the participants, are presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F11" title="Figure 11 ‣ 5.1 Usability Study: Edge Detection Algorithm ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 11</span></a>.
The complete results are available in the supplemental material.
Converting the users’ answers into the final scores yields results between 70 and 92.5 points, with a mean of 82.5 points.
According to Brooke, average scores above 80 are considered <em class="ltx_emph ltx_font_italic" id="S5.SS1.p3.1.2">very good</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib89" title="">89</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F11.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F11.2.1.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" id="S5.F11.3.2" style="font-size:90%;">Results for the SUS survey, showing range (colored lines) and means (vertical black bars) of given answers.
Positive questions (odd-numbered, blue lines) aim for a high score, and negative questions (even-numbered, red lines) aim for a low score. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span class="ltx_text ltx_font_italic" id="S5.SS2.1.1">Case Study I: Crystal Powder Diffraction</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Our first case-study user is a physics professor who specializes in solid-state materials.
He studies crystalline structures using a procedure known as <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">powder diffraction</em> and compares the results to simulated model data using a <math alttext="\chi^{2}" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><msup id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">χ</mi><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝜒</ci><cn id="S5.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\chi^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>-metric to learn about molecular behavior inside the crystal.
The knowledge gained from such experiments helps the physicist to grow new crystals with desired features.</p>
</div>
<figure class="ltx_figure" id="S5.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F12.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F12.8.4.1" style="font-size:90%;">Figure 12</span>: </span><span class="ltx_text" id="S5.F12.6.3" style="font-size:90%;">Recommendations for tasks optimization <span class="ltx_text" id="S5.F12.4.1.1" style="position:relative; bottom:-2.7pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S5.F12.4.1.1.g1" src="extracted/5846816/figures/task_labels/Topt.png" width="27"/></span>, fitting <span class="ltx_text" id="S5.F12.5.2.2" style="position:relative; bottom:-2.7pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S5.F12.5.2.2.g1" src="extracted/5846816/figures/task_labels/Tfit.png" width="27"/></span>, and sensitivity <span class="ltx_text" id="S5.F12.6.3.3" style="position:relative; bottom:-2.7pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S5.F12.6.3.3.g1" src="extracted/5846816/figures/task_labels/Tsens.png" width="27"/></span> for the Powder-dataset.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.2">The physicist provided fifty random samples for four parameters of interest and 1D outputs and derived <math alttext="\chi^{2}" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><msup id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">χ</mi><mn id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">superscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">𝜒</ci><cn id="S5.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\chi^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>-metrics.
<span class="ltx_text" id="S5.SS2.p2.2.2" style="color:#000000;">Due to timing constraints, the analysis was divided into two sessions: one in-person and one online.
At the beginning of the in-person session, he received a brief introduction to RSVP, followed by time to experiment with the system and ask questions.</span>
The recommendations that underpin the dashboard depicted in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S3.F5" title="Figure 5 ‣ 3.4 VisRec Strategy ( L4 ) ‣ 3 VPSA Meta Design Study ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>-<span class="ltx_text" id="S5.SS2.p2.2.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S5.SS2.p2.2.1.g1" src="extracted/5846816/figures/teaser_labels/Ex3.png" width="30"/></span>, which showcases the most noteworthy insights, are shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F12" title="Figure 12 ‣ 5.2 Case Study I: Crystal Powder Diffraction ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 12</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.2">The Parallel Coordinates (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F13" title="Figure 13 ‣ 5.2 Case Study I: Crystal Powder Diffraction ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 13</span></a>) show that parameter settings to obtain a low <math alttext="{\chi}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><msup id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml"><mi id="S5.SS2.p3.1.m1.1.1.2" xref="S5.SS2.p3.1.m1.1.1.2.cmml">χ</mi><mn id="S5.SS2.p3.1.m1.1.1.3" xref="S5.SS2.p3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><apply id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p3.1.m1.1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S5.SS2.p3.1.m1.1.1.2.cmml" xref="S5.SS2.p3.1.m1.1.1.2">𝜒</ci><cn id="S5.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">{\chi}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> result scatter over the entire range for parameters <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.1">angl1</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.2">angl2</em>, but they become narrower for <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.3">zoff1</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.4">zoff2</em>.
This behavior indicates that <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.5">angl1</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.6">angl2</em> have little to no influence to get a good <math alttext="{\chi}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><msup id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml"><mi id="S5.SS2.p3.2.m2.1.1.2" xref="S5.SS2.p3.2.m2.1.1.2.cmml">χ</mi><mn id="S5.SS2.p3.2.m2.1.1.3" xref="S5.SS2.p3.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><apply id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p3.2.m2.1.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S5.SS2.p3.2.m2.1.1.2.cmml" xref="S5.SS2.p3.2.m2.1.1.2">𝜒</ci><cn id="S5.SS2.p3.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p3.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">{\chi}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> result, whereas <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.7">zoff1</em> and <em class="ltx_emph ltx_font_italic" id="S5.SS2.p3.2.8">zoff2</em> do.
The physicist was aware of this behavior but was surprised that such a low-effort approach using a coarse sampling strategy combined with a relatively simple visualization could reveal what he had learned from long computational cycles and multiple sequential experiments.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">Studying the complex object visualizations revealed insights previously unknown to the scientist.
Generally speaking, the physicist tries to figure out how the molecules fit together inside the crystal.
The curves in the 1D-Linegraph represent crystal structures in reciprocal space, a Fourier transform of the real space<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib90" title="">90</a>]</cite>.
The peak locations and spacings represent the periodicity of the crystal in three space dimensions, and peak heights indicate details about the molecular structure.
Usually, the domain scientist studies these curves one at a time instead of overplotting the results of several experiments in a single graph.</p>
</div>
<figure class="ltx_figure" id="S5.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F13.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F13.4.2.1" style="font-size:90%;">Figure 13</span>: </span><span class="ltx_text" id="S5.F13.2.1" style="font-size:90%;">Detail view of the filters and Parallel Coordinates from <span class="ltx_text" id="S5.F13.2.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S5.F13.2.1.1.g1" src="extracted/5846816/figures/teaser_labels/Ex3.png" width="27"/></span>. </span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1">As presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F14" title="Figure 14 ‣ 5.2 Case Study I: Crystal Powder Diffraction ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 14</span></a>, the four input parameters highly influence the peak at position 196, a well-known circumstance to the scientist.</p>
</div>
<figure class="ltx_figure" id="S5.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F14.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F14.4.2.1" style="font-size:90%;">Figure 14</span>: </span><span class="ltx_text" id="S5.F14.2.1" style="font-size:90%;">Showing the 1D-Linegraph and the 1D-Cumulative Histogram from dashboard <span class="ltx_text" id="S5.F14.2.1.1" style="position:relative; bottom:-2.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="15" id="S5.F14.2.1.1.g1" src="extracted/5846816/figures/teaser_labels/Ex3.png" width="27"/></span>, with several good candidates selected and presenting zooms for multiple areas of interest.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.2">However, he was surprised by the high variance of suitable candidates for good <math alttext="{\chi}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p6.1.m1.1"><semantics id="S5.SS2.p6.1.m1.1a"><msup id="S5.SS2.p6.1.m1.1.1" xref="S5.SS2.p6.1.m1.1.1.cmml"><mi id="S5.SS2.p6.1.m1.1.1.2" xref="S5.SS2.p6.1.m1.1.1.2.cmml">χ</mi><mn id="S5.SS2.p6.1.m1.1.1.3" xref="S5.SS2.p6.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.1.m1.1b"><apply id="S5.SS2.p6.1.m1.1.1.cmml" xref="S5.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p6.1.m1.1.1.1.cmml" xref="S5.SS2.p6.1.m1.1.1">superscript</csymbol><ci id="S5.SS2.p6.1.m1.1.1.2.cmml" xref="S5.SS2.p6.1.m1.1.1.2">𝜒</ci><cn id="S5.SS2.p6.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.1.m1.1c">{\chi}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p6.1.m1.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> results (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F14" title="Figure 14 ‣ 5.2 Case Study I: Crystal Powder Diffraction ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 14</span></a>-<span class="ltx_text" id="S5.SS2.p6.2.1" style="color:#FFFFFF;background-color:#808080;">Z1</span>).
He expected the margin of error at this position to be way lower for suitable candidates.
Another finding was that the peak at position 291 is invariant under these four parameters, meaning it remains static for any parameterization (see <span class="ltx_text" id="S5.SS2.p6.2.2" style="color:#FFFFFF;background-color:#808080;">Z2</span>, left peak).
It will require further research on why the molecules are invariant to depth (zoff) and rotation (angl) at this particular frequency.
Combining these findings and studying them within the <span class="ltx_text ltx_font_italic" id="S5.SS2.p6.2.3">1D Cumulative Histogram</span> view revealed further insights.
Highlighting runs with good <math alttext="{\chi}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p6.2.m2.1"><semantics id="S5.SS2.p6.2.m2.1a"><msup id="S5.SS2.p6.2.m2.1.1" xref="S5.SS2.p6.2.m2.1.1.cmml"><mi id="S5.SS2.p6.2.m2.1.1.2" xref="S5.SS2.p6.2.m2.1.1.2.cmml">χ</mi><mn id="S5.SS2.p6.2.m2.1.1.3" xref="S5.SS2.p6.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.2.m2.1b"><apply id="S5.SS2.p6.2.m2.1.1.cmml" xref="S5.SS2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p6.2.m2.1.1.1.cmml" xref="S5.SS2.p6.2.m2.1.1">superscript</csymbol><ci id="S5.SS2.p6.2.m2.1.1.2.cmml" xref="S5.SS2.p6.2.m2.1.1.2">𝜒</ci><cn id="S5.SS2.p6.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p6.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.2.m2.1c">{\chi}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p6.2.m2.1d">italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> results show that they do not change their positions relative to each other between the peaks at locations 196 and 291 (see <span class="ltx_text" id="S5.SS2.p6.2.4" style="color:#FFFFFF;background-color:#808080;">Z3</span> and <span class="ltx_text" id="S5.SS2.p6.2.5" style="color:#FFFFFF;background-color:#808080;">Z4</span>, respectively).
In other words, the area between these two peaks is stable regarding the objective function.
From a global perspective, the peak with the highest variability is followed by a relatively stable area, culminating in a perfectly stable state at position 291 before massive changes set in again immediately after this location (the right side of <span class="ltx_text" id="S5.SS2.p6.2.6" style="color:#FFFFFF;background-color:#808080;">Z4</span> shows how the highlighted runs begin crossing each other).
The scientist was completely unaware of this global pattern that actually challenged his understanding of this crystal entirely.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span><span class="ltx_text ltx_font_italic" id="S5.SS3.1.1">Case Study II: Lighting Design Optimization</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Our second domain scientist is a researcher who aims to automate the placement of light sources in official buildings by adapting the lighting configuration through a gradient-based optimization approach.
Office environments and official buildings must meet specific lighting standards for different areas, like desk surfaces.
Current commercial lighting design tools necessitate manual adjustments of luminaires to reach the desired outcome.
This new approach would allow designers to directly set target radiances for surfaces, eliminating the need to manually adjust the luminaires to achieve the intended results.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">The researcher was intrigued by the general VPSA approach and its potential benefits to his work. He conducted 685 runs of a two-level office room with four lamps. The positioning of the lamps was unconstrained, allowing them to be placed anywhere in the room. Each lamp’s position in 3D space constituted twelve parameters, along with the objective function results for each configuration. Additionally, he provided gradients for the optimization step, including the gradient norm, adding thirteen more parameters, for a total of twenty-six to analyze. Generating the samples and converting them into the required format took approximately forty-five minutes.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text" id="S5.SS3.p3.1.1" style="color:#000000;">The analysis session was conducted in person on a 2021 16-inch MacBook Pro equipped with an Apple M1 Max chip and 64GB of memory, running a locally hosted version of RSVP.
After receiving a brief introduction to RSVP, the researcher began with the analysis, during which he could ask questions about the system at any time.</span>
He experimented with combining the dimensions in different ways and studied the recommendations and what they meant. During the session, he created numerous dashboards and had several interesting insights.
The dashboard presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F15" title="Figure 15 ‣ 5.3 Case Study II: Lighting Design Optimization ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">Figure 15</span></a> summarizes some of the most interesting ones.
This is the outcome of RSVP’s recommendation for task optimization when encoding all parameters (PSc for both inputs and outputs) and subsequently adding the recommendation when only including the y-dimensions of the lights (SPLOM).</p>
</div>
<figure class="ltx_figure" id="S5.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="265" id="S5.F15.g1" src="extracted/5846816/figures/CaseStudy/CaseStudy-II-2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F15.3.1.1" style="font-size:90%;">Figure 15</span>: </span><span class="ltx_text" id="S5.F15.4.2" style="font-size:90%;color:#000000;">Dashboard created during the Case Study on Automated Lighting Optimization<span class="ltx_text" id="S5.F15.4.2.1" style="color:#000000;"> </span></span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">In this dashboard, the objective function value is filtered to a relatively low level, highlighting options with favorable values.
An interesting observation emerged regarding the y-positions of the lamps, indicating a necessity for at least two lamps on the bottom level and one on the top level of the office, while the position of the remaining lamp could be more flexible.
The researcher could deduct this from the images and confirm it with the recommended plots.
Although not surprising, since effective lighting is mainly required for three surfaces in this particular room, this insight prompted the realization that a simple sampling strategy could address a challenge in their algorithm: determining the minimum number of lamps to place in a room initially
Apparently, a straightforward random sampling strategy could be used with varying numbers of lights, and those yielding feasible objective values could then serve as the starting points for their optimization algorithm.</p>
</div>
<div class="ltx_para" id="S5.SS3.p5">
<p class="ltx_p" id="S5.SS3.p5.1">The other insight pertained more to the system itself.
While all values are below a required threshold, examining the rendered images reveals that not all of them are visually pleasing.
Several results display bright spots on the wall (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F16.sf1" title="16(a) ‣ Figure 16 ‣ 5.3 Case Study II: Lighting Design Optimization ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">16(a)</span></a>), which should be avoided in efficient lighting design.
On the other, elements that should receive at least some light can appear rather dark, like the staircase in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S5.F16.sf2" title="16(b) ‣ Figure 16 ‣ 5.3 Case Study II: Lighting Design Optimization ‣ 5 Evaluation ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">16(b)</span></a>.
Both issues can be addressed by adjusting the illumination constraints on these objects. While relatively easy to achieve in theory, it is often overlooked in practice to add all constraints that are not part of the requirement specification. RSVP could be utilized for debugging these configurations. Rendering a second image from a different perspective would essentially provide a 360° view of the office, allowing one to scrutinize good results for possible mistakes stemming from missing negative constraints.</p>
</div>
<figure class="ltx_figure" id="S5.F16">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F16.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="286" id="S5.F16.sf1.g1" src="extracted/5846816/figures/CaseStudy/sample_221.png" width="395"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F16.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S5.F16.sf1.3.2" style="font-size:90%;">Bright Spot</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F16.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="286" id="S5.F16.sf2.g1" src="extracted/5846816/figures/CaseStudy/sample_359.png" width="395"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F16.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S5.F16.sf2.3.2" style="font-size:90%;">Poorly Lit Staircase</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F16.2.1.1" style="font-size:90%;">Figure 16</span>: </span><span class="ltx_text" id="S5.F16.3.2" style="font-size:90%;">Office Examples</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Discussion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we present our findings regarding the evaluations and our two key design goals, followed by additional analysis concerning the design aspects of RSVP. We conclude this section by outlining the limitations and potential directions for future research.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span class="ltx_text ltx_font_italic" id="S6.SS1.1.1">Findings</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Our basic assumption for the meta design study proved to be correct.
It was possible to extract an expressive visualization design space and a task-oriented visualization recommendation strategy from existing literature, utilizing insights from the conceptual VPSA framework.
In the following, we will analyze how our design achieves our two key goals.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS1.p2.1.1">Low Cost (Key-I)<span class="ltx_text ltx_font_upright" id="S6.SS1.p2.1.1.1"> :</span></span>
The physicist reported that sampling the model and formatting the data took approximately sixty minutes.
This estimate includes the time required to figure out how to perform the sampling.
He believes this process could be reduced to a few minutes with some exercise.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">Five out of six participants of the usablity study were unaware of at least one visualization offered by RSVP.
However, no participant had trouble interpreting and using any of them.
All the users mentioned that it was beneficial to see the visualization options side by side encoded with actual data, which made learning by comparison easy.
Three participants noted that the step-by-step introduction was helpful for them.
One of them noted: <em class="ltx_emph ltx_font_italic" id="S6.SS1.p3.1.1">”Seeing all the visualizations [encoded] with all the dimensions immediately would probably have been overwhelming. But seeing how similar they are in the beginning was very interesting and made it easy to follow as you added new dimensions.”</em></p>
</div>
<div class="ltx_para" id="S6.SS1.p4">
<p class="ltx_p" id="S6.SS1.p4.1">The domain scientist was pleased to see his data visualized right away.
He had prior experience with a design study that took months and several iterations before he saw actual visualizations of his data.
<em class="ltx_emph ltx_font_italic" id="S6.SS1.p4.1.1">”Back then, I entered the design study with the prospect of learning something about visualizing my data and finding out if it could help me with my research. RSVP did all of that, just really fast.”</em></p>
</div>
<div class="ltx_para" id="S6.SS1.p5">
<p class="ltx_p" id="S6.SS1.p5.1">Regarding the SUS questionnaire, we argue that <span class="ltx_text ltx_font_italic" id="S6.SS1.p5.1.1">high usability</span> can be interpreted as <span class="ltx_text ltx_font_italic" id="S6.SS1.p5.1.2">low cost</span> of using a system.
As previously reported, RSVP achieved an average score of 82.5 points, which is considered to be <em class="ltx_emph ltx_font_italic" id="S6.SS1.p5.1.3">very good</em><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib89" title="">89</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p6">
<p class="ltx_p" id="S6.SS1.p6.1">We take those findings as positive indicators that RSVP achieves Key-I, imposing <span class="ltx_text ltx_font_italic" id="S6.SS1.p6.1.1">low costs</span> on the user in terms of time and cognitive effort required for using it.</p>
</div>
<div class="ltx_para" id="S6.SS1.p7">
<p class="ltx_p" id="S6.SS1.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS1.p7.1.1">High Trust (Key-II)<span class="ltx_text ltx_font_upright" id="S6.SS1.p7.1.1.1"> :</span></span>
The domain scientist admitted that he was initially skeptical about the VPSA approach.
He could not imagine that such a coarse sampling could reveal anything about the data that he did not already know.
However, fast revelations and confirming existing knowledge about the data helped to build trust and further spurred his curiosity.
Consecutive findings and insights led to the decision to adopt RSVP for future research.
He issued the following statement:
<em class="ltx_emph ltx_font_italic" id="S6.SS1.p7.1.2">”Although the instruments for taking physical measurements have improved over the years, the way scientists analyze their data has not changed much.
VPSA, in general, could change how scientists study their models, and RSVP, in specific, could probably help them to achieve this.”</em></p>
</div>
<div class="ltx_para" id="S6.SS1.p8">
<p class="ltx_p" id="S6.SS1.p8.1">Trustworthiness in VisRec may not be captured by simple measures, but Dasgupta et al. suggest that trust can be defined as self-calibrated confidence in the analysis outcome <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib33" title="">33</a>]</cite>.
Therefore, the confidence ratings obtained from the usability study indirectly reflect the reliability of both the VPSA approach and the VisRec strategy.
The overall confidence score was 4.17 points, which means that usability testers were <em class="ltx_emph ltx_font_italic" id="S6.SS1.p8.1.1">rather confident</em> in their findings.
Interestingly, the challenges with the highest complexity had the highest confidence ratings (4.83 points on average).
This finding is similar to observations by Dasgupta et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib33" title="">33</a>]</cite> where they reported that domain scientists’ trust in a visual analysis system increased with the complexity of the analysis tasks.
The users explained this behavior by the experience gained during the previous challenges and that they would not have known how to evaluate the objective functions otherwise.
We take these findings as proof that RSVP also fulfills Key-II, making users feel <em class="ltx_emph ltx_font_italic" id="S6.SS1.p8.1.2">high trust</em> in both the RSVP system and the VPSA method in general.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span class="ltx_text ltx_font_italic" id="S6.SS2.1.1">Further Design Analysis</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">As previously discussed, a meta design study diverges from a classical design study in its method of deriving domain knowledge. While the latter emphasizes user-centric design, the former derives domain knowledge not from direct interaction with individuals but rather from written reports. This is also how assumptions about domain scientists are formed. However, to enhance the overall usability of such a tool or to potentially address the needs of individual scientists, iterative and user-centric design remain essential.
Therefore, we will delve into these aspects in this section.
<span class="ltx_text" id="S6.SS2.p1.1.1" style="color:#000000;">
Furthermore, existing frameworks like ComVis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib65" title="">65</a>]</cite> and Visplore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib66" title="">66</a>]</cite> generally allow for the creation of more powerful dashboards compared to those possible with RSVP.
However, they are not readily accessible to domain scientists, requiring a visualization expert to design and develop a customized application or dashboard before analysis can begin.
In contrast, RSVP allows domain scientists to independently develop their own VPSA dashboards without the assistance of a visualization expert.</span>
<span class="ltx_text" id="S6.SS2.p1.1.2" style="color:#000000;">
Tableau, however, does not require programming and can effectively create all the visualizations that RSVP can.</span>
This raises the question: what factors would motivate choosing RSVP over Tableau?
To address this, we will compare RSVP to Tableau and attempt to answer this question.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS2.p2.1.1">Iterative Design:</span>
The design study discussed in the supplementary material represents an early application of RSVP, demonstrating its initial functionality.
At this stage, RSVP only featured a single spatial encoding field, necessitating the sequential creation of visualizations for inputs and outputs. Recommendations were provided in the form of a ranked list of visualizations deemed effective for specific tasks. While this study provided interesting insights for the user, it showed the necessity of collaboration with visualization experts familiar with RSVP and VPSA for the development of comprehensive dashboards.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">This experience prompted a redesign of RSVP, introducing two spatial fields to enable simultaneous input and output dimension encoding. Additionally, it prompted a reassessment of the coding table concerning the Vis Rec strategy, culminating in the strategy detailed in Section 3.3.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1">Furthermore, prior to conducting the usability study, two pilot studies involving an undergraduate student and a Ph.D. student were conducted, resulting in further usability enhancements.
These enhancements included clarifications on task meanings, explanations within the dashboard, and adjustments to color schemes. While the initial color differentiations between tasks and encoding channels were distinct, efforts were made after the pilot studies to align them more closely, facilitating task-channel associations. Moreover, the color scheme for the third column in small multiples was revised to reflect a blend of the colors used in the first two columns, enhancing participants’ understanding of the data representation.</p>
</div>
<div class="ltx_para" id="S6.SS2.p5">
<p class="ltx_p" id="S6.SS2.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS2.p5.1.1">User-oriented Design:</span>
In situations where specific users have requirements that can not be addressed by RSVP, a traditional design study may be warranted.
Nonetheless, RSVP continues to play a crucial role by serving as a bridge between domain scientists and visualization researchers, effectively acting as a liaison <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib91" title="">91</a>]</cite>. Domain scientists can utilize RSVP to construct dashboards with their own data, simplifying the explanation of data, tasks, and system limitations to visualization researchers. Consequently, these researchers can better grasp the actual needs of domain scientists and expedite the design of potential solutions.</p>
</div>
<div class="ltx_para" id="S6.SS2.p6">
<p class="ltx_p" id="S6.SS2.p6.1">RSVP was designed with extensibility in mind for such cases. It provides a mechanism whereby visualization designers proficient in creating visualizations with Vega can develop new visualizations. As long as these visualizations adhere to certain requirements regarding data setup, RSVP can seamlessly integrate them into the visualization dashboard <span class="ltx_text" id="S6.SS2.p6.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S6.SS2.p6.1.1.g1" src="extracted/5846816/figures/teaser_labels/VDB.png" width="30"/></span>. This integration has the potential to substantially reduce the time required for design studies, which in some instances can extend over several years <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib77" title="">77</a>]</cite>. Although this mechanism within RSVP is still in its early stages, it will be refined in future iterations of the system.</p>
</div>
<div class="ltx_para" id="S6.SS2.p7">
<p class="ltx_p" id="S6.SS2.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS2.p7.1.2">Comparison to Tableau:</span>
The draggable markers in RSVP’s data-selection panel <span class="ltx_text" id="S6.SS2.p7.1.1" style="position:relative; bottom:-3.1pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="17" id="S6.SS2.p7.1.1.g1" src="extracted/5846816/figures/teaser_labels/DSP.png" width="30"/></span> were inspired by Tableau. However, Tableau does not allow for editing two different visualizations simultaneously, unlike RSVP, which facilitates this through two distinct spatial fields.
This is a critical aspect when creating VPSA applications, as input and output dimensions are often encoded in separate views.</p>
</div>
<div class="ltx_para" id="S6.SS2.p8">
<p class="ltx_p" id="S6.SS2.p8.1">Similar to VisRec in RSVP, Tableau’s ”Show Me” feature also utilizes small multiples of different visualizations, employs colored frames to highlight recommended visualizations, and provides hints to the user on how to encode a specific visualization.
However, the small multiples in Tableau are static icons and do not display actual user data. To view them encoded, the user must instantiate a visualization. If a user wishes to compare multiple visualizations, they must instantiate them individually and compare them sequentially.
In RSVP, all available visualizations are instantiated simultaneously, allowing for easy comparison.
This approach aims to address potential issues with visualization literacy and save time for users, which is particularly important for domain scientists.
Furthermore, recommendations in Tableau are generic suggestions based on certain data features, while recommendations in RSVP are task-oriented, tailored to problems commonly encountered in VPSA.</p>
</div>
<div class="ltx_para" id="S6.SS2.p9">
<p class="ltx_p" id="S6.SS2.p9.1">Tableau can handle 1D objects in the form of additionally loaded and linked data sheets.
2D objects can be added as links to images, similar to how it is done in RSVP.
However, converting links into images is not straightforward in Tableau and requires considerable expertise to accomplish.
This becomes even more challenging when juxtaposing or superimposing selected images.
Furthermore, Tableau does not provide guidance on combining these complex objects with other visualizations in the dashboard to facilitate analysis and achieve specific high-level tasks.</p>
</div>
<div class="ltx_para" id="S6.SS2.p10">
<p class="ltx_p" id="S6.SS2.p10.1">In summary, Tableau offers greater overall power compared to RSVP.
However, RSVP is highly efficient and effective for handling VPSA-related problems. This comparison is akin to comparing a domain-specific language (DSL) with a general-purpose programming language: while a general-purpose language can theoretically achieve anything, it may be complex to achieve.
In contrast, a DSL simplifies achieving specific tasks by making operations irrelevant to the domain impossible<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib92" title="">92</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span class="ltx_text ltx_font_italic" id="S6.SS3.1.1">Limitations and Future Work</span>
</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.5"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p1.5.6" style="color:#000000;">Number of Participants in Usability Study:</span><span class="ltx_text" id="S6.SS3.p1.1.1" style="color:#000000;">
Our decision for <math alttext="n=6" class="ltx_Math" display="inline" id="S6.SS3.p1.1.1.m1.1"><semantics id="S6.SS3.p1.1.1.m1.1a"><mrow id="S6.SS3.p1.1.1.m1.1.1" xref="S6.SS3.p1.1.1.m1.1.1.cmml"><mi id="S6.SS3.p1.1.1.m1.1.1.2" mathcolor="#000000" xref="S6.SS3.p1.1.1.m1.1.1.2.cmml">n</mi><mo id="S6.SS3.p1.1.1.m1.1.1.1" mathcolor="#000000" xref="S6.SS3.p1.1.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.1.1.m1.1.1.3" mathcolor="#000000" xref="S6.SS3.p1.1.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.1.m1.1b"><apply id="S6.SS3.p1.1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.1.m1.1.1"><eq id="S6.SS3.p1.1.1.m1.1.1.1.cmml" xref="S6.SS3.p1.1.1.m1.1.1.1"></eq><ci id="S6.SS3.p1.1.1.m1.1.1.2.cmml" xref="S6.SS3.p1.1.1.m1.1.1.2">𝑛</ci><cn id="S6.SS3.p1.1.1.m1.1.1.3.cmml" type="integer" xref="S6.SS3.p1.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.1.m1.1c">n=6</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.1.1.m1.1d">italic_n = 6</annotation></semantics></math> follows recommendations aimed at optimizing sample size for usability tests to maximize return on investment (ROI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib87" title="">87</a>]</cite>.
</span>
<span class="ltx_text" id="S6.SS3.p1.5.5" style="color:#000000;">We set our problem discovery goal at a value of 0.9, which we considered sufficient for a prototype at this stage.
Based on a preliminary study involving two users and a previous case study, we estimated a problem discovery rate <math alttext="p=0.33" class="ltx_Math" display="inline" id="S6.SS3.p1.2.2.m1.1"><semantics id="S6.SS3.p1.2.2.m1.1a"><mrow id="S6.SS3.p1.2.2.m1.1.1" xref="S6.SS3.p1.2.2.m1.1.1.cmml"><mi id="S6.SS3.p1.2.2.m1.1.1.2" mathcolor="#000000" xref="S6.SS3.p1.2.2.m1.1.1.2.cmml">p</mi><mo id="S6.SS3.p1.2.2.m1.1.1.1" mathcolor="#000000" xref="S6.SS3.p1.2.2.m1.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.2.2.m1.1.1.3" mathcolor="#000000" xref="S6.SS3.p1.2.2.m1.1.1.3.cmml">0.33</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.2.m1.1b"><apply id="S6.SS3.p1.2.2.m1.1.1.cmml" xref="S6.SS3.p1.2.2.m1.1.1"><eq id="S6.SS3.p1.2.2.m1.1.1.1.cmml" xref="S6.SS3.p1.2.2.m1.1.1.1"></eq><ci id="S6.SS3.p1.2.2.m1.1.1.2.cmml" xref="S6.SS3.p1.2.2.m1.1.1.2">𝑝</ci><cn id="S6.SS3.p1.2.2.m1.1.1.3.cmml" type="float" xref="S6.SS3.p1.2.2.m1.1.1.3">0.33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.2.2.m1.1c">p=0.33</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.2.2.m1.1d">italic_p = 0.33</annotation></semantics></math> per user.
In order to meet our goal with this rate, six participants were necessary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib86" title="">86</a>]</cite>.
If we wanted to enhance the robustness of the results, <math alttext="n=8" class="ltx_Math" display="inline" id="S6.SS3.p1.3.3.m2.1"><semantics id="S6.SS3.p1.3.3.m2.1a"><mrow id="S6.SS3.p1.3.3.m2.1.1" xref="S6.SS3.p1.3.3.m2.1.1.cmml"><mi id="S6.SS3.p1.3.3.m2.1.1.2" mathcolor="#000000" xref="S6.SS3.p1.3.3.m2.1.1.2.cmml">n</mi><mo id="S6.SS3.p1.3.3.m2.1.1.1" mathcolor="#000000" xref="S6.SS3.p1.3.3.m2.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.3.3.m2.1.1.3" mathcolor="#000000" xref="S6.SS3.p1.3.3.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.3.3.m2.1b"><apply id="S6.SS3.p1.3.3.m2.1.1.cmml" xref="S6.SS3.p1.3.3.m2.1.1"><eq id="S6.SS3.p1.3.3.m2.1.1.1.cmml" xref="S6.SS3.p1.3.3.m2.1.1.1"></eq><ci id="S6.SS3.p1.3.3.m2.1.1.2.cmml" xref="S6.SS3.p1.3.3.m2.1.1.2">𝑛</ci><cn id="S6.SS3.p1.3.3.m2.1.1.3.cmml" type="integer" xref="S6.SS3.p1.3.3.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.3.3.m2.1c">n=8</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.3.3.m2.1d">italic_n = 8</annotation></semantics></math> could accommodate variability in the discovery rate up to 0.08 points.
In other words, if our estimated discovery rate was overly optimistic at 0.33, but the actual rate was 0.25, <math alttext="n=8" class="ltx_Math" display="inline" id="S6.SS3.p1.4.4.m3.1"><semantics id="S6.SS3.p1.4.4.m3.1a"><mrow id="S6.SS3.p1.4.4.m3.1.1" xref="S6.SS3.p1.4.4.m3.1.1.cmml"><mi id="S6.SS3.p1.4.4.m3.1.1.2" mathcolor="#000000" xref="S6.SS3.p1.4.4.m3.1.1.2.cmml">n</mi><mo id="S6.SS3.p1.4.4.m3.1.1.1" mathcolor="#000000" xref="S6.SS3.p1.4.4.m3.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.4.4.m3.1.1.3" mathcolor="#000000" xref="S6.SS3.p1.4.4.m3.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.4.4.m3.1b"><apply id="S6.SS3.p1.4.4.m3.1.1.cmml" xref="S6.SS3.p1.4.4.m3.1.1"><eq id="S6.SS3.p1.4.4.m3.1.1.1.cmml" xref="S6.SS3.p1.4.4.m3.1.1.1"></eq><ci id="S6.SS3.p1.4.4.m3.1.1.2.cmml" xref="S6.SS3.p1.4.4.m3.1.1.2">𝑛</ci><cn id="S6.SS3.p1.4.4.m3.1.1.3.cmml" type="integer" xref="S6.SS3.p1.4.4.m3.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.4.4.m3.1c">n=8</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.4.4.m3.1d">italic_n = 8</annotation></semantics></math> would achieve our goal of 0.9.
Conversely, if our estimation of 0.33 was accurate, <math alttext="n=8" class="ltx_Math" display="inline" id="S6.SS3.p1.5.5.m4.1"><semantics id="S6.SS3.p1.5.5.m4.1a"><mrow id="S6.SS3.p1.5.5.m4.1.1" xref="S6.SS3.p1.5.5.m4.1.1.cmml"><mi id="S6.SS3.p1.5.5.m4.1.1.2" mathcolor="#000000" xref="S6.SS3.p1.5.5.m4.1.1.2.cmml">n</mi><mo id="S6.SS3.p1.5.5.m4.1.1.1" mathcolor="#000000" xref="S6.SS3.p1.5.5.m4.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.5.5.m4.1.1.3" mathcolor="#000000" xref="S6.SS3.p1.5.5.m4.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.5.5.m4.1b"><apply id="S6.SS3.p1.5.5.m4.1.1.cmml" xref="S6.SS3.p1.5.5.m4.1.1"><eq id="S6.SS3.p1.5.5.m4.1.1.1.cmml" xref="S6.SS3.p1.5.5.m4.1.1.1"></eq><ci id="S6.SS3.p1.5.5.m4.1.1.2.cmml" xref="S6.SS3.p1.5.5.m4.1.1.2">𝑛</ci><cn id="S6.SS3.p1.5.5.m4.1.1.3.cmml" type="integer" xref="S6.SS3.p1.5.5.m4.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.5.5.m4.1c">n=8</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.5.5.m4.1d">italic_n = 8</annotation></semantics></math> would increase the problem discovery probability to 0.95.
These considerations pertain to the evaluation of a single prototype.
If the SUS was used to assess user preferences between two competing prototypes, eight to twelve participants would be necessary to ensure robust results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib93" title="">93</a>]</cite>.
However, since our study currently does not involve a comparison between prototypes, this recommendation does not immediately apply to our situation.</span></p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p2.1.1">Predictions:</span>

The dataflow model presented in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2409.07105v1#S2.F2.sf1" title="2(a) ‣ Figure 2 ‣ 2.1 VPSA - Introduction ‣ 2 Background ‣ RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis"><span class="ltx_text ltx_ref_tag">2(a)</span></a> is an abbreviated version of the model proposed by Sedlmair et al.
The complete version includes an alternative prediction step, which allows analyzing data points that have not been sampled and simulated yet but were approximated with a surrogate model.
Using prediction allows the continuous analysis of the parameter space.
However, it requires more complicated visualizations and advanced navigation techniques, and keeping selections consistent across discrete and continuous views would be rather complicated, if possible at all.
Showing complex objects for non-simulated data points would be another challenge.
Training deep learning based surrogate models capable of approximating complex objects for not simulated points can take up to several hours on a supercomputer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib94" title="">94</a>]</cite>, which is not feasible for most users.
Despite these challenges, including predictive analysis capabilities in a generic visualization tool would undoubtedly appeal to many users performing VPSA.</p>
</div>
<div class="ltx_para" id="S6.SS3.p3">
<p class="ltx_p" id="S6.SS3.p3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p3.1.1" style="color:#000000;">Transferability:</span> We have shown how a meta design study can help extract a visualization design space and a suitable visualization recommendation strategy for VPSA.
<span class="ltx_text" id="S6.SS3.p3.1.2" style="color:#000000;"> However, we believe this approach can be applied to other problem domains</span> <span class="ltx_text" id="S6.SS3.p3.1.3" style="color:#000000;">For example, many of the papers analyzed in our study deal with complex objects and devote considerable effort to describing techniques for transforming them into lower-dimensional representations for analysis.</span> Selecting appropriate transformations can be challenging, and users may not be aware of all possible transformations for their analyzed objects.
To the best of our knowledge, assisting users in selecting suitable transformations for complex objects into alternative representations offering enhanced analytical capabilities is currently a research gap that could potentially be addressed by a meta design study.</p>
</div>
<div class="ltx_para" id="S6.SS3.p4">
<p class="ltx_p" id="S6.SS3.p4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p4.1.1">Scalablity:</span>
As previously stated, VPSA is an approach that facilitates the analysis of multi-dimensional input-output-related problems, where the dimensions carry semantic meaning.
For high-dimensional problems encountered in fields like machine learning and deep learning, alternative strategies exist Hohman et al., 2019.
There is no definitive threshold distinguishing between multi-dimensional and high-dimensional problems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib9" title="">9</a>]</cite>, but the analysis of the applications in the meta design study revealed that most of them featured examples with less than ten dimensions, and none of them exceeded twenty.</p>
</div>
<div class="ltx_para" id="S6.SS3.p5">
<p class="ltx_p" id="S6.SS3.p5.1">RSVP provides visualization options and recommendations for up to fifteen input and output dimensions, respectively, with support for up to one thousand runs (Con-2). If these limits are significantly exceeded, alternative visualization options and a potentially faster rendering solutions (such as a WebGL/WebGPU implementation of the renderer in Vega) may be necessary.</p>
</div>
<div class="ltx_para" id="S6.SS3.p6">
<p class="ltx_p" id="S6.SS3.p6.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p6.1.1">Extensibility:</span>
As previously explained, the visualization dashboard is already extensible with new Vega visualizations (though currently undocumented), but the visualization options in the overview area are not currently extensible. Additionally, the VisRec rules are presently derived manually, which complicates the introduction of new rules or updates to existing ones when new papers or applications are added to the knowledge base. Converting our hard-coded rules into constraints for answer-set-programming or utilizing a framework like Knowledge Rocks for handling visualization knowledge might mitigate this problem, but further research is necessary in this regard. Moreover, automating the extraction of new VisRec rules from design study papers is a task for future research.</p>
</div>
<div class="ltx_para" id="S6.SS3.p7">
<p class="ltx_p" id="S6.SS3.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p7.1.1" style="color:#000000;">Sampling Support:</span> <span class="ltx_text" id="S6.SS3.p7.1.2" style="color:#000000;">Users often can</span> sample their model using random or Cartesian grid sampling but are incapable of using more sophisticated strategies like Latin Hypercube sampling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib95" title="">95</a>]</cite> or uniform sampling on a space-filling curve <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib96" title="">96</a>]</cite>.
However, advanced visualization techniques like the previously discussed ones also necessitate improved sampling strategies.
Furthermore, Latin Hypercube Sampling would probably improve uncertainty and sensitivity analysis<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib97" title="">97</a>]</cite>.
We envision a tool like Hanpuku <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib98" title="">98</a>]</cite>, which would support domain scientists in sampling their models with more sophisticated strategies and create outputs that could be directly used by tools like RSVP.</p>
</div>
<div class="ltx_para" id="S6.SS3.p8">
<p class="ltx_p" id="S6.SS3.p8.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.SS3.p8.1.1" style="color:#000000;">Automated Dashboard Design:</span> RSVP provides multi-view recommendations and hints to users on how to interact with them, but it does not support arranging those views in the dashboard.
The size of individual views related to the amount of data they encode could be determined using Pixnostics<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib99" title="">99</a>]</cite>, Scagnostics<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib100" title="">100</a>]</cite>, and Pargnostics<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib101" title="">101</a>]</cite>.
Layout proposals could be based on simple heuristics<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib102" title="">102</a>]</cite>, or they could be learned from online dashboards<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib103" title="">103</a>]</cite>.
A domain-oriented recommendation approach could also be considered.
Domain scientists tag and share dashboards they deem helpful, and the system could recommend those to users facing a similar problem.
The similarity could be established by analyzing those tags and data<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib104" title="">104</a>]</cite> or via an ontology-based approach<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07105v1#bib.bib105" title="">105</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We presented RSVP, a system based on an extensive meta design study on the subject of VPSA, designed to enable domain scientists wihtout programming skills to create custom visualization dashboards quickly.
It features a task-oriented visualization recommendation strategy and a drag-and-drop interaface for creating said dashbaords.
RSVP not only guides users through their data analysis needs but also promotes learning and provides explanations for its recommendations.
A usability study and case studies confirm RSVP’s user-friendliness and its ability to provide valuable insights, suggesting its applicability across various fields. Future updates will focus on enhancing RSVP’s capabilities regarding the expansion of visualization options, recommendations, and support for more complex data types.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We would like to thank Silvia Miksch for the valuable discussions and her helpful insights.
This research was partially supported by NSF award 2007436 and WWTF award ICT19-041.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. Potter, A. Wilson, P. Bremer, D. Williams, C. Doutriaux, V. Pascucci, and C. R. Johnson, “Ensemble-Vis: A framework for the statistical visualization of ensemble data,” in <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">IEEE International Conference on Data Mining Workshops</em>, 2009, pp. 233–240.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Wang, X. Liu, H. Shen, and G. Lin, “Multi-resolution climate ensemble parameter analysis with nested parallel coordinates plots,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 23, no. 1, pp. 81–90, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. Matkovic, D. Gracanin, B. Klarin, and H. Hauser, “Interactive visual analysis of complex scientific data as families of data surfaces,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L. Cibulski, H. Mitterhofer, T. May, and J. Kohlhammer, “Paved: Pareto front visualization for engineering design,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Computer Graphics Forum</em>, vol. 39, no. 3, pp. 405–416, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Bruckner and T. Möller, “Result-driven exploration of simulation parameter spaces for visual effects design,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Matejka, M. Glueck, E. Bradner, A. Hashemi, T. Grossman, and G. Fitzmaurice, “Dream Lens: Exploration and visualization of large-scale generative design datasets,” in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">CHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’18.   New York, NY, USA: Association for Computing Machinery, 2018, p. 1–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Mühlbacher, L. Linhardt, T. Möller, and H. Piringer, “TreePOD: Sensitivity-aware selection of pareto-optimal decision trees,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Hamid, A. Derstroff, S. Klemm, Q. Q. Ngo, X. Jiang, and L. Linsen, “Visual ensemble analysis to study the influence of hyper-parameters on training deep neural networks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Machine Learning Methods in Visualisation for Big Data</em>.   The Eurographics Association, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M. Sedlmair, C. Heinzl, S. Bruckner, H. Piringer, and T. Möller, “Visual parameter space analysis: A conceptual framework,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
M. Sedlmair, M. Meyer, and T. Munzner, “Design study methodology: Reflections from the trenches and the stacks,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
E. Horvitz, “Principles of mixed-initiative user interfaces,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
P. Federico, M. Wagner, A. Rind, A. Amor-Amorós, S. Miksch, and W. Aigner, “The role of explicit knowledge: A conceptual model of knowledge-assisted visual analytics,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2017 IEEE Conference on Visual Analytics Science and Technology (VAST)</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Canny, “A computational approach to edge detection,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. PAMI-8, no. 6, pp. 679–698, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. J. Pretorius, M. Bray, A. E. Carpenter, and R. A. Ruddle, “Visualization of parameter space for image analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T. Torsney-Weir, A. Saad, T. Möller, H. Hege, B. Weber, J. Verbavatz, and S. Bergner, “Tuner: Principled parameter finding for image segmentation algorithms using visual response surface exploration,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 17, no. 12, pp. 1892–1901, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
B. Fröhler, T. Möller, and C. Heinzl, “GEMSe: Visualization-guided exploration of multi-channel segmentation algorithms,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Computer Graphics Forum</em>, vol. 35, no. 3, pp. 191–200, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. Oppermann and T. Munzner, “Data-first visualization design studies,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">IEEE Workshop on Evaluation and Beyond - Methodological Approaches to Visualization (BELIV)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. W. Lipsey and D. B. Wilson, <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Practical meta-analysis.</em>   SAGE publications, Inc, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T. Munzner, “A nested model for visualization design and validation,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 15, no. 6, pp. 921–928, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T. Munzner, <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Visualization analysis and design</em>.   CRC press, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Sedlmair, P. Isenberg, D. Baur, and A. Butz, “Information visualization evaluation in large companies: Challenges, experiences and recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Information Visualization</em>, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
D. M. Russell, “Simple is good: Observations of visualization use amongst the big data digerati,” in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Working Conference on Advanced Visual Interfaces</em>, ser. AVI ’16.   New York, NY, USA: Association for Computing Machinery, 2016, p. 7–12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
N. Boukhelifa, A. Bezerianos, I. C. Trelea, N. M. Perrot, and E. Lutton, “An exploratory study on visual exploration of model simulations by multiple types of experts,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. Ma’ayan, W. Ni, K. Ye, C. Kulkarni, and J. Sunshine, “How domain experts create conceptual diagrams and implications for tool design,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">CHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’20.   New York, NY, USA: Association for Computing Machinery, 2020, p. 1–14.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. Slingsby and J. Dykes, “Experiences in involving analysts in visualisation design,” in <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2012 BELIV Workshop: Beyond Time and Errors - Novel Evaluation Methods for Visualization</em>, New York, NY, USA, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y. Ye, F. Sauer, K.-L. Ma, K. Aditya, and J. Chen, “A user-centered design study in scientific visualization targeting domain experts,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
E. Mayr, P. Federico, S. Miksch, G. Schreder, M. Smuc, and F. Windhager, “Visualization of cultural heritage data for casual users,” in <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">IEEE VIS Workshop on Visualization for the Digital Humanities</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Gegenfurtner and M. Seppänen, “Transfer of expertise: An eye tracking and think aloud study using dynamic medical visualizations,” <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Computers &amp; Education</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
P. Ruchikachorn and K. Mueller, “Learning visualizations by analogy: Promoting visual literacy through visualization morphing,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 21, no. 9, pp. 1028–1044, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y. L. Wong, K. Madhavan, and N. Elmqvist, “Towards characterizing domain experts as a user group,” in <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">IEEE Evaluation and Beyond - Methodological Approaches for Visualization (BELIV)</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
L. Grammel, “User interfaces supporting information visualization novices in visualization construction,” Ph.D. dissertation, University of Victoria, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
J. van Wijk, “The value of visualization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">IEEE Visualization</em>, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
A. Dasgupta, J. Lee, R. Wilson, R. A. Lafrance, N. Cramer, K. Cook, and S. Payne, “Familiarity vs trust: A comparative study of domain scientists’ trust in visual analytics and conventional analysis methods,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Zhu, G. Sun, Q. Jiang, M. Zha, and R. Liang, “A survey on automatic infographics and visualization recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Visual Informatics</em>, vol. 4, no. 3, pp. 24–40, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J. Mackinlay, “Automating the design of graphical presentations of relational information,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">ACM Transactions on Graphics</em>, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, and J. Heer, “Towards a general-purpose query language for visualization recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the Workshop on Human-In-the-Loop Data Analytics</em>.   New York, NY, USA: Association for Computing Machinery, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
K. Wongsuphasawat, Z. Qu, D. Moritz, R. Chang, F. Ouk, A. Anand, J. Mackinlay, B. Howe, and J. Heer, “Voyager 2: Augmenting visual analysis with partial view specifications,” in <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">CHI Conference on Human Factors in Computing Systems</em>.   New York, NY, USA: Association for Computing Machinery, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
D. Moritz, C. Wang, G. L. Nelson, H. Lin, A. M. Smith, B. Howe, and J. Heer, “Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
H. Lin, D. Moritz, and J. Heer, “Dziban: Balancing agency &amp; automation in visualization design via anchored recommendations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">CHI Conference on Human Factors in Computing Systems</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. Wehrend and C. Lewis, “A problem-oriented classification of visualization techniques,” in <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">IEEE Conference on Visualization: Visualization ‘90</em>, 1990, pp. 139–143.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
“Task-analytic approach to the automated design of graphic presentations,” <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">ACM Trans. Graph.</em>, 1991.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
S. F. Roth, J. Kolojejchick, J. Mattis, and J. Goldstein, “Interactive graphic design using automatic presentation knowledge,” in <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the SIGCHI conference on Human factors in computing systems</em>, 1994, pp. 112–117.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
M. X. Zhou and S. K. Feiner, “Visual task characterization for automated visual discourse synthesis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">CHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’98.   USA: ACM Press/Addison-Wesley Publishing Co., 1998, p. 392–399.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
R. Amar and J. Stasko, “A knowledge task-based framework for design and evaluation of information visualizations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IEEE Symposium on Information Visualization</em>, 2004, pp. 143–150.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
C. Demiralp, P. J. Haas, S. Parthasarathy, and T. Pedapati, “Foresight: Recommending visual insights,” <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proc. VLDB Endow.</em>, vol. 10, no. 12, p. 1937–1940, Aug. 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
D. J.-L. Lee, V. Setlur, M. Tory, K. G. Karahalios, and A. Parameswaran, “Deconstructing categorization in visualization recommendation: A taxonomy and comparative study,” <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
L. Shen, E. Shen, Z. Tai, Y. Song, and J. Wang, “Taskvis: Task-oriented visualization recommendation,” 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
A. Key, B. Howe, D. Perry, and C. Aragon, “VizDeck: Self-organizing dashboards for visual analytics,” in <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">ACM SIGMOD International Conference on Management of Data</em>, ser. SIGMOD ’12, New York, NY, USA, 2012, p. 681–684.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Y. Luo, X. Qin, N. Tang, and G. Li, “DeepEye: Towards automatic data visualization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">IEEE International Conference on Data Engineering (ICDE)</em>, 2018, pp. 101–112.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A. Wu, Y. Wang, M. Zhou, X. He, H. Zhang, H. Qu, and D. Zhang, “Multivision: Designing analytical dashboards with deep learning based recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, pp. 1–1, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
N. Tintarev and J. Masthoff, “A survey of explanations in recommender systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">2007 IEEE 23rd International Conference on Data Engineering Workshop</em>, 2007, pp. 801–810.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
A. McNutt, A. Crisan, and M. Correll, “Divining insights: Visual analytics through cartomancy,” in <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">CHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
H. Schulz, T. Nocke, M. Heitzler, and H. Schumann, “A design space of visualization tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 19, no. 12, pp. 2366–2375, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
H. Li, Y. Wang, S. Zhang, Y. Song, and H. Qu, “Kg4vis: A knowledge graph-based approach for visualization recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
K. Hu, M. A. Bakker, S. Li, T. Kraska, and C. Hidalgo, <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">VizML: A Machine Learning Approach to Visualization Recommendation</em>, New York, NY, USA, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
O. Gilson, N. Silva, P. Grant, and M. Chen, “From web data to visualization via ontology mapping,” <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Computer Graphics Forum</em>, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
J. Polowinski and M. Voigt, “Viso: A shared, formal knowledge base as a foundation for semi-automatic infovis systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">CHI ’13 Extended Abstracts on Human Factors in Computing Systems</em>, New York, NY, USA, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
A.-P. Lohfink, S. D. D. Anton, H. Leitte, and C. Garth, “Knowledge rocks: Adding knowledge assistance to visualization systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, and J. Heer, “Voyager: Exploratory analysis via faceted browsing of visualization recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 22, no. 1, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
E. Chi, P. Barry, J. Riedl, and J. Konstan, “A spreadsheet approach to information visualization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Proceedings of VIZ ’97: Visualization Conference, Information Visualization Symposium and Parallel Rendering Symposium</em>, 1997, pp. 17–24.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
T. J. Jankun-Kelly and Kwan-Liu Ma, “Visualization exploration and encapsulation via a spreadsheet-like interface,” <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
J. Roberts, “On encouraging multiple views for visualization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Proceedings. IEEE Conference on Information Visualization</em>, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
S. van den Elzen and J. J. van Wijk, “Small multiples, large singles: A new approach for visual data exploration,” <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Computer Graphics Forum</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
C. Weaver, “Building highly-coordinated visualizations in Improvise,” in <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">IEEE Symposium on Information Visualization</em>, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
K. Matkovic, W. Freiler, D. Gracanin, and H. Hauser, “ComVis: A coordinated multiple views system for prototyping new visualization technology,” in <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">International Conference Information Visualisation</em>, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
H. Piringer, C. Tominski, P. Muigg, and W. Berger, “A multi-threading architecture to support interactive visual exploration,” <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
M. A. Yalçın, N. Elmqvist, and B. B. Bederson, “Keshif: Rapid and expressive tabular data exploration for novices,” <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
“Tableau,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.tableau.com" title="">https://www.tableau.com</a>, accessed: 2024-06-28.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
C. Stolte, D. Tang, and P. Hanrahan, “Polaris: a system for query, analysis, and visualization of multidimensional relational databases,” <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 8, no. 1, pp. 52–65, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
A. Bryman, <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">Social research methods</em>.   Oxford university press, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
D. Furniss, A. Blandford, and P. Curzon, “Confessions from a grounded theory phd: Experiences and lessons learnt,” in <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’11.   New York, NY, USA: Association for Computing Machinery, 2011, p. 113–122.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
A. MacLean, R. M. Young, and T. P. Moran, “Design rationale: The argument behind the artifact,” in <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">SIGCHI Conference on Human Factors in Computing Systems</em>, ser. CHI ’89.   New York, NY, USA: Association for Computing Machinery, 1989, p. 247–252.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
A. Unger, S. Schulte, V. Klemann, and D. Dransch, “A visual analysis concept for the validation of geoscientific simulation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 18, no. 12, pp. 2216–2225, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
H. Piringer, W. Berger, and J. Krasser, “HyperMoVal: Interactive visual validation of regression models for real-time simulation,” <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Computer Graphics Forum</em>, vol. 29, no. 3, pp. 983–992, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
J. Weissenböck, A. Amirkhanov, E. Gröller, J. Kastner, and C. Heinzl, “PorosityAnalyzer: Visual analysis and evaluation of segmentation pipelines to determine the porosity in fiber-reinforced polymers,” in <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">IEEE Conference on Visual Analytics Science and Technology (VAST)</em>, 2016, pp. 101–110.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
W. Berger, H. Piringer, P. Filzmoser, and E. Gröller, “Uncertainty-aware exploration of continuous parameter spaces using multivariate prediction,” <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">Computer Graphics Forum</em>, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
M. Booshehrian, T. Möller, R. M. Peterman, and T. Munzner, “Vismon: Facilitating analysis of trade-offs, uncertainty, and sensitivity in fisheries management decision making,” <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">Computer Graphics Forum</em>, vol. 31, no. 3pt3, pp. 1235–1244, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
M. Luboschik, S. Rybacki, F. Haack, and H.-J. Schulz, “Supporting the integrated visual analysis of input parameters and simulation trajectories,” <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Computers &amp; Graphics</em>, vol. 39, pp. 37 – 47, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
A. Satyanarayan and J. Heer, “Lyra: An interactive visualization design environment,” <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">Computer Graphics Forum</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
B. Shneiderman, “The eyes have it: a task by data type taxonomy for information visualizations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">IEEE Symposium on Visual Languages</em>, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
J. C. Roberts, “Encouraging coupled views for visualization exploration,” in <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Visual Data Exploration and Analysis VI</em>, R. F. Erbacher, P. C. Chen, and C. M. Wittenbrink, Eds.   International Society for Optics and Photonics, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
S. Lee, S. Kim, Y. Hung, H. Lam, Y. Kang, and J. S. Yi, “How do people make sense of unfamiliar visualizations?: A grounded model of novice’s information visualization sensemaking,” <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
D. Ceneda, T. Gschwandtner, T. May, S. Miksch, H. Schulz, M. Streit, and C. Tominski, “Characterizing guidance in visual analytics,” <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 23, no. 1, pp. 111–120, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
M. Khayat, M. Karimzadeh, D. S. Ebert, and A. Ghafoor, “The validity, generalizability and feasibility of summative evaluation methods in visual analytics,” <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 26, no. 1, pp. 353–363, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
T. Isenberg, P. Isenberg, J. Chen, M. Sedlmair, and T. Möller, “A systematic review on the practice of evaluating visualization,” <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
C. W. Turner, J. R. Lewis, and J. Nielsen, “Determining usability test sample size,” <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">International encyclopedia of ergonomics and human factors</em>, vol. 3, no. 2, pp. 3084–3088, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
J. R. Lewis, “Sample sizes for usability studies: Additional considerations,” <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">Human Factors</em>, 1994.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
A. Dasgupta, S. Burrows, K. Han, and P. J. Rasch, “Empirical analysis of the subjective impressions and objective measures of domain scientists’ visual analytic judgments,” in <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Proceedings CHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
J. Brooke, “Sus: a retrospective,” <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Journal of usability studies</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
C. Kittel and P. McEuen, <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">Introduction to solid state physics</em>.   John Wiley &amp; Sons, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
S. Simon, S. Mittelstädt, D. A. Keim, and M. Sedlmair, “Bridging the gap of domain and visualization experts with a liaison,” in <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Eurographics Conference on Visualization (EuroVis) - Short Papers</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
A. M. McNutt, “No grammar to rule them all: A survey of json-style dsls for visualization,” <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
T. S. Tullis and J. N. Stetson, “A comparison of questionnaires for assessing website usability,” in <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">Usability professional association conference</em>, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
W. He, J. Wang, H. Guo, K.-C. Wang, H.-W. Shen, M. Raj, Y. S. G. Nashed, and T. Peterka, “Insitunet: Deep image synthesis for parameter space exploration of ensemble simulations,” <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
M. D. Mckay, R. J. Beckman, and W. J. Conover, “A comparison of three methods for selecting values of input variables in the analysis of output from a computer code,” <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">Technometrics</em>, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Z. He and A. B. Owen, “Extensible grids: uniform sampling on a space filling curve,” <em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
J. Helton and F. Davis, “Latin hypercube sampling and the propagation of uncertainty in analyses of complex systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Reliability Engineering &amp; System Safety</em>, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
A. Bigelow, S. Drucker, D. Fisher, and M. Meyer, “Iterating between tools to create and edit visualizations,” <em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
J. Schneidewind, M. Sips, and D. A. Keim, “Pixnostics: Towards measuring the value of visualization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">2006 IEEE Symposium On Visual Analytics Science And Technology</em>, 2006, pp. 199–206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
L. Wilkinson, A. Anand, and R. Grossman, “Graph-theoretic scagnostics,” in <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">Information Visualization, IEEE Symposium on</em>.   IEEE Computer Society, 2005, pp. 21–21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
A. Dasgupta and R. Kosara, “Pargnostics: Screen-space metrics for parallel coordinates,” <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
B. Bach, Z. Wang, M. Farinella, D. Murray-Rust, and N. Henry Riche, “Design patterns for data comics,” in <em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</em>, New York, NY, USA, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Y. Lin, H. Li, A. Wu, Y. Wang, and H. Qu, “Dminer: Dashboard design mining and recommendation,” 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
M. Oppermann, R. Kincaid, and T. Munzner, “Vizcommender: Computing text-based similarity in visualization repositories for content-based recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
T. Sobral, T. Galvão, and J. Borges, “An ontology-based approach to knowledge-assisted integration and visualization of urban mobility data,” <em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">Expert Systems with Applications</em>, 2020.

</span>
</li>
</ul>
</section>
<figure class="ltx_float biography" id="id1">
<table class="ltx_tabular" id="id1.1">
<tr class="ltx_tr" id="id1.1.1">
<td class="ltx_td" id="id1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="249" id="id1.1.1.1.g1" src="x38.jpg" width="193"/></td>
<td class="ltx_td" id="id1.1.1.2">
<span class="ltx_inline-block" id="id1.1.1.2.1">
<span class="ltx_p" id="id1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id1.1.1.2.1.1.1">Manfred Klaffenboeck</span> 
is a doctoral candidate at TU Wien’s Institute for Visual Computing and Human-Centered Technology in Vienna, Austria.
He earned a Magister degree in Movie and Media Science in 2013, followed by a BSc in Computer Science in 2016 and an MSc in Media Informatics in 2018, all from the University of Vienna.
His research integrates computer graphics, computer vision, data visualization, and media analysis, with a current focus on semi-automated multiverse analysis leveraging (visual) parameter space exploration, visual analytics, and knowledge assistance.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id2">
<table class="ltx_tabular" id="id2.1">
<tr class="ltx_tr" id="id2.1.1">
<td class="ltx_td" id="id2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="230" id="id2.1.1.1.g1" src="x39.jpg" width="199"/></td>
<td class="ltx_td" id="id2.1.1.2">
<span class="ltx_inline-block" id="id2.1.1.2.1">
<span class="ltx_p" id="id2.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id2.1.1.2.1.1.1">Michael Gleicher</span> 
is a Professor in the Department of Computer Sciences at the University of Wisconsin, Madison. Prof. Gleicher is founder of the Department’s Visual Computing Group and co-directs both the Visual Computing Laboratory and the Collaborative Robotics Laboratory at UW-Madison. His research interests span the range of visual computing, including data visualization, robotics, and virtual/extended reality. His recent work includes exploring perceptual issues in visualization, the use of visual simulation for robotics, and geometric approaches to enhance robot perception and interaction.
He earned his Ph. D. in Computer Science (1994) from Carnegie Mellon University, and earned a B.S.E. in Electrical Engineering from Duke University (1988).
In 2023-2024, Prof. Gleicher holds a concurrent appointment as a Design Scholar at Amazon Robotics. This work is not associated with Amazon.
</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id3">
<table class="ltx_tabular" id="id3.1">
<tr class="ltx_tr" id="id3.1.1">
<td class="ltx_td" id="id3.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="249" id="id3.1.1.1.g1" src="x40.jpg" width="21"/></td>
<td class="ltx_td" id="id3.1.1.2">
<span class="ltx_inline-block" id="id3.1.1.2.1">
<span class="ltx_p" id="id3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id3.1.1.2.1.1.1">Johannes Sorger</span> 
received his computer science degree in visual computing from the TU Wien at the Institute of Computer graphics and Algorithms, where he also finished his PhD in collaboration with the VRVis research center. Johannes’ main research interests are centred around the application of visualization as an enabling technology. For his work on the visualization of neuronal networks Johannes received the 2014 OCG Incentive Award, as well as the Best Paper Award at the 2013 IEEE Symposium on Biological Data Visualization.
During his postdoc, he was heading the visualization team at CSH Vienna where he researched novel approaches in Immersive network analytics.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id4">
<table class="ltx_tabular" id="id4.1">
<tr class="ltx_tr" id="id4.1.1">
<td class="ltx_td" id="id4.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="249" id="id4.1.1.1.g1" src="x41.jpg" width="187"/></td>
<td class="ltx_td" id="id4.1.1.2">
<span class="ltx_inline-block" id="id4.1.1.2.1">
<span class="ltx_p" id="id4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id4.1.1.2.1.1.1">Michael Wimmer</span> 
is currently a full professor at the Institute of Visual Computing and Human-Centered Technology at TU Wien, where he heads the Rendering and Modeling Group. He is also the director of the Center for Geometry and Computational Design (GCD). His academic career started with his M.Sc. in 1997 at TU Wien, where he also obtained his Ph.D. in 2001.
His research interests are real-time rendering, computer games, real-time visualization of urban environments, point-based rendering, reconstruction of urban models, procedural modeling, shape modeling, and computational design.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="id5">
<table class="ltx_tabular" id="id5.1">
<tr class="ltx_tr" id="id5.1.1">
<td class="ltx_td" id="id5.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="212" id="id5.1.1.1.g1" src="x42.jpg" width="199"/></td>
<td class="ltx_td" id="id5.1.1.2">
<span class="ltx_inline-block" id="id5.1.1.2.1">
<span class="ltx_p" id="id5.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="id5.1.1.2.1.1.1">Torsten Möller</span> 
(Senior Member, IEEE) received the Vordiplom (BSc) degree in mathematical computer science from the Humboldt University of Berlin, Germany, and the PhD in computer and information science from Ohio State University in 1999. He has been a professor of computer science at the University of Vienna, Austria, since 2013. Between 1999 and 2012, he served as a computing science faculty member at Simon Fraser University, Canada. He is a senior member of ACM, IEEE, and a member of Eurographics. His research interests include algorithms and tools for analyzing and displaying data with principles rooted in computer graphics, human-computer interaction, signal processing, data science, and visualization.</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 10 23:57:07 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
