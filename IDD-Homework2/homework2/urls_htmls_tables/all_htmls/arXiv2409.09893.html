<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation</title>
<!--Generated on Sun Sep 15 23:14:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.09893v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S1" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S2" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S2.SS0.SSS0.Px1" title="In 2 Related Work â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Image Segmentation:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S2.SS0.SSS0.Px2" title="In 2 Related Work â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Scaling Data for Segmentation Models:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS1" title="In 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS2" title="In 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Preliminaries: Model Framework</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS3" title="In 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Language Embeddings as Classifiers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4" title="In 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Label-space Specific Query Embeddings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4.SSS0.Px1" title="In 3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Inconsistent Semantics.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4.SSS0.Px2" title="In 3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Naive approach.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4.SSS0.Px3" title="In 3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Our solution.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4.SSS0.Px4" title="In 3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Underlying intuition.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS5" title="In 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Inference with LSQEs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1" title="In 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px1" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Training datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px2" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Benchmarking Image Segmentation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px3" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Mixed label space benchmarks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px4" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Evaluation Settings.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px5" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Metrics.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px6" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Baselines.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px7" title="In 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Model training.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2" title="In 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Evaluation on Mixed Label Spaces</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2.SSS0.Px1" title="In 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Panoptic Segmentation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2.SSS0.Px2" title="In 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Panoptic post-processing.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2.SSS0.Px3" title="In 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Instance Segmentation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2.SSS0.Px4" title="In 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Semantic Segmentation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS2.SSS0.Px5" title="In 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title">Panoptic Instance Segmentation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS3" title="In 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Evaluation on Per-dataset Label Spaces</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S5" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:144%;">A</span> </span><span class="ltx_text" style="font-size:144%;">Panoptic Segmentation Post-processing</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A2" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:144%;">B</span> </span><span class="ltx_text" style="font-size:144%;">Mixed-label Space Benchmarks</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:144%;">C</span> </span><span class="ltx_text" style="font-size:144%;">Additional Qualitative Comparison</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A4" title="In Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:144%;">D</span> </span><span class="ltx_text" style="font-size:144%;">Model Training Details</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Qilong Zhangli<sup class="ltx_sup" id="id1.1.id1">1</sup>â€ƒDi Liu<sup class="ltx_sup" id="id2.2.id2">1</sup>â€ƒAbhishek Aich<sup class="ltx_sup" id="id3.3.id3">2</sup>â€ƒDimitris N. Metaxas<sup class="ltx_sup" id="id4.4.id4">1</sup>â€ƒSamuel Schulter<sup class="ltx_sup" id="id5.5.id5">2</sup>â€ƒ
<br class="ltx_break"/>
<sup class="ltx_sup" id="id6.6.id6">1</sup>Rutgers Universityâ€ƒ<sup class="ltx_sup" id="id7.7.id7">2</sup>NEC Laboratories America
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">Leveraging multiple training datasets to scale up image segmentation models enhances robustness and semantic understanding. Individual datasets have well-defined ground truth with non-overlapping mask layouts and mutually exclusive semantics. However, merging them for multi-dataset training disrupts this harmony and leads to semantic inconsistencies. For instance, the class â€œpersonâ€ in one dataset and the class â€œfaceâ€ in another will require multilabel handling for certain pixels. Existing methods struggle with this setting, particularly when evaluated on label spaces mixed from the individual training sets. To address these challenges, we introduce a simple yet effective multi-dataset training approach by integrating language-based embeddings of class names and label space-specific query embeddings. Our method maintains high performance regardless of the underlying inconsistencies between training datasets. Notably, on four benchmark datasets with label space inconsistencies during inference, we outperform previous methods by 1.6% mIoU for semantic segmentation, 9.1% PQ for panoptic segmentation, 12.1% AP for instance segmentation, and 3.0% in the newly proposed PIQ metric.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The advancement of image segmentation hinges significantly on scaling models to improve robustness and deepen semantic understandingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib27" title="">27</a>]</cite>. This scaling necessitates an extensive collection of annotated datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib66" title="">66</a>]</cite>. However, creating such datasets is both costly and labor-intensiveÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib12" title="">12</a>]</cite>. Models like SAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib46" title="">46</a>]</cite> and HQ-SAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib22" title="">22</a>]</cite> have demonstrated remarkable capabilities with meticulously curated datasets, but these are extremely expensive to produce and often lack comprehensive semantic labels. An alternative strategy involves leveraging existing datasets that are already annotated. Individually, these datasets maintain a consistent label space, but when combined, their labels may conflict, introducing challenges in maintaining semantic consistency across the datasets.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The concept of multi-dataset training, although progressing in various domains such as object detection and semantic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib2" title="">2</a>]</cite>, presents unique challenges when applied to more complex segmentation scenarios where combining datasets leads to inconsistent semantics. As the number of labels increases, traditional assumptions, such as exclusive per-pixel labeling, become less practical. For example, when combining two datasets, the individual semantics may violate the mutual exclusivity assumption, such as with â€œpersonâ€ and â€œclothingâ€ (retail), â€œroadâ€ and â€œlane markingâ€ (mobility), or â€œpersonâ€ and â€œfaceâ€ (surveillance), as shown in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We found that even state-of-the-art base models, like Mask2Former (M2F)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite>, combined with existing multi-dataset training strategiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite> falter in this setting. While M2F is equipped to meet some of our requirements, it falls short in dealing with the intricacies presented by multi-dataset training (see Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>). This challenge underscores the necessity of not only a more adaptable segmentation model but also a revised approach to benchmarking and ground truth annotationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="201" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.4.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.5.2" style="font-size:90%;">Leveraging multiple datasets for training segmentation models increases robustness and semantic understanding. However, existing methods (1) fail to capture the full masks of objects, such as â€œpersonâ€ category, (2) often predict incorrect labels, for instance, mistaking â€œlegsâ€ for â€œpantsâ€. This issue is caused by unexpected conflicts in multiple label spaces, although each dataset (<span class="ltx_text ltx_font_italic" id="S1.F1.5.2.1">A</span> and <span class="ltx_text ltx_font_italic" id="S1.F1.5.2.2">B</span>) has consistent ground truth mask layouts that provide non-overlapping and mutually-exclusive semantics.
</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In response to these challenges, we propose a novel multi-dataset training framework, <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">RESI</span> (<span class="ltx_text ltx_font_bold" id="S1.p4.1.2">Res</span>olving <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">I</span>nconsistent Semantics in Multi-Dataset Image Segmentation), specifically designed to address the issue of inconsistent semantics in label spaces when training across multiple datasets. Our approach extends the baseline Mask2Former frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> with the following key modifications:</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_italic" id="S1.p5.1.1">First</span>, we replace the fixed-size label space classifier with vision &amp; language embeddings from CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib43" title="">43</a>]</cite>, similar to works likeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib30" title="">30</a>]</cite>. This serves two purposes: <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">(1)</span> mapping all categories into a single, consistent space that preserves semantic relations from the pre-trained vision-language model, and <span class="ltx_text ltx_font_italic" id="S1.p5.1.3">(2)</span> enabling our model to operate with any combination of training set labels at inference.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_italic" id="S1.p6.1.1">Second</span>, we introduce label space-specific query embeddings added as residuals to the transformer decoder in Mask2Former. These learnable embeddings condition the decoder, and thus mask predictions, on the label spaces by retrieving the relevant query embeddings. These enhancements equip our model to effectively adapt to and reconcile the inconsistencies inherent in multi-dataset training.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">To validate our proposed framework RESI, we conduct a series of experiments where we train on various groups of multiple datasets. We compare RESI with multiple baselines on two newly created benchmarks that specifically evaluate situations where the test-time label space is a combination of the individual training datasets.
It is important to note that no single segmentation task - semantic, instance or panoptic - adequately benchmarks scenarios that include (instance-aware) â€œthingâ€ and â€œstuffâ€ classes and that allows semantic overlaps (multilabel). Hence, we evaluate on all three tasks, as well as a newly introduced metric. The Panoptic Instance Quality (PIQ) is innovatively designed to combine the per-pixel classification strength of panoptic segmentation with the ability to accommodate overlapping masks inherent in instance segmentation, thus providing a more comprehensive assessment of segmentation models in mixed label space scenarios.
Averaged over all benchmarks, RESI outperforms the best baseline by 1.6% mIoU for semantic segmentation, 12.1% AP for instance segmentation, 9.1% PQ for panoptic segmentation, and 3.0% on the newly introduced PIQ metric, demonstrating its ability to handle semantic conflicts and overlapping masks. We also demonstrate on-par or better performance on standard multi-dataset benchmarks that evaluate models on the individual label spaces of the training datasets.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Image Segmentation:</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Understanding and interpreting visual data is a core challenge in computer vision encompassing various tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib52" title="">52</a>]</cite>, with segmentation being one of the most important. Different formulations have been proposed, including semantic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib16" title="">16</a>]</cite> (pixels are assigned a semantic class without distinction of instances from the same class), instance segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib18" title="">18</a>]</cite> (separates instances, but does not consider â€œstuffâ€ categories - amorphous non-countable objects like sky or road), and panoptic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib6" title="">6</a>]</cite> (handles all categories and separates instances). With the goal of universal and robust segmentation, the latest research focused on building unified architectures to handle all three task formulations simultaneously. Building on Transformer architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib51" title="">51</a>]</cite>, MaskFormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite>, Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> and UniFormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib33" title="">33</a>]</cite> are good examples of such unified architectures. Our work extends the Mask2Former architecture to better handle semantic inconsistencies when training from multiple datasets, which is a key part when scaling segmentation models.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Scaling Data for Segmentation Models:</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">With the same motivation of universal segmentation comes the requirement of training from large-scale data in order to increase model robustness and semantic understanding. The Segment Anything projectÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib46" title="">46</a>]</cite> demonstrated possibilities but required significant annotation effort and does not address semantic inconsistencies. On the other hand, more cost effective solutions are proposed with open-vocabulary and multi-dataset training.
The goal of <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">open-vocabulary segmentation</em> is to extend semantic understanding to unseen categories without explicit mask annotations. Building on recent advances in vision &amp; language modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib24" title="">24</a>]</cite>, open-vocabulary variants for semantic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib67" title="">67</a>]</cite> and panopticÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib70" title="">70</a>]</cite> segmentation have been proposed. While such works can be trained from multiple datasets, the typical settings and benchmarks for open-vocabulary segmentation do not explicitly challenge the model with inconsistent semantics.
The goal of <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.2">multi-dataset training</em> is to leverage existing datasets with various semantic annotations to improve generalization robustness. Methods have been introduced for object detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite>, semantic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib25" title="">25</a>]</cite>, and panoptic segmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite>.
However, none of the works in open-vocabulary or multi-dataset segmentation investigate or evaluate semantic inconsistencies in label space that arise when combining multiple datasets. In this work, we highlight this issue, demonstrate limitations of existing methods, extend Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> to handle such inconsistencies, and propose methods for effective evaluation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Motivation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">One efficient way to scale up a segmentation model is through multi-dataset training, which involves training a single model to perform accurately across various datasets. However, as we increase the number of classes in such training, we often face label space inconsistencies. Our goal is to facilitate multi-dataset training while accommodating these inconsistencies. A straightforward approach, similar to that inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite>, would be to condition the decoder of an existing MaskFormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> model with the label space. However, our early experiments showed that this method did not significantly improve upon the baseline MaskFormer model. (Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1" title="Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F4" title="Figure 4 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>) We believe this is due to two primary reasons: Firstly, conditioning the MaskFormer decoder on a per-dataset label space restricts the model from understanding novel combinations of categories from different datasets. During inference, the model struggles with new label spaces it did not encounter during training. Secondly, this approach does not adequately address the issue of inconsistent annotations in the training data. For instance, when the mask of â€œpersonâ€ overlaps with the mask of â€œpantsâ€, the modelâ€™s confidence in these regions diminishes, resulting in ambiguous predictions (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Preliminaries: Model Framework</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">Given an image <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_I</annotation></semantics></math>, our segmentation model is designed to predict multiple masks, potentially overlapping, with each mask being associated with a semantic category <math alttext="c\in\{1,\ldots,C\}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.3"><semantics id="S3.SS2.p1.2.m2.3a"><mrow id="S3.SS2.p1.2.m2.3.4" xref="S3.SS2.p1.2.m2.3.4.cmml"><mi id="S3.SS2.p1.2.m2.3.4.2" xref="S3.SS2.p1.2.m2.3.4.2.cmml">c</mi><mo id="S3.SS2.p1.2.m2.3.4.1" xref="S3.SS2.p1.2.m2.3.4.1.cmml">âˆˆ</mo><mrow id="S3.SS2.p1.2.m2.3.4.3.2" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml"><mo id="S3.SS2.p1.2.m2.3.4.3.2.1" stretchy="false" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">{</mo><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">1</mn><mo id="S3.SS2.p1.2.m2.3.4.3.2.2" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p1.2.m2.2.2" mathvariant="normal" xref="S3.SS2.p1.2.m2.2.2.cmml">â€¦</mi><mo id="S3.SS2.p1.2.m2.3.4.3.2.3" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p1.2.m2.3.3" xref="S3.SS2.p1.2.m2.3.3.cmml">C</mi><mo id="S3.SS2.p1.2.m2.3.4.3.2.4" stretchy="false" xref="S3.SS2.p1.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.3b"><apply id="S3.SS2.p1.2.m2.3.4.cmml" xref="S3.SS2.p1.2.m2.3.4"><in id="S3.SS2.p1.2.m2.3.4.1.cmml" xref="S3.SS2.p1.2.m2.3.4.1"></in><ci id="S3.SS2.p1.2.m2.3.4.2.cmml" xref="S3.SS2.p1.2.m2.3.4.2">ğ‘</ci><set id="S3.SS2.p1.2.m2.3.4.3.1.cmml" xref="S3.SS2.p1.2.m2.3.4.3.2"><cn id="S3.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1">1</cn><ci id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">â€¦</ci><ci id="S3.SS2.p1.2.m2.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3">ğ¶</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.3c">c\in\{1,\ldots,C\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.3d">italic_c âˆˆ { 1 , â€¦ , italic_C }</annotation></semantics></math>. This approach deviates from the conventional semantic or panoptic segmentation settings where typically only one label per pixel is predicted with no overlaps allowed.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The set of <math alttext="C" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_C</annotation></semantics></math> categories annotated in each dataset is divided into instance-aware â€œthingâ€ categories (countable objects like cars or persons) and â€œstuffâ€ categories (amorphous, non-countable objects like sky or road). For â€œstuffâ€ categories, instances are irrelevant and thus multiple masks of the same â€œstuffâ€ category are merged.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.7">Our work builds on Mask2Former (M2F)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> but can be easily integrated into other models. This model processes the input image <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_I</annotation></semantics></math> with a combination of a standard visual backbone (CNN or Transformer) and a Transformer-based encoder, which outputs multi-scale visual features. Then, a Transformer-based decoder predicts a set of <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_N</annotation></semantics></math> masks <math alttext="m_{i}\in[0,1]^{H\times W}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.2"><semantics id="S3.SS2.p3.3.m3.2a"><mrow id="S3.SS2.p3.3.m3.2.3" xref="S3.SS2.p3.3.m3.2.3.cmml"><msub id="S3.SS2.p3.3.m3.2.3.2" xref="S3.SS2.p3.3.m3.2.3.2.cmml"><mi id="S3.SS2.p3.3.m3.2.3.2.2" xref="S3.SS2.p3.3.m3.2.3.2.2.cmml">m</mi><mi id="S3.SS2.p3.3.m3.2.3.2.3" xref="S3.SS2.p3.3.m3.2.3.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.3.m3.2.3.1" xref="S3.SS2.p3.3.m3.2.3.1.cmml">âˆˆ</mo><msup id="S3.SS2.p3.3.m3.2.3.3" xref="S3.SS2.p3.3.m3.2.3.3.cmml"><mrow id="S3.SS2.p3.3.m3.2.3.3.2.2" xref="S3.SS2.p3.3.m3.2.3.3.2.1.cmml"><mo id="S3.SS2.p3.3.m3.2.3.3.2.2.1" stretchy="false" xref="S3.SS2.p3.3.m3.2.3.3.2.1.cmml">[</mo><mn id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">0</mn><mo id="S3.SS2.p3.3.m3.2.3.3.2.2.2" xref="S3.SS2.p3.3.m3.2.3.3.2.1.cmml">,</mo><mn id="S3.SS2.p3.3.m3.2.2" xref="S3.SS2.p3.3.m3.2.2.cmml">1</mn><mo id="S3.SS2.p3.3.m3.2.3.3.2.2.3" stretchy="false" xref="S3.SS2.p3.3.m3.2.3.3.2.1.cmml">]</mo></mrow><mrow id="S3.SS2.p3.3.m3.2.3.3.3" xref="S3.SS2.p3.3.m3.2.3.3.3.cmml"><mi id="S3.SS2.p3.3.m3.2.3.3.3.2" xref="S3.SS2.p3.3.m3.2.3.3.3.2.cmml">H</mi><mo id="S3.SS2.p3.3.m3.2.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p3.3.m3.2.3.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p3.3.m3.2.3.3.3.3" xref="S3.SS2.p3.3.m3.2.3.3.3.3.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.2b"><apply id="S3.SS2.p3.3.m3.2.3.cmml" xref="S3.SS2.p3.3.m3.2.3"><in id="S3.SS2.p3.3.m3.2.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.1"></in><apply id="S3.SS2.p3.3.m3.2.3.2.cmml" xref="S3.SS2.p3.3.m3.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.3.2.1.cmml" xref="S3.SS2.p3.3.m3.2.3.2">subscript</csymbol><ci id="S3.SS2.p3.3.m3.2.3.2.2.cmml" xref="S3.SS2.p3.3.m3.2.3.2.2">ğ‘š</ci><ci id="S3.SS2.p3.3.m3.2.3.2.3.cmml" xref="S3.SS2.p3.3.m3.2.3.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.3.m3.2.3.3.cmml" xref="S3.SS2.p3.3.m3.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.3.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.3">superscript</csymbol><interval closure="closed" id="S3.SS2.p3.3.m3.2.3.3.2.1.cmml" xref="S3.SS2.p3.3.m3.2.3.3.2.2"><cn id="S3.SS2.p3.3.m3.1.1.cmml" type="integer" xref="S3.SS2.p3.3.m3.1.1">0</cn><cn id="S3.SS2.p3.3.m3.2.2.cmml" type="integer" xref="S3.SS2.p3.3.m3.2.2">1</cn></interval><apply id="S3.SS2.p3.3.m3.2.3.3.3.cmml" xref="S3.SS2.p3.3.m3.2.3.3.3"><times id="S3.SS2.p3.3.m3.2.3.3.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.3.3.1"></times><ci id="S3.SS2.p3.3.m3.2.3.3.3.2.cmml" xref="S3.SS2.p3.3.m3.2.3.3.3.2">ğ»</ci><ci id="S3.SS2.p3.3.m3.2.3.3.3.3.cmml" xref="S3.SS2.p3.3.m3.2.3.3.3.3">ğ‘Š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.2c">m_{i}\in[0,1]^{H\times W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.2d">italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_H Ã— italic_W end_POSTSUPERSCRIPT</annotation></semantics></math>, with <math alttext="i\in{1,\ldots,N}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.3"><semantics id="S3.SS2.p3.4.m4.3a"><mrow id="S3.SS2.p3.4.m4.3.4" xref="S3.SS2.p3.4.m4.3.4.cmml"><mi id="S3.SS2.p3.4.m4.3.4.2" xref="S3.SS2.p3.4.m4.3.4.2.cmml">i</mi><mo id="S3.SS2.p3.4.m4.3.4.1" xref="S3.SS2.p3.4.m4.3.4.1.cmml">âˆˆ</mo><mrow id="S3.SS2.p3.4.m4.3.4.3.2" xref="S3.SS2.p3.4.m4.3.4.3.1.cmml"><mn id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">1</mn><mo id="S3.SS2.p3.4.m4.3.4.3.2.1" xref="S3.SS2.p3.4.m4.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.2.2" mathvariant="normal" xref="S3.SS2.p3.4.m4.2.2.cmml">â€¦</mi><mo id="S3.SS2.p3.4.m4.3.4.3.2.2" xref="S3.SS2.p3.4.m4.3.4.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.3.3" xref="S3.SS2.p3.4.m4.3.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.3b"><apply id="S3.SS2.p3.4.m4.3.4.cmml" xref="S3.SS2.p3.4.m4.3.4"><in id="S3.SS2.p3.4.m4.3.4.1.cmml" xref="S3.SS2.p3.4.m4.3.4.1"></in><ci id="S3.SS2.p3.4.m4.3.4.2.cmml" xref="S3.SS2.p3.4.m4.3.4.2">ğ‘–</ci><list id="S3.SS2.p3.4.m4.3.4.3.1.cmml" xref="S3.SS2.p3.4.m4.3.4.3.2"><cn id="S3.SS2.p3.4.m4.1.1.cmml" type="integer" xref="S3.SS2.p3.4.m4.1.1">1</cn><ci id="S3.SS2.p3.4.m4.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2">â€¦</ci><ci id="S3.SS2.p3.4.m4.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3">ğ‘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.3c">i\in{1,\ldots,N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.3d">italic_i âˆˆ 1 , â€¦ , italic_N</annotation></semantics></math>, along with class probabilities <math alttext="p_{i}\in\mathbb{R}^{C+1}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mrow id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><msub id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2.2" xref="S3.SS2.p3.5.m5.1.1.2.2.cmml">p</mi><mi id="S3.SS2.p3.5.m5.1.1.2.3" xref="S3.SS2.p3.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.5.m5.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.3.2" xref="S3.SS2.p3.5.m5.1.1.3.3.2.cmml">C</mi><mo id="S3.SS2.p3.5.m5.1.1.3.3.1" xref="S3.SS2.p3.5.m5.1.1.3.3.1.cmml">+</mo><mn id="S3.SS2.p3.5.m5.1.1.3.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><in id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1"></in><apply id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p3.5.m5.1.1.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">â„</ci><apply id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3"><plus id="S3.SS2.p3.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.1"></plus><ci id="S3.SS2.p3.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.2">ğ¶</ci><cn id="S3.SS2.p3.5.m5.1.1.3.3.3.cmml" type="integer" xref="S3.SS2.p3.5.m5.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">p_{i}\in\mathbb{R}^{C+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_C + 1 end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="H,W" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.2"><semantics id="S3.SS2.p3.6.m6.2a"><mrow id="S3.SS2.p3.6.m6.2.3.2" xref="S3.SS2.p3.6.m6.2.3.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">H</mi><mo id="S3.SS2.p3.6.m6.2.3.2.1" xref="S3.SS2.p3.6.m6.2.3.1.cmml">,</mo><mi id="S3.SS2.p3.6.m6.2.2" xref="S3.SS2.p3.6.m6.2.2.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.2b"><list id="S3.SS2.p3.6.m6.2.3.1.cmml" xref="S3.SS2.p3.6.m6.2.3.2"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">ğ»</ci><ci id="S3.SS2.p3.6.m6.2.2.cmml" xref="S3.SS2.p3.6.m6.2.2">ğ‘Š</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.2c">H,W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.2d">italic_H , italic_W</annotation></semantics></math> are downscaled image dimensions and <math alttext="C+1" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">C</mi><mo id="S3.SS2.p3.7.m7.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.cmml">+</mo><mn id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><plus id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1"></plus><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">ğ¶</ci><cn id="S3.SS2.p3.7.m7.1.1.3.cmml" type="integer" xref="S3.SS2.p3.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">C+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_C + 1</annotation></semantics></math> is the number of categories including background.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">Note that this model formulation naturally handles both â€œthingâ€ and â€œstuffâ€ categories and theoretically also allows for mask overlaps. The decoder is a multi-layer Transformer that takes <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_N</annotation></semantics></math> learnable embeddings <math alttext="e^{O}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><msubsup id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2.2" xref="S3.SS2.p4.2.m2.1.1.2.2.cmml">e</mi><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">i</mi><mi id="S3.SS2.p4.2.m2.1.1.2.3" xref="S3.SS2.p4.2.m2.1.1.2.3.cmml">O</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2.2">ğ‘’</ci><ci id="S3.SS2.p4.2.m2.1.1.2.3.cmml" xref="S3.SS2.p4.2.m2.1.1.2.3">ğ‘‚</ci></apply><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">e^{O}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_e start_POSTSUPERSCRIPT italic_O end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> (or <math alttext="O" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">ğ‘‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">O</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_O</annotation></semantics></math>bject queries) as input, and that performs self-attention among the <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_N</annotation></semantics></math> object queries as well as cross-attention with the image features in each layer. The high-level architecture is evident in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.F2" title="Figure 2 â€£ 3.3 Language Embeddings as Classifiers â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a>. The objective of M2F can be defined as</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A4.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}=\sum_{i=1}^{N}l_{\mathrm{C}}\left(p_{i},p^{\mathrm{*}%
}\right)+\left[p^{\mathrm{*}}\neq\emptyset\right]\,l_{\mathrm{BC}}\left(m_{i},%
m^{\mathrm{*}}\right)\;," class="ltx_Math" display="inline" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.7" xref="S3.E1.m1.1.1.1.1.7.cmml">â„’</mi><mo id="S3.E1.m1.1.1.1.1.6" xref="S3.E1.m1.1.1.1.1.6.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml"><mrow id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><munderover id="S3.E1.m1.1.1.1.1.2.2.3a" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><mo id="S3.E1.m1.1.1.1.1.2.2.3.2.2" movablelimits="false" xref="S3.E1.m1.1.1.1.1.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.3.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.3.2.3.2" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E1.m1.1.1.1.1.2.2.3.2.3.1" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E1.m1.1.1.1.1.2.2.3.2.3.3" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.1.1.1.1.2.2.3.3" xref="S3.E1.m1.1.1.1.1.2.2.3.3.cmml">N</mi></munderover></mstyle><mrow id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.cmml"><msub id="S3.E1.m1.1.1.1.1.2.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.2.4.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.4.2" xref="S3.E1.m1.1.1.1.1.2.2.2.4.2.cmml">l</mi><mi id="S3.E1.m1.1.1.1.1.2.2.2.4.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.2.2.2.4.3.cmml">C</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">â¢</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml"><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml">,</mo><msup id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml">p</mi><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">âˆ—</mo></msup><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.2.5" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.5.6" xref="S3.E1.m1.1.1.1.1.5.6.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.5.5" xref="S3.E1.m1.1.1.1.1.5.5.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.3.1.1" xref="S3.E1.m1.1.1.1.1.3.3.1.2.cmml"><mo id="S3.E1.m1.1.1.1.1.3.3.1.1.2" xref="S3.E1.m1.1.1.1.1.3.3.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.1.1.1.1.3.3.1.1.1" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.cmml"><msup id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.2.cmml">p</mi><mo id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.3.cmml">âˆ—</mo></msup><mo id="S3.E1.m1.1.1.1.1.3.3.1.1.1.1" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.1.cmml">â‰ </mo><mi id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.cmml">âˆ…</mi></mrow><mo id="S3.E1.m1.1.1.1.1.3.3.1.1.3" xref="S3.E1.m1.1.1.1.1.3.3.1.2.1.cmml">]</mo></mrow><mo id="S3.E1.m1.1.1.1.1.5.5.4" lspace="0.170em" xref="S3.E1.m1.1.1.1.1.5.5.4.cmml">â¢</mo><msub id="S3.E1.m1.1.1.1.1.5.5.5" xref="S3.E1.m1.1.1.1.1.5.5.5.cmml"><mi id="S3.E1.m1.1.1.1.1.5.5.5.2" xref="S3.E1.m1.1.1.1.1.5.5.5.2.cmml">l</mi><mi id="S3.E1.m1.1.1.1.1.5.5.5.3" xref="S3.E1.m1.1.1.1.1.5.5.5.3.cmml">BC</mi></msub><mo id="S3.E1.m1.1.1.1.1.5.5.4a" xref="S3.E1.m1.1.1.1.1.5.5.4.cmml">â¢</mo><mrow id="S3.E1.m1.1.1.1.1.5.5.3.2" xref="S3.E1.m1.1.1.1.1.5.5.3.3.cmml"><mo id="S3.E1.m1.1.1.1.1.5.5.3.2.3" xref="S3.E1.m1.1.1.1.1.5.5.3.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.4.4.2.1.1" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.4.4.2.1.1.2" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1.2.cmml">m</mi><mi id="S3.E1.m1.1.1.1.1.4.4.2.1.1.3" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.5.5.3.2.4" xref="S3.E1.m1.1.1.1.1.5.5.3.3.cmml">,</mo><msup id="S3.E1.m1.1.1.1.1.5.5.3.2.2" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.5.5.3.2.2.2" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2.2.cmml">m</mi><mo id="S3.E1.m1.1.1.1.1.5.5.3.2.2.3" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2.3.cmml">âˆ—</mo></msup><mo id="S3.E1.m1.1.1.1.1.5.5.3.2.5" rspace="0.280em" xref="S3.E1.m1.1.1.1.1.5.5.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.6.cmml" xref="S3.E1.m1.1.1.1.1.6"></eq><ci id="S3.E1.m1.1.1.1.1.7.cmml" xref="S3.E1.m1.1.1.1.1.7">â„’</ci><apply id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5"><plus id="S3.E1.m1.1.1.1.1.5.6.cmml" xref="S3.E1.m1.1.1.1.1.5.6"></plus><apply id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2"><apply id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3">subscript</csymbol><sum id="S3.E1.m1.1.1.1.1.2.2.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3.2.2"></sum><apply id="S3.E1.m1.1.1.1.1.2.2.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3"><eq id="S3.E1.m1.1.1.1.1.2.2.3.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.1"></eq><ci id="S3.E1.m1.1.1.1.1.2.2.3.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.2">ğ‘–</ci><cn id="S3.E1.m1.1.1.1.1.2.2.3.2.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3.3">ğ‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><times id="S3.E1.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.3"></times><apply id="S3.E1.m1.1.1.1.1.2.2.2.4.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.4.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.4.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.4.2">ğ‘™</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.4.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.4.3">C</ci></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.2">ğ‘</ci><times id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.3"></times></apply></interval></apply></apply><apply id="S3.E1.m1.1.1.1.1.5.5.cmml" xref="S3.E1.m1.1.1.1.1.5.5"><times id="S3.E1.m1.1.1.1.1.5.5.4.cmml" xref="S3.E1.m1.1.1.1.1.5.5.4"></times><apply id="S3.E1.m1.1.1.1.1.3.3.1.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.3.3.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.1.1.1.1.3.3.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1"><neq id="S3.E1.m1.1.1.1.1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.1"></neq><apply id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.2">ğ‘</ci><times id="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.2.3"></times></apply><emptyset id="S3.E1.m1.1.1.1.1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1.1.1.3"></emptyset></apply></apply><apply id="S3.E1.m1.1.1.1.1.5.5.5.cmml" xref="S3.E1.m1.1.1.1.1.5.5.5"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.5.5.5.1.cmml" xref="S3.E1.m1.1.1.1.1.5.5.5">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.5.5.5.2.cmml" xref="S3.E1.m1.1.1.1.1.5.5.5.2">ğ‘™</ci><ci id="S3.E1.m1.1.1.1.1.5.5.5.3.cmml" xref="S3.E1.m1.1.1.1.1.5.5.5.3">BC</ci></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.5.5.3.3.cmml" xref="S3.E1.m1.1.1.1.1.5.5.3.2"><apply id="S3.E1.m1.1.1.1.1.4.4.2.1.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.4.2.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.4.2.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1.2">ğ‘š</ci><ci id="S3.E1.m1.1.1.1.1.4.4.2.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.4.4.2.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.1.1.1.1.5.5.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.5.5.3.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.5.5.3.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2.2">ğ‘š</ci><times id="S3.E1.m1.1.1.1.1.5.5.3.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.5.5.3.2.2.3"></times></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle\mathcal{L}=\sum_{i=1}^{N}l_{\mathrm{C}}\left(p_{i},p^{\mathrm{*}%
}\right)+\left[p^{\mathrm{*}}\neq\emptyset\right]\,l_{\mathrm{BC}}\left(m_{i},%
m^{\mathrm{*}}\right)\;,</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">caligraphic_L = âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_p start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT ) + [ italic_p start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT â‰  âˆ… ] italic_l start_POSTSUBSCRIPT roman_BC end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_m start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.5">where <math alttext="l_{\mathrm{(B)C}}" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><msub id="S3.SS2.p6.1.m1.1.2" xref="S3.SS2.p6.1.m1.1.2.cmml"><mi id="S3.SS2.p6.1.m1.1.2.2" xref="S3.SS2.p6.1.m1.1.2.2.cmml">l</mi><mrow id="S3.SS2.p6.1.m1.1.1.1" xref="S3.SS2.p6.1.m1.1.1.1.cmml"><mrow id="S3.SS2.p6.1.m1.1.1.1.3.2" xref="S3.SS2.p6.1.m1.1.1.1.cmml"><mo id="S3.SS2.p6.1.m1.1.1.1.3.2.1" stretchy="false" xref="S3.SS2.p6.1.m1.1.1.1.cmml">(</mo><mi id="S3.SS2.p6.1.m1.1.1.1.1" mathvariant="normal" xref="S3.SS2.p6.1.m1.1.1.1.1.cmml">B</mi><mo id="S3.SS2.p6.1.m1.1.1.1.3.2.2" stretchy="false" xref="S3.SS2.p6.1.m1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p6.1.m1.1.1.1.2" xref="S3.SS2.p6.1.m1.1.1.1.2.cmml">â¢</mo><mi id="S3.SS2.p6.1.m1.1.1.1.4" mathvariant="normal" xref="S3.SS2.p6.1.m1.1.1.1.4.cmml">C</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><apply id="S3.SS2.p6.1.m1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.1.2.1.cmml" xref="S3.SS2.p6.1.m1.1.2">subscript</csymbol><ci id="S3.SS2.p6.1.m1.1.2.2.cmml" xref="S3.SS2.p6.1.m1.1.2.2">ğ‘™</ci><apply id="S3.SS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1.1"><times id="S3.SS2.p6.1.m1.1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.1.1.2"></times><ci id="S3.SS2.p6.1.m1.1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1.1.1">B</ci><ci id="S3.SS2.p6.1.m1.1.1.1.4.cmml" xref="S3.SS2.p6.1.m1.1.1.1.4">C</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">l_{\mathrm{(B)C}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">italic_l start_POSTSUBSCRIPT ( roman_B ) roman_C end_POSTSUBSCRIPT</annotation></semantics></math> stands for (binary) cross-entropy loss, <math alttext="[\cdot]" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mrow id="S3.SS2.p6.2.m2.1.2.2" xref="S3.SS2.p6.2.m2.1.2.1.cmml"><mo id="S3.SS2.p6.2.m2.1.2.2.1" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.1.1.cmml">[</mo><mo id="S3.SS2.p6.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p6.2.m2.1.1.cmml">â‹…</mo><mo id="S3.SS2.p6.2.m2.1.2.2.2" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><apply id="S3.SS2.p6.2.m2.1.2.1.cmml" xref="S3.SS2.p6.2.m2.1.2.2"><csymbol cd="latexml" id="S3.SS2.p6.2.m2.1.2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">[\cdot]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">[ â‹… ]</annotation></semantics></math> is the indicator function, and <math alttext="\{p,m\}^{\mathrm{*}}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.2"><semantics id="S3.SS2.p6.3.m3.2a"><msup id="S3.SS2.p6.3.m3.2.3" xref="S3.SS2.p6.3.m3.2.3.cmml"><mrow id="S3.SS2.p6.3.m3.2.3.2.2" xref="S3.SS2.p6.3.m3.2.3.2.1.cmml"><mo id="S3.SS2.p6.3.m3.2.3.2.2.1" stretchy="false" xref="S3.SS2.p6.3.m3.2.3.2.1.cmml">{</mo><mi id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml">p</mi><mo id="S3.SS2.p6.3.m3.2.3.2.2.2" xref="S3.SS2.p6.3.m3.2.3.2.1.cmml">,</mo><mi id="S3.SS2.p6.3.m3.2.2" xref="S3.SS2.p6.3.m3.2.2.cmml">m</mi><mo id="S3.SS2.p6.3.m3.2.3.2.2.3" stretchy="false" xref="S3.SS2.p6.3.m3.2.3.2.1.cmml">}</mo></mrow><mo id="S3.SS2.p6.3.m3.2.3.3" xref="S3.SS2.p6.3.m3.2.3.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.2b"><apply id="S3.SS2.p6.3.m3.2.3.cmml" xref="S3.SS2.p6.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.2.3.1.cmml" xref="S3.SS2.p6.3.m3.2.3">superscript</csymbol><set id="S3.SS2.p6.3.m3.2.3.2.1.cmml" xref="S3.SS2.p6.3.m3.2.3.2.2"><ci id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">ğ‘</ci><ci id="S3.SS2.p6.3.m3.2.2.cmml" xref="S3.SS2.p6.3.m3.2.2">ğ‘š</ci></set><times id="S3.SS2.p6.3.m3.2.3.3.cmml" xref="S3.SS2.p6.3.m3.2.3.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.2c">\{p,m\}^{\mathrm{*}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.2d">{ italic_p , italic_m } start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT</annotation></semantics></math> indicate ground truth category (<math alttext="p" class="ltx_Math" display="inline" id="S3.SS2.p6.4.m4.1"><semantics id="S3.SS2.p6.4.m4.1a"><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.1b"><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.4.m4.1d">italic_p</annotation></semantics></math>) and mask (<math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p6.5.m5.1"><semantics id="S3.SS2.p6.5.m5.1a"><mi id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><ci id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.5.m5.1d">italic_m</annotation></semantics></math>). To compute the loss function, a bipartite matching algorithm is employed to optimally pair predictions with ground truth. Once the matching is established, the loss is calculated based on these pairs. Please refer toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> for more details.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">Next, we outline the key adaptations for the multi-dataset training setting: language-based classifiers (Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS3" title="3.3 Language Embeddings as Classifiers â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3.3</span></a>) and label space-specific query embeddings (Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4" title="3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Language Embeddings as Classifiers</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.6">To train from multiple datasets, we need to handle heterogeneous label spaces. While some prior works resolve the conflicting label spaces manuallyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib65" title="">65</a>]</cite> or via post-training optimizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite>, we use language embeddings from the CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib43" title="">43</a>]</cite> text encoder as a simple but effective solution. Instead of directly predicting a probability distribution <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">p</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> with a fixed-label space classifier, our model predicts an embedding vector <math alttext="e^{I}_{i}\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><msubsup id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2.2.2" xref="S3.SS3.p1.2.m2.1.1.2.2.2.cmml">e</mi><mi id="S3.SS3.p1.2.m2.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.2.3.cmml">i</mi><mi id="S3.SS3.p1.2.m2.1.1.2.2.3" xref="S3.SS3.p1.2.m2.1.1.2.2.3.cmml">I</mi></msubsup><mo id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">â„</mi><mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><in id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></in><apply id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.2">subscript</csymbol><apply id="S3.SS3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.2">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2.2.2">ğ‘’</ci><ci id="S3.SS3.p1.2.m2.1.1.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.2.2.3">ğ¼</ci></apply><ci id="S3.SS3.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">â„</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">e^{I}_{i}\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> for each object query <math alttext="i\in\{1,\ldots,N\}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.3"><semantics id="S3.SS3.p1.3.m3.3a"><mrow id="S3.SS3.p1.3.m3.3.4" xref="S3.SS3.p1.3.m3.3.4.cmml"><mi id="S3.SS3.p1.3.m3.3.4.2" xref="S3.SS3.p1.3.m3.3.4.2.cmml">i</mi><mo id="S3.SS3.p1.3.m3.3.4.1" xref="S3.SS3.p1.3.m3.3.4.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p1.3.m3.3.4.3.2" xref="S3.SS3.p1.3.m3.3.4.3.1.cmml"><mo id="S3.SS3.p1.3.m3.3.4.3.2.1" stretchy="false" xref="S3.SS3.p1.3.m3.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">1</mn><mo id="S3.SS3.p1.3.m3.3.4.3.2.2" xref="S3.SS3.p1.3.m3.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p1.3.m3.2.2" mathvariant="normal" xref="S3.SS3.p1.3.m3.2.2.cmml">â€¦</mi><mo id="S3.SS3.p1.3.m3.3.4.3.2.3" xref="S3.SS3.p1.3.m3.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p1.3.m3.3.3" xref="S3.SS3.p1.3.m3.3.3.cmml">N</mi><mo id="S3.SS3.p1.3.m3.3.4.3.2.4" stretchy="false" xref="S3.SS3.p1.3.m3.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.3b"><apply id="S3.SS3.p1.3.m3.3.4.cmml" xref="S3.SS3.p1.3.m3.3.4"><in id="S3.SS3.p1.3.m3.3.4.1.cmml" xref="S3.SS3.p1.3.m3.3.4.1"></in><ci id="S3.SS3.p1.3.m3.3.4.2.cmml" xref="S3.SS3.p1.3.m3.3.4.2">ğ‘–</ci><set id="S3.SS3.p1.3.m3.3.4.3.1.cmml" xref="S3.SS3.p1.3.m3.3.4.3.2"><cn id="S3.SS3.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS3.p1.3.m3.1.1">1</cn><ci id="S3.SS3.p1.3.m3.2.2.cmml" xref="S3.SS3.p1.3.m3.2.2">â€¦</ci><ci id="S3.SS3.p1.3.m3.3.3.cmml" xref="S3.SS3.p1.3.m3.3.3">ğ‘</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.3c">i\in\{1,\ldots,N\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.3d">italic_i âˆˆ { 1 , â€¦ , italic_N }</annotation></semantics></math>. We then use CLIPâ€™s (pre-trained and frozen) text-encoder to compute embedding vectors <math alttext="e^{T}_{c}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><msubsup id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.2.2.cmml">e</mi><mi id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">c</mi><mi id="S3.SS3.p1.4.m4.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.2.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><apply id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2.2">ğ‘’</ci><ci id="S3.SS3.p1.4.m4.1.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.2.3">ğ‘‡</ci></apply><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">e^{T}_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> for each category <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m5.1"><semantics id="S3.SS3.p1.5.m5.1a"><mi id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m5.1d">italic_c</annotation></semantics></math>. Based on these two embedding vectors, we can define the class probability <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m6.1"><semantics id="S3.SS3.p1.6.m6.1a"><msub id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2" xref="S3.SS3.p1.6.m6.1.1.2.cmml">p</mi><mi id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">ğ‘</ci><ci id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m6.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{i}=\mathrm{S}\left(\frac{1}{\tau}\left[\langle e^{I}_{i},e^{T}_{1}\rangle,%
\ldots,\langle e^{I}_{i},e^{T}_{C}\rangle,\langle e^{I}_{i},e^{T}_{\emptyset}%
\rangle\right]\right)\;," class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3" mathvariant="normal" xref="S3.E2.m1.2.2.1.1.1.3.cmml">S</mi><mo id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mfrac id="S3.E2.m1.2.2.1.1.1.1.1.1.5" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5.cmml"><mn id="S3.E2.m1.2.2.1.1.1.1.1.1.5.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5.2.cmml">1</mn><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.5.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5.3.cmml">Ï„</mi></mfrac><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.4.cmml">â¢</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml">[</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">âŸ¨</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">e</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">I</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">e</mi><mn id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml">1</mn><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">T</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">âŸ©</mo></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.5" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml">,</mo><mi id="S3.E2.m1.1.1" mathvariant="normal" xref="S3.E2.m1.1.1.cmml">â€¦</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.6" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml">âŸ¨</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.2.cmml">e</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.3.cmml">i</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.3.cmml">I</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.2.cmml">e</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3.cmml">C</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.3.cmml">T</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.5" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml">âŸ©</mo></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.7" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.3.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.3" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.3.cmml">âŸ¨</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.2.cmml">e</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.3.cmml">i</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.3.cmml">I</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.2.cmml">e</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.3" mathvariant="normal" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.3.cmml">âˆ…</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.3.cmml">T</mi></msubsup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.5" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.3.cmml">âŸ©</mo></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.8" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml">]</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.3" rspace="0.280em" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">ğ‘</ci><ci id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"></times><ci id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3">S</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.4"></times><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5"><divide id="S3.E2.m1.2.2.1.1.1.1.1.1.5.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5"></divide><cn id="S3.E2.m1.2.2.1.1.1.1.1.1.5.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5.2">1</cn><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.5.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.5.3">ğœ</ci></apply><list id="S3.E2.m1.2.2.1.1.1.1.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3"><list id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3">ğ¼</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3">ğ‘‡</ci></apply><cn id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3">1</cn></apply></list><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">â€¦</ci><list id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.2.3">ğ¼</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.2.3">ğ‘‡</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.2.2.2.2.3">ğ¶</ci></apply></list><list id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.2.3">ğ¼</ci></apply><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2">subscript</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.2.3">ğ‘‡</ci></apply><emptyset id="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.3.3.2.2.3"></emptyset></apply></list></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">p_{i}=\mathrm{S}\left(\frac{1}{\tau}\left[\langle e^{I}_{i},e^{T}_{1}\rangle,%
\ldots,\langle e^{I}_{i},e^{T}_{C}\rangle,\langle e^{I}_{i},e^{T}_{\emptyset}%
\rangle\right]\right)\;,</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_S ( divide start_ARG 1 end_ARG start_ARG italic_Ï„ end_ARG [ âŸ¨ italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT âŸ© , â€¦ , âŸ¨ italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT âŸ© , âŸ¨ italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT âˆ… end_POSTSUBSCRIPT âŸ© ] ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.10">where <math alttext="\mathrm{S}(\cdot)" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.2" xref="S3.SS3.p3.1.m1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.2.2" mathvariant="normal" xref="S3.SS3.p3.1.m1.1.2.2.cmml">S</mi><mo id="S3.SS3.p3.1.m1.1.2.1" xref="S3.SS3.p3.1.m1.1.2.1.cmml">â¢</mo><mrow id="S3.SS3.p3.1.m1.1.2.3.2" xref="S3.SS3.p3.1.m1.1.2.cmml"><mo id="S3.SS3.p3.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS3.p3.1.m1.1.2.cmml">(</mo><mo id="S3.SS3.p3.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p3.1.m1.1.1.cmml">â‹…</mo><mo id="S3.SS3.p3.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS3.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.2"><times id="S3.SS3.p3.1.m1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.2.1"></times><ci id="S3.SS3.p3.1.m1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.2.2">S</ci><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathrm{S}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">roman_S ( â‹… )</annotation></semantics></math> is the SoftMax function, <math alttext="\langle\cdot,\cdot\rangle" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.2"><semantics id="S3.SS3.p3.2.m2.2a"><mrow id="S3.SS3.p3.2.m2.2.3.2" xref="S3.SS3.p3.2.m2.2.3.1.cmml"><mo id="S3.SS3.p3.2.m2.2.3.2.1" stretchy="false" xref="S3.SS3.p3.2.m2.2.3.1.cmml">âŸ¨</mo><mo id="S3.SS3.p3.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p3.2.m2.1.1.cmml">â‹…</mo><mo id="S3.SS3.p3.2.m2.2.3.2.2" rspace="0em" xref="S3.SS3.p3.2.m2.2.3.1.cmml">,</mo><mo id="S3.SS3.p3.2.m2.2.2" lspace="0em" rspace="0em" xref="S3.SS3.p3.2.m2.2.2.cmml">â‹…</mo><mo id="S3.SS3.p3.2.m2.2.3.2.3" stretchy="false" xref="S3.SS3.p3.2.m2.2.3.1.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.2b"><list id="S3.SS3.p3.2.m2.2.3.1.cmml" xref="S3.SS3.p3.2.m2.2.3.2"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">â‹…</ci><ci id="S3.SS3.p3.2.m2.2.2.cmml" xref="S3.SS3.p3.2.m2.2.2">â‹…</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.2c">\langle\cdot,\cdot\rangle</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.2d">âŸ¨ â‹… , â‹… âŸ©</annotation></semantics></math> denotes the dot product and <math alttext="e^{T}_{\emptyset}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><msubsup id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2.2" xref="S3.SS3.p3.3.m3.1.1.2.2.cmml">e</mi><mi id="S3.SS3.p3.3.m3.1.1.3" mathvariant="normal" xref="S3.SS3.p3.3.m3.1.1.3.cmml">âˆ…</mi><mi id="S3.SS3.p3.3.m3.1.1.2.3" xref="S3.SS3.p3.3.m3.1.1.2.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><apply id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.2.1.cmml" xref="S3.SS3.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2.2">ğ‘’</ci><ci id="S3.SS3.p3.3.m3.1.1.2.3.cmml" xref="S3.SS3.p3.3.m3.1.1.2.3">ğ‘‡</ci></apply><emptyset id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">e^{T}_{\emptyset}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT âˆ… end_POSTSUBSCRIPT</annotation></semantics></math> is an all-zero vector representing the â€œno-objectâ€ class, following <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib59" title="">59</a>]</cite>. We set the temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m4.1d">italic_Ï„</annotation></semantics></math> to <math alttext="0.01" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m5.1"><semantics id="S3.SS3.p3.5.m5.1a"><mn id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><cn id="S3.SS3.p3.5.m5.1.1.cmml" type="float" xref="S3.SS3.p3.5.m5.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">0.01</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m5.1d">0.01</annotation></semantics></math>Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib43" title="">43</a>]</cite>. All embedding vectors <math alttext="e^{\{I,T\}}" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m6.2"><semantics id="S3.SS3.p3.6.m6.2a"><msup id="S3.SS3.p3.6.m6.2.3" xref="S3.SS3.p3.6.m6.2.3.cmml"><mi id="S3.SS3.p3.6.m6.2.3.2" xref="S3.SS3.p3.6.m6.2.3.2.cmml">e</mi><mrow id="S3.SS3.p3.6.m6.2.2.2.4" xref="S3.SS3.p3.6.m6.2.2.2.3.cmml"><mo id="S3.SS3.p3.6.m6.2.2.2.4.1" stretchy="false" xref="S3.SS3.p3.6.m6.2.2.2.3.cmml">{</mo><mi id="S3.SS3.p3.6.m6.1.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.1.cmml">I</mi><mo id="S3.SS3.p3.6.m6.2.2.2.4.2" xref="S3.SS3.p3.6.m6.2.2.2.3.cmml">,</mo><mi id="S3.SS3.p3.6.m6.2.2.2.2" xref="S3.SS3.p3.6.m6.2.2.2.2.cmml">T</mi><mo id="S3.SS3.p3.6.m6.2.2.2.4.3" stretchy="false" xref="S3.SS3.p3.6.m6.2.2.2.3.cmml">}</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.2b"><apply id="S3.SS3.p3.6.m6.2.3.cmml" xref="S3.SS3.p3.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.2.3.1.cmml" xref="S3.SS3.p3.6.m6.2.3">superscript</csymbol><ci id="S3.SS3.p3.6.m6.2.3.2.cmml" xref="S3.SS3.p3.6.m6.2.3.2">ğ‘’</ci><set id="S3.SS3.p3.6.m6.2.2.2.3.cmml" xref="S3.SS3.p3.6.m6.2.2.2.4"><ci id="S3.SS3.p3.6.m6.1.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1">ğ¼</ci><ci id="S3.SS3.p3.6.m6.2.2.2.2.cmml" xref="S3.SS3.p3.6.m6.2.2.2.2">ğ‘‡</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.2c">e^{\{I,T\}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m6.2d">italic_e start_POSTSUPERSCRIPT { italic_I , italic_T } end_POSTSUPERSCRIPT</annotation></semantics></math> are <math alttext="\ell_{2}" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m7.1"><semantics id="S3.SS3.p3.7.m7.1a"><msub id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml"><mi id="S3.SS3.p3.7.m7.1.1.2" mathvariant="normal" xref="S3.SS3.p3.7.m7.1.1.2.cmml">â„“</mi><mn id="S3.SS3.p3.7.m7.1.1.3" xref="S3.SS3.p3.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><apply id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m7.1.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p3.7.m7.1.1.2.cmml" xref="S3.SS3.p3.7.m7.1.1.2">â„“</ci><cn id="S3.SS3.p3.7.m7.1.1.3.cmml" type="integer" xref="S3.SS3.p3.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">\ell_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m7.1d">roman_â„“ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>-normalized. The class probability <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m8.1"><semantics id="S3.SS3.p3.8.m8.1a"><msub id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">p</mi><mi id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2">ğ‘</ci><ci id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m8.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> can be plugged into Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.E1" title="Equation 1 â€£ 3.2 Preliminaries: Model Framework â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a> for training. During training, we first sample a dataset <math alttext="k\in\{1,\ldots,K\}" class="ltx_Math" display="inline" id="S3.SS3.p3.9.m9.3"><semantics id="S3.SS3.p3.9.m9.3a"><mrow id="S3.SS3.p3.9.m9.3.4" xref="S3.SS3.p3.9.m9.3.4.cmml"><mi id="S3.SS3.p3.9.m9.3.4.2" xref="S3.SS3.p3.9.m9.3.4.2.cmml">k</mi><mo id="S3.SS3.p3.9.m9.3.4.1" xref="S3.SS3.p3.9.m9.3.4.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p3.9.m9.3.4.3.2" xref="S3.SS3.p3.9.m9.3.4.3.1.cmml"><mo id="S3.SS3.p3.9.m9.3.4.3.2.1" stretchy="false" xref="S3.SS3.p3.9.m9.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml">1</mn><mo id="S3.SS3.p3.9.m9.3.4.3.2.2" xref="S3.SS3.p3.9.m9.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p3.9.m9.2.2" mathvariant="normal" xref="S3.SS3.p3.9.m9.2.2.cmml">â€¦</mi><mo id="S3.SS3.p3.9.m9.3.4.3.2.3" xref="S3.SS3.p3.9.m9.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p3.9.m9.3.3" xref="S3.SS3.p3.9.m9.3.3.cmml">K</mi><mo id="S3.SS3.p3.9.m9.3.4.3.2.4" stretchy="false" xref="S3.SS3.p3.9.m9.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.3b"><apply id="S3.SS3.p3.9.m9.3.4.cmml" xref="S3.SS3.p3.9.m9.3.4"><in id="S3.SS3.p3.9.m9.3.4.1.cmml" xref="S3.SS3.p3.9.m9.3.4.1"></in><ci id="S3.SS3.p3.9.m9.3.4.2.cmml" xref="S3.SS3.p3.9.m9.3.4.2">ğ‘˜</ci><set id="S3.SS3.p3.9.m9.3.4.3.1.cmml" xref="S3.SS3.p3.9.m9.3.4.3.2"><cn id="S3.SS3.p3.9.m9.1.1.cmml" type="integer" xref="S3.SS3.p3.9.m9.1.1">1</cn><ci id="S3.SS3.p3.9.m9.2.2.cmml" xref="S3.SS3.p3.9.m9.2.2">â€¦</ci><ci id="S3.SS3.p3.9.m9.3.3.cmml" xref="S3.SS3.p3.9.m9.3.3">ğ¾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.3c">k\in\{1,\ldots,K\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.9.m9.3d">italic_k âˆˆ { 1 , â€¦ , italic_K }</annotation></semantics></math>, which defines the active label space <math alttext="\mathcal{L}_{k}" class="ltx_Math" display="inline" id="S3.SS3.p3.10.m10.1"><semantics id="S3.SS3.p3.10.m10.1a"><msub id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml">â„’</mi><mi id="S3.SS3.p3.10.m10.1.1.3" xref="S3.SS3.p3.10.m10.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b"><apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2">â„’</ci><ci id="S3.SS3.p3.10.m10.1.1.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">\mathcal{L}_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.10.m10.1d">caligraphic_L start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> that is used in the current iteration. The pre-defined embedding space of the vision-and-language model naturally handles the different label spaces. While each category has its own spots in the embedding space, different names of the same semantic category (e.g., synonyms like â€œsofaâ€ and â€œcouchâ€) will be close due to the large-scale pre-training of CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib43" title="">43</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="270" id="S3.F2.g1" src="extracted/5856734/figures/framework_overview.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.7.2.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.2.1" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S3.F2.2.1.1">Overview of our proposed framework</span>: <span class="ltx_text ltx_font_italic" id="S3.F2.2.1.2">Training</span>. We build upon Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> and replace the fixed-label space classifier with language-based embeddings. We introduce learnable label space-specific query embeddings (LSQE) that are added to the decoder in order to handle conflicting label spaces that arise in the multi-dataset setting.
<span class="ltx_text ltx_font_italic" id="S3.F2.2.1.3">Inference</span>. Given a new label space for inference â€“ any combination of the categories of the training datasets â€“ the model first predicts what training label spaces can â€œserveâ€ the test-label space by matching the text-embeddings of the class names. This process selects the LSQEs that are needed for inference. Then, the decoder of the model runs for each selected LSQE â€“ at most <math alttext="K" class="ltx_Math" display="inline" id="S3.F2.2.1.m1.1"><semantics id="S3.F2.2.1.m1.1b"><mi id="S3.F2.2.1.m1.1.1" xref="S3.F2.2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.F2.2.1.m1.1c"><ci id="S3.F2.2.1.m1.1.1.cmml" xref="S3.F2.2.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.1.m1.1d">K</annotation><annotation encoding="application/x-llamapun" id="S3.F2.2.1.m1.1e">italic_K</annotation></semantics></math>, the number of training datasets.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Label-space Specific Query Embeddings</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">While <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.1">language-based classifiers like CLIP</span> are powerful in mapping diverse label spaces into a unified embedding space, they alone <span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.2">are not sufficient to fully resolve inconsistent semantics across multiple datasets</span>. CLIP helps align categories with similar meanings but does not address overlapping masks, hierarchical inconsistencies (e.g., â€œpersonâ€ vs. â€œsunglasses on a personâ€), or conflicting annotations in multi-dataset training.</p>
</div>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Inconsistent Semantics.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">In multi-dataset training, semantic conflicts can naturally emerge when different datasets annotate objects at varying levels within a semantic hierarchy. An example of such a hierarchy is the <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS0.Px1.p1.1.1">part-whole</span> relationship. For instance, Dataset <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS0.Px1.p1.1.2">A</span> might annotate â€œcarâ€, while Dataset <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS0.Px1.p1.1.3">B</span> focuses on parts, like â€œwheelâ€. Inconsistencies can also arise between datasets. For example, Dataset <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS0.Px1.p1.1.4">C</span> could annotate â€œpersonâ€ in natural images, whereas Dataset <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS0.Px1.p1.1.5">D</span> might annotate accessories like â€œsunglassesâ€ in product photos. Individually, each dataset maintains semantic consistency and follows the principle that one pixel should belong to exactly one semantic class and one object instance (if it belongs to a â€œthingâ€ class). However, inconsistencies emerge when these label spaces are combined, resulting in scenarios where one pixel might correspond to two different semantic classes and instance masks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Naive approach.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">While instance segmentation methods naturally handle overlaps, they do not integrate â€œstuffâ€ categories. However, the Mask2Former framework, as described above, provides this flexibility, offering state-of-the-art instance segmentation results while handling both â€œthingâ€ and â€œstuffâ€ categories. We also experimented with Mask2Former in this setting. However, even after incorporating language-based embeddings as classifiers, the resulting models often struggled with semantically inconsistent relationships between label spaces (details provided in the supplementary materials).</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Our solution.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px3.p1.7">To resolve potential conflicts due to inconsistent semantic relations when training from multiple datasets, we introduce label space-specific query embeddings (<span class="ltx_text ltx_font_bold" id="S3.SS4.SSS0.Px3.p1.7.1">LSQE</span>) in the decoder-transformer of Mask2Former. These are <math alttext="K" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS4.SSS0.Px3.p1.1.m1.1a"><mi id="S3.SS4.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.1.m1.1b"><ci id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.1.m1.1d">italic_K</annotation></semantics></math> learnable embeddings <math alttext="e^{L}_{k}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.2.m2.1"><semantics id="S3.SS4.SSS0.Px3.p1.2.m2.1a"><msubsup id="S3.SS4.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.2" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">e</mi><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.cmml">k</mi><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.3" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.3.cmml">L</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.2.m2.1b"><apply id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.2">ğ‘’</ci><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.3">ğ¿</ci></apply><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.2.m2.1c">e^{L}_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.2.m2.1d">italic_e start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> (same dimension size as <math alttext="e^{O}_{i}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.3.m3.1"><semantics id="S3.SS4.SSS0.Px3.p1.3.m3.1a"><msubsup id="S3.SS4.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.2" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.2.cmml">e</mi><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.cmml">i</mi><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.3" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.3.cmml">O</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.2">ğ‘’</ci><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.3">ğ‘‚</ci></apply><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.3.m3.1c">e^{O}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.3.m3.1d">italic_e start_POSTSUPERSCRIPT italic_O end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>), one for each of the <math alttext="K" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.4.m4.1"><semantics id="S3.SS4.SSS0.Px3.p1.4.m4.1a"><mi id="S3.SS4.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS4.SSS0.Px3.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.4.m4.1b"><ci id="S3.SS4.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.4.m4.1d">italic_K</annotation></semantics></math> training datasets. When training from an image of dataset <math alttext="k" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.5.m5.1"><semantics id="S3.SS4.SSS0.Px3.p1.5.m5.1a"><mi id="S3.SS4.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS4.SSS0.Px3.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.5.m5.1b"><ci id="S3.SS4.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.5.m5.1d">italic_k</annotation></semantics></math>, we add the corresponding LSQE to each of the <math alttext="N" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.6.m6.1"><semantics id="S3.SS4.SSS0.Px3.p1.6.m6.1a"><mi id="S3.SS4.SSS0.Px3.p1.6.m6.1.1" xref="S3.SS4.SSS0.Px3.p1.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.6.m6.1b"><ci id="S3.SS4.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.6.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.6.m6.1d">italic_N</annotation></semantics></math> object query embeddings, obtaining new inputs to the decoder as <math alttext="e^{O,k}_{i}=e^{O}_{i}+e^{L}_{k}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.7.m7.2"><semantics id="S3.SS4.SSS0.Px3.p1.7.m7.2a"><mrow id="S3.SS4.SSS0.Px3.p1.7.m7.2.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.cmml"><msubsup id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.cmml"><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.2.cmml">e</mi><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.3.cmml">i</mi><mrow id="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.4" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.3.cmml"><mi id="S3.SS4.SSS0.Px3.p1.7.m7.1.1.1.1" xref="S3.SS4.SSS0.Px3.p1.7.m7.1.1.1.1.cmml">O</mi><mo id="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.4.1" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.2.cmml">k</mi></mrow></msubsup><mo id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.1" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.1.cmml">=</mo><mrow id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.cmml"><msubsup id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.cmml"><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.2.cmml">e</mi><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.3.cmml">i</mi><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.3.cmml">O</mi></msubsup><mo id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.1" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.1.cmml">+</mo><msubsup id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.cmml"><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.2" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.2.cmml">e</mi><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.3.cmml">k</mi><mi id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.3" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.3.cmml">L</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.7.m7.2b"><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3"><eq id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.1"></eq><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2">subscript</csymbol><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2">superscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.2.2">ğ‘’</ci><list id="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.4"><ci id="S3.SS4.SSS0.Px3.p1.7.m7.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.1.1.1.1">ğ‘‚</ci><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.2.2.2">ğ‘˜</ci></list></apply><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.2.3">ğ‘–</ci></apply><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3"><plus id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.1"></plus><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2">subscript</csymbol><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2">superscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.2">ğ‘’</ci><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.2.3">ğ‘‚</ci></apply><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.2.3">ğ‘–</ci></apply><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3">subscript</csymbol><apply id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.1.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3">superscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.2.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.2">ğ‘’</ci><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.2.3">ğ¿</ci></apply><ci id="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.7.m7.2.3.3.3.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.7.m7.2c">e^{O,k}_{i}=e^{O}_{i}+e^{L}_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.7.m7.2d">italic_e start_POSTSUPERSCRIPT italic_O , italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_e start_POSTSUPERSCRIPT italic_O end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_e start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>. Hence, LSQEs introduce a decomposition of object queries into object-specific and label space-specific parts, which we illustrate in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.F2" title="Figure 2 â€£ 3.3 Language Embeddings as Classifiers â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Underlying intuition.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px4.p1.1">LSQEs give the model the freedom to internally resolve potential conflicts, while at the same time leverage common information from multiple datasets. Similar to UniDetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite>, the label space-specific information is multiplexed through the network. Images from multiple datasets and label spaces go into the network and predictions for individual datasets are made. While <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite> computes per-label space probabilities with only the last classification layer, our LSQEs allow the model to consider this information throughout the whole decoder stage, which can also influence the mask predictions.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Inference with LSQEs</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.6">Associated with each of the <math alttext="K" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">italic_K</annotation></semantics></math> LSQEs are the class embedding vectors for each individual dataset <math alttext="\{e^{T}_{c,k}\}" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.3"><semantics id="S3.SS5.p1.2.m2.3a"><mrow id="S3.SS5.p1.2.m2.3.3.1" xref="S3.SS5.p1.2.m2.3.3.2.cmml"><mo id="S3.SS5.p1.2.m2.3.3.1.2" stretchy="false" xref="S3.SS5.p1.2.m2.3.3.2.cmml">{</mo><msubsup id="S3.SS5.p1.2.m2.3.3.1.1" xref="S3.SS5.p1.2.m2.3.3.1.1.cmml"><mi id="S3.SS5.p1.2.m2.3.3.1.1.2.2" xref="S3.SS5.p1.2.m2.3.3.1.1.2.2.cmml">e</mi><mrow id="S3.SS5.p1.2.m2.2.2.2.4" xref="S3.SS5.p1.2.m2.2.2.2.3.cmml"><mi id="S3.SS5.p1.2.m2.1.1.1.1" xref="S3.SS5.p1.2.m2.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p1.2.m2.2.2.2.4.1" xref="S3.SS5.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS5.p1.2.m2.2.2.2.2" xref="S3.SS5.p1.2.m2.2.2.2.2.cmml">k</mi></mrow><mi id="S3.SS5.p1.2.m2.3.3.1.1.2.3" xref="S3.SS5.p1.2.m2.3.3.1.1.2.3.cmml">T</mi></msubsup><mo id="S3.SS5.p1.2.m2.3.3.1.3" stretchy="false" xref="S3.SS5.p1.2.m2.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.3b"><set id="S3.SS5.p1.2.m2.3.3.2.cmml" xref="S3.SS5.p1.2.m2.3.3.1"><apply id="S3.SS5.p1.2.m2.3.3.1.1.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.3.3.1.1.1.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1">subscript</csymbol><apply id="S3.SS5.p1.2.m2.3.3.1.1.2.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.3.3.1.1.2.1.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1">superscript</csymbol><ci id="S3.SS5.p1.2.m2.3.3.1.1.2.2.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p1.2.m2.3.3.1.1.2.3.cmml" xref="S3.SS5.p1.2.m2.3.3.1.1.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p1.2.m2.2.2.2.3.cmml" xref="S3.SS5.p1.2.m2.2.2.2.4"><ci id="S3.SS5.p1.2.m2.1.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1.1.1">ğ‘</ci><ci id="S3.SS5.p1.2.m2.2.2.2.2.cmml" xref="S3.SS5.p1.2.m2.2.2.2.2">ğ‘˜</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.3c">\{e^{T}_{c,k}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.2.m2.3d">{ italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , italic_k end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="k" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1"><semantics id="S3.SS5.p1.3.m3.1a"><mi id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><ci id="S3.SS5.p1.3.m3.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.3.m3.1d">italic_k</annotation></semantics></math> indices the label-space and <math alttext="c" class="ltx_Math" display="inline" id="S3.SS5.p1.4.m4.1"><semantics id="S3.SS5.p1.4.m4.1a"><mi id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><ci id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.4.m4.1d">italic_c</annotation></semantics></math> the class within that label-space. During inference, our model can take any combination of categories from all training datasets as the input label space, which are also encoded with the CLIP text-encoder to <math alttext="\{e^{T}_{c,*}\}" class="ltx_Math" display="inline" id="S3.SS5.p1.5.m5.3"><semantics id="S3.SS5.p1.5.m5.3a"><mrow id="S3.SS5.p1.5.m5.3.3.1" xref="S3.SS5.p1.5.m5.3.3.2.cmml"><mo id="S3.SS5.p1.5.m5.3.3.1.2" stretchy="false" xref="S3.SS5.p1.5.m5.3.3.2.cmml">{</mo><msubsup id="S3.SS5.p1.5.m5.3.3.1.1" xref="S3.SS5.p1.5.m5.3.3.1.1.cmml"><mi id="S3.SS5.p1.5.m5.3.3.1.1.2.2" xref="S3.SS5.p1.5.m5.3.3.1.1.2.2.cmml">e</mi><mrow id="S3.SS5.p1.5.m5.2.2.2.4" xref="S3.SS5.p1.5.m5.2.2.2.3.cmml"><mi id="S3.SS5.p1.5.m5.1.1.1.1" xref="S3.SS5.p1.5.m5.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p1.5.m5.2.2.2.4.1" rspace="0em" xref="S3.SS5.p1.5.m5.2.2.2.3.cmml">,</mo><mo id="S3.SS5.p1.5.m5.2.2.2.2" lspace="0em" xref="S3.SS5.p1.5.m5.2.2.2.2.cmml">âˆ—</mo></mrow><mi id="S3.SS5.p1.5.m5.3.3.1.1.2.3" xref="S3.SS5.p1.5.m5.3.3.1.1.2.3.cmml">T</mi></msubsup><mo id="S3.SS5.p1.5.m5.3.3.1.3" stretchy="false" xref="S3.SS5.p1.5.m5.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.5.m5.3b"><set id="S3.SS5.p1.5.m5.3.3.2.cmml" xref="S3.SS5.p1.5.m5.3.3.1"><apply id="S3.SS5.p1.5.m5.3.3.1.1.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.5.m5.3.3.1.1.1.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1">subscript</csymbol><apply id="S3.SS5.p1.5.m5.3.3.1.1.2.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.5.m5.3.3.1.1.2.1.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1">superscript</csymbol><ci id="S3.SS5.p1.5.m5.3.3.1.1.2.2.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p1.5.m5.3.3.1.1.2.3.cmml" xref="S3.SS5.p1.5.m5.3.3.1.1.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p1.5.m5.2.2.2.3.cmml" xref="S3.SS5.p1.5.m5.2.2.2.4"><ci id="S3.SS5.p1.5.m5.1.1.1.1.cmml" xref="S3.SS5.p1.5.m5.1.1.1.1">ğ‘</ci><times id="S3.SS5.p1.5.m5.2.2.2.2.cmml" xref="S3.SS5.p1.5.m5.2.2.2.2"></times></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.5.m5.3c">\{e^{T}_{c,*}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.5.m5.3d">{ italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , âˆ— end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="*" class="ltx_Math" display="inline" id="S3.SS5.p1.6.m6.1"><semantics id="S3.SS5.p1.6.m6.1a"><mo id="S3.SS5.p1.6.m6.1.1" xref="S3.SS5.p1.6.m6.1.1.cmml">âˆ—</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.6.m6.1b"><times id="S3.SS5.p1.6.m6.1.1.cmml" xref="S3.SS5.p1.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.6.m6.1c">*</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.6.m6.1d">âˆ—</annotation></semantics></math> refers to the inference-time label space.</p>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.12">To do inference with LSQEs, we first find the closest match between each test class embedding <math alttext="e^{T}_{c,*}" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.2"><semantics id="S3.SS5.p2.1.m1.2a"><msubsup id="S3.SS5.p2.1.m1.2.3" xref="S3.SS5.p2.1.m1.2.3.cmml"><mi id="S3.SS5.p2.1.m1.2.3.2.2" xref="S3.SS5.p2.1.m1.2.3.2.2.cmml">e</mi><mrow id="S3.SS5.p2.1.m1.2.2.2.4" xref="S3.SS5.p2.1.m1.2.2.2.3.cmml"><mi id="S3.SS5.p2.1.m1.1.1.1.1" xref="S3.SS5.p2.1.m1.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p2.1.m1.2.2.2.4.1" rspace="0em" xref="S3.SS5.p2.1.m1.2.2.2.3.cmml">,</mo><mo id="S3.SS5.p2.1.m1.2.2.2.2" lspace="0em" xref="S3.SS5.p2.1.m1.2.2.2.2.cmml">âˆ—</mo></mrow><mi id="S3.SS5.p2.1.m1.2.3.2.3" xref="S3.SS5.p2.1.m1.2.3.2.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.2b"><apply id="S3.SS5.p2.1.m1.2.3.cmml" xref="S3.SS5.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.1.m1.2.3.1.cmml" xref="S3.SS5.p2.1.m1.2.3">subscript</csymbol><apply id="S3.SS5.p2.1.m1.2.3.2.cmml" xref="S3.SS5.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.1.m1.2.3.2.1.cmml" xref="S3.SS5.p2.1.m1.2.3">superscript</csymbol><ci id="S3.SS5.p2.1.m1.2.3.2.2.cmml" xref="S3.SS5.p2.1.m1.2.3.2.2">ğ‘’</ci><ci id="S3.SS5.p2.1.m1.2.3.2.3.cmml" xref="S3.SS5.p2.1.m1.2.3.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p2.1.m1.2.2.2.3.cmml" xref="S3.SS5.p2.1.m1.2.2.2.4"><ci id="S3.SS5.p2.1.m1.1.1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1.1.1">ğ‘</ci><times id="S3.SS5.p2.1.m1.2.2.2.2.cmml" xref="S3.SS5.p2.1.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.2c">e^{T}_{c,*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.2d">italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , âˆ— end_POSTSUBSCRIPT</annotation></semantics></math> and the training class embeddings <math alttext="\{e^{T}_{c,k}\}" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.3"><semantics id="S3.SS5.p2.2.m2.3a"><mrow id="S3.SS5.p2.2.m2.3.3.1" xref="S3.SS5.p2.2.m2.3.3.2.cmml"><mo id="S3.SS5.p2.2.m2.3.3.1.2" stretchy="false" xref="S3.SS5.p2.2.m2.3.3.2.cmml">{</mo><msubsup id="S3.SS5.p2.2.m2.3.3.1.1" xref="S3.SS5.p2.2.m2.3.3.1.1.cmml"><mi id="S3.SS5.p2.2.m2.3.3.1.1.2.2" xref="S3.SS5.p2.2.m2.3.3.1.1.2.2.cmml">e</mi><mrow id="S3.SS5.p2.2.m2.2.2.2.4" xref="S3.SS5.p2.2.m2.2.2.2.3.cmml"><mi id="S3.SS5.p2.2.m2.1.1.1.1" xref="S3.SS5.p2.2.m2.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p2.2.m2.2.2.2.4.1" xref="S3.SS5.p2.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS5.p2.2.m2.2.2.2.2" xref="S3.SS5.p2.2.m2.2.2.2.2.cmml">k</mi></mrow><mi id="S3.SS5.p2.2.m2.3.3.1.1.2.3" xref="S3.SS5.p2.2.m2.3.3.1.1.2.3.cmml">T</mi></msubsup><mo id="S3.SS5.p2.2.m2.3.3.1.3" stretchy="false" xref="S3.SS5.p2.2.m2.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.3b"><set id="S3.SS5.p2.2.m2.3.3.2.cmml" xref="S3.SS5.p2.2.m2.3.3.1"><apply id="S3.SS5.p2.2.m2.3.3.1.1.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.2.m2.3.3.1.1.1.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1">subscript</csymbol><apply id="S3.SS5.p2.2.m2.3.3.1.1.2.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.2.m2.3.3.1.1.2.1.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1">superscript</csymbol><ci id="S3.SS5.p2.2.m2.3.3.1.1.2.2.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p2.2.m2.3.3.1.1.2.3.cmml" xref="S3.SS5.p2.2.m2.3.3.1.1.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p2.2.m2.2.2.2.3.cmml" xref="S3.SS5.p2.2.m2.2.2.2.4"><ci id="S3.SS5.p2.2.m2.1.1.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1.1.1">ğ‘</ci><ci id="S3.SS5.p2.2.m2.2.2.2.2.cmml" xref="S3.SS5.p2.2.m2.2.2.2.2">ğ‘˜</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.3c">\{e^{T}_{c,k}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.3d">{ italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , italic_k end_POSTSUBSCRIPT }</annotation></semantics></math>. Each match reveals a label-space specific index <math alttext="k" class="ltx_Math" display="inline" id="S3.SS5.p2.3.m3.1"><semantics id="S3.SS5.p2.3.m3.1a"><mi id="S3.SS5.p2.3.m3.1.1" xref="S3.SS5.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.1b"><ci id="S3.SS5.p2.3.m3.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.3.m3.1d">italic_k</annotation></semantics></math>, which we collect to the set <math alttext="D=\{k\}" class="ltx_Math" display="inline" id="S3.SS5.p2.4.m4.1"><semantics id="S3.SS5.p2.4.m4.1a"><mrow id="S3.SS5.p2.4.m4.1.2" xref="S3.SS5.p2.4.m4.1.2.cmml"><mi id="S3.SS5.p2.4.m4.1.2.2" xref="S3.SS5.p2.4.m4.1.2.2.cmml">D</mi><mo id="S3.SS5.p2.4.m4.1.2.1" xref="S3.SS5.p2.4.m4.1.2.1.cmml">=</mo><mrow id="S3.SS5.p2.4.m4.1.2.3.2" xref="S3.SS5.p2.4.m4.1.2.3.1.cmml"><mo id="S3.SS5.p2.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS5.p2.4.m4.1.2.3.1.cmml">{</mo><mi id="S3.SS5.p2.4.m4.1.1" xref="S3.SS5.p2.4.m4.1.1.cmml">k</mi><mo id="S3.SS5.p2.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS5.p2.4.m4.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.4.m4.1b"><apply id="S3.SS5.p2.4.m4.1.2.cmml" xref="S3.SS5.p2.4.m4.1.2"><eq id="S3.SS5.p2.4.m4.1.2.1.cmml" xref="S3.SS5.p2.4.m4.1.2.1"></eq><ci id="S3.SS5.p2.4.m4.1.2.2.cmml" xref="S3.SS5.p2.4.m4.1.2.2">ğ·</ci><set id="S3.SS5.p2.4.m4.1.2.3.1.cmml" xref="S3.SS5.p2.4.m4.1.2.3.2"><ci id="S3.SS5.p2.4.m4.1.1.cmml" xref="S3.SS5.p2.4.m4.1.1">ğ‘˜</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.4.m4.1c">D=\{k\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.4.m4.1d">italic_D = { italic_k }</annotation></semantics></math>. This set can have at most <math alttext="K" class="ltx_Math" display="inline" id="S3.SS5.p2.5.m5.1"><semantics id="S3.SS5.p2.5.m5.1a"><mi id="S3.SS5.p2.5.m5.1.1" xref="S3.SS5.p2.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.5.m5.1b"><ci id="S3.SS5.p2.5.m5.1.1.cmml" xref="S3.SS5.p2.5.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.5.m5.1d">italic_K</annotation></semantics></math> elements. If any test-time class <math alttext="e^{T}_{c,*}" class="ltx_Math" display="inline" id="S3.SS5.p2.6.m6.2"><semantics id="S3.SS5.p2.6.m6.2a"><msubsup id="S3.SS5.p2.6.m6.2.3" xref="S3.SS5.p2.6.m6.2.3.cmml"><mi id="S3.SS5.p2.6.m6.2.3.2.2" xref="S3.SS5.p2.6.m6.2.3.2.2.cmml">e</mi><mrow id="S3.SS5.p2.6.m6.2.2.2.4" xref="S3.SS5.p2.6.m6.2.2.2.3.cmml"><mi id="S3.SS5.p2.6.m6.1.1.1.1" xref="S3.SS5.p2.6.m6.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p2.6.m6.2.2.2.4.1" rspace="0em" xref="S3.SS5.p2.6.m6.2.2.2.3.cmml">,</mo><mo id="S3.SS5.p2.6.m6.2.2.2.2" lspace="0em" xref="S3.SS5.p2.6.m6.2.2.2.2.cmml">âˆ—</mo></mrow><mi id="S3.SS5.p2.6.m6.2.3.2.3" xref="S3.SS5.p2.6.m6.2.3.2.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.6.m6.2b"><apply id="S3.SS5.p2.6.m6.2.3.cmml" xref="S3.SS5.p2.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.6.m6.2.3.1.cmml" xref="S3.SS5.p2.6.m6.2.3">subscript</csymbol><apply id="S3.SS5.p2.6.m6.2.3.2.cmml" xref="S3.SS5.p2.6.m6.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.6.m6.2.3.2.1.cmml" xref="S3.SS5.p2.6.m6.2.3">superscript</csymbol><ci id="S3.SS5.p2.6.m6.2.3.2.2.cmml" xref="S3.SS5.p2.6.m6.2.3.2.2">ğ‘’</ci><ci id="S3.SS5.p2.6.m6.2.3.2.3.cmml" xref="S3.SS5.p2.6.m6.2.3.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p2.6.m6.2.2.2.3.cmml" xref="S3.SS5.p2.6.m6.2.2.2.4"><ci id="S3.SS5.p2.6.m6.1.1.1.1.cmml" xref="S3.SS5.p2.6.m6.1.1.1.1">ğ‘</ci><times id="S3.SS5.p2.6.m6.2.2.2.2.cmml" xref="S3.SS5.p2.6.m6.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.6.m6.2c">e^{T}_{c,*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.6.m6.2d">italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , âˆ— end_POSTSUBSCRIPT</annotation></semantics></math> has equal similarity to multiple classes from different datasets, we include both label-space specific indices. This happens when multiple datasets share the same category, like â€œpersonâ€. We then run the decoder <math alttext="|D|" class="ltx_Math" display="inline" id="S3.SS5.p2.7.m7.1"><semantics id="S3.SS5.p2.7.m7.1a"><mrow id="S3.SS5.p2.7.m7.1.2.2" xref="S3.SS5.p2.7.m7.1.2.1.cmml"><mo id="S3.SS5.p2.7.m7.1.2.2.1" stretchy="false" xref="S3.SS5.p2.7.m7.1.2.1.1.cmml">|</mo><mi id="S3.SS5.p2.7.m7.1.1" xref="S3.SS5.p2.7.m7.1.1.cmml">D</mi><mo id="S3.SS5.p2.7.m7.1.2.2.2" stretchy="false" xref="S3.SS5.p2.7.m7.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.7.m7.1b"><apply id="S3.SS5.p2.7.m7.1.2.1.cmml" xref="S3.SS5.p2.7.m7.1.2.2"><abs id="S3.SS5.p2.7.m7.1.2.1.1.cmml" xref="S3.SS5.p2.7.m7.1.2.2.1"></abs><ci id="S3.SS5.p2.7.m7.1.1.cmml" xref="S3.SS5.p2.7.m7.1.1">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.7.m7.1c">|D|</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.7.m7.1d">| italic_D |</annotation></semantics></math> times with the corresponding LSQEs <math alttext="e^{L}_{k}" class="ltx_Math" display="inline" id="S3.SS5.p2.8.m8.1"><semantics id="S3.SS5.p2.8.m8.1a"><msubsup id="S3.SS5.p2.8.m8.1.1" xref="S3.SS5.p2.8.m8.1.1.cmml"><mi id="S3.SS5.p2.8.m8.1.1.2.2" xref="S3.SS5.p2.8.m8.1.1.2.2.cmml">e</mi><mi id="S3.SS5.p2.8.m8.1.1.3" xref="S3.SS5.p2.8.m8.1.1.3.cmml">k</mi><mi id="S3.SS5.p2.8.m8.1.1.2.3" xref="S3.SS5.p2.8.m8.1.1.2.3.cmml">L</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.8.m8.1b"><apply id="S3.SS5.p2.8.m8.1.1.cmml" xref="S3.SS5.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.8.m8.1.1.1.cmml" xref="S3.SS5.p2.8.m8.1.1">subscript</csymbol><apply id="S3.SS5.p2.8.m8.1.1.2.cmml" xref="S3.SS5.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.8.m8.1.1.2.1.cmml" xref="S3.SS5.p2.8.m8.1.1">superscript</csymbol><ci id="S3.SS5.p2.8.m8.1.1.2.2.cmml" xref="S3.SS5.p2.8.m8.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p2.8.m8.1.1.2.3.cmml" xref="S3.SS5.p2.8.m8.1.1.2.3">ğ¿</ci></apply><ci id="S3.SS5.p2.8.m8.1.1.3.cmml" xref="S3.SS5.p2.8.m8.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.8.m8.1c">e^{L}_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.8.m8.1d">italic_e start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and collect the <math alttext="N\cdot|D|" class="ltx_Math" display="inline" id="S3.SS5.p2.9.m9.1"><semantics id="S3.SS5.p2.9.m9.1a"><mrow id="S3.SS5.p2.9.m9.1.2" xref="S3.SS5.p2.9.m9.1.2.cmml"><mi id="S3.SS5.p2.9.m9.1.2.2" xref="S3.SS5.p2.9.m9.1.2.2.cmml">N</mi><mo id="S3.SS5.p2.9.m9.1.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS5.p2.9.m9.1.2.1.cmml">â‹…</mo><mrow id="S3.SS5.p2.9.m9.1.2.3.2" xref="S3.SS5.p2.9.m9.1.2.3.1.cmml"><mo id="S3.SS5.p2.9.m9.1.2.3.2.1" stretchy="false" xref="S3.SS5.p2.9.m9.1.2.3.1.1.cmml">|</mo><mi id="S3.SS5.p2.9.m9.1.1" xref="S3.SS5.p2.9.m9.1.1.cmml">D</mi><mo id="S3.SS5.p2.9.m9.1.2.3.2.2" stretchy="false" xref="S3.SS5.p2.9.m9.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.9.m9.1b"><apply id="S3.SS5.p2.9.m9.1.2.cmml" xref="S3.SS5.p2.9.m9.1.2"><ci id="S3.SS5.p2.9.m9.1.2.1.cmml" xref="S3.SS5.p2.9.m9.1.2.1">â‹…</ci><ci id="S3.SS5.p2.9.m9.1.2.2.cmml" xref="S3.SS5.p2.9.m9.1.2.2">ğ‘</ci><apply id="S3.SS5.p2.9.m9.1.2.3.1.cmml" xref="S3.SS5.p2.9.m9.1.2.3.2"><abs id="S3.SS5.p2.9.m9.1.2.3.1.1.cmml" xref="S3.SS5.p2.9.m9.1.2.3.2.1"></abs><ci id="S3.SS5.p2.9.m9.1.1.cmml" xref="S3.SS5.p2.9.m9.1.1">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.9.m9.1c">N\cdot|D|</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.9.m9.1d">italic_N â‹… | italic_D |</annotation></semantics></math> predictions consisting of masks and embedding vectors <math alttext="e^{I}_{i}" class="ltx_Math" display="inline" id="S3.SS5.p2.10.m10.1"><semantics id="S3.SS5.p2.10.m10.1a"><msubsup id="S3.SS5.p2.10.m10.1.1" xref="S3.SS5.p2.10.m10.1.1.cmml"><mi id="S3.SS5.p2.10.m10.1.1.2.2" xref="S3.SS5.p2.10.m10.1.1.2.2.cmml">e</mi><mi id="S3.SS5.p2.10.m10.1.1.3" xref="S3.SS5.p2.10.m10.1.1.3.cmml">i</mi><mi id="S3.SS5.p2.10.m10.1.1.2.3" xref="S3.SS5.p2.10.m10.1.1.2.3.cmml">I</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.10.m10.1b"><apply id="S3.SS5.p2.10.m10.1.1.cmml" xref="S3.SS5.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.10.m10.1.1.1.cmml" xref="S3.SS5.p2.10.m10.1.1">subscript</csymbol><apply id="S3.SS5.p2.10.m10.1.1.2.cmml" xref="S3.SS5.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.10.m10.1.1.2.1.cmml" xref="S3.SS5.p2.10.m10.1.1">superscript</csymbol><ci id="S3.SS5.p2.10.m10.1.1.2.2.cmml" xref="S3.SS5.p2.10.m10.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p2.10.m10.1.1.2.3.cmml" xref="S3.SS5.p2.10.m10.1.1.2.3">ğ¼</ci></apply><ci id="S3.SS5.p2.10.m10.1.1.3.cmml" xref="S3.SS5.p2.10.m10.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.10.m10.1c">e^{I}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.10.m10.1d">italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. This strategy is highly effective in preserving label-space consistency and accuracy but can increase the inference time by a small factor (see Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T5" title="Table 5 â€£ 4.3 Evaluation on Per-dataset Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">5</span></a>). The per-prediction classification is computed as the dot product between <math alttext="e^{I}_{i}" class="ltx_Math" display="inline" id="S3.SS5.p2.11.m11.1"><semantics id="S3.SS5.p2.11.m11.1a"><msubsup id="S3.SS5.p2.11.m11.1.1" xref="S3.SS5.p2.11.m11.1.1.cmml"><mi id="S3.SS5.p2.11.m11.1.1.2.2" xref="S3.SS5.p2.11.m11.1.1.2.2.cmml">e</mi><mi id="S3.SS5.p2.11.m11.1.1.3" xref="S3.SS5.p2.11.m11.1.1.3.cmml">i</mi><mi id="S3.SS5.p2.11.m11.1.1.2.3" xref="S3.SS5.p2.11.m11.1.1.2.3.cmml">I</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.11.m11.1b"><apply id="S3.SS5.p2.11.m11.1.1.cmml" xref="S3.SS5.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.11.m11.1.1.1.cmml" xref="S3.SS5.p2.11.m11.1.1">subscript</csymbol><apply id="S3.SS5.p2.11.m11.1.1.2.cmml" xref="S3.SS5.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.11.m11.1.1.2.1.cmml" xref="S3.SS5.p2.11.m11.1.1">superscript</csymbol><ci id="S3.SS5.p2.11.m11.1.1.2.2.cmml" xref="S3.SS5.p2.11.m11.1.1.2.2">ğ‘’</ci><ci id="S3.SS5.p2.11.m11.1.1.2.3.cmml" xref="S3.SS5.p2.11.m11.1.1.2.3">ğ¼</ci></apply><ci id="S3.SS5.p2.11.m11.1.1.3.cmml" xref="S3.SS5.p2.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.11.m11.1c">e^{I}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.11.m11.1d">italic_e start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and all test-time class embeddings <math alttext="e^{T}_{c,*}" class="ltx_Math" display="inline" id="S3.SS5.p2.12.m12.2"><semantics id="S3.SS5.p2.12.m12.2a"><msubsup id="S3.SS5.p2.12.m12.2.3" xref="S3.SS5.p2.12.m12.2.3.cmml"><mi id="S3.SS5.p2.12.m12.2.3.2.2" xref="S3.SS5.p2.12.m12.2.3.2.2.cmml">e</mi><mrow id="S3.SS5.p2.12.m12.2.2.2.4" xref="S3.SS5.p2.12.m12.2.2.2.3.cmml"><mi id="S3.SS5.p2.12.m12.1.1.1.1" xref="S3.SS5.p2.12.m12.1.1.1.1.cmml">c</mi><mo id="S3.SS5.p2.12.m12.2.2.2.4.1" rspace="0em" xref="S3.SS5.p2.12.m12.2.2.2.3.cmml">,</mo><mo id="S3.SS5.p2.12.m12.2.2.2.2" lspace="0em" xref="S3.SS5.p2.12.m12.2.2.2.2.cmml">âˆ—</mo></mrow><mi id="S3.SS5.p2.12.m12.2.3.2.3" xref="S3.SS5.p2.12.m12.2.3.2.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.12.m12.2b"><apply id="S3.SS5.p2.12.m12.2.3.cmml" xref="S3.SS5.p2.12.m12.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.12.m12.2.3.1.cmml" xref="S3.SS5.p2.12.m12.2.3">subscript</csymbol><apply id="S3.SS5.p2.12.m12.2.3.2.cmml" xref="S3.SS5.p2.12.m12.2.3"><csymbol cd="ambiguous" id="S3.SS5.p2.12.m12.2.3.2.1.cmml" xref="S3.SS5.p2.12.m12.2.3">superscript</csymbol><ci id="S3.SS5.p2.12.m12.2.3.2.2.cmml" xref="S3.SS5.p2.12.m12.2.3.2.2">ğ‘’</ci><ci id="S3.SS5.p2.12.m12.2.3.2.3.cmml" xref="S3.SS5.p2.12.m12.2.3.2.3">ğ‘‡</ci></apply><list id="S3.SS5.p2.12.m12.2.2.2.3.cmml" xref="S3.SS5.p2.12.m12.2.2.2.4"><ci id="S3.SS5.p2.12.m12.1.1.1.1.cmml" xref="S3.SS5.p2.12.m12.1.1.1.1">ğ‘</ci><times id="S3.SS5.p2.12.m12.2.2.2.2.cmml" xref="S3.SS5.p2.12.m12.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.12.m12.2c">e^{T}_{c,*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.12.m12.2d">italic_e start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c , âˆ— end_POSTSUBSCRIPT</annotation></semantics></math>. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.F2" title="Figure 2 â€£ 3.3 Language Embeddings as Classifiers â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the inference process.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Training datasets.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">Since our models all train from multiple datasets, we define a list of three different datasets combinations (details provided in the supplementary materials):</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_typewriter" id="S4.I1.i1.p1.1.1">D1</span>: COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib35" title="">35</a>]</cite>, ADE20KÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib66" title="">66</a>]</cite>, and VistasÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib41" title="">41</a>]</cite></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_typewriter" id="S4.I1.i2.p1.1.1">D2</span>: COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib35" title="">35</a>]</cite> and CIHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib17" title="">17</a>]</cite></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_typewriter" id="S4.I1.i3.p1.1.1">D3</span>: CityScapesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib12" title="">12</a>]</cite> and CityScapesPartsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib13" title="">13</a>]</cite></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.2">The datasets COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib35" title="">35</a>]</cite>, ADE20KÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib66" title="">66</a>]</cite>, VistasÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib41" title="">41</a>]</cite>, and CityScapesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib12" title="">12</a>]</cite> are standard benchmarks for panoptic segmentation, defining label spaces of sizes 133, 150, 48, and 19, respectively. CIHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib17" title="">17</a>]</cite> annotates human parts such as faces, hair, arms, and clothing, but not the entire person as a whole. Similarly, CityScapesParts (CSP)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib13" title="">13</a>]</cite> annotates parts of humans and cars (e.g., license plates, windshields), but not the complete objects. The goal for groups <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px1.p1.2.1">D2</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px1.p1.2.2">D3</span> is for the models to combine whole-object annotations from one dataset with part annotations from another dataset.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_align_right ltx_centering ltx_img_landscape" height="272" id="S4.F3.g1" src="extracted/5856734/figures/dataset_vis_cihp_csp.jpg" width="598"/>
<figcaption class="ltx_caption ltx_align_right ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.6.3.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.4.2" style="font-size:90%;">
Examples of the mixed-label space evaluation-only datasets. Each row shows two examples from CIHP/CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.F3.3.1.m1.1"><semantics id="S4.F3.3.1.m1.1b"><msub id="S4.F3.3.1.m1.1.1" xref="S4.F3.3.1.m1.1.1.cmml"><mi id="S4.F3.3.1.m1.1.1b" xref="S4.F3.3.1.m1.1.1.cmml"></mi><mtext id="S4.F3.3.1.m1.1.1.1" xref="S4.F3.3.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F3.3.1.m1.1c"><apply id="S4.F3.3.1.m1.1.1.cmml" xref="S4.F3.3.1.m1.1.1"><ci id="S4.F3.3.1.m1.1.1.1a.cmml" xref="S4.F3.3.1.m1.1.1.1"><mtext id="S4.F3.3.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.F3.3.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.3.1.m1.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.F3.3.1.m1.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math> (left and middle) and one from CIHP/CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.F3.4.2.m2.1"><semantics id="S4.F3.4.2.m2.1b"><msub id="S4.F3.4.2.m2.1.1" xref="S4.F3.4.2.m2.1.1.cmml"><mi id="S4.F3.4.2.m2.1.1b" xref="S4.F3.4.2.m2.1.1.cmml"></mi><mtext id="S4.F3.4.2.m2.1.1.1" xref="S4.F3.4.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F3.4.2.m2.1c"><apply id="S4.F3.4.2.m2.1.1.cmml" xref="S4.F3.4.2.m2.1.1"><ci id="S4.F3.4.2.m2.1.1.1a.cmml" xref="S4.F3.4.2.m2.1.1.1"><mtext id="S4.F3.4.2.m2.1.1.1.cmml" mathsize="70%" xref="S4.F3.4.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.4.2.m2.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.F3.4.2.m2.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math> (right).</span></figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Benchmarking Image Segmentation.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">Effectively scaling segmentation requires a critical evaluation of current benchmarking standards for semantic, instance, and panoptic segmentation. While these tasks offer a solid evaluation framework, they fall short when dealing with complex scenarios involving overlapping categories.
Scaling segmentation increases the semantic label space, which includes â€œthingâ€ and â€œstuffâ€ classes and necessitates multi-label assignments for pixels where semantics overlap, e.g., â€œpersonâ€ and â€œfaceâ€. Neither semantic segmentation (not instance-aware and no overlaps), instance segmentation (no â€œstuffâ€ categories), or panoptic segmentation (no overlaps) provide a comprehensive benchmark.
Thus, in addition to traditional evaluation metrics for semantic, panoptic, and instance segmentation, we propose a novel approach to benchmarking called Panoptic Instance Quality (PIQ).
It combines the advantages of per-pixel classification from panoptic segmentation and the allowance for overlapping masks in instance segmentation to better measure a modelâ€™s accuracy in a unified, scalable manner. We achieve this by averaging the Average Precision (AP) score of all instances in the â€œthingâ€ categories and the Panoptic Quality (PQ) score for uncountable background categories (â€œstuffâ€). We also include the variations of PIQ like PIQ50 and PIQ75 which follow a similar convention as used in other metrics like AP (Average Precision) in object detection, where AP50 and AP75 represent the precision score calculated at different Intersection over Union (IoU) thresholds.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Mixed label space benchmarks.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.13">To properly evaluate the ability of multi-dataset models to handle any combination of label spaces <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px3.p1.1.m1.1a"><mi id="S4.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.1.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.1.m1.1d">italic_A</annotation></semantics></math> and <math alttext="B" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.2.m2.1"><semantics id="S4.SS1.SSS0.Px3.p1.2.m2.1a"><mi id="S4.SS1.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px3.p1.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.2.m2.1b"><ci id="S4.SS1.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.2.m2.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.2.m2.1d">italic_B</annotation></semantics></math> of the individual datasets, we build a dataset with label space <math alttext="C" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.3.m3.1"><semantics id="S4.SS1.SSS0.Px3.p1.3.m3.1a"><mi id="S4.SS1.SSS0.Px3.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px3.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.3.m3.1b"><ci id="S4.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.3.m3.1d">italic_C</annotation></semantics></math> that has the following property. Label space <math alttext="C" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.4.m4.1"><semantics id="S4.SS1.SSS0.Px3.p1.4.m4.1a"><mi id="S4.SS1.SSS0.Px3.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px3.p1.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.4.m4.1b"><ci id="S4.SS1.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.4.m4.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.4.m4.1d">italic_C</annotation></semantics></math> must contain two partitions that contain categories that come exclusively from either training dataset, i.e., <math alttext="|C\cap A\setminus B|&gt;\emptyset\land|C\cap B\setminus A|&gt;\emptyset" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.5.m5.2"><semantics id="S4.SS1.SSS0.Px3.p1.5.m5.2a"><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.2.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.cmml"><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.2.cmml"><mo id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.2" stretchy="false" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.2.1.cmml">|</mo><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.cmml"><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.2.cmml">C</mi><mo id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.1.cmml">âˆ©</mo><mi id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.3.cmml">A</mi></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.1.cmml">âˆ–</mo><mi id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.3" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.3.cmml">B</mi></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.3" stretchy="false" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.2.1.cmml">|</mo></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.4" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.4.cmml">&gt;</mo><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.cmml"><mi id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.3" mathvariant="normal" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.3.cmml">âˆ…</mi><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.2.cmml">âˆ§</mo><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.2.cmml"><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.2" stretchy="false" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.cmml"><mrow id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.2.cmml">C</mi><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.1.cmml">âˆ©</mo><mi id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.3.cmml">B</mi></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.1" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.1.cmml">âˆ–</mo><mi id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.3" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.3.cmml">A</mi></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.3" stretchy="false" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.2.1.cmml">|</mo></mrow></mrow><mo id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.5" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.5.cmml">&gt;</mo><mi id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.6" mathvariant="normal" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.6.cmml">âˆ…</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.5.m5.2b"><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2"><and id="S4.SS1.SSS0.Px3.p1.5.m5.2.2a.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2"></and><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2b.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2"><gt id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.4.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.4"></gt><apply id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1"><abs id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.2"></abs><apply id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1"><setdiff id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.1"></setdiff><apply id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2"><intersect id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.1"></intersect><ci id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.2">ğ¶</ci><ci id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.3.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.2.3">ğ´</ci></apply><ci id="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.1.1.1.1.1.3">ğµ</ci></apply></apply><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2"><and id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.2"></and><emptyset id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.3.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.3"></emptyset><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1"><abs id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.2"></abs><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1"><setdiff id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.1"></setdiff><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2"><intersect id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.1"></intersect><ci id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.2">ğ¶</ci><ci id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.3.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.2.3">ğµ</ci></apply><ci id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.1.1.1.3">ğ´</ci></apply></apply></apply></apply><apply id="S4.SS1.SSS0.Px3.p1.5.m5.2.2c.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2"><gt id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.5.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.5"></gt><share href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px3.p1.5.m5.2.2.2.cmml" id="S4.SS1.SSS0.Px3.p1.5.m5.2.2d.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2"></share><emptyset id="S4.SS1.SSS0.Px3.p1.5.m5.2.2.6.cmml" xref="S4.SS1.SSS0.Px3.p1.5.m5.2.2.6"></emptyset></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.5.m5.2c">|C\cap A\setminus B|&gt;\emptyset\land|C\cap B\setminus A|&gt;\emptyset</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.5.m5.2d">| italic_C âˆ© italic_A âˆ– italic_B | &gt; âˆ… âˆ§ | italic_C âˆ© italic_B âˆ– italic_A | &gt; âˆ…</annotation></semantics></math>. (This can be easily extended to more than two training datasets.) To build such a dataset, we can use CIHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib17" title="">17</a>]</cite> and CSPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib13" title="">13</a>]</cite> that annotate parts of persons and cars. In both cases, putting all masks together results in the super-category, person or car, which is not part of CIHP or CSP themselves, but is part of COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib35" title="">35</a>]</cite> and CityScapesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib12" title="">12</a>]</cite>. We do not use all parts, because otherwise the super-categories are fully covered by parts. Hence, we create multiple separate datasets by combining subsets of parts with the super-category. First, we use all parts individually which defines the datasets CIHP<math alttext="{}_{\textrm{pair}}^{i}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.6.m6.1"><semantics id="S4.SS1.SSS0.Px3.p1.6.m6.1a"><mmultiscripts id="S4.SS1.SSS0.Px3.p1.6.m6.1.1" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.2.cmml"></mi><mprescripts id="S4.SS1.SSS0.Px3.p1.6.m6.1.1a" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.cmml"></mprescripts><mrow id="S4.SS1.SSS0.Px3.p1.6.m6.1.1b" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.cmml"></mrow><mi id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.3" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.3.cmml">i</mi><mtext id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3a.cmml">pair</mtext><mrow id="S4.SS1.SSS0.Px3.p1.6.m6.1.1c" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.6.m6.1b"><apply id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.2">absent</csymbol><ci id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3a.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3"><mtext id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.2.3">pair</mtext></ci></apply><ci id="S4.SS1.SSS0.Px3.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.6.m6.1c">{}_{\textrm{pair}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.6.m6.1d">start_FLOATSUBSCRIPT pair end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{pair}}^{i}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.7.m7.1"><semantics id="S4.SS1.SSS0.Px3.p1.7.m7.1a"><mmultiscripts id="S4.SS1.SSS0.Px3.p1.7.m7.1.1" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.2.cmml"></mi><mprescripts id="S4.SS1.SSS0.Px3.p1.7.m7.1.1a" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.cmml"></mprescripts><mrow id="S4.SS1.SSS0.Px3.p1.7.m7.1.1b" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.cmml"></mrow><mi id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.3" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.3.cmml">i</mi><mtext id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3a.cmml">pair</mtext><mrow id="S4.SS1.SSS0.Px3.p1.7.m7.1.1c" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.7.m7.1b"><apply id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.2">absent</csymbol><ci id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3a.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3"><mtext id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.2.3">pair</mtext></ci></apply><ci id="S4.SS1.SSS0.Px3.p1.7.m7.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.7.m7.1c">{}_{\textrm{pair}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.7.m7.1d">start_FLOATSUBSCRIPT pair end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>, which all contain two labels. Furthermore we define 4 datasets that use multiple parts together with the super-category, CIHP<math alttext="{}_{\textrm{multi}}^{i}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.8.m8.1"><semantics id="S4.SS1.SSS0.Px3.p1.8.m8.1a"><mmultiscripts id="S4.SS1.SSS0.Px3.p1.8.m8.1.1" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.2.cmml"></mi><mprescripts id="S4.SS1.SSS0.Px3.p1.8.m8.1.1a" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.cmml"></mprescripts><mrow id="S4.SS1.SSS0.Px3.p1.8.m8.1.1b" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.cmml"></mrow><mi id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.3" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.3.cmml">i</mi><mtext id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3a.cmml">multi</mtext><mrow id="S4.SS1.SSS0.Px3.p1.8.m8.1.1c" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.8.m8.1b"><apply id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.2">absent</csymbol><ci id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3a.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3"><mtext id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.2.3">multi</mtext></ci></apply><ci id="S4.SS1.SSS0.Px3.p1.8.m8.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.8.m8.1c">{}_{\textrm{multi}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.8.m8.1d">start_FLOATSUBSCRIPT multi end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{multi}}^{i}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.9.m9.1"><semantics id="S4.SS1.SSS0.Px3.p1.9.m9.1a"><mmultiscripts id="S4.SS1.SSS0.Px3.p1.9.m9.1.1" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.2" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.2.cmml"></mi><mprescripts id="S4.SS1.SSS0.Px3.p1.9.m9.1.1a" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.cmml"></mprescripts><mrow id="S4.SS1.SSS0.Px3.p1.9.m9.1.1b" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.cmml"></mrow><mi id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.3" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.3.cmml">i</mi><mtext id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3a.cmml">multi</mtext><mrow id="S4.SS1.SSS0.Px3.p1.9.m9.1.1c" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.9.m9.1b"><apply id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.2">absent</csymbol><ci id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3a.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3"><mtext id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.2.3">multi</mtext></ci></apply><ci id="S4.SS1.SSS0.Px3.p1.9.m9.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.9.m9.1c">{}_{\textrm{multi}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.9.m9.1d">start_FLOATSUBSCRIPT multi end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F3" title="Figure 3 â€£ Training datasets. â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a> shows some examples and details are in the supplementary materials. To report results, we evaluate models on all individual datasets and then average the panoptic quality (PQ)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib27" title="">27</a>]</cite> to form four benchmarks: CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.10.m10.1"><semantics id="S4.SS1.SSS0.Px3.p1.10.m10.1a"><msub id="S4.SS1.SSS0.Px3.p1.10.m10.1.1" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.10.m10.1.1a" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.10.m10.1b"><apply id="S4.SS1.SSS0.Px3.p1.10.m10.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1"><ci id="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1a.cmml" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1"><mtext id="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.10.m10.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.10.m10.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.10.m10.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.11.m11.1"><semantics id="S4.SS1.SSS0.Px3.p1.11.m11.1a"><msub id="S4.SS1.SSS0.Px3.p1.11.m11.1.1" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.11.m11.1.1a" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.11.m11.1b"><apply id="S4.SS1.SSS0.Px3.p1.11.m11.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1"><ci id="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1a.cmml" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1"><mtext id="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.11.m11.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.11.m11.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.11.m11.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>, CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.12.m12.1"><semantics id="S4.SS1.SSS0.Px3.p1.12.m12.1a"><msub id="S4.SS1.SSS0.Px3.p1.12.m12.1.1" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.12.m12.1.1a" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.12.m12.1b"><apply id="S4.SS1.SSS0.Px3.p1.12.m12.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1"><ci id="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1a.cmml" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1"><mtext id="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.12.m12.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.12.m12.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.12.m12.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.13.m13.1"><semantics id="S4.SS1.SSS0.Px3.p1.13.m13.1a"><msub id="S4.SS1.SSS0.Px3.p1.13.m13.1.1" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p1.13.m13.1.1a" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.13.m13.1b"><apply id="S4.SS1.SSS0.Px3.p1.13.m13.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1"><ci id="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1a.cmml" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1"><mtext id="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px3.p1.13.m13.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.13.m13.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.13.m13.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math> (more benchmark details are provided in the supplementary materials).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Evaluation Settings.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.4">We do two types of quantitative evaluations. Firstly, we conduct a <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS0.Px4.p1.4.1">mixed-label space evaluation</em> utilizing our newly created dataset annotations that blend classes from multiple datasets, including CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.1.1a" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1"><ci id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1a.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1"><mtext id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.2.m2.1"><semantics id="S4.SS1.SSS0.Px4.p1.2.m2.1a"><msub id="S4.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1a" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1"><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1a.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1"><mtext id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.m2.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.2.m2.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>, CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.3.m3.1"><semantics id="S4.SS1.SSS0.Px4.p1.3.m3.1a"><msub id="S4.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.1.1a" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1"><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1a.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1"><mtext id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m3.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.3.m3.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, and CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.4.m4.1"><semantics id="S4.SS1.SSS0.Px4.p1.4.m4.1a"><msub id="S4.SS1.SSS0.Px4.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.4.m4.1.1a" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml"></mi><mtext id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.4.m4.1b"><apply id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1"><ci id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1a.cmml" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1"><mtext id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.4.m4.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.4.m4.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>. Secondly, we perform a <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS0.Px4.p1.4.2">per-label space evaluation</em>, following the approach of prior workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite>. In this approach, we assess the modelâ€™s performance on each of the individual datasets within our defined dataset groups (<span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px4.p1.4.3">D1</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px4.p1.4.4">D2</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px4.p1.4.5">D3</span>).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Metrics.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px5.p1.1">As discussed before, no single task - semantic, instance or panoptic - provides a comprehensive benchmark when semantic inconsistencies exist. Hence, for quantitative analysis, we employ metrics from all tasks: Intersection over Union (IoU), Average Precision (AP), and Panoptic Quality (PQ). Moreover, we add our newly proposed Panoptic Instance Quality (PIQ). Each metric provides unique insights into the modelâ€™s performance. Notably, PIQ is instrumental in evaluating performance in the proposed panoptic-instance segmentation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Baselines.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px6.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px6.p1.1">We compare our method against three relevant baselines. (1) LMSegÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite> is a recently proposed state-of-the-art model for multi-dataset image segmentation (and the only prior work on panoptic segmentation, to the best of our knowledge)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>To report results for LMSegÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite>, we train the model ourselves with the latest Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> framework, which gives higher PQ values than reported inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a>]</cite> and is a fairer comparison with equal training settings.</span></span></span>. (2) We extend the idea of a dataset-specific classification head from UniDetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a>]</cite>, which was developed for object detection, to segmentation. (3) Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite> with language-embeddings as classifier, see Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS3" title="3.3 Language Embeddings as Classifiers â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3.3</span></a>. This baseline is the same as our RESI model, but without the label space-specific query embeddings.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px7">
<h4 class="ltx_title ltx_title_paragraph">Model training.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px7.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px7.p1.1">For detailed information on model training, hyperparameters, and the panoptic inference algorithm, please refer to the supplementary materials.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation on Mixed Label Spaces</h3>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="254" id="S4.F4.g1" src="extracted/5856734/figures/qualitative_multi.jpg" width="685"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">Visual comparison of multi-category segmentation performance. We present a overview of RESIâ€™s capabilities in handling complex label spaces. The depicted scenarios demonstrate the modelâ€™s proficiency in simultaneous cross-label space multi-category predictions, a task where traditional segmentation approaches often fall short.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_align_center" id="S4.T1.st1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.st1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.st1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T1.st1.4.4.5" rowspan="2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.4.5.1" style="font-size:80%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" colspan="3" id="S4.T1.st1.1.1.1" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.1.1.1.1" style="font-size:80%;">CIHP</span><math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.T1.st1.1.1.1.m1.1"><semantics id="S4.T1.st1.1.1.1.m1.1a"><msub id="S4.T1.st1.1.1.1.m1.1.1" xref="S4.T1.st1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.st1.1.1.1.m1.1.1a" xref="S4.T1.st1.1.1.1.m1.1.1.cmml"></mi><mtext id="S4.T1.st1.1.1.1.m1.1.1.1" mathsize="80%" xref="S4.T1.st1.1.1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.st1.1.1.1.m1.1b"><apply id="S4.T1.st1.1.1.1.m1.1.1.cmml" xref="S4.T1.st1.1.1.1.m1.1.1"><ci id="S4.T1.st1.1.1.1.m1.1.1.1a.cmml" xref="S4.T1.st1.1.1.1.m1.1.1.1"><mtext id="S4.T1.st1.1.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st1.1.1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.1.1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st1.1.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3" id="S4.T1.st1.2.2.2" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.2.2.2.1" style="font-size:80%;">CIHP</span><math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.T1.st1.2.2.2.m1.1"><semantics id="S4.T1.st1.2.2.2.m1.1a"><msub id="S4.T1.st1.2.2.2.m1.1.1" xref="S4.T1.st1.2.2.2.m1.1.1.cmml"><mi id="S4.T1.st1.2.2.2.m1.1.1a" xref="S4.T1.st1.2.2.2.m1.1.1.cmml"></mi><mtext id="S4.T1.st1.2.2.2.m1.1.1.1" mathsize="80%" xref="S4.T1.st1.2.2.2.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.st1.2.2.2.m1.1b"><apply id="S4.T1.st1.2.2.2.m1.1.1.cmml" xref="S4.T1.st1.2.2.2.m1.1.1"><ci id="S4.T1.st1.2.2.2.m1.1.1.1a.cmml" xref="S4.T1.st1.2.2.2.m1.1.1.1"><mtext id="S4.T1.st1.2.2.2.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st1.2.2.2.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.2.2.2.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st1.2.2.2.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3" id="S4.T1.st1.3.3.3" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.3.3.3.1" style="font-size:80%;">CSP</span><math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.T1.st1.3.3.3.m1.1"><semantics id="S4.T1.st1.3.3.3.m1.1a"><msub id="S4.T1.st1.3.3.3.m1.1.1" xref="S4.T1.st1.3.3.3.m1.1.1.cmml"><mi id="S4.T1.st1.3.3.3.m1.1.1a" xref="S4.T1.st1.3.3.3.m1.1.1.cmml"></mi><mtext id="S4.T1.st1.3.3.3.m1.1.1.1" mathsize="80%" xref="S4.T1.st1.3.3.3.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.st1.3.3.3.m1.1b"><apply id="S4.T1.st1.3.3.3.m1.1.1.cmml" xref="S4.T1.st1.3.3.3.m1.1.1"><ci id="S4.T1.st1.3.3.3.m1.1.1.1a.cmml" xref="S4.T1.st1.3.3.3.m1.1.1.1"><mtext id="S4.T1.st1.3.3.3.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st1.3.3.3.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.3.3.3.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st1.3.3.3.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3" id="S4.T1.st1.4.4.4" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.4.4.4.1" style="font-size:80%;">CSP</span><math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.T1.st1.4.4.4.m1.1"><semantics id="S4.T1.st1.4.4.4.m1.1a"><msub id="S4.T1.st1.4.4.4.m1.1.1" xref="S4.T1.st1.4.4.4.m1.1.1.cmml"><mi id="S4.T1.st1.4.4.4.m1.1.1a" xref="S4.T1.st1.4.4.4.m1.1.1.cmml"></mi><mtext id="S4.T1.st1.4.4.4.m1.1.1.1" mathsize="80%" xref="S4.T1.st1.4.4.4.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.st1.4.4.4.m1.1b"><apply id="S4.T1.st1.4.4.4.m1.1.1.cmml" xref="S4.T1.st1.4.4.4.m1.1.1"><ci id="S4.T1.st1.4.4.4.m1.1.1.1a.cmml" xref="S4.T1.st1.4.4.4.m1.1.1.1"><mtext id="S4.T1.st1.4.4.4.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st1.4.4.4.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.4.4.4.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st1.4.4.4.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr" id="S4.T1.st1.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T1.st1.4.5.1.1" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.1.1" style="font-size:80%;">PQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.2.1" style="font-size:80%;">SQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.3" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.3.1" style="font-size:80%;">RQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.4" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.4.1" style="font-size:80%;">PQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.5" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.5.1" style="font-size:80%;">SQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.6" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.6.1" style="font-size:80%;">RQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.7" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.7.1" style="font-size:80%;">PQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.8" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.8.1" style="font-size:80%;">SQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.9" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.9.1" style="font-size:80%;">RQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.10" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.10.1" style="font-size:80%;">PQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.11" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.11.1" style="font-size:80%;">SQ</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st1.4.5.1.12" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.5.1.12.1" style="font-size:80%;">RQ</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.st1.4.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T1.st1.4.6.1.1" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.4.6.1.1.1" style="font-size:80%;">UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st1.4.6.1.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="S4.T1.st1.4.6.1.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T1.st1.4.6.1.2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.2.1" style="font-size:80%;">45.2</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.3" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.3.1" style="font-size:80%;">77.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.4" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.4.1" style="font-size:80%;">57.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.5" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.5.1" style="font-size:80%;">53.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.6" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.6.1" style="font-size:80%;">77.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.7" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.7.1" style="font-size:80%;">66.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.8" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.8.1" style="font-size:80%;">35.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.9" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.9.1" style="font-size:80%;">76.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.10" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.10.1" style="font-size:80%;">45.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.11" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.11.1" style="font-size:80%;">21.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.12" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.12.1" style="font-size:80%;">74.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st1.4.6.1.13" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.6.1.13.1" style="font-size:80%;">28.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st1.4.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st1.4.7.2.1" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.4.7.2.1.1" style="font-size:80%;">LMSegÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st1.4.7.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a><span class="ltx_text" id="S4.T1.st1.4.7.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st1.4.7.2.2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.2.1" style="font-size:80%;">41.7</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.3" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.3.1" style="font-size:80%;">77.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.4" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.4.1" style="font-size:80%;">53.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.5" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.5.1" style="font-size:80%;">52.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.6" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.6.1" style="font-size:80%;">77.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.7" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.7.1" style="font-size:80%;">65.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.8" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.8.1" style="font-size:80%;">37.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.9" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.9.1" style="font-size:80%;">77.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.10" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.10.1" style="font-size:80%;">47.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.11" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.11.1" style="font-size:80%;">22.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.12" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.12.1" style="font-size:80%;">73.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.7.2.13" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.7.2.13.1" style="font-size:80%;">30.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st1.4.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st1.4.8.3.1" style="padding-left:10.8pt;padding-right:10.8pt;">
<span class="ltx_text" id="S4.T1.st1.4.8.3.1.1" style="font-size:80%;">M2F+LEÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st1.4.8.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a><span class="ltx_text" id="S4.T1.st1.4.8.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st1.4.8.3.2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.2.1" style="font-size:80%;">45.2</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.3" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.3.1" style="font-size:80%;">79.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.4" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.4.1" style="font-size:80%;">56.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.5" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.5.1" style="font-size:80%;">53.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.6" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.6.1" style="font-size:80%;">78.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.7" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.7.1" style="font-size:80%;">66.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.8" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.8.1" style="font-size:80%;">38.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.9" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.9.1" style="font-size:80%;">78.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.10" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.10.1" style="font-size:80%;">48.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.11" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.11.1" style="font-size:80%;">22.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.12" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.12.1" style="font-size:80%;">74.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st1.4.8.3.13" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.8.3.13.1" style="font-size:80%;">29.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st1.4.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.st1.4.9.4.1" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text" id="S4.T1.st1.4.9.4.1.1" style="font-size:80%;">RESI (Ours)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.st1.4.9.4.2" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.2.1" style="font-size:80%;">61.5</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.3" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.3.1" style="font-size:80%;">84.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.4" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.4.1" style="font-size:80%;">71.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.5" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.5.1" style="font-size:80%;">58.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.6" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.6.1" style="font-size:80%;">81.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.7" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.7.1" style="font-size:80%;">70.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.8" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.8.1" style="font-size:80%;">45.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.9" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.9.1" style="font-size:80%;">78.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.10" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.10.1" style="font-size:80%;">57.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.11" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.11.1" style="font-size:80%;">31.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.12" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.12.1" style="font-size:80%;">75.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st1.4.9.4.13" style="padding-left:10.8pt;padding-right:10.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st1.4.9.4.13.1" style="font-size:80%;">41.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.st1.8.1.1" style="font-size:113%;">(a)</span> </span><span class="ltx_text" id="S4.T1.st1.9.2" style="font-size:113%;">Panoptic segmentation</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel ltx_align_center" id="S4.T1.st2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.st2.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.st2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T1.st2.2.2.3" rowspan="2" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.2.2.3.1" style="font-size:80%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3" id="S4.T1.st2.1.1.1" style="padding-left:5.8pt;padding-right:5.8pt;">
<span class="ltx_text" id="S4.T1.st2.1.1.1.1" style="font-size:80%;">CIHP</span><math alttext="{}_{\textrm{P}}^{\textrm{-inst}}" class="ltx_Math" display="inline" id="S4.T1.st2.1.1.1.m1.1"><semantics id="S4.T1.st2.1.1.1.m1.1a"><mmultiscripts id="S4.T1.st2.1.1.1.m1.1.1" xref="S4.T1.st2.1.1.1.m1.1.1.cmml"><mi id="S4.T1.st2.1.1.1.m1.1.1.2.2" xref="S4.T1.st2.1.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.1.1.1.m1.1.1a" xref="S4.T1.st2.1.1.1.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.1.1.1.m1.1.1b" xref="S4.T1.st2.1.1.1.m1.1.1.cmml"></mrow><mtext id="S4.T1.st2.1.1.1.m1.1.1.3" mathsize="80%" xref="S4.T1.st2.1.1.1.m1.1.1.3a.cmml">-inst</mtext><mtext id="S4.T1.st2.1.1.1.m1.1.1.2.3" mathsize="80%" xref="S4.T1.st2.1.1.1.m1.1.1.2.3a.cmml">P</mtext><mrow id="S4.T1.st2.1.1.1.m1.1.1c" xref="S4.T1.st2.1.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.1.1.1.m1.1b"><apply id="S4.T1.st2.1.1.1.m1.1.1.cmml" xref="S4.T1.st2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.1.1.1.m1.1.1.1.cmml" xref="S4.T1.st2.1.1.1.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.1.1.1.m1.1.1.2.cmml" xref="S4.T1.st2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.1.1.1.m1.1.1.2.1.cmml" xref="S4.T1.st2.1.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.1.1.1.m1.1.1.2.2.cmml" xref="S4.T1.st2.1.1.1.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.1.1.1.m1.1.1.2.3a.cmml" xref="S4.T1.st2.1.1.1.m1.1.1.2.3"><mtext id="S4.T1.st2.1.1.1.m1.1.1.2.3.cmml" mathsize="56%" xref="S4.T1.st2.1.1.1.m1.1.1.2.3">P</mtext></ci></apply><ci id="S4.T1.st2.1.1.1.m1.1.1.3a.cmml" xref="S4.T1.st2.1.1.1.m1.1.1.3"><mtext id="S4.T1.st2.1.1.1.m1.1.1.3.cmml" mathsize="56%" xref="S4.T1.st2.1.1.1.m1.1.1.3">-inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.1.1.1.m1.1c">{}_{\textrm{P}}^{\textrm{-inst}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.1.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT -inst end_POSTSUPERSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3" id="S4.T1.st2.2.2.2" style="padding-left:5.8pt;padding-right:5.8pt;">
<span class="ltx_text" id="S4.T1.st2.2.2.2.1" style="font-size:80%;">CSP</span><math alttext="{}_{\textrm{P}}^{\textrm{-inst}}" class="ltx_Math" display="inline" id="S4.T1.st2.2.2.2.m1.1"><semantics id="S4.T1.st2.2.2.2.m1.1a"><mmultiscripts id="S4.T1.st2.2.2.2.m1.1.1" xref="S4.T1.st2.2.2.2.m1.1.1.cmml"><mi id="S4.T1.st2.2.2.2.m1.1.1.2.2" xref="S4.T1.st2.2.2.2.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.2.2.2.m1.1.1a" xref="S4.T1.st2.2.2.2.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.2.2.2.m1.1.1b" xref="S4.T1.st2.2.2.2.m1.1.1.cmml"></mrow><mtext id="S4.T1.st2.2.2.2.m1.1.1.3" mathsize="80%" xref="S4.T1.st2.2.2.2.m1.1.1.3a.cmml">-inst</mtext><mtext id="S4.T1.st2.2.2.2.m1.1.1.2.3" mathsize="80%" xref="S4.T1.st2.2.2.2.m1.1.1.2.3a.cmml">P</mtext><mrow id="S4.T1.st2.2.2.2.m1.1.1c" xref="S4.T1.st2.2.2.2.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.2.2.2.m1.1b"><apply id="S4.T1.st2.2.2.2.m1.1.1.cmml" xref="S4.T1.st2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.2.2.2.m1.1.1.1.cmml" xref="S4.T1.st2.2.2.2.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.2.2.2.m1.1.1.2.cmml" xref="S4.T1.st2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.2.2.2.m1.1.1.2.1.cmml" xref="S4.T1.st2.2.2.2.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.2.2.2.m1.1.1.2.2.cmml" xref="S4.T1.st2.2.2.2.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.2.2.2.m1.1.1.2.3a.cmml" xref="S4.T1.st2.2.2.2.m1.1.1.2.3"><mtext id="S4.T1.st2.2.2.2.m1.1.1.2.3.cmml" mathsize="56%" xref="S4.T1.st2.2.2.2.m1.1.1.2.3">P</mtext></ci></apply><ci id="S4.T1.st2.2.2.2.m1.1.1.3a.cmml" xref="S4.T1.st2.2.2.2.m1.1.1.3"><mtext id="S4.T1.st2.2.2.2.m1.1.1.3.cmml" mathsize="56%" xref="S4.T1.st2.2.2.2.m1.1.1.3">-inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.2.2.2.m1.1c">{}_{\textrm{P}}^{\textrm{-inst}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.2.2.2.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT -inst end_POSTSUPERSCRIPT</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr" id="S4.T1.st2.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.3.3.1" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP" class="ltx_Math" display="inline" id="S4.T1.st2.3.3.1.m1.1"><semantics id="S4.T1.st2.3.3.1.m1.1a"><mrow id="S4.T1.st2.3.3.1.m1.1.1" xref="S4.T1.st2.3.3.1.m1.1.1.cmml"><mi id="S4.T1.st2.3.3.1.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.3.3.1.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.3.3.1.m1.1.1.1" xref="S4.T1.st2.3.3.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.T1.st2.3.3.1.m1.1.1.3" mathsize="80%" xref="S4.T1.st2.3.3.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.3.3.1.m1.1b"><apply id="S4.T1.st2.3.3.1.m1.1.1.cmml" xref="S4.T1.st2.3.3.1.m1.1.1"><times id="S4.T1.st2.3.3.1.m1.1.1.1.cmml" xref="S4.T1.st2.3.3.1.m1.1.1.1"></times><ci id="S4.T1.st2.3.3.1.m1.1.1.2.cmml" xref="S4.T1.st2.3.3.1.m1.1.1.2">ğ´</ci><ci id="S4.T1.st2.3.3.1.m1.1.1.3.cmml" xref="S4.T1.st2.3.3.1.m1.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.3.3.1.m1.1c">AP</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.3.3.1.m1.1d">italic_A italic_P</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.4.4.2" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP_{50}" class="ltx_Math" display="inline" id="S4.T1.st2.4.4.2.m1.1"><semantics id="S4.T1.st2.4.4.2.m1.1a"><mrow id="S4.T1.st2.4.4.2.m1.1.1" xref="S4.T1.st2.4.4.2.m1.1.1.cmml"><mi id="S4.T1.st2.4.4.2.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.4.4.2.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.4.4.2.m1.1.1.1" xref="S4.T1.st2.4.4.2.m1.1.1.1.cmml">â¢</mo><msub id="S4.T1.st2.4.4.2.m1.1.1.3" xref="S4.T1.st2.4.4.2.m1.1.1.3.cmml"><mi id="S4.T1.st2.4.4.2.m1.1.1.3.2" mathsize="80%" xref="S4.T1.st2.4.4.2.m1.1.1.3.2.cmml">P</mi><mn id="S4.T1.st2.4.4.2.m1.1.1.3.3" mathsize="80%" xref="S4.T1.st2.4.4.2.m1.1.1.3.3.cmml">50</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.4.4.2.m1.1b"><apply id="S4.T1.st2.4.4.2.m1.1.1.cmml" xref="S4.T1.st2.4.4.2.m1.1.1"><times id="S4.T1.st2.4.4.2.m1.1.1.1.cmml" xref="S4.T1.st2.4.4.2.m1.1.1.1"></times><ci id="S4.T1.st2.4.4.2.m1.1.1.2.cmml" xref="S4.T1.st2.4.4.2.m1.1.1.2">ğ´</ci><apply id="S4.T1.st2.4.4.2.m1.1.1.3.cmml" xref="S4.T1.st2.4.4.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T1.st2.4.4.2.m1.1.1.3.1.cmml" xref="S4.T1.st2.4.4.2.m1.1.1.3">subscript</csymbol><ci id="S4.T1.st2.4.4.2.m1.1.1.3.2.cmml" xref="S4.T1.st2.4.4.2.m1.1.1.3.2">ğ‘ƒ</ci><cn id="S4.T1.st2.4.4.2.m1.1.1.3.3.cmml" type="integer" xref="S4.T1.st2.4.4.2.m1.1.1.3.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.4.4.2.m1.1c">AP_{50}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.4.4.2.m1.1d">italic_A italic_P start_POSTSUBSCRIPT 50 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.5.5.3" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP_{75}" class="ltx_Math" display="inline" id="S4.T1.st2.5.5.3.m1.1"><semantics id="S4.T1.st2.5.5.3.m1.1a"><mrow id="S4.T1.st2.5.5.3.m1.1.1" xref="S4.T1.st2.5.5.3.m1.1.1.cmml"><mi id="S4.T1.st2.5.5.3.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.5.5.3.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.5.5.3.m1.1.1.1" xref="S4.T1.st2.5.5.3.m1.1.1.1.cmml">â¢</mo><msub id="S4.T1.st2.5.5.3.m1.1.1.3" xref="S4.T1.st2.5.5.3.m1.1.1.3.cmml"><mi id="S4.T1.st2.5.5.3.m1.1.1.3.2" mathsize="80%" xref="S4.T1.st2.5.5.3.m1.1.1.3.2.cmml">P</mi><mn id="S4.T1.st2.5.5.3.m1.1.1.3.3" mathsize="80%" xref="S4.T1.st2.5.5.3.m1.1.1.3.3.cmml">75</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.5.5.3.m1.1b"><apply id="S4.T1.st2.5.5.3.m1.1.1.cmml" xref="S4.T1.st2.5.5.3.m1.1.1"><times id="S4.T1.st2.5.5.3.m1.1.1.1.cmml" xref="S4.T1.st2.5.5.3.m1.1.1.1"></times><ci id="S4.T1.st2.5.5.3.m1.1.1.2.cmml" xref="S4.T1.st2.5.5.3.m1.1.1.2">ğ´</ci><apply id="S4.T1.st2.5.5.3.m1.1.1.3.cmml" xref="S4.T1.st2.5.5.3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T1.st2.5.5.3.m1.1.1.3.1.cmml" xref="S4.T1.st2.5.5.3.m1.1.1.3">subscript</csymbol><ci id="S4.T1.st2.5.5.3.m1.1.1.3.2.cmml" xref="S4.T1.st2.5.5.3.m1.1.1.3.2">ğ‘ƒ</ci><cn id="S4.T1.st2.5.5.3.m1.1.1.3.3.cmml" type="integer" xref="S4.T1.st2.5.5.3.m1.1.1.3.3">75</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.5.5.3.m1.1c">AP_{75}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.5.5.3.m1.1d">italic_A italic_P start_POSTSUBSCRIPT 75 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.6.6.4" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP" class="ltx_Math" display="inline" id="S4.T1.st2.6.6.4.m1.1"><semantics id="S4.T1.st2.6.6.4.m1.1a"><mrow id="S4.T1.st2.6.6.4.m1.1.1" xref="S4.T1.st2.6.6.4.m1.1.1.cmml"><mi id="S4.T1.st2.6.6.4.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.6.6.4.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.6.6.4.m1.1.1.1" xref="S4.T1.st2.6.6.4.m1.1.1.1.cmml">â¢</mo><mi id="S4.T1.st2.6.6.4.m1.1.1.3" mathsize="80%" xref="S4.T1.st2.6.6.4.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.6.6.4.m1.1b"><apply id="S4.T1.st2.6.6.4.m1.1.1.cmml" xref="S4.T1.st2.6.6.4.m1.1.1"><times id="S4.T1.st2.6.6.4.m1.1.1.1.cmml" xref="S4.T1.st2.6.6.4.m1.1.1.1"></times><ci id="S4.T1.st2.6.6.4.m1.1.1.2.cmml" xref="S4.T1.st2.6.6.4.m1.1.1.2">ğ´</ci><ci id="S4.T1.st2.6.6.4.m1.1.1.3.cmml" xref="S4.T1.st2.6.6.4.m1.1.1.3">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.6.6.4.m1.1c">AP</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.6.6.4.m1.1d">italic_A italic_P</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.7.7.5" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP_{50}" class="ltx_Math" display="inline" id="S4.T1.st2.7.7.5.m1.1"><semantics id="S4.T1.st2.7.7.5.m1.1a"><mrow id="S4.T1.st2.7.7.5.m1.1.1" xref="S4.T1.st2.7.7.5.m1.1.1.cmml"><mi id="S4.T1.st2.7.7.5.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.7.7.5.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.7.7.5.m1.1.1.1" xref="S4.T1.st2.7.7.5.m1.1.1.1.cmml">â¢</mo><msub id="S4.T1.st2.7.7.5.m1.1.1.3" xref="S4.T1.st2.7.7.5.m1.1.1.3.cmml"><mi id="S4.T1.st2.7.7.5.m1.1.1.3.2" mathsize="80%" xref="S4.T1.st2.7.7.5.m1.1.1.3.2.cmml">P</mi><mn id="S4.T1.st2.7.7.5.m1.1.1.3.3" mathsize="80%" xref="S4.T1.st2.7.7.5.m1.1.1.3.3.cmml">50</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.7.7.5.m1.1b"><apply id="S4.T1.st2.7.7.5.m1.1.1.cmml" xref="S4.T1.st2.7.7.5.m1.1.1"><times id="S4.T1.st2.7.7.5.m1.1.1.1.cmml" xref="S4.T1.st2.7.7.5.m1.1.1.1"></times><ci id="S4.T1.st2.7.7.5.m1.1.1.2.cmml" xref="S4.T1.st2.7.7.5.m1.1.1.2">ğ´</ci><apply id="S4.T1.st2.7.7.5.m1.1.1.3.cmml" xref="S4.T1.st2.7.7.5.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T1.st2.7.7.5.m1.1.1.3.1.cmml" xref="S4.T1.st2.7.7.5.m1.1.1.3">subscript</csymbol><ci id="S4.T1.st2.7.7.5.m1.1.1.3.2.cmml" xref="S4.T1.st2.7.7.5.m1.1.1.3.2">ğ‘ƒ</ci><cn id="S4.T1.st2.7.7.5.m1.1.1.3.3.cmml" type="integer" xref="S4.T1.st2.7.7.5.m1.1.1.3.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.7.7.5.m1.1c">AP_{50}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.7.7.5.m1.1d">italic_A italic_P start_POSTSUBSCRIPT 50 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st2.8.8.6" style="padding-left:5.8pt;padding-right:5.8pt;"><math alttext="AP_{75}" class="ltx_Math" display="inline" id="S4.T1.st2.8.8.6.m1.1"><semantics id="S4.T1.st2.8.8.6.m1.1a"><mrow id="S4.T1.st2.8.8.6.m1.1.1" xref="S4.T1.st2.8.8.6.m1.1.1.cmml"><mi id="S4.T1.st2.8.8.6.m1.1.1.2" mathsize="80%" xref="S4.T1.st2.8.8.6.m1.1.1.2.cmml">A</mi><mo id="S4.T1.st2.8.8.6.m1.1.1.1" xref="S4.T1.st2.8.8.6.m1.1.1.1.cmml">â¢</mo><msub id="S4.T1.st2.8.8.6.m1.1.1.3" xref="S4.T1.st2.8.8.6.m1.1.1.3.cmml"><mi id="S4.T1.st2.8.8.6.m1.1.1.3.2" mathsize="80%" xref="S4.T1.st2.8.8.6.m1.1.1.3.2.cmml">P</mi><mn id="S4.T1.st2.8.8.6.m1.1.1.3.3" mathsize="80%" xref="S4.T1.st2.8.8.6.m1.1.1.3.3.cmml">75</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.st2.8.8.6.m1.1b"><apply id="S4.T1.st2.8.8.6.m1.1.1.cmml" xref="S4.T1.st2.8.8.6.m1.1.1"><times id="S4.T1.st2.8.8.6.m1.1.1.1.cmml" xref="S4.T1.st2.8.8.6.m1.1.1.1"></times><ci id="S4.T1.st2.8.8.6.m1.1.1.2.cmml" xref="S4.T1.st2.8.8.6.m1.1.1.2">ğ´</ci><apply id="S4.T1.st2.8.8.6.m1.1.1.3.cmml" xref="S4.T1.st2.8.8.6.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T1.st2.8.8.6.m1.1.1.3.1.cmml" xref="S4.T1.st2.8.8.6.m1.1.1.3">subscript</csymbol><ci id="S4.T1.st2.8.8.6.m1.1.1.3.2.cmml" xref="S4.T1.st2.8.8.6.m1.1.1.3.2">ğ‘ƒ</ci><cn id="S4.T1.st2.8.8.6.m1.1.1.3.3.cmml" type="integer" xref="S4.T1.st2.8.8.6.m1.1.1.3.3">75</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.8.8.6.m1.1c">AP_{75}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st2.8.8.6.m1.1d">italic_A italic_P start_POSTSUBSCRIPT 75 end_POSTSUBSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.st2.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T1.st2.8.9.1.1" style="padding-left:5.8pt;padding-right:5.8pt;">
<span class="ltx_text" id="S4.T1.st2.8.9.1.1.1" style="font-size:80%;">UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st2.8.9.1.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="S4.T1.st2.8.9.1.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.2" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.2.1" style="font-size:80%;">23.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.3" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.3.1" style="font-size:80%;">45.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.4" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.4.1" style="font-size:80%;">22.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.5" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.5.1" style="font-size:80%;">18.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.6" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.6.1" style="font-size:80%;">34.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st2.8.9.1.7" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.9.1.7.1" style="font-size:80%;">17.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st2.8.10.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st2.8.10.2.1" style="padding-left:5.8pt;padding-right:5.8pt;">
<span class="ltx_text" id="S4.T1.st2.8.10.2.1.1" style="font-size:80%;">LMSegÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st2.8.10.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a><span class="ltx_text" id="S4.T1.st2.8.10.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.2" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.2.1" style="font-size:80%;">21.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.3" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.3.1" style="font-size:80%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.4" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.4.1" style="font-size:80%;">20.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.5" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.5.1" style="font-size:80%;">18.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.6" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.6.1" style="font-size:80%;">35.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.10.2.7" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.10.2.7.1" style="font-size:80%;">17.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st2.8.11.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.st2.8.11.3.1" style="padding-left:5.8pt;padding-right:5.8pt;">
<span class="ltx_text" id="S4.T1.st2.8.11.3.1.1" style="font-size:80%;">M2F+LEÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T1.st2.8.11.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a><span class="ltx_text" id="S4.T1.st2.8.11.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.2" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.2.1" style="font-size:80%;">24.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.3" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.3.1" style="font-size:80%;">46.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.4" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.4.1" style="font-size:80%;">23.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.5" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.5.1" style="font-size:80%;">19.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.6" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.6.1" style="font-size:80%;">36.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st2.8.11.3.7" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.11.3.7.1" style="font-size:80%;">19.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st2.8.12.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.st2.8.12.4.1" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text" id="S4.T1.st2.8.12.4.1.1" style="font-size:80%;">RESI (Ours)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.2" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.2.1" style="font-size:80%;">44.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.3" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.3.1" style="font-size:80%;">68.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.4" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.4.1" style="font-size:80%;">48.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.5" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.5.1" style="font-size:80%;">24.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.6" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.6.1" style="font-size:80%;">44.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st2.8.12.4.7" style="padding-left:5.8pt;padding-right:5.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st2.8.12.4.7.1" style="font-size:80%;">23.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.st2.12.1.1" style="font-size:113%;">(b)</span> </span><span class="ltx_text" id="S4.T1.st2.13.2" style="font-size:113%;">Instance segmentation</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel ltx_align_center" id="S4.T1.st3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.st3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.st3.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4" id="S4.T1.st3.1.1.1" style="padding-left:4.5pt;padding-right:4.5pt;">
<span class="ltx_text" id="S4.T1.st3.1.1.1.1" style="font-size:80%;">COCO</span><math alttext="{}^{\textrm{-sem}}" class="ltx_Math" display="inline" id="S4.T1.st3.1.1.1.m1.1"><semantics id="S4.T1.st3.1.1.1.m1.1a"><msup id="S4.T1.st3.1.1.1.m1.1.1" xref="S4.T1.st3.1.1.1.m1.1.1.cmml"><mi id="S4.T1.st3.1.1.1.m1.1.1a" xref="S4.T1.st3.1.1.1.m1.1.1.cmml"></mi><mtext id="S4.T1.st3.1.1.1.m1.1.1.1" mathsize="80%" xref="S4.T1.st3.1.1.1.m1.1.1.1a.cmml">-sem</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.T1.st3.1.1.1.m1.1b"><apply id="S4.T1.st3.1.1.1.m1.1.1.cmml" xref="S4.T1.st3.1.1.1.m1.1.1"><ci id="S4.T1.st3.1.1.1.m1.1.1.1a.cmml" xref="S4.T1.st3.1.1.1.m1.1.1.1"><mtext id="S4.T1.st3.1.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st3.1.1.1.m1.1.1.1">-sem</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st3.1.1.1.m1.1c">{}^{\textrm{-sem}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st3.1.1.1.m1.1d">start_FLOATSUPERSCRIPT -sem end_FLOATSUPERSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4" id="S4.T1.st3.2.2.2" style="padding-left:4.5pt;padding-right:4.5pt;">
<span class="ltx_text" id="S4.T1.st3.2.2.2.1" style="font-size:80%;">CS</span><math alttext="{}^{\textrm{-sem}}" class="ltx_Math" display="inline" id="S4.T1.st3.2.2.2.m1.1"><semantics id="S4.T1.st3.2.2.2.m1.1a"><msup id="S4.T1.st3.2.2.2.m1.1.1" xref="S4.T1.st3.2.2.2.m1.1.1.cmml"><mi id="S4.T1.st3.2.2.2.m1.1.1a" xref="S4.T1.st3.2.2.2.m1.1.1.cmml"></mi><mtext id="S4.T1.st3.2.2.2.m1.1.1.1" mathsize="80%" xref="S4.T1.st3.2.2.2.m1.1.1.1a.cmml">-sem</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.T1.st3.2.2.2.m1.1b"><apply id="S4.T1.st3.2.2.2.m1.1.1.cmml" xref="S4.T1.st3.2.2.2.m1.1.1"><ci id="S4.T1.st3.2.2.2.m1.1.1.1a.cmml" xref="S4.T1.st3.2.2.2.m1.1.1.1"><mtext id="S4.T1.st3.2.2.2.m1.1.1.1.cmml" mathsize="56%" xref="S4.T1.st3.2.2.2.m1.1.1.1">-sem</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st3.2.2.2.m1.1c">{}^{\textrm{-sem}}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.st3.2.2.2.m1.1d">start_FLOATSUPERSCRIPT -sem end_FLOATSUPERSCRIPT</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr" id="S4.T1.st3.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.1" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.1.1" style="font-size:80%;">mIoU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.2" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.2.1" style="font-size:80%;">fwIoU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.3" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.3.1" style="font-size:80%;">mACC</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.4" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.4.1" style="font-size:80%;">pACC</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.5" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.5.1" style="font-size:80%;">mIoU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.6" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.6.1" style="font-size:80%;">fwIoU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.7" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.7.1" style="font-size:80%;">mACC</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.st3.2.3.1.8" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.3.1.8.1" style="font-size:80%;">pACC</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.st3.2.4.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.1" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.1.1" style="font-size:80%;">58.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.2" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.2.1" style="font-size:80%;">67.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.3" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.3.1" style="font-size:80%;">71.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.4" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.4.1" style="font-size:80%;">79.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.5" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.5.1" style="font-size:80%;">75.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.6" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.6.1" style="font-size:80%;">50.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.7" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.7.1" style="font-size:80%;">89.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.st3.2.4.1.8" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.4.1.8.1" style="font-size:80%;">68.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st3.2.5.2">
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.1" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.1.1" style="font-size:80%;">59.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.2" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.2.1" style="font-size:80%;">68.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.3" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.3.1" style="font-size:80%;">71.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.4" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.4.1" style="font-size:80%;">79.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.5" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.5.1" style="font-size:80%;">73.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.6" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.6.1" style="font-size:80%;">50.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.7" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.7.1" style="font-size:80%;">89.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.5.2.8" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.5.2.8.1" style="font-size:80%;">68.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st3.2.6.3">
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.1" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.1.1" style="font-size:80%;">58.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.2" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.2.1" style="font-size:80%;">68.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.3" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.3.1" style="font-size:80%;">71.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.4" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.4.1" style="font-size:80%;">79.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.5" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.5.1" style="font-size:80%;">75.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.6" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.6.1" style="font-size:80%;">52.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.7" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.7.1" style="font-size:80%;">89.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.st3.2.6.3.8" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text" id="S4.T1.st3.2.6.3.8.1" style="font-size:80%;">67.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.st3.2.7.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.1" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.1.1" style="font-size:80%;">59.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.2" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.2.1" style="font-size:80%;">68.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.3" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.3.1" style="font-size:80%;">72.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.4" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.4.1" style="font-size:80%;">79.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.5" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.5.1" style="font-size:80%;">78.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.6" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.6.1" style="font-size:80%;">62.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.7" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.7.1" style="font-size:80%;">90.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.st3.2.7.4.8" style="padding-left:4.5pt;padding-right:4.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.st3.2.7.4.8.1" style="font-size:80%;">80.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.st3.6.1.1" style="font-size:113%;">(c)</span> </span><span class="ltx_text" id="S4.T1.st3.7.2" style="font-size:113%;">Semantic segmentation</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.4.1.1" style="font-size:113%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.5.2" style="font-size:113%;">Performance improvements on various datasets across three segmentation tasks: panoptic, instance, and semantic.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.6.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T2.6.6.6.7" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.6.7.1" style="font-size:80%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.1.1.1.1" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml"><mi id="S4.T2.1.1.1.1.m1.1.1.2" mathsize="80%" xref="S4.T2.1.1.1.1.m1.1.1.2.cmml">P</mi><mo id="S4.T2.1.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.1.1.1.1.m1.1.1.3" mathsize="80%" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml">I</mi><mo id="S4.T2.1.1.1.1.m1.1.1.1a" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.1.1.1.1.m1.1.1.4" mathsize="80%" xref="S4.T2.1.1.1.1.m1.1.1.4.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1"><times id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1"></times><ci id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">ğ¼</ci><ci id="S4.T2.1.1.1.1.m1.1.1.4.cmml" xref="S4.T2.1.1.1.1.m1.1.1.4">ğ‘„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">PIQ</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">italic_P italic_I italic_Q</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.2.2.2.2" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ_{50}" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><mi id="S4.T2.2.2.2.2.m1.1.1.2" mathsize="80%" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml">P</mi><mo id="S4.T2.2.2.2.2.m1.1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.2.2.2.2.m1.1.1.3" mathsize="80%" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml">I</mi><mo id="S4.T2.2.2.2.2.m1.1.1.1a" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">â¢</mo><msub id="S4.T2.2.2.2.2.m1.1.1.4" xref="S4.T2.2.2.2.2.m1.1.1.4.cmml"><mi id="S4.T2.2.2.2.2.m1.1.1.4.2" mathsize="80%" xref="S4.T2.2.2.2.2.m1.1.1.4.2.cmml">Q</mi><mn id="S4.T2.2.2.2.2.m1.1.1.4.3" mathsize="80%" xref="S4.T2.2.2.2.2.m1.1.1.4.3.cmml">50</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><times id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1"></times><ci id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">ğ¼</ci><apply id="S4.T2.2.2.2.2.m1.1.1.4.cmml" xref="S4.T2.2.2.2.2.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T2.2.2.2.2.m1.1.1.4.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.4">subscript</csymbol><ci id="S4.T2.2.2.2.2.m1.1.1.4.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.4.2">ğ‘„</ci><cn id="S4.T2.2.2.2.2.m1.1.1.4.3.cmml" type="integer" xref="S4.T2.2.2.2.2.m1.1.1.4.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">PIQ_{50}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.m1.1d">italic_P italic_I italic_Q start_POSTSUBSCRIPT 50 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.3.3.3.3" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ_{75}" class="ltx_Math" display="inline" id="S4.T2.3.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.3.m1.1.1.2" mathsize="80%" xref="S4.T2.3.3.3.3.m1.1.1.2.cmml">P</mi><mo id="S4.T2.3.3.3.3.m1.1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.3.3.3.3.m1.1.1.3" mathsize="80%" xref="S4.T2.3.3.3.3.m1.1.1.3.cmml">I</mi><mo id="S4.T2.3.3.3.3.m1.1.1.1a" xref="S4.T2.3.3.3.3.m1.1.1.1.cmml">â¢</mo><msub id="S4.T2.3.3.3.3.m1.1.1.4" xref="S4.T2.3.3.3.3.m1.1.1.4.cmml"><mi id="S4.T2.3.3.3.3.m1.1.1.4.2" mathsize="80%" xref="S4.T2.3.3.3.3.m1.1.1.4.2.cmml">Q</mi><mn id="S4.T2.3.3.3.3.m1.1.1.4.3" mathsize="80%" xref="S4.T2.3.3.3.3.m1.1.1.4.3.cmml">75</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1"><times id="S4.T2.3.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1.1"></times><ci id="S4.T2.3.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.3.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.3.m1.1.1.3">ğ¼</ci><apply id="S4.T2.3.3.3.3.m1.1.1.4.cmml" xref="S4.T2.3.3.3.3.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T2.3.3.3.3.m1.1.1.4.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1.4">subscript</csymbol><ci id="S4.T2.3.3.3.3.m1.1.1.4.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.4.2">ğ‘„</ci><cn id="S4.T2.3.3.3.3.m1.1.1.4.3.cmml" type="integer" xref="S4.T2.3.3.3.3.m1.1.1.4.3">75</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">PIQ_{75}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.3.m1.1d">italic_P italic_I italic_Q start_POSTSUBSCRIPT 75 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.4.4.4.4" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ_{s}" class="ltx_Math" display="inline" id="S4.T2.4.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml"><mi id="S4.T2.4.4.4.4.m1.1.1.2" mathsize="80%" xref="S4.T2.4.4.4.4.m1.1.1.2.cmml">P</mi><mo id="S4.T2.4.4.4.4.m1.1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.4.4.4.4.m1.1.1.3" mathsize="80%" xref="S4.T2.4.4.4.4.m1.1.1.3.cmml">I</mi><mo id="S4.T2.4.4.4.4.m1.1.1.1a" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">â¢</mo><msub id="S4.T2.4.4.4.4.m1.1.1.4" xref="S4.T2.4.4.4.4.m1.1.1.4.cmml"><mi id="S4.T2.4.4.4.4.m1.1.1.4.2" mathsize="80%" xref="S4.T2.4.4.4.4.m1.1.1.4.2.cmml">Q</mi><mi id="S4.T2.4.4.4.4.m1.1.1.4.3" mathsize="80%" xref="S4.T2.4.4.4.4.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1"><times id="S4.T2.4.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.1"></times><ci id="S4.T2.4.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.4.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.3">ğ¼</ci><apply id="S4.T2.4.4.4.4.m1.1.1.4.cmml" xref="S4.T2.4.4.4.4.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T2.4.4.4.4.m1.1.1.4.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.4">subscript</csymbol><ci id="S4.T2.4.4.4.4.m1.1.1.4.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.4.2">ğ‘„</ci><ci id="S4.T2.4.4.4.4.m1.1.1.4.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.4.3">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">PIQ_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.4.m1.1d">italic_P italic_I italic_Q start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.5.5.5.5" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ_{m}" class="ltx_Math" display="inline" id="S4.T2.5.5.5.5.m1.1"><semantics id="S4.T2.5.5.5.5.m1.1a"><mrow id="S4.T2.5.5.5.5.m1.1.1" xref="S4.T2.5.5.5.5.m1.1.1.cmml"><mi id="S4.T2.5.5.5.5.m1.1.1.2" mathsize="80%" xref="S4.T2.5.5.5.5.m1.1.1.2.cmml">P</mi><mo id="S4.T2.5.5.5.5.m1.1.1.1" xref="S4.T2.5.5.5.5.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.5.5.5.5.m1.1.1.3" mathsize="80%" xref="S4.T2.5.5.5.5.m1.1.1.3.cmml">I</mi><mo id="S4.T2.5.5.5.5.m1.1.1.1a" xref="S4.T2.5.5.5.5.m1.1.1.1.cmml">â¢</mo><msub id="S4.T2.5.5.5.5.m1.1.1.4" xref="S4.T2.5.5.5.5.m1.1.1.4.cmml"><mi id="S4.T2.5.5.5.5.m1.1.1.4.2" mathsize="80%" xref="S4.T2.5.5.5.5.m1.1.1.4.2.cmml">Q</mi><mi id="S4.T2.5.5.5.5.m1.1.1.4.3" mathsize="80%" xref="S4.T2.5.5.5.5.m1.1.1.4.3.cmml">m</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1"><times id="S4.T2.5.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1.1"></times><ci id="S4.T2.5.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.5.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.5.5.5.5.m1.1.1.3.cmml" xref="S4.T2.5.5.5.5.m1.1.1.3">ğ¼</ci><apply id="S4.T2.5.5.5.5.m1.1.1.4.cmml" xref="S4.T2.5.5.5.5.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T2.5.5.5.5.m1.1.1.4.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1.4">subscript</csymbol><ci id="S4.T2.5.5.5.5.m1.1.1.4.2.cmml" xref="S4.T2.5.5.5.5.m1.1.1.4.2">ğ‘„</ci><ci id="S4.T2.5.5.5.5.m1.1.1.4.3.cmml" xref="S4.T2.5.5.5.5.m1.1.1.4.3">ğ‘š</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.m1.1c">PIQ_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.5.5.m1.1d">italic_P italic_I italic_Q start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.6.6.6.6" style="padding-left:4.2pt;padding-right:4.2pt;"><math alttext="PIQ_{l}" class="ltx_Math" display="inline" id="S4.T2.6.6.6.6.m1.1"><semantics id="S4.T2.6.6.6.6.m1.1a"><mrow id="S4.T2.6.6.6.6.m1.1.1" xref="S4.T2.6.6.6.6.m1.1.1.cmml"><mi id="S4.T2.6.6.6.6.m1.1.1.2" mathsize="80%" xref="S4.T2.6.6.6.6.m1.1.1.2.cmml">P</mi><mo id="S4.T2.6.6.6.6.m1.1.1.1" xref="S4.T2.6.6.6.6.m1.1.1.1.cmml">â¢</mo><mi id="S4.T2.6.6.6.6.m1.1.1.3" mathsize="80%" xref="S4.T2.6.6.6.6.m1.1.1.3.cmml">I</mi><mo id="S4.T2.6.6.6.6.m1.1.1.1a" xref="S4.T2.6.6.6.6.m1.1.1.1.cmml">â¢</mo><msub id="S4.T2.6.6.6.6.m1.1.1.4" xref="S4.T2.6.6.6.6.m1.1.1.4.cmml"><mi id="S4.T2.6.6.6.6.m1.1.1.4.2" mathsize="80%" xref="S4.T2.6.6.6.6.m1.1.1.4.2.cmml">Q</mi><mi id="S4.T2.6.6.6.6.m1.1.1.4.3" mathsize="80%" xref="S4.T2.6.6.6.6.m1.1.1.4.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.6.m1.1b"><apply id="S4.T2.6.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1"><times id="S4.T2.6.6.6.6.m1.1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1.1"></times><ci id="S4.T2.6.6.6.6.m1.1.1.2.cmml" xref="S4.T2.6.6.6.6.m1.1.1.2">ğ‘ƒ</ci><ci id="S4.T2.6.6.6.6.m1.1.1.3.cmml" xref="S4.T2.6.6.6.6.m1.1.1.3">ğ¼</ci><apply id="S4.T2.6.6.6.6.m1.1.1.4.cmml" xref="S4.T2.6.6.6.6.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T2.6.6.6.6.m1.1.1.4.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1.4">subscript</csymbol><ci id="S4.T2.6.6.6.6.m1.1.1.4.2.cmml" xref="S4.T2.6.6.6.6.m1.1.1.4.2">ğ‘„</ci><ci id="S4.T2.6.6.6.6.m1.1.1.4.3.cmml" xref="S4.T2.6.6.6.6.m1.1.1.4.3">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.6.m1.1c">PIQ_{l}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.6.6.m1.1d">italic_P italic_I italic_Q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.6.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.6.6.7.1.1" style="padding-left:4.2pt;padding-right:4.2pt;">
<span class="ltx_text" id="S4.T2.6.6.7.1.1.1" style="font-size:80%;">UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.6.6.7.1.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="S4.T2.6.6.7.1.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.2" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.2.1" style="font-size:80%;">41.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.3" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.3.1" style="font-size:80%;">49.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.4" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.4.1" style="font-size:80%;">41.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.5" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.5.1" style="font-size:80%;">36.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.6" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.6.1" style="font-size:80%;">48.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.6.6.7.1.7" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.7.1.7.1" style="font-size:80%;">54.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.6.6.8.2.1" style="padding-left:4.2pt;padding-right:4.2pt;">
<span class="ltx_text" id="S4.T2.6.6.8.2.1.1" style="font-size:80%;">LMSegÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.6.6.8.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a><span class="ltx_text" id="S4.T2.6.6.8.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.2" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.2.1" style="font-size:80%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.3" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.3.1" style="font-size:80%;">50.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.4" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.4.1" style="font-size:80%;">41.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.5" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.5.1" style="font-size:80%;">36.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.6" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.6.1" style="font-size:80%;">49.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8.2.7" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.8.2.7.1" style="font-size:80%;">52.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.9.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.6.6.9.3.1" style="padding-left:4.2pt;padding-right:4.2pt;">
<span class="ltx_text" id="S4.T2.6.6.9.3.1.1" style="font-size:80%;">M2F+LEÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.6.6.9.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a><span class="ltx_text" id="S4.T2.6.6.9.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.2" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.2.1" style="font-size:80%;">42.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.3" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.3.1" style="font-size:80%;">51.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.4" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.4.1" style="font-size:80%;">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.5" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.5.1" style="font-size:80%;">36.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.6" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.6.1" style="font-size:80%;">50.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9.3.7" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.9.3.7.1" style="font-size:80%;">57.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.10.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.6.6.10.4.1" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text" id="S4.T2.6.6.10.4.1.1" style="font-size:80%;">RESI (Ours)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.2" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.2.1" style="font-size:80%;">45.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.3" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.3.1" style="font-size:80%;">56.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.4" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.4.1" style="font-size:80%;">45.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.5" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.5.1" style="font-size:80%;">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.6" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.6.1" style="font-size:80%;">54.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.6.10.4.7" style="padding-left:4.2pt;padding-right:4.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.10.4.7.1" style="font-size:80%;">60.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.8.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.9.2" style="font-size:90%;">Comparative analysis of Panoptic Instance Quality (PIQ) on the Cityscapes Panoptic Parts benchmark with overlapping masks for thing categories.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T3.2.1.1.1" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.1.1" style="font-size:80%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.2" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.2.1" style="font-size:80%;">COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.3" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.3.1" style="font-size:80%;">CIHP</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.4" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.4.1" style="font-size:80%;">CS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.5" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.5.1" style="font-size:80%;">CSP</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.6" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.6.1" style="font-size:80%;">COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.7" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.7.1" style="font-size:80%;">ADE</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T3.2.1.1.8" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.8.1" style="font-size:80%;">VST</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.1.1.9" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.1.1.9.1" style="font-size:80%;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T3.2.2.1.1" style="padding-left:3.2pt;padding-right:3.2pt;">
<span class="ltx_text" id="S4.T3.2.2.1.1.1" style="font-size:80%;">UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.2.2.1.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="S4.T3.2.2.1.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.2" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.2.1" style="font-size:80%;">48.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.3" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.3.1" style="font-size:80%;">61.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.4" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.4.1" style="font-size:80%;">57.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.5" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.5.1" style="font-size:80%;">19.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.6" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.6.1" style="font-size:80%;">47.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.7" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.7.1" style="font-size:80%;">41.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.2.2.1.8" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.8.1" style="font-size:80%;">35.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.2.1.9" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.2.1.9.1" style="font-size:80%;">44.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.3.2.1" style="padding-left:3.2pt;padding-right:3.2pt;">
<span class="ltx_text" id="S4.T3.2.3.2.1.1" style="font-size:80%;">LMSegÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.2.3.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a><span class="ltx_text" id="S4.T3.2.3.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.2" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.2.1" style="font-size:80%;">48.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.3" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.3.1" style="font-size:80%;">61.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.4" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.4.1" style="font-size:80%;">56.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.5" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.5.1" style="font-size:80%;">23.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.6" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.6.1" style="font-size:80%;">47.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.7" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.7.1" style="font-size:80%;">40.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.3.2.8" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.8.1" style="font-size:80%;">34.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.9" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.3.2.9.1" style="font-size:80%;">44.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.4.3.1" style="padding-left:3.2pt;padding-right:3.2pt;">
<span class="ltx_text" id="S4.T3.2.4.3.1.1" style="font-size:80%;">M2F+LEÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.2.4.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a><span class="ltx_text" id="S4.T3.2.4.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.2" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.2.1" style="font-size:80%;">48.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.3" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.4.3.3.1" style="font-size:80%;">62.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.4" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.4.1" style="font-size:80%;">57.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.5" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.5.1" style="font-size:80%;">24.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.6" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.6.1" style="font-size:80%;">47.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.7" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.7.1" style="font-size:80%;">41.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.4.3.8" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.8.1" style="font-size:80%;">33.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.9" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.4.3.9.1" style="font-size:80%;">45.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.2.5.4.1" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.5.4.1.1" style="font-size:80%;">RESI (Ours)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.2" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.2.1" style="font-size:80%;">49.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.3" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text" id="S4.T3.2.5.4.3.1" style="font-size:80%;">61.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.4" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.4.1" style="font-size:80%;">61.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.5" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.5.1" style="font-size:80%;">32.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.6" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.6.1" style="font-size:80%;">48.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.7" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.7.1" style="font-size:80%;">42.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.2.5.4.8" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.8.1" style="font-size:80%;">35.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.5.4.9" style="padding-left:3.2pt;padding-right:3.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.2.5.4.9.1" style="font-size:80%;">47.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.11.1.1" style="font-size:113%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.12.2" style="font-size:113%;">Per-dataset label space evaluation for three dataset groups (<span class="ltx_text ltx_font_typewriter" id="S4.T3.12.2.1">D1</span>, <span class="ltx_text ltx_font_typewriter" id="S4.T3.12.2.2">D2</span>, <span class="ltx_text ltx_font_typewriter" id="S4.T3.12.2.3">D3</span>). Each method (rows) was trained for each of the three groups and then evaluated on the individual label spaces.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T4.4.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4.4.5.1" style="width:21.1pt;height:7.1pt;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="width:21.1pt;transform:translate(0pt,2.33pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.4.4.5.1.1"><span class="ltx_text" id="S4.T4.4.4.5.1.1.1" style="font-size:80%;">LSQE</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T4.4.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4.4.6.1" style="width:34.2pt;height:5.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:34.2pt;transform:translate(0pt,0pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.4.4.6.1.1"><span class="ltx_text" id="S4.T4.4.4.6.1.1.1" style="font-size:80%;">ESF-OMI</span></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.1.1.1.1" style="width:23.2pt;height:7pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="width:23.2pt;transform:translate(0pt,2.3pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.1.1.1.1.1"><span class="ltx_text" id="S4.T4.1.1.1.1.1.1" style="font-size:80%;">CIHP</span><math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><msub id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.1.1.m1.1.1a" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml"></mi><mtext id="S4.T4.1.1.1.1.1.m1.1.1.1" mathsize="80%" xref="S4.T4.1.1.1.1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1"><ci id="S4.T4.1.1.1.1.1.m1.1.1.1a.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1.1"><mtext id="S4.T4.1.1.1.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T4.1.1.1.1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.2.2.2.1" style="width:24.2pt;height:7pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="width:24.2pt;transform:translate(0pt,2.3pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.2.2.2.1.1"><span class="ltx_text" id="S4.T4.2.2.2.1.1.1" style="font-size:80%;">CIHP</span><math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.T4.2.2.2.1.1.m1.1"><semantics id="S4.T4.2.2.2.1.1.m1.1a"><msub id="S4.T4.2.2.2.1.1.m1.1.1" xref="S4.T4.2.2.2.1.1.m1.1.1.cmml"><mi id="S4.T4.2.2.2.1.1.m1.1.1a" xref="S4.T4.2.2.2.1.1.m1.1.1.cmml"></mi><mtext id="S4.T4.2.2.2.1.1.m1.1.1.1" mathsize="80%" xref="S4.T4.2.2.2.1.1.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.1.1.m1.1b"><apply id="S4.T4.2.2.2.1.1.m1.1.1.cmml" xref="S4.T4.2.2.2.1.1.m1.1.1"><ci id="S4.T4.2.2.2.1.1.m1.1.1.1a.cmml" xref="S4.T4.2.2.2.1.1.m1.1.1.1"><mtext id="S4.T4.2.2.2.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T4.2.2.2.1.1.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.1.1.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.1.1.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.3.3.3.1" style="width:18.7pt;height:7pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="width:18.7pt;transform:translate(0pt,2.3pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.3.3.3.1.1"><span class="ltx_text" id="S4.T4.3.3.3.1.1.1" style="font-size:80%;">CSP</span><math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.T4.3.3.3.1.1.m1.1"><semantics id="S4.T4.3.3.3.1.1.m1.1a"><msub id="S4.T4.3.3.3.1.1.m1.1.1" xref="S4.T4.3.3.3.1.1.m1.1.1.cmml"><mi id="S4.T4.3.3.3.1.1.m1.1.1a" xref="S4.T4.3.3.3.1.1.m1.1.1.cmml"></mi><mtext id="S4.T4.3.3.3.1.1.m1.1.1.1" mathsize="80%" xref="S4.T4.3.3.3.1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.1.1.m1.1b"><apply id="S4.T4.3.3.3.1.1.m1.1.1.cmml" xref="S4.T4.3.3.3.1.1.m1.1.1"><ci id="S4.T4.3.3.3.1.1.m1.1.1.1a.cmml" xref="S4.T4.3.3.3.1.1.m1.1.1.1"><mtext id="S4.T4.3.3.3.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T4.3.3.3.1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4.4.4.1" style="width:19.8pt;height:7pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="width:19.8pt;transform:translate(0pt,2.3pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.4.4.4.1.1"><span class="ltx_text" id="S4.T4.4.4.4.1.1.1" style="font-size:80%;">CSP</span><math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.T4.4.4.4.1.1.m1.1"><semantics id="S4.T4.4.4.4.1.1.m1.1a"><msub id="S4.T4.4.4.4.1.1.m1.1.1" xref="S4.T4.4.4.4.1.1.m1.1.1.cmml"><mi id="S4.T4.4.4.4.1.1.m1.1.1a" xref="S4.T4.4.4.4.1.1.m1.1.1.cmml"></mi><mtext id="S4.T4.4.4.4.1.1.m1.1.1.1" mathsize="80%" xref="S4.T4.4.4.4.1.1.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.1.m1.1b"><apply id="S4.T4.4.4.4.1.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.1.m1.1.1"><ci id="S4.T4.4.4.4.1.1.m1.1.1.1a.cmml" xref="S4.T4.4.4.4.1.1.m1.1.1.1"><mtext id="S4.T4.4.4.4.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S4.T4.4.4.4.1.1.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.1.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.1.1.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math></p>
</span></div>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.4.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4.4.7.1" style="width:14.2pt;height:7.1pt;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="width:14.2pt;transform:translate(0pt,2.33pt) rotate(-0deg) ;">
<p class="ltx_p" id="S4.T4.4.4.7.1.1"><span class="ltx_text" id="S4.T4.4.4.7.1.1.1" style="font-size:80%;">Avg</span></p>
</span></div>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.4.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S4.T4.4.5.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.1.1" style="font-size:80%;">âœ—</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.4.5.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.2.1" style="font-size:80%;">âœ—</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.5.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.3.1" style="font-size:80%;">45.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.5.1.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.4.1" style="font-size:80%;">53.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.5.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.5.1" style="font-size:80%;">38.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.4.5.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.6.1" style="font-size:80%;">22.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.5.1.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.5.1.7.1" style="font-size:80%;">40.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.4.6.2.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.1.1" style="font-size:80%;">âœ“</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.6.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.2.1" style="font-size:80%;">âœ—</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.6.2.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.3.1" style="font-size:80%;">60.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.6.2.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.4.1" style="font-size:80%;">56.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.6.2.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.5.1" style="font-size:80%;">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.6.2.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.6.1" style="font-size:80%;">11.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.6.2.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.6.2.7.1" style="font-size:80%;">40.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.7.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.4.7.3.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.1.1" style="font-size:80%;">âœ—</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.7.3.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.2.1" style="font-size:80%;">âœ“</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.7.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.3.1" style="font-size:80%;">45.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.7.3.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.4.1" style="font-size:80%;">53.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.7.3.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.5.1" style="font-size:80%;">38.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.4.7.3.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.6.1" style="font-size:80%;">22.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.7.3.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.7.3.7.1" style="font-size:80%;">40.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.8.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T4.4.8.4.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.8.4.1.1" style="font-size:80%;">âœ“</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T4.4.8.4.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S4.T4.4.8.4.2.1" style="font-size:80%;">âœ“</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.8.4.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.8.4.3.1" style="font-size:80%;">61.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.8.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.8.4.4.1" style="font-size:80%;">58.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.8.4.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.8.4.5.1" style="font-size:80%;">45.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.4.8.4.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.8.4.6.1" style="font-size:80%;">31.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.8.4.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.8.4.7.1" style="font-size:80%;">49.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.14.3.1" style="font-size:113%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.8.2" style="font-size:113%;">Ablation study of different model components in RESI on average PQ. LSQE enables the model to generate diverse masks from various input categories, even in the presence of potential semantic conflicts. However, this diversity may sometimes result in a performance drop due to confusion and overlap, as seen in the second row for CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.T4.7.1.m1.1"><semantics id="S4.T4.7.1.m1.1b"><msub id="S4.T4.7.1.m1.1.1" xref="S4.T4.7.1.m1.1.1.cmml"><mi id="S4.T4.7.1.m1.1.1b" xref="S4.T4.7.1.m1.1.1.cmml"></mi><mtext id="S4.T4.7.1.m1.1.1.1" xref="S4.T4.7.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.7.1.m1.1c"><apply id="S4.T4.7.1.m1.1.1.cmml" xref="S4.T4.7.1.m1.1.1"><ci id="S4.T4.7.1.m1.1.1.1a.cmml" xref="S4.T4.7.1.m1.1.1.1"><mtext id="S4.T4.7.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.T4.7.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.1.m1.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.1.m1.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.T4.8.2.m2.1"><semantics id="S4.T4.8.2.m2.1b"><msub id="S4.T4.8.2.m2.1.1" xref="S4.T4.8.2.m2.1.1.cmml"><mi id="S4.T4.8.2.m2.1.1b" xref="S4.T4.8.2.m2.1.1.cmml"></mi><mtext id="S4.T4.8.2.m2.1.1.1" xref="S4.T4.8.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.8.2.m2.1c"><apply id="S4.T4.8.2.m2.1.1.cmml" xref="S4.T4.8.2.m2.1.1"><ci id="S4.T4.8.2.m2.1.1.1a.cmml" xref="S4.T4.8.2.m2.1.1.1"><mtext id="S4.T4.8.2.m2.1.1.1.cmml" mathsize="70%" xref="S4.T4.8.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.2.m2.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.2.m2.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>. ESF-OMI effectively refines the masks produced by LSQE, leading to superior performance when both modules operate in tandem (last row).</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="98" id="S4.F5.g1" src="x2.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.4.2.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.2.1" style="font-size:90%;">
Average PQ w.r.t. total training cost for three panoptic segmentation dataset(COCO, ADE20K, Mapillary Vistas) and two mixed-label space evaluation-only datasets CIHP/CSP<math alttext="{}_{\textrm{multi}}" class="ltx_Math" display="inline" id="S4.F5.2.1.m1.1"><semantics id="S4.F5.2.1.m1.1b"><msub id="S4.F5.2.1.m1.1.1" xref="S4.F5.2.1.m1.1.1.cmml"><mi id="S4.F5.2.1.m1.1.1b" xref="S4.F5.2.1.m1.1.1.cmml"></mi><mtext id="S4.F5.2.1.m1.1.1.1" xref="S4.F5.2.1.m1.1.1.1a.cmml">multi</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F5.2.1.m1.1c"><apply id="S4.F5.2.1.m1.1.1.cmml" xref="S4.F5.2.1.m1.1.1"><ci id="S4.F5.2.1.m1.1.1.1a.cmml" xref="S4.F5.2.1.m1.1.1.1"><mtext id="S4.F5.2.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.F5.2.1.m1.1.1.1">multi</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.2.1.m1.1d">{}_{\textrm{multi}}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.2.1.m1.1e">start_FLOATSUBSCRIPT multi end_FLOATSUBSCRIPT</annotation></semantics></math>.</span></figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Panoptic Segmentation.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.4">Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1" title="Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates our results on the mixed-label space benchmarks CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><msub id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.1.m1.1.1a" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"></mi><mtext id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1"><ci id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1a.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1"><mtext id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS2.SSS0.Px1.p1.2.m2.1a"><msub id="S4.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.2.m2.1.1a" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"></mi><mtext id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1"><ci id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1a.cmml" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1"><mtext id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" mathsize="70%" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.m2.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.2.m2.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>, CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S4.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.3.m3.1.1a" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"></mi><mtext id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1"><ci id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1a.cmml" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1"><mtext id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" mathsize="70%" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.3.m3.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.3.m3.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.4.m4.1"><semantics id="S4.SS2.SSS0.Px1.p1.4.m4.1a"><msub id="S4.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.4.m4.1.1a" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"></mi><mtext id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1"><ci id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1a.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1"><mtext id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" mathsize="70%" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.4.m4.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p1.4.m4.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>. For each method, we evaluate two models trained on dataset groups <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS0.Px1.p1.4.1">D2</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS0.Px1.p1.4.2">D3</span>, respectively. Our method RESI outperforms all baselines on all four benchmarks.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p2.1">To ensure that our superior performance was not merely a result of differences in convergence rates or training iterations among the models, we standardized the hyperparameter settings across all models during training. This standardization allowed for a fair assessment of each modelâ€™s intrinsic capabilities. As illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F5" title="Figure 5 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">5</span></a>, RESI consistently outperforms the competition across the board. The Average PQ scores, plotted with respect to training steps for three multi-dataset training settings, indicate that our model maintains a higher performance level throughout the training process.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p3.1">The baselines struggle with handling the mixed label spaces and the semantic inconsistencies in the combined training datasets. To better illustrate this large performance gap, we visualize qualitative results in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F4" title="Figure 4 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>. These results clearly show imperfect mask predictions for the baseline, indicating a significant limitation in their ability to adapt to complex segmentation scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p4">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p4.1">In addition to these observations, we also noted a strong generalization ability of our model across diverse paired category situations (results provided in supplementary materials). This is demonstrated in a qualitative comparison in handling user-specified, random category combinations. We see RESI consistently delivers accurate segmentations for paired random categorical combinations chosen across all label spaces from different datasets.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Panoptic post-processing.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.2">Models influenced by Mask2Former, such as RESI, generate a set of <math alttext="N" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px2.p1.1.m1.1d">italic_N</annotation></semantics></math> masks (or <math alttext="N*|D|" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><mrow id="S4.SS2.SSS0.Px2.p1.2.m2.1.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.cmml"><mi id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.2.cmml">N</mi><mo id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.1.cmml">âˆ—</mo><mrow id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.1.cmml"><mo id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.1.1.cmml">|</mo><mi id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">D</mi><mo id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2"><times id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.1"></times><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.2">ğ‘</ci><apply id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.2"><abs id="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.2.3.2.1"></abs><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">N*|D|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px2.p1.2.m2.1d">italic_N âˆ— | italic_D |</annotation></semantics></math> in the case of RESI), each accompanied by a probability distribution across the label space. The decoderâ€™s self-attention layers help correlate predictions; however, overlapping masks can still occur. To produce a coherent and non-overlapping segmentation output, post-processing is essential to resolve overlaps and create a unified segmentation mask that accurately represents different objects and regions. The original Mask2Former method does not adequately address the challenge of overlapping but accurate masks, especially in multi-dataset scenarios. Additionally, when smaller objects (like sunglasses on a person) overlap with larger ones, the original algorithm often fails to retain these smaller objects. To improve this, we introduce ESF-OMI, which refines how overlapping masks are handled. Surprisingly, simple modifications to the existing inference algorithm, as done in ESF-OMI, effectively resolve the issue and significantly improve segmentation accuracy. More details and pseudocode of ESF-OMI can be found in the supplementary materials.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p2.1">We next investigate the impact of different model components. We evaluate ESF-OMI on the proposed model RESI and one baseline, M2F+LE. As shown in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T4" title="Table 4 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>, the proposed inference algorithm ESF-OMI is crucial when handling semantically overlapping label spaces. For non-overlapping spaces, both methods perform similarly, with the original algorithmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> having a slight advantage. However, the post-processing algorithm alone does not account for the entire performance gap between RESI and the baselines in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1.st1" title="Table 1(a) â€£ Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1(a)</span></a>. Even with the original post-processing, RESI outperforms the baselines. Additionally, we assess per-dataset label-space performance in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T3" title="Table 3 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>, demonstrating LSQEâ€™s effectiveness in resolving semantic inconsistencies during multi-dataset training.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Instance Segmentation.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">Furthermore, we also investigate whether the baselines struggle only with the post-processing (all methods are based on Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite>) or with the mask prediction in the first place. To do so, we evaluate the models on instance segmentation which does not require any post-processing as it allows overlapping masks. Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1.st2" title="Table 1(b) â€£ Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1(b)</span></a> demonstrates that all baselines struggle already in predicting correct masks, which matches our observations from the qualitative results in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F4" title="Figure 4 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Semantic Segmentation.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px4.p1.1">Additionally, we extended our evaluation to semantic segmentation tasks to further assess the versatility of our model. Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1.st3" title="Table 1(c) â€£ Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1(c)</span></a> presents these results, where RESI outperforms all baselines. This superior performance in semantic segmentation, a task focusing on per-pixel classification without the complexity of instance delineation, offers a purer assessment of RESIâ€™s capability in discerning and categorizing diverse label spaces.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Panoptic Instance Segmentation.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px5.p1.1">In addition to panoptic, instance, and semantic segmentation, we evaluate the Panoptic Instance Quality (PIQ) on the Cityscapes Panoptic Parts benchmark, which features overlapping masks for â€œthingâ€ categories. As detailed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.SS1.SSS0.Px2" title="Benchmarking Image Segmentation. â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4.1</span></a> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS0.Px5.p1.1.1">Benchmarking Image Segmentation</em>, our aim is to combine the benefits of per-pixel classification from panoptic segmentation with the allowance for overlapping masks in instance segmentation, thereby enhancing the accuracy measurement of a model in a unified and scalable manner. Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T2" title="Table 2 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates that RESI outperforms all baselines.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluation on Per-dataset Label Spaces</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Next, we evaluate all models on the label spaces of the individual datasets for each of the three training dataset groups, <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.1">D1</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.2">D2</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.3">D3</span>. As shown in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T3" title="Table 3 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>, all four models perform similarly well across most benchmarks. This demonstrates that our adapted inference algorithm, which runs the decoder multiple times (Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S3.SS4" title="3.4 Label-space Specific Query Embeddings â€£ 3 Method â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3.4</span></a>), remains effective in this setting while clearly outperforming the baselines in the mixed-label space setting (Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T1.st1" title="Table 1(a) â€£ Table 1 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">1(a)</span></a>). Notably, even during per-dataset label space evaluation, the decoder in RESI runs multiple times if two of the training datasets share the same category. We focus on PQ in this setting to facilitate comparison with prior works that only conducted per-dataset evaluations.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">One standout result in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.T3" title="Table 3 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a> is the significantly higher PQ of RESI on the benchmarks CS and CSP. The reason is that in dataset group <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p2.1.1">D3</span>, the training images are exactly the same but the annotations are different (whole objects versus parts in CityScapesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib12" title="">12</a>]</cite>). This seems to confuse all baseline models while RESI can handle this. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#S4.F4" title="Figure 4 â€£ 4.2 Evaluation on Mixed Label Spaces â€£ 4 Experiments â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a> shows some examples. Note that this is even a practical use case where an existing annotated dataset is extended with new labels but not for all images to save cost.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T5.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.1.2.1" style="font-size:80%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T5.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_center" id="S4.T5.1.1.1.1">
<span class="ltx_p" id="S4.T5.1.1.1.1.1"><span class="ltx_text" id="S4.T5.1.1.1.1.1.1" style="font-size:80%;">Max GFlops: (</span><math alttext="10^{9}" class="ltx_Math" display="inline" id="S4.T5.1.1.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.1.1.m1.1a"><msup id="S4.T5.1.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T5.1.1.1.1.1.m1.1.1.2" mathsize="80%" xref="S4.T5.1.1.1.1.1.m1.1.1.2.cmml">10</mn><mn id="S4.T5.1.1.1.1.1.m1.1.1.3" mathsize="80%" xref="S4.T5.1.1.1.1.1.m1.1.1.3.cmml">9</mn></msup><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1">superscript</csymbol><cn id="S4.T5.1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="S4.T5.1.1.1.1.1.m1.1.1.2">10</cn><cn id="S4.T5.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T5.1.1.1.1.1.m1.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.1.m1.1c">10^{9}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.1.1.m1.1d">10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.T5.1.1.1.1.1.2" style="font-size:80%;"> ops/s)</span></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_center" id="S4.T5.1.1.3.1">
<span class="ltx_p" id="S4.T5.1.1.3.1.1"><span class="ltx_text" id="S4.T5.1.1.3.1.1.1" style="font-size:80%;">Avg Time: (s/iter/device)</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.1.2.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text" id="S4.T5.1.2.1.1.1" style="font-size:80%;">UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.1.2.1.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="S4.T5.1.2.1.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T5.1.2.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.2.1.2.1" style="font-size:80%;">272.4 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.1.2.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.2.1.3.1" style="font-size:80%;">0.1530</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.1.3.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text" id="S4.T5.1.3.2.1.1" style="font-size:80%;">LMSegÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.1.3.2.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib68" title="">68</a><span class="ltx_text" id="S4.T5.1.3.2.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.3.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.3.2.2.1" style="font-size:80%;">273.0 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.3.2.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.3.2.3.1" style="font-size:80%;">0.1655</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.1.4.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text" id="S4.T5.1.4.3.1.1" style="font-size:80%;">M2F+LEÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.1.4.3.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a><span class="ltx_text" id="S4.T5.1.4.3.1.3.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.4.3.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.4.3.2.1" style="font-size:80%;">272.5 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.4.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.4.3.3.1" style="font-size:80%;">0.1593</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.1.5.4.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.5.4.1.1" style="font-size:80%;">RESI 1 dataset</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.5.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.5.4.2.1" style="font-size:80%;">272.5 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.5.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.5.4.3.1" style="font-size:80%;">0.1593</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.1.6.5.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.6.5.1.1" style="font-size:80%;">RESI 2 datasets</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.6.5.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.6.5.2.1" style="font-size:80%;">360.1 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.6.5.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.6.5.3.1" style="font-size:80%;">0.2756</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T5.1.7.6.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.7.6.1.1" style="font-size:80%;">RESI 3 datasets</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.1.7.6.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.7.6.2.1" style="font-size:80%;">447.7 Â± 0.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.7.6.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.1.7.6.3.1" style="font-size:80%;">0.3919</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.5.1.1" style="font-size:113%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.6.2" style="font-size:113%;">Max total GFlops and pure compute time for all methods (average of 500 inferences, batch size 16, and 100 queries).</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Leveraging multiple existing datasets to train image segmentation models is a cost-effective way to scale up and is crucial for improving robustness and semantic understanding. However, multi-dataset training becomes challenging when mixing label spaces leads to inconsistent semantics. While prior methods struggle, our proposed model, RESI, directly addresses these inconsistencies with learnable label space-specific parameters and novel inference strategies. Extensive experiments show that RESI effectively handles complex label spaces, with a negligible impact on model size and a slight increase in inference time. For future work, we plan to explore more efficient methods to merge label spaces and resolve conflicts in an open-vocabulary setting.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Ali Athar, Alexander Hermans, Jonathon Luiten, Deva Ramanan, and Bastian Leibe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">Tarvis: A unified approach for target-based video segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib1.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib1.5.3" style="font-size:90%;">, pages 18738â€“18748, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Petra BevandiÄ‡, Marin OrÅ¡iÄ‡, Ivan GrubiÅ¡iÄ‡, Josip Å ariÄ‡, and SiniÅ¡a Å egviÄ‡.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Multi-domain semantic segmentation with overlapping labels.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF winter conference on applications of computer vision</span><span class="ltx_text" id="bib.bib2.5.3" style="font-size:90%;">, pages 2615â€“2624, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">End-to-end object detection with transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib3.4.2" style="font-size:90%;">European conference on computer vision</span><span class="ltx_text" id="bib.bib3.5.3" style="font-size:90%;">, pages 213â€“229. Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Qi Chang, Zhennan Yan, Mu Zhou, Di Liu, Khalid Sawalha, Meng Ye, Qilong Zhangli, Mikael Kanski, Subhi Alâ€™Aref, Leon Axel, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">Deeprecon: Joint 2d cardiac segmentation and 3d volume reconstruction via a structure-specific generative method.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib4.4.2" style="font-size:90%;">International Conference on Medical Image Computing and Computer-Assisted Intervention</span><span class="ltx_text" id="bib.bib4.5.3" style="font-size:90%;">, pages 567â€“577. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Encoder-decoder with atrous separable convolution for semantic image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib5.4.2" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span class="ltx_text" id="bib.bib5.5.3" style="font-size:90%;">, pages 801â€“818, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Ting Chen, Lala Li, Saurabh Saxena, Geoffrey Hinton, and DavidÂ J Fleet.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">A generalist framework for panoptic segmentation of images and videos.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span class="ltx_text" id="bib.bib6.5.3" style="font-size:90%;">, pages 909â€“919, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed ElÂ Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and Jingjing Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Uniter: Universal image-text representation learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib7.4.2" style="font-size:90%;">European conference on computer vision</span><span class="ltx_text" id="bib.bib7.5.3" style="font-size:90%;">, pages 104â€“120. Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Bowen Cheng, MaxwellÂ D Collins, Yukun Zhu, Ting Liu, ThomasÂ S Huang, Hartwig Adam, and Liang-Chieh Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib8.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib8.5.3" style="font-size:90%;">, pages 12475â€“12485, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
Bowen Cheng, Ishan Misra, AlexanderÂ G Schwing, Alexander Kirillov, and Rohit Girdhar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">Masked-attention mask transformer for universal image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib9.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib9.5.3" style="font-size:90%;">, pages 1290â€“1299, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Bowen Cheng, Alex Schwing, and Alexander Kirillov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">Per-pixel classification is not all you need for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.3.1" style="font-size:90%;">Advances in neural information processing systems</span><span class="ltx_text" id="bib.bib10.4.2" style="font-size:90%;">, 34:17864â€“17875, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, and Ying Shan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Yolo-world: Real-time open-vocabulary object detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib11.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib11.5.3" style="font-size:90%;">, pages 16901â€“16911, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">The cityscapes dataset for semantic urban scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib12.5.3" style="font-size:90%;">, pages 3213â€“3223, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
Daan de Geus, Panagiotis Meletis, Chenyang Lu, Xiaoxiao Wen, and Gijs Dubbelman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Part-aware panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib13.5.3" style="font-size:90%;">, pages 5485â€“5494, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Zheng Ding, Jieke Wang, and Zhuowen Tu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">Open-vocabulary panoptic segmentation with maskclip.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.3.1" style="font-size:90%;">arXiv preprint arXiv:2208.08984</span><span class="ltx_text" id="bib.bib14.4.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
Mingfei Gao, Chen Xing, JuanÂ Carlos Niebles, Junnan Li, Ran Xu, Wenhao Liu, and Caiming Xiong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">Open vocabulary object detection with pseudo bounding-box labels.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib15.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib15.5.3" style="font-size:90%;">, pages 266â€“282. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
Yunhe Gao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.2.1" style="font-size:90%;">Training like a medical resident: Context-prior learning toward universal medical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib16.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib16.5.3" style="font-size:90%;">, pages 11194â€“11204, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Ke Gong, Xiaodan Liang, Yicheng Li, Yimin Chen, Ming Yang, and Liang Lin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Instance-level human parsing via part grouping network.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib17.4.2" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span class="ltx_text" id="bib.bib17.5.3" style="font-size:90%;">, pages 770â€“785, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
Xiuye Gu, Yin Cui, Jonathan Huang, Abdullah Rashwan, Xuan Yang, Xingyi Zhou, Golnaz Ghiasi, Weicheng Kuo, Huizhong Chen, Liang-Chieh Chen, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.2.1" style="font-size:90%;">Dataseg: Taming a universal multi-dataset multi-task segmentation model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib18.4.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
Xiaoxiao He, Chaowei Tan, Bo Liu, Liping Si, Weiwu Yao, Liang Zhao, Di Liu, Qilong Zhangli, Qi Chang, Kang Li, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.2.1" style="font-size:90%;">Dealing with heterogeneous 3d mr knee images: A federated few-shot learning method with dual knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib19.4.2" style="font-size:90%;">2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</span><span class="ltx_text" id="bib.bib19.5.3" style="font-size:90%;">, pages 1â€“5. IEEE, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.2.1" style="font-size:90%;">Scaling up visual and vision-language representation learning with noisy text supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib20.4.2" style="font-size:90%;">International conference on machine learning</span><span class="ltx_text" id="bib.bib20.5.3" style="font-size:90%;">, pages 4904â€“4916. PMLR, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
Markus KÃ¤ppeler, KÃ¼rsat Petek, Niclas VÃ¶disch, Wolfram Burgard, and Abhinav Valada.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.2.1" style="font-size:90%;">Few-shot panoptic segmentation with foundation models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib21.4.2" style="font-size:90%;">2024 IEEE International Conference on Robotics and Automation (ICRA)</span><span class="ltx_text" id="bib.bib21.5.3" style="font-size:90%;">, pages 7718â€“7724. IEEE, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Lei Ke, Mingqiao Ye, Martin Danelljan, Yu-Wing Tai, Chi-Keung Tang, Fisher Yu, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.2.1" style="font-size:90%;">Segment anything in high quality.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib22.4.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
Jana Kemnitz, ChristianÂ F Baumgartner, Wolfgang Wirth, Felix Eckstein, SebastianÂ K Eder, and Ender Konukoglu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.2.1" style="font-size:90%;">Combining heterogeneously labeled datasets for training segmentation networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.4.2" style="font-size:90%;">Machine Learning in Medical Imaging: 9th International Workshop, MLMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 9</span><span class="ltx_text" id="bib.bib23.5.3" style="font-size:90%;">, pages 276â€“284. Springer, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
Zaid Khan, BG VijayÂ Kumar, Xiang Yu, Samuel Schulter, Manmohan Chandraker, and Yun Fu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.2.1" style="font-size:90%;">Single-stream multi-level alignment for vision-language pretraining.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib24.5.3" style="font-size:90%;">, pages 735â€“751. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Dongwan Kim, Yi-Hsuan Tsai, Yumin Suh, Masoud Faraki, Sparsh Garg, Manmohan Chandraker, and Bohyung Han.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.2.1" style="font-size:90%;">Learning semantic segmentation from multiple datasets with label shifts.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib25.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib25.5.3" style="font-size:90%;">, pages 20â€“36. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr DollÃ¡r.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.2.1" style="font-size:90%;">Panoptic feature pyramid networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib26.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib26.5.3" style="font-size:90%;">, pages 6399â€“6408, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
Alexander Kirillov, Kaiming He, Ross Girshick, Carsten Rother, and Piotr DollÃ¡r.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.2.1" style="font-size:90%;">Panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib27.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib27.5.3" style="font-size:90%;">, pages 9404â€“9413, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, AlexanderÂ C Berg, Wan-Yen Lo, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.2.1" style="font-size:90%;">Segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib28.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span class="ltx_text" id="bib.bib28.5.3" style="font-size:90%;">, pages 4015â€“4026, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
John Lambert, Zhuang Liu, Ozan Sener, James Hays, and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.2.1" style="font-size:90%;">Mseg: A composite dataset for multi-domain semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib29.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib29.5.3" style="font-size:90%;">, pages 2879â€“2888, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
Boyi Li, KilianÂ Q. Weinberger, Serge Belongie, Vladlen Koltun, and RenÃ© Ranftl.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.2.1" style="font-size:90%;">Language-driven Semantic Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib30.4.2" style="font-size:90%;">International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib30.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
Jie Li, Allan Raventos, Arjun Bhargava, Takaaki Tagawa, and Adrien Gaidon.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.2.1" style="font-size:90%;">Learning to fuse things and stuff.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.3.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib31.4.2" style="font-size:90%;">, abs/1812.01192, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, and Steven ChuÂ Hong Hoi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.2.1" style="font-size:90%;">Align before fuse: Vision and language representation learning with momentum distillation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib32.3.1" style="font-size:90%;">Advances in neural information processing systems</span><span class="ltx_text" id="bib.bib32.4.2" style="font-size:90%;">, 34:9694â€“9705, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
Kunchang Li, Yali Wang, Junhao Zhang, Peng Gao, Guanglu Song, Yu Liu, Hongsheng Li, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.2.1" style="font-size:90%;">Uniformer: Unifying convolution and self-attention for visual recognition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.3.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span class="ltx_text" id="bib.bib33.4.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
Yanwei Li, Xinze Chen, Zheng Zhu, Lingxi Xie, Guan Huang, Dalong Du, and Xingang Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.2.1" style="font-size:90%;">Attention-guided unified network for panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib34.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib34.5.3" style="font-size:90%;">, pages 7026â€“7035, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.1.1" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, and CÂ Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.2.1" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib35.4.2" style="font-size:90%;">Computer Visionâ€“ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13</span><span class="ltx_text" id="bib.bib35.5.3" style="font-size:90%;">, pages 740â€“755. Springer, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.1.1" style="font-size:90%;">
Di Liu, Yunhe Gao, Qilong Zhangli, Ligong Han, Xiaoxiao He, Zhaoyang Xia, Song Wen, Qi Chang, Zhennan Yan, Mu Zhou, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.2.1" style="font-size:90%;">Transfusion: multi-view divergent fusion for medical image segmentation with transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib36.4.2" style="font-size:90%;">International Conference on Medical Image Computing and Computer-Assisted Intervention</span><span class="ltx_text" id="bib.bib36.5.3" style="font-size:90%;">, pages 485â€“495. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.1.1" style="font-size:90%;">
Di Liu, Anastasis Stathopoulos, Qilong Zhangli, Yunhe Gao, and Dimitris Metaxas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.2.1" style="font-size:90%;">Lepard: Learning explicit part discovery for 3d articulated shape reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib37.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib37.4.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.1.1" style="font-size:90%;">
Jonathan Long, Evan Shelhamer, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.2.1" style="font-size:90%;">Fully convolutional networks for semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib38.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib38.5.3" style="font-size:90%;">, pages 3431â€“3440, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.1.1" style="font-size:90%;">
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.2.1" style="font-size:90%;">Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.3.1" style="font-size:90%;">Advances in neural information processing systems</span><span class="ltx_text" id="bib.bib39.4.2" style="font-size:90%;">, 32, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.1.1" style="font-size:90%;">
Rohit Mohan and Abhinav Valada.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.2.1" style="font-size:90%;">Efficientps: Efficient panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.3.1" style="font-size:90%;">International Journal of Computer Vision</span><span class="ltx_text" id="bib.bib40.4.2" style="font-size:90%;">, 129(5):1551â€“1579, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.1.1" style="font-size:90%;">
Gerhard Neuhold, Tobias Ollmann, Samuel RotaÂ Bulo, and Peter Kontschieder.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.2.1" style="font-size:90%;">The mapillary vistas dataset for semantic understanding of street scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib41.4.2" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</span><span class="ltx_text" id="bib.bib41.5.3" style="font-size:90%;">, pages 4990â€“4999, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.1.1" style="font-size:90%;">
Lorenzo Porzi, SamuelÂ Rota Bulo, Aleksander Colovic, and Peter Kontschieder.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.2.1" style="font-size:90%;">Seamless scene segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib42.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib42.5.3" style="font-size:90%;">, pages 8277â€“8286, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.1.1" style="font-size:90%;">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.2.1" style="font-size:90%;">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib43.4.2" style="font-size:90%;">International conference on machine learning</span><span class="ltx_text" id="bib.bib43.5.3" style="font-size:90%;">, pages 8748â€“8763. PMLR, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.1.1" style="font-size:90%;">
Alexandre Rame, Emilien Garreau, Hedi Ben-Younes, and Charles Ollion.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.2.1" style="font-size:90%;">Omnia faster r-cnn: Detection in the wild through dataset merging and soft distillation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib44.3.1" style="font-size:90%;">arXiv preprint arXiv:1812.02611</span><span class="ltx_text" id="bib.bib44.4.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.1.1" style="font-size:90%;">
Yongming Rao, Wenliang Zhao, Guangyi Chen, Yansong Tang, Zheng Zhu, Guan Huang, Jie Zhou, and Jiwen Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.2.1" style="font-size:90%;">Denseclip: Language-guided dense prediction with context-aware prompting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib45.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib45.5.3" style="font-size:90%;">, pages 18082â€“18091, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.1.1" style="font-size:90%;">
Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman RÃ¤dle, Chloe Rolland, Laura Gustafson, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.2.1" style="font-size:90%;">Sam 2: Segment anything in images and videos.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib46.3.1" style="font-size:90%;">arXiv preprint arXiv:2408.00714</span><span class="ltx_text" id="bib.bib46.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.1.1" style="font-size:90%;">
LohrasbÂ Ross Sayadi, UsamaÂ S Hamdan, Qilong Zhangli, and RajÂ M Vyas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.2.1" style="font-size:90%;">Harnessing the power of artificial intelligence to teach cleft lip surgery.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib47.3.1" style="font-size:90%;">Plastic and Reconstructive Surgeryâ€“Global Open</span><span class="ltx_text" id="bib.bib47.4.2" style="font-size:90%;">, 10(7):e4451, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.1.1" style="font-size:90%;">
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.2.1" style="font-size:90%;">Videobert: A joint model for video and language representation learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib48.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span class="ltx_text" id="bib.bib48.5.3" style="font-size:90%;">, pages 7464â€“7473, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.1.1" style="font-size:90%;">
Shuyang Sun, Weijun Wang, Andrew Howard, Qihang Yu, Philip Torr, and Liang-Chieh Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.2.1" style="font-size:90%;">Remax: Relaxing for better training on efficient panoptic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib49.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib49.4.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.1.1" style="font-size:90%;">
A Vaswani.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.2.1" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib50.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib50.4.2" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.1.1" style="font-size:90%;">
Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.2.1" style="font-size:90%;">Max-deeplab: End-to-end panoptic segmentation with mask transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib51.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib51.5.3" style="font-size:90%;">, pages 5463â€“5474, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.1.1" style="font-size:90%;">
Song Wen, Hao Wang, Di Liu, Qilong Zhangli, and Dimitris Metaxas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.2.1" style="font-size:90%;">Second-order graph odes for multi-agent trajectory forecasting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib52.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</span><span class="ltx_text" id="bib.bib52.5.3" style="font-size:90%;">, pages 5101â€“5110, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.1.1" style="font-size:90%;">
Zhaoyang Xia, Yuxiao Chen, Qilong Zhangli, Matt Huenerfauth, Carol Neidle, and Dimitris Metaxas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.2.1" style="font-size:90%;">Sign language video anonymization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib53.4.2" style="font-size:90%;">Proceedings of the LREC2022 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources, Marseille, France, 25 June 2022</span><span class="ltx_text" id="bib.bib53.5.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.1.1" style="font-size:90%;">
Yuwen Xiong, Renjie Liao, Hengshuang Zhao, Rui Hu, Min Bai, Ersin Yumer, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.2.1" style="font-size:90%;">Upsnet: A unified panoptic segmentation network.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib54.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib54.5.3" style="font-size:90%;">, pages 8818â€“8826, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.1.1" style="font-size:90%;">
Jiarui Xu, Sifei Liu, Arash Vahdat, Wonmin Byeon, Xiaolong Wang, and Shalini DeÂ Mello.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.2.1" style="font-size:90%;">Open-vocabulary panoptic segmentation with text-to-image diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib55.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib55.5.3" style="font-size:90%;">, pages 2955â€“2966, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.1.1" style="font-size:90%;">
Mengde Xu, Zheng Zhang, Fangyun Wei, Yutong Lin, Yue Cao, Han Hu, and Xiang Bai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.2.1" style="font-size:90%;">A simple baseline for open-vocabulary semantic segmentation with pre-trained vision-language model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib56.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib56.5.3" style="font-size:90%;">, pages 736â€“753. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.1.1" style="font-size:90%;">
Yongqiang Yao, Yan Wang, Yu Guo, Jiaojiao Lin, Hongwei Qin, and Junjie Yan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.2.1" style="font-size:90%;">Cross-dataset training for class increasing object detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib57.3.1" style="font-size:90%;">arXiv preprint arXiv:2001.04621</span><span class="ltx_text" id="bib.bib57.4.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.1.1" style="font-size:90%;">
Fisher Yu and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.2.1" style="font-size:90%;">Multi-Scale Context Aggregation by Dilated Convolutions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib58.4.2" style="font-size:90%;">The 4th International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib58.5.3" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.1.1" style="font-size:90%;">
Alireza Zareian, KevinÂ Dela Rosa, DerekÂ Hao Hu, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.2.1" style="font-size:90%;">Open-vocabulary object detection using captions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib59.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib59.5.3" style="font-size:90%;">, pages 14393â€“14402, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.1.1" style="font-size:90%;">
Hao Zhang, Feng Li, Xueyan Zou, Shilong Liu, Chunyuan Li, Jianwei Yang, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.2.1" style="font-size:90%;">A simple framework for open-vocabulary segmentation and detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib60.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span class="ltx_text" id="bib.bib60.5.3" style="font-size:90%;">, pages 1020â€“1031, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.1.1" style="font-size:90%;">
Qilong Zhangli, Jindong Jiang, Di Liu, Licheng Yu, Xiaoliang Dai, Ankit Ramchandani, Guan Pang, DimitrisÂ N Metaxas, and Praveen Krishnan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.2.1" style="font-size:90%;">Layout-agnostic scene text image synthesis with diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib61.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib61.5.3" style="font-size:90%;">, pages 7496â€“7506, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.1.1" style="font-size:90%;">
Qilong Zhangli, Jingru Yi, Di Liu, Xiaoxiao He, Zhaoyang Xia, Qi Chang, Ligong Han, Yunhe Gao, Song Wen, Haiming Tang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.2.1" style="font-size:90%;">Region proposal rectification towards robust instance segmentation of biological images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib62.4.2" style="font-size:90%;">International Conference on Medical Image Computing and Computer-Assisted Intervention</span><span class="ltx_text" id="bib.bib62.5.3" style="font-size:90%;">, pages 129â€“139. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.1.1" style="font-size:90%;">
Bowen Zhao, Chen Chen, Wanpeng Xiao, Xi Xiao, Qi Ju, and Shutao Xia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.2.1" style="font-size:90%;">Towards a category-extended object detector without relabeling or conflicts.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib63.3.1" style="font-size:90%;">arXiv preprint arXiv:2012.14115</span><span class="ltx_text" id="bib.bib63.4.2" style="font-size:90%;">, 2, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.1.1" style="font-size:90%;">
Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.2.1" style="font-size:90%;">Pyramid scene parsing network.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib64.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib64.5.3" style="font-size:90%;">, pages 2881â€“2890, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.1.1" style="font-size:90%;">
Xiangyun Zhao, Samuel Schulter, Gaurav Sharma, Yi-Hsuan Tsai, Manmohan Chandraker, and Ying Wu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.2.1" style="font-size:90%;">Object detection with a unified label space from multiple datasets.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib65.4.2" style="font-size:90%;">Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XIV 16</span><span class="ltx_text" id="bib.bib65.5.3" style="font-size:90%;">, pages 178â€“193. Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.1.1" style="font-size:90%;">
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.2.1" style="font-size:90%;">Scene parsing through ade20k dataset.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib66.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib66.5.3" style="font-size:90%;">, pages 633â€“641, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.1.1" style="font-size:90%;">
Chong Zhou, ChenÂ Change Loy, and Bo Dai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.2.1" style="font-size:90%;">Extract free dense labels from clip.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib67.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib67.5.3" style="font-size:90%;">, pages 696â€“712. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.1.1" style="font-size:90%;">
Qiang Zhou, Yuang Liu, Chaohui Yu, Jingliang Li, Zhibin Wang, and Fan Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.2.1" style="font-size:90%;">LMSeg: Language-guided multi-dataset segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib68.4.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib68.5.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.1.1" style="font-size:90%;">
Xingyi Zhou, Vladlen Koltun, and Philipp KrÃ¤henbÃ¼hl.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.2.1" style="font-size:90%;">Simple multi-dataset detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib69.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib69.5.3" style="font-size:90%;">, pages 7571â€“7580, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.1.1" style="font-size:90%;">
Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.2.1" style="font-size:90%;">Generalized decoding for pixel, image, and language.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib70.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib70.5.3" style="font-size:90%;">, pages 15116â€“15127, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\thetitle</span>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.2"><span class="ltx_text" id="p1.2.1" style="font-size:144%;">Supplementary Material 
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1"><span class="ltx_text" id="p3.1.1" style="font-size:144%;">In this supplementary material, we provide additional details and results that were not included in the main paper due to space constraints. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1" title="Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">A</span></a>, we give pseudo code and details of our post-processing strategy for panoptic segmentation. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A2" title="Appendix B Mixed-label Space Benchmarks â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">B</span></a>, we provide details of how we construct the testing benchmarks. In Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3" title="Appendix C Additional Qualitative Comparison â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">C</span></a>, we give more qualitative comparisons. Finally, in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A4" title="Appendix D Model Training Details â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">D</span></a>, we introduce the details of our model training.</span></p>
</div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Panoptic Segmentation Post-processing</h2>
<figure class="ltx_figure" id="A1.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="314" id="A1.F6.g1" src="x3.png" width="951"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F6.7.1.1" style="font-size:63%;">Figure 6</span>: </span><span class="ltx_text" id="A1.F6.8.2" style="font-size:63%;">Pseudo code of the original post-processing algorithm fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> and our proposed algorithm, ESF-OMI, which aims to resolve overlapping mask predictions for panoptic segmentation.</span></figcaption>
</figure>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.12"><span class="ltx_text" id="A1.p1.12.1" style="font-size:144%;">Both algorithms are summarized with pseudo code in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1.F6" style="font-size:144%;" title="Figure 6 â€£ Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="A1.p1.12.2" style="font-size:144%;">, and both receive as input mask predictions </span><math alttext="M_{pred}" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><msub id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" mathsize="144%" xref="A1.p1.1.m1.1.1.2.cmml">M</mi><mrow id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3.cmml"><mi id="A1.p1.1.m1.1.1.3.2" mathsize="144%" xref="A1.p1.1.m1.1.1.3.2.cmml">p</mi><mo id="A1.p1.1.m1.1.1.3.1" xref="A1.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.1.m1.1.1.3.3" mathsize="144%" xref="A1.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="A1.p1.1.m1.1.1.3.1a" xref="A1.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.1.m1.1.1.3.4" mathsize="144%" xref="A1.p1.1.m1.1.1.3.4.cmml">e</mi><mo id="A1.p1.1.m1.1.1.3.1b" xref="A1.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.1.m1.1.1.3.5" mathsize="144%" xref="A1.p1.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">ğ‘€</ci><apply id="A1.p1.1.m1.1.1.3.cmml" xref="A1.p1.1.m1.1.1.3"><times id="A1.p1.1.m1.1.1.3.1.cmml" xref="A1.p1.1.m1.1.1.3.1"></times><ci id="A1.p1.1.m1.1.1.3.2.cmml" xref="A1.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="A1.p1.1.m1.1.1.3.3.cmml" xref="A1.p1.1.m1.1.1.3.3">ğ‘Ÿ</ci><ci id="A1.p1.1.m1.1.1.3.4.cmml" xref="A1.p1.1.m1.1.1.3.4">ğ‘’</ci><ci id="A1.p1.1.m1.1.1.3.5.cmml" xref="A1.p1.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">M_{pred}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">italic_M start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.3" style="font-size:144%;"> with class probabilities </span><math alttext="M_{cls}" class="ltx_Math" display="inline" id="A1.p1.2.m2.1"><semantics id="A1.p1.2.m2.1a"><msub id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mi id="A1.p1.2.m2.1.1.2" mathsize="144%" xref="A1.p1.2.m2.1.1.2.cmml">M</mi><mrow id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3.cmml"><mi id="A1.p1.2.m2.1.1.3.2" mathsize="144%" xref="A1.p1.2.m2.1.1.3.2.cmml">c</mi><mo id="A1.p1.2.m2.1.1.3.1" xref="A1.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.2.m2.1.1.3.3" mathsize="144%" xref="A1.p1.2.m2.1.1.3.3.cmml">l</mi><mo id="A1.p1.2.m2.1.1.3.1a" xref="A1.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.2.m2.1.1.3.4" mathsize="144%" xref="A1.p1.2.m2.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1">subscript</csymbol><ci id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">ğ‘€</ci><apply id="A1.p1.2.m2.1.1.3.cmml" xref="A1.p1.2.m2.1.1.3"><times id="A1.p1.2.m2.1.1.3.1.cmml" xref="A1.p1.2.m2.1.1.3.1"></times><ci id="A1.p1.2.m2.1.1.3.2.cmml" xref="A1.p1.2.m2.1.1.3.2">ğ‘</ci><ci id="A1.p1.2.m2.1.1.3.3.cmml" xref="A1.p1.2.m2.1.1.3.3">ğ‘™</ci><ci id="A1.p1.2.m2.1.1.3.4.cmml" xref="A1.p1.2.m2.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">M_{cls}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.1d">italic_M start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.4" style="font-size:144%;"> and output the panoptic segmentation map </span><math alttext="P_{seg}" class="ltx_Math" display="inline" id="A1.p1.3.m3.1"><semantics id="A1.p1.3.m3.1a"><msub id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mi id="A1.p1.3.m3.1.1.2" mathsize="144%" xref="A1.p1.3.m3.1.1.2.cmml">P</mi><mrow id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml"><mi id="A1.p1.3.m3.1.1.3.2" mathsize="144%" xref="A1.p1.3.m3.1.1.3.2.cmml">s</mi><mo id="A1.p1.3.m3.1.1.3.1" xref="A1.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.3.m3.1.1.3.3" mathsize="144%" xref="A1.p1.3.m3.1.1.3.3.cmml">e</mi><mo id="A1.p1.3.m3.1.1.3.1a" xref="A1.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.3.m3.1.1.3.4" mathsize="144%" xref="A1.p1.3.m3.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1">subscript</csymbol><ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">ğ‘ƒ</ci><apply id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3"><times id="A1.p1.3.m3.1.1.3.1.cmml" xref="A1.p1.3.m3.1.1.3.1"></times><ci id="A1.p1.3.m3.1.1.3.2.cmml" xref="A1.p1.3.m3.1.1.3.2">ğ‘ </ci><ci id="A1.p1.3.m3.1.1.3.3.cmml" xref="A1.p1.3.m3.1.1.3.3">ğ‘’</ci><ci id="A1.p1.3.m3.1.1.3.4.cmml" xref="A1.p1.3.m3.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">P_{seg}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.1d">italic_P start_POSTSUBSCRIPT italic_s italic_e italic_g end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.5" style="font-size:144%;">. The original algorithm first computes the most likely class (</span><math alttext="L" class="ltx_Math" display="inline" id="A1.p1.4.m4.1"><semantics id="A1.p1.4.m4.1a"><mi id="A1.p1.4.m4.1.1" mathsize="144%" xref="A1.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><ci id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.1d">italic_L</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.6" style="font-size:144%;">) and confidence (</span><math alttext="S" class="ltx_Math" display="inline" id="A1.p1.5.m5.1"><semantics id="A1.p1.5.m5.1a"><mi id="A1.p1.5.m5.1.1" mathsize="144%" xref="A1.p1.5.m5.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><ci id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">S</annotation><annotation encoding="application/x-llamapun" id="A1.p1.5.m5.1d">italic_S</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.7" style="font-size:144%;">) for each mask, and filters out low-scoring ones or those that are assigned the background class. The panoptic map </span><math alttext="P_{seg}" class="ltx_Math" display="inline" id="A1.p1.6.m6.1"><semantics id="A1.p1.6.m6.1a"><msub id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml"><mi id="A1.p1.6.m6.1.1.2" mathsize="144%" xref="A1.p1.6.m6.1.1.2.cmml">P</mi><mrow id="A1.p1.6.m6.1.1.3" xref="A1.p1.6.m6.1.1.3.cmml"><mi id="A1.p1.6.m6.1.1.3.2" mathsize="144%" xref="A1.p1.6.m6.1.1.3.2.cmml">s</mi><mo id="A1.p1.6.m6.1.1.3.1" xref="A1.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.6.m6.1.1.3.3" mathsize="144%" xref="A1.p1.6.m6.1.1.3.3.cmml">e</mi><mo id="A1.p1.6.m6.1.1.3.1a" xref="A1.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.6.m6.1.1.3.4" mathsize="144%" xref="A1.p1.6.m6.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><apply id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A1.p1.6.m6.1.1.1.cmml" xref="A1.p1.6.m6.1.1">subscript</csymbol><ci id="A1.p1.6.m6.1.1.2.cmml" xref="A1.p1.6.m6.1.1.2">ğ‘ƒ</ci><apply id="A1.p1.6.m6.1.1.3.cmml" xref="A1.p1.6.m6.1.1.3"><times id="A1.p1.6.m6.1.1.3.1.cmml" xref="A1.p1.6.m6.1.1.3.1"></times><ci id="A1.p1.6.m6.1.1.3.2.cmml" xref="A1.p1.6.m6.1.1.3.2">ğ‘ </ci><ci id="A1.p1.6.m6.1.1.3.3.cmml" xref="A1.p1.6.m6.1.1.3.3">ğ‘’</ci><ci id="A1.p1.6.m6.1.1.3.4.cmml" xref="A1.p1.6.m6.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">P_{seg}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.6.m6.1d">italic_P start_POSTSUBSCRIPT italic_s italic_e italic_g end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.8" style="font-size:144%;"> is then iteratively filled, starting with the most confident mask. A new mask is only added if it occupies an appropriate area of the image and is not too small (â€œif vavlid area, overlapâ€). The proposed method ESF-OMI makes two key adjustments, which are highlighted in orange and purple in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1.F6" style="font-size:144%;" title="Figure 6 â€£ Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="A1.p1.12.9" style="font-size:144%;">.
(1) Masks are filtered in a different way. The background class is excluded from the filtering step and all masks with a score above a threshold survive the filtering. Note there can be class confidences of 0.3 for one class, but 0.7 for background â€“ this mask is filtered in the original algorithm but kept in ESF-OMI if the threshold is below 0.3. (2) The criteria for placing masks on the pantopic segmentation map </span><math alttext="P_{seg}" class="ltx_Math" display="inline" id="A1.p1.7.m7.1"><semantics id="A1.p1.7.m7.1a"><msub id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml"><mi id="A1.p1.7.m7.1.1.2" mathsize="144%" xref="A1.p1.7.m7.1.1.2.cmml">P</mi><mrow id="A1.p1.7.m7.1.1.3" xref="A1.p1.7.m7.1.1.3.cmml"><mi id="A1.p1.7.m7.1.1.3.2" mathsize="144%" xref="A1.p1.7.m7.1.1.3.2.cmml">s</mi><mo id="A1.p1.7.m7.1.1.3.1" xref="A1.p1.7.m7.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.7.m7.1.1.3.3" mathsize="144%" xref="A1.p1.7.m7.1.1.3.3.cmml">e</mi><mo id="A1.p1.7.m7.1.1.3.1a" xref="A1.p1.7.m7.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.7.m7.1.1.3.4" mathsize="144%" xref="A1.p1.7.m7.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><apply id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A1.p1.7.m7.1.1.1.cmml" xref="A1.p1.7.m7.1.1">subscript</csymbol><ci id="A1.p1.7.m7.1.1.2.cmml" xref="A1.p1.7.m7.1.1.2">ğ‘ƒ</ci><apply id="A1.p1.7.m7.1.1.3.cmml" xref="A1.p1.7.m7.1.1.3"><times id="A1.p1.7.m7.1.1.3.1.cmml" xref="A1.p1.7.m7.1.1.3.1"></times><ci id="A1.p1.7.m7.1.1.3.2.cmml" xref="A1.p1.7.m7.1.1.3.2">ğ‘ </ci><ci id="A1.p1.7.m7.1.1.3.3.cmml" xref="A1.p1.7.m7.1.1.3.3">ğ‘’</ci><ci id="A1.p1.7.m7.1.1.3.4.cmml" xref="A1.p1.7.m7.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">P_{seg}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.7.m7.1d">italic_P start_POSTSUBSCRIPT italic_s italic_e italic_g end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.10" style="font-size:144%;"> are different. First, a non-maxima-suppression (NMS) step based on masks removes near-duplicates, which would otherwise lead to noisy outputs, see Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1.F7" style="font-size:144%;" title="Figure 7 â€£ Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">7</span></a><span class="ltx_text" id="A1.p1.12.11" style="font-size:144%;">. Second, when placing masks on the segmentation map the criterion â€œvalid selective overlapâ€ allows smaller masks </span><math alttext="M_{S}" class="ltx_Math" display="inline" id="A1.p1.8.m8.1"><semantics id="A1.p1.8.m8.1a"><msub id="A1.p1.8.m8.1.1" xref="A1.p1.8.m8.1.1.cmml"><mi id="A1.p1.8.m8.1.1.2" mathsize="144%" xref="A1.p1.8.m8.1.1.2.cmml">M</mi><mi id="A1.p1.8.m8.1.1.3" mathsize="144%" xref="A1.p1.8.m8.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p1.8.m8.1b"><apply id="A1.p1.8.m8.1.1.cmml" xref="A1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A1.p1.8.m8.1.1.1.cmml" xref="A1.p1.8.m8.1.1">subscript</csymbol><ci id="A1.p1.8.m8.1.1.2.cmml" xref="A1.p1.8.m8.1.1.2">ğ‘€</ci><ci id="A1.p1.8.m8.1.1.3.cmml" xref="A1.p1.8.m8.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.8.m8.1c">M_{S}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.8.m8.1d">italic_M start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.12" style="font-size:144%;"> (with a lower score) to be placed on top of an existing mask </span><math alttext="M_{B}" class="ltx_Math" display="inline" id="A1.p1.9.m9.1"><semantics id="A1.p1.9.m9.1a"><msub id="A1.p1.9.m9.1.1" xref="A1.p1.9.m9.1.1.cmml"><mi id="A1.p1.9.m9.1.1.2" mathsize="144%" xref="A1.p1.9.m9.1.1.2.cmml">M</mi><mi id="A1.p1.9.m9.1.1.3" mathsize="144%" xref="A1.p1.9.m9.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p1.9.m9.1b"><apply id="A1.p1.9.m9.1.1.cmml" xref="A1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.p1.9.m9.1.1.1.cmml" xref="A1.p1.9.m9.1.1">subscript</csymbol><ci id="A1.p1.9.m9.1.1.2.cmml" xref="A1.p1.9.m9.1.1.2">ğ‘€</ci><ci id="A1.p1.9.m9.1.1.3.cmml" xref="A1.p1.9.m9.1.1.3">ğµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.9.m9.1c">M_{B}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.9.m9.1d">italic_M start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.13" style="font-size:144%;"> in </span><math alttext="P_{seg}" class="ltx_Math" display="inline" id="A1.p1.10.m10.1"><semantics id="A1.p1.10.m10.1a"><msub id="A1.p1.10.m10.1.1" xref="A1.p1.10.m10.1.1.cmml"><mi id="A1.p1.10.m10.1.1.2" mathsize="144%" xref="A1.p1.10.m10.1.1.2.cmml">P</mi><mrow id="A1.p1.10.m10.1.1.3" xref="A1.p1.10.m10.1.1.3.cmml"><mi id="A1.p1.10.m10.1.1.3.2" mathsize="144%" xref="A1.p1.10.m10.1.1.3.2.cmml">s</mi><mo id="A1.p1.10.m10.1.1.3.1" xref="A1.p1.10.m10.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.10.m10.1.1.3.3" mathsize="144%" xref="A1.p1.10.m10.1.1.3.3.cmml">e</mi><mo id="A1.p1.10.m10.1.1.3.1a" xref="A1.p1.10.m10.1.1.3.1.cmml">â¢</mo><mi id="A1.p1.10.m10.1.1.3.4" mathsize="144%" xref="A1.p1.10.m10.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.10.m10.1b"><apply id="A1.p1.10.m10.1.1.cmml" xref="A1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="A1.p1.10.m10.1.1.1.cmml" xref="A1.p1.10.m10.1.1">subscript</csymbol><ci id="A1.p1.10.m10.1.1.2.cmml" xref="A1.p1.10.m10.1.1.2">ğ‘ƒ</ci><apply id="A1.p1.10.m10.1.1.3.cmml" xref="A1.p1.10.m10.1.1.3"><times id="A1.p1.10.m10.1.1.3.1.cmml" xref="A1.p1.10.m10.1.1.3.1"></times><ci id="A1.p1.10.m10.1.1.3.2.cmml" xref="A1.p1.10.m10.1.1.3.2">ğ‘ </ci><ci id="A1.p1.10.m10.1.1.3.3.cmml" xref="A1.p1.10.m10.1.1.3.3">ğ‘’</ci><ci id="A1.p1.10.m10.1.1.3.4.cmml" xref="A1.p1.10.m10.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.10.m10.1c">P_{seg}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.10.m10.1d">italic_P start_POSTSUBSCRIPT italic_s italic_e italic_g end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.14" style="font-size:144%;"> if </span><math alttext="M_{S}" class="ltx_Math" display="inline" id="A1.p1.11.m11.1"><semantics id="A1.p1.11.m11.1a"><msub id="A1.p1.11.m11.1.1" xref="A1.p1.11.m11.1.1.cmml"><mi id="A1.p1.11.m11.1.1.2" mathsize="144%" xref="A1.p1.11.m11.1.1.2.cmml">M</mi><mi id="A1.p1.11.m11.1.1.3" mathsize="144%" xref="A1.p1.11.m11.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p1.11.m11.1b"><apply id="A1.p1.11.m11.1.1.cmml" xref="A1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A1.p1.11.m11.1.1.1.cmml" xref="A1.p1.11.m11.1.1">subscript</csymbol><ci id="A1.p1.11.m11.1.1.2.cmml" xref="A1.p1.11.m11.1.1.2">ğ‘€</ci><ci id="A1.p1.11.m11.1.1.3.cmml" xref="A1.p1.11.m11.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.11.m11.1c">M_{S}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.11.m11.1d">italic_M start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.15" style="font-size:144%;"> is fully contained in </span><math alttext="M_{B}" class="ltx_Math" display="inline" id="A1.p1.12.m12.1"><semantics id="A1.p1.12.m12.1a"><msub id="A1.p1.12.m12.1.1" xref="A1.p1.12.m12.1.1.cmml"><mi id="A1.p1.12.m12.1.1.2" mathsize="144%" xref="A1.p1.12.m12.1.1.2.cmml">M</mi><mi id="A1.p1.12.m12.1.1.3" mathsize="144%" xref="A1.p1.12.m12.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p1.12.m12.1b"><apply id="A1.p1.12.m12.1.1.cmml" xref="A1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="A1.p1.12.m12.1.1.1.cmml" xref="A1.p1.12.m12.1.1">subscript</csymbol><ci id="A1.p1.12.m12.1.1.2.cmml" xref="A1.p1.12.m12.1.1.2">ğ‘€</ci><ci id="A1.p1.12.m12.1.1.3.cmml" xref="A1.p1.12.m12.1.1.3">ğµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.12.m12.1c">M_{B}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.12.m12.1d">italic_M start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.p1.12.16" style="font-size:144%;"> (with some slack). This ensures that smaller objects are not omitted in the final segmentation, like sunglasses on a person as illustrated in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1.F8" style="font-size:144%;" title="Figure 8 â€£ Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text" id="A1.p1.12.17" style="font-size:144%;">.</span></p>
</div>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="156" id="A1.F7.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F7.4.1.1" style="font-size:63%;">Figure 7</span>: </span><span class="ltx_text" id="A1.F7.5.2" style="font-size:63%;">An illustration of the mask-NMS used in the proposed post-processing algorithm, ESF-OMI. The figure shows how near-duplicate masks are removed in panoptic segmentation.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="91" id="A1.F8.g1" src="extracted/5856734/figures/different_Inference_Strategy.png" width="299"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F8.7.1.1" style="font-size:63%;">Figure 8</span>: </span><span class="ltx_text" id="A1.F8.8.2" style="font-size:63%;">Example output of the original panoptic post-processing algorithm from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib10" title="">10</a>]</cite> (left) versus the output of the proposed post-processing ESF-OMI (right). For panoptic segmentation task, our proposed algorithm better handles overlapping mask predictions like the sunglasses in the figure (red circle), which are suppressed by the original algorithm.
</span></figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Mixed-label Space Benchmarks</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.4"><span class="ltx_text" id="A2.p1.4.1" style="font-size:144%;">As stated in the main paper, we build multiple evaluation-only mixed-label space benchmarks to properly evaluate the ability of multi-dataset models to handle any combination of label spaces </span><math alttext="A" class="ltx_Math" display="inline" id="A2.p1.1.m1.1"><semantics id="A2.p1.1.m1.1a"><mi id="A2.p1.1.m1.1.1" mathsize="144%" xref="A2.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><ci id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.1d">italic_A</annotation></semantics></math><span class="ltx_text" id="A2.p1.4.2" style="font-size:144%;"> and </span><math alttext="B" class="ltx_Math" display="inline" id="A2.p1.2.m2.1"><semantics id="A2.p1.2.m2.1a"><mi id="A2.p1.2.m2.1.1" mathsize="144%" xref="A2.p1.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><ci id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="A2.p1.2.m2.1d">italic_B</annotation></semantics></math><span class="ltx_text" id="A2.p1.4.3" style="font-size:144%;"> of the individual datasets. Label space </span><math alttext="C" class="ltx_Math" display="inline" id="A2.p1.3.m3.1"><semantics id="A2.p1.3.m3.1a"><mi id="A2.p1.3.m3.1.1" mathsize="144%" xref="A2.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.1b"><ci id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="A2.p1.3.m3.1d">italic_C</annotation></semantics></math><span class="ltx_text" id="A2.p1.4.4" style="font-size:144%;"> must contain two partitions that include categories exclusively from either training dataset, i.e., </span><math alttext="|C\cap(A\setminus B)|&gt;\emptyset\land|C\cap(B\setminus A)|&gt;\emptyset" class="ltx_Math" display="inline" id="A2.p1.4.m4.2"><semantics id="A2.p1.4.m4.2a"><mrow id="A2.p1.4.m4.2.2" xref="A2.p1.4.m4.2.2.cmml"><mrow id="A2.p1.4.m4.1.1.1.1" xref="A2.p1.4.m4.1.1.1.2.cmml"><mo id="A2.p1.4.m4.1.1.1.1.2" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.1.1.1.2.1.cmml">|</mo><mrow id="A2.p1.4.m4.1.1.1.1.1" xref="A2.p1.4.m4.1.1.1.1.1.cmml"><mi id="A2.p1.4.m4.1.1.1.1.1.3" mathsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.3.cmml">C</mi><mo id="A2.p1.4.m4.1.1.1.1.1.2" mathsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.2.cmml">âˆ©</mo><mrow id="A2.p1.4.m4.1.1.1.1.1.1.1" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.cmml"><mo id="A2.p1.4.m4.1.1.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A2.p1.4.m4.1.1.1.1.1.1.1.1" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.cmml"><mi id="A2.p1.4.m4.1.1.1.1.1.1.1.1.2" mathsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.2.cmml">A</mi><mo id="A2.p1.4.m4.1.1.1.1.1.1.1.1.1" mathsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml">âˆ–</mo><mi id="A2.p1.4.m4.1.1.1.1.1.1.1.1.3" mathsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.3.cmml">B</mi></mrow><mo id="A2.p1.4.m4.1.1.1.1.1.1.1.3" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A2.p1.4.m4.1.1.1.1.3" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.1.1.1.2.1.cmml">|</mo></mrow><mo id="A2.p1.4.m4.2.2.4" mathsize="144%" xref="A2.p1.4.m4.2.2.4.cmml">&gt;</mo><mrow id="A2.p1.4.m4.2.2.2" xref="A2.p1.4.m4.2.2.2.cmml"><mi id="A2.p1.4.m4.2.2.2.3" mathsize="144%" mathvariant="normal" xref="A2.p1.4.m4.2.2.2.3.cmml">âˆ…</mi><mo id="A2.p1.4.m4.2.2.2.2" mathsize="144%" xref="A2.p1.4.m4.2.2.2.2.cmml">âˆ§</mo><mrow id="A2.p1.4.m4.2.2.2.1.1" xref="A2.p1.4.m4.2.2.2.1.2.cmml"><mo id="A2.p1.4.m4.2.2.2.1.1.2" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.2.2.2.1.2.1.cmml">|</mo><mrow id="A2.p1.4.m4.2.2.2.1.1.1" xref="A2.p1.4.m4.2.2.2.1.1.1.cmml"><mi id="A2.p1.4.m4.2.2.2.1.1.1.3" mathsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.3.cmml">C</mi><mo id="A2.p1.4.m4.2.2.2.1.1.1.2" mathsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.2.cmml">âˆ©</mo><mrow id="A2.p1.4.m4.2.2.2.1.1.1.1.1" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.cmml"><mo id="A2.p1.4.m4.2.2.2.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.cmml"><mi id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.2" mathsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.2.cmml">B</mi><mo id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.1" mathsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.1.cmml">âˆ–</mo><mi id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.3" mathsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.3.cmml">A</mi></mrow><mo id="A2.p1.4.m4.2.2.2.1.1.1.1.1.3" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A2.p1.4.m4.2.2.2.1.1.3" maxsize="144%" minsize="144%" xref="A2.p1.4.m4.2.2.2.1.2.1.cmml">|</mo></mrow></mrow><mo id="A2.p1.4.m4.2.2.5" mathsize="144%" xref="A2.p1.4.m4.2.2.5.cmml">&gt;</mo><mi id="A2.p1.4.m4.2.2.6" mathsize="144%" mathvariant="normal" xref="A2.p1.4.m4.2.2.6.cmml">âˆ…</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.4.m4.2b"><apply id="A2.p1.4.m4.2.2.cmml" xref="A2.p1.4.m4.2.2"><and id="A2.p1.4.m4.2.2a.cmml" xref="A2.p1.4.m4.2.2"></and><apply id="A2.p1.4.m4.2.2b.cmml" xref="A2.p1.4.m4.2.2"><gt id="A2.p1.4.m4.2.2.4.cmml" xref="A2.p1.4.m4.2.2.4"></gt><apply id="A2.p1.4.m4.1.1.1.2.cmml" xref="A2.p1.4.m4.1.1.1.1"><abs id="A2.p1.4.m4.1.1.1.2.1.cmml" xref="A2.p1.4.m4.1.1.1.1.2"></abs><apply id="A2.p1.4.m4.1.1.1.1.1.cmml" xref="A2.p1.4.m4.1.1.1.1.1"><intersect id="A2.p1.4.m4.1.1.1.1.1.2.cmml" xref="A2.p1.4.m4.1.1.1.1.1.2"></intersect><ci id="A2.p1.4.m4.1.1.1.1.1.3.cmml" xref="A2.p1.4.m4.1.1.1.1.1.3">ğ¶</ci><apply id="A2.p1.4.m4.1.1.1.1.1.1.1.1.cmml" xref="A2.p1.4.m4.1.1.1.1.1.1.1"><setdiff id="A2.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.1"></setdiff><ci id="A2.p1.4.m4.1.1.1.1.1.1.1.1.2.cmml" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.2">ğ´</ci><ci id="A2.p1.4.m4.1.1.1.1.1.1.1.1.3.cmml" xref="A2.p1.4.m4.1.1.1.1.1.1.1.1.3">ğµ</ci></apply></apply></apply><apply id="A2.p1.4.m4.2.2.2.cmml" xref="A2.p1.4.m4.2.2.2"><and id="A2.p1.4.m4.2.2.2.2.cmml" xref="A2.p1.4.m4.2.2.2.2"></and><emptyset id="A2.p1.4.m4.2.2.2.3.cmml" xref="A2.p1.4.m4.2.2.2.3"></emptyset><apply id="A2.p1.4.m4.2.2.2.1.2.cmml" xref="A2.p1.4.m4.2.2.2.1.1"><abs id="A2.p1.4.m4.2.2.2.1.2.1.cmml" xref="A2.p1.4.m4.2.2.2.1.1.2"></abs><apply id="A2.p1.4.m4.2.2.2.1.1.1.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1"><intersect id="A2.p1.4.m4.2.2.2.1.1.1.2.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.2"></intersect><ci id="A2.p1.4.m4.2.2.2.1.1.1.3.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.3">ğ¶</ci><apply id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1"><setdiff id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.1.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.1"></setdiff><ci id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.2.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.2">ğµ</ci><ci id="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.3.cmml" xref="A2.p1.4.m4.2.2.2.1.1.1.1.1.1.3">ğ´</ci></apply></apply></apply></apply></apply><apply id="A2.p1.4.m4.2.2c.cmml" xref="A2.p1.4.m4.2.2"><gt id="A2.p1.4.m4.2.2.5.cmml" xref="A2.p1.4.m4.2.2.5"></gt><share href="https://arxiv.org/html/2409.09893v1#A2.p1.4.m4.2.2.2.cmml" id="A2.p1.4.m4.2.2d.cmml" xref="A2.p1.4.m4.2.2"></share><emptyset id="A2.p1.4.m4.2.2.6.cmml" xref="A2.p1.4.m4.2.2.6"></emptyset></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.4.m4.2c">|C\cap(A\setminus B)|&gt;\emptyset\land|C\cap(B\setminus A)|&gt;\emptyset</annotation><annotation encoding="application/x-llamapun" id="A2.p1.4.m4.2d">| italic_C âˆ© ( italic_A âˆ– italic_B ) | &gt; âˆ… âˆ§ | italic_C âˆ© ( italic_B âˆ– italic_A ) | &gt; âˆ…</annotation></semantics></math><span class="ltx_text" id="A2.p1.4.5" style="font-size:144%;">. This can be extended to more than two training datasets easily.</span></p>
</div>
<figure class="ltx_figure" id="A2.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="222" id="A2.F9.g1" src="extracted/5856734/appendix_figures/dataset_vis.jpg" width="586"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F9.16.5.1" style="font-size:63%;">Figure 9</span>: </span><span class="ltx_text" id="A2.F9.8.4" style="font-size:63%;">More examples of the mixed-label space evaluation-only datasets: CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A2.F9.5.1.m1.1"><semantics id="A2.F9.5.1.m1.1b"><msub id="A2.F9.5.1.m1.1.1" xref="A2.F9.5.1.m1.1.1.cmml"><mi id="A2.F9.5.1.m1.1.1b" xref="A2.F9.5.1.m1.1.1.cmml"></mi><mtext id="A2.F9.5.1.m1.1.1.1" xref="A2.F9.5.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.F9.5.1.m1.1c"><apply id="A2.F9.5.1.m1.1.1.cmml" xref="A2.F9.5.1.m1.1.1"><ci id="A2.F9.5.1.m1.1.1.1a.cmml" xref="A2.F9.5.1.m1.1.1.1"><mtext id="A2.F9.5.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.F9.5.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F9.5.1.m1.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A2.F9.5.1.m1.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A2.F9.6.2.m2.1"><semantics id="A2.F9.6.2.m2.1b"><msub id="A2.F9.6.2.m2.1.1" xref="A2.F9.6.2.m2.1.1.cmml"><mi id="A2.F9.6.2.m2.1.1b" xref="A2.F9.6.2.m2.1.1.cmml"></mi><mtext id="A2.F9.6.2.m2.1.1.1" xref="A2.F9.6.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.F9.6.2.m2.1c"><apply id="A2.F9.6.2.m2.1.1.cmml" xref="A2.F9.6.2.m2.1.1"><ci id="A2.F9.6.2.m2.1.1.1a.cmml" xref="A2.F9.6.2.m2.1.1.1"><mtext id="A2.F9.6.2.m2.1.1.1.cmml" mathsize="70%" xref="A2.F9.6.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F9.6.2.m2.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A2.F9.6.2.m2.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>, CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A2.F9.7.3.m3.1"><semantics id="A2.F9.7.3.m3.1b"><msub id="A2.F9.7.3.m3.1.1" xref="A2.F9.7.3.m3.1.1.cmml"><mi id="A2.F9.7.3.m3.1.1b" xref="A2.F9.7.3.m3.1.1.cmml"></mi><mtext id="A2.F9.7.3.m3.1.1.1" xref="A2.F9.7.3.m3.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.F9.7.3.m3.1c"><apply id="A2.F9.7.3.m3.1.1.cmml" xref="A2.F9.7.3.m3.1.1"><ci id="A2.F9.7.3.m3.1.1.1a.cmml" xref="A2.F9.7.3.m3.1.1.1"><mtext id="A2.F9.7.3.m3.1.1.1.cmml" mathsize="70%" xref="A2.F9.7.3.m3.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F9.7.3.m3.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A2.F9.7.3.m3.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math>, and CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A2.F9.8.4.m4.1"><semantics id="A2.F9.8.4.m4.1b"><msub id="A2.F9.8.4.m4.1.1" xref="A2.F9.8.4.m4.1.1.cmml"><mi id="A2.F9.8.4.m4.1.1b" xref="A2.F9.8.4.m4.1.1.cmml"></mi><mtext id="A2.F9.8.4.m4.1.1.1" xref="A2.F9.8.4.m4.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.F9.8.4.m4.1c"><apply id="A2.F9.8.4.m4.1.1.cmml" xref="A2.F9.8.4.m4.1.1"><ci id="A2.F9.8.4.m4.1.1.1a.cmml" xref="A2.F9.8.4.m4.1.1.1"><mtext id="A2.F9.8.4.m4.1.1.1.cmml" mathsize="70%" xref="A2.F9.8.4.m4.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F9.8.4.m4.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A2.F9.8.4.m4.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>.</span></figcaption>
</figure>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1"><span class="ltx_text" id="A2.p2.1.1" style="font-size:144%;">Here, we show all the sub-dataset label spaces in each of the mixed-label space benchmarks (more visualizations can be found in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A2.F9" style="font-size:144%;" title="Figure 9 â€£ Appendix B Mixed-label Space Benchmarks â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text" id="A2.p2.1.2" style="font-size:144%;">):</span></p>
</div>
<div class="ltx_para" id="A2.p3">
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A2.I1.i1.p1.1.1" style="font-size:144%;">CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A2.I1.i1.p1.1.1.m1.1"><semantics id="A2.I1.i1.p1.1.1.m1.1a"><msub id="A2.I1.i1.p1.1.1.m1.1.1" xref="A2.I1.i1.p1.1.1.m1.1.1.cmml"><mi id="A2.I1.i1.p1.1.1.m1.1.1a" xref="A2.I1.i1.p1.1.1.m1.1.1.cmml"></mi><mtext id="A2.I1.i1.p1.1.1.m1.1.1.1" xref="A2.I1.i1.p1.1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.1.1.m1.1b"><apply id="A2.I1.i1.p1.1.1.m1.1.1.cmml" xref="A2.I1.i1.p1.1.1.m1.1.1"><ci id="A2.I1.i1.p1.1.1.m1.1.1.1a.cmml" xref="A2.I1.i1.p1.1.1.m1.1.1.1"><mtext id="A2.I1.i1.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.I1.i1.p1.1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i1.p1.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math></span><span class="ltx_text" id="A2.I1.i1.p1.1.2" style="font-size:144%;">: [arm, person], [coat, person], [dress, person], [face, person], [glove, person], [hair, person], [hat, person], [leg, person], [pants, person], [scarf, person], [shoe, person], [skirt, person], [socks, person], [sunglasses, person], [upper clothes, person]</span></p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1"><span class="ltx_text ltx_font_typewriter" id="A2.I1.i2.p1.1.1" style="font-size:144%;">CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A2.I1.i2.p1.1.1.m1.1"><semantics id="A2.I1.i2.p1.1.1.m1.1a"><msub id="A2.I1.i2.p1.1.1.m1.1.1" xref="A2.I1.i2.p1.1.1.m1.1.1.cmml"><mi id="A2.I1.i2.p1.1.1.m1.1.1a" xref="A2.I1.i2.p1.1.1.m1.1.1.cmml"></mi><mtext id="A2.I1.i2.p1.1.1.m1.1.1.1" xref="A2.I1.i2.p1.1.1.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.1.1.m1.1b"><apply id="A2.I1.i2.p1.1.1.m1.1.1.cmml" xref="A2.I1.i2.p1.1.1.m1.1.1"><ci id="A2.I1.i2.p1.1.1.m1.1.1.1a.cmml" xref="A2.I1.i2.p1.1.1.m1.1.1.1"><mtext id="A2.I1.i2.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.I1.i2.p1.1.1.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.1.1.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i2.p1.1.1.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math></span><span class="ltx_text" id="A2.I1.i2.p1.1.2" style="font-size:144%;">: [leg, shoe, person], [hat, hair, face, person], [hat, hair, face, arm, leg, person]</span></p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1"><span class="ltx_text ltx_font_typewriter" id="A2.I1.i3.p1.1.1" style="font-size:144%;">CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A2.I1.i3.p1.1.1.m1.1"><semantics id="A2.I1.i3.p1.1.1.m1.1a"><msub id="A2.I1.i3.p1.1.1.m1.1.1" xref="A2.I1.i3.p1.1.1.m1.1.1.cmml"><mi id="A2.I1.i3.p1.1.1.m1.1.1a" xref="A2.I1.i3.p1.1.1.m1.1.1.cmml"></mi><mtext id="A2.I1.i3.p1.1.1.m1.1.1.1" xref="A2.I1.i3.p1.1.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.1.m1.1b"><apply id="A2.I1.i3.p1.1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.1.m1.1.1"><ci id="A2.I1.i3.p1.1.1.m1.1.1.1a.cmml" xref="A2.I1.i3.p1.1.1.m1.1.1.1"><mtext id="A2.I1.i3.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.I1.i3.p1.1.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.1.m1.1c">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i3.p1.1.1.m1.1d">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math></span><span class="ltx_text" id="A2.I1.i3.p1.1.2" style="font-size:144%;">: [window, car], [wheel, car], [light, car], [license plate, car], [head, person], [arm, person], [leg, person]</span></p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1"><span class="ltx_text ltx_font_typewriter" id="A2.I1.i4.p1.1.1" style="font-size:144%;">CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A2.I1.i4.p1.1.1.m1.1"><semantics id="A2.I1.i4.p1.1.1.m1.1a"><msub id="A2.I1.i4.p1.1.1.m1.1.1" xref="A2.I1.i4.p1.1.1.m1.1.1.cmml"><mi id="A2.I1.i4.p1.1.1.m1.1.1a" xref="A2.I1.i4.p1.1.1.m1.1.1.cmml"></mi><mtext id="A2.I1.i4.p1.1.1.m1.1.1.1" xref="A2.I1.i4.p1.1.1.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.1.1.m1.1b"><apply id="A2.I1.i4.p1.1.1.m1.1.1.cmml" xref="A2.I1.i4.p1.1.1.m1.1.1"><ci id="A2.I1.i4.p1.1.1.m1.1.1.1a.cmml" xref="A2.I1.i4.p1.1.1.m1.1.1.1"><mtext id="A2.I1.i4.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.I1.i4.p1.1.1.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.1.1.m1.1c">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A2.I1.i4.p1.1.1.m1.1d">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math></span><span class="ltx_text" id="A2.I1.i4.p1.1.2" style="font-size:144%;">: [license plate, light, wheel, window, car, arm, head, leg, person]</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A2.p4">
<p class="ltx_p" id="A2.p4.1"><span class="ltx_text" id="A2.p4.1.1" style="font-size:144%;">The ground truth annotations for the original training datasets are shown in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A2.F10" style="font-size:144%;" title="Figure 10 â€£ Appendix B Mixed-label Space Benchmarks â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text" id="A2.p4.1.2" style="font-size:144%;"> for reference.</span></p>
</div>
<figure class="ltx_figure" id="A2.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="116" id="A2.F10.g1" src="extracted/5856734/appendix_figures/training_anno.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F10.4.1.1" style="font-size:63%;">Figure 10</span>: </span><span class="ltx_text" id="A2.F10.5.2" style="font-size:63%;">Examples of the ground truth annotations for the original training datasets (from left to right): COCO, CIHP, CS, and CSP.</span></figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Qualitative Comparison</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1"><span class="ltx_text" id="A3.p1.1.1" style="font-size:144%;">We provide a visual comparison to showcase the qualitative performance of each model, alongside the original image and ground truth annotations.</span></p>
<ol class="ltx_enumerate" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text" id="A3.I1.i1.p1.1.1" style="font-size:144%;">RESI excels in handling complex class combinations (e.g., â€œlicense plate, light, wheel, window, car, arm, head, leg, personâ€). See Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3.F13" style="font-size:144%;" title="Figure 13 â€£ Appendix C Additional Qualitative Comparison â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">13</span></a><span class="ltx_text" id="A3.I1.i1.p1.1.2" style="font-size:144%;">.</span></p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text" id="A3.I1.i2.p1.1.1" style="font-size:144%;">RESI also shows versatility across various class combinations, outperforming others in Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3.F12" style="font-size:144%;" title="Figure 12 â€£ Appendix C Additional Qualitative Comparison â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">12</span></a><span class="ltx_text" id="A3.I1.i2.p1.1.2" style="font-size:144%;"> and Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3.F11" style="font-size:144%;" title="Figure 11 â€£ Appendix C Additional Qualitative Comparison â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text" id="A3.I1.i2.p1.1.3" style="font-size:144%;">.</span></p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p" id="A3.p2.1"><span class="ltx_text" id="A3.p2.1.1" style="font-size:144%;">As stated in Sec. </span><span class="ltx_text" id="A3.p2.1.2" style="font-size:144%;color:#FF0000;">3.4</span><span class="ltx_text" id="A3.p2.1.3" style="font-size:144%;"> - Naive Approach, we observed that even when including language-based embeddings as classifiers for existing instance segmentation models, the resulting models often struggle with semantically inconsistent relationships between label spaces. Examples are shown in the first row of Fig.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A3.F11" style="font-size:144%;" title="Figure 11 â€£ Appendix C Additional Qualitative Comparison â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text" id="A3.p2.1.4" style="font-size:144%;">.</span></p>
</div>
<figure class="ltx_figure" id="A3.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="203" id="A3.F11.g1" src="x5.png" width="951"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F11.7.1.1" style="font-size:63%;">Figure 11</span>: </span><span class="ltx_text" id="A3.F11.8.2" style="font-size:63%;">
More visual comparisons of pair-category segmentation performance. RESI consistently demonstrates superior results in handling diverse category combinations during inference compared to conventional approaches, exemplified here by Mask2Former+LEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib9" title="">9</a>]</cite>.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A3.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="491" id="A3.F12.g1" src="extracted/5856734/appendix_figures/pair_vis_full.jpg" width="685"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F12.10.3.1" style="font-size:63%;">Figure 12</span>: </span><span class="ltx_text" id="A3.F12.4.2" style="font-size:63%;">More visual comparison of pair-category segmentation performance across all models on CIHP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A3.F12.3.1.m1.1"><semantics id="A3.F12.3.1.m1.1b"><msub id="A3.F12.3.1.m1.1.1" xref="A3.F12.3.1.m1.1.1.cmml"><mi id="A3.F12.3.1.m1.1.1b" xref="A3.F12.3.1.m1.1.1.cmml"></mi><mtext id="A3.F12.3.1.m1.1.1.1" xref="A3.F12.3.1.m1.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A3.F12.3.1.m1.1c"><apply id="A3.F12.3.1.m1.1.1.cmml" xref="A3.F12.3.1.m1.1.1"><ci id="A3.F12.3.1.m1.1.1.1a.cmml" xref="A3.F12.3.1.m1.1.1.1"><mtext id="A3.F12.3.1.m1.1.1.1.cmml" mathsize="70%" xref="A3.F12.3.1.m1.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F12.3.1.m1.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A3.F12.3.1.m1.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{P}}" class="ltx_Math" display="inline" id="A3.F12.4.2.m2.1"><semantics id="A3.F12.4.2.m2.1b"><msub id="A3.F12.4.2.m2.1.1" xref="A3.F12.4.2.m2.1.1.cmml"><mi id="A3.F12.4.2.m2.1.1b" xref="A3.F12.4.2.m2.1.1.cmml"></mi><mtext id="A3.F12.4.2.m2.1.1.1" xref="A3.F12.4.2.m2.1.1.1a.cmml">P</mtext></msub><annotation-xml encoding="MathML-Content" id="A3.F12.4.2.m2.1c"><apply id="A3.F12.4.2.m2.1.1.cmml" xref="A3.F12.4.2.m2.1.1"><ci id="A3.F12.4.2.m2.1.1.1a.cmml" xref="A3.F12.4.2.m2.1.1.1"><mtext id="A3.F12.4.2.m2.1.1.1.cmml" mathsize="70%" xref="A3.F12.4.2.m2.1.1.1">P</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F12.4.2.m2.1d">{}_{\textrm{P}}</annotation><annotation encoding="application/x-llamapun" id="A3.F12.4.2.m2.1e">start_FLOATSUBSCRIPT P end_FLOATSUBSCRIPT</annotation></semantics></math> </span></figcaption>
</figure>
<figure class="ltx_figure" id="A3.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="592" id="A3.F13.g1" src="extracted/5856734/appendix_figures/multi_vis_full.jpg" width="685"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F13.10.3.1" style="font-size:63%;">Figure 13</span>: </span><span class="ltx_text" id="A3.F13.4.2" style="font-size:63%;">More visual comparison of multi-category segmentation performance across all models on CIHP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A3.F13.3.1.m1.1"><semantics id="A3.F13.3.1.m1.1b"><msub id="A3.F13.3.1.m1.1.1" xref="A3.F13.3.1.m1.1.1.cmml"><mi id="A3.F13.3.1.m1.1.1b" xref="A3.F13.3.1.m1.1.1.cmml"></mi><mtext id="A3.F13.3.1.m1.1.1.1" xref="A3.F13.3.1.m1.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A3.F13.3.1.m1.1c"><apply id="A3.F13.3.1.m1.1.1.cmml" xref="A3.F13.3.1.m1.1.1"><ci id="A3.F13.3.1.m1.1.1.1a.cmml" xref="A3.F13.3.1.m1.1.1.1"><mtext id="A3.F13.3.1.m1.1.1.1.cmml" mathsize="70%" xref="A3.F13.3.1.m1.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F13.3.1.m1.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A3.F13.3.1.m1.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math> and CSP<math alttext="{}_{\textrm{M}}" class="ltx_Math" display="inline" id="A3.F13.4.2.m2.1"><semantics id="A3.F13.4.2.m2.1b"><msub id="A3.F13.4.2.m2.1.1" xref="A3.F13.4.2.m2.1.1.cmml"><mi id="A3.F13.4.2.m2.1.1b" xref="A3.F13.4.2.m2.1.1.cmml"></mi><mtext id="A3.F13.4.2.m2.1.1.1" xref="A3.F13.4.2.m2.1.1.1a.cmml">M</mtext></msub><annotation-xml encoding="MathML-Content" id="A3.F13.4.2.m2.1c"><apply id="A3.F13.4.2.m2.1.1.cmml" xref="A3.F13.4.2.m2.1.1"><ci id="A3.F13.4.2.m2.1.1.1a.cmml" xref="A3.F13.4.2.m2.1.1.1"><mtext id="A3.F13.4.2.m2.1.1.1.cmml" mathsize="70%" xref="A3.F13.4.2.m2.1.1.1">M</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F13.4.2.m2.1d">{}_{\textrm{M}}</annotation><annotation encoding="application/x-llamapun" id="A3.F13.4.2.m2.1e">start_FLOATSUBSCRIPT M end_FLOATSUBSCRIPT</annotation></semantics></math>.</span></figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix" style="font-size:144%;">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Model Training Details</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1"><span class="ltx_text" id="A4.p1.1.1" style="font-size:144%;">We use ResNet-50 (R50) as our backbone across all experiments. For each multi-dataset training method, we train the model for 200k iterations on COCO-CIHP and Cityscapes-CPP, and 300k iterations on COCO, ADE20K, and Mapillary Vistas. We use a batch size of 16 and train on 8 A100 GPUs. To accommodate the different sizes of the multiple datasets employed, we implement a data sampling scheme that aims to sample images from each dataset with equal frequency, as described in UniDetÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A4.p1.1.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#bib.bib69" title="">69</a><span class="ltx_text" id="A4.p1.1.3.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="A4.p1.1.4" style="font-size:144%;">. Information regarding the evaluation dataset setup can be found in Mixed-label Space Benchmarks(Sec.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A2" style="font-size:144%;" title="Appendix B Mixed-label Space Benchmarks â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">B</span></a><span class="ltx_text" id="A4.p1.1.5" style="font-size:144%;">). Further details about the panoptic inference algorithm setup can be found in Panoptic Segmentation Post-processing(Sec.Â </span><a class="ltx_ref" href="https://arxiv.org/html/2409.09893v1#A1" style="font-size:144%;" title="Appendix A Panoptic Segmentation Post-processing â€£ Resolving Inconsistent Semantics in Multi-Dataset Image Segmentation"><span class="ltx_text ltx_ref_tag">A</span></a><span class="ltx_text" id="A4.p1.1.6" style="font-size:144%;">).</span></p>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Sep 15 23:14:08 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
