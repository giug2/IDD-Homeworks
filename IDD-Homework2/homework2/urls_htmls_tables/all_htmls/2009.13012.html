<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2009.13012] Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges</title><meta property="og:description" content="The Internet of Things (IoT) will be ripe for the deployment of novel machine learning algorithm for both network and application management. However, given the presence of massively distributed and private datasets, i…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2009.13012">

<!--Generated on Fri Mar  8 09:06:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  Internet of Things,  wireless networks.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\justify</span>
</div>
<h1 class="ltx_title ltx_title_document">Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Latif U. Khan, Walid Saad, , Zhu Han, , Ekram Hossain, , and Choong Seon Hong
</span><span class="ltx_author_notes">
L. U. Khan and C. S. Hong are with the Department of Computer Science &amp; Engineering, Kyung Hee University, Yongin-si 17104, South Korea.
Walid Saad is with the Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA 24061 USA.
Zhu Han is with the Electrical and Computer Engineering Department, University of Houston, Houston, TX 77004 USA, and also with the Computer Science Department, University of Houston, Houston, TX 77004 USA, and the Department of Computer Science and Engineering, Kyung Hee University, South Korea.
E. Hossain is with Department of Electrical and Computer Engineering at University of Manitoba, Winnipeg, Canada.
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">The Internet of Things (IoT) will be ripe for the deployment of novel machine learning algorithm for both network and application management. However, given the presence of massively distributed and private datasets, it is challenging to use classical centralized learning algorithms in the IoT. To overcome this challenge, federated learning can be a promising solution that enables on-device machine learning without the need to migrate the private end-user data to a central cloud. In federated learning, only learning model updates are transferred between end-devices and the aggregation server. Although federated learning can offer better privacy preservation than centralized machine learning, it has still privacy concerns. In this paper, first, we present the recent advances of federated learning towards enabling federated learning-powered IoT applications. A set of metrics such as sparsification, robustness, quantization, scalability, security, and privacy, is delineated in order to rigorously evaluate the recent advances. Second, we devise a taxonomy for federated learning over IoT networks. Finally, we present several open research challenges with their possible solutions.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, Internet of Things, wireless networks.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.4" class="ltx_p">Internet of Things (IoT) applications can lead to the true realization of smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Smart cities can offer several critical applications such as intelligent transportation, smart industries, healthcare, and smart surveillance, among others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. To successfully deploy these smart services, a massive number of IoT devices are required <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. According to statistics, the number of IoT devices will reach <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="125" display="inline"><semantics id="S1.p1.1.m1.1a"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">125</mn><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><cn type="integer" id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">125</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">125</annotation></semantics></math> billion by <math id="S1.p1.2.m2.1" class="ltx_Math" alttext="2030" display="inline"><semantics id="S1.p1.2.m2.1a"><mn id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">2030</mn><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><cn type="integer" id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">2030</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">2030</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. These IoT devices will generate enormous amount of data. A recent report in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> revealed that the data generated by IoT devices will reach <math id="S1.p1.3.m3.1" class="ltx_Math" alttext="79.4" display="inline"><semantics id="S1.p1.3.m3.1a"><mn id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml">79.4</mn><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><cn type="float" id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1">79.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">79.4</annotation></semantics></math> zettabytes (ZB) by <math id="S1.p1.4.m4.1" class="ltx_Math" alttext="2025" display="inline"><semantics id="S1.p1.4.m4.1a"><mn id="S1.p1.4.m4.1.1" xref="S1.p1.4.m4.1.1.cmml">2025</mn><annotation-xml encoding="MathML-Content" id="S1.p1.4.m4.1b"><cn type="integer" id="S1.p1.4.m4.1.1.cmml" xref="S1.p1.4.m4.1.1">2025</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.4.m4.1c">2025</annotation></semantics></math>. Such a remarkable increase in both IoT network size and accompanying data volume open up attractive opportunities for artificial intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. To this end, one can use centralized machine learning schemes to enable these smart IoT applications. However, centralized machine learning techniques suffer from the inherent issue of users’ privacy leakage because of the need to transfer the end-devices data to a centralized third party server for training. Furthermore, centralized machine learning might not be feasible when the data size is very large (e.g., astronomical data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>) and located at multiple locations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To cope with the aforementioned challenge of large, distributed datasets, we can use distributed machine learning to distribute the machine learning workload to multiple machines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. These multiple machines can then train several models at distributed locations in parallel to create a machine learning model. Distributed learning enables high-performance computing via parallel computation of a machine learning model. Two types of approaches such as data-parallel and model-parallel approaches can be used for distributed machine learning. In a data-parallel approach, the whole data is divided among a set of distributed servers, while each server using the same model for training. The model-parallel approach uses exactly the same data for all servers to train distinct portions of a machine learning model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. The model-parallel approach might not be suitable for some applications because all the machine learning model can not be divided into parts.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2009.13012/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="544" height="408" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">An overview of federated learning for IoT networks.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Although distributed machine learning offers parallel computation of models at geographically distributed locations, it does not explicitly addressed some more practical challenges of data and system heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Here, system heterogeneity refers to variations in computational resources (CPU-cycles/sec), communication resources, and storage capacity of end-devices, whereas data heterogeneity deals with non-independent and identical distribution (non-IID) of data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Additionally, traditional distributed machine learning algorithms that rely on the model-parallel or the data-parallel approach do not truly preserve the privacy of users. These distributed machine learning schemes use training of machine learning models at distributed servers that rely on data from multiple end-users, and thus suffers from privacy leakage issue. To ensure privacy preservation while considering system and data heterogeneity in machine learning, federated learning<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Federated learning itself has privacy concerns and does not completely guarantee privacy.</span></span></span> has been introduced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. In contrast to traditional machine learning schemes, federated learning does not require migration of data from end-devices to a centralized edge/cloud server for training. The process of federated learning involves local learning model computation at end-devices, which is followed by sending the local learning model parameters to the edge/ cloud server for global model aggregation. Finally, the global model parameters are sent back to the end-devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. To implement federated learning for IoT networks, we will face some challenges. Computing local learning model for federated learning requires significant computational power and backup energy. Additionally, implementing federated learning for IoT applications where the IoT sensors generate fewer data seems challenging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. To train a local learning model, a sufficient amount of data is required for better learning accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Therefore, training a local learning model with better accuracy for computing resource-constrained devices with less data is challenging. To address this challenge one can migrate the data from resource-constrained IoT sensors (e.g., temperature monitoring sensors) to the nearby trustworthy edge for local model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. On the other hand, autonomous driving cars generate a significant amount of data (i.e., <math id="S1.p3.1.m1.2" class="ltx_Math" alttext="4,000" display="inline"><semantics id="S1.p3.1.m1.2a"><mrow id="S1.p3.1.m1.2.3.2" xref="S1.p3.1.m1.2.3.1.cmml"><mn id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">4</mn><mo id="S1.p3.1.m1.2.3.2.1" xref="S1.p3.1.m1.2.3.1.cmml">,</mo><mn id="S1.p3.1.m1.2.2" xref="S1.p3.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.2b"><list id="S1.p3.1.m1.2.3.1.cmml" xref="S1.p3.1.m1.2.3.2"><cn type="integer" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">4</cn><cn type="integer" id="S1.p3.1.m1.2.2.cmml" xref="S1.p3.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.2c">4,000</annotation></semantics></math> gigaoctet) everyday <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Therefore, sending everyday autonomous driving cars will consume more communication resources. One can only send a local learning model to the aggregation server that will consume fewer communication resources than the whole data. Additionally, autonomous cars have more computational power with sufficient energy. Therefore, federated learning can be easily implemented for autonomous driving cars from the perspective of resource usage.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">An overview of federated learning for IoT networks is presented in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. First of all, end-devices iteratively compute the local learning models using their local datasets. After local model computation, the local learning model updates are sent by end-devices to the aggregation server for the global aggregation. Generally, aggregation can be performed in federated learning either at the edge or cloud. Therefore, we can say that federated learning can be either edge-based or cloud-based depending on the location of the global model aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Edge-based federated learning performs global model aggregation at the edge server, whereas cloud-based federated learning performs global federated learning model aggregation at the remote cloud. The edge server serves a small geographical area with a limited number of devices. Therefore, edge-based federated learning is preferable for use in applications that have local context-awareness and require specialized machine learning models for a set of users located in close vicinity to each other <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. For instance, consider the training of keyboard keyword suggestion model for a language of a particular region using federated learning. There can two ways to train such type of model: a specialized model for the regional language via edge-based federated learning and a generalized model for languages of different regions via cloud-based federated learning. A model using edge-based federated can offer more promising results in such a scenario than cloud-based federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. On the other hand, the cloud serves a large number of users located over a large distributed area. Therefore, federated learning that uses aggregation at the cloud (i.e., cloud-based federated learning) is more suitable for training more generalized models than edge-based federated learning by considering a large number of geographically distributed users. It must be noted that we derive the use of terms <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">edge-based federated learning</em> and <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">cloud-based federated learning</em> from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Other than edge-based federated learning and cloud-based federated learning, we can jointly use both edge and cloud servers for the aggregation of learning models. We refer to federated learning that uses aggregation at both cloud and edge as edge-cloud-based federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Communication with an edge is less expansive in terms of communication resources consumption and latency than the remote cloud <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Therefore, end-devices can easily communicate with the edge server that will perform aggregation of local learning models to yield an edge-aggregated learning model. On the other hand, edge server has generally small coverage area and has a limited capacity to serve end-devices. Therefore, few of the end-devices located in a different geographical area as that of the edge server will directly communicate with the cloud. The edge-cloud-based federated learning will perform aggregation of local learning models of these devices with the edge-aggregated learning models. The main advantage of edge-cloud-based federated learning lies in enabling the participation of more devices in the learning process, and thus improves federated learning performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Although federated learning enables on-device machine learning, it suffers from security, robustness, and resource (both computational and communication) optimization challenges. To truly benefit from the use of federated learning in IoT networks, there is a need to resolve these challenges. To cope with resource constraints issues, one can develop federated learning protocols based on device-to-device (D2D) communication. An IoT device might not be able to communicate with a central base station (BS) due to communication resource constraints. To enable participation of such IoT devices in federated learning, one can use collaborative federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Collaborative federated learning allows resource-constrained IoT devices to send their local learning models to nearby devices rather than the BS, where local aggregation takes place between the receiving device local model and the received local model. Then, the locally aggregated model is sent to the centralized edge/cloud server for global aggregation. Similar to traditional federated learning, collaborative federated learning can be either edge-based or cloud-based depending on the context of the machine learning model. On the other hand, a malicious aggregation server can infer end-devices information from their learning model parameters, and thus might cause privacy leakage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. To cope with this issue, one can use differential privacy-aware federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Next, we discuss market statistics and research trends of federated learning and IoT-networks.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2009.13012/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="242" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.3.2" class="ltx_text" style="font-size:90%;">Year wise publications of (a) federated learning, and (b) Internet of Things [Scopus data, Access month: February 2021].</span></figcaption>
</figure>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.4.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.5.2" class="ltx_text ltx_font_italic">Market Statistics and Research Trends</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">According to statistics, the market of artificial intelligence is expected to grow at a Compound Annual Growth Rate (CAGR) of 33.2% from 27.23 billion US Dollar in 2019 to 266.93 billion US Dollar in 2027 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. The key driver of the increase in the artificial intelligence market is the proliferation of technological advancement and data generation. Banking, financial and insurance (BFSI) vertical, IT and telecom, retail, healthcare, automotive, advertising and media, among others are various industries that are mainly contributing to the artificial intelligence market. On the other hand, North America has shown significant growth in the artificial intelligence market in 2019 with the US as the highest contributor. The Asia Pacific is also expected to have significant growth in the artificial intelligence market. China will add a major portion to the artificial intelligence market in the Asia Pacific region.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">The IoT market is expected to reach 1463.19 billion US Dollar from 250.72 billion US Dollar in 2027 compared to 2019 at a CAGR of 24.9% <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. The key drivers of IoT markets are telecommunication, transportation, manufacturing, health-care, government, retail, BFSI, among others. The highest share is hold by BFSI sector. The highest revenue generated by the Asia Pacific region in 2018 is 98.86 billion US Dollar, which is further expected to lead the IoT market in future. Within Asia Pacific region, China has the highest share. Other than market share of machine learning and IoT, the number of research publications versus year are shown in Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It is clear from the Fig. <a href="#S1.F2" title="Figure 2 ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> that there is significant increase in number of publications every year for both federated learning and IoT. Based on the above-discussed facts, machine learning and IoT are expected to opens up novel opportunities for research and development in the foreseeable future.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S1.T1.3.2" class="ltx_text" style="font-size:90%;">Summary of existing surveys and tutorials with their primary focus.</span></figcaption>
<table id="S1.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.4.1" class="ltx_tr">
<td id="S1.T1.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S1.T1.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.2.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Internet of Things</span></span>
</span>
</td>
<td id="S1.T1.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.3.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.4.1.3.1.1.1" class="ltx_text ltx_font_bold">Resource optimization for federated learning</span></span>
</span>
</td>
<td id="S1.T1.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.4.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.4.1.4.1.1.1" class="ltx_text ltx_font_bold">Incentive mechanism for federated learning</span></span>
</span>
</td>
<td id="S1.T1.4.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S1.T1.4.1.5.1.1.1" class="ltx_text ltx_font_bold">Learning algorithm design for federated learning</span></span>
</span>
</td>
<td id="S1.T1.4.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.6.1.1" class="ltx_p" style="width:51.2pt;"><span id="S1.T1.4.1.6.1.1.1" class="ltx_text ltx_font_bold">Taxonomy</span></span>
</span>
</td>
<td id="S1.T1.4.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.4.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.7.1.1" class="ltx_p" style="width:99.6pt;"><span id="S1.T1.4.1.7.1.1.1" class="ltx_text ltx_font_bold">Remark</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.4.2" class="ltx_tr" style="background-color:#FFFFFF;">
<td id="S1.T1.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.1.1.1" class="ltx_p" style="width:51.2pt;">Lim <span id="S1.T1.4.2.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.3.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.4.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.2.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.2.7.1.1" class="ltx_p" style="width:99.6pt;">Federated learning at network edge is considered.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.3" class="ltx_tr" style="background-color:#DFDFDF;">
<td id="S1.T1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.1.1.1" class="ltx_p" style="width:51.2pt;">Li <span id="S1.T1.4.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.3.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.3.7.1.1" class="ltx_p" style="width:99.6pt;">N.A</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.4" class="ltx_tr" style="background-color:#FFFFFF;">
<td id="S1.T1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.1.1.1" class="ltx_p" style="width:51.2pt;">Li <span id="S1.T1.4.4.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.4.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.4.7.1.1" class="ltx_p" style="width:99.6pt;">N.A</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.5" class="ltx_tr" style="background-color:#DFDFDF;">
<td id="S1.T1.4.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.1.1.1" class="ltx_p" style="width:51.2pt;">Wang <span id="S1.T1.4.5.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.5.1.1" class="ltx_p" style="width:71.1pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.5.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.5.7.1.1" class="ltx_p" style="width:99.6pt;">Mainly considered federated learning for caching and computational offloading.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.6" class="ltx_tr" style="background-color:#FFFFFF;">
<td id="S1.T1.4.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.1.1.1" class="ltx_p" style="width:51.2pt;">Lyu <span id="S1.T1.4.6.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.5.1.1" class="ltx_p" style="width:71.1pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.6.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.6.7.1.1" class="ltx_p" style="width:99.6pt;">Surveyed security in federated learning.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.7" class="ltx_tr" style="background-color:#DFDFDF;">
<td id="S1.T1.4.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.1.1.1" class="ltx_p" style="width:51.2pt;">Kairouz <span id="S1.T1.4.7.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.7.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.7.7.1.1" class="ltx_p" style="width:99.6pt;">N.A</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.8" class="ltx_tr" style="background-color:#FFFFFF;">
<td id="S1.T1.4.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.1.1.1" class="ltx_p" style="width:51.2pt;">Khan <span id="S1.T1.4.8.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.5.1.1" class="ltx_p" style="width:71.1pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.8.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.8.7.1.1" class="ltx_p" style="width:99.6pt;">The work introduced dispersed federated learning, devise its taxonomy, and presented future directions.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.9" class="ltx_tr" style="background-color:#DFDFDF;">
<td id="S1.T1.4.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.1.1.1" class="ltx_p" style="width:51.2pt;">Rahman <span id="S1.T1.4.9.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.3.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.9.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.9.7.1.1" class="ltx_p" style="width:99.6pt;">Surveyed federated learning design aspects (i.e., learning algorithm design and resource optimization) and open challenges.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.10" class="ltx_tr" style="background-color:#FFFFFF;">
<td id="S1.T1.4.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.1.1.1" class="ltx_p" style="width:51.2pt;">Aledhari <span id="S1.T1.4.10.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.2.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.3.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.4.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.6.1.1" class="ltx_p" style="width:51.2pt;">✗</span>
</span>
</td>
<td id="S1.T1.4.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.4.10.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFFFFF;">
<span id="S1.T1.4.10.7.1.1" class="ltx_p" style="width:99.6pt;">Focused mainly on federated learning architecture and enablers.</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.11" class="ltx_tr" style="background-color:#DFDFDF;">
<td id="S1.T1.4.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.1.1.1" class="ltx_p" style="width:51.2pt;">Our Tutorial</span>
</span>
</td>
<td id="S1.T1.4.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.2.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.3.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.4.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.5.1.1" class="ltx_p" style="width:71.1pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.6.1.1" class="ltx_p" style="width:51.2pt;">✓</span>
</span>
</td>
<td id="S1.T1.4.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.4.11.7.1" class="ltx_inline-block ltx_align_top" style="background-color:#DFDFDF;">
<span id="S1.T1.4.11.7.1.1" class="ltx_p" style="width:99.6pt;">N.A</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.4.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.5.2" class="ltx_text ltx_font_italic">Existing Surveys and Tutorials</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Numerous surveys and tutorials primarily reviewed federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>,and<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Lim <span id="S1.SS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> presented a comprehensive survey of federated learning for mobile edge networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. First, the authors provided an overview of federated learning. Second, the key implementation challenges with existing solutions and several applications of federated learning in mobile edge networks are discussed. Finally, several open research challenges are presented. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, Li <span id="S1.SS2.p1.1.2" class="ltx_text ltx_font_italic">et el.</span> surveyed implementation challenges of federated learning, existing approaches, and future research directions. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> presented an overview of federated learning, devised taxonomy, and discussed the existing solutions with their limitations in enabling federated learning. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, Wang <span id="S1.SS2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> proposed an “In-Edge AI” framework for edge networks to enable efficient collaboration between end-devices and edge servers for learning model updates exchange. They considered two use cases such as edge caching and computation offloading. To efficiently enable these use cases, a double deep Q-learning agent was trained using federated learning. Finally, several open research challenges were presented. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, Lyu <span id="S1.SS2.p1.1.4" class="ltx_text ltx_font_italic">et al.</span> presented a survey of threats to federated learning. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, Kairouz <span id="S1.SS2.p1.1.5" class="ltx_text ltx_font_italic">et al.</span> comprehensively surveyed federated learning, and they discussed basics, privacy preservation, robustness, and ensuring fairness. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> presented a vision of dispersed federated learning that is based on true decentralization. Furthermore, a taxonomy and future directions are presented for dispersed federated learning. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> primarily surveyed federated learning design aspects (i.e., learning algorithm design and resource optimization) and presented open challenges. Aledhari <span id="S1.SS2.p1.1.6" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> presented enabling technologies, protocols, and few applications of federated along with open challenges. On the other hand, there are few surveys <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> that have briefly discussed federated learning as a solution to some existing problems (e.g., caching at the network edge). However, their primary perspective was to use machine learning for enabling IoT. In contrast, our tutorial primarily focus on federated learning for IoT.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2009.13012/assets/x3.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="241" height="529" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S1.F3.3.2" class="ltx_text" style="font-size:90%;">Overview of our tutorial.</span></figcaption>
</figure>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS3.4.1.1" class="ltx_text">I-C</span> </span><span id="S1.SS3.5.2" class="ltx_text ltx_font_italic">Our Tutorial</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">Mostly, the existing surveys and tutorials <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> considered resource optimization, incentive mechanism, and learning algorithm design for federated learning. In contrast (as given in Table <a href="#S1.T1" title="TABLE I ‣ I-A Market Statistics and Research Trends ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>) to work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, we present state-of-the-art advances of federated learning towards enabling IoT applications and devise a taxonomy. Furthermore, the open research challenges in our paper are significantly different than those in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div id="S1.SS3.p2" class="ltx_para">
<p id="S1.SS3.p2.1" class="ltx_p">The contributions of this tutorial (whose overview is given in Fig. <a href="#S1.F3" title="Figure 3 ‣ I-B Existing Surveys and Tutorials ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">First, we discuss and critically evaluate the recent federated learning literature, with a focus on the works that are pertinent to IoT applications. To assess these recent works, metrics that serve as key evaluation criteria: Scalability, quantization, robustness, sparsification, security and privacy, are considered. Furthermore, a summary of key contributions and evaluation metrics are presented.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Second, we derive a taxonomy for federated learning based on different parameters. These parameters include federated optimization schemes, incentive mechanism, security and privacy, operation modes depending on global model aggregation fashion, end-device design, local learning models, resources, miners classification, edge collaboration, and cloud server design.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Third, we present several key open research challenges with their possible solutions.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS3.p3" class="ltx_para">
<p id="S1.SS3.p3.1" class="ltx_p">The rest of the tutorial is organized as follows: Section <a href="#S2" title="II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> outlines fundamental concepts of federated learning. Recent works of federated learning leading towards IoT applications are presented in Section <a href="#S3" title="III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. A taxonomy is devised in Section <a href="#S4" title="IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> using various parameters. Finally, open research challenges with possible solutions are presented in Section <a href="#S5" title="V Open Research Challenges ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and paper is concluded in Section <a href="#S6" title="VI Conclusions and Future Prospects ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p>
</div>
<figure id="S1.F4" class="ltx_figure"><img src="/html/2009.13012/assets/x4.png" id="S1.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="545" height="484" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S1.F4.3.2" class="ltx_text" style="font-size:90%;">Architectural overview of federated learning for IoT networks.</span></figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning for IoT: Fundamental Concepts</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section presents a high-level architecture, federated optimization schemes, and various frameworks for federated learning-enabled IoT networks. Next, we briefly discuss various aspects of federated learning-enabled IoT networks.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">High-Level Architecture</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">A high-level architecture of federated learning-enabled IoT networks is shown in Fig. <a href="#S1.F4" title="Figure 4 ‣ I-C Our Tutorial ‣ I Introduction ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The process starts with selection of a set of end-devices according to a suitable criterion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. Generally, only a set of devices can participate due to communication resources constraints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. Therefore, we must select devices according to an effective criterion using effective sparsification scheme (step 1). For instance, the criteria can be end-devices with clean datasets, more computational resources, and high-backup power, to enable accurate computation of local learning model within less time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. To compute the local learning models using local datasets, we can use various schemes at end-devices, such as feed-forward neural networks (FNN), convolutional neural neural networks (CNN), support vector machines (SVM), and long-short term memory (LSTM), among others (step 2). After computation of the local learning model, we can employ effective quantization scheme to reduce the number of bits used for representation of the local learning model updates (step 3). Various quantization schemes for federated learning were introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, a lossy federated learning (LFL) scheme based on quantization was proposed. In LFL, both local learning updates and global model updates are quantized by slightly modifying Communication-Efficient stochastic gradient descent (SGD) via Gradient Quantization and Encoding (QSGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> prior to transmission. LFL has shown performance near to federated learning without quantization while reducing communication resources consumption. In another work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, the authors proposed a secure aggregation scheme using heterogeneous quantization for federated learning. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> presented a subtractive dithered lattice quantization-based federated learning scheme. Moreover, dithered hexgonial lattice quantization has shown less compression error compared to dithered scalar quantization, uniform quantization with random unitary rotation, and subsampling with <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mn id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><cn type="integer" id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">3</annotation></semantics></math> bits quantizers. Although various lossy quantization schemes of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> can offer a tradeoff between accuracy and communication cost for federated learning, loss in accuracy due to a quantization must be further reduced.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Next to quantization, we can use some effective encryption algorithm (step 4). A malicious end-device and aggregation server can infer end-devices sensitive information using their local learning model updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. To avoid this kind of privacy leakage, we can use additive homomorphic encryption in federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. Although homomorphic encryption will allow aggregation server to perform global model update from encrypted local learning models without the need for decryption, it will add computation and communication cost. The decryption and encryption in case of homomorphic encryption require multiple modular exponentiation and multiplication operations which are complex operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. Moreover, larger ciphertexts are used by homomorphic encryption that will require more communication resources for transmission. To address these issues, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> proposed a BatchCrypt scheme that is based on encrypting a batch of quantized gradients. The batch of quantized gradients will be then encrypted and gradient-wise aggregation takes place at the aggregation server. Specifically, BatchCrypt jointly uses batch encoding, quantization, and analytical quantization modeling for improving computation and communication efficiency. One of the main advantage of BatchCrypt is the ability to preserve the aggregated model quality similar to cross-silo federated learning based on homomorphic encryption.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">After quantization and encryption, there is a need to use effective channel coding scheme with low overhead and better performance (step 5). The feasible way can be to use Short Block-Length Codes designed for Ultra-Reliable Low Latency Communications (URLLC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. The key design aspects of URLLC codes are latency, reliability, and flexibility. To achieve low latency communication, we should use short packets. Another way to achieve low latency is to use more bandwidth to minimize the latency. Therefore, use of short-block length codes are preferred for URLLC using short packets. Turbo codes, convolutional codes, Bose, Chaudhuri, and Hocquenghem (BCH), and Low-density parity-check (LDPC) codes can be used for packet error rate improvement. However, the complexity associated with Turbo codes makes them difficult to apply to IoT devices with computation resource constraints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, it is shown that BCH codes exhibits highest reliability under optimal decoding among Turbo codes, LDPC codes, polar codes, and convolutional codes. Therefore, one can use BCH codes for federated learning-based IoT networks where ultra-reliable communication is necessary. After channel coding (step <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mn id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><cn type="integer" id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">5</annotation></semantics></math>), the local learning model updates are transmitted to the aggregation server.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">There are many ways to aggregate the local learning models, such as at edge server or cloud server or using miners of a blockchain network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. Aggregation at the edge and cloud server is simple by using averaging in case of FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and then sending back the global learning model updates to end-devices. In case of aggregation via blockchain miners, first of all the miners will receive local model updates from the end-devices. Next, they will share the learning models among themselves and run a blockchain consensus algorithm to update their blocks. After updating the blocks, a global model aggregation takes place at every miner in a distributed manner without the need for centralized aggregation server. Although using blockchain-based miners for global model aggregation in a distributed manner suffers from significant computational complexity due to running a consensus algorithm, it offers the advantage of robustness without the need for a centralized aggregation server. A centralized aggregation server malfunctions due to a security attack or physical damage. Next, we discuss various federated learning schemes depending mainly on various aggregation schemes.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Federated Learning Schemes</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.17" class="ltx_p">In this subsection, we present various federated learning schemes. These schemes use different strategies to account for the challenges that are involved in distributed learning systems. The two main challenges in federated learning are:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">System heterogeneity refers to the variations in end-devices features (i.e., computational resource (<math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="CPU-cycles/sec" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mrow id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mrow id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2.2" xref="S2.I1.i1.p1.1.m1.1.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.2.1" xref="S2.I1.i1.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.2.3" xref="S2.I1.i1.p1.1.m1.1.1.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.2.1a" xref="S2.I1.i1.p1.1.m1.1.1.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.2.4" xref="S2.I1.i1.p1.1.m1.1.1.2.4.cmml">U</mi></mrow><mo id="S2.I1.i1.p1.1.m1.1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.1.cmml">−</mo><mrow id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml"><mrow id="S2.I1.i1.p1.1.m1.1.1.3.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.cmml"><mrow id="S2.I1.i1.p1.1.m1.1.1.3.2.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.3" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1a" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.4" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1b" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.5" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1c" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.6" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1d" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.2.7" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.7.cmml">s</mi></mrow><mo id="S2.I1.i1.p1.1.m1.1.1.3.2.1" xref="S2.I1.i1.p1.1.m1.1.1.3.2.1.cmml">/</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.2.3" xref="S2.I1.i1.p1.1.m1.1.1.3.2.3.cmml">s</mi></mrow><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.1" xref="S2.I1.i1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.3" xref="S2.I1.i1.p1.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.1.m1.1.1.3.1a" xref="S2.I1.i1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.4" xref="S2.I1.i1.p1.1.m1.1.1.3.4.cmml">c</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><minus id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1"></minus><apply id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2"><times id="S2.I1.i1.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.1"></times><ci id="S2.I1.i1.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.2">𝐶</ci><ci id="S2.I1.i1.p1.1.m1.1.1.2.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.3">𝑃</ci><ci id="S2.I1.i1.p1.1.m1.1.1.2.4.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.4">𝑈</ci></apply><apply id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3"><times id="S2.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.1"></times><apply id="S2.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2"><divide id="S2.I1.i1.p1.1.m1.1.1.3.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.1"></divide><apply id="S2.I1.i1.p1.1.m1.1.1.3.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2"><times id="S2.I1.i1.p1.1.m1.1.1.3.2.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.1"></times><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.2">𝑐</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.3">𝑦</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.4.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.4">𝑐</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.5.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.5">𝑙</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.6.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.6">𝑒</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.2.7.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.2.7">𝑠</ci></apply><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2.3">𝑠</ci></apply><ci id="S2.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.3">𝑒</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.4.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">CPU-cycles/sec</annotation></semantics></math>), backup power, etc.) and wireless channel uncertainties.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Data heterogeneity refers to unbalanced local datasets and non-IID data among end-devices.</p>
</div>
</li>
</ul>
<p id="S2.SS2.p1.16" class="ltx_p">To show how federated learning model is trained, consider a set <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\mathcal{N}</annotation></semantics></math> of <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">N</annotation></semantics></math> devices. Every device <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">n</annotation></semantics></math> has a local dataset <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="d_{n}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">d</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝑑</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">d_{n}</annotation></semantics></math> of <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="k_{n}" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><msub id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">k</mi><mi id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">𝑘</ci><ci id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">k_{n}</annotation></semantics></math> data points. The goal of federated learning is to minimize the global loss function <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="f_{\textrm{FL}}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><msub id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">f</mi><mtext id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3a.cmml">FL</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2">𝑓</ci><ci id="S2.SS2.p1.6.m6.1.1.3a.cmml" xref="S2.SS2.p1.6.m6.1.1.3"><mtext mathsize="70%" id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3">FL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">f_{\textrm{FL}}</annotation></semantics></math>, i.e., <math id="S2.SS2.p1.7.m7.1" class="ltx_Math" alttext="\underset{\bm{\omega}}{\text{min}}\frac{1}{K}\sum_{n=1}^{N}\sum_{k=1}^{k_{n}}{f_{k}(\bm{\omega})}" display="inline"><semantics id="S2.SS2.p1.7.m7.1a"><mrow id="S2.SS2.p1.7.m7.1.2" xref="S2.SS2.p1.7.m7.1.2.cmml"><munder accentunder="true" id="S2.SS2.p1.7.m7.1.2.2" xref="S2.SS2.p1.7.m7.1.2.2.cmml"><mtext id="S2.SS2.p1.7.m7.1.2.2.2" xref="S2.SS2.p1.7.m7.1.2.2.2a.cmml">min</mtext><mo id="S2.SS2.p1.7.m7.1.2.2.1" xref="S2.SS2.p1.7.m7.1.2.2.1.cmml">𝝎</mo></munder><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m7.1.2.1" xref="S2.SS2.p1.7.m7.1.2.1.cmml">​</mo><mfrac id="S2.SS2.p1.7.m7.1.2.3" xref="S2.SS2.p1.7.m7.1.2.3.cmml"><mn id="S2.SS2.p1.7.m7.1.2.3.2" xref="S2.SS2.p1.7.m7.1.2.3.2.cmml">1</mn><mi id="S2.SS2.p1.7.m7.1.2.3.3" xref="S2.SS2.p1.7.m7.1.2.3.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m7.1.2.1a" xref="S2.SS2.p1.7.m7.1.2.1.cmml">​</mo><mrow id="S2.SS2.p1.7.m7.1.2.4" xref="S2.SS2.p1.7.m7.1.2.4.cmml"><msubsup id="S2.SS2.p1.7.m7.1.2.4.1" xref="S2.SS2.p1.7.m7.1.2.4.1.cmml"><mo rspace="0em" id="S2.SS2.p1.7.m7.1.2.4.1.2.2" xref="S2.SS2.p1.7.m7.1.2.4.1.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.7.m7.1.2.4.1.2.3" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.cmml"><mi id="S2.SS2.p1.7.m7.1.2.4.1.2.3.2" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.2.cmml">n</mi><mo id="S2.SS2.p1.7.m7.1.2.4.1.2.3.1" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.7.m7.1.2.4.1.2.3.3" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p1.7.m7.1.2.4.1.3" xref="S2.SS2.p1.7.m7.1.2.4.1.3.cmml">N</mi></msubsup><mrow id="S2.SS2.p1.7.m7.1.2.4.2" xref="S2.SS2.p1.7.m7.1.2.4.2.cmml"><msubsup id="S2.SS2.p1.7.m7.1.2.4.2.1" xref="S2.SS2.p1.7.m7.1.2.4.2.1.cmml"><mo id="S2.SS2.p1.7.m7.1.2.4.2.1.2.2" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.cmml"><mi id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.2" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.2.cmml">k</mi><mo id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.1" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.3" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.3.cmml">1</mn></mrow><msub id="S2.SS2.p1.7.m7.1.2.4.2.1.3" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3.cmml"><mi id="S2.SS2.p1.7.m7.1.2.4.2.1.3.2" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3.2.cmml">k</mi><mi id="S2.SS2.p1.7.m7.1.2.4.2.1.3.3" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3.3.cmml">n</mi></msub></msubsup><mrow id="S2.SS2.p1.7.m7.1.2.4.2.2" xref="S2.SS2.p1.7.m7.1.2.4.2.2.cmml"><msub id="S2.SS2.p1.7.m7.1.2.4.2.2.2" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2.cmml"><mi id="S2.SS2.p1.7.m7.1.2.4.2.2.2.2" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2.2.cmml">f</mi><mi id="S2.SS2.p1.7.m7.1.2.4.2.2.2.3" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m7.1.2.4.2.2.1" xref="S2.SS2.p1.7.m7.1.2.4.2.2.1.cmml">​</mo><mrow id="S2.SS2.p1.7.m7.1.2.4.2.2.3.2" xref="S2.SS2.p1.7.m7.1.2.4.2.2.cmml"><mo stretchy="false" id="S2.SS2.p1.7.m7.1.2.4.2.2.3.2.1" xref="S2.SS2.p1.7.m7.1.2.4.2.2.cmml">(</mo><mi id="S2.SS2.p1.7.m7.1.1" xref="S2.SS2.p1.7.m7.1.1.cmml">𝝎</mi><mo stretchy="false" id="S2.SS2.p1.7.m7.1.2.4.2.2.3.2.2" xref="S2.SS2.p1.7.m7.1.2.4.2.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m7.1b"><apply id="S2.SS2.p1.7.m7.1.2.cmml" xref="S2.SS2.p1.7.m7.1.2"><times id="S2.SS2.p1.7.m7.1.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.1"></times><apply id="S2.SS2.p1.7.m7.1.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.2"><ci id="S2.SS2.p1.7.m7.1.2.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.2.1">𝝎</ci><ci id="S2.SS2.p1.7.m7.1.2.2.2a.cmml" xref="S2.SS2.p1.7.m7.1.2.2.2"><mtext id="S2.SS2.p1.7.m7.1.2.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.2.2">min</mtext></ci></apply><apply id="S2.SS2.p1.7.m7.1.2.3.cmml" xref="S2.SS2.p1.7.m7.1.2.3"><divide id="S2.SS2.p1.7.m7.1.2.3.1.cmml" xref="S2.SS2.p1.7.m7.1.2.3"></divide><cn type="integer" id="S2.SS2.p1.7.m7.1.2.3.2.cmml" xref="S2.SS2.p1.7.m7.1.2.3.2">1</cn><ci id="S2.SS2.p1.7.m7.1.2.3.3.cmml" xref="S2.SS2.p1.7.m7.1.2.3.3">𝐾</ci></apply><apply id="S2.SS2.p1.7.m7.1.2.4.cmml" xref="S2.SS2.p1.7.m7.1.2.4"><apply id="S2.SS2.p1.7.m7.1.2.4.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.1.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1">superscript</csymbol><apply id="S2.SS2.p1.7.m7.1.2.4.1.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.1.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1">subscript</csymbol><sum id="S2.SS2.p1.7.m7.1.2.4.1.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.2.2"></sum><apply id="S2.SS2.p1.7.m7.1.2.4.1.2.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3"><eq id="S2.SS2.p1.7.m7.1.2.4.1.2.3.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.1"></eq><ci id="S2.SS2.p1.7.m7.1.2.4.1.2.3.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.2">𝑛</ci><cn type="integer" id="S2.SS2.p1.7.m7.1.2.4.1.2.3.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p1.7.m7.1.2.4.1.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.1.3">𝑁</ci></apply><apply id="S2.SS2.p1.7.m7.1.2.4.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2"><apply id="S2.SS2.p1.7.m7.1.2.4.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.2.1.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1">superscript</csymbol><apply id="S2.SS2.p1.7.m7.1.2.4.2.1.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.2.1.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1">subscript</csymbol><sum id="S2.SS2.p1.7.m7.1.2.4.2.1.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.2"></sum><apply id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3"><eq id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.1"></eq><ci id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.p1.7.m7.1.2.4.2.1.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.2.1.3.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3">subscript</csymbol><ci id="S2.SS2.p1.7.m7.1.2.4.2.1.3.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3.2">𝑘</ci><ci id="S2.SS2.p1.7.m7.1.2.4.2.1.3.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.1.3.3">𝑛</ci></apply></apply><apply id="S2.SS2.p1.7.m7.1.2.4.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2"><times id="S2.SS2.p1.7.m7.1.2.4.2.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2.1"></times><apply id="S2.SS2.p1.7.m7.1.2.4.2.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.2.4.2.2.2.1.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.7.m7.1.2.4.2.2.2.2.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2.2">𝑓</ci><ci id="S2.SS2.p1.7.m7.1.2.4.2.2.2.3.cmml" xref="S2.SS2.p1.7.m7.1.2.4.2.2.2.3">𝑘</ci></apply><ci id="S2.SS2.p1.7.m7.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1">𝝎</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m7.1c">\underset{\bm{\omega}}{\text{min}}\frac{1}{K}\sum_{n=1}^{N}\sum_{k=1}^{k_{n}}{f_{k}(\bm{\omega})}</annotation></semantics></math>. Where <math id="S2.SS2.p1.8.m8.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S2.SS2.p1.8.m8.1a"><mi id="S2.SS2.p1.8.m8.1.1" xref="S2.SS2.p1.8.m8.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m8.1b"><ci id="S2.SS2.p1.8.m8.1.1.cmml" xref="S2.SS2.p1.8.m8.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m8.1c">\omega</annotation></semantics></math> and <math id="S2.SS2.p1.9.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS2.p1.9.m9.1a"><mi id="S2.SS2.p1.9.m9.1.1" xref="S2.SS2.p1.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m9.1b"><ci id="S2.SS2.p1.9.m9.1.1.cmml" xref="S2.SS2.p1.9.m9.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m9.1c">K</annotation></semantics></math> represent the global model weights and total data points of all devices involved in learning, respectively. The nature of the loss function <math id="S2.SS2.p1.10.m10.1" class="ltx_Math" alttext="f_{\textrm{FL}}" display="inline"><semantics id="S2.SS2.p1.10.m10.1a"><msub id="S2.SS2.p1.10.m10.1.1" xref="S2.SS2.p1.10.m10.1.1.cmml"><mi id="S2.SS2.p1.10.m10.1.1.2" xref="S2.SS2.p1.10.m10.1.1.2.cmml">f</mi><mtext id="S2.SS2.p1.10.m10.1.1.3" xref="S2.SS2.p1.10.m10.1.1.3a.cmml">FL</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.10.m10.1b"><apply id="S2.SS2.p1.10.m10.1.1.cmml" xref="S2.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m10.1.1.1.cmml" xref="S2.SS2.p1.10.m10.1.1">subscript</csymbol><ci id="S2.SS2.p1.10.m10.1.1.2.cmml" xref="S2.SS2.p1.10.m10.1.1.2">𝑓</ci><ci id="S2.SS2.p1.10.m10.1.1.3a.cmml" xref="S2.SS2.p1.10.m10.1.1.3"><mtext mathsize="70%" id="S2.SS2.p1.10.m10.1.1.3.cmml" xref="S2.SS2.p1.10.m10.1.1.3">FL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.10.m10.1c">f_{\textrm{FL}}</annotation></semantics></math> depends on problem. For instance, prediction error can be the loss function for prediction of a time series, whereas classification error for classification tasks. One way to train a global machine learning model for a set of devices with local dataset is through stochastic gradient descent (SGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. However, typically SGD involves one device in training of a local learning model during one communication round that may take long time for convergence. Therefore, one must modify the SGD algorithm for federated setting. In federated SGD, for all end-devices (i.e., fraction of clients <math id="S2.SS2.p1.11.m11.1" class="ltx_Math" alttext="C=1" display="inline"><semantics id="S2.SS2.p1.11.m11.1a"><mrow id="S2.SS2.p1.11.m11.1.1" xref="S2.SS2.p1.11.m11.1.1.cmml"><mi id="S2.SS2.p1.11.m11.1.1.2" xref="S2.SS2.p1.11.m11.1.1.2.cmml">C</mi><mo id="S2.SS2.p1.11.m11.1.1.1" xref="S2.SS2.p1.11.m11.1.1.1.cmml">=</mo><mn id="S2.SS2.p1.11.m11.1.1.3" xref="S2.SS2.p1.11.m11.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.11.m11.1b"><apply id="S2.SS2.p1.11.m11.1.1.cmml" xref="S2.SS2.p1.11.m11.1.1"><eq id="S2.SS2.p1.11.m11.1.1.1.cmml" xref="S2.SS2.p1.11.m11.1.1.1"></eq><ci id="S2.SS2.p1.11.m11.1.1.2.cmml" xref="S2.SS2.p1.11.m11.1.1.2">𝐶</ci><cn type="integer" id="S2.SS2.p1.11.m11.1.1.3.cmml" xref="S2.SS2.p1.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.11.m11.1c">C=1</annotation></semantics></math>) and learning rate <math id="S2.SS2.p1.12.m12.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SS2.p1.12.m12.1a"><mi id="S2.SS2.p1.12.m12.1.1" xref="S2.SS2.p1.12.m12.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.12.m12.1b"><ci id="S2.SS2.p1.12.m12.1.1.cmml" xref="S2.SS2.p1.12.m12.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.12.m12.1c">\eta</annotation></semantics></math>, every client computes <math id="S2.SS2.p1.13.m13.1" class="ltx_Math" alttext="g_{n}=\bigtriangledown F_{n}(\bm{\omega})" display="inline"><semantics id="S2.SS2.p1.13.m13.1a"><mrow id="S2.SS2.p1.13.m13.1.2" xref="S2.SS2.p1.13.m13.1.2.cmml"><msub id="S2.SS2.p1.13.m13.1.2.2" xref="S2.SS2.p1.13.m13.1.2.2.cmml"><mi id="S2.SS2.p1.13.m13.1.2.2.2" xref="S2.SS2.p1.13.m13.1.2.2.2.cmml">g</mi><mi id="S2.SS2.p1.13.m13.1.2.2.3" xref="S2.SS2.p1.13.m13.1.2.2.3.cmml">n</mi></msub><mo rspace="0.1389em" id="S2.SS2.p1.13.m13.1.2.1" xref="S2.SS2.p1.13.m13.1.2.1.cmml">=</mo><mrow id="S2.SS2.p1.13.m13.1.2.3" xref="S2.SS2.p1.13.m13.1.2.3.cmml"><mo lspace="0.1389em" rspace="0em" id="S2.SS2.p1.13.m13.1.2.3a" xref="S2.SS2.p1.13.m13.1.2.3.cmml">▽</mo><mrow id="S2.SS2.p1.13.m13.1.2.3.2" xref="S2.SS2.p1.13.m13.1.2.3.2.cmml"><msub id="S2.SS2.p1.13.m13.1.2.3.2.2" xref="S2.SS2.p1.13.m13.1.2.3.2.2.cmml"><mi id="S2.SS2.p1.13.m13.1.2.3.2.2.2" xref="S2.SS2.p1.13.m13.1.2.3.2.2.2.cmml">F</mi><mi id="S2.SS2.p1.13.m13.1.2.3.2.2.3" xref="S2.SS2.p1.13.m13.1.2.3.2.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.p1.13.m13.1.2.3.2.1" xref="S2.SS2.p1.13.m13.1.2.3.2.1.cmml">​</mo><mrow id="S2.SS2.p1.13.m13.1.2.3.2.3.2" xref="S2.SS2.p1.13.m13.1.2.3.2.cmml"><mo stretchy="false" id="S2.SS2.p1.13.m13.1.2.3.2.3.2.1" xref="S2.SS2.p1.13.m13.1.2.3.2.cmml">(</mo><mi id="S2.SS2.p1.13.m13.1.1" xref="S2.SS2.p1.13.m13.1.1.cmml">𝝎</mi><mo stretchy="false" id="S2.SS2.p1.13.m13.1.2.3.2.3.2.2" xref="S2.SS2.p1.13.m13.1.2.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.13.m13.1b"><apply id="S2.SS2.p1.13.m13.1.2.cmml" xref="S2.SS2.p1.13.m13.1.2"><eq id="S2.SS2.p1.13.m13.1.2.1.cmml" xref="S2.SS2.p1.13.m13.1.2.1"></eq><apply id="S2.SS2.p1.13.m13.1.2.2.cmml" xref="S2.SS2.p1.13.m13.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m13.1.2.2.1.cmml" xref="S2.SS2.p1.13.m13.1.2.2">subscript</csymbol><ci id="S2.SS2.p1.13.m13.1.2.2.2.cmml" xref="S2.SS2.p1.13.m13.1.2.2.2">𝑔</ci><ci id="S2.SS2.p1.13.m13.1.2.2.3.cmml" xref="S2.SS2.p1.13.m13.1.2.2.3">𝑛</ci></apply><apply id="S2.SS2.p1.13.m13.1.2.3.cmml" xref="S2.SS2.p1.13.m13.1.2.3"><ci id="S2.SS2.p1.13.m13.1.2.3.1.cmml" xref="S2.SS2.p1.13.m13.1.2.3">▽</ci><apply id="S2.SS2.p1.13.m13.1.2.3.2.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2"><times id="S2.SS2.p1.13.m13.1.2.3.2.1.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2.1"></times><apply id="S2.SS2.p1.13.m13.1.2.3.2.2.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m13.1.2.3.2.2.1.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.13.m13.1.2.3.2.2.2.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2.2.2">𝐹</ci><ci id="S2.SS2.p1.13.m13.1.2.3.2.2.3.cmml" xref="S2.SS2.p1.13.m13.1.2.3.2.2.3">𝑛</ci></apply><ci id="S2.SS2.p1.13.m13.1.1.cmml" xref="S2.SS2.p1.13.m13.1.1">𝝎</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.13.m13.1c">g_{n}=\bigtriangledown F_{n}(\bm{\omega})</annotation></semantics></math> (where <math id="S2.SS2.p1.14.m14.1" class="ltx_Math" alttext="F_{n}=\frac{1}{K_{n}}\sum_{k=1}^{k_{n}}{f_{k}(\bm{w})}" display="inline"><semantics id="S2.SS2.p1.14.m14.1a"><mrow id="S2.SS2.p1.14.m14.1.2" xref="S2.SS2.p1.14.m14.1.2.cmml"><msub id="S2.SS2.p1.14.m14.1.2.2" xref="S2.SS2.p1.14.m14.1.2.2.cmml"><mi id="S2.SS2.p1.14.m14.1.2.2.2" xref="S2.SS2.p1.14.m14.1.2.2.2.cmml">F</mi><mi id="S2.SS2.p1.14.m14.1.2.2.3" xref="S2.SS2.p1.14.m14.1.2.2.3.cmml">n</mi></msub><mo id="S2.SS2.p1.14.m14.1.2.1" xref="S2.SS2.p1.14.m14.1.2.1.cmml">=</mo><mrow id="S2.SS2.p1.14.m14.1.2.3" xref="S2.SS2.p1.14.m14.1.2.3.cmml"><mfrac id="S2.SS2.p1.14.m14.1.2.3.2" xref="S2.SS2.p1.14.m14.1.2.3.2.cmml"><mn id="S2.SS2.p1.14.m14.1.2.3.2.2" xref="S2.SS2.p1.14.m14.1.2.3.2.2.cmml">1</mn><msub id="S2.SS2.p1.14.m14.1.2.3.2.3" xref="S2.SS2.p1.14.m14.1.2.3.2.3.cmml"><mi id="S2.SS2.p1.14.m14.1.2.3.2.3.2" xref="S2.SS2.p1.14.m14.1.2.3.2.3.2.cmml">K</mi><mi id="S2.SS2.p1.14.m14.1.2.3.2.3.3" xref="S2.SS2.p1.14.m14.1.2.3.2.3.3.cmml">n</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p1.14.m14.1.2.3.1" xref="S2.SS2.p1.14.m14.1.2.3.1.cmml">​</mo><mrow id="S2.SS2.p1.14.m14.1.2.3.3" xref="S2.SS2.p1.14.m14.1.2.3.3.cmml"><msubsup id="S2.SS2.p1.14.m14.1.2.3.3.1" xref="S2.SS2.p1.14.m14.1.2.3.3.1.cmml"><mo id="S2.SS2.p1.14.m14.1.2.3.3.1.2.2" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.cmml"><mi id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.2" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.1" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.3" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.3.cmml">1</mn></mrow><msub id="S2.SS2.p1.14.m14.1.2.3.3.1.3" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3.cmml"><mi id="S2.SS2.p1.14.m14.1.2.3.3.1.3.2" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3.2.cmml">k</mi><mi id="S2.SS2.p1.14.m14.1.2.3.3.1.3.3" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3.3.cmml">n</mi></msub></msubsup><mrow id="S2.SS2.p1.14.m14.1.2.3.3.2" xref="S2.SS2.p1.14.m14.1.2.3.3.2.cmml"><msub id="S2.SS2.p1.14.m14.1.2.3.3.2.2" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2.cmml"><mi id="S2.SS2.p1.14.m14.1.2.3.3.2.2.2" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2.2.cmml">f</mi><mi id="S2.SS2.p1.14.m14.1.2.3.3.2.2.3" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.p1.14.m14.1.2.3.3.2.1" xref="S2.SS2.p1.14.m14.1.2.3.3.2.1.cmml">​</mo><mrow id="S2.SS2.p1.14.m14.1.2.3.3.2.3.2" xref="S2.SS2.p1.14.m14.1.2.3.3.2.cmml"><mo stretchy="false" id="S2.SS2.p1.14.m14.1.2.3.3.2.3.2.1" xref="S2.SS2.p1.14.m14.1.2.3.3.2.cmml">(</mo><mi id="S2.SS2.p1.14.m14.1.1" xref="S2.SS2.p1.14.m14.1.1.cmml">𝒘</mi><mo stretchy="false" id="S2.SS2.p1.14.m14.1.2.3.3.2.3.2.2" xref="S2.SS2.p1.14.m14.1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.14.m14.1b"><apply id="S2.SS2.p1.14.m14.1.2.cmml" xref="S2.SS2.p1.14.m14.1.2"><eq id="S2.SS2.p1.14.m14.1.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.1"></eq><apply id="S2.SS2.p1.14.m14.1.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.2">subscript</csymbol><ci id="S2.SS2.p1.14.m14.1.2.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.2.2">𝐹</ci><ci id="S2.SS2.p1.14.m14.1.2.2.3.cmml" xref="S2.SS2.p1.14.m14.1.2.2.3">𝑛</ci></apply><apply id="S2.SS2.p1.14.m14.1.2.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3"><times id="S2.SS2.p1.14.m14.1.2.3.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.1"></times><apply id="S2.SS2.p1.14.m14.1.2.3.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2"><divide id="S2.SS2.p1.14.m14.1.2.3.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2"></divide><cn type="integer" id="S2.SS2.p1.14.m14.1.2.3.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2.2">1</cn><apply id="S2.SS2.p1.14.m14.1.2.3.2.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.3.2.3.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2.3">subscript</csymbol><ci id="S2.SS2.p1.14.m14.1.2.3.2.3.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2.3.2">𝐾</ci><ci id="S2.SS2.p1.14.m14.1.2.3.2.3.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.2.3.3">𝑛</ci></apply></apply><apply id="S2.SS2.p1.14.m14.1.2.3.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3"><apply id="S2.SS2.p1.14.m14.1.2.3.3.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.3.3.1.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1">superscript</csymbol><apply id="S2.SS2.p1.14.m14.1.2.3.3.1.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.3.3.1.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1">subscript</csymbol><sum id="S2.SS2.p1.14.m14.1.2.3.3.1.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.2"></sum><apply id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3"><eq id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.1"></eq><ci id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.p1.14.m14.1.2.3.3.1.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.3.3.1.3.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3">subscript</csymbol><ci id="S2.SS2.p1.14.m14.1.2.3.3.1.3.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3.2">𝑘</ci><ci id="S2.SS2.p1.14.m14.1.2.3.3.1.3.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.1.3.3">𝑛</ci></apply></apply><apply id="S2.SS2.p1.14.m14.1.2.3.3.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2"><times id="S2.SS2.p1.14.m14.1.2.3.3.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2.1"></times><apply id="S2.SS2.p1.14.m14.1.2.3.3.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.2.3.3.2.2.1.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.14.m14.1.2.3.3.2.2.2.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2.2">𝑓</ci><ci id="S2.SS2.p1.14.m14.1.2.3.3.2.2.3.cmml" xref="S2.SS2.p1.14.m14.1.2.3.3.2.2.3">𝑘</ci></apply><ci id="S2.SS2.p1.14.m14.1.1.cmml" xref="S2.SS2.p1.14.m14.1.1">𝒘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.14.m14.1c">F_{n}=\frac{1}{K_{n}}\sum_{k=1}^{k_{n}}{f_{k}(\bm{w})}</annotation></semantics></math> is computed once using their local dataset <math id="S2.SS2.p1.15.m15.1" class="ltx_Math" alttext="d_{n}" display="inline"><semantics id="S2.SS2.p1.15.m15.1a"><msub id="S2.SS2.p1.15.m15.1.1" xref="S2.SS2.p1.15.m15.1.1.cmml"><mi id="S2.SS2.p1.15.m15.1.1.2" xref="S2.SS2.p1.15.m15.1.1.2.cmml">d</mi><mi id="S2.SS2.p1.15.m15.1.1.3" xref="S2.SS2.p1.15.m15.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.15.m15.1b"><apply id="S2.SS2.p1.15.m15.1.1.cmml" xref="S2.SS2.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.15.m15.1.1.1.cmml" xref="S2.SS2.p1.15.m15.1.1">subscript</csymbol><ci id="S2.SS2.p1.15.m15.1.1.2.cmml" xref="S2.SS2.p1.15.m15.1.1.2">𝑑</ci><ci id="S2.SS2.p1.15.m15.1.1.3.cmml" xref="S2.SS2.p1.15.m15.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.15.m15.1c">d_{n}</annotation></semantics></math>). Then all the local models are aggregated and the update <math id="S2.SS2.p1.16.m16.1" class="ltx_Math" alttext="\bm{\omega}^{t+1}\leftarrow\bm{\omega}^{t}-\eta\sum_{n=1}^{N}{\frac{k_{n}}{{K}}g_{n}}" display="inline"><semantics id="S2.SS2.p1.16.m16.1a"><mrow id="S2.SS2.p1.16.m16.1.1" xref="S2.SS2.p1.16.m16.1.1.cmml"><msup id="S2.SS2.p1.16.m16.1.1.2" xref="S2.SS2.p1.16.m16.1.1.2.cmml"><mi id="S2.SS2.p1.16.m16.1.1.2.2" xref="S2.SS2.p1.16.m16.1.1.2.2.cmml">𝝎</mi><mrow id="S2.SS2.p1.16.m16.1.1.2.3" xref="S2.SS2.p1.16.m16.1.1.2.3.cmml"><mi id="S2.SS2.p1.16.m16.1.1.2.3.2" xref="S2.SS2.p1.16.m16.1.1.2.3.2.cmml">t</mi><mo id="S2.SS2.p1.16.m16.1.1.2.3.1" xref="S2.SS2.p1.16.m16.1.1.2.3.1.cmml">+</mo><mn id="S2.SS2.p1.16.m16.1.1.2.3.3" xref="S2.SS2.p1.16.m16.1.1.2.3.3.cmml">1</mn></mrow></msup><mo stretchy="false" id="S2.SS2.p1.16.m16.1.1.1" xref="S2.SS2.p1.16.m16.1.1.1.cmml">←</mo><mrow id="S2.SS2.p1.16.m16.1.1.3" xref="S2.SS2.p1.16.m16.1.1.3.cmml"><msup id="S2.SS2.p1.16.m16.1.1.3.2" xref="S2.SS2.p1.16.m16.1.1.3.2.cmml"><mi id="S2.SS2.p1.16.m16.1.1.3.2.2" xref="S2.SS2.p1.16.m16.1.1.3.2.2.cmml">𝝎</mi><mi id="S2.SS2.p1.16.m16.1.1.3.2.3" xref="S2.SS2.p1.16.m16.1.1.3.2.3.cmml">t</mi></msup><mo id="S2.SS2.p1.16.m16.1.1.3.1" xref="S2.SS2.p1.16.m16.1.1.3.1.cmml">−</mo><mrow id="S2.SS2.p1.16.m16.1.1.3.3" xref="S2.SS2.p1.16.m16.1.1.3.3.cmml"><mi id="S2.SS2.p1.16.m16.1.1.3.3.2" xref="S2.SS2.p1.16.m16.1.1.3.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.16.m16.1.1.3.3.1" xref="S2.SS2.p1.16.m16.1.1.3.3.1.cmml">​</mo><mrow id="S2.SS2.p1.16.m16.1.1.3.3.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.cmml"><msubsup id="S2.SS2.p1.16.m16.1.1.3.3.3.1" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.cmml"><mo id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.2.cmml">∑</mo><mrow id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.cmml"><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.2.cmml">n</mi><mo id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.1" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.1.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.3.cmml">N</mi></msubsup><mrow id="S2.SS2.p1.16.m16.1.1.3.3.3.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.cmml"><mfrac id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.cmml"><msub id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.cmml"><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.2.cmml">k</mi><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.3.cmml">n</mi></msub><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p1.16.m16.1.1.3.3.3.2.1" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.1.cmml">​</mo><msub id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.cmml"><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.2" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.2.cmml">g</mi><mi id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.3" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.3.cmml">n</mi></msub></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.16.m16.1b"><apply id="S2.SS2.p1.16.m16.1.1.cmml" xref="S2.SS2.p1.16.m16.1.1"><ci id="S2.SS2.p1.16.m16.1.1.1.cmml" xref="S2.SS2.p1.16.m16.1.1.1">←</ci><apply id="S2.SS2.p1.16.m16.1.1.2.cmml" xref="S2.SS2.p1.16.m16.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.2">superscript</csymbol><ci id="S2.SS2.p1.16.m16.1.1.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.2.2">𝝎</ci><apply id="S2.SS2.p1.16.m16.1.1.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.2.3"><plus id="S2.SS2.p1.16.m16.1.1.2.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.2.3.1"></plus><ci id="S2.SS2.p1.16.m16.1.1.2.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.SS2.p1.16.m16.1.1.2.3.3.cmml" xref="S2.SS2.p1.16.m16.1.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.p1.16.m16.1.1.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3"><minus id="S2.SS2.p1.16.m16.1.1.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.1"></minus><apply id="S2.SS2.p1.16.m16.1.1.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.3.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.2">superscript</csymbol><ci id="S2.SS2.p1.16.m16.1.1.3.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.2.2">𝝎</ci><ci id="S2.SS2.p1.16.m16.1.1.3.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.2.3">𝑡</ci></apply><apply id="S2.SS2.p1.16.m16.1.1.3.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3"><times id="S2.SS2.p1.16.m16.1.1.3.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.1"></times><ci id="S2.SS2.p1.16.m16.1.1.3.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.2">𝜂</ci><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3"><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.3.3.3.1.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1">superscript</csymbol><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1">subscript</csymbol><sum id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.2"></sum><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3"><eq id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.1"></eq><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.2">𝑛</ci><cn type="integer" id="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.1.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.1.3">𝑁</ci></apply><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2"><times id="S2.SS2.p1.16.m16.1.1.3.3.3.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.1"></times><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2"><divide id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2"></divide><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.2">𝑘</ci><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.2.3">𝑛</ci></apply><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.2.3">𝐾</ci></apply><apply id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.1.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3">subscript</csymbol><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.2.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.2">𝑔</ci><ci id="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3.3.3.2.3.3">𝑛</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.16.m16.1c">\bm{\omega}^{t+1}\leftarrow\bm{\omega}^{t}-\eta\sum_{n=1}^{N}{\frac{k_{n}}{{K}}g_{n}}</annotation></semantics></math> is applied. Although federated SGD can enable distributed machine learning without migrating the end-devices local datasets to the centralized server for training, its performance can be further improve if we perform more local iterations before sending the local model updates to an aggregation sever. Overview of FedAvg is given in Algorithm <a href="#alg1" title="Algorithm 1 ‣ II-B Federated Learning Schemes ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> that uses multiple local iterations at devices before sending model updates to the aggregation server<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><em id="alg1.l1.2" class="ltx_emph ltx_font_bold ltx_font_italic">Aggregation Server</em>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>Weights initialization <math id="alg1.l2.m1.1" class="ltx_Math" alttext="\bm{\omega}^{0}" display="inline"><semantics id="alg1.l2.m1.1a"><msup id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">𝝎</mi><mn id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">superscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝝎</ci><cn type="integer" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\bm{\omega}^{0}</annotation></semantics></math>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span><span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span> t=0, 1,…, Global Rounds-1 <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.2.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>     <span id="alg1.l4.1" class="ltx_text">Select <math id="alg1.l4.1.m1.1" class="ltx_math_unparsed" alttext="\mathcal{N}_{s}\leftarrow m=max(C.N)" display="inline"><semantics id="alg1.l4.1.m1.1a"><mrow id="alg1.l4.1.m1.1b"><msub id="alg1.l4.1.m1.1.1"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.1.m1.1.1.2">𝒩</mi><mi id="alg1.l4.1.m1.1.1.3">s</mi></msub><mo stretchy="false" id="alg1.l4.1.m1.1.2">←</mo><mi id="alg1.l4.1.m1.1.3">m</mi><mo id="alg1.l4.1.m1.1.4">=</mo><mi id="alg1.l4.1.m1.1.5">m</mi><mi id="alg1.l4.1.m1.1.6">a</mi><mi id="alg1.l4.1.m1.1.7">x</mi><mrow id="alg1.l4.1.m1.1.8"><mo stretchy="false" id="alg1.l4.1.m1.1.8.1">(</mo><mi id="alg1.l4.1.m1.1.8.2">C</mi><mo lspace="0em" rspace="0.167em" id="alg1.l4.1.m1.1.8.3">.</mo><mi id="alg1.l4.1.m1.1.8.4">N</mi><mo stretchy="false" id="alg1.l4.1.m1.1.8.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="alg1.l4.1.m1.1c">\mathcal{N}_{s}\leftarrow m=max(C.N)</annotation></semantics></math> clients randomly.</span>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>     <span id="alg1.l5.2" class="ltx_text ltx_font_bold">for</span> For every device <math id="alg1.l5.m1.1" class="ltx_Math" alttext="n\in\mathcal{N}_{s}" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">n</mi><mo id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">∈</mo><msub id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.1.1.3.2" xref="alg1.l5.m1.1.1.3.2.cmml">𝒩</mi><mi id="alg1.l5.m1.1.1.3.3" xref="alg1.l5.m1.1.1.3.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><in id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"></in><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">𝑛</ci><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3">subscript</csymbol><ci id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3.2">𝒩</ci><ci id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">n\in\mathcal{N}_{s}</annotation></semantics></math>, parallel run. <span id="alg1.l5.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>         <math id="alg1.l6.m1.2" class="ltx_Math" alttext="\omega_{n}^{t+1}\leftarrow DeviceUpdate(n,\omega_{n}^{t})" display="inline"><semantics id="alg1.l6.m1.2a"><mrow id="alg1.l6.m1.2.2" xref="alg1.l6.m1.2.2.cmml"><msubsup id="alg1.l6.m1.2.2.3" xref="alg1.l6.m1.2.2.3.cmml"><mi id="alg1.l6.m1.2.2.3.2.2" xref="alg1.l6.m1.2.2.3.2.2.cmml">ω</mi><mi id="alg1.l6.m1.2.2.3.2.3" xref="alg1.l6.m1.2.2.3.2.3.cmml">n</mi><mrow id="alg1.l6.m1.2.2.3.3" xref="alg1.l6.m1.2.2.3.3.cmml"><mi id="alg1.l6.m1.2.2.3.3.2" xref="alg1.l6.m1.2.2.3.3.2.cmml">t</mi><mo id="alg1.l6.m1.2.2.3.3.1" xref="alg1.l6.m1.2.2.3.3.1.cmml">+</mo><mn id="alg1.l6.m1.2.2.3.3.3" xref="alg1.l6.m1.2.2.3.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="alg1.l6.m1.2.2.2" xref="alg1.l6.m1.2.2.2.cmml">←</mo><mrow id="alg1.l6.m1.2.2.1" xref="alg1.l6.m1.2.2.1.cmml"><mi id="alg1.l6.m1.2.2.1.3" xref="alg1.l6.m1.2.2.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.4" xref="alg1.l6.m1.2.2.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2a" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.5" xref="alg1.l6.m1.2.2.1.5.cmml">v</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2b" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.6" xref="alg1.l6.m1.2.2.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2c" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.7" xref="alg1.l6.m1.2.2.1.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2d" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.8" xref="alg1.l6.m1.2.2.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2e" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.9" xref="alg1.l6.m1.2.2.1.9.cmml">U</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2f" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.10" xref="alg1.l6.m1.2.2.1.10.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2g" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.11" xref="alg1.l6.m1.2.2.1.11.cmml">d</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2h" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.12" xref="alg1.l6.m1.2.2.1.12.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2i" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.13" xref="alg1.l6.m1.2.2.1.13.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2j" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mi id="alg1.l6.m1.2.2.1.14" xref="alg1.l6.m1.2.2.1.14.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m1.2.2.1.2k" xref="alg1.l6.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.l6.m1.2.2.1.1.1" xref="alg1.l6.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="alg1.l6.m1.2.2.1.1.1.2" xref="alg1.l6.m1.2.2.1.1.2.cmml">(</mo><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">n</mi><mo id="alg1.l6.m1.2.2.1.1.1.3" xref="alg1.l6.m1.2.2.1.1.2.cmml">,</mo><msubsup id="alg1.l6.m1.2.2.1.1.1.1" xref="alg1.l6.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l6.m1.2.2.1.1.1.1.2.2" xref="alg1.l6.m1.2.2.1.1.1.1.2.2.cmml">ω</mi><mi id="alg1.l6.m1.2.2.1.1.1.1.2.3" xref="alg1.l6.m1.2.2.1.1.1.1.2.3.cmml">n</mi><mi id="alg1.l6.m1.2.2.1.1.1.1.3" xref="alg1.l6.m1.2.2.1.1.1.1.3.cmml">t</mi></msubsup><mo stretchy="false" id="alg1.l6.m1.2.2.1.1.1.4" xref="alg1.l6.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.2b"><apply id="alg1.l6.m1.2.2.cmml" xref="alg1.l6.m1.2.2"><ci id="alg1.l6.m1.2.2.2.cmml" xref="alg1.l6.m1.2.2.2">←</ci><apply id="alg1.l6.m1.2.2.3.cmml" xref="alg1.l6.m1.2.2.3"><csymbol cd="ambiguous" id="alg1.l6.m1.2.2.3.1.cmml" xref="alg1.l6.m1.2.2.3">superscript</csymbol><apply id="alg1.l6.m1.2.2.3.2.cmml" xref="alg1.l6.m1.2.2.3"><csymbol cd="ambiguous" id="alg1.l6.m1.2.2.3.2.1.cmml" xref="alg1.l6.m1.2.2.3">subscript</csymbol><ci id="alg1.l6.m1.2.2.3.2.2.cmml" xref="alg1.l6.m1.2.2.3.2.2">𝜔</ci><ci id="alg1.l6.m1.2.2.3.2.3.cmml" xref="alg1.l6.m1.2.2.3.2.3">𝑛</ci></apply><apply id="alg1.l6.m1.2.2.3.3.cmml" xref="alg1.l6.m1.2.2.3.3"><plus id="alg1.l6.m1.2.2.3.3.1.cmml" xref="alg1.l6.m1.2.2.3.3.1"></plus><ci id="alg1.l6.m1.2.2.3.3.2.cmml" xref="alg1.l6.m1.2.2.3.3.2">𝑡</ci><cn type="integer" id="alg1.l6.m1.2.2.3.3.3.cmml" xref="alg1.l6.m1.2.2.3.3.3">1</cn></apply></apply><apply id="alg1.l6.m1.2.2.1.cmml" xref="alg1.l6.m1.2.2.1"><times id="alg1.l6.m1.2.2.1.2.cmml" xref="alg1.l6.m1.2.2.1.2"></times><ci id="alg1.l6.m1.2.2.1.3.cmml" xref="alg1.l6.m1.2.2.1.3">𝐷</ci><ci id="alg1.l6.m1.2.2.1.4.cmml" xref="alg1.l6.m1.2.2.1.4">𝑒</ci><ci id="alg1.l6.m1.2.2.1.5.cmml" xref="alg1.l6.m1.2.2.1.5">𝑣</ci><ci id="alg1.l6.m1.2.2.1.6.cmml" xref="alg1.l6.m1.2.2.1.6">𝑖</ci><ci id="alg1.l6.m1.2.2.1.7.cmml" xref="alg1.l6.m1.2.2.1.7">𝑐</ci><ci id="alg1.l6.m1.2.2.1.8.cmml" xref="alg1.l6.m1.2.2.1.8">𝑒</ci><ci id="alg1.l6.m1.2.2.1.9.cmml" xref="alg1.l6.m1.2.2.1.9">𝑈</ci><ci id="alg1.l6.m1.2.2.1.10.cmml" xref="alg1.l6.m1.2.2.1.10">𝑝</ci><ci id="alg1.l6.m1.2.2.1.11.cmml" xref="alg1.l6.m1.2.2.1.11">𝑑</ci><ci id="alg1.l6.m1.2.2.1.12.cmml" xref="alg1.l6.m1.2.2.1.12">𝑎</ci><ci id="alg1.l6.m1.2.2.1.13.cmml" xref="alg1.l6.m1.2.2.1.13">𝑡</ci><ci id="alg1.l6.m1.2.2.1.14.cmml" xref="alg1.l6.m1.2.2.1.14">𝑒</ci><interval closure="open" id="alg1.l6.m1.2.2.1.1.2.cmml" xref="alg1.l6.m1.2.2.1.1.1"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">𝑛</ci><apply id="alg1.l6.m1.2.2.1.1.1.1.cmml" xref="alg1.l6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l6.m1.2.2.1.1.1.1">superscript</csymbol><apply id="alg1.l6.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.2.2.1.1.1.1.2.1.cmml" xref="alg1.l6.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.2.2.1.1.1.1.2.2.cmml" xref="alg1.l6.m1.2.2.1.1.1.1.2.2">𝜔</ci><ci id="alg1.l6.m1.2.2.1.1.1.1.2.3.cmml" xref="alg1.l6.m1.2.2.1.1.1.1.2.3">𝑛</ci></apply><ci id="alg1.l6.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l6.m1.2.2.1.1.1.1.3">𝑡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.2c">\omega_{n}^{t+1}\leftarrow DeviceUpdate(n,\omega_{n}^{t})</annotation></semantics></math>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>         <math id="alg1.l7.m1.1" class="ltx_Math" alttext="\bm{\omega}^{t+1}\leftarrow\sum_{n=1}^{N_{s}}{\frac{k_{n}}{{K}}\omega_{n}^{t+1}}" display="inline"><semantics id="alg1.l7.m1.1a"><mrow id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><msup id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml"><mi id="alg1.l7.m1.1.1.2.2" xref="alg1.l7.m1.1.1.2.2.cmml">𝝎</mi><mrow id="alg1.l7.m1.1.1.2.3" xref="alg1.l7.m1.1.1.2.3.cmml"><mi id="alg1.l7.m1.1.1.2.3.2" xref="alg1.l7.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l7.m1.1.1.2.3.1" xref="alg1.l7.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.2.3.3" xref="alg1.l7.m1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo rspace="0.111em" stretchy="false" id="alg1.l7.m1.1.1.1" xref="alg1.l7.m1.1.1.1.cmml">←</mo><mrow id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml"><msubsup id="alg1.l7.m1.1.1.3.1" xref="alg1.l7.m1.1.1.3.1.cmml"><mo id="alg1.l7.m1.1.1.3.1.2.2" xref="alg1.l7.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.l7.m1.1.1.3.1.2.3" xref="alg1.l7.m1.1.1.3.1.2.3.cmml"><mi id="alg1.l7.m1.1.1.3.1.2.3.2" xref="alg1.l7.m1.1.1.3.1.2.3.2.cmml">n</mi><mo id="alg1.l7.m1.1.1.3.1.2.3.1" xref="alg1.l7.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="alg1.l7.m1.1.1.3.1.2.3.3" xref="alg1.l7.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><msub id="alg1.l7.m1.1.1.3.1.3" xref="alg1.l7.m1.1.1.3.1.3.cmml"><mi id="alg1.l7.m1.1.1.3.1.3.2" xref="alg1.l7.m1.1.1.3.1.3.2.cmml">N</mi><mi id="alg1.l7.m1.1.1.3.1.3.3" xref="alg1.l7.m1.1.1.3.1.3.3.cmml">s</mi></msub></msubsup><mrow id="alg1.l7.m1.1.1.3.2" xref="alg1.l7.m1.1.1.3.2.cmml"><mfrac id="alg1.l7.m1.1.1.3.2.2" xref="alg1.l7.m1.1.1.3.2.2.cmml"><msub id="alg1.l7.m1.1.1.3.2.2.2" xref="alg1.l7.m1.1.1.3.2.2.2.cmml"><mi id="alg1.l7.m1.1.1.3.2.2.2.2" xref="alg1.l7.m1.1.1.3.2.2.2.2.cmml">k</mi><mi id="alg1.l7.m1.1.1.3.2.2.2.3" xref="alg1.l7.m1.1.1.3.2.2.2.3.cmml">n</mi></msub><mi id="alg1.l7.m1.1.1.3.2.2.3" xref="alg1.l7.m1.1.1.3.2.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l7.m1.1.1.3.2.1" xref="alg1.l7.m1.1.1.3.2.1.cmml">​</mo><msubsup id="alg1.l7.m1.1.1.3.2.3" xref="alg1.l7.m1.1.1.3.2.3.cmml"><mi id="alg1.l7.m1.1.1.3.2.3.2.2" xref="alg1.l7.m1.1.1.3.2.3.2.2.cmml">ω</mi><mi id="alg1.l7.m1.1.1.3.2.3.2.3" xref="alg1.l7.m1.1.1.3.2.3.2.3.cmml">n</mi><mrow id="alg1.l7.m1.1.1.3.2.3.3" xref="alg1.l7.m1.1.1.3.2.3.3.cmml"><mi id="alg1.l7.m1.1.1.3.2.3.3.2" xref="alg1.l7.m1.1.1.3.2.3.3.2.cmml">t</mi><mo id="alg1.l7.m1.1.1.3.2.3.3.1" xref="alg1.l7.m1.1.1.3.2.3.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.3.2.3.3.3" xref="alg1.l7.m1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><ci id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1">←</ci><apply id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.1.cmml" xref="alg1.l7.m1.1.1.2">superscript</csymbol><ci id="alg1.l7.m1.1.1.2.2.cmml" xref="alg1.l7.m1.1.1.2.2">𝝎</ci><apply id="alg1.l7.m1.1.1.2.3.cmml" xref="alg1.l7.m1.1.1.2.3"><plus id="alg1.l7.m1.1.1.2.3.1.cmml" xref="alg1.l7.m1.1.1.2.3.1"></plus><ci id="alg1.l7.m1.1.1.2.3.2.cmml" xref="alg1.l7.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l7.m1.1.1.2.3.3.cmml" xref="alg1.l7.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3"><apply id="alg1.l7.m1.1.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.1.1.cmml" xref="alg1.l7.m1.1.1.3.1">superscript</csymbol><apply id="alg1.l7.m1.1.1.3.1.2.cmml" xref="alg1.l7.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.1.2.1.cmml" xref="alg1.l7.m1.1.1.3.1">subscript</csymbol><sum id="alg1.l7.m1.1.1.3.1.2.2.cmml" xref="alg1.l7.m1.1.1.3.1.2.2"></sum><apply id="alg1.l7.m1.1.1.3.1.2.3.cmml" xref="alg1.l7.m1.1.1.3.1.2.3"><eq id="alg1.l7.m1.1.1.3.1.2.3.1.cmml" xref="alg1.l7.m1.1.1.3.1.2.3.1"></eq><ci id="alg1.l7.m1.1.1.3.1.2.3.2.cmml" xref="alg1.l7.m1.1.1.3.1.2.3.2">𝑛</ci><cn type="integer" id="alg1.l7.m1.1.1.3.1.2.3.3.cmml" xref="alg1.l7.m1.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="alg1.l7.m1.1.1.3.1.3.cmml" xref="alg1.l7.m1.1.1.3.1.3"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.1.3">subscript</csymbol><ci id="alg1.l7.m1.1.1.3.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.1.3.2">𝑁</ci><ci id="alg1.l7.m1.1.1.3.1.3.3.cmml" xref="alg1.l7.m1.1.1.3.1.3.3">𝑠</ci></apply></apply><apply id="alg1.l7.m1.1.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.2"><times id="alg1.l7.m1.1.1.3.2.1.cmml" xref="alg1.l7.m1.1.1.3.2.1"></times><apply id="alg1.l7.m1.1.1.3.2.2.cmml" xref="alg1.l7.m1.1.1.3.2.2"><divide id="alg1.l7.m1.1.1.3.2.2.1.cmml" xref="alg1.l7.m1.1.1.3.2.2"></divide><apply id="alg1.l7.m1.1.1.3.2.2.2.cmml" xref="alg1.l7.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.2.2.2.1.cmml" xref="alg1.l7.m1.1.1.3.2.2.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.3.2.2.2.2.cmml" xref="alg1.l7.m1.1.1.3.2.2.2.2">𝑘</ci><ci id="alg1.l7.m1.1.1.3.2.2.2.3.cmml" xref="alg1.l7.m1.1.1.3.2.2.2.3">𝑛</ci></apply><ci id="alg1.l7.m1.1.1.3.2.2.3.cmml" xref="alg1.l7.m1.1.1.3.2.2.3">𝐾</ci></apply><apply id="alg1.l7.m1.1.1.3.2.3.cmml" xref="alg1.l7.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.2.3.1.cmml" xref="alg1.l7.m1.1.1.3.2.3">superscript</csymbol><apply id="alg1.l7.m1.1.1.3.2.3.2.cmml" xref="alg1.l7.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.3.2.3.2.1.cmml" xref="alg1.l7.m1.1.1.3.2.3">subscript</csymbol><ci id="alg1.l7.m1.1.1.3.2.3.2.2.cmml" xref="alg1.l7.m1.1.1.3.2.3.2.2">𝜔</ci><ci id="alg1.l7.m1.1.1.3.2.3.2.3.cmml" xref="alg1.l7.m1.1.1.3.2.3.2.3">𝑛</ci></apply><apply id="alg1.l7.m1.1.1.3.2.3.3.cmml" xref="alg1.l7.m1.1.1.3.2.3.3"><plus id="alg1.l7.m1.1.1.3.2.3.3.1.cmml" xref="alg1.l7.m1.1.1.3.2.3.3.1"></plus><ci id="alg1.l7.m1.1.1.3.2.3.3.2.cmml" xref="alg1.l7.m1.1.1.3.2.3.3.2">𝑡</ci><cn type="integer" id="alg1.l7.m1.1.1.3.2.3.3.3.cmml" xref="alg1.l7.m1.1.1.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\bm{\omega}^{t+1}\leftarrow\sum_{n=1}^{N_{s}}{\frac{k_{n}}{{K}}\omega_{n}^{t+1}}</annotation></semantics></math>

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>     <span id="alg1.l8.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span><span id="alg1.l9.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l9.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.2.1.1" class="ltx_text" style="font-size:80%;">10:</span></span><em id="alg1.l10.1" class="ltx_emph ltx_font_italic"><span id="alg1.l10.1.1" class="ltx_text ltx_font_bold">DeviceUpdate</span>(n,<math id="alg1.l10.1.m1.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="alg1.l10.1.m1.1a"><mi id="alg1.l10.1.m1.1.1" xref="alg1.l10.1.m1.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.1.m1.1b"><ci id="alg1.l10.1.m1.1.1.cmml" xref="alg1.l10.1.m1.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.1.m1.1c">\omega</annotation></semantics></math>)</em>

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.3.1.1" class="ltx_text" style="font-size:80%;">11:</span></span><span id="alg1.l11.2" class="ltx_text"><math id="alg1.l11.1.m1.1" class="ltx_Math" alttext="\mathcal{B}\leftarrow" display="inline"><semantics id="alg1.l11.1.m1.1a"><mrow id="alg1.l11.1.m1.1.1" xref="alg1.l11.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.1.m1.1.1.2" xref="alg1.l11.1.m1.1.1.2.cmml">ℬ</mi><mo stretchy="false" id="alg1.l11.1.m1.1.1.1" xref="alg1.l11.1.m1.1.1.1.cmml">←</mo><mi id="alg1.l11.1.m1.1.1.3" xref="alg1.l11.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.1.m1.1b"><apply id="alg1.l11.1.m1.1.1.cmml" xref="alg1.l11.1.m1.1.1"><ci id="alg1.l11.1.m1.1.1.1.cmml" xref="alg1.l11.1.m1.1.1.1">←</ci><ci id="alg1.l11.1.m1.1.1.2.cmml" xref="alg1.l11.1.m1.1.1.2">ℬ</ci><csymbol cd="latexml" id="alg1.l11.1.m1.1.1.3.cmml" xref="alg1.l11.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.1.m1.1c">\mathcal{B}\leftarrow</annotation></semantics></math> Split <math id="alg1.l11.2.m2.1" class="ltx_Math" alttext="d_{k}" display="inline"><semantics id="alg1.l11.2.m2.1a"><msub id="alg1.l11.2.m2.1.1" xref="alg1.l11.2.m2.1.1.cmml"><mi id="alg1.l11.2.m2.1.1.2" xref="alg1.l11.2.m2.1.1.2.cmml">d</mi><mi id="alg1.l11.2.m2.1.1.3" xref="alg1.l11.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l11.2.m2.1b"><apply id="alg1.l11.2.m2.1.1.cmml" xref="alg1.l11.2.m2.1.1"><csymbol cd="ambiguous" id="alg1.l11.2.m2.1.1.1.cmml" xref="alg1.l11.2.m2.1.1">subscript</csymbol><ci id="alg1.l11.2.m2.1.1.2.cmml" xref="alg1.l11.2.m2.1.1.2">𝑑</ci><ci id="alg1.l11.2.m2.1.1.3.cmml" xref="alg1.l11.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.2.m2.1c">d_{k}</annotation></semantics></math> into batches.</span>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span><span id="alg1.l12.2" class="ltx_text ltx_font_bold">for</span> e=0, 1, .. , Local iterations-1 <span id="alg1.l12.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>     <span id="alg1.l13.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l13.m1.1" class="ltx_Math" alttext="b\in\mathcal{B}" display="inline"><semantics id="alg1.l13.m1.1a"><mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><mi id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml">b</mi><mo id="alg1.l13.m1.1.1.1" xref="alg1.l13.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml">ℬ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><in id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1"></in><ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">𝑏</ci><ci id="alg1.l13.m1.1.1.3.cmml" xref="alg1.l13.m1.1.1.3">ℬ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">b\in\mathcal{B}</annotation></semantics></math> <span id="alg1.l13.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>         <math id="alg1.l14.m1.2" class="ltx_Math" alttext="\omega\leftarrow\omega-\eta\bigtriangledown l(\omega,b)" display="inline"><semantics id="alg1.l14.m1.2a"><mrow id="alg1.l14.m1.2.3" xref="alg1.l14.m1.2.3.cmml"><mi id="alg1.l14.m1.2.3.2" xref="alg1.l14.m1.2.3.2.cmml">ω</mi><mo stretchy="false" id="alg1.l14.m1.2.3.1" xref="alg1.l14.m1.2.3.1.cmml">←</mo><mrow id="alg1.l14.m1.2.3.3" xref="alg1.l14.m1.2.3.3.cmml"><mrow id="alg1.l14.m1.2.3.3.2" xref="alg1.l14.m1.2.3.3.2.cmml"><mi id="alg1.l14.m1.2.3.3.2.2" xref="alg1.l14.m1.2.3.3.2.2.cmml">ω</mi><mo id="alg1.l14.m1.2.3.3.2.1" xref="alg1.l14.m1.2.3.3.2.1.cmml">−</mo><mi id="alg1.l14.m1.2.3.3.2.3" xref="alg1.l14.m1.2.3.3.2.3.cmml">η</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="alg1.l14.m1.2.3.3.1" xref="alg1.l14.m1.2.3.3.1.cmml">▽</mo><mrow id="alg1.l14.m1.2.3.3.3" xref="alg1.l14.m1.2.3.3.3.cmml"><mi id="alg1.l14.m1.2.3.3.3.2" xref="alg1.l14.m1.2.3.3.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l14.m1.2.3.3.3.1" xref="alg1.l14.m1.2.3.3.3.1.cmml">​</mo><mrow id="alg1.l14.m1.2.3.3.3.3.2" xref="alg1.l14.m1.2.3.3.3.3.1.cmml"><mo stretchy="false" id="alg1.l14.m1.2.3.3.3.3.2.1" xref="alg1.l14.m1.2.3.3.3.3.1.cmml">(</mo><mi id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">ω</mi><mo id="alg1.l14.m1.2.3.3.3.3.2.2" xref="alg1.l14.m1.2.3.3.3.3.1.cmml">,</mo><mi id="alg1.l14.m1.2.2" xref="alg1.l14.m1.2.2.cmml">b</mi><mo stretchy="false" id="alg1.l14.m1.2.3.3.3.3.2.3" xref="alg1.l14.m1.2.3.3.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.2b"><apply id="alg1.l14.m1.2.3.cmml" xref="alg1.l14.m1.2.3"><ci id="alg1.l14.m1.2.3.1.cmml" xref="alg1.l14.m1.2.3.1">←</ci><ci id="alg1.l14.m1.2.3.2.cmml" xref="alg1.l14.m1.2.3.2">𝜔</ci><apply id="alg1.l14.m1.2.3.3.cmml" xref="alg1.l14.m1.2.3.3"><ci id="alg1.l14.m1.2.3.3.1.cmml" xref="alg1.l14.m1.2.3.3.1">▽</ci><apply id="alg1.l14.m1.2.3.3.2.cmml" xref="alg1.l14.m1.2.3.3.2"><minus id="alg1.l14.m1.2.3.3.2.1.cmml" xref="alg1.l14.m1.2.3.3.2.1"></minus><ci id="alg1.l14.m1.2.3.3.2.2.cmml" xref="alg1.l14.m1.2.3.3.2.2">𝜔</ci><ci id="alg1.l14.m1.2.3.3.2.3.cmml" xref="alg1.l14.m1.2.3.3.2.3">𝜂</ci></apply><apply id="alg1.l14.m1.2.3.3.3.cmml" xref="alg1.l14.m1.2.3.3.3"><times id="alg1.l14.m1.2.3.3.3.1.cmml" xref="alg1.l14.m1.2.3.3.3.1"></times><ci id="alg1.l14.m1.2.3.3.3.2.cmml" xref="alg1.l14.m1.2.3.3.3.2">𝑙</ci><interval closure="open" id="alg1.l14.m1.2.3.3.3.3.1.cmml" xref="alg1.l14.m1.2.3.3.3.3.2"><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">𝜔</ci><ci id="alg1.l14.m1.2.2.cmml" xref="alg1.l14.m1.2.2">𝑏</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.2c">\omega\leftarrow\omega-\eta\bigtriangledown l(\omega,b)</annotation></semantics></math>

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>     <span id="alg1.l15.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l15.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span><span id="alg1.l16.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l16.3" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</figure>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Although the FedAvg scheme <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> was the first work to enable distributed learning in environments with main focus on heterogeneous systems parameters, and data distributions, it seems difficult to provably get convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. This is because FedAvg is based on a simple averaging of local model updates from the end-devices at aggregation server that might not produce better results for heterogeneous environments. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> has shown that hyper parameters (i.e., local iterations, global iterations, learning rate, etc.) play an important role in convergence of FedAvg. However, for high number of local iterations, the dissimilar local objectives might lead end-devices toward their local optima rather than the global one. Therefore, we can say that FedAvg seems difficult to provably converge for heterogeneous scenarios. Furthermore, setting higher local iterations may cause some of the devices not to complete computing their local learning models within maximum allowed time. Therefore, these devices will not be able to participate in learning process for the given communication round. To cope with these limitations, FedProx was introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> that is based on adding a proximal term to local model loss function term in FedAvg.</p>
<table id="S2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1X.2.1.1.m1.4" class="ltx_Math" alttext="\displaystyle\underset{\bm{\omega}}{\text{min}}~{}h_{n}(\omega;\omega^{t})=F_{n}(\omega)+\frac{\mu}{2}\parallel\omega-\omega^{t}\parallel^{2}" display="inline"><semantics id="S2.E1X.2.1.1.m1.4a"><mrow id="S2.E1X.2.1.1.m1.4.4" xref="S2.E1X.2.1.1.m1.4.4.cmml"><mrow id="S2.E1X.2.1.1.m1.3.3.1" xref="S2.E1X.2.1.1.m1.3.3.1.cmml"><munder accentunder="true" id="S2.E1X.2.1.1.m1.3.3.1.3" xref="S2.E1X.2.1.1.m1.3.3.1.3.cmml"><mtext id="S2.E1X.2.1.1.m1.3.3.1.3.2" xref="S2.E1X.2.1.1.m1.3.3.1.3.2a.cmml">min</mtext><mo id="S2.E1X.2.1.1.m1.3.3.1.3.1" xref="S2.E1X.2.1.1.m1.3.3.1.3.1.cmml">𝝎</mo></munder><mo lspace="0.330em" rspace="0em" id="S2.E1X.2.1.1.m1.3.3.1.2" xref="S2.E1X.2.1.1.m1.3.3.1.2.cmml">​</mo><msub id="S2.E1X.2.1.1.m1.3.3.1.4" xref="S2.E1X.2.1.1.m1.3.3.1.4.cmml"><mi id="S2.E1X.2.1.1.m1.3.3.1.4.2" xref="S2.E1X.2.1.1.m1.3.3.1.4.2.cmml">h</mi><mi id="S2.E1X.2.1.1.m1.3.3.1.4.3" xref="S2.E1X.2.1.1.m1.3.3.1.4.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.3.3.1.2a" xref="S2.E1X.2.1.1.m1.3.3.1.2.cmml">​</mo><mrow id="S2.E1X.2.1.1.m1.3.3.1.1.1" xref="S2.E1X.2.1.1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.3.3.1.1.1.2" xref="S2.E1X.2.1.1.m1.3.3.1.1.2.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml">ω</mi><mo id="S2.E1X.2.1.1.m1.3.3.1.1.1.3" xref="S2.E1X.2.1.1.m1.3.3.1.1.2.cmml">;</mo><msup id="S2.E1X.2.1.1.m1.3.3.1.1.1.1" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2.cmml">ω</mi><mi id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3.cmml">t</mi></msup><mo stretchy="false" id="S2.E1X.2.1.1.m1.3.3.1.1.1.4" xref="S2.E1X.2.1.1.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1X.2.1.1.m1.4.4.3" xref="S2.E1X.2.1.1.m1.4.4.3.cmml">=</mo><mrow id="S2.E1X.2.1.1.m1.4.4.2" xref="S2.E1X.2.1.1.m1.4.4.2.cmml"><mrow id="S2.E1X.2.1.1.m1.4.4.2.3" xref="S2.E1X.2.1.1.m1.4.4.2.3.cmml"><msub id="S2.E1X.2.1.1.m1.4.4.2.3.2" xref="S2.E1X.2.1.1.m1.4.4.2.3.2.cmml"><mi id="S2.E1X.2.1.1.m1.4.4.2.3.2.2" xref="S2.E1X.2.1.1.m1.4.4.2.3.2.2.cmml">F</mi><mi id="S2.E1X.2.1.1.m1.4.4.2.3.2.3" xref="S2.E1X.2.1.1.m1.4.4.2.3.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.4.4.2.3.1" xref="S2.E1X.2.1.1.m1.4.4.2.3.1.cmml">​</mo><mrow id="S2.E1X.2.1.1.m1.4.4.2.3.3.2" xref="S2.E1X.2.1.1.m1.4.4.2.3.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.4.4.2.3.3.2.1" xref="S2.E1X.2.1.1.m1.4.4.2.3.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.2.2" xref="S2.E1X.2.1.1.m1.2.2.cmml">ω</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.4.4.2.3.3.2.2" xref="S2.E1X.2.1.1.m1.4.4.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E1X.2.1.1.m1.4.4.2.2" xref="S2.E1X.2.1.1.m1.4.4.2.2.cmml">+</mo><mrow id="S2.E1X.2.1.1.m1.4.4.2.1" xref="S2.E1X.2.1.1.m1.4.4.2.1.cmml"><mstyle displaystyle="true" id="S2.E1X.2.1.1.m1.4.4.2.1.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.cmml"><mfrac id="S2.E1X.2.1.1.m1.4.4.2.1.3a" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.cmml"><mi id="S2.E1X.2.1.1.m1.4.4.2.1.3.2" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.2.cmml">μ</mi><mn id="S2.E1X.2.1.1.m1.4.4.2.1.3.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.3.cmml">2</mn></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.4.4.2.1.2" xref="S2.E1X.2.1.1.m1.4.4.2.1.2.cmml">​</mo><msup id="S2.E1X.2.1.1.m1.4.4.2.1.1" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.cmml"><mrow id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.2" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.2.1.cmml">‖</mo><mrow id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.2" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.2.cmml">ω</mi><mo id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.1" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.1.cmml">−</mo><msup id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.cmml"><mi id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.2" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.2.cmml">ω</mi><mi id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.3.cmml">t</mi></msup></mrow><mo stretchy="false" id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S2.E1X.2.1.1.m1.4.4.2.1.1.3" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.4b"><apply id="S2.E1X.2.1.1.m1.4.4.cmml" xref="S2.E1X.2.1.1.m1.4.4"><eq id="S2.E1X.2.1.1.m1.4.4.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.3"></eq><apply id="S2.E1X.2.1.1.m1.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1"><times id="S2.E1X.2.1.1.m1.3.3.1.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.2"></times><apply id="S2.E1X.2.1.1.m1.3.3.1.3.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.3"><ci id="S2.E1X.2.1.1.m1.3.3.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.3.1">𝝎</ci><ci id="S2.E1X.2.1.1.m1.3.3.1.3.2a.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.3.2"><mtext id="S2.E1X.2.1.1.m1.3.3.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.3.2">min</mtext></ci></apply><apply id="S2.E1X.2.1.1.m1.3.3.1.4.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.4"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.3.3.1.4.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.4">subscript</csymbol><ci id="S2.E1X.2.1.1.m1.3.3.1.4.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.4.2">ℎ</ci><ci id="S2.E1X.2.1.1.m1.3.3.1.4.3.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.4.3">𝑛</ci></apply><list id="S2.E1X.2.1.1.m1.3.3.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1"><ci id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">𝜔</ci><apply id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2">𝜔</ci><ci id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3">𝑡</ci></apply></list></apply><apply id="S2.E1X.2.1.1.m1.4.4.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2"><plus id="S2.E1X.2.1.1.m1.4.4.2.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2"></plus><apply id="S2.E1X.2.1.1.m1.4.4.2.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3"><times id="S2.E1X.2.1.1.m1.4.4.2.3.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3.1"></times><apply id="S2.E1X.2.1.1.m1.4.4.2.3.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3.2"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.4.4.2.3.2.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3.2">subscript</csymbol><ci id="S2.E1X.2.1.1.m1.4.4.2.3.2.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3.2.2">𝐹</ci><ci id="S2.E1X.2.1.1.m1.4.4.2.3.2.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.3.2.3">𝑛</ci></apply><ci id="S2.E1X.2.1.1.m1.2.2.cmml" xref="S2.E1X.2.1.1.m1.2.2">𝜔</ci></apply><apply id="S2.E1X.2.1.1.m1.4.4.2.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1"><times id="S2.E1X.2.1.1.m1.4.4.2.1.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.2"></times><apply id="S2.E1X.2.1.1.m1.4.4.2.1.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.3"><divide id="S2.E1X.2.1.1.m1.4.4.2.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.3"></divide><ci id="S2.E1X.2.1.1.m1.4.4.2.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.2">𝜇</ci><cn type="integer" id="S2.E1X.2.1.1.m1.4.4.2.1.3.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.3.3">2</cn></apply><apply id="S2.E1X.2.1.1.m1.4.4.2.1.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.4.4.2.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1">superscript</csymbol><apply id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1"><csymbol cd="latexml" id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.2.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.2">norm</csymbol><apply id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1"><minus id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.1"></minus><ci id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.2">𝜔</ci><apply id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.2">𝜔</ci><ci id="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.1.1.1.3.3">𝑡</ci></apply></apply></apply><cn type="integer" id="S2.E1X.2.1.1.m1.4.4.2.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.4c">\displaystyle\underset{\bm{\omega}}{\text{min}}~{}h_{n}(\omega;\omega^{t})=F_{n}(\omega)+\frac{\mu}{2}\parallel\omega-\omega^{t}\parallel^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<p id="S2.SS2.p2.2" class="ltx_p">In (<a href="#S2.E1" title="In II-B Federated Learning Schemes ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), the proximal term offers the advantage of better addressing the statistical heterogeneity by restricting the local updates more to a global model, and thus devices heterogeneous data impact will be minimized on the local model. Both FedAvg and FedProx tried to effectively consider the effect of heterogeneous system parameters (i.e., local computational resource) and data heterogeneity (i.e., unbalanced datasets, non-independent and identical distributions), they did not study the effect of wireless channel uncertainties on the performance federated learning. For enabling federated learning over IoT networks, we must carefully handle loss in performance of federated learning due to wireless channel uncertainties. Chen <span id="S2.SS2.p2.2.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> studied the effect of wireless channel uncertainties on the performance of federated learning. They presented a framework for joint learning and communication. Moreover, they formulated a problem to minimize a federated learning cost by jointly optimizing power allocation, resource block allocation, and user selection. In another work, Tran <span id="S2.SS2.p2.2.2" class="ltx_text ltx_font_italic">et al.</span> analyzed the performance of federated learning over wireless networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. An optimization problem to minimize both energy consumption and computation time was formulated. Moreover, they provided extensive numerical results to analyze the performance of federated learning over wireless networks.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Local Learning Models</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">We present various local learning models used for computing local learning models in federated learning. The type of local learning model used strictly depends on the IoT application considered. CNN, FNN, LSTM, and SVM, among others can be used for local model computation. Table <a href="#S2.T2" title="TABLE II ‣ II-C Local Learning Models ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> lists various machine learning algorithms for IoT applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Typically, a neural network has an input layer, hidden layers, and the output layer. Increasing the number of hidden layers generally improves the performance but at the cost of computational complexity. On the other hand, the selection of a particular local learning model strictly depends on the application. For instance, CNN is normally considered for IoT tasks that are based on image classification. One can also consider simple fully connected FNN with low complexity for image classification. However, the low complexity local learning model might not perform very well. Coping with this issue, CNN with sufficient layers should be preferably used. It must be noted here that increasing the number of hidden layers does not always guarantee performance improvement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Therefore, we must properly choose network size. Furthermore, activation functions (i.e., determines output of a neural network) must be properly used in various neural networks. Activation functions can be broadly categorized into: binary step functions, linear activation functions, and non-linear activation functions. Within non-linear activation functions, there can be sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), soft-max, among others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. A summary of activation functions that can be used in various local learning model is given in Table <a href="#S2.T3" title="TABLE III ‣ II-C Local Learning Models ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. For federated learning, selection of a local learning model with low complexity and better performance is of significant interest. In contrast to the centralized machine learning, federated learning involves a massive number of end-devices with lower computational capacity than the centralized server used by centralized machine learning. Furthermore, there are energy limitations of the IoT end-devices. Keeping in the mind the aforementioned points, there is a need to use efficient local learning model for federated learning. To effectively choose the neural network size, one can use neural architecture search (NAS) to find the optimal architecture out of possible available architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. More details on how NAS can be employed for local learning models at the end-devices will be given in Section <a href="#S4.SS10" title="IV-J End-Device Design for Federated Learning ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-J</span></span></a>.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.2.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S2.T2.3.2" class="ltx_text" style="font-size:90%;">Local learning models used for IoT applications.</span></figcaption>
<table id="S2.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T2.4.1" class="ltx_tr">
<td id="S2.T2.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T2.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.1.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S2.T2.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Local learning model</span></span>
</span>
</td>
<td id="S2.T2.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T2.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.1.2.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T2.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S2.T2.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T2.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.1.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="S2.T2.4.1.3.1.1.1" class="ltx_text ltx_font_bold">Primary IoT application</span></span>
</span>
</td>
</tr>
<tr id="S2.T2.4.2" class="ltx_tr">
<td id="S2.T2.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.2.1.1.1" class="ltx_p" style="width:56.9pt;">SVM</span>
</span>
</td>
<td id="S2.T2.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.2.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.2.3.1.1" class="ltx_p" style="width:113.8pt;">Network slicing.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.3" class="ltx_tr">
<td id="S2.T2.4.3.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T2.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.3.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.3.3.1.1" class="ltx_p" style="width:113.8pt;">Malware detection.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.4" class="ltx_tr">
<td id="S2.T2.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.4.1.1.1" class="ltx_p" style="width:56.9pt;">CNN</span>
</span>
</td>
<td id="S2.T2.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.4.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.4.3.1.1" class="ltx_p" style="width:113.8pt;">Disease diagnosis based on image classification.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.5" class="ltx_tr">
<td id="S2.T2.4.5.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T2.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.5.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.5.3.1.1" class="ltx_p" style="width:113.8pt;">Caching for infotainment-enabled smart cars.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.6" class="ltx_tr">
<td id="S2.T2.4.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.6.1.1.1" class="ltx_p" style="width:56.9pt;">LSTM</span>
</span>
</td>
<td id="S2.T2.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.6.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.6.3.1.1" class="ltx_p" style="width:113.8pt;">Traffic prediction in Vehicle-to-Vehicle Communication.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.7" class="ltx_tr">
<td id="S2.T2.4.7.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T2.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.7.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.7.3.1.1" class="ltx_p" style="width:113.8pt;">Edge caching.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.8" class="ltx_tr">
<td id="S2.T2.4.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.8.1.1.1" class="ltx_p" style="width:56.9pt;">FNN</span>
</span>
</td>
<td id="S2.T2.4.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.8.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.8.3.1.1" class="ltx_p" style="width:113.8pt;">Distributed denial of service attacks detectio.n</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.9" class="ltx_tr">
<td id="S2.T2.4.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.9.1.1.1" class="ltx_p" style="width:56.9pt;">K-means</span>
</span>
</td>
<td id="S2.T2.4.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.9.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.9.3.1.1" class="ltx_p" style="width:113.8pt;">Clustering of sensor networks to minimize packet error rate.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.10" class="ltx_tr">
<td id="S2.T2.4.10.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T2.4.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.10.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.10.3.1.1" class="ltx_p" style="width:113.8pt;">Proactive caching for IoT networks.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.11" class="ltx_tr">
<td id="S2.T2.4.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.11.1.1.1" class="ltx_p" style="width:56.9pt;">RNN</span>
</span>
</td>
<td id="S2.T2.4.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.11.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.11.3.1.1" class="ltx_p" style="width:113.8pt;">Time series forecasting.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.12" class="ltx_tr">
<td id="S2.T2.4.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.12.1.1.1" class="ltx_p" style="width:56.9pt;">Naive Bayes</span>
</span>
</td>
<td id="S2.T2.4.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.12.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T2.4.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.12.3.1.1" class="ltx_p" style="width:113.8pt;">Botnets attack detection for IoT.</span>
</span>
</td>
</tr>
<tr id="S2.T2.4.13" class="ltx_tr">
<td id="S2.T2.4.13.1" class="ltx_td ltx_align_top ltx_border_bb"></td>
<td id="S2.T2.4.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T2.4.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.13.2.1.1" class="ltx_p" style="width:34.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite></span>
</span>
</td>
<td id="S2.T2.4.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T2.4.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.4.13.3.1.1" class="ltx_p" style="width:113.8pt;">Anomaly detection for IoT-Fog-Cloud computing model.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S2.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T3.17.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S2.T3.18.2" class="ltx_text" style="font-size:90%;">Summary of commonly used activation functions for local learning models.</span></figcaption>
<table id="S2.T3.15.15" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T3.15.15.16" class="ltx_tr">
<td id="S2.T3.15.15.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T3.15.15.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.16.1.1.1" class="ltx_p" style="width:65.4pt;"><span id="S2.T3.15.15.16.1.1.1.1" class="ltx_text ltx_font_bold">Activation function</span></span>
</span>
</td>
<td id="S2.T3.15.15.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T3.15.15.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.16.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S2.T3.15.15.16.2.1.1.1" class="ltx_text ltx_font_bold">Equation</span></span>
</span>
</td>
<td id="S2.T3.15.15.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T3.15.15.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.16.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.15.15.16.3.1.1.1" class="ltx_text ltx_font_bold">Derivative</span></span>
</span>
</td>
<td id="S2.T3.15.15.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T3.15.15.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.16.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.15.15.16.4.1.1.1" class="ltx_text ltx_font_bold">Diagram</span></span>
</span>
</td>
<td id="S2.T3.15.15.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T3.15.15.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.16.5.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.15.15.16.5.1.1.1" class="ltx_text ltx_font_bold">Limitation</span></span>
</span>
</td>
</tr>
<tr id="S2.T3.3.3.3" class="ltx_tr">
<td id="S2.T3.3.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.3.3.3.4.1.1" class="ltx_p" style="width:65.4pt;"><span id="S2.T3.3.3.3.4.1.1.1" class="ltx_text">Unit step function</span></span>
</span>
</td>
<td id="S2.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T3.1.1.1.1.1.1.m1.7" class="ltx_Math" alttext="f(x)=\begin{cases}0&amp;\text{if $x&lt;0$}\\
0.5&amp;\text{if $x=0$}\\
1&amp;\text{if $x&gt;0$}\\
\end{cases}" display="inline"><semantics id="S2.T3.1.1.1.1.1.1.m1.7a"><mrow id="S2.T3.1.1.1.1.1.1.m1.7.8" xref="S2.T3.1.1.1.1.1.1.m1.7.8.cmml"><mrow id="S2.T3.1.1.1.1.1.1.m1.7.8.2" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.cmml"><mi id="S2.T3.1.1.1.1.1.1.m1.7.8.2.2" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.1.1.1.1.1.1.m1.7.8.2.1" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.1.cmml">​</mo><mrow id="S2.T3.1.1.1.1.1.1.m1.7.8.2.3.2" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.cmml"><mo stretchy="false" id="S2.T3.1.1.1.1.1.1.m1.7.8.2.3.2.1" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.cmml">(</mo><mi id="S2.T3.1.1.1.1.1.1.m1.7.7" xref="S2.T3.1.1.1.1.1.1.m1.7.7.cmml">x</mi><mo stretchy="false" id="S2.T3.1.1.1.1.1.1.m1.7.8.2.3.2.2" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.1.1.1.1.1.1.m1.7.8.1" xref="S2.T3.1.1.1.1.1.1.m1.7.8.1.cmml">=</mo><mrow id="S2.T3.1.1.1.1.1.1.m1.6.6" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mo id="S2.T3.1.1.1.1.1.1.m1.6.6.7" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S2.T3.1.1.1.1.1.1.m1.6.6.6" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mtr id="S2.T3.1.1.1.1.1.1.m1.6.6.6a" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6b" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mn id="S2.T3.1.1.1.1.1.1.m1.4.4.4.4.2.1" xref="S2.T3.1.1.1.1.1.1.m1.4.4.4.4.2.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6c" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mrow id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1b.cmml"><mtext id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1b.cmml">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr><mtr id="S2.T3.1.1.1.1.1.1.m1.6.6.6d" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6e" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mn id="S2.T3.1.1.1.1.1.1.m1.5.5.5.5.2.1" xref="S2.T3.1.1.1.1.1.1.m1.5.5.5.5.2.1.cmml">0.5</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6f" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mrow id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1b.cmml"><mtext id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1a" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1b.cmml">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr><mtr id="S2.T3.1.1.1.1.1.1.m1.6.6.6g" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6h" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mn id="S2.T3.1.1.1.1.1.1.m1.6.6.6.6.2.1" xref="S2.T3.1.1.1.1.1.1.m1.6.6.6.6.2.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.1.1.1.1.1.1.m1.6.6.6i" xref="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml"><mrow id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1b.cmml"><mtext id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1a" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1b.cmml">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.2" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.1" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.3" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.1.1.1.m1.7b"><apply id="S2.T3.1.1.1.1.1.1.m1.7.8.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.8"><eq id="S2.T3.1.1.1.1.1.1.m1.7.8.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.8.1"></eq><apply id="S2.T3.1.1.1.1.1.1.m1.7.8.2.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2"><times id="S2.T3.1.1.1.1.1.1.m1.7.8.2.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.1"></times><ci id="S2.T3.1.1.1.1.1.1.m1.7.8.2.2.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.8.2.2">𝑓</ci><ci id="S2.T3.1.1.1.1.1.1.m1.7.7.cmml" xref="S2.T3.1.1.1.1.1.1.m1.7.7">𝑥</ci></apply><apply id="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.6.6"><csymbol cd="latexml" id="S2.T3.1.1.1.1.1.1.m1.7.8.3.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.6.6.7">cases</csymbol><cn type="integer" id="S2.T3.1.1.1.1.1.1.m1.4.4.4.4.2.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.4.4.4.4.2.1">0</cn><ci id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1b.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1"><mrow id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1"><mtext id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1a.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1"><mi id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1">&lt;</mo><mn id="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.1.1.1.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci><cn type="float" id="S2.T3.1.1.1.1.1.1.m1.5.5.5.5.2.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.5.5.5.5.2.1">0.5</cn><ci id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1b.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1"><mrow id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1"><mtext id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1a.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1"><mi id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1">=</mo><mn id="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.1.1.1.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci><cn type="integer" id="S2.T3.1.1.1.1.1.1.m1.6.6.6.6.2.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.6.6.6.6.2.1">1</cn><ci id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1b.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1"><mrow id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1"><mtext id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1a.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1">if </mtext><mrow id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1"><mi id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.1">&gt;</mo><mn id="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.1.1.1.1.1.1.m1.3.3.3.3.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.1.1.1.m1.7c">f(x)=\begin{cases}0&amp;\text{if $x&lt;0$}\\
0.5&amp;\text{if $x=0$}\\
1&amp;\text{if $x&gt;0$}\\
\end{cases}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.2.2.2.2.1.1" class="ltx_p" style="width:99.6pt;"><math id="S2.T3.2.2.2.2.1.1.m1.2" class="ltx_Math" alttext="f^{{}^{\prime}}(x)=\delta(t)" display="inline"><semantics id="S2.T3.2.2.2.2.1.1.m1.2a"><mrow id="S2.T3.2.2.2.2.1.1.m1.2.3" xref="S2.T3.2.2.2.2.1.1.m1.2.3.cmml"><mrow id="S2.T3.2.2.2.2.1.1.m1.2.3.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.cmml"><msup id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.cmml"><mi id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.2.cmml">f</mi><msup id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.cmml"><mi id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3a" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.cmml"></mi><mo id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.1.cmml">′</mo></msup></msup><mo lspace="0em" rspace="0em" id="S2.T3.2.2.2.2.1.1.m1.2.3.2.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.T3.2.2.2.2.1.1.m1.2.3.2.3.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.T3.2.2.2.2.1.1.m1.2.3.2.3.2.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.cmml">(</mo><mi id="S2.T3.2.2.2.2.1.1.m1.1.1" xref="S2.T3.2.2.2.2.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.2.2.2.2.1.1.m1.2.3.2.3.2.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.2.2.2.2.1.1.m1.2.3.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.1.cmml">=</mo><mrow id="S2.T3.2.2.2.2.1.1.m1.2.3.3" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.cmml"><mi id="S2.T3.2.2.2.2.1.1.m1.2.3.3.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.T3.2.2.2.2.1.1.m1.2.3.3.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.1.cmml">​</mo><mrow id="S2.T3.2.2.2.2.1.1.m1.2.3.3.3.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.cmml"><mo stretchy="false" id="S2.T3.2.2.2.2.1.1.m1.2.3.3.3.2.1" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.cmml">(</mo><mi id="S2.T3.2.2.2.2.1.1.m1.2.2" xref="S2.T3.2.2.2.2.1.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.T3.2.2.2.2.1.1.m1.2.3.3.3.2.2" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.2.2.1.1.m1.2b"><apply id="S2.T3.2.2.2.2.1.1.m1.2.3.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3"><eq id="S2.T3.2.2.2.2.1.1.m1.2.3.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.1"></eq><apply id="S2.T3.2.2.2.2.1.1.m1.2.3.2.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2"><times id="S2.T3.2.2.2.2.1.1.m1.2.3.2.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.1"></times><apply id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2">superscript</csymbol><ci id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.2.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.2">𝑓</ci><apply id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3"><ci id="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.2.2.3.1">′</ci></apply></apply><ci id="S2.T3.2.2.2.2.1.1.m1.1.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T3.2.2.2.2.1.1.m1.2.3.3.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3"><times id="S2.T3.2.2.2.2.1.1.m1.2.3.3.1.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.1"></times><ci id="S2.T3.2.2.2.2.1.1.m1.2.3.3.2.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.3.3.2">𝛿</ci><ci id="S2.T3.2.2.2.2.1.1.m1.2.2.cmml" xref="S2.T3.2.2.2.2.1.1.m1.2.2">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.2.2.1.1.m1.2c">f^{{}^{\prime}}(x)=\delta(t)</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.3.3.3.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.3.3.3.3.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2009.13012/assets/x5.png" id="S2.T3.3.3.3.3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="37" height="21" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="S2.T3.3.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.3.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.3.3.3.5.1.1" class="ltx_p" style="width:99.6pt;">Does not allow multi-value outputs (i.e., classification of inputs into several categories).</span>
</span>
</td>
</tr>
<tr id="S2.T3.6.6.6" class="ltx_tr">
<td id="S2.T3.6.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.6.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.6.6.6.4.1.1" class="ltx_p" style="width:65.4pt;">Linear function</span>
</span>
</td>
<td id="S2.T3.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.4.4.4.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T3.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="f(x)=x" display="inline"><semantics id="S2.T3.4.4.4.1.1.1.m1.1a"><mrow id="S2.T3.4.4.4.1.1.1.m1.1.2" xref="S2.T3.4.4.4.1.1.1.m1.1.2.cmml"><mrow id="S2.T3.4.4.4.1.1.1.m1.1.2.2" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.cmml"><mi id="S2.T3.4.4.4.1.1.1.m1.1.2.2.2" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.4.4.4.1.1.1.m1.1.2.2.1" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.1.cmml">​</mo><mrow id="S2.T3.4.4.4.1.1.1.m1.1.2.2.3.2" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.cmml"><mo stretchy="false" id="S2.T3.4.4.4.1.1.1.m1.1.2.2.3.2.1" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.cmml">(</mo><mi id="S2.T3.4.4.4.1.1.1.m1.1.1" xref="S2.T3.4.4.4.1.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.4.4.4.1.1.1.m1.1.2.2.3.2.2" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.4.4.4.1.1.1.m1.1.2.1" xref="S2.T3.4.4.4.1.1.1.m1.1.2.1.cmml">=</mo><mi id="S2.T3.4.4.4.1.1.1.m1.1.2.3" xref="S2.T3.4.4.4.1.1.1.m1.1.2.3.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.4.4.4.1.1.1.m1.1b"><apply id="S2.T3.4.4.4.1.1.1.m1.1.2.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2"><eq id="S2.T3.4.4.4.1.1.1.m1.1.2.1.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2.1"></eq><apply id="S2.T3.4.4.4.1.1.1.m1.1.2.2.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2"><times id="S2.T3.4.4.4.1.1.1.m1.1.2.2.1.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.1"></times><ci id="S2.T3.4.4.4.1.1.1.m1.1.2.2.2.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2.2.2">𝑓</ci><ci id="S2.T3.4.4.4.1.1.1.m1.1.1.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.1">𝑥</ci></apply><ci id="S2.T3.4.4.4.1.1.1.m1.1.2.3.cmml" xref="S2.T3.4.4.4.1.1.1.m1.1.2.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.4.4.4.1.1.1.m1.1c">f(x)=x</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.5.5.5.2.1.1" class="ltx_p" style="width:99.6pt;"><math id="S2.T3.5.5.5.2.1.1.m1.1" class="ltx_Math" alttext="f^{{}^{\prime}}(x)=1" display="inline"><semantics id="S2.T3.5.5.5.2.1.1.m1.1a"><mrow id="S2.T3.5.5.5.2.1.1.m1.1.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.cmml"><mrow id="S2.T3.5.5.5.2.1.1.m1.1.2.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.cmml"><msup id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.cmml"><mi id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.2.cmml">f</mi><msup id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.cmml"><mi id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3a" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.cmml"></mi><mo id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.1" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.1.cmml">′</mo></msup></msup><mo lspace="0em" rspace="0em" id="S2.T3.5.5.5.2.1.1.m1.1.2.2.1" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.1.cmml">​</mo><mrow id="S2.T3.5.5.5.2.1.1.m1.1.2.2.3.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.cmml"><mo stretchy="false" id="S2.T3.5.5.5.2.1.1.m1.1.2.2.3.2.1" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.cmml">(</mo><mi id="S2.T3.5.5.5.2.1.1.m1.1.1" xref="S2.T3.5.5.5.2.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.5.5.5.2.1.1.m1.1.2.2.3.2.2" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.5.5.5.2.1.1.m1.1.2.1" xref="S2.T3.5.5.5.2.1.1.m1.1.2.1.cmml">=</mo><mn id="S2.T3.5.5.5.2.1.1.m1.1.2.3" xref="S2.T3.5.5.5.2.1.1.m1.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.5.5.5.2.1.1.m1.1b"><apply id="S2.T3.5.5.5.2.1.1.m1.1.2.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2"><eq id="S2.T3.5.5.5.2.1.1.m1.1.2.1.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.1"></eq><apply id="S2.T3.5.5.5.2.1.1.m1.1.2.2.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2"><times id="S2.T3.5.5.5.2.1.1.m1.1.2.2.1.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.1"></times><apply id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2"><csymbol cd="ambiguous" id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.1.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2">superscript</csymbol><ci id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.2.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.2">𝑓</ci><apply id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3"><ci id="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.1.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.2.2.3.1">′</ci></apply></apply><ci id="S2.T3.5.5.5.2.1.1.m1.1.1.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.1">𝑥</ci></apply><cn type="integer" id="S2.T3.5.5.5.2.1.1.m1.1.2.3.cmml" xref="S2.T3.5.5.5.2.1.1.m1.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.5.5.5.2.1.1.m1.1c">f^{{}^{\prime}}(x)=1</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.6.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.6.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.6.6.6.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.6.6.6.3.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2009.13012/assets/x6.png" id="S2.T3.6.6.6.3.1.1.1.g1" class="ltx_graphics ltx_img_square" width="37" height="35" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="S2.T3.6.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.6.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.6.6.6.5.1.1" class="ltx_p" style="width:99.6pt;">The last layer will be the linear sum of previous layers independent of the number of layers are in a network. Therefore, a neural network with a linear activation function is simply a linear regression model.</span>
</span>
</td>
</tr>
<tr id="S2.T3.9.9.9" class="ltx_tr">
<td id="S2.T3.9.9.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.9.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.9.9.9.4.1.1" class="ltx_p" style="width:65.4pt;">Sigmoid function</span>
</span>
</td>
<td id="S2.T3.7.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.7.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.7.7.7.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T3.7.7.7.1.1.1.m1.1" class="ltx_Math" alttext="f(x)=\frac{1}{1+e^{-x}}" display="inline"><semantics id="S2.T3.7.7.7.1.1.1.m1.1a"><mrow id="S2.T3.7.7.7.1.1.1.m1.1.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.cmml"><mrow id="S2.T3.7.7.7.1.1.1.m1.1.2.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.cmml"><mi id="S2.T3.7.7.7.1.1.1.m1.1.2.2.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.7.7.7.1.1.1.m1.1.2.2.1" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.1.cmml">​</mo><mrow id="S2.T3.7.7.7.1.1.1.m1.1.2.2.3.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.cmml"><mo stretchy="false" id="S2.T3.7.7.7.1.1.1.m1.1.2.2.3.2.1" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.cmml">(</mo><mi id="S2.T3.7.7.7.1.1.1.m1.1.1" xref="S2.T3.7.7.7.1.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.7.7.7.1.1.1.m1.1.2.2.3.2.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.7.7.7.1.1.1.m1.1.2.1" xref="S2.T3.7.7.7.1.1.1.m1.1.2.1.cmml">=</mo><mfrac id="S2.T3.7.7.7.1.1.1.m1.1.2.3" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.cmml"><mn id="S2.T3.7.7.7.1.1.1.m1.1.2.3.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.2.cmml">1</mn><mrow id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.cmml"><mn id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.2.cmml">1</mn><mo id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.1" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.1.cmml">+</mo><msup id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.cmml"><mi id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.2.cmml">e</mi><mrow id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.cmml"><mo id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3a" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.cmml">−</mo><mi id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.2" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.2.cmml">x</mi></mrow></msup></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.7.7.7.1.1.1.m1.1b"><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2"><eq id="S2.T3.7.7.7.1.1.1.m1.1.2.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.1"></eq><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2"><times id="S2.T3.7.7.7.1.1.1.m1.1.2.2.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.1"></times><ci id="S2.T3.7.7.7.1.1.1.m1.1.2.2.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.2.2">𝑓</ci><ci id="S2.T3.7.7.7.1.1.1.m1.1.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.3.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3"><divide id="S2.T3.7.7.7.1.1.1.m1.1.2.3.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3"></divide><cn type="integer" id="S2.T3.7.7.7.1.1.1.m1.1.2.3.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.2">1</cn><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3"><plus id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.1"></plus><cn type="integer" id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.2">1</cn><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3"><csymbol cd="ambiguous" id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3">superscript</csymbol><ci id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.2">𝑒</ci><apply id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3"><minus id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.1.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3"></minus><ci id="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.2.cmml" xref="S2.T3.7.7.7.1.1.1.m1.1.2.3.3.3.3.2">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.7.7.7.1.1.1.m1.1c">f(x)=\frac{1}{1+e^{-x}}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.8.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.8.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.8.8.8.2.1.1" class="ltx_p" style="width:99.6pt;"><math id="S2.T3.8.8.8.2.1.1.m1.4" class="ltx_Math" alttext="f^{{}^{\prime}}(x)=f(x)(1-f(x))" display="inline"><semantics id="S2.T3.8.8.8.2.1.1.m1.4a"><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4" xref="S2.T3.8.8.8.2.1.1.m1.4.4.cmml"><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.3" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.cmml"><msup id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.cmml"><mi id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.2.cmml">f</mi><msup id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.cmml"><mi id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3a" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.cmml"></mi><mo id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.1.cmml">′</mo></msup></msup><mo lspace="0em" rspace="0em" id="S2.T3.8.8.8.2.1.1.m1.4.4.3.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.1.cmml">​</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.3.3.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.cmml"><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.3.3.2.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.cmml">(</mo><mi id="S2.T3.8.8.8.2.1.1.m1.1.1" xref="S2.T3.8.8.8.2.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.3.3.2.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S2.T3.8.8.8.2.1.1.m1.4.4.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.2.cmml">=</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.cmml"><mi id="S2.T3.8.8.8.2.1.1.m1.4.4.1.3" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.2.cmml">​</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1.4.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.cmml"><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.4.2.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.cmml">(</mo><mi id="S2.T3.8.8.8.2.1.1.m1.2.2" xref="S2.T3.8.8.8.2.1.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.4.2.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.2a" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.2.cmml">​</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.cmml"><mn id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.2.cmml">1</mn><mo id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.1.cmml">−</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.cmml"><mi id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.3.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.3.2.1" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.cmml">(</mo><mi id="S2.T3.8.8.8.2.1.1.m1.3.3" xref="S2.T3.8.8.8.2.1.1.m1.3.3.cmml">x</mi><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.3.2.2" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.3" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.8.8.8.2.1.1.m1.4b"><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4"><eq id="S2.T3.8.8.8.2.1.1.m1.4.4.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.2"></eq><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.3.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3"><times id="S2.T3.8.8.8.2.1.1.m1.4.4.3.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.1"></times><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2"><csymbol cd="ambiguous" id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2">superscript</csymbol><ci id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.2">𝑓</ci><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3"><ci id="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.3.2.3.1">′</ci></apply></apply><ci id="S2.T3.8.8.8.2.1.1.m1.1.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1"><times id="S2.T3.8.8.8.2.1.1.m1.4.4.1.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.2"></times><ci id="S2.T3.8.8.8.2.1.1.m1.4.4.1.3.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.3">𝑓</ci><ci id="S2.T3.8.8.8.2.1.1.m1.2.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.2.2">𝑥</ci><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1"><minus id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.1"></minus><cn type="integer" id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.2">1</cn><apply id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3"><times id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.1.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.1"></times><ci id="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.2.cmml" xref="S2.T3.8.8.8.2.1.1.m1.4.4.1.1.1.1.3.2">𝑓</ci><ci id="S2.T3.8.8.8.2.1.1.m1.3.3.cmml" xref="S2.T3.8.8.8.2.1.1.m1.3.3">𝑥</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.8.8.8.2.1.1.m1.4c">f^{{}^{\prime}}(x)=f(x)(1-f(x))</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.9.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.9.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.9.9.9.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.9.9.9.3.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2009.13012/assets/x7.png" id="S2.T3.9.9.9.3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="55" height="33" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="S2.T3.9.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.9.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.9.9.9.5.1.1" class="ltx_p" style="width:99.6pt;">The change in prediction is not significant for lower and higher values of input. Therefore, it might cause a vanishing gradient problem. Moreover output is not centered at zero and it is computationally expensive.</span>
</span>
</td>
</tr>
<tr id="S2.T3.12.12.12" class="ltx_tr">
<td id="S2.T3.12.12.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.12.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.12.12.12.4.1.1" class="ltx_p" style="width:65.4pt;">Hyperbolic tangent</span>
</span>
</td>
<td id="S2.T3.10.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.10.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.10.10.10.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T3.10.10.10.1.1.1.m1.1" class="ltx_Math" alttext="f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}" display="inline"><semantics id="S2.T3.10.10.10.1.1.1.m1.1a"><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.cmml"><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.cmml"><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.10.10.10.1.1.1.m1.1.2.2.1" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.1.cmml">​</mo><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.2.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.cmml"><mo stretchy="false" id="S2.T3.10.10.10.1.1.1.m1.1.2.2.3.2.1" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.cmml">(</mo><mi id="S2.T3.10.10.10.1.1.1.m1.1.1" xref="S2.T3.10.10.10.1.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.10.10.10.1.1.1.m1.1.2.2.3.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.10.10.10.1.1.1.m1.1.2.1" xref="S2.T3.10.10.10.1.1.1.m1.1.2.1.cmml">=</mo><mfrac id="S2.T3.10.10.10.1.1.1.m1.1.2.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.cmml"><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.cmml"><msup id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.cmml"><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.2.cmml">e</mi><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.3.cmml">x</mi></msup><mo id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.1" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.1.cmml">−</mo><msup id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.cmml"><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.2.cmml">e</mi><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.cmml"><mo id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3a" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.cmml">−</mo><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.2.cmml">x</mi></mrow></msup></mrow><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.cmml"><msup id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.cmml"><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.2.cmml">e</mi><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.3.cmml">x</mi></msup><mo id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.1" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.1.cmml">+</mo><msup id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.cmml"><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.2.cmml">e</mi><mrow id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.cmml"><mo id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3a" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.cmml">−</mo><mi id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.2" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.2.cmml">x</mi></mrow></msup></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.10.10.10.1.1.1.m1.1b"><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2"><eq id="S2.T3.10.10.10.1.1.1.m1.1.2.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.1"></eq><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2"><times id="S2.T3.10.10.10.1.1.1.m1.1.2.2.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.1"></times><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.2.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.2.2">𝑓</ci><ci id="S2.T3.10.10.10.1.1.1.m1.1.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3"><divide id="S2.T3.10.10.10.1.1.1.m1.1.2.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3"></divide><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2"><minus id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.1"></minus><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2"><csymbol cd="ambiguous" id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2">superscript</csymbol><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.2">𝑒</ci><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.2.3">𝑥</ci></apply><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3"><csymbol cd="ambiguous" id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3">superscript</csymbol><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.2">𝑒</ci><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3"><minus id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3"></minus><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.2.3.3.2">𝑥</ci></apply></apply></apply><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3"><plus id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.1"></plus><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2"><csymbol cd="ambiguous" id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2">superscript</csymbol><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.2">𝑒</ci><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.2.3">𝑥</ci></apply><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3"><csymbol cd="ambiguous" id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3">superscript</csymbol><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.2">𝑒</ci><apply id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3"><minus id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.1.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3"></minus><ci id="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.2.cmml" xref="S2.T3.10.10.10.1.1.1.m1.1.2.3.3.3.3.2">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.10.10.10.1.1.1.m1.1c">f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.11.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.11.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.11.11.11.2.1.1" class="ltx_p" style="width:99.6pt;"><math id="S2.T3.11.11.11.2.1.1.m1.2" class="ltx_Math" alttext="f^{{}^{\prime}}(x)=1-f^{2}(x)" display="inline"><semantics id="S2.T3.11.11.11.2.1.1.m1.2a"><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3" xref="S2.T3.11.11.11.2.1.1.m1.2.3.cmml"><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.cmml"><msup id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.cmml"><mi id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.2.cmml">f</mi><msup id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.cmml"><mi id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3a" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.cmml"></mi><mo id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.1.cmml">′</mo></msup></msup><mo lspace="0em" rspace="0em" id="S2.T3.11.11.11.2.1.1.m1.2.3.2.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3.2.3.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.T3.11.11.11.2.1.1.m1.2.3.2.3.2.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.cmml">(</mo><mi id="S2.T3.11.11.11.2.1.1.m1.1.1" xref="S2.T3.11.11.11.2.1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.T3.11.11.11.2.1.1.m1.2.3.2.3.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.11.11.11.2.1.1.m1.2.3.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.1.cmml">=</mo><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3.3" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.cmml"><mn id="S2.T3.11.11.11.2.1.1.m1.2.3.3.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.2.cmml">1</mn><mo id="S2.T3.11.11.11.2.1.1.m1.2.3.3.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.1.cmml">−</mo><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.cmml"><msup id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.cmml"><mi id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.2.cmml">f</mi><mn id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.3" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.1.cmml">​</mo><mrow id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.3.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.cmml"><mo stretchy="false" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.3.2.1" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.cmml">(</mo><mi id="S2.T3.11.11.11.2.1.1.m1.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.3.2.2" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.11.11.11.2.1.1.m1.2b"><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3"><eq id="S2.T3.11.11.11.2.1.1.m1.2.3.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.1"></eq><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2"><times id="S2.T3.11.11.11.2.1.1.m1.2.3.2.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.1"></times><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2">superscript</csymbol><ci id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.2">𝑓</ci><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3"><ci id="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.2.2.3.1">′</ci></apply></apply><ci id="S2.T3.11.11.11.2.1.1.m1.1.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.1.1">𝑥</ci></apply><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.3.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3"><minus id="S2.T3.11.11.11.2.1.1.m1.2.3.3.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.1"></minus><cn type="integer" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.2">1</cn><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3"><times id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.1"></times><apply id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2"><csymbol cd="ambiguous" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.1.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2">superscript</csymbol><ci id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.2">𝑓</ci><cn type="integer" id="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.3.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.3.3.3.2.3">2</cn></apply><ci id="S2.T3.11.11.11.2.1.1.m1.2.2.cmml" xref="S2.T3.11.11.11.2.1.1.m1.2.2">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.11.11.11.2.1.1.m1.2c">f^{{}^{\prime}}(x)=1-f^{2}(x)</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.12.12.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.12.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.12.12.12.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.12.12.12.3.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2009.13012/assets/x8.png" id="S2.T3.12.12.12.3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="55" height="36" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="S2.T3.12.12.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T3.12.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.12.12.12.5.1.1" class="ltx_p" style="width:99.6pt;">Similar to sigmoid, the change in prediction is not significant for lower and higher values of input. Additionally, it is computationally expensive.</span>
</span>
</td>
</tr>
<tr id="S2.T3.15.15.15" class="ltx_tr">
<td id="S2.T3.15.15.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T3.15.15.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.15.4.1.1" class="ltx_p" style="width:65.4pt;">Rectified linear unit</span>
</span>
</td>
<td id="S2.T3.13.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T3.13.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.13.13.13.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T3.13.13.13.1.1.1.m1.5" class="ltx_Math" alttext="f(x)=\begin{cases}x&amp;\text{if $x\geq 0$}\\
0&amp;\text{if $x&lt;0$}\\
\end{cases}" display="inline"><semantics id="S2.T3.13.13.13.1.1.1.m1.5a"><mrow id="S2.T3.13.13.13.1.1.1.m1.5.6" xref="S2.T3.13.13.13.1.1.1.m1.5.6.cmml"><mrow id="S2.T3.13.13.13.1.1.1.m1.5.6.2" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.cmml"><mi id="S2.T3.13.13.13.1.1.1.m1.5.6.2.2" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.T3.13.13.13.1.1.1.m1.5.6.2.1" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.1.cmml">​</mo><mrow id="S2.T3.13.13.13.1.1.1.m1.5.6.2.3.2" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.cmml"><mo stretchy="false" id="S2.T3.13.13.13.1.1.1.m1.5.6.2.3.2.1" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.cmml">(</mo><mi id="S2.T3.13.13.13.1.1.1.m1.5.5" xref="S2.T3.13.13.13.1.1.1.m1.5.5.cmml">x</mi><mo stretchy="false" id="S2.T3.13.13.13.1.1.1.m1.5.6.2.3.2.2" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.13.13.13.1.1.1.m1.5.6.1" xref="S2.T3.13.13.13.1.1.1.m1.5.6.1.cmml">=</mo><mrow id="S2.T3.13.13.13.1.1.1.m1.4.4" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mo id="S2.T3.13.13.13.1.1.1.m1.4.4.5" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S2.T3.13.13.13.1.1.1.m1.4.4.4" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mtr id="S2.T3.13.13.13.1.1.1.m1.4.4.4a" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.13.13.13.1.1.1.m1.4.4.4b" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mi id="S2.T3.13.13.13.1.1.1.m1.3.3.3.3.2.1" xref="S2.T3.13.13.13.1.1.1.m1.3.3.3.3.2.1.cmml">x</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.13.13.13.1.1.1.m1.4.4.4c" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mrow id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1b.cmml"><mtext id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1a" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1b.cmml">if </mtext><mrow id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">≥</mo><mn id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr><mtr id="S2.T3.13.13.13.1.1.1.m1.4.4.4d" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.13.13.13.1.1.1.m1.4.4.4e" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mn id="S2.T3.13.13.13.1.1.1.m1.4.4.4.4.2.1" xref="S2.T3.13.13.13.1.1.1.m1.4.4.4.4.2.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.13.13.13.1.1.1.m1.4.4.4f" xref="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml"><mrow id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1b.cmml"><mtext id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1a" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1b.cmml">if </mtext><mrow id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.13.13.13.1.1.1.m1.5b"><apply id="S2.T3.13.13.13.1.1.1.m1.5.6.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.6"><eq id="S2.T3.13.13.13.1.1.1.m1.5.6.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.6.1"></eq><apply id="S2.T3.13.13.13.1.1.1.m1.5.6.2.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2"><times id="S2.T3.13.13.13.1.1.1.m1.5.6.2.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.1"></times><ci id="S2.T3.13.13.13.1.1.1.m1.5.6.2.2.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.6.2.2">𝑓</ci><ci id="S2.T3.13.13.13.1.1.1.m1.5.5.cmml" xref="S2.T3.13.13.13.1.1.1.m1.5.5">𝑥</ci></apply><apply id="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.4.4"><csymbol cd="latexml" id="S2.T3.13.13.13.1.1.1.m1.5.6.3.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.4.4.5">cases</csymbol><ci id="S2.T3.13.13.13.1.1.1.m1.3.3.3.3.2.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.3.3.3.3.2.1">𝑥</ci><ci id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1b.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1"><mrow id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1"><mtext id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1a.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1">if </mtext><mrow id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1"><mi id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1">≥</mo><mn id="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.13.13.13.1.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci><cn type="integer" id="S2.T3.13.13.13.1.1.1.m1.4.4.4.4.2.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.4.4.4.4.2.1">0</cn><ci id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1b.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1"><mrow id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1"><mtext id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1a.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1">if </mtext><mrow id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1"><mi id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1">&lt;</mo><mn id="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.13.13.13.1.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.13.13.13.1.1.1.m1.5c">f(x)=\begin{cases}x&amp;\text{if $x\geq 0$}\\
0&amp;\text{if $x&lt;0$}\\
\end{cases}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.14.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T3.14.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.14.14.14.2.1.1" class="ltx_p" style="width:99.6pt;"><math id="S2.T3.14.14.14.2.1.1.m1.5" class="ltx_Math" alttext="f^{{}^{\prime}}(x)=\begin{cases}1&amp;\text{if $x\geq 0$}\\
0&amp;\text{if $x&lt;0$}\\
\end{cases}" display="inline"><semantics id="S2.T3.14.14.14.2.1.1.m1.5a"><mrow id="S2.T3.14.14.14.2.1.1.m1.5.6" xref="S2.T3.14.14.14.2.1.1.m1.5.6.cmml"><mrow id="S2.T3.14.14.14.2.1.1.m1.5.6.2" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.cmml"><msup id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.cmml"><mi id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.2" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.2.cmml">f</mi><msup id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.cmml"><mi id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3a" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.cmml"></mi><mo id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.1" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.1.cmml">′</mo></msup></msup><mo lspace="0em" rspace="0em" id="S2.T3.14.14.14.2.1.1.m1.5.6.2.1" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.1.cmml">​</mo><mrow id="S2.T3.14.14.14.2.1.1.m1.5.6.2.3.2" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.cmml"><mo stretchy="false" id="S2.T3.14.14.14.2.1.1.m1.5.6.2.3.2.1" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.cmml">(</mo><mi id="S2.T3.14.14.14.2.1.1.m1.5.5" xref="S2.T3.14.14.14.2.1.1.m1.5.5.cmml">x</mi><mo stretchy="false" id="S2.T3.14.14.14.2.1.1.m1.5.6.2.3.2.2" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.cmml">)</mo></mrow></mrow><mo id="S2.T3.14.14.14.2.1.1.m1.5.6.1" xref="S2.T3.14.14.14.2.1.1.m1.5.6.1.cmml">=</mo><mrow id="S2.T3.14.14.14.2.1.1.m1.4.4" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mo id="S2.T3.14.14.14.2.1.1.m1.4.4.5" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S2.T3.14.14.14.2.1.1.m1.4.4.4" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mtr id="S2.T3.14.14.14.2.1.1.m1.4.4.4a" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.14.14.14.2.1.1.m1.4.4.4b" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mn id="S2.T3.14.14.14.2.1.1.m1.3.3.3.3.2.1" xref="S2.T3.14.14.14.2.1.1.m1.3.3.3.3.2.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.14.14.14.2.1.1.m1.4.4.4c" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mrow id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1b.cmml"><mtext id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1a" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1b.cmml">if </mtext><mrow id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">≥</mo><mn id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr><mtr id="S2.T3.14.14.14.2.1.1.m1.4.4.4d" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.T3.14.14.14.2.1.1.m1.4.4.4e" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mn id="S2.T3.14.14.14.2.1.1.m1.4.4.4.4.2.1" xref="S2.T3.14.14.14.2.1.1.m1.4.4.4.4.2.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.T3.14.14.14.2.1.1.m1.4.4.4f" xref="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml"><mrow id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1b.cmml"><mtext id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1a" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1b.cmml">if </mtext><mrow id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">x</mi><mo id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T3.14.14.14.2.1.1.m1.5b"><apply id="S2.T3.14.14.14.2.1.1.m1.5.6.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6"><eq id="S2.T3.14.14.14.2.1.1.m1.5.6.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.1"></eq><apply id="S2.T3.14.14.14.2.1.1.m1.5.6.2.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2"><times id="S2.T3.14.14.14.2.1.1.m1.5.6.2.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.1"></times><apply id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2"><csymbol cd="ambiguous" id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2">superscript</csymbol><ci id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.2.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.2">𝑓</ci><apply id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3"><ci id="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.6.2.2.3.1">′</ci></apply></apply><ci id="S2.T3.14.14.14.2.1.1.m1.5.5.cmml" xref="S2.T3.14.14.14.2.1.1.m1.5.5">𝑥</ci></apply><apply id="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.4.4"><csymbol cd="latexml" id="S2.T3.14.14.14.2.1.1.m1.5.6.3.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.4.4.5">cases</csymbol><cn type="integer" id="S2.T3.14.14.14.2.1.1.m1.3.3.3.3.2.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.3.3.3.3.2.1">1</cn><ci id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1b.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1"><mrow id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1"><mtext id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1a.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1">if </mtext><mrow id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1"><mi id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.1">≥</mo><mn id="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.14.14.14.2.1.1.m1.1.1.1.1.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci><cn type="integer" id="S2.T3.14.14.14.2.1.1.m1.4.4.4.4.2.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.4.4.4.4.2.1">0</cn><ci id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1b.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1"><mrow id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1"><mtext id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1a.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1">if </mtext><mrow id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1"><mi id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.2">x</mi><mo id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.1">&lt;</mo><mn id="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S2.T3.14.14.14.2.1.1.m1.2.2.2.2.1.1.1.1.m1.1.1.3">0</mn></mrow></mrow></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.14.14.14.2.1.1.m1.5c">f^{{}^{\prime}}(x)=\begin{cases}1&amp;\text{if $x\geq 0$}\\
0&amp;\text{if $x&lt;0$}\\
\end{cases}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T3.15.15.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T3.15.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.15.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T3.15.15.15.3.1.1.1" class="ltx_text" style="position:relative; bottom:-0.5pt;"><img src="/html/2009.13012/assets/x9.png" id="S2.T3.15.15.15.3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="32" height="20" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="S2.T3.15.15.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T3.15.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T3.15.15.15.5.1.1" class="ltx_p" style="width:99.6pt;">For zero or less than zero inputs, the function becomes zero and does not learn.</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.6" class="ltx_p">Next to selection of the local learning model, there must be effective technique to optimize the local model weights update to enable faster convergence of the federated learning model. Mostly, SGD was considered for local model weights updating <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. In SGD, the weights are updated at end-devices using partial derivative of loss function w.r.t weights, which are then multiplied by the learning rate. The learning rate represents the step size of gradient descent. The mini-batch SGD is given by.</p>
<table id="S2.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\omega=\omega-\eta\frac{\partial F}{\partial\omega_{t}}" display="inline"><semantics id="S2.E2X.2.1.1.m1.1a"><mrow id="S2.E2X.2.1.1.m1.1.1" xref="S2.E2X.2.1.1.m1.1.1.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.2" xref="S2.E2X.2.1.1.m1.1.1.2.cmml">ω</mi><mo id="S2.E2X.2.1.1.m1.1.1.1" xref="S2.E2X.2.1.1.m1.1.1.1.cmml">=</mo><mrow id="S2.E2X.2.1.1.m1.1.1.3" xref="S2.E2X.2.1.1.m1.1.1.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.3.2" xref="S2.E2X.2.1.1.m1.1.1.3.2.cmml">ω</mi><mo id="S2.E2X.2.1.1.m1.1.1.3.1" xref="S2.E2X.2.1.1.m1.1.1.3.1.cmml">−</mo><mrow id="S2.E2X.2.1.1.m1.1.1.3.3" xref="S2.E2X.2.1.1.m1.1.1.3.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.3.3.2" xref="S2.E2X.2.1.1.m1.1.1.3.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.E2X.2.1.1.m1.1.1.3.3.1" xref="S2.E2X.2.1.1.m1.1.1.3.3.1.cmml">​</mo><mstyle displaystyle="true" id="S2.E2X.2.1.1.m1.1.1.3.3.3" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.cmml"><mfrac id="S2.E2X.2.1.1.m1.1.1.3.3.3a" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.cmml"><mrow id="S2.E2X.2.1.1.m1.1.1.3.3.3.2" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2.cmml"><mo rspace="0em" id="S2.E2X.2.1.1.m1.1.1.3.3.3.2.1" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2.1.cmml">∂</mo><mi id="S2.E2X.2.1.1.m1.1.1.3.3.3.2.2" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2.2.cmml">F</mi></mrow><mrow id="S2.E2X.2.1.1.m1.1.1.3.3.3.3" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.cmml"><mo rspace="0em" id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.1" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.1.cmml">∂</mo><msub id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.cmml"><mi id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.2" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.2.cmml">ω</mi><mi id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.3" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.3.cmml">t</mi></msub></mrow></mfrac></mstyle></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2X.2.1.1.m1.1b"><apply id="S2.E2X.2.1.1.m1.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1"><eq id="S2.E2X.2.1.1.m1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.1"></eq><ci id="S2.E2X.2.1.1.m1.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.2">𝜔</ci><apply id="S2.E2X.2.1.1.m1.1.1.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.3"><minus id="S2.E2X.2.1.1.m1.1.1.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.1"></minus><ci id="S2.E2X.2.1.1.m1.1.1.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.2">𝜔</ci><apply id="S2.E2X.2.1.1.m1.1.1.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3"><times id="S2.E2X.2.1.1.m1.1.1.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.1"></times><ci id="S2.E2X.2.1.1.m1.1.1.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.2">𝜂</ci><apply id="S2.E2X.2.1.1.m1.1.1.3.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3"><divide id="S2.E2X.2.1.1.m1.1.1.3.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3"></divide><apply id="S2.E2X.2.1.1.m1.1.1.3.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2"><partialdiff id="S2.E2X.2.1.1.m1.1.1.3.3.3.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2.1"></partialdiff><ci id="S2.E2X.2.1.1.m1.1.1.3.3.3.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.2.2">𝐹</ci></apply><apply id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3"><partialdiff id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.1"></partialdiff><apply id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.1.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.2.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.2">𝜔</ci><ci id="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.3.cmml" xref="S2.E2X.2.1.1.m1.1.1.3.3.3.3.2.3">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2X.2.1.1.m1.1c">\displaystyle\omega=\omega-\eta\frac{\partial F}{\partial\omega_{t}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<table id="S2.E3" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E3X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\frac{\partial F}{\partial\omega}\approx\frac{1}{m}\sum_{i\in\mathcal{B}}\frac{\partial f_{i}}{\partial\omega}," display="inline"><semantics id="S2.E3X.2.1.1.m1.1a"><mrow id="S2.E3X.2.1.1.m1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S2.E3X.2.1.1.m1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E3X.2.1.1.m1.1.1.1.1.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.cmml"><mfrac id="S2.E3X.2.1.1.m1.1.1.1.1.2a" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.cmml"><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2.cmml"><mo rspace="0em" id="S2.E3X.2.1.1.m1.1.1.1.1.2.2.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2.1.cmml">∂</mo><mi id="S2.E3X.2.1.1.m1.1.1.1.1.2.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2.2.cmml">F</mi></mrow><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.2.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3.cmml"><mo rspace="0em" id="S2.E3X.2.1.1.m1.1.1.1.1.2.3.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3.1.cmml">∂</mo><mi id="S2.E3X.2.1.1.m1.1.1.1.1.2.3.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3.2.cmml">ω</mi></mrow></mfrac></mstyle><mo id="S2.E3X.2.1.1.m1.1.1.1.1.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.1.cmml">≈</mo><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.cmml"><mstyle displaystyle="true" id="S2.E3X.2.1.1.m1.1.1.1.1.3.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.cmml"><mfrac id="S2.E3X.2.1.1.m1.1.1.1.1.3.2a" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.cmml"><mn id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.2.cmml">1</mn><mi id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.3.cmml">m</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S2.E3X.2.1.1.m1.1.1.1.1.3.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.3.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.cmml"><mstyle displaystyle="true" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.cmml"><munder id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1a" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.2.cmml">∑</mo><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.cmml"><mi id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.2.cmml">i</mi><mo id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.3.cmml">ℬ</mi></mrow></munder></mstyle><mstyle displaystyle="true" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.cmml"><mfrac id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2a" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.cmml"><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml"><mo rspace="0em" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.1.cmml">∂</mo><msub id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.cmml"><mi id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.2.cmml">f</mi><mi id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.3.cmml">i</mi></msub></mrow><mrow id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.cmml"><mo rspace="0em" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.1" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.1.cmml">∂</mo><mi id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.2.cmml">ω</mi></mrow></mfrac></mstyle></mrow></mrow></mrow><mo id="S2.E3X.2.1.1.m1.1.1.1.2" xref="S2.E3X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3X.2.1.1.m1.1b"><apply id="S2.E3X.2.1.1.m1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1"><approx id="S2.E3X.2.1.1.m1.1.1.1.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.1"></approx><apply id="S2.E3X.2.1.1.m1.1.1.1.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2"><divide id="S2.E3X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2"></divide><apply id="S2.E3X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2"><partialdiff id="S2.E3X.2.1.1.m1.1.1.1.1.2.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2.1"></partialdiff><ci id="S2.E3X.2.1.1.m1.1.1.1.1.2.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.2.2">𝐹</ci></apply><apply id="S2.E3X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3"><partialdiff id="S2.E3X.2.1.1.m1.1.1.1.1.2.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3.1"></partialdiff><ci id="S2.E3X.2.1.1.m1.1.1.1.1.2.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.2.3.2">𝜔</ci></apply></apply><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3"><times id="S2.E3X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.1"></times><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2"><divide id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2"></divide><cn type="integer" id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.2">1</cn><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.2.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.2.3">𝑚</ci></apply><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3"><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.2"></sum><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3"><in id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.1"></in><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.2">𝑖</ci><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.1.3.3">ℬ</ci></apply></apply><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2"><divide id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2"></divide><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2"><partialdiff id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.1"></partialdiff><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2">subscript</csymbol><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.2">𝑓</ci><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.2.2.3">𝑖</ci></apply></apply><apply id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3"><partialdiff id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.1"></partialdiff><ci id="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S2.E3X.2.1.1.m1.1.1.1.1.3.3.2.3.2">𝜔</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3X.2.1.1.m1.1c">\displaystyle\frac{\partial F}{\partial\omega}\approx\frac{1}{m}\sum_{i\in\mathcal{B}}\frac{\partial f_{i}}{\partial\omega},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(3)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<p id="S2.SS3.p2.5" class="ltx_p">where <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">m</annotation></semantics></math> denotes the number of elements in a batch. The batch size significantly affects the performance global federated learning model. For FedAvg, using client fraction <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="C=0.1" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><mi id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml">C</mi><mo id="S2.SS3.p2.2.m2.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><eq id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1"></eq><ci id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2">𝐶</ci><cn type="float" id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">C=0.1</annotation></semantics></math> and batch size <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><mn id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><cn type="integer" id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">10</annotation></semantics></math> generally have shown better results compared to full batch size for MNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Other than client fraction <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><mi id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><ci id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">C</annotation></semantics></math> and batch size, learning rate significantly affects the performance of the federated learning global model. Therefore, we must wisely chose the client fraction <math id="S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS3.p2.5.m5.1a"><mi id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><ci id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">C</annotation></semantics></math>, batch size, and learning rate.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.4.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.5.2" class="ltx_text ltx_font_italic">Frameworks</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">In this subsection, we discuss various frameworks developed for implementing federated learning over IoT networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>:</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">PySyft:</span> PySyft is a python framework that can be used to implement secure and private deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. End-devices private data is decoupled during the training process by using Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)), differential privacy, and federated learning. PySyft is primarily based on Pytorch and it retains native Torch interface <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. For simulation of federated learning using PySyft, end-devices are created as virtual workers. The data is divided into virtual workers. Next, a PointerTensor is used for specification of data storage location and owner. For global federated learning model aggregation, local model updates can be fetched from virtual workers.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">FedML:</span> FedML is an open research framework to facilitate development of federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. FedML has two main components, such as FedML-core and FedML-API. FedML-core performs separation of model training and distributed communication into two modules, such as distributed communication module and training module. The responsibility of distributed communication module is to carry out low-level communication among various clients, whereas training module is implemented using PyTorch. New algorithms in FedML can be easily implemented using client-oriented programming interface. The primary advantage of FedML is a TopologyManager that can provide a support for many network topologies to implement various federated learning algorithms.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">TensorFlow Federated:</span> TensorFlow Federated (TFF) is an open source framework developed by Google for performing experiments on distributed datasets using machine learning and other computations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. TFF interfaces can be divided into two types, such as federated core API, and federated learning API. Federated learning API provides high-level interfaces set that enable us to use the existing TensorFlow models. Federated core API is set of lower-level interfaces that can enable new federated learning algorithms using TensorFlow and distributed communication operations.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p"><span id="S2.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">LEAF:</span> LEAF is a framework for federated settings that can support various applications, such as meta-learning, multi-task learning, and federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>. LEAF consists of three parts, such as open-source datasets suit, system and statistical metrics array, and reference implementations set. LEAF offers the modular design that has the advantage of easier implementation of diverse experimental scenarios. The datasets suit has Federated Extended MNIST, Sentiment140, Shakespeare, CelebA, Reddit, and synthetic dataset that is based on modification of synthetic dataset of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> for making it more challenging for meta-learning methods. Initial implementations of LEAF are Mocha <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and minibatch SGD.</p>
</div>
</li>
<li id="S2.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i5.p1" class="ltx_para">
<p id="S2.I2.i5.p1.1" class="ltx_p"><span id="S2.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Paddle FL:</span> Paddle FL is an open source framework developed mainly for industry applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. Paddle FL can easily replicate various federated learning algorithms for large scale distributed clusters. Paddle FL will offer federated learning implementation in natural language processing, computer vision, and so on. Furthermore, support for implementation of transfer learning and multi-task learning in federated learning will be provided <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. Using elastic scheduling of training job on Kubernetes and large scale distributed training of PaddlePaddle’s, paddle FL can be easily deployed on full-stack open sourced software.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">All of the above-mentioned frameworks present implementation of various federated learning schemes, but they did not effectively considered the effect of wireless channel uncertainties and limited communication resources. IoT applications will suffer from significant performance degradation due to wireless channel uncertainties. Therefore, we should propose novel federated learning frameworks for IoT networks that will enable us to effectively handle wireless channel uncertainties. Furthermore, we can use channel coding schemes to improve the performance of the federated learning over IoT networks. Therefore, the framework for federated learning over IoT networks must provide support for channel coding schemes.</p>
</div>
<figure id="S2.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T4.7.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S2.T4.8.2" class="ltx_text" style="font-size:90%;">Evaluation metrics: explanation, dimension, and advantages.</span></figcaption>
<table id="S2.T4.5.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T4.5.5.6" class="ltx_tr">
<td id="S2.T4.5.5.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T4.5.5.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.6.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S2.T4.5.5.6.1.1.1.1" class="ltx_text ltx_font_bold">Metric</span></span>
</span>
</td>
<td id="S2.T4.5.5.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T4.5.5.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.6.2.1.1" class="ltx_p" style="width:170.7pt;"><span id="S2.T4.5.5.6.2.1.1.1" class="ltx_text ltx_font_bold">Explanation</span></span>
</span>
</td>
<td id="S2.T4.5.5.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T4.5.5.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.6.3.1.1" class="ltx_p" style="width:170.7pt;"><span id="S2.T4.5.5.6.3.1.1.1" class="ltx_text ltx_font_bold">Benefits for federated learning</span></span>
</span>
</td>
</tr>
<tr id="S2.T4.1.1.1" class="ltx_tr">
<td id="S2.T4.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T4.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="P_{1}" display="inline"><semantics id="S2.T4.1.1.1.1.1.1.m1.1a"><msub id="S2.T4.1.1.1.1.1.1.m1.1.1" xref="S2.T4.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T4.1.1.1.1.1.1.m1.1.1.2" xref="S2.T4.1.1.1.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S2.T4.1.1.1.1.1.1.m1.1.1.3" xref="S2.T4.1.1.1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T4.1.1.1.1.1.1.m1.1b"><apply id="S2.T4.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T4.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T4.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T4.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T4.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T4.1.1.1.1.1.1.m1.1.1.2">𝑃</ci><cn type="integer" id="S2.T4.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T4.1.1.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.1.1.1.1.1.1.m1.1c">P_{1}</annotation></semantics></math><span id="S2.T4.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">: Security and privacy</span></span>
</span>
</td>
<td id="S2.T4.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.1.1.2.1.1" class="ltx_p" style="width:170.7pt;">This metric deals with malicious user attacks during learning model parameters transmission between end-devices and the aggregation server. Moreover, the malicious aggregation server and end-device can infer other end-devices sensitive information from their local learning model updates. Therefore, we must propose federated learning schemes that offer both security and privacy.</span>
</span>
</td>
<td id="S2.T4.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.1.1.3.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S2.I3" class="ltx_itemize">
<span id="S2.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I3.i1.p1" class="ltx_para">
<span id="S2.I3.i1.p1.1" class="ltx_p">Users’ privacy protection.</span>
</span></span>
<span id="S2.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I3.i2.p1" class="ltx_para">
<span id="S2.I3.i2.p1.1" class="ltx_p">Trustful verification of learning model updates.</span>
</span></span>
<span id="S2.I3.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I3.i3.p1" class="ltx_para">
<span id="S2.I3.i3.p1.1" class="ltx_p">Secure exchange of learning model updates.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S2.T4.2.2.2" class="ltx_tr">
<td id="S2.T4.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.2.2.2.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T4.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="P_{2}" display="inline"><semantics id="S2.T4.2.2.2.1.1.1.m1.1a"><msub id="S2.T4.2.2.2.1.1.1.m1.1.1" xref="S2.T4.2.2.2.1.1.1.m1.1.1.cmml"><mi id="S2.T4.2.2.2.1.1.1.m1.1.1.2" xref="S2.T4.2.2.2.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S2.T4.2.2.2.1.1.1.m1.1.1.3" xref="S2.T4.2.2.2.1.1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T4.2.2.2.1.1.1.m1.1b"><apply id="S2.T4.2.2.2.1.1.1.m1.1.1.cmml" xref="S2.T4.2.2.2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T4.2.2.2.1.1.1.m1.1.1.1.cmml" xref="S2.T4.2.2.2.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T4.2.2.2.1.1.1.m1.1.1.2.cmml" xref="S2.T4.2.2.2.1.1.1.m1.1.1.2">𝑃</ci><cn type="integer" id="S2.T4.2.2.2.1.1.1.m1.1.1.3.cmml" xref="S2.T4.2.2.2.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.2.2.2.1.1.1.m1.1c">P_{2}</annotation></semantics></math><span id="S2.T4.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">: Scalability</span></span>
</span>
</td>
<td id="S2.T4.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.2.2.2.2.1.1" class="ltx_p" style="width:170.7pt;">Scalability captures to the ability of a federated learning system to incorporate more users during the training process for better accuracy.</span>
</span>
</td>
<td id="S2.T4.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.2.2.2.3.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S2.I4" class="ltx_itemize">
<span id="S2.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I4.i1.p1" class="ltx_para">
<span id="S2.I4.i1.p1.1" class="ltx_p">High federated learning accuracy.</span>
</span></span>
<span id="S2.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I4.i2.p1" class="ltx_para">
<span id="S2.I4.i2.p1.1" class="ltx_p">Massive connectivity during federated learning process.</span>
</span></span>
<span id="S2.I4.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I4.i3.p1" class="ltx_para">
<span id="S2.I4.i3.p1.1" class="ltx_p">Better accuracy due to participation of more users.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S2.T4.3.3.3" class="ltx_tr">
<td id="S2.T4.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.3.3.3.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T4.3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="P_{3}" display="inline"><semantics id="S2.T4.3.3.3.1.1.1.m1.1a"><msub id="S2.T4.3.3.3.1.1.1.m1.1.1" xref="S2.T4.3.3.3.1.1.1.m1.1.1.cmml"><mi id="S2.T4.3.3.3.1.1.1.m1.1.1.2" xref="S2.T4.3.3.3.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S2.T4.3.3.3.1.1.1.m1.1.1.3" xref="S2.T4.3.3.3.1.1.1.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T4.3.3.3.1.1.1.m1.1b"><apply id="S2.T4.3.3.3.1.1.1.m1.1.1.cmml" xref="S2.T4.3.3.3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T4.3.3.3.1.1.1.m1.1.1.1.cmml" xref="S2.T4.3.3.3.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T4.3.3.3.1.1.1.m1.1.1.2.cmml" xref="S2.T4.3.3.3.1.1.1.m1.1.1.2">𝑃</ci><cn type="integer" id="S2.T4.3.3.3.1.1.1.m1.1.1.3.cmml" xref="S2.T4.3.3.3.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.3.3.3.1.1.1.m1.1c">P_{3}</annotation></semantics></math><span id="S2.T4.3.3.3.1.1.1.1" class="ltx_text ltx_font_bold">: Quantization</span></span>
</span>
</td>
<td id="S2.T4.3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.3.3.3.2.1.1" class="ltx_p" style="width:170.7pt;">Quantization refers to the need for minimizing the size of local learning model updates to reduce federated learning convergence time.</span>
</span>
</td>
<td id="S2.T4.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.3.3.3.3.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S2.I5" class="ltx_itemize">
<span id="S2.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I5.i1.p1" class="ltx_para">
<span id="S2.I5.i1.p1.1" class="ltx_p">Fast federated learning convergence.</span>
</span></span>
<span id="S2.I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I5.i2.p1" class="ltx_para">
<span id="S2.I5.i2.p1.1" class="ltx_p">Better accuracy due to participation of more users for fix communication resources.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S2.T4.4.4.4" class="ltx_tr">
<td id="S2.T4.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.4.4.4.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T4.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="P_{4}" display="inline"><semantics id="S2.T4.4.4.4.1.1.1.m1.1a"><msub id="S2.T4.4.4.4.1.1.1.m1.1.1" xref="S2.T4.4.4.4.1.1.1.m1.1.1.cmml"><mi id="S2.T4.4.4.4.1.1.1.m1.1.1.2" xref="S2.T4.4.4.4.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S2.T4.4.4.4.1.1.1.m1.1.1.3" xref="S2.T4.4.4.4.1.1.1.m1.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T4.4.4.4.1.1.1.m1.1b"><apply id="S2.T4.4.4.4.1.1.1.m1.1.1.cmml" xref="S2.T4.4.4.4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T4.4.4.4.1.1.1.m1.1.1.1.cmml" xref="S2.T4.4.4.4.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T4.4.4.4.1.1.1.m1.1.1.2.cmml" xref="S2.T4.4.4.4.1.1.1.m1.1.1.2">𝑃</ci><cn type="integer" id="S2.T4.4.4.4.1.1.1.m1.1.1.3.cmml" xref="S2.T4.4.4.4.1.1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.4.4.4.1.1.1.m1.1c">P_{4}</annotation></semantics></math><span id="S2.T4.4.4.4.1.1.1.1" class="ltx_text ltx_font_bold">: Robustness</span></span>
</span>
</td>
<td id="S2.T4.4.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.4.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.4.4.4.2.1.1" class="ltx_p" style="width:170.7pt;">This refers to the ability of a federated learning algorithm to perform the learning process successfully in face of a possible malfunction or failure of the edge/cloud server.</span>
</span>
</td>
<td id="S2.T4.4.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.4.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.4.4.4.3.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S2.I6" class="ltx_itemize">
<span id="S2.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I6.i1.p1" class="ltx_para">
<span id="S2.I6.i1.p1.1" class="ltx_p">Cost optimization.</span>
</span></span>
<span id="S2.I6.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I6.i2.p1" class="ltx_para">
<span id="S2.I6.i2.p1.1" class="ltx_p">Accurate federated learning model.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S2.T4.5.5.5" class="ltx_tr">
<td id="S2.T4.5.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T4.5.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.5.1.1.1" class="ltx_p" style="width:85.4pt;"><math id="S2.T4.5.5.5.1.1.1.m1.1" class="ltx_Math" alttext="P_{5}" display="inline"><semantics id="S2.T4.5.5.5.1.1.1.m1.1a"><msub id="S2.T4.5.5.5.1.1.1.m1.1.1" xref="S2.T4.5.5.5.1.1.1.m1.1.1.cmml"><mi id="S2.T4.5.5.5.1.1.1.m1.1.1.2" xref="S2.T4.5.5.5.1.1.1.m1.1.1.2.cmml">P</mi><mn id="S2.T4.5.5.5.1.1.1.m1.1.1.3" xref="S2.T4.5.5.5.1.1.1.m1.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T4.5.5.5.1.1.1.m1.1b"><apply id="S2.T4.5.5.5.1.1.1.m1.1.1.cmml" xref="S2.T4.5.5.5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T4.5.5.5.1.1.1.m1.1.1.1.cmml" xref="S2.T4.5.5.5.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T4.5.5.5.1.1.1.m1.1.1.2.cmml" xref="S2.T4.5.5.5.1.1.1.m1.1.1.2">𝑃</ci><cn type="integer" id="S2.T4.5.5.5.1.1.1.m1.1.1.3.cmml" xref="S2.T4.5.5.5.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.5.5.5.1.1.1.m1.1c">P_{5}</annotation></semantics></math><span id="S2.T4.5.5.5.1.1.1.1" class="ltx_text ltx_font_bold">: Sparsification</span></span>
</span>
</td>
<td id="S2.T4.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T4.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.5.2.1.1" class="ltx_p" style="width:170.7pt;">Sparsification refers to the selection of most suitable devices among a set of massive numbers of devices according to a specific criteria.</span>
</span>
</td>
<td id="S2.T4.5.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T4.5.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.5.5.5.3.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S2.I7" class="ltx_itemize">
<span id="S2.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I7.i1.p1" class="ltx_para">
<span id="S2.I7.i1.p1.1" class="ltx_p">Lower federated learning convergence time.</span>
</span></span>
<span id="S2.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S2.I7.i2.p1" class="ltx_para">
<span id="S2.I7.i2.p1.1" class="ltx_p">High federated learning accuracy.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">State-Of-The-Art</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section discusses the recent works in federated learning towards enabling IoT-based smart applications. We critically investigate and rigorously evaluate these recent works, whose summary is given in Tables <a href="#S3.T6" title="TABLE VI ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> and <a href="#S3.T7" title="TABLE VII ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>. To rigorously evaluate the recent works, we derive several key metrics from the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib90" title="" class="ltx_ref">90</a>, <a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib92" title="" class="ltx_ref">92</a>, <a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite> as follows.</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Security and privacy:</span> Although federated learning was developed to preserve the users’ privacy, it still faces privacy challenges. For instance, the edge/cloud server can infer the end-devices’ sensitive information using their learning model updates, and thus causes the end-device privacy leakage. Furthermore, the malicious user can infer the devices’ sensitive information from their local learning models during their exchange with the aggregation server. Beyond inferring the end-devices’ sensitive information, the malicious user can alter the learning model updates, and thus prolong the convergence time of a federated learning model. On the other hand, an unauthorized user can access the edge/cloud server and perform false data injection. Therefore, it is necessary to enable federated learning with security and privacy.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Scalability:</span> For a limited communication resource, scalability refers to the ability to incorporate more devices in the federated learning process. Generally, incorporating more devices in federated learning can lead to more accurate results. Scalability in federated learning can be enabled via different schemes such as resource optimization, selection of high-computational power devices, and compression schemes for learning model parameters transmission. An efficient resource optimization scheme for fixed communication resources can enable more devices to participate in the federated learning process, and thus offers better performance. Typically, a set of devices can participate in the federated learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Therefore, for synchronous federated learning algorithms that allow fixed local model computation time for all the participating devices, selecting the devices’ high-computation power (CPU-cycles/sec) will enable more devices to participate in the federated learning process.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Quantization:</span> The concept of quantization refers to schemes used to reduce the size of the local learning model updates. Minimizing the number of local model updates size results in high throughput, which subsequently minimizes the federated learning convergence time.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Robustness:</span> This deals with the ability of the system to successfully carry out the process of federated learning during edge/cloud server failure. Traditional federated learning based on a centralized edge/cloud server for global aggregation suffers from interruption if the aggregation server stops working due to malfunctioning.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Sparsification:</span> This metric deals with the selection of a set of most suitable devices under communication resource constraints for federated learning. Under communication resource constraints, only a subset of a massive number of devices will be allowed to participate in federated learning. The selection criteria for suitable devices can be less noisy datasets, large size datasets, and data uniqueness. Selecting the most suitable device set results in low convergence time for federated learning. Different from quantization-based schemes that reduce the size of local learning model parameters for all devices before sending to the aggregation server, sparsification-based schemes select only a set of most relevant devices according to a particular criterion.</p>
</div>
</li>
</ul>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">A summary of the evaluation metrics with advantages is given in Table <a href="#S2.T4" title="TABLE IV ‣ II-D Frameworks ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. We use (✓) if the evaluation metric is fulfilled by recent advances and (✗) otherwise. A summary of these recent works is given in Table <a href="#S3.T5" title="TABLE V ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. Furthermore, Table <a href="#S3.T6" title="TABLE VI ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> and Table <a href="#S3.T7" title="TABLE VII ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> evaluate these works using precise metrics (discussed later). We categorize the recent advances mainly into advances based on centralized aggregation, advances based on distributed aggregation, and advances based on hierarchical aggregation. Fig. <a href="#S3.F5" title="Figure 5 ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the overview of various aggregation fashion for federated learning. In centralized aggregation, a single edge or cloud server acts for the aggregation of local learning models of all devices. Distributed aggregation involves multiple aggregation servers that receive local learning model updates from their associated devices. The received local learning models from various devices are shared among various aggregation servers which are followed by global aggregation. On the other hand, hierarchical aggregation involves aggregations (e.g., at edge servers) before a central global aggregation takes place. Next, we present various advances of federated learning for IoT networks.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2009.13012/assets/x10.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="545" height="212" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">Federated learning based on: (a) centralized aggregation, (b) distributed aggregation, and (c) hierarchical aggregation.</span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Advances Based on Centralized Aggregation</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Many works such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> considered federated learning based on a centralized aggregation of end-devices local learning models for various IoT applications. In all these works, end-devices compute their local learning models and send the learning model updates to a centralized aggregation server for computing the global federated learning model. The centralized aggregation server can be either located at the network edge or a remote cloud. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, Wang <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> proposed an intelligent framework as shown in Fig. <a href="#S3.F6" title="Figure 6 ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, namely, In-Edge-AI for edge computing-enabled IoT networks. The authors provided a detailed discussion on how to use Deep Q-Learning agents for two tasks, computation offloading and edge caching. Different use cases of deep Q-learning agent deployment were discussed with their pros and cons. Motivated by the notion of unbalanced, non-IID data, and limited communication resources, federated learning was proposed for the training of deep Q-learning agents. Simulation results showed that federated learning has significantly reduced the training cost for the proposed In-Edge-AI framework. Finally, the authors presented open research challenges regarding the practical deployment of their framework. Although the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> proposed a detailed framework regarding the implementation of Deep Q-Learning agents based on federated learning, the authors did not properly addressed the issues of security and privacy in their framework. A malicious end-device or an aggregation server can easily infer the end-devices sensitive information from local learning models. Therefore, we must tackle the issues of security and privacy for the In-Edge AI framework. Additionally, Deep Q-Learning agents based on federated learning result in slight loss of performance compared to Deep Q-Learning agents using traditional, centralized machine learning. One possible reason for this performance degradation can be the simple averaging of local learning models. There exist significant variations in the wireless channel and local learning models that must be taken into account while averaging the learning model updates from the edge servers where agents are deployed. One way can be weighted averaging by assigning higher weights to poorly performing nodes so as to minimize the impact of better performing devices on the global model. In another work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>, the authors also considered federated learning at the network edge. They analyzed the convergence bound for federated learning using gradient descent. A novel theoretical convergence bound was derived that considered non-IID nature of the data. Furthermore, based on the derived convergence bound, a control algorithm was proposed that minimizes learning loss for a fixed resource budget. The control algorithm performed learning loss minimization by learning model characteristics, system dynamics, and data distribution. The performance of the proposed control algorithm was evaluated for real datasets using hardware prototype and simulations results. Although the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> presented extensive theoretical convergence analysis for convex loss functions, it does not provide analysis for non-convex loss functions which is more practical for various IoT learning tasks. Additionally, efficient management of resources such as local computation resources and wireless resources must be performed for federated learning over edge networks.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2009.13012/assets/x11.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="272" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Deep Q-Learning agents training using (a) centralized training, (b) federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, a framework for joint learning and communication for wireless federated learning was presented. First, the authors extensively studied the performance of federated learning for wireless networks. Then, joint wireless resource allocation, power allocation, and user selection optimization problem was formulated for minimizing the federated learning loss function. For the expected convergence rate of federated learning, a closed-form expression was derived to account for the wireless factors on learning performance. Using the derived closed-form expression, optimal transmit power allocation was performed for a fixed resource block allocation and user selection. Next, resource block allocation and user selection were performed to minimize the federated learning loss function. The framework of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> can offer scalability by enabling the participation of more users using efficient resource allocation. Moreover, it can offer sparsification by enabling the participation of suitable devices. Although the proposed framework offered several advantages, its performance against the security attacks can be further enhanced by using encryption schemes. Beyond wireless security, the centralized aggregation server might fail due to physical damage, and thus can be suffered from robustness issues.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Beyond the theoretical works on the deployment of federated learning at the network edge in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> proposed an architecture, namely, CoLearn for federated learning at edge networks. CoLearn was proposed to address the challenges of malicious devices’ presence and asynchronous participation of resource-constrained IoT devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. CoLearn uses federated learning framework <em id="S3.SS1.p3.1.1" class="ltx_emph ltx_font_italic">PySyft</em> and open-source Manufacturer Usage Description (MUD). PySyft is a python framework that can be used to implement federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. PySyft uses Pytorch while retaining native Torch interface. Fig. <a href="#S3.F7" title="Figure 7 ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the interaction between different components of CoLearn architecture. The CoLearn mainly consists of MUD manager and user policy server, federated learning server, and IoT devices. The IoT devices transmit their MUD-URLs in their DHCP requests to the router. The MUD manager sends valid IoT devices to the federated learning coordinator to minimize the risk of attack. Moreover, the federated learning coordinator performs interaction with devices using WebSockets and MQTT. To enable more flexibility in the design, the user policy server enables a network administrators to enforce rules other than defined by the manufacturer. The proposed architecture showed significant advantages, its performance can be further improved by applying light-weight authentication algorithms at the IoT devices. Another study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> demonstrated federated learning over emulated wide-area communications network having features of intermittent, heterogeneous, and dynamic availability of resources. The network is emulated using CORE/EMANE and consists of both mobile and fixed nodes. Any node can be selected as a server that initiates the process of federated learning. The specifications i.e., as the data type, expected prediction labels, and model architecture are broadcasted to all nodes during the task initialization phase. All the nodes wait for a certain time after the task initialization is done and then start the federated learning process. Any node in a network can leave or enter the learning process. The outdated local learning model parameters of the nodes are ignored and are not considered in the federated learning process. The proposed emulated federated learning environment has advantages of considering intermittent and dynamic behavior of the network resources that make it more feasible for practical applications. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, the authors provided an implementation of asynchronous federated learning for a scenario with both mobile and static nodes. However, a random selection of any node to act as an aggregation server might not always result in better performance. There must be an effective criterion for the selection of nodes to acts as a server. One possible criterion can be a selection of a static node as a server. This will enable higher connectivity to other static nodes compared to mobile nodes. However, this approach might not yield promising results when the number of mobile nodes is significantly greater than the static nodes. Therefore, we must propose effective criteria for the selection of nodes as an aggregation server that will result in higher connectivity with other devices involved in federated learning.</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2009.13012/assets/x12.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.3.2" class="ltx_text" style="font-size:90%;">CoLearn framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>.</span></figcaption>
</figure>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2009.13012/assets/x13.png" id="S3.F8.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="272" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.3.2" class="ltx_text" style="font-size:90%;">FedCS protocol steps <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</span></figcaption>
</figure>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">The aforementioned works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> provide theoretical analysis pertaining to the deployment of federated learning as well general architecture with implementation for IoT networks. In contrast, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> particularly focused on a federated learning client selection protocol, namely, <em id="S3.SS1.p4.1.1" class="ltx_emph ltx_font_italic">FedCS</em> (shown in Fig. <a href="#S3.F8" title="Figure 8 ‣ III-A Advances Based on Centralized Aggregation ‣ III State-Of-The-Art ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>) that offers an efficient selection of clients for federated learning process based on their available resources. Typically, client selection is performed randomly by a federated learning algorithm that might suffer from an increase in overall federated learning convergence time. For instance, selecting the nodes with the low computational resource (CPU-cycles/sec) results in an increase in overall federated learning time for synchronous federated learning. In FedCS, first of all, the edge computing server requests all the end-devices for their information such as data size, computational capacities, and wireless channel states. Based on the information, a set of nodes is selected for the federated learning process. Then, the edge server distributes the learning model updates to the selected nodes. Finally, all the selected nodes for learning update their local models and send them to the edge server. Simulation results showed that the FedCS mostly attains comparable accuracy within less time compared to traditional federated learning protocols for CIFAR-10 and Fashion-MNIST datasets. The FedCS protocol uses end-devices private information (e.g., the number and classes of its data) by aggregation server, and thus it might suffer from end-devices privacy leakage issue. Additionally, FedCS tried to involve a higher number of end-devices in learning for better performance. However, it does not consider power allocation that can be optimally performed to minimize the transmission latency so that a large number of devices will be able to participate in the synchronous federated learning process. Synchronous federated learning will consider only end-devices local learning models that arrive within a maximum limit of waiting time. On the other hand, a single aggregation edge server is considered in FedCS at BS. There may be multiple base stations (BSs) and an aggregation server will be at the remote cloud. For this kind of scenarios, one must use computing resource efficient devices and a BS association scheme for minimizing the transmission latency.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T5.2.1.1" class="ltx_text" style="font-size:90%;">TABLE V</span>: </span><span id="S3.T5.3.2" class="ltx_text" style="font-size:90%;">A summary of state-of-the-art advances.</span></figcaption>
<table id="S3.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T5.4.1" class="ltx_tr">
<td id="S3.T5.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S3.T5.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S3.T5.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.2.1.1" class="ltx_p" style="width:34.1pt;"><span id="S3.T5.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Local learning model</span></span>
</span>
</td>
<td id="S3.T5.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T5.4.1.3.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</td>
<td id="S3.T5.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S3.T5.4.1.4.1.1.1" class="ltx_text ltx_font_bold">Data Distribution</span></span>
</span>
</td>
<td id="S3.T5.4.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.5.1.1" class="ltx_p" style="width:34.1pt;"><span id="S3.T5.4.1.5.1.1.1" class="ltx_text ltx_font_bold">Aggregation fashion</span></span>
</span>
</td>
<td id="S3.T5.4.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.6.1.1" class="ltx_p" style="width:37.0pt;"><span id="S3.T5.4.1.6.1.1.1" class="ltx_text ltx_font_bold">Analytical convergence analysis</span></span>
</span>
</td>
<td id="S3.T5.4.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.7.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T5.4.1.7.1.1.1" class="ltx_text ltx_font_bold">Primary objective</span></span>
</span>
</td>
<td id="S3.T5.4.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T5.4.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.1.8.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T5.4.1.8.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</td>
</tr>
<tr id="S3.T5.4.2" class="ltx_tr">
<td id="S3.T5.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.1.1.1" class="ltx_p" style="width:28.5pt;">Wang <span id="S3.T5.4.2.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [29]</span>
</span>
</td>
<td id="S3.T5.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.2.1.1" class="ltx_p" style="width:34.1pt;">FNN</span>
</span>
</td>
<td id="S3.T5.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.3.1.1" class="ltx_p" style="width:42.7pt;">Xender’s trace [101]</span>
</span>
</td>
<td id="S3.T5.4.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.4.1.1" class="ltx_p" style="width:34.1pt;">Non-IID</span>
</span>
</td>
<td id="S3.T5.4.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.7.1.1" class="ltx_p" style="width:85.4pt;">Federated learning was used for training of Deep Q-agents in a resource optimized way.</span>
</span>
</td>
<td id="S3.T5.4.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.2.8.1.1" class="ltx_p" style="width:85.4pt;">Edge-AI framework has security and privacy concerns.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.3" class="ltx_tr">
<td id="S3.T5.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.1.1.1" class="ltx_p" style="width:28.5pt;">Wang <span id="S3.T5.4.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>,  [88]</span>
</span>
</td>
<td id="S3.T5.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.2.1.1" class="ltx_p" style="width:34.1pt;">SVM, CNN</span>
</span>
</td>
<td id="S3.T5.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST, Fashion MNIST</span>
</span>
</td>
<td id="S3.T5.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.6.1.1" class="ltx_p" style="width:37.0pt;">✓</span>
</span>
</td>
<td id="S3.T5.4.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.7.1.1" class="ltx_p" style="width:85.4pt;">Optimized number of local iterations at network edge.</span>
</span>
</td>
<td id="S3.T5.4.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.3.8.1.1" class="ltx_p" style="width:85.4pt;">No convergence analysis for non-convex loss functions</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.4" class="ltx_tr">
<td id="S3.T5.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.1.1.1" class="ltx_p" style="width:28.5pt;">Chen <span id="S3.T5.4.4.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [64]</span>
</span>
</td>
<td id="S3.T5.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.2.1.1" class="ltx_p" style="width:34.1pt;">FNN</span>
</span>
</td>
<td id="S3.T5.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST, Synthetic dataset</span>
</span>
</td>
<td id="S3.T5.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.4.1.1" class="ltx_p" style="width:34.1pt;">Non-IID</span>
</span>
</td>
<td id="S3.T5.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.6.1.1" class="ltx_p" style="width:37.0pt;">✓</span>
</span>
</td>
<td id="S3.T5.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.7.1.1" class="ltx_p" style="width:85.4pt;">A joint learning and communication framework for federated learning at edge was proposed.</span>
</span>
</td>
<td id="S3.T5.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.4.8.1.1" class="ltx_p" style="width:85.4pt;">No convergence analysis for non-convex loss functions</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.5" class="ltx_tr">
<td id="S3.T5.4.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.1.1.1" class="ltx_p" style="width:28.5pt;">Feraudo <span id="S3.T5.4.5.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [89]</span>
</span>
</td>
<td id="S3.T5.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.2.1.1" class="ltx_p" style="width:34.1pt;">FNN</span>
</span>
</td>
<td id="S3.T5.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.3.1.1" class="ltx_p" style="width:42.7pt;">IoT Botnet identification dataset</span>
</span>
</td>
<td id="S3.T5.4.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.4.1.1" class="ltx_p" style="width:34.1pt;">IID</span>
</span>
</td>
<td id="S3.T5.4.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.7.1.1" class="ltx_p" style="width:85.4pt;">A CoLearn framework for federated learning at network edge was proposed.</span>
</span>
</td>
<td id="S3.T5.4.5.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.5.8.1.1" class="ltx_p" style="width:85.4pt;">CoLearn framework has security concerns.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.6" class="ltx_tr">
<td id="S3.T5.4.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.1.1.1" class="ltx_p" style="width:28.5pt;">Conway-Jones <span id="S3.T5.4.6.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [95]</span>
</span>
</td>
<td id="S3.T5.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.2.1.1" class="ltx_p" style="width:34.1pt;">SVM</span>
</span>
</td>
<td id="S3.T5.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST</span>
</span>
</td>
<td id="S3.T5.4.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.7.1.1" class="ltx_p" style="width:85.4pt;">Emulated federated learning in a resource constrained environment.</span>
</span>
</td>
<td id="S3.T5.4.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.6.8.1.1" class="ltx_p" style="width:85.4pt;">Lack of efficient criteria for selecting node as an aggregation server</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.7" class="ltx_tr">
<td id="S3.T5.4.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.1.1.1" class="ltx_p" style="width:28.5pt;">Nishio <span id="S3.T5.4.7.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [45]</span>
</span>
</td>
<td id="S3.T5.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.3.1.1" class="ltx_p" style="width:42.7pt;">Fashion MNIST, CIFAR-10</span>
</span>
</td>
<td id="S3.T5.4.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.7.1.1" class="ltx_p" style="width:85.4pt;">A client selection protocol for performance improvement in FedAvg was proposed.</span>
</span>
</td>
<td id="S3.T5.4.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.7.8.1.1" class="ltx_p" style="width:85.4pt;">FedCS protocol did not consider transmit power allocation than can further improve performance.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.8" class="ltx_tr">
<td id="S3.T5.4.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.1.1.1" class="ltx_p" style="width:28.5pt;">Kang <span id="S3.T5.4.8.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [94]</span>
</span>
</td>
<td id="S3.T5.4.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.2.1.1" class="ltx_p" style="width:34.1pt;">Not available</span>
</span>
</td>
<td id="S3.T5.4.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST</span>
</span>
</td>
<td id="S3.T5.4.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.7.1.1" class="ltx_p" style="width:85.4pt;">A framework to minimize false local learning model injection was proposed.</span>
</span>
</td>
<td id="S3.T5.4.8.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.8.8.1.1" class="ltx_p" style="width:85.4pt;">High latency due to running blockchain consensus algorithm</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.9" class="ltx_tr">
<td id="S3.T5.4.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.1.1.1" class="ltx_p" style="width:28.5pt;">Chen <span id="S3.T5.4.9.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [97]</span>
</span>
</td>
<td id="S3.T5.4.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.3.1.1" class="ltx_p" style="width:42.7pt;">UCI Smartphone [102]</span>
</span>
</td>
<td id="S3.T5.4.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.4.1.1" class="ltx_p" style="width:34.1pt;">Non-IID</span>
</span>
</td>
<td id="S3.T5.4.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.7.1.1" class="ltx_p" style="width:85.4pt;">Federated healthcare framework using transfer learning was proposed.</span>
</span>
</td>
<td id="S3.T5.4.9.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.9.8.1.1" class="ltx_p" style="width:85.4pt;">The framework did not effectively address the issue of data heterogeneity.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.10" class="ltx_tr">
<td id="S3.T5.4.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.1.1.1" class="ltx_p" style="width:28.5pt;">Yu <span id="S3.T5.4.10.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [93]</span>
</span>
</td>
<td id="S3.T5.4.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.3.1.1" class="ltx_p" style="width:42.7pt;">Pascal VOC 2007, Pascal VOC 2012 [103]</span>
</span>
</td>
<td id="S3.T5.4.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.7.1.1" class="ltx_p" style="width:85.4pt;">Federated learning-based object detection scheme was proposed.</span>
</span>
</td>
<td id="S3.T5.4.10.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.10.8.1.1" class="ltx_p" style="width:85.4pt;">Federated optimization scheme can be modified to improve the performance for extreme non-IID case.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.11" class="ltx_tr">
<td id="S3.T5.4.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.1.1.1" class="ltx_p" style="width:28.5pt;">Ye <span id="S3.T5.4.11.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [99]</span>
</span>
</td>
<td id="S3.T5.4.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST, BelgiumTSC [104]</span>
</span>
</td>
<td id="S3.T5.4.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.4.1.1" class="ltx_p" style="width:34.1pt;">IID</span>
</span>
</td>
<td id="S3.T5.4.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized aggregation</span>
</span>
</td>
<td id="S3.T5.4.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.7.1.1" class="ltx_p" style="width:85.4pt;">Federated learning framework for vehicular edge computing was proposed.</span>
</span>
</td>
<td id="S3.T5.4.11.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.11.8.1.1" class="ltx_p" style="width:85.4pt;">The framework has robustness issues in case of failure of a centralized aggregation server.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.12" class="ltx_tr">
<td id="S3.T5.4.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.1.1.1" class="ltx_p" style="width:28.5pt;">Chen <span id="S3.T5.4.12.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [98]</span>
</span>
</td>
<td id="S3.T5.4.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.3.1.1" class="ltx_p" style="width:42.7pt;">CIFAR-10</span>
</span>
</td>
<td id="S3.T5.4.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.5.1.1" class="ltx_p" style="width:34.1pt;">Centralized averaging</span>
</span>
</td>
<td id="S3.T5.4.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.12.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.7.1.1" class="ltx_p" style="width:85.4pt;">Federated learning-based augmented reality framework was proposed.</span>
</span>
</td>
<td id="S3.T5.4.12.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.12.8.1.1" class="ltx_p" style="width:85.4pt;">FedAvg can be replaced by other federated optimization schemes (e.g., FedProx) to further improve the performance.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.13" class="ltx_tr">
<td id="S3.T5.4.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.1.1.1" class="ltx_p" style="width:28.5pt;">Qu <span id="S3.T5.4.13.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [91]</span>
</span>
</td>
<td id="S3.T5.4.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.3.1.1" class="ltx_p" style="width:42.7pt;">Fashion-MNIST, CIFAR-10</span>
</span>
</td>
<td id="S3.T5.4.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.4.1.1" class="ltx_p" style="width:34.1pt;">IID</span>
</span>
</td>
<td id="S3.T5.4.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.5.1.1" class="ltx_p" style="width:34.1pt;">Distributed aggregations</span>
</span>
</td>
<td id="S3.T5.4.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.13.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.7.1.1" class="ltx_p" style="width:85.4pt;">A robust architecture, namely, FL-Block was proposed.</span>
</span>
</td>
<td id="S3.T5.4.13.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.13.8.1.1" class="ltx_p" style="width:85.4pt;">High latency and energy consumption associated with the framework</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.14" class="ltx_tr">
<td id="S3.T5.4.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.1.1.1" class="ltx_p" style="width:28.5pt;">Savazzi <span id="S3.T5.4.14.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [96]</span>
</span>
</td>
<td id="S3.T5.4.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.2.1.1" class="ltx_p" style="width:34.1pt;">CNN, 2-NN</span>
</span>
</td>
<td id="S3.T5.4.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.3.1.1" class="ltx_p" style="width:42.7pt;">Real time industrial IoT setup data</span>
</span>
</td>
<td id="S3.T5.4.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.4.1.1" class="ltx_p" style="width:34.1pt;">Non-IID</span>
</span>
</td>
<td id="S3.T5.4.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.5.1.1" class="ltx_p" style="width:34.1pt;">Distributed aggregations</span>
</span>
</td>
<td id="S3.T5.4.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.14.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.7.1.1" class="ltx_p" style="width:85.4pt;">A framework using cooperation among devices to enable federated learning without using centralized aggregation server.</span>
</span>
</td>
<td id="S3.T5.4.14.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.14.8.1.1" class="ltx_p" style="width:85.4pt;">The framework did not consider resource and power allocation that can further improve its performance.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.15" class="ltx_tr">
<td id="S3.T5.4.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.1.1.1" class="ltx_p" style="width:28.5pt;">Zhao <span id="S3.T5.4.15.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [90]</span>
</span>
</td>
<td id="S3.T5.4.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.2.1.1" class="ltx_p" style="width:34.1pt;">MLP</span>
</span>
</td>
<td id="S3.T5.4.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST</span>
</span>
</td>
<td id="S3.T5.4.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.5.1.1" class="ltx_p" style="width:34.1pt;">Hierarchical aggregation</span>
</span>
</td>
<td id="S3.T5.4.15.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.6.1.1" class="ltx_p" style="width:37.0pt;">✗</span>
</span>
</td>
<td id="S3.T5.4.15.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.7.1.1" class="ltx_p" style="width:85.4pt;">A hierarchical architecture for federated learning using for radio access was proposed.</span>
</span>
</td>
<td id="S3.T5.4.15.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.15.8.1.1" class="ltx_p" style="width:85.4pt;">No theoretical convergence analysis for their proposed scheme</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.16" class="ltx_tr">
<td id="S3.T5.4.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.1.1.1" class="ltx_p" style="width:28.5pt;">Wang <span id="S3.T5.4.16.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [105]</span>
</span>
</td>
<td id="S3.T5.4.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.2.1.1" class="ltx_p" style="width:34.1pt;">Not available</span>
</span>
</td>
<td id="S3.T5.4.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.3.1.1" class="ltx_p" style="width:42.7pt;">CIFAR-10</span>
</span>
</td>
<td id="S3.T5.4.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.5.1.1" class="ltx_p" style="width:34.1pt;">Hierarchical aggregation</span>
</span>
</td>
<td id="S3.T5.4.16.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.6.1.1" class="ltx_p" style="width:37.0pt;">✓</span>
</span>
</td>
<td id="S3.T5.4.16.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.7.1.1" class="ltx_p" style="width:85.4pt;">Hierarchical federated learning framework was proposed.</span>
</span>
</td>
<td id="S3.T5.4.16.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T5.4.16.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.16.8.1.1" class="ltx_p" style="width:85.4pt;">A criterion for grouping of devices based on wireless parameters is missing.</span>
</span>
</td>
</tr>
<tr id="S3.T5.4.17" class="ltx_tr">
<td id="S3.T5.4.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.1.1.1" class="ltx_p" style="width:28.5pt;">Liu <span id="S3.T5.4.17.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, [31]</span>
</span>
</td>
<td id="S3.T5.4.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.2.1.1" class="ltx_p" style="width:34.1pt;">CNN</span>
</span>
</td>
<td id="S3.T5.4.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.3.1.1" class="ltx_p" style="width:42.7pt;">MNIST, CIFAR-10</span>
</span>
</td>
<td id="S3.T5.4.17.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.4.1.1" class="ltx_p" style="width:34.1pt;">IID, non-IID</span>
</span>
</td>
<td id="S3.T5.4.17.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.5.1.1" class="ltx_p" style="width:34.1pt;">Hierarchical aggregation</span>
</span>
</td>
<td id="S3.T5.4.17.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.6.1.1" class="ltx_p" style="width:37.0pt;">✓</span>
</span>
</td>
<td id="S3.T5.4.17.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.7.1.1" class="ltx_p" style="width:85.4pt;">Hierarchical edge-cloud-based federated learning framework was proposed.</span>
</span>
</td>
<td id="S3.T5.4.17.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T5.4.17.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T5.4.17.8.1.1" class="ltx_p" style="width:85.4pt;">Robustness concerns due a centralized global aggregation server</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T6.2.1.1" class="ltx_text" style="font-size:90%;">TABLE VI</span>: </span><span id="S3.T6.3.2" class="ltx_text" style="font-size:90%;">Primary contribution area, key contributions, and evaluation of the recent advances.</span></figcaption>
<table id="S3.T6.4" class="ltx_tabular ltx_align_middle">
<tr id="S3.T6.4.1" class="ltx_tr">
<td id="S3.T6.4.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T6.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.1.1.1.1" class="ltx_p">Primary contribution area</span>
</span>
</td>
<td id="S3.T6.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" rowspan="2">
<span id="S3.T6.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.1.2.1.1" class="ltx_p" style="width:51.2pt;"><span id="S3.T6.4.1.2.1.1.1" class="ltx_text">Reference</span></span>
</span>
</td>
<td id="S3.T6.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" rowspan="2">
<span id="S3.T6.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.1.3.1.1" class="ltx_p" style="width:199.2pt;"><span id="S3.T6.4.1.3.1.1.1" class="ltx_text">Key contributions</span></span>
</span>
</td>
<td id="S3.T6.4.1.4" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="5">Evaluation parameters</td>
</tr>
<tr id="S3.T6.4.2" class="ltx_tr">
<td id="S3.T6.4.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P1</td>
<td id="S3.T6.4.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P2</td>
<td id="S3.T6.4.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P3</td>
<td id="S3.T6.4.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P4</td>
<td id="S3.T6.4.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P5</td>
</tr>
<tr id="S3.T6.4.3" class="ltx_tr">
<td id="S3.T6.4.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T6.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.3.1.1.1" class="ltx_p">Edge AI</span>
</span>
</td>
<td id="S3.T6.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.3.2.1.1" class="ltx_p" style="width:51.2pt;">Wang <span id="S3.T6.4.3.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>,  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.3.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I2" class="ltx_itemize">
<span id="S3.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i1.p1" class="ltx_para">
<span id="S3.I2.i1.p1.1" class="ltx_p">A control algorithm is proposed to minimize learning loss under resource budget constraints.</span>
</span></span>
<span id="S3.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i2.p1" class="ltx_para">
<span id="S3.I2.i2.p1.1" class="ltx_p">Performance of the proposed algorithm was evaluated using real time datasets.</span>
</span></span>
<span id="S3.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i3.p1" class="ltx_para">
<span id="S3.I2.i3.p1.1" class="ltx_p">A theoretical convergence bound was derived for federated learning at network edge.</span>
</span></span>
<span id="S3.I2.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i4.p1" class="ltx_para">
<span id="S3.I2.i4.p1.1" class="ltx_p">The proposed control algorithm learns learning model characteristics, system dynamics, and data distribution.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.3.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.3.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.4" class="ltx_tr">
<td id="S3.T6.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.4.2.1.1" class="ltx_p" style="width:51.2pt;">Wang <span id="S3.T6.4.4.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.4.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I3" class="ltx_itemize">
<span id="S3.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i1.p1" class="ltx_para">
<span id="S3.I3.i1.p1.1" class="ltx_p">An EdgeAI framework was proposed.</span>
</span></span>
<span id="S3.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i2.p1" class="ltx_para">
<span id="S3.I3.i2.p1.1" class="ltx_p">Intelligent computation offloading and edge caching were considered.</span>
</span></span>
<span id="S3.I3.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i3.p1" class="ltx_para">
<span id="S3.I3.i3.p1.1" class="ltx_p">Used double deep Q-learning networks.</span>
</span></span>
<span id="S3.I3.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I3.i4.p1" class="ltx_para">
<span id="S3.I3.i4.p1.1" class="ltx_p">Federated learning was considered for reducing the transmission overhead during the training process.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.4.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.4.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.5" class="ltx_tr">
<td id="S3.T6.4.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.5.2.1.1" class="ltx_p" style="width:51.2pt;">Nishio <span id="S3.T6.4.5.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.5.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I4" class="ltx_itemize">
<span id="S3.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i1.p1" class="ltx_para">
<span id="S3.I4.i1.p1.1" class="ltx_p">Proposed a client selection protocol using edge server.</span>
</span></span>
<span id="S3.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i2.p1" class="ltx_para">
<span id="S3.I4.i2.p1.1" class="ltx_p">The edge server manages the resources for communication between clients and edge server.</span>
</span></span>
<span id="S3.I4.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I4.i3.p1" class="ltx_para">
<span id="S3.I4.i3.p1.1" class="ltx_p">The proposed FedCS mostly has attained accuracy within less time for CIFAR-10 and Fashion-MNIST datasets.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
</tr>
<tr id="S3.T6.4.6" class="ltx_tr">
<td id="S3.T6.4.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.6.2.1.1" class="ltx_p" style="width:51.2pt;">Feraudo <span id="S3.T6.4.6.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.6.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I5" class="ltx_itemize">
<span id="S3.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I5.i1.p1" class="ltx_para">
<span id="S3.I5.i1.p1.1" class="ltx_p">A federated learning architecture for edge networks called as CoLearn was proposed.</span>
</span></span>
<span id="S3.I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I5.i2.p1" class="ltx_para">
<span id="S3.I5.i2.p1.1" class="ltx_p">To enable more flexibility in their architecture, the user policy server was considered that enables network administrator to enforce rules other than defined by manufacturer.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.6.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.6.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.7" class="ltx_tr">
<td id="S3.T6.4.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.7.2.1.1" class="ltx_p" style="width:51.2pt;">Zhao <span id="S3.T6.4.7.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <span id="S3.T6.4.7.2.1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.7.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I6" class="ltx_itemize">
<span id="S3.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I6.i1.p1" class="ltx_para">
<span id="S3.I6.i1.p1.1" class="ltx_p">A federated learning-enabled intelligent fog radio access networks framework was proposed.</span>
</span></span>
<span id="S3.I6.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I6.i2.p1" class="ltx_para">
<span id="S3.I6.i2.p1.1" class="ltx_p">Considered hierarchical federated learning that offered two stages of learning model aggregation such as local at fog node and global at cloud.</span>
</span></span>
<span id="S3.I6.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I6.i3.p1" class="ltx_para">
<span id="S3.I6.i3.p1.1" class="ltx_p">Neural network compression and learning model parameters compression are considered.</span>
</span></span>
<span id="S3.I6.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I6.i4.p1" class="ltx_para">
<span id="S3.I6.i4.p1.1" class="ltx_p">Key enabling technologies for enabling federated learning-enabled intelligent fog radio access networks were presented.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.7.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.7.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.8" class="ltx_tr">
<td id="S3.T6.4.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T6.4.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.8.2.1.1" class="ltx_p" style="width:51.2pt;">Qu <span id="S3.T6.4.8.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.8.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I7" class="ltx_itemize">
<span id="S3.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I7.i1.p1" class="ltx_para">
<span id="S3.I7.i1.p1.1" class="ltx_p">Proposed a blockchain-enabled federated learning (FL-Block) for fog computing scenarios to offers robustness against the poisoning attacks.</span>
</span></span>
<span id="S3.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I7.i2.p1" class="ltx_para">
<span id="S3.I7.i2.p1.1" class="ltx_p">FL-Block used decentralized fashion for aggregation of local learning model rather than centralized server to offer robustness.</span>
</span></span>
<span id="S3.I7.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I7.i3.p1" class="ltx_para">
<span id="S3.I7.i3.p1.1" class="ltx_p">Additionally, decentralized privacy scheme was proposed for FL-Block.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.8.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T6.4.8.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.9" class="ltx_tr">
<td id="S3.T6.4.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T6.4.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.9.1.1.1" class="ltx_p">Smart object detection</span>
</span>
</td>
<td id="S3.T6.4.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.9.2.1.1" class="ltx_p" style="width:51.2pt;">Yu <span id="S3.T6.4.9.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T6.4.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.9.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I8" class="ltx_itemize">
<span id="S3.I8.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I8.i1.p1" class="ltx_para">
<span id="S3.I8.i1.p1.1" class="ltx_p">Proposed a smart object detection scheme.</span>
</span></span>
<span id="S3.I8.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I8.i2.p1" class="ltx_para">
<span id="S3.I8.i2.p1.1" class="ltx_p">Considered three types of data distribution such as IID. Non-IID, and extreme IID for analysis.</span>
</span></span>
<span id="S3.I8.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I8.i3.p1" class="ltx_para">
<span id="S3.I8.i3.p1.1" class="ltx_p">Abnormal weights suppression was used to trim the weights far from average normal weights during training.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.9.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.9.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T6.4.10" class="ltx_tr">
<td id="S3.T6.4.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;" rowspan="3">
<span id="S3.T6.4.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.10.1.1.1" class="ltx_p">Augmented/Virtual reality</span>
</span>
</td>
<td id="S3.T6.4.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T6.4.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.10.2.1.1" class="ltx_p" style="width:51.2pt;">Chen <span id="S3.T6.4.10.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite></span>
</span>
</td>
<td id="S3.T6.4.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T6.4.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T6.4.10.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I9" class="ltx_itemize">
<span id="S3.I9.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I9.i1.p1" class="ltx_para">
<span id="S3.I9.i1.p1.1" class="ltx_p">A system model for augmented reality applications with object detection and classification problem formulation was presented.</span>
</span></span>
<span id="S3.I9.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I9.i2.p1" class="ltx_para">
<span id="S3.I9.i2.p1.1" class="ltx_p">To solve the formulated problem, the authors proposed a framework based on mobile edge computing enabled by federated learning.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T6.4.10.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.10.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.10.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.10.7" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T6.4.10.8" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
</tr>
</table>
</figure>
<figure id="S3.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T7.2.1.1" class="ltx_text" style="font-size:90%;">TABLE VII</span>: </span><span id="S3.T7.3.2" class="ltx_text" style="font-size:90%;">Primary contribution area, key contributions, and evaluation of the recent advances.</span></figcaption>
<table id="S3.T7.4" class="ltx_tabular ltx_align_middle">
<tr id="S3.T7.4.1" class="ltx_tr">
<td id="S3.T7.4.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T7.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.1.1.1.1" class="ltx_p">Primary contribution area</span>
</span>
</td>
<td id="S3.T7.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" rowspan="2">
<span id="S3.T7.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.1.2.1.1" class="ltx_p" style="width:51.2pt;"><span id="S3.T7.4.1.2.1.1.1" class="ltx_text">Reference</span></span>
</span>
</td>
<td id="S3.T7.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" rowspan="2">
<span id="S3.T7.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.1.3.1.1" class="ltx_p" style="width:199.2pt;"><span id="S3.T7.4.1.3.1.1.1" class="ltx_text">Key contributions</span></span>
</span>
</td>
<td id="S3.T7.4.1.4" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="5">Evaluation parameters</td>
</tr>
<tr id="S3.T7.4.2" class="ltx_tr">
<td id="S3.T7.4.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P1</td>
<td id="S3.T7.4.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P2</td>
<td id="S3.T7.4.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P3</td>
<td id="S3.T7.4.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P4</td>
<td id="S3.T7.4.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">P5</td>
</tr>
<tr id="S3.T7.4.3" class="ltx_tr">
<td id="S3.T7.4.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T7.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.3.1.1.1" class="ltx_p">Mobile networks</span>
</span>
</td>
<td id="S3.T7.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.3.2.1.1" class="ltx_p" style="width:51.2pt;">Kang <span id="S3.T7.4.3.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.3.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I10" class="ltx_itemize">
<span id="S3.I10.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I10.i1.p1" class="ltx_para">
<span id="S3.I10.i1.p1.1" class="ltx_p">Proposed a reliable federated learning scheme based on consortium blockchain for mobile networks.</span>
</span></span>
<span id="S3.I10.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I10.i2.p1" class="ltx_para">
<span id="S3.I10.i2.p1.1" class="ltx_p">Using the reputation-based metric, a worker (reliable end-devices) selection scheme based on consortium blockchain was proposed.</span>
</span></span>
<span id="S3.I10.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I10.i3.p1" class="ltx_para">
<span id="S3.I10.i3.p1.1" class="ltx_p">Several future research directions were provided.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.3.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.3.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.4" class="ltx_tr">
<td id="S3.T7.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.4.2.1.1" class="ltx_p" style="width:51.2pt;">Conway-Jones <span id="S3.T7.4.4.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.4.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I11" class="ltx_itemize">
<span id="S3.I11.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I11.i1.p1" class="ltx_para">
<span id="S3.I11.i1.p1.1" class="ltx_p">Federated learning over emulated wide area communications network having features of intermittent, heterogeneous, and dynamic availability of resources was studied.</span>
</span></span>
<span id="S3.I11.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I11.i2.p1" class="ltx_para">
<span id="S3.I11.i2.p1.1" class="ltx_p">Intermittent and dynamic behavior was considered which might made the design suitable for use in various practical applications.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.4.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.4.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.5" class="ltx_tr">
<td id="S3.T7.4.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.5.2.1.1" class="ltx_p" style="width:51.2pt;">Savazzi <span id="S3.T7.4.5.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.5.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I12" class="ltx_itemize">
<span id="S3.I12.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I12.i1.p1" class="ltx_para">
<span id="S3.I12.i1.p1.1" class="ltx_p">Presented federated learning scheme that uses cooperation between devices to avoid use of centralized edge/cloud server for global model aggregation.</span>
</span></span>
<span id="S3.I12.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I12.i2.p1" class="ltx_para">
<span id="S3.I12.i2.p1.1" class="ltx_p">Two strategies such as consensus-based federated averaging and consensus-based federated averaging with gradients exchange, were proposed to enable effective distributed optimization.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.6" class="ltx_tr">
<td id="S3.T7.4.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.6.2.1.1" class="ltx_p" style="width:51.2pt;">Chen <span id="S3.T7.4.6.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.6.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I13" class="ltx_itemize">
<span id="S3.I13.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I13.i1.p1" class="ltx_para">
<span id="S3.I13.i1.p1.1" class="ltx_p">A framework for joint learning and communication for wireless federated learning was presented.</span>
</span></span>
<span id="S3.I13.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I13.i2.p1" class="ltx_para">
<span id="S3.I13.i2.p1.1" class="ltx_p">A problem for joint power allocation, resource block allocation, and user selection problem was formulated.</span>
</span></span>
<span id="S3.I13.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I13.i3.p1" class="ltx_para">
<span id="S3.I13.i3.p1.1" class="ltx_p">A close-form expression for the expected convergence rate of federated learning was derived to account for the effect of wireless channel on federated learning.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.6.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.6.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
</tr>
<tr id="S3.T7.4.7" class="ltx_tr">
<td id="S3.T7.4.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.7.2.1.1" class="ltx_p" style="width:51.2pt;">Wang <span id="S3.T7.4.7.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.7.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I14" class="ltx_itemize">
<span id="S3.I14.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I14.i1.p1" class="ltx_para">
<span id="S3.I14.i1.p1.1" class="ltx_p">A hierarchical framework for federated learning was presented.</span>
</span></span>
<span id="S3.I14.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I14.i2.p1" class="ltx_para">
<span id="S3.I14.i2.p1.1" class="ltx_p">Detailed convergence analysis were presented.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.7.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.7.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.8" class="ltx_tr">
<td id="S3.T7.4.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:85.4pt;"></td>
<td id="S3.T7.4.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.8.2.1.1" class="ltx_p" style="width:51.2pt;">Liu <span id="S3.T7.4.8.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.8.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I15" class="ltx_itemize">
<span id="S3.I15.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I15.i1.p1" class="ltx_para">
<span id="S3.I15.i1.p1.1" class="ltx_p">An edge-cloud-hierarchical federated learning framework was presented.</span>
</span></span>
<span id="S3.I15.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I15.i2.p1" class="ltx_para">
<span id="S3.I15.i2.p1.1" class="ltx_p">Convergence analysis with simulation results were presented.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.8.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.8.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.9" class="ltx_tr">
<td id="S3.T7.4.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T7.4.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.9.1.1.1" class="ltx_p">Smart health-care</span>
</span>
</td>
<td id="S3.T7.4.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.9.2.1.1" class="ltx_p" style="width:51.2pt;">Chen <span id="S3.T7.4.9.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T7.4.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.9.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I16" class="ltx_itemize">
<span id="S3.I16.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I16.i1.p1" class="ltx_para">
<span id="S3.I16.i1.p1.1" class="ltx_p">A framework namely, FedHealth, based on federated transfer learning was proposed for smart health-care.</span>
</span></span>
<span id="S3.I16.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I16.i2.p1" class="ltx_para">
<span id="S3.I16.i2.p1.1" class="ltx_p">Homomorphic encryption was considered for secure transfer of learning model updates between the end-users and aggregation server.</span>
</span></span>
<span id="S3.I16.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I16.i3.p1" class="ltx_para">
<span id="S3.I16.i3.p1.1" class="ltx_p">Transfer learning was used by FedHealth framework to enable effective personalized models for end-users.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✓</td>
<td id="S3.T7.4.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.9.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.9.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">✗</td>
</tr>
<tr id="S3.T7.4.10" class="ltx_tr">
<td id="S3.T7.4.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="width:85.4pt;" rowspan="3">
<span id="S3.T7.4.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.10.1.1.1" class="ltx_p">Vehicular networks</span>
</span>
</td>
<td id="S3.T7.4.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T7.4.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.10.2.1.1" class="ltx_p" style="width:51.2pt;">Ye <span id="S3.T7.4.10.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite></span>
</span>
</td>
<td id="S3.T7.4.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T7.4.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T7.4.10.3.1.1" class="ltx_p" style="width:199.2pt;">
<span id="S3.I17" class="ltx_itemize">
<span id="S3.I17.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I17.i1.p1" class="ltx_para">
<span id="S3.I17.i1.p1.1" class="ltx_p">Proposed a selective model aggregation-based federated learning framework for image classification task in vehicular edge computing.</span>
</span></span>
<span id="S3.I17.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I17.i2.p1" class="ltx_para">
<span id="S3.I17.i2.p1.1" class="ltx_p">To overcome the limitation of FedAvg that is based on random selection of clients for learning process, the authors proposed a selective clients selection based on contract theory.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S3.T7.4.10.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.10.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.10.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.10.7" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✗</td>
<td id="S3.T7.4.10.8" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">✓</td>
</tr>
</table>
</figure>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">To apply federated learning for IoT networks, we must take into account the reliability of end-devices involved in federated learning. A malicious end-device can send the wrong local learning model updates to the aggregation server, and thus delay the convergence of the global federated learning model. Additionally, the global federated learning model might not converge due to wrong local learning model updates. Therefore, there is a need to address this challenge. To do so, Kang <span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_italic">et al.</span> proposed a reliable federated learning scheme based on consortium blockchain for mobile networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. The proposed scheme tackles the issue of unreliable updates in federated learning process. A non trusty end-device can send unreliable updates to the aggregation server, and thus degrades the global federated learning accuracy. The authors introduced reputation-based metric for reliable federated learning over mobile networks. Using the reputation-based metric, a worker (i.e., reliable end-devices) selection scheme based on consortium blockchain is proposed. The scheme consists of five steps, task publishment, worker selection, reputation collection, federated learning, and reputation updating. In task publishment, task publishers broadcast task with requirements to mobile devices. Mobile devices fulfilling requirements and willing to join a certain task in turn send joining request to publisher. Next in worker selection scheme, the publisher verifies devices and allow only valid devices participation. The workers with reputation values (computed using subjective logic model) greater than the certain threshold are selected. Then, the federated learning step is performed to yield global federated learning model updates. Finally, the reputation values of end-devices are updated to yield the latest updates after blockchain consensus algorithm is finished. Although the proposed scheme offers protection against malicious users in federated learning, the delay associated with the blockchain consensus algorithm might not be desirable. Additionally, the energy consumption associated with the blockchain consensus algorithm must be minimized. For instance, PoW consumes significantly high energy and suffers from high latency but it offers more decentralization. Therefore, depending on the IoT application and requirements, one must develop blockchain consensus algorithms that will consume low energy (e.g., delegated proof of stake) and offer low-latency (e.g., Byzantine fault tolerance) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">The works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> applied federated learning various IoT applications. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, a framework, namely, FedHealth, based on federated transfer learning was proposed for smart health-care. The purpose of using transfer learning in FedHealth is to reduce the distribution divergence among various domains. Additionally, FedHealth uses homomorphic encryption to enable secure transfer of learning model updates between the aggregation server and end-users. FedAvg has been used as a federated optimization scheme in FedHealth. Although the global model obtained at cloud is available to all end-users, the personalized model for each user might not perform well. Therefore, to improve the performance of the federated learning model for end-users, the authors used transfer learning to learn personalized models. For validation of the FedHealth framework, the public human activity recognition dataset, namely, UCI smartphone was used. The FedHealth framework considered FedAvg as a federated optimization scheme, and thus, its performance can be further improved using FedProx that better considers heterogeneity among end-users. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, Yu <span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_italic">et al.</span> proposed a federated learning-based object detection scheme to overcome the privacy leakage issue of deep learning-based object detection schemes. The authors considered three kinds of data distributions such as IID, non-IID, and extreme non-IID. IID has local datasets of similar distribution, whereas non-IID uses a subset of images of a certain type for the same client. In the case of extreme non-IID, the only object of interest is marked (labeled) in contrast to the non-IID case which involves marking all the objects. The authors used abnormal weight suppression in their proposed federated object detection model to enable trimming of the weights (due to non-IID and extreme non-IID local datasets) that are far from normal weights mean. The federated learning-based object detection model was validated for both IID and non-IID data which revealed degraded performance for non-IID data. Furthermore, for extreme non-IID datasets, performance degradation is the highest.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">Ye <span id="S3.SS1.p7.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> proposed a selective model aggregation-based federated learning framework for image classification task in vehicular edge computing. The proposed framework consists of a centralized server and vehicular clients. The vehicular clients equipped with various sensors to capture images, train their local learning models for image classification tasks after receiving a request from the centralized server. The locally learned models are then sent to the centralized server for global aggregation. To overcome the limitation of FedAvg that is based on a random selection of clients for the learning process, the authors proposed a selective client selection. Selecting clients with low image quality and poor performance degrades the global federated learning model accuracy. Therefore, we must select clients with better performance. However, determining the client local information (i.e., image quality and computational power) at the centralized is server is not available. Coping with this challenge of information asymmetry, a set of devices with fine quality images is selected using contract theory-based scheme. The authors evaluated their scheme for Belgium TSC and MNIST datasets which showed better performance than FedAvg.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.1" class="ltx_p">Chen <span id="S3.SS1.p8.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> studied augmented reality based on federated learning-enabled mobile edge computing. Specifically, the authors focused on the solution of computation efficiency, low-latency object detection, and classification problems of AR applications. A system model for augmented reality applications with object detection and classification problem formulation was presented. One way to solve the problem is through the use of centralized machine learning. However, it suffers from high communication resources consumption costs associated with transferring the data from end-devices to the centralized server for training. Moreover, the end-devices of augmented reality-based applications might not want to share their data with the centralized server due to privacy concerns. To solve the formulated problem, the authors proposed a framework based on mobile edge computing enabled by federated learning. Finally, the authors validated their proposal for image classification tasks using CIFAR-10 datasets for non-IID and IID settings.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Advances Based on Distributed Aggregation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> considered federated learning based on a distributed aggregation of end-devices local learning models for various IoT applications. Here, end-devices compute their local learning models and sent the learning model updates to various distributed aggregation servers. The distributed aggregation servers share the local learning models of their associated end-devices and finally, perform global model aggregation. In contrast to the centralized aggregation server-based federated learning, distributed aggregation servers based federated learning do not require the use of a centralized aggregation server. Qu <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> proposed a blockchain-enabled federated learning
(FL-Block) for fog computing scenarios to offers robustness against the poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. FL-Block uses decentralized fashion for aggregation of local learning models rather than the centralized server to offer robustness. A single centralized server might get malfunctioned or accessed by an unauthorized malicious user. The process of federated learning in FL-Block starts with the local learning model by all the devices. The local learning models are transmitted to the fog servers where cross-verification takes place. Next, the block is generated by the winning miner and block propagation takes place. Finally, global model updates are computed via the aggregation of local learning model parameters at every fog server and sent to all the devices involved in learning. The authors analyzed the latency of the proposed framework. Additionally, a decentralized privacy-preserving scheme is proposed for FL-Block. The authors provided extensive simulation results to validate their proposal. Specifically, they have shown that the proposed scheme performs superior in terms of learning latency for the scenario without malfunctioning of the miners than malfunctioned miners case. Although the FL-Block offers a key feature of robustness, the consensus algorithms used by blockchain typically require high latency to reach consensus. Therefore, novel schemes will be required for federated learning based on blockchain. On the other hand, the end-devices involved in the learning framework of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> might not be able to access the fog server due to strict communication resource constraints. To cope with this issue, one can use device-to-device communication that can reuse the channel resources already in use by other cellular users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Other than channel resources reuse, cooperation between devices can enable federated learning without the need for a centralized aggregation server. To do so, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> presented a federated learning scheme that used cooperation between devices to avoid the use of a centralized edge/cloud server for global model aggregation. To effectively enable all the devices in a network to contribute in distributed optimization of the global federated learning model, two strategies are proposed: consensus-based federated averaging and consensus-based federated averaging with gradients exchange. In consensus-based federated averaging, all the devices receive learning model parameters from other nodes which are subsequently used for updating their own models. On the other hand, consensus-based federated averaging with gradient exchange uses additional steps including consensus-based federated averaging to improve convergence speed, but at the cost of extra complexity. Finally, the authors validate their proposal via experimental results for industrial IoT setup. The advantage of the approach considered in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> is the non-usage of a centralized server and thus, offers more robust federated learning. Furthermore, the proposed scheme can offer scalability by incorporating more nodes in a dense D2D network. Although the proposed scheme offered several advantages, one must perform efficient resource allocation for dense D2D networks. Optimization theory, heuristic schemes, and game theory can be used for resource allocation. Other than resource allocation, one can propose effective power control schemes to further improve the packet error rates, and thus increase the global federated learning model accuracy. This power control scheme will enable users to optimally allocate the transmit power while fulfilling the power constraints of the system.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Advances Based on Hierarchical Aggregation</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Considering the aforementioned advantages and disadvantages of both centralized aggregation and distributed aggregation-based federated learning, we can consider the hierarchical fashion of aggregation for federated learning. In hierarchical federated learning, few aggregations of local learning models (e.g. at the edge servers) take place prior to central aggregation (e.g., at cloud server). Few works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>, and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> consider hierarchical federated learning for IoT networks. A framework for federated learning-enabled intelligent fog radio access networks was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>. The authors identified the key issues (i.e., high communication cost and security and privacy issues) of a centralized machine learning-enabled fog radio access networks. To overcome these limitations, the federated learning-based framework was proposed. Both traditional federated learning and hierarchical federated learning were considered. In the hierarchical federated learning, two kinds of aggregation take place, one at fog nodes and the other one at a remote cloud. Furthermore, to enable participation of more end-devices in the training process, local model neural network architecture compression and parameter compression are considered. Finally, key enabling technologies for enabling federated learning-enabled intelligent fog radio access networks and open research challenges were presented. Furthermore, the works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> proposed a hierarchical federated learning framework for mobile networks. Their proposals considered local aggregations prior to global aggregation at the cloud. It must be noted here that hierarchical federated learning can be used to improve performance. End-devices can communicate with the edge by reusing the communication resources already in use by other cellular users. However, careful design considerations, such as frequency of aggregations at the edge server before a global aggregation takes place, must be taken. In hierarchical federated learning based on FedAvg, there will be two kinds of weights divergences, such as the edge (i.e., due to client-edge divergence) and cloud (i.e., due to edge-cloud divergence), where aggregations take place. The upper bound on the weights divergences is dependent on the number of edge aggregations and local learning model iterations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>. For a fixed product of local iterations and the number of edge aggregations, generally increasing the number of edge aggregations will improve the learning performance for non-IID data. One thing must be noted here that the performance of hierarchical federated learning also depends on data distribution and the federated optimization (i.e., FedAvg and FedProx) scheme used. Therefore, properly handling the data heterogeneity using an effective federated optimization scheme and the numbers of local iterations and edge aggregations will cause performance improvement for hierarchical federated learning.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Lessons Learned and Recommendations</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We have discussed recent advances of federated learning towards enabling IoT networks. We have learned several lessons and future enhancements:</p>
<ul id="S3.I18" class="ltx_itemize">
<li id="S3.I18.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i1.p1" class="ltx_para">
<p id="S3.I18.i1.p1.1" class="ltx_p">From <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, we derived that federated learning must use some effective compression technique due to limited communication resources and a massive number of IoT devices. Several compression techniques such as gradient compression and model broadcast compression can be used <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. The gradient compression minimizes the size of local learning models that are transmitted to the edge/cloud server. Although compression results in size reduction of the bits used to represent the learning model updates, it might result in data loss. Therefore, compression techniques with low loss in data will need to be developed.</p>
</div>
</li>
<li id="S3.I18.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i2.p1" class="ltx_para">
<p id="S3.I18.i2.p1.1" class="ltx_p">We derived from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> that there should be robust federated learning scheme for IoT networks. Vanilla federated learning is based on a single centralized aggregation server, which can be easily attacked by a malicious user or it stops working due to physical damage. These issues result in the interruption of the federated learning process. Therefore, we must tackle these issues to enable robust federated learning over IoT networks. To address the robustness issue, a novel design based on distributed aggregation servers will be required.</p>
</div>
</li>
<li id="S3.I18.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i3.p1" class="ltx_para">
<p id="S3.I18.i3.p1.1" class="ltx_p">We derived from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> that heterogeneity and noise-aware federated learning protocols must be proposed. The set of devices involved in federated learning have different computational resource (CPU-cycles/sec) and dataset sizes. Furthermore, the distribution of their datasets is not always identical. Such a heterogeneous nature of end-devices poses significant challenges to the design of a federated optimization algorithm. For instance, FedAvg was developed without more carefully considering devices’ heterogeneous system parameters. To cope with this limitation, FedProx was developed to offer a more practical design. FedProx is based on the addition of a scaled proximal term to FedAvg local device loss function. However, the scaling constant might be difficult to adjust for different applications. On the other hand, we must assign communication resources adaptively (i.e., more communication resources to a device with high local model computation time and vice versa) to optimize the overall global federated learning model time. Furthermore, the noise present in the local devices datasets significantly affects the local learning model accuracy. Therefore, novel federated optimization schemes that consider devices heterogeneity and local datasets noise in the devices selection phase will be required.</p>
</div>
</li>
<li id="S3.I18.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i4.p1" class="ltx_para">
<p id="S3.I18.i4.p1.1" class="ltx_p">From <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>, we derived that distributed aggregation-based federated learning for IoT networks must share the learning model updates in a secure and trustful manner. Recently, blockchain-based federated learning has been proposed for secure and trustful sharing of learning model updates between different miners. Although blockchain can provide many features, it has an inherent issue of high latency associated with consensus algorithms. On the other hand, federated learning consists of a number of global iterations (i.e., communication rounds). Therefore, using blockchain during the training of a federated learning model might not be desirable due to the high latency associated with the blockchain consensus algorithm. To cope with the high latency issue, there is a need to develop low complexity consensus algorithms.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Taxonomy of Federated Learning for IoT</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Federated learning over wireless networks involves many players, such as end-devices, edge/cloud servers, and miners <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. These players use wireless channel and core network resources in addition to computing resources for successfully enabling complex interaction between themselves <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Moreover, end-devices must be given some incentives to motivate their participation in federated learning process. Keeping in mind the aforementioned facts, we derive a taxonomy (illustrated in Fig. <a href="#S4.F9" title="Figure 9 ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>) using operation modes based on global aggregation, resources, local learning models, incentive mechanism, federated optimization schemes, end-device design, miners classification, cloud server design, edge collaboration, security, and privacy, as parameters. A detailed discussion with insights about every parameter of the taxonomy will be given later in this section. In Fig. <a href="#S4.F9" title="Figure 9 ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we place various parameters of taxonomy at three layers: end-devices layer, edge layer, and cloud layer, to provide more clear insights about their relationship to federated learning-enabled IoT networks. End-devices design and local learning models are specific to local devices and it will perform local model training for federated learning. Next to local model training, we can do aggregation either at a remote cloud or edge servers. Cloud servers at the cloud layer can be implemented using container-based design or virtual machine-based design. To perform aggregation at the edge layer, we can use simply an edge server (edge-assisted aggregation) or miners implemented at the edge. The use of miners for blockchain-based federated learning will be explained in more detail later in this section. Moreover, we can use collaboration among edge servers for federated learning global model computation (more details will be given in Section <a href="#S4.SS6" title="IV-F Edge Collaboration ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-F</span></span></a>). On the other hand, incentive mechanism design, security, and federated learning optimization/learning schemes involve end-devices, edge servers, and cloud servers. Therefore, they are positioned by considering all the three layers, such as the devices layer, edge layer, and cloud layer. Next, we describe various parameters of taxonomy for federated learning over IoT networks in detail.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2009.13012/assets/x14.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="545" height="696" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.3.2" class="ltx_text" style="font-size:90%;">Taxonomy of federated learning for IoT networks.</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Security and Privacy</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Federated learning over IoT networks have security and privacy concerns. Although federated learning was introduced to enable users’ privacy, it has still privacy leakage concerns<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In this sub-section, we use the keyword ”privacy leakage” to end-devices sensitive information leakage due to the information inferring capability of a malicious user or aggregation server using their learning model updates. On the other hand, accessing end-devices due to weak authentication schemes and altering the end-devices are considered as a security concern.</span></span></span>. A malicious end-device and aggregation server can infer end-devices private information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. To address this issue, a differential privacy scheme can be used that is based on the addition of noise to local learning model parameters before sending it to the global aggregation server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib106" title="" class="ltx_ref">106</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>. In local differential privacy, each end-device performs differential private transformation by adding noise which reduces the accuracy of the federated learning model. Noise for local differential privacy can be added via various ways, such as the Gaussian mechanism and the Laplace mechanism. Laplace mechanism adds noise of Laplace distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>. However, adding a Laplace noise directly to the local learning models might cause significant performance degradation especially for larger values of the noise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>. To cope with this limitation, one can use differential privacy based on an exponential mechanism. An exponential mechanism is based on mapping the local learning model updates to values within a range with a probability that follows an exponential distribution. Although exponential mechanism generally performs better than Laplace mechanism, it might suffer from performance degradation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. Another way to improve the performance of local differential privacy is to use a Gaussian mechanism that adds noise according to a zero-mean isotropic Gaussian distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. The addition of Gaussian noise has the main advantage of being additive in nature. Adding a Gaussian noise to Gaussian distributed local learning model weights will result in another Gaussian distribution whose analysis is simple. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, the authors showed that generally adding more noise to local learning model parameters can increase the privacy preservation capability, but at the cost of loss in accuracy and long convergence time. Therefore, we must make a tradeoff between the convergence and privacy preservation level. Another way to avoid prolonging the convergence time would be to use secure multiparty computation-based schemes, achieved by the encoding of local learning model updates. However, this approach will cause more communication overhead and might not be fully effective against the privacy leakage attacks. Therefore, to resolve these issues, one can use a hybrid approach that combines both local differential privacy via the addition of minimum possible noise and secure multiparty computation-based scheme via low-overhead encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In addition to privacy leakage, federated learning for IoT networks has a few security concerns. Generally, security in federated learning for wireless networks can be divided into two main categories: devices physical security and cybersecurity. Devices’ physical security refers to restricting the physical access to the end-devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Enabling end-devices, servers, and miners with physical security is challenging. On other hand, cybersecurity refers to network security, information security, and applications security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. To ensure the integrity of data stored at end-devices, one must use effective and light-weight authentication schemes due to the fact that a malicious user can physically access the end-devices with fewer efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>. Similarly, the edge servers have distributed nature and enabling its physical security is very challenging. To enable its security, one must develop new light-weight authentication schemes to provide access to only registered and trustworthy users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>, <a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>. The main reason for the development of light-weight authentication schemes for federated learning-enabled IoT networks is due to power constraints of the most IoT devices. In contrast to the edge, the cloud has centralized nature and can be easily attacked by a malicious user <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>. Specifically, the cloud-based federated learning has serious security concerns. A malicious user can easily access the centralized cloud server and introduce error in the global federated learning model. Therefore, similar to edge, we must use effective authentication schemes for cloud security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>, <a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>. It is to be noted here that, the authentication scheme used at the cloud can be of higher complexity than that of edge server due to presence of more computational capacity at the cloud. Other than end-devices, edge servers, and cloud security, federated learning is susceptible to malicious user attacks during the exchange of learning model updates between end-devices and the aggregation server. To address this issue, one can use an effective encryption scheme <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>. It must be noted here that using an effective authentication scheme can preserve privacy as well. A malicious user or aggregation server can not easily infer the end-devices sensitive information from their encrypted local learning model updates. Generally, complexity of an encryption algorithm increases with performance. Therefore, we must make a trade-off between performance and communication overhead and complexity.</p>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2009.13012/assets/x15.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="545" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S4.F10.3.2" class="ltx_text" style="font-size:90%;">Federated learning (a) sequence diagram, (b) overview of resources, local learning algorithms, and federated optimization schemes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Resources</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">Enabling efficient federated learning over an IoT-network requires optimization of both computational and communication resources, as shown in Fig. <a href="#S4.F10" title="Figure 10 ‣ IV-A Security and Privacy ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. The computational resource can be local computational resources of the end-devices or global computational resources of the aggregation server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>, <a href="#bib.bib127" title="" class="ltx_ref">127</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>. To compute the local learning model, the end-device performance (i.e., local learning accuracy and computation time) is mainly determined by its dataset size, available energy, and computational resource (CPU-cycles/sec). The computation time of a local learning model for a fixed accuracy strictly depends on the dataset size and the device computational resource (CPU-cycles/sec). The energy consumption of the device having operating frequency <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">f</annotation></semantics></math>, dataset size <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">D</annotation></semantics></math>, and <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="I_{l}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msub id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">I</mi><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">𝐼</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">I_{l}</annotation></semantics></math> local iterations, is given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>:</p>
<table id="S4.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle E_{\textrm{local}}=I_{l}\left(\rho\zeta Df^{2}\right)," display="inline"><semantics id="S4.E4X.2.1.1.m1.1a"><mrow id="S4.E4X.2.1.1.m1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S4.E4X.2.1.1.m1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.cmml"><msub id="S4.E4X.2.1.1.m1.1.1.1.1.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.cmml"><mi id="S4.E4X.2.1.1.m1.1.1.1.1.3.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.2.cmml">E</mi><mtext id="S4.E4X.2.1.1.m1.1.1.1.1.3.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.3a.cmml">local</mtext></msub><mo id="S4.E4X.2.1.1.m1.1.1.1.1.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E4X.2.1.1.m1.1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.cmml"><msub id="S4.E4X.2.1.1.m1.1.1.1.1.1.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3.cmml"><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3.2.cmml">I</mi><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S4.E4X.2.1.1.m1.1.1.1.1.1.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">ρ</mi><mo lspace="0em" rspace="0em" id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">ζ</mi><mo lspace="0em" rspace="0em" id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1a" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.4" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1b" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msup id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.2.cmml">f</mi><mn id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.3.cmml">2</mn></msup></mrow><mo id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E4X.2.1.1.m1.1.1.1.2" xref="S4.E4X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4X.2.1.1.m1.1b"><apply id="S4.E4X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1"><eq id="S4.E4X.2.1.1.m1.1.1.1.1.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S4.E4X.2.1.1.m1.1.1.1.1.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.2">𝐸</ci><ci id="S4.E4X.2.1.1.m1.1.1.1.1.3.3a.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S4.E4X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.3.3">local</mtext></ci></apply><apply id="S4.E4X.2.1.1.m1.1.1.1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1"><times id="S4.E4X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.2"></times><apply id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3.2">𝐼</ci><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.3.3">𝑙</ci></apply><apply id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1"><times id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1"></times><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2">𝜌</ci><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝜁</ci><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.4">𝐷</ci><apply id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5">superscript</csymbol><ci id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.2">𝑓</ci><cn type="integer" id="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.3.cmml" xref="S4.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.5.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4X.2.1.1.m1.1c">\displaystyle E_{\textrm{local}}=I_{l}\left(\rho\zeta Df^{2}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<p id="S4.SS2.p1.5" class="ltx_p">where <math id="S4.SS2.p1.4.m1.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S4.SS2.p1.4.m1.1a"><mi id="S4.SS2.p1.4.m1.1.1" xref="S4.SS2.p1.4.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m1.1b"><ci id="S4.SS2.p1.4.m1.1.1.cmml" xref="S4.SS2.p1.4.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m1.1c">\rho</annotation></semantics></math> and <math id="S4.SS2.p1.5.m2.1" class="ltx_Math" alttext="\zeta" display="inline"><semantics id="S4.SS2.p1.5.m2.1a"><mi id="S4.SS2.p1.5.m2.1.1" xref="S4.SS2.p1.5.m2.1.1.cmml">ζ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m2.1b"><ci id="S4.SS2.p1.5.m2.1.1.cmml" xref="S4.SS2.p1.5.m2.1.1">𝜁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m2.1c">\zeta</annotation></semantics></math> are the CPU dependent constant parameter and CPU-cycles required to process a single dataset point, respectively. The local learning model computation time is given by:</p>
<table id="S4.E5" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E5X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E5X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle T_{\textrm{local}}=I_{l}\left(\frac{\zeta D}{f}\right)." display="inline"><semantics id="S4.E5X.2.1.1.m1.2a"><mrow id="S4.E5X.2.1.1.m1.2.2.1" xref="S4.E5X.2.1.1.m1.2.2.1.1.cmml"><mrow id="S4.E5X.2.1.1.m1.2.2.1.1" xref="S4.E5X.2.1.1.m1.2.2.1.1.cmml"><msub id="S4.E5X.2.1.1.m1.2.2.1.1.2" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.cmml"><mi id="S4.E5X.2.1.1.m1.2.2.1.1.2.2" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.2.cmml">T</mi><mtext id="S4.E5X.2.1.1.m1.2.2.1.1.2.3" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.3a.cmml">local</mtext></msub><mo id="S4.E5X.2.1.1.m1.2.2.1.1.1" xref="S4.E5X.2.1.1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S4.E5X.2.1.1.m1.2.2.1.1.3" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.cmml"><msub id="S4.E5X.2.1.1.m1.2.2.1.1.3.2" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2.cmml"><mi id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.2" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2.2.cmml">I</mi><mi id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.3" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S4.E5X.2.1.1.m1.2.2.1.1.3.1" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E5X.2.1.1.m1.2.2.1.1.3.3.2" xref="S4.E5X.2.1.1.m1.1.1.cmml"><mo id="S4.E5X.2.1.1.m1.2.2.1.1.3.3.2.1" xref="S4.E5X.2.1.1.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S4.E5X.2.1.1.m1.1.1" xref="S4.E5X.2.1.1.m1.1.1.cmml"><mfrac id="S4.E5X.2.1.1.m1.1.1a" xref="S4.E5X.2.1.1.m1.1.1.cmml"><mrow id="S4.E5X.2.1.1.m1.1.1.2" xref="S4.E5X.2.1.1.m1.1.1.2.cmml"><mi id="S4.E5X.2.1.1.m1.1.1.2.2" xref="S4.E5X.2.1.1.m1.1.1.2.2.cmml">ζ</mi><mo lspace="0em" rspace="0em" id="S4.E5X.2.1.1.m1.1.1.2.1" xref="S4.E5X.2.1.1.m1.1.1.2.1.cmml">​</mo><mi id="S4.E5X.2.1.1.m1.1.1.2.3" xref="S4.E5X.2.1.1.m1.1.1.2.3.cmml">D</mi></mrow><mi id="S4.E5X.2.1.1.m1.1.1.3" xref="S4.E5X.2.1.1.m1.1.1.3.cmml">f</mi></mfrac></mstyle><mo id="S4.E5X.2.1.1.m1.2.2.1.1.3.3.2.2" xref="S4.E5X.2.1.1.m1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E5X.2.1.1.m1.2.2.1.2" xref="S4.E5X.2.1.1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5X.2.1.1.m1.2b"><apply id="S4.E5X.2.1.1.m1.2.2.1.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1"><eq id="S4.E5X.2.1.1.m1.2.2.1.1.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.1"></eq><apply id="S4.E5X.2.1.1.m1.2.2.1.1.2.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E5X.2.1.1.m1.2.2.1.1.2.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.2">subscript</csymbol><ci id="S4.E5X.2.1.1.m1.2.2.1.1.2.2.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.2">𝑇</ci><ci id="S4.E5X.2.1.1.m1.2.2.1.1.2.3a.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.3"><mtext mathsize="70%" id="S4.E5X.2.1.1.m1.2.2.1.1.2.3.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.2.3">local</mtext></ci></apply><apply id="S4.E5X.2.1.1.m1.2.2.1.1.3.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3"><times id="S4.E5X.2.1.1.m1.2.2.1.1.3.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.1"></times><apply id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.2.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2.2">𝐼</ci><ci id="S4.E5X.2.1.1.m1.2.2.1.1.3.2.3.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.2.3">𝑙</ci></apply><apply id="S4.E5X.2.1.1.m1.1.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.3.2"><divide id="S4.E5X.2.1.1.m1.1.1.1.cmml" xref="S4.E5X.2.1.1.m1.2.2.1.1.3.3.2"></divide><apply id="S4.E5X.2.1.1.m1.1.1.2.cmml" xref="S4.E5X.2.1.1.m1.1.1.2"><times id="S4.E5X.2.1.1.m1.1.1.2.1.cmml" xref="S4.E5X.2.1.1.m1.1.1.2.1"></times><ci id="S4.E5X.2.1.1.m1.1.1.2.2.cmml" xref="S4.E5X.2.1.1.m1.1.1.2.2">𝜁</ci><ci id="S4.E5X.2.1.1.m1.1.1.2.3.cmml" xref="S4.E5X.2.1.1.m1.1.1.2.3">𝐷</ci></apply><ci id="S4.E5X.2.1.1.m1.1.1.3.cmml" xref="S4.E5X.2.1.1.m1.1.1.3">𝑓</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5X.2.1.1.m1.2c">\displaystyle T_{\textrm{local}}=I_{l}\left(\frac{\zeta D}{f}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<p id="S4.SS2.p1.6" class="ltx_p">From (<a href="#S4.E4" title="In IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) and (<a href="#S4.E5" title="In IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), it is clear that there exists a tradeoff between simultaneously minimizing local learning model computation time and energy consumption. For a fixed local model accuracy and device operating frequency, the dataset size determines the computation time of the local learning model. For fixed dataset points and local model accuracy, the local model computation time can be decreased by increasing the operating frequency of the device. However, energy consumption increases proportionally to the square of the local device operating frequency. Therefore, we must make a trade-off between the end-device operating frequency and energy consumption while computing a local learning model. A set of devices involved in federated learning shows significant heterogeneity in terms of computation resource, dataset size, operating frequency, and available energy. For a fixed local model computation time, the end-devices’ heterogeneous parameters result in local learning models of variable accuracy. To account for variable local learning model accuracy of end-devices due to heterogeneity, we can use the notion of relative local accuracy <math id="S4.SS2.p1.6.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS2.p1.6.m1.1a"><mi id="S4.SS2.p1.6.m1.1.1" xref="S4.SS2.p1.6.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m1.1b"><ci id="S4.SS2.p1.6.m1.1.1.cmml" xref="S4.SS2.p1.6.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m1.1c">\theta</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>. Smaller values of relative local accuracy show better local learning model accuracy and vice versa.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">After computing the local learning model at every end-device, the learning model parameters are sent to the aggregation server. Depending on the federated learning scheme, the aggregation of the local learning model can be carried out either at a centralized aggregation server or distributed nodes. For a vanilla federated learning, the global model aggregation takes place at the edge server/cloud <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. The global model updates are sent back to the end-devices. On the other hand, the local learning model updates of all the end-devices are transferred between miner-enabled BSs for a blockchain-based federated learning model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>. The miners exchange the local learning model parameters of all the devices through distributed ledger in a trustworthy way. After a consensus is reached among the miners, all the miners send the block which contains local learning models of all the devices to their corresponding end-devices where the global model aggregation takes place. The transmission time for transferring of model updates between the BSs and end-devices depends on the radio access scheme and channel variations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. For a data rate <math id="S4.SS2.p2.1.m1.2" class="ltx_Math" alttext="R_{n},\forall{n\in\mathcal{N}}" display="inline"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2" xref="S4.SS2.p2.1.m1.2.2.cmml"><mrow id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml"><msub id="S4.SS2.p2.1.m1.1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.1.2.cmml">R</mi><mi id="S4.SS2.p2.1.m1.1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml">,</mo><mrow id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml"><mo rspace="0.167em" id="S4.SS2.p2.1.m1.2.2.2.2.2.1" xref="S4.SS2.p2.1.m1.2.2.2.2.2.1.cmml">∀</mo><mi id="S4.SS2.p2.1.m1.2.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.2.cmml">n</mi></mrow></mrow><mo id="S4.SS2.p2.1.m1.2.2.3" xref="S4.SS2.p2.1.m1.2.2.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p2.1.m1.2.2.4" xref="S4.SS2.p2.1.m1.2.2.4.cmml">𝒩</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><apply id="S4.SS2.p2.1.m1.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2"><in id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.3"></in><list id="S4.SS2.p2.1.m1.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.2">𝑅</ci><ci id="S4.SS2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.3">𝑛</ci></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2.1">for-all</csymbol><ci id="S4.SS2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2.2">𝑛</ci></apply></list><ci id="S4.SS2.p2.1.m1.2.2.4.cmml" xref="S4.SS2.p2.1.m1.2.2.4">𝒩</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">R_{n},\forall{n\in\mathcal{N}}</annotation></semantics></math> , the time taken during sending of learning model parameters of size <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="\nu" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">ν</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">𝜈</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\nu</annotation></semantics></math> to the aggregation server can be given by:</p>
<table id="S4.E6" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E6X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E6X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle T_{\textrm{trans}}=\sum_{n\in\mathcal{N}}{\left(\frac{\nu}{R_{n}}\right)}." display="inline"><semantics id="S4.E6X.2.1.1.m1.2a"><mrow id="S4.E6X.2.1.1.m1.2.2.1" xref="S4.E6X.2.1.1.m1.2.2.1.1.cmml"><mrow id="S4.E6X.2.1.1.m1.2.2.1.1" xref="S4.E6X.2.1.1.m1.2.2.1.1.cmml"><msub id="S4.E6X.2.1.1.m1.2.2.1.1.2" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.cmml"><mi id="S4.E6X.2.1.1.m1.2.2.1.1.2.2" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.2.cmml">T</mi><mtext id="S4.E6X.2.1.1.m1.2.2.1.1.2.3" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.3a.cmml">trans</mtext></msub><mo id="S4.E6X.2.1.1.m1.2.2.1.1.1" xref="S4.E6X.2.1.1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S4.E6X.2.1.1.m1.2.2.1.1.3" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.cmml"><mstyle displaystyle="true" id="S4.E6X.2.1.1.m1.2.2.1.1.3.1" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.cmml"><munder id="S4.E6X.2.1.1.m1.2.2.1.1.3.1a" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.cmml"><mo movablelimits="false" id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.2" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.2.cmml">∑</mo><mrow id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.cmml"><mi id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.2" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.2.cmml">n</mi><mo id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.1" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.3" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.3.cmml">𝒩</mi></mrow></munder></mstyle><mrow id="S4.E6X.2.1.1.m1.2.2.1.1.3.2.2" xref="S4.E6X.2.1.1.m1.1.1.cmml"><mo id="S4.E6X.2.1.1.m1.2.2.1.1.3.2.2.1" xref="S4.E6X.2.1.1.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S4.E6X.2.1.1.m1.1.1" xref="S4.E6X.2.1.1.m1.1.1.cmml"><mfrac id="S4.E6X.2.1.1.m1.1.1a" xref="S4.E6X.2.1.1.m1.1.1.cmml"><mi id="S4.E6X.2.1.1.m1.1.1.2" xref="S4.E6X.2.1.1.m1.1.1.2.cmml">ν</mi><msub id="S4.E6X.2.1.1.m1.1.1.3" xref="S4.E6X.2.1.1.m1.1.1.3.cmml"><mi id="S4.E6X.2.1.1.m1.1.1.3.2" xref="S4.E6X.2.1.1.m1.1.1.3.2.cmml">R</mi><mi id="S4.E6X.2.1.1.m1.1.1.3.3" xref="S4.E6X.2.1.1.m1.1.1.3.3.cmml">n</mi></msub></mfrac></mstyle><mo id="S4.E6X.2.1.1.m1.2.2.1.1.3.2.2.2" xref="S4.E6X.2.1.1.m1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E6X.2.1.1.m1.2.2.1.2" xref="S4.E6X.2.1.1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E6X.2.1.1.m1.2b"><apply id="S4.E6X.2.1.1.m1.2.2.1.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1"><eq id="S4.E6X.2.1.1.m1.2.2.1.1.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.1"></eq><apply id="S4.E6X.2.1.1.m1.2.2.1.1.2.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E6X.2.1.1.m1.2.2.1.1.2.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.2">subscript</csymbol><ci id="S4.E6X.2.1.1.m1.2.2.1.1.2.2.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.2">𝑇</ci><ci id="S4.E6X.2.1.1.m1.2.2.1.1.2.3a.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.3"><mtext mathsize="70%" id="S4.E6X.2.1.1.m1.2.2.1.1.2.3.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.2.3">trans</mtext></ci></apply><apply id="S4.E6X.2.1.1.m1.2.2.1.1.3.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3"><apply id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1"><csymbol cd="ambiguous" id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1">subscript</csymbol><sum id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.2.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.2"></sum><apply id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3"><in id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.1"></in><ci id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.2.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.2">𝑛</ci><ci id="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.3.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.1.3.3">𝒩</ci></apply></apply><apply id="S4.E6X.2.1.1.m1.1.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.2.2"><divide id="S4.E6X.2.1.1.m1.1.1.1.cmml" xref="S4.E6X.2.1.1.m1.2.2.1.1.3.2.2"></divide><ci id="S4.E6X.2.1.1.m1.1.1.2.cmml" xref="S4.E6X.2.1.1.m1.1.1.2">𝜈</ci><apply id="S4.E6X.2.1.1.m1.1.1.3.cmml" xref="S4.E6X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E6X.2.1.1.m1.1.1.3.1.cmml" xref="S4.E6X.2.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.E6X.2.1.1.m1.1.1.3.2.cmml" xref="S4.E6X.2.1.1.m1.1.1.3.2">𝑅</ci><ci id="S4.E6X.2.1.1.m1.1.1.3.3.cmml" xref="S4.E6X.2.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6X.2.1.1.m1.2c">\displaystyle T_{\textrm{trans}}=\sum_{n\in\mathcal{N}}{\left(\frac{\nu}{R_{n}}\right)}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(6)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">On the other hand, the energy consumed during transmission using transmit power <math id="S4.SS2.p3.1.m1.2" class="ltx_Math" alttext="P_{n},\forall{n\in\mathcal{N}}" display="inline"><semantics id="S4.SS2.p3.1.m1.2a"><mrow id="S4.SS2.p3.1.m1.2.2" xref="S4.SS2.p3.1.m1.2.2.cmml"><mrow id="S4.SS2.p3.1.m1.2.2.2.2" xref="S4.SS2.p3.1.m1.2.2.2.3.cmml"><msub id="S4.SS2.p3.1.m1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.1.1.1.2.cmml">P</mi><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS2.p3.1.m1.2.2.2.2.3" xref="S4.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><mrow id="S4.SS2.p3.1.m1.2.2.2.2.2" xref="S4.SS2.p3.1.m1.2.2.2.2.2.cmml"><mo rspace="0.167em" id="S4.SS2.p3.1.m1.2.2.2.2.2.1" xref="S4.SS2.p3.1.m1.2.2.2.2.2.1.cmml">∀</mo><mi id="S4.SS2.p3.1.m1.2.2.2.2.2.2" xref="S4.SS2.p3.1.m1.2.2.2.2.2.2.cmml">n</mi></mrow></mrow><mo id="S4.SS2.p3.1.m1.2.2.3" xref="S4.SS2.p3.1.m1.2.2.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.1.m1.2.2.4" xref="S4.SS2.p3.1.m1.2.2.4.cmml">𝒩</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.2b"><apply id="S4.SS2.p3.1.m1.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2"><in id="S4.SS2.p3.1.m1.2.2.3.cmml" xref="S4.SS2.p3.1.m1.2.2.3"></in><list id="S4.SS2.p3.1.m1.2.2.2.3.cmml" xref="S4.SS2.p3.1.m1.2.2.2.2"><apply id="S4.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.2">𝑃</ci><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.3">𝑛</ci></apply><apply id="S4.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="latexml" id="S4.SS2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS2.p3.1.m1.2.2.2.2.2.1">for-all</csymbol><ci id="S4.SS2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2.2.2.2.2">𝑛</ci></apply></list><ci id="S4.SS2.p3.1.m1.2.2.4.cmml" xref="S4.SS2.p3.1.m1.2.2.4">𝒩</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.2c">P_{n},\forall{n\in\mathcal{N}}</annotation></semantics></math> of the learning model parameters from end-devices to the aggregation server is given by:</p>
<table id="S4.E7" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E7X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E7X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle E_{\textrm{trans}}=\sum_{n\in\mathcal{N}}{\left(\frac{\nu P_{n}}{R_{n}}\right)}." display="inline"><semantics id="S4.E7X.2.1.1.m1.2a"><mrow id="S4.E7X.2.1.1.m1.2.2.1" xref="S4.E7X.2.1.1.m1.2.2.1.1.cmml"><mrow id="S4.E7X.2.1.1.m1.2.2.1.1" xref="S4.E7X.2.1.1.m1.2.2.1.1.cmml"><msub id="S4.E7X.2.1.1.m1.2.2.1.1.2" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.cmml"><mi id="S4.E7X.2.1.1.m1.2.2.1.1.2.2" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.2.cmml">E</mi><mtext id="S4.E7X.2.1.1.m1.2.2.1.1.2.3" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.3a.cmml">trans</mtext></msub><mo id="S4.E7X.2.1.1.m1.2.2.1.1.1" xref="S4.E7X.2.1.1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S4.E7X.2.1.1.m1.2.2.1.1.3" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.cmml"><mstyle displaystyle="true" id="S4.E7X.2.1.1.m1.2.2.1.1.3.1" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.cmml"><munder id="S4.E7X.2.1.1.m1.2.2.1.1.3.1a" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.cmml"><mo movablelimits="false" id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.2" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.2.cmml">∑</mo><mrow id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.cmml"><mi id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.2" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.2.cmml">n</mi><mo id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.1" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.3" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.3.cmml">𝒩</mi></mrow></munder></mstyle><mrow id="S4.E7X.2.1.1.m1.2.2.1.1.3.2.2" xref="S4.E7X.2.1.1.m1.1.1.cmml"><mo id="S4.E7X.2.1.1.m1.2.2.1.1.3.2.2.1" xref="S4.E7X.2.1.1.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S4.E7X.2.1.1.m1.1.1" xref="S4.E7X.2.1.1.m1.1.1.cmml"><mfrac id="S4.E7X.2.1.1.m1.1.1a" xref="S4.E7X.2.1.1.m1.1.1.cmml"><mrow id="S4.E7X.2.1.1.m1.1.1.2" xref="S4.E7X.2.1.1.m1.1.1.2.cmml"><mi id="S4.E7X.2.1.1.m1.1.1.2.2" xref="S4.E7X.2.1.1.m1.1.1.2.2.cmml">ν</mi><mo lspace="0em" rspace="0em" id="S4.E7X.2.1.1.m1.1.1.2.1" xref="S4.E7X.2.1.1.m1.1.1.2.1.cmml">​</mo><msub id="S4.E7X.2.1.1.m1.1.1.2.3" xref="S4.E7X.2.1.1.m1.1.1.2.3.cmml"><mi id="S4.E7X.2.1.1.m1.1.1.2.3.2" xref="S4.E7X.2.1.1.m1.1.1.2.3.2.cmml">P</mi><mi id="S4.E7X.2.1.1.m1.1.1.2.3.3" xref="S4.E7X.2.1.1.m1.1.1.2.3.3.cmml">n</mi></msub></mrow><msub id="S4.E7X.2.1.1.m1.1.1.3" xref="S4.E7X.2.1.1.m1.1.1.3.cmml"><mi id="S4.E7X.2.1.1.m1.1.1.3.2" xref="S4.E7X.2.1.1.m1.1.1.3.2.cmml">R</mi><mi id="S4.E7X.2.1.1.m1.1.1.3.3" xref="S4.E7X.2.1.1.m1.1.1.3.3.cmml">n</mi></msub></mfrac></mstyle><mo id="S4.E7X.2.1.1.m1.2.2.1.1.3.2.2.2" xref="S4.E7X.2.1.1.m1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E7X.2.1.1.m1.2.2.1.2" xref="S4.E7X.2.1.1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7X.2.1.1.m1.2b"><apply id="S4.E7X.2.1.1.m1.2.2.1.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1"><eq id="S4.E7X.2.1.1.m1.2.2.1.1.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.1"></eq><apply id="S4.E7X.2.1.1.m1.2.2.1.1.2.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E7X.2.1.1.m1.2.2.1.1.2.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.2">subscript</csymbol><ci id="S4.E7X.2.1.1.m1.2.2.1.1.2.2.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.2">𝐸</ci><ci id="S4.E7X.2.1.1.m1.2.2.1.1.2.3a.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.3"><mtext mathsize="70%" id="S4.E7X.2.1.1.m1.2.2.1.1.2.3.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.2.3">trans</mtext></ci></apply><apply id="S4.E7X.2.1.1.m1.2.2.1.1.3.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3"><apply id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1"><csymbol cd="ambiguous" id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1">subscript</csymbol><sum id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.2.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.2"></sum><apply id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3"><in id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.1"></in><ci id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.2.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.2">𝑛</ci><ci id="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.3.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.1.3.3">𝒩</ci></apply></apply><apply id="S4.E7X.2.1.1.m1.1.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.2.2"><divide id="S4.E7X.2.1.1.m1.1.1.1.cmml" xref="S4.E7X.2.1.1.m1.2.2.1.1.3.2.2"></divide><apply id="S4.E7X.2.1.1.m1.1.1.2.cmml" xref="S4.E7X.2.1.1.m1.1.1.2"><times id="S4.E7X.2.1.1.m1.1.1.2.1.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.1"></times><ci id="S4.E7X.2.1.1.m1.1.1.2.2.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.2">𝜈</ci><apply id="S4.E7X.2.1.1.m1.1.1.2.3.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E7X.2.1.1.m1.1.1.2.3.1.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.3">subscript</csymbol><ci id="S4.E7X.2.1.1.m1.1.1.2.3.2.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.3.2">𝑃</ci><ci id="S4.E7X.2.1.1.m1.1.1.2.3.3.cmml" xref="S4.E7X.2.1.1.m1.1.1.2.3.3">𝑛</ci></apply></apply><apply id="S4.E7X.2.1.1.m1.1.1.3.cmml" xref="S4.E7X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E7X.2.1.1.m1.1.1.3.1.cmml" xref="S4.E7X.2.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.E7X.2.1.1.m1.1.1.3.2.cmml" xref="S4.E7X.2.1.1.m1.1.1.3.2">𝑅</ci><ci id="S4.E7X.2.1.1.m1.1.1.3.3.cmml" xref="S4.E7X.2.1.1.m1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7X.2.1.1.m1.2c">\displaystyle E_{\textrm{trans}}=\sum_{n\in\mathcal{N}}{\left(\frac{\nu P_{n}}{R_{n}}\right)}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(7)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.2" class="ltx_p">From the above discussions regarding computational resource and communication resource consumption, one can define computational and communication costs. The computational cost can be the number of local iterations for local model computation, whereas communication cost can be the number of global communication rounds between the end-devices and aggregation server. For a fixed global federated learning model accuracy, computational and communication costs have contradictory relations with each other. An increase in computational cost decreases the communication cost and vice versa. For a relative local accuracy <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\theta</annotation></semantics></math> and global federated learning model accuracy <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mi id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><ci id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\epsilon</annotation></semantics></math>, the global iterations can be given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite>:</p>
<table id="S4.E8" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E8X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E8X.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle I_{g}=\frac{\alpha\log\left(\frac{1}{\epsilon}\right)}{1-\theta}," display="inline"><semantics id="S4.E8X.2.1.1.m1.3a"><mrow id="S4.E8X.2.1.1.m1.3.3.1" xref="S4.E8X.2.1.1.m1.3.3.1.1.cmml"><mrow id="S4.E8X.2.1.1.m1.3.3.1.1" xref="S4.E8X.2.1.1.m1.3.3.1.1.cmml"><msub id="S4.E8X.2.1.1.m1.3.3.1.1.2" xref="S4.E8X.2.1.1.m1.3.3.1.1.2.cmml"><mi id="S4.E8X.2.1.1.m1.3.3.1.1.2.2" xref="S4.E8X.2.1.1.m1.3.3.1.1.2.2.cmml">I</mi><mi id="S4.E8X.2.1.1.m1.3.3.1.1.2.3" xref="S4.E8X.2.1.1.m1.3.3.1.1.2.3.cmml">g</mi></msub><mo id="S4.E8X.2.1.1.m1.3.3.1.1.1" xref="S4.E8X.2.1.1.m1.3.3.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E8X.2.1.1.m1.2.2" xref="S4.E8X.2.1.1.m1.2.2.cmml"><mfrac id="S4.E8X.2.1.1.m1.2.2a" xref="S4.E8X.2.1.1.m1.2.2.cmml"><mrow id="S4.E8X.2.1.1.m1.2.2.2" xref="S4.E8X.2.1.1.m1.2.2.2.cmml"><mi id="S4.E8X.2.1.1.m1.2.2.2.4" xref="S4.E8X.2.1.1.m1.2.2.2.4.cmml">α</mi><mo lspace="0.167em" rspace="0em" id="S4.E8X.2.1.1.m1.2.2.2.3" xref="S4.E8X.2.1.1.m1.2.2.2.3.cmml">​</mo><mrow id="S4.E8X.2.1.1.m1.2.2.2.5.2" xref="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml"><mi id="S4.E8X.2.1.1.m1.1.1.1.1" xref="S4.E8X.2.1.1.m1.1.1.1.1.cmml">log</mi><mo id="S4.E8X.2.1.1.m1.2.2.2.5.2a" xref="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml">⁡</mo><mrow id="S4.E8X.2.1.1.m1.2.2.2.5.2.1" xref="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml"><mo id="S4.E8X.2.1.1.m1.2.2.2.5.2.1.1" xref="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml">(</mo><mfrac id="S4.E8X.2.1.1.m1.2.2.2.2" xref="S4.E8X.2.1.1.m1.2.2.2.2.cmml"><mn id="S4.E8X.2.1.1.m1.2.2.2.2.2" xref="S4.E8X.2.1.1.m1.2.2.2.2.2.cmml">1</mn><mi id="S4.E8X.2.1.1.m1.2.2.2.2.3" xref="S4.E8X.2.1.1.m1.2.2.2.2.3.cmml">ϵ</mi></mfrac><mo id="S4.E8X.2.1.1.m1.2.2.2.5.2.1.2" xref="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S4.E8X.2.1.1.m1.2.2.4" xref="S4.E8X.2.1.1.m1.2.2.4.cmml"><mn id="S4.E8X.2.1.1.m1.2.2.4.2" xref="S4.E8X.2.1.1.m1.2.2.4.2.cmml">1</mn><mo id="S4.E8X.2.1.1.m1.2.2.4.1" xref="S4.E8X.2.1.1.m1.2.2.4.1.cmml">−</mo><mi id="S4.E8X.2.1.1.m1.2.2.4.3" xref="S4.E8X.2.1.1.m1.2.2.4.3.cmml">θ</mi></mrow></mfrac></mstyle></mrow><mo id="S4.E8X.2.1.1.m1.3.3.1.2" xref="S4.E8X.2.1.1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E8X.2.1.1.m1.3b"><apply id="S4.E8X.2.1.1.m1.3.3.1.1.cmml" xref="S4.E8X.2.1.1.m1.3.3.1"><eq id="S4.E8X.2.1.1.m1.3.3.1.1.1.cmml" xref="S4.E8X.2.1.1.m1.3.3.1.1.1"></eq><apply id="S4.E8X.2.1.1.m1.3.3.1.1.2.cmml" xref="S4.E8X.2.1.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.E8X.2.1.1.m1.3.3.1.1.2.1.cmml" xref="S4.E8X.2.1.1.m1.3.3.1.1.2">subscript</csymbol><ci id="S4.E8X.2.1.1.m1.3.3.1.1.2.2.cmml" xref="S4.E8X.2.1.1.m1.3.3.1.1.2.2">𝐼</ci><ci id="S4.E8X.2.1.1.m1.3.3.1.1.2.3.cmml" xref="S4.E8X.2.1.1.m1.3.3.1.1.2.3">𝑔</ci></apply><apply id="S4.E8X.2.1.1.m1.2.2.cmml" xref="S4.E8X.2.1.1.m1.2.2"><divide id="S4.E8X.2.1.1.m1.2.2.3.cmml" xref="S4.E8X.2.1.1.m1.2.2"></divide><apply id="S4.E8X.2.1.1.m1.2.2.2.cmml" xref="S4.E8X.2.1.1.m1.2.2.2"><times id="S4.E8X.2.1.1.m1.2.2.2.3.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.3"></times><ci id="S4.E8X.2.1.1.m1.2.2.2.4.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.4">𝛼</ci><apply id="S4.E8X.2.1.1.m1.2.2.2.5.1.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.5.2"><log id="S4.E8X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E8X.2.1.1.m1.1.1.1.1"></log><apply id="S4.E8X.2.1.1.m1.2.2.2.2.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.2"><divide id="S4.E8X.2.1.1.m1.2.2.2.2.1.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.2"></divide><cn type="integer" id="S4.E8X.2.1.1.m1.2.2.2.2.2.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.2.2">1</cn><ci id="S4.E8X.2.1.1.m1.2.2.2.2.3.cmml" xref="S4.E8X.2.1.1.m1.2.2.2.2.3">italic-ϵ</ci></apply></apply></apply><apply id="S4.E8X.2.1.1.m1.2.2.4.cmml" xref="S4.E8X.2.1.1.m1.2.2.4"><minus id="S4.E8X.2.1.1.m1.2.2.4.1.cmml" xref="S4.E8X.2.1.1.m1.2.2.4.1"></minus><cn type="integer" id="S4.E8X.2.1.1.m1.2.2.4.2.cmml" xref="S4.E8X.2.1.1.m1.2.2.4.2">1</cn><ci id="S4.E8X.2.1.1.m1.2.2.4.3.cmml" xref="S4.E8X.2.1.1.m1.2.2.4.3">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8X.2.1.1.m1.3c">\displaystyle I_{g}=\frac{\alpha\log\left(\frac{1}{\epsilon}\right)}{1-\theta},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(8)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">From (<a href="#S4.E8" title="In IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>), it is clear that for a fixed global accuracy, more local iterations are required to minimize the relative local accuracy <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mi id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><ci id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">\theta</annotation></semantics></math> (i.e., to maximize the local learning model accuracy). The local iterations can be given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>:</p>
<table id="S4.E9" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E9X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E9X.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle I_{l}=\gamma\log\left(\frac{1}{\theta}\right)," display="inline"><semantics id="S4.E9X.2.1.1.m1.3a"><mrow id="S4.E9X.2.1.1.m1.3.3.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.cmml"><mrow id="S4.E9X.2.1.1.m1.3.3.1.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.cmml"><msub id="S4.E9X.2.1.1.m1.3.3.1.1.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.2.cmml"><mi id="S4.E9X.2.1.1.m1.3.3.1.1.2.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.2.2.cmml">I</mi><mi id="S4.E9X.2.1.1.m1.3.3.1.1.2.3" xref="S4.E9X.2.1.1.m1.3.3.1.1.2.3.cmml">l</mi></msub><mo id="S4.E9X.2.1.1.m1.3.3.1.1.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.1.cmml">=</mo><mrow id="S4.E9X.2.1.1.m1.3.3.1.1.3" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.cmml"><mi id="S4.E9X.2.1.1.m1.3.3.1.1.3.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.2.cmml">γ</mi><mo lspace="0.167em" rspace="0em" id="S4.E9X.2.1.1.m1.3.3.1.1.3.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.1.cmml">​</mo><mrow id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml"><mi id="S4.E9X.2.1.1.m1.1.1" xref="S4.E9X.2.1.1.m1.1.1.cmml">log</mi><mo id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2a" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml">⁡</mo><mrow id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml"><mo id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2.1.1" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml">(</mo><mstyle displaystyle="true" id="S4.E9X.2.1.1.m1.2.2" xref="S4.E9X.2.1.1.m1.2.2.cmml"><mfrac id="S4.E9X.2.1.1.m1.2.2a" xref="S4.E9X.2.1.1.m1.2.2.cmml"><mn id="S4.E9X.2.1.1.m1.2.2.2" xref="S4.E9X.2.1.1.m1.2.2.2.cmml">1</mn><mi id="S4.E9X.2.1.1.m1.2.2.3" xref="S4.E9X.2.1.1.m1.2.2.3.cmml">θ</mi></mfrac></mstyle><mo id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2.1.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E9X.2.1.1.m1.3.3.1.2" xref="S4.E9X.2.1.1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E9X.2.1.1.m1.3b"><apply id="S4.E9X.2.1.1.m1.3.3.1.1.cmml" xref="S4.E9X.2.1.1.m1.3.3.1"><eq id="S4.E9X.2.1.1.m1.3.3.1.1.1.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.1"></eq><apply id="S4.E9X.2.1.1.m1.3.3.1.1.2.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.E9X.2.1.1.m1.3.3.1.1.2.1.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.2">subscript</csymbol><ci id="S4.E9X.2.1.1.m1.3.3.1.1.2.2.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.2.2">𝐼</ci><ci id="S4.E9X.2.1.1.m1.3.3.1.1.2.3.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.2.3">𝑙</ci></apply><apply id="S4.E9X.2.1.1.m1.3.3.1.1.3.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.3"><times id="S4.E9X.2.1.1.m1.3.3.1.1.3.1.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.1"></times><ci id="S4.E9X.2.1.1.m1.3.3.1.1.3.2.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.2">𝛾</ci><apply id="S4.E9X.2.1.1.m1.3.3.1.1.3.3.1.cmml" xref="S4.E9X.2.1.1.m1.3.3.1.1.3.3.2"><log id="S4.E9X.2.1.1.m1.1.1.cmml" xref="S4.E9X.2.1.1.m1.1.1"></log><apply id="S4.E9X.2.1.1.m1.2.2.cmml" xref="S4.E9X.2.1.1.m1.2.2"><divide id="S4.E9X.2.1.1.m1.2.2.1.cmml" xref="S4.E9X.2.1.1.m1.2.2"></divide><cn type="integer" id="S4.E9X.2.1.1.m1.2.2.2.cmml" xref="S4.E9X.2.1.1.m1.2.2.2">1</cn><ci id="S4.E9X.2.1.1.m1.2.2.3.cmml" xref="S4.E9X.2.1.1.m1.2.2.3">𝜃</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9X.2.1.1.m1.3c">\displaystyle I_{l}=\gamma\log\left(\frac{1}{\theta}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(9)</span></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<p id="S4.SS2.p5.2" class="ltx_p">where <math id="S4.SS2.p5.2.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS2.p5.2.m1.1a"><mi id="S4.SS2.p5.2.m1.1.1" xref="S4.SS2.p5.2.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m1.1b"><ci id="S4.SS2.p5.2.m1.1.1.cmml" xref="S4.SS2.p5.2.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m1.1c">\gamma</annotation></semantics></math> is constant, which depends on end-device local sub problem and dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>. Fig. <a href="#S4.F11" title="Figure 11 ‣ IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the variations in global and local iterations vs. relative local accuracy for a fixed global accuracy. To achieve lower values of relative local accuracy, more local iterations and few global iterations are needed for a fixed global accuracy and vice versa.</p>
</div>
<figure id="S4.F11" class="ltx_figure"><img src="" id="S4.F11.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S4.F11.3.2" class="ltx_text" style="font-size:90%;">Global and local iterations vs. relative local accuracy.</span></figcaption>
</figure>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">From the aforementioned discussions, it is evident that there must be some effective mechanism for the selection of local devices operating frequencies for federated learning. The devices’ operating frequencies determine the energy consumption and local model computation delay for a fixed number of dataset points and fixed local learning model accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. On the other hand, there exist significant variations in the wireless channel and different devices have different transmission delays for sending local learning models to edge/cloud server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite>. Therefore, the joint optimization of energy and latency for federated learning over wireless networks must be considered. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, joint optimization of energy and latency for single task federated learning was considered. On the other hand, multitask federated learning has attractive applications in smart industries. Therefore, multitask federated learning schemes that jointly optimize energy and latency will be required.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.49.1.1" class="ltx_text" style="font-size:90%;">TABLE VIII</span>: </span><span id="S4.T8.50.2" class="ltx_text" style="font-size:90%;">Local learning models with discussion used in various federated learning-enabled IoT applications.</span></figcaption>
<table id="S4.T8.47.47" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T8.47.47.48" class="ltx_tr">
<td id="S4.T8.47.47.48.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T8.47.47.48.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.48.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T8.47.47.48.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S4.T8.47.47.48.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T8.47.47.48.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.48.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T8.47.47.48.2.1.1.1" class="ltx_text ltx_font_bold">Local learning model</span></span>
</span>
</td>
<td id="S4.T8.47.47.48.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T8.47.47.48.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.48.3.1.1" class="ltx_p" style="width:34.1pt;"><span id="S4.T8.47.47.48.3.1.1.1" class="ltx_text ltx_font_bold">Primary contribution</span></span>
</span>
</td>
<td id="S4.T8.47.47.48.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T8.47.47.48.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.48.4.1.1" class="ltx_p" style="width:130.9pt;"><span id="S4.T8.47.47.48.4.1.1.1" class="ltx_text ltx_font_bold">Local model architecture</span></span>
</span>
</td>
<td id="S4.T8.47.47.48.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T8.47.47.48.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.48.5.1.1" class="ltx_p" style="width:247.5pt;"><span id="S4.T8.47.47.48.5.1.1.1" class="ltx_text ltx_font_bold">Discussion</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.7.7.7" class="ltx_tr">
<td id="S4.T8.7.7.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.7.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.7.7.8.1.1" class="ltx_p" style="width:28.5pt;">Wang <span id="S4.T8.7.7.7.8.1.1.1" class="ltx_text ltx_font_italic">et al.</span>,  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite></span>
</span>
</td>
<td id="S4.T8.7.7.7.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.7.7.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.7.7.9.1.1" class="ltx_p" style="width:28.5pt;">SVM, CNN</span>
</span>
</td>
<td id="S4.T8.7.7.7.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.7.7.7.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.7.7.10.1.1" class="ltx_p" style="width:34.1pt;">Edge AI</span>
</span>
</td>
<td id="S4.T8.7.7.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.7.7.7.7.7" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.7.7.7.7.7" class="ltx_p" style="width:130.9pt;">The network has <math id="S4.T8.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.T8.1.1.1.1.1.1.m1.1a"><mn id="S4.T8.1.1.1.1.1.1.m1.1.1" xref="S4.T8.1.1.1.1.1.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S4.T8.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.1.1.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.1.1.1.m1.1c">9</annotation></semantics></math> layers with <math id="S4.T8.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="5\times 5\times 32" display="inline"><semantics id="S4.T8.2.2.2.2.2.2.m2.1a"><mrow id="S4.T8.2.2.2.2.2.2.m2.1.1" xref="S4.T8.2.2.2.2.2.2.m2.1.1.cmml"><mn id="S4.T8.2.2.2.2.2.2.m2.1.1.2" xref="S4.T8.2.2.2.2.2.2.m2.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.2.2.2.2.2.2.m2.1.1.1" xref="S4.T8.2.2.2.2.2.2.m2.1.1.1.cmml">×</mo><mn id="S4.T8.2.2.2.2.2.2.m2.1.1.3" xref="S4.T8.2.2.2.2.2.2.m2.1.1.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.2.2.2.2.2.2.m2.1.1.1a" xref="S4.T8.2.2.2.2.2.2.m2.1.1.1.cmml">×</mo><mn id="S4.T8.2.2.2.2.2.2.m2.1.1.4" xref="S4.T8.2.2.2.2.2.2.m2.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.2.2.2.m2.1b"><apply id="S4.T8.2.2.2.2.2.2.m2.1.1.cmml" xref="S4.T8.2.2.2.2.2.2.m2.1.1"><times id="S4.T8.2.2.2.2.2.2.m2.1.1.1.cmml" xref="S4.T8.2.2.2.2.2.2.m2.1.1.1"></times><cn type="integer" id="S4.T8.2.2.2.2.2.2.m2.1.1.2.cmml" xref="S4.T8.2.2.2.2.2.2.m2.1.1.2">5</cn><cn type="integer" id="S4.T8.2.2.2.2.2.2.m2.1.1.3.cmml" xref="S4.T8.2.2.2.2.2.2.m2.1.1.3">5</cn><cn type="integer" id="S4.T8.2.2.2.2.2.2.m2.1.1.4.cmml" xref="S4.T8.2.2.2.2.2.2.m2.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.2.2.2.m2.1c">5\times 5\times 32</annotation></semantics></math> convolutional, <math id="S4.T8.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S4.T8.3.3.3.3.3.3.m3.1a"><mrow id="S4.T8.3.3.3.3.3.3.m3.1.1" xref="S4.T8.3.3.3.3.3.3.m3.1.1.cmml"><mn id="S4.T8.3.3.3.3.3.3.m3.1.1.2" xref="S4.T8.3.3.3.3.3.3.m3.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.3.3.3.3.3.3.m3.1.1.1" xref="S4.T8.3.3.3.3.3.3.m3.1.1.1.cmml">×</mo><mn id="S4.T8.3.3.3.3.3.3.m3.1.1.3" xref="S4.T8.3.3.3.3.3.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.3.3.3.m3.1b"><apply id="S4.T8.3.3.3.3.3.3.m3.1.1.cmml" xref="S4.T8.3.3.3.3.3.3.m3.1.1"><times id="S4.T8.3.3.3.3.3.3.m3.1.1.1.cmml" xref="S4.T8.3.3.3.3.3.3.m3.1.1.1"></times><cn type="integer" id="S4.T8.3.3.3.3.3.3.m3.1.1.2.cmml" xref="S4.T8.3.3.3.3.3.3.m3.1.1.2">2</cn><cn type="integer" id="S4.T8.3.3.3.3.3.3.m3.1.1.3.cmml" xref="S4.T8.3.3.3.3.3.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.3.3.3.m3.1c">2\times 2</annotation></semantics></math> MaxPool, local response normalization, <math id="S4.T8.4.4.4.4.4.4.m4.1" class="ltx_Math" alttext="5\times 5\times 32" display="inline"><semantics id="S4.T8.4.4.4.4.4.4.m4.1a"><mrow id="S4.T8.4.4.4.4.4.4.m4.1.1" xref="S4.T8.4.4.4.4.4.4.m4.1.1.cmml"><mn id="S4.T8.4.4.4.4.4.4.m4.1.1.2" xref="S4.T8.4.4.4.4.4.4.m4.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.4.4.4.4.4.4.m4.1.1.1" xref="S4.T8.4.4.4.4.4.4.m4.1.1.1.cmml">×</mo><mn id="S4.T8.4.4.4.4.4.4.m4.1.1.3" xref="S4.T8.4.4.4.4.4.4.m4.1.1.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.4.4.4.4.4.4.m4.1.1.1a" xref="S4.T8.4.4.4.4.4.4.m4.1.1.1.cmml">×</mo><mn id="S4.T8.4.4.4.4.4.4.m4.1.1.4" xref="S4.T8.4.4.4.4.4.4.m4.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.4.4.4.m4.1b"><apply id="S4.T8.4.4.4.4.4.4.m4.1.1.cmml" xref="S4.T8.4.4.4.4.4.4.m4.1.1"><times id="S4.T8.4.4.4.4.4.4.m4.1.1.1.cmml" xref="S4.T8.4.4.4.4.4.4.m4.1.1.1"></times><cn type="integer" id="S4.T8.4.4.4.4.4.4.m4.1.1.2.cmml" xref="S4.T8.4.4.4.4.4.4.m4.1.1.2">5</cn><cn type="integer" id="S4.T8.4.4.4.4.4.4.m4.1.1.3.cmml" xref="S4.T8.4.4.4.4.4.4.m4.1.1.3">5</cn><cn type="integer" id="S4.T8.4.4.4.4.4.4.m4.1.1.4.cmml" xref="S4.T8.4.4.4.4.4.4.m4.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.4.4.4.m4.1c">5\times 5\times 32</annotation></semantics></math> Convolutional, local response normalization, <math id="S4.T8.5.5.5.5.5.5.m5.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S4.T8.5.5.5.5.5.5.m5.1a"><mrow id="S4.T8.5.5.5.5.5.5.m5.1.1" xref="S4.T8.5.5.5.5.5.5.m5.1.1.cmml"><mn id="S4.T8.5.5.5.5.5.5.m5.1.1.2" xref="S4.T8.5.5.5.5.5.5.m5.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.5.5.5.5.5.5.m5.1.1.1" xref="S4.T8.5.5.5.5.5.5.m5.1.1.1.cmml">×</mo><mn id="S4.T8.5.5.5.5.5.5.m5.1.1.3" xref="S4.T8.5.5.5.5.5.5.m5.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.5.5.5.5.5.5.m5.1b"><apply id="S4.T8.5.5.5.5.5.5.m5.1.1.cmml" xref="S4.T8.5.5.5.5.5.5.m5.1.1"><times id="S4.T8.5.5.5.5.5.5.m5.1.1.1.cmml" xref="S4.T8.5.5.5.5.5.5.m5.1.1.1"></times><cn type="integer" id="S4.T8.5.5.5.5.5.5.m5.1.1.2.cmml" xref="S4.T8.5.5.5.5.5.5.m5.1.1.2">2</cn><cn type="integer" id="S4.T8.5.5.5.5.5.5.m5.1.1.3.cmml" xref="S4.T8.5.5.5.5.5.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.5.5.5.5.5.m5.1c">2\times 2</annotation></semantics></math> MaxPool, <math id="S4.T8.6.6.6.6.6.6.m6.1" class="ltx_Math" alttext="z\times 256" display="inline"><semantics id="S4.T8.6.6.6.6.6.6.m6.1a"><mrow id="S4.T8.6.6.6.6.6.6.m6.1.1" xref="S4.T8.6.6.6.6.6.6.m6.1.1.cmml"><mi id="S4.T8.6.6.6.6.6.6.m6.1.1.2" xref="S4.T8.6.6.6.6.6.6.m6.1.1.2.cmml">z</mi><mo lspace="0.222em" rspace="0.222em" id="S4.T8.6.6.6.6.6.6.m6.1.1.1" xref="S4.T8.6.6.6.6.6.6.m6.1.1.1.cmml">×</mo><mn id="S4.T8.6.6.6.6.6.6.m6.1.1.3" xref="S4.T8.6.6.6.6.6.6.m6.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.6.6.6.6.6.6.m6.1b"><apply id="S4.T8.6.6.6.6.6.6.m6.1.1.cmml" xref="S4.T8.6.6.6.6.6.6.m6.1.1"><times id="S4.T8.6.6.6.6.6.6.m6.1.1.1.cmml" xref="S4.T8.6.6.6.6.6.6.m6.1.1.1"></times><ci id="S4.T8.6.6.6.6.6.6.m6.1.1.2.cmml" xref="S4.T8.6.6.6.6.6.6.m6.1.1.2">𝑧</ci><cn type="integer" id="S4.T8.6.6.6.6.6.6.m6.1.1.3.cmml" xref="S4.T8.6.6.6.6.6.6.m6.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.6.6.6.6.6.m6.1c">z\times 256</annotation></semantics></math> fully connected, <math id="S4.T8.7.7.7.7.7.7.m7.1" class="ltx_Math" alttext="256\times 10" display="inline"><semantics id="S4.T8.7.7.7.7.7.7.m7.1a"><mrow id="S4.T8.7.7.7.7.7.7.m7.1.1" xref="S4.T8.7.7.7.7.7.7.m7.1.1.cmml"><mn id="S4.T8.7.7.7.7.7.7.m7.1.1.2" xref="S4.T8.7.7.7.7.7.7.m7.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.7.7.7.7.7.7.m7.1.1.1" xref="S4.T8.7.7.7.7.7.7.m7.1.1.1.cmml">×</mo><mn id="S4.T8.7.7.7.7.7.7.m7.1.1.3" xref="S4.T8.7.7.7.7.7.7.m7.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.7.7.7.7.7.7.m7.1b"><apply id="S4.T8.7.7.7.7.7.7.m7.1.1.cmml" xref="S4.T8.7.7.7.7.7.7.m7.1.1"><times id="S4.T8.7.7.7.7.7.7.m7.1.1.1.cmml" xref="S4.T8.7.7.7.7.7.7.m7.1.1.1"></times><cn type="integer" id="S4.T8.7.7.7.7.7.7.m7.1.1.2.cmml" xref="S4.T8.7.7.7.7.7.7.m7.1.1.2">256</cn><cn type="integer" id="S4.T8.7.7.7.7.7.7.m7.1.1.3.cmml" xref="S4.T8.7.7.7.7.7.7.m7.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.7.7.7.7.7.m7.1c">256\times 10</annotation></semantics></math> fully connected, and softmax activation. The other model is squared-SVM.</span>
</span>
</td>
<td id="S4.T8.7.7.7.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.7.7.7.11.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.7.7.11.1.1" class="ltx_p" style="width:247.5pt;">The authors considered various data distributions for analysis with the aim to find the optimal number of local iterations. Their analysis shows that number of optimal local iterations depends on the type of dataset, data distribution, and local learning model. Meanwhile, their proposed adaptive algorithm generally achieved better performance than traditional federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> by optimally adjusting local learning model iterations. Although theoretical analysis for convex loss functions are provided, the work did not consider theoretical analysis for non-convex loss functions of many practical scenarios.</span>
</span>
</td>
</tr>
<tr id="S4.T8.47.47.49" class="ltx_tr">
<td id="S4.T8.47.47.49.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.47.47.49.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.49.1.1.1" class="ltx_p" style="width:28.5pt;">Wang <span id="S4.T8.47.47.49.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S4.T8.47.47.49.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.47.47.49.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.49.2.1.1" class="ltx_p" style="width:28.5pt;">FNN</span>
</span>
</td>
<td id="S4.T8.47.47.49.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.47.47.49.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.49.3.1.1" class="ltx_p" style="width:34.1pt;">Intelligent edge caching and computational offloading</span>
</span>
</td>
<td id="S4.T8.47.47.49.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.47.47.49.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.49.4.1.1" class="ltx_p" style="width:130.9pt;">Single-layer fully-connected FNN, that has 200 neurons.</span>
</span>
</td>
<td id="S4.T8.47.47.49.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.47.47.49.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.49.5.1.1" class="ltx_p" style="width:247.5pt;">The federated learning-based double deep Q-network performed near to centralized double deep Q-network. Meanwhile, transmission cost is also low for federated learning-based double deep Q-network compared to centralized learning-based double deep Q-network. However, its performance is little degraded than the deep Q-network based on centralized training, which may be further improved by considering more complex local learning model (e.g., convolutional neural network with many layers).</span>
</span>
</td>
</tr>
<tr id="S4.T8.19.19.19" class="ltx_tr">
<td id="S4.T8.19.19.19.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.19.19.19.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.19.19.19.13.1.1" class="ltx_p" style="width:28.5pt;">Nishio <span id="S4.T8.19.19.19.13.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
</span>
</td>
<td id="S4.T8.19.19.19.14" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.19.19.19.14.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.19.19.19.14.1.1" class="ltx_p" style="width:28.5pt;">CNN</span>
</span>
</td>
<td id="S4.T8.19.19.19.15" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.19.19.19.15.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.19.19.19.15.1.1" class="ltx_p" style="width:34.1pt;">Client selection protocol</span>
</span>
</td>
<td id="S4.T8.18.18.18.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.18.18.18.11.11" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.18.18.18.11.11.11" class="ltx_p" style="width:130.9pt;">The model has six convolution layers with <math id="S4.T8.8.8.8.1.1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.T8.8.8.8.1.1.1.m1.1a"><mn id="S4.T8.8.8.8.1.1.1.m1.1.1" xref="S4.T8.8.8.8.1.1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.T8.8.8.8.1.1.1.m1.1b"><cn type="integer" id="S4.T8.8.8.8.1.1.1.m1.1.1.cmml" xref="S4.T8.8.8.8.1.1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.8.8.1.1.1.m1.1c">32</annotation></semantics></math>, <math id="S4.T8.9.9.9.2.2.2.m2.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.T8.9.9.9.2.2.2.m2.1a"><mn id="S4.T8.9.9.9.2.2.2.m2.1.1" xref="S4.T8.9.9.9.2.2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.T8.9.9.9.2.2.2.m2.1b"><cn type="integer" id="S4.T8.9.9.9.2.2.2.m2.1.1.cmml" xref="S4.T8.9.9.9.2.2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.9.9.9.2.2.2.m2.1c">32</annotation></semantics></math> , <math id="S4.T8.10.10.10.3.3.3.m3.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.T8.10.10.10.3.3.3.m3.1a"><mn id="S4.T8.10.10.10.3.3.3.m3.1.1" xref="S4.T8.10.10.10.3.3.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.T8.10.10.10.3.3.3.m3.1b"><cn type="integer" id="S4.T8.10.10.10.3.3.3.m3.1.1.cmml" xref="S4.T8.10.10.10.3.3.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.10.10.10.3.3.3.m3.1c">64</annotation></semantics></math>, <math id="S4.T8.11.11.11.4.4.4.m4.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.T8.11.11.11.4.4.4.m4.1a"><mn id="S4.T8.11.11.11.4.4.4.m4.1.1" xref="S4.T8.11.11.11.4.4.4.m4.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.T8.11.11.11.4.4.4.m4.1b"><cn type="integer" id="S4.T8.11.11.11.4.4.4.m4.1.1.cmml" xref="S4.T8.11.11.11.4.4.4.m4.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.11.11.11.4.4.4.m4.1c">64</annotation></semantics></math>, <math id="S4.T8.12.12.12.5.5.5.m5.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S4.T8.12.12.12.5.5.5.m5.1a"><mn id="S4.T8.12.12.12.5.5.5.m5.1.1" xref="S4.T8.12.12.12.5.5.5.m5.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.T8.12.12.12.5.5.5.m5.1b"><cn type="integer" id="S4.T8.12.12.12.5.5.5.m5.1.1.cmml" xref="S4.T8.12.12.12.5.5.5.m5.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.12.12.12.5.5.5.m5.1c">128</annotation></semantics></math>, and <math id="S4.T8.13.13.13.6.6.6.m6.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S4.T8.13.13.13.6.6.6.m6.1a"><mn id="S4.T8.13.13.13.6.6.6.m6.1.1" xref="S4.T8.13.13.13.6.6.6.m6.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.T8.13.13.13.6.6.6.m6.1b"><cn type="integer" id="S4.T8.13.13.13.6.6.6.m6.1.1.cmml" xref="S4.T8.13.13.13.6.6.6.m6.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.13.13.13.6.6.6.m6.1c">128</annotation></semantics></math> channels. All the convolutional layer use <math id="S4.T8.14.14.14.7.7.7.m7.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.T8.14.14.14.7.7.7.m7.1a"><mrow id="S4.T8.14.14.14.7.7.7.m7.1.1" xref="S4.T8.14.14.14.7.7.7.m7.1.1.cmml"><mn id="S4.T8.14.14.14.7.7.7.m7.1.1.2" xref="S4.T8.14.14.14.7.7.7.m7.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.14.14.14.7.7.7.m7.1.1.1" xref="S4.T8.14.14.14.7.7.7.m7.1.1.1.cmml">×</mo><mn id="S4.T8.14.14.14.7.7.7.m7.1.1.3" xref="S4.T8.14.14.14.7.7.7.m7.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.14.14.14.7.7.7.m7.1b"><apply id="S4.T8.14.14.14.7.7.7.m7.1.1.cmml" xref="S4.T8.14.14.14.7.7.7.m7.1.1"><times id="S4.T8.14.14.14.7.7.7.m7.1.1.1.cmml" xref="S4.T8.14.14.14.7.7.7.m7.1.1.1"></times><cn type="integer" id="S4.T8.14.14.14.7.7.7.m7.1.1.2.cmml" xref="S4.T8.14.14.14.7.7.7.m7.1.1.2">3</cn><cn type="integer" id="S4.T8.14.14.14.7.7.7.m7.1.1.3.cmml" xref="S4.T8.14.14.14.7.7.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.14.14.14.7.7.7.m7.1c">3\times 3</annotation></semantics></math> filters. All the layers are are followed by ReLU and batch normalization. After every two layers <math id="S4.T8.15.15.15.8.8.8.m8.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S4.T8.15.15.15.8.8.8.m8.1a"><mrow id="S4.T8.15.15.15.8.8.8.m8.1.1" xref="S4.T8.15.15.15.8.8.8.m8.1.1.cmml"><mn id="S4.T8.15.15.15.8.8.8.m8.1.1.2" xref="S4.T8.15.15.15.8.8.8.m8.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.15.15.15.8.8.8.m8.1.1.1" xref="S4.T8.15.15.15.8.8.8.m8.1.1.1.cmml">×</mo><mn id="S4.T8.15.15.15.8.8.8.m8.1.1.3" xref="S4.T8.15.15.15.8.8.8.m8.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.15.15.15.8.8.8.m8.1b"><apply id="S4.T8.15.15.15.8.8.8.m8.1.1.cmml" xref="S4.T8.15.15.15.8.8.8.m8.1.1"><times id="S4.T8.15.15.15.8.8.8.m8.1.1.1.cmml" xref="S4.T8.15.15.15.8.8.8.m8.1.1.1"></times><cn type="integer" id="S4.T8.15.15.15.8.8.8.m8.1.1.2.cmml" xref="S4.T8.15.15.15.8.8.8.m8.1.1.2">2</cn><cn type="integer" id="S4.T8.15.15.15.8.8.8.m8.1.1.3.cmml" xref="S4.T8.15.15.15.8.8.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.15.15.15.8.8.8.m8.1c">2\times 2</annotation></semantics></math> max pooling is used. These convolutional layers are followed by three fully connected layers with <math id="S4.T8.16.16.16.9.9.9.m9.1" class="ltx_Math" alttext="382" display="inline"><semantics id="S4.T8.16.16.16.9.9.9.m9.1a"><mn id="S4.T8.16.16.16.9.9.9.m9.1.1" xref="S4.T8.16.16.16.9.9.9.m9.1.1.cmml">382</mn><annotation-xml encoding="MathML-Content" id="S4.T8.16.16.16.9.9.9.m9.1b"><cn type="integer" id="S4.T8.16.16.16.9.9.9.m9.1.1.cmml" xref="S4.T8.16.16.16.9.9.9.m9.1.1">382</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.16.16.16.9.9.9.m9.1c">382</annotation></semantics></math> and <math id="S4.T8.17.17.17.10.10.10.m10.1" class="ltx_Math" alttext="192" display="inline"><semantics id="S4.T8.17.17.17.10.10.10.m10.1a"><mn id="S4.T8.17.17.17.10.10.10.m10.1.1" xref="S4.T8.17.17.17.10.10.10.m10.1.1.cmml">192</mn><annotation-xml encoding="MathML-Content" id="S4.T8.17.17.17.10.10.10.m10.1b"><cn type="integer" id="S4.T8.17.17.17.10.10.10.m10.1.1.cmml" xref="S4.T8.17.17.17.10.10.10.m10.1.1">192</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.17.17.17.10.10.10.m10.1c">192</annotation></semantics></math> units. The last layer has <math id="S4.T8.18.18.18.11.11.11.m11.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T8.18.18.18.11.11.11.m11.1a"><mn id="S4.T8.18.18.18.11.11.11.m11.1.1" xref="S4.T8.18.18.18.11.11.11.m11.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T8.18.18.18.11.11.11.m11.1b"><cn type="integer" id="S4.T8.18.18.18.11.11.11.m11.1.1.cmml" xref="S4.T8.18.18.18.11.11.11.m11.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.18.18.18.11.11.11.m11.1c">10</annotation></semantics></math> units with softmax activation.</span>
</span>
</td>
<td id="S4.T8.19.19.19.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.19.19.19.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.19.19.19.12.1.1" class="ltx_p" style="width:247.5pt;">The proposed client selection protocol showed performance improvement than the random client selection of FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> with an increase in deadline that accounts for overall global model computation time using both IID and non-IID settings for fashion MNIST and CIFAR-<math id="S4.T8.19.19.19.12.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T8.19.19.19.12.1.1.m1.1a"><mn id="S4.T8.19.19.19.12.1.1.m1.1.1" xref="S4.T8.19.19.19.12.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T8.19.19.19.12.1.1.m1.1b"><cn type="integer" id="S4.T8.19.19.19.12.1.1.m1.1.1.cmml" xref="S4.T8.19.19.19.12.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.19.19.19.12.1.1.m1.1c">10</annotation></semantics></math> datasets. Although the client selection protocol offered significant performance improvement, it did not consider the scenario of multiple BSs with aggregation server at a remote cloud.</span>
</span>
</td>
</tr>
<tr id="S4.T8.21.21.21" class="ltx_tr">
<td id="S4.T8.21.21.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.21.21.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.21.21.21.3.1.1" class="ltx_p" style="width:28.5pt;">Feraudo <span id="S4.T8.21.21.21.3.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite></span>
</span>
</td>
<td id="S4.T8.21.21.21.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.21.21.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.21.21.21.4.1.1" class="ltx_p" style="width:28.5pt;">FNN</span>
</span>
</td>
<td id="S4.T8.21.21.21.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.21.21.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.21.21.21.5.1.1" class="ltx_p" style="width:34.1pt;">Framework for intelligent edge</span>
</span>
</td>
<td id="S4.T8.21.21.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.21.21.21.2.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.21.21.21.2.2.2" class="ltx_p" style="width:130.9pt;">FNN model with two hidden layers having <math id="S4.T8.20.20.20.1.1.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.T8.20.20.20.1.1.1.m1.1a"><mn id="S4.T8.20.20.20.1.1.1.m1.1.1" xref="S4.T8.20.20.20.1.1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.T8.20.20.20.1.1.1.m1.1b"><cn type="integer" id="S4.T8.20.20.20.1.1.1.m1.1.1.cmml" xref="S4.T8.20.20.20.1.1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.20.20.20.1.1.1.m1.1c">50</annotation></semantics></math> and <math id="S4.T8.21.21.21.2.2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.T8.21.21.21.2.2.2.m2.1a"><mn id="S4.T8.21.21.21.2.2.2.m2.1.1" xref="S4.T8.21.21.21.2.2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.T8.21.21.21.2.2.2.m2.1b"><cn type="integer" id="S4.T8.21.21.21.2.2.2.m2.1.1.cmml" xref="S4.T8.21.21.21.2.2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.21.21.21.2.2.2.m2.1c">30</annotation></semantics></math> neurons.</span>
</span>
</td>
<td id="S4.T8.21.21.21.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.21.21.21.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.21.21.21.6.1.1" class="ltx_p" style="width:247.5pt;">From the analysis of this work, it is revealed that their framework generally results in performance improvement for an increase in number of local iterations. The proposed framework does not effectively tackle the security issues of the IoT devices. One must use effective authentication schemes for IoT devices to avoid injection of false local learning model updates. Injecting false local learning model updates will prolong the global federated learning convergence time.</span>
</span>
</td>
</tr>
<tr id="S4.T8.32.32.32" class="ltx_tr">
<td id="S4.T8.32.32.32.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.32.32.32.12.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.32.32.32.12.1.1" class="ltx_p" style="width:28.5pt;">Qu <span id="S4.T8.32.32.32.12.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite></span>
</span>
</td>
<td id="S4.T8.32.32.32.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.32.32.32.13.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.32.32.32.13.1.1" class="ltx_p" style="width:28.5pt;">CNN</span>
</span>
</td>
<td id="S4.T8.32.32.32.14" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.32.32.32.14.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.32.32.32.14.1.1" class="ltx_p" style="width:34.1pt;">Edge AI</span>
</span>
</td>
<td id="S4.T8.32.32.32.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.32.32.32.11.11" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.32.32.32.11.11.11" class="ltx_p" style="width:130.9pt;">The model has six convolution layers with <math id="S4.T8.22.22.22.1.1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.T8.22.22.22.1.1.1.m1.1a"><mn id="S4.T8.22.22.22.1.1.1.m1.1.1" xref="S4.T8.22.22.22.1.1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.T8.22.22.22.1.1.1.m1.1b"><cn type="integer" id="S4.T8.22.22.22.1.1.1.m1.1.1.cmml" xref="S4.T8.22.22.22.1.1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.22.22.22.1.1.1.m1.1c">32</annotation></semantics></math>, <math id="S4.T8.23.23.23.2.2.2.m2.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.T8.23.23.23.2.2.2.m2.1a"><mn id="S4.T8.23.23.23.2.2.2.m2.1.1" xref="S4.T8.23.23.23.2.2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.T8.23.23.23.2.2.2.m2.1b"><cn type="integer" id="S4.T8.23.23.23.2.2.2.m2.1.1.cmml" xref="S4.T8.23.23.23.2.2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.23.23.23.2.2.2.m2.1c">32</annotation></semantics></math> , <math id="S4.T8.24.24.24.3.3.3.m3.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.T8.24.24.24.3.3.3.m3.1a"><mn id="S4.T8.24.24.24.3.3.3.m3.1.1" xref="S4.T8.24.24.24.3.3.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.T8.24.24.24.3.3.3.m3.1b"><cn type="integer" id="S4.T8.24.24.24.3.3.3.m3.1.1.cmml" xref="S4.T8.24.24.24.3.3.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.24.24.24.3.3.3.m3.1c">64</annotation></semantics></math>, <math id="S4.T8.25.25.25.4.4.4.m4.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.T8.25.25.25.4.4.4.m4.1a"><mn id="S4.T8.25.25.25.4.4.4.m4.1.1" xref="S4.T8.25.25.25.4.4.4.m4.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.T8.25.25.25.4.4.4.m4.1b"><cn type="integer" id="S4.T8.25.25.25.4.4.4.m4.1.1.cmml" xref="S4.T8.25.25.25.4.4.4.m4.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.25.25.25.4.4.4.m4.1c">64</annotation></semantics></math>, <math id="S4.T8.26.26.26.5.5.5.m5.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S4.T8.26.26.26.5.5.5.m5.1a"><mn id="S4.T8.26.26.26.5.5.5.m5.1.1" xref="S4.T8.26.26.26.5.5.5.m5.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.T8.26.26.26.5.5.5.m5.1b"><cn type="integer" id="S4.T8.26.26.26.5.5.5.m5.1.1.cmml" xref="S4.T8.26.26.26.5.5.5.m5.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.26.26.26.5.5.5.m5.1c">128</annotation></semantics></math>, and <math id="S4.T8.27.27.27.6.6.6.m6.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S4.T8.27.27.27.6.6.6.m6.1a"><mn id="S4.T8.27.27.27.6.6.6.m6.1.1" xref="S4.T8.27.27.27.6.6.6.m6.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.T8.27.27.27.6.6.6.m6.1b"><cn type="integer" id="S4.T8.27.27.27.6.6.6.m6.1.1.cmml" xref="S4.T8.27.27.27.6.6.6.m6.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.27.27.27.6.6.6.m6.1c">128</annotation></semantics></math> channels. All the convolutional layer use <math id="S4.T8.28.28.28.7.7.7.m7.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.T8.28.28.28.7.7.7.m7.1a"><mrow id="S4.T8.28.28.28.7.7.7.m7.1.1" xref="S4.T8.28.28.28.7.7.7.m7.1.1.cmml"><mn id="S4.T8.28.28.28.7.7.7.m7.1.1.2" xref="S4.T8.28.28.28.7.7.7.m7.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.28.28.28.7.7.7.m7.1.1.1" xref="S4.T8.28.28.28.7.7.7.m7.1.1.1.cmml">×</mo><mn id="S4.T8.28.28.28.7.7.7.m7.1.1.3" xref="S4.T8.28.28.28.7.7.7.m7.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.28.28.28.7.7.7.m7.1b"><apply id="S4.T8.28.28.28.7.7.7.m7.1.1.cmml" xref="S4.T8.28.28.28.7.7.7.m7.1.1"><times id="S4.T8.28.28.28.7.7.7.m7.1.1.1.cmml" xref="S4.T8.28.28.28.7.7.7.m7.1.1.1"></times><cn type="integer" id="S4.T8.28.28.28.7.7.7.m7.1.1.2.cmml" xref="S4.T8.28.28.28.7.7.7.m7.1.1.2">3</cn><cn type="integer" id="S4.T8.28.28.28.7.7.7.m7.1.1.3.cmml" xref="S4.T8.28.28.28.7.7.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.28.28.28.7.7.7.m7.1c">3\times 3</annotation></semantics></math> filters. All the layers are are followed by ReLU and batch normalization. After every two layers <math id="S4.T8.29.29.29.8.8.8.m8.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S4.T8.29.29.29.8.8.8.m8.1a"><mrow id="S4.T8.29.29.29.8.8.8.m8.1.1" xref="S4.T8.29.29.29.8.8.8.m8.1.1.cmml"><mn id="S4.T8.29.29.29.8.8.8.m8.1.1.2" xref="S4.T8.29.29.29.8.8.8.m8.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.29.29.29.8.8.8.m8.1.1.1" xref="S4.T8.29.29.29.8.8.8.m8.1.1.1.cmml">×</mo><mn id="S4.T8.29.29.29.8.8.8.m8.1.1.3" xref="S4.T8.29.29.29.8.8.8.m8.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.29.29.29.8.8.8.m8.1b"><apply id="S4.T8.29.29.29.8.8.8.m8.1.1.cmml" xref="S4.T8.29.29.29.8.8.8.m8.1.1"><times id="S4.T8.29.29.29.8.8.8.m8.1.1.1.cmml" xref="S4.T8.29.29.29.8.8.8.m8.1.1.1"></times><cn type="integer" id="S4.T8.29.29.29.8.8.8.m8.1.1.2.cmml" xref="S4.T8.29.29.29.8.8.8.m8.1.1.2">2</cn><cn type="integer" id="S4.T8.29.29.29.8.8.8.m8.1.1.3.cmml" xref="S4.T8.29.29.29.8.8.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.29.29.29.8.8.8.m8.1c">2\times 2</annotation></semantics></math> max pooling is used. These convolutional layers are followed by three fully connected layers with <math id="S4.T8.30.30.30.9.9.9.m9.1" class="ltx_Math" alttext="382" display="inline"><semantics id="S4.T8.30.30.30.9.9.9.m9.1a"><mn id="S4.T8.30.30.30.9.9.9.m9.1.1" xref="S4.T8.30.30.30.9.9.9.m9.1.1.cmml">382</mn><annotation-xml encoding="MathML-Content" id="S4.T8.30.30.30.9.9.9.m9.1b"><cn type="integer" id="S4.T8.30.30.30.9.9.9.m9.1.1.cmml" xref="S4.T8.30.30.30.9.9.9.m9.1.1">382</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.30.30.30.9.9.9.m9.1c">382</annotation></semantics></math> and <math id="S4.T8.31.31.31.10.10.10.m10.1" class="ltx_Math" alttext="192" display="inline"><semantics id="S4.T8.31.31.31.10.10.10.m10.1a"><mn id="S4.T8.31.31.31.10.10.10.m10.1.1" xref="S4.T8.31.31.31.10.10.10.m10.1.1.cmml">192</mn><annotation-xml encoding="MathML-Content" id="S4.T8.31.31.31.10.10.10.m10.1b"><cn type="integer" id="S4.T8.31.31.31.10.10.10.m10.1.1.cmml" xref="S4.T8.31.31.31.10.10.10.m10.1.1">192</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.31.31.31.10.10.10.m10.1c">192</annotation></semantics></math> units. The last layer has <math id="S4.T8.32.32.32.11.11.11.m11.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.T8.32.32.32.11.11.11.m11.1a"><mn id="S4.T8.32.32.32.11.11.11.m11.1.1" xref="S4.T8.32.32.32.11.11.11.m11.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.T8.32.32.32.11.11.11.m11.1b"><cn type="integer" id="S4.T8.32.32.32.11.11.11.m11.1.1.cmml" xref="S4.T8.32.32.32.11.11.11.m11.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.32.32.32.11.11.11.m11.1c">10</annotation></semantics></math> units with softmax activation.</span>
</span>
</td>
<td id="S4.T8.32.32.32.15" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.32.32.32.15.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.32.32.32.15.1.1" class="ltx_p" style="width:247.5pt;">A block-FL framework using blockchain was proposed to avoid data poisoning. For both CIFAR-10 and fashion MNIST, the authors evaluated the performance of proposed scheme by increasing the round time for global model computation. Generally, increasing the number of round time causes an increase in global federated learning accuracy. Although FL-block can offer us with the robust operation, it has additional latency due to blockchain consensus algorithm.</span>
</span>
</td>
</tr>
<tr id="S4.T8.38.38.38" class="ltx_tr">
<td id="S4.T8.38.38.38.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.38.38.38.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.38.38.38.7.1.1" class="ltx_p" style="width:28.5pt;">Savazzi <span id="S4.T8.38.38.38.7.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite></span>
</span>
</td>
<td id="S4.T8.38.38.38.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.38.38.38.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.38.38.38.8.1.1" class="ltx_p" style="width:28.5pt;">CNN, FNN</span>
</span>
</td>
<td id="S4.T8.38.38.38.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.38.38.38.9.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.38.38.38.9.1.1" class="ltx_p" style="width:34.1pt;">Mobile networks</span>
</span>
</td>
<td id="S4.T8.38.38.38.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.38.38.38.6.6" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.38.38.38.6.6.6" class="ltx_p" style="width:130.9pt;">The 2NN model uses fully connected layer of <math id="S4.T8.33.33.33.1.1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.T8.33.33.33.1.1.1.m1.1a"><mn id="S4.T8.33.33.33.1.1.1.m1.1.1" xref="S4.T8.33.33.33.1.1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.T8.33.33.33.1.1.1.m1.1b"><cn type="integer" id="S4.T8.33.33.33.1.1.1.m1.1.1.cmml" xref="S4.T8.33.33.33.1.1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.33.33.33.1.1.1.m1.1c">32</annotation></semantics></math> hidden nodes (dimension <math id="S4.T8.34.34.34.2.2.2.m2.1" class="ltx_math_unparsed" alttext="512\times 32)" display="inline"><semantics id="S4.T8.34.34.34.2.2.2.m2.1a"><mrow id="S4.T8.34.34.34.2.2.2.m2.1b"><mn id="S4.T8.34.34.34.2.2.2.m2.1.1">512</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.34.34.34.2.2.2.m2.1.2">×</mo><mn id="S4.T8.34.34.34.2.2.2.m2.1.3">32</mn><mo stretchy="false" id="S4.T8.34.34.34.2.2.2.m2.1.4">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T8.34.34.34.2.2.2.m2.1c">512\times 32)</annotation></semantics></math> followed by a ReLU layer and a second fully connected layer of dimension <math id="S4.T8.35.35.35.3.3.3.m3.1" class="ltx_Math" alttext="32\times C" display="inline"><semantics id="S4.T8.35.35.35.3.3.3.m3.1a"><mrow id="S4.T8.35.35.35.3.3.3.m3.1.1" xref="S4.T8.35.35.35.3.3.3.m3.1.1.cmml"><mn id="S4.T8.35.35.35.3.3.3.m3.1.1.2" xref="S4.T8.35.35.35.3.3.3.m3.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.35.35.35.3.3.3.m3.1.1.1" xref="S4.T8.35.35.35.3.3.3.m3.1.1.1.cmml">×</mo><mi id="S4.T8.35.35.35.3.3.3.m3.1.1.3" xref="S4.T8.35.35.35.3.3.3.m3.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.35.35.35.3.3.3.m3.1b"><apply id="S4.T8.35.35.35.3.3.3.m3.1.1.cmml" xref="S4.T8.35.35.35.3.3.3.m3.1.1"><times id="S4.T8.35.35.35.3.3.3.m3.1.1.1.cmml" xref="S4.T8.35.35.35.3.3.3.m3.1.1.1"></times><cn type="integer" id="S4.T8.35.35.35.3.3.3.m3.1.1.2.cmml" xref="S4.T8.35.35.35.3.3.3.m3.1.1.2">32</cn><ci id="S4.T8.35.35.35.3.3.3.m3.1.1.3.cmml" xref="S4.T8.35.35.35.3.3.3.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.35.35.35.3.3.3.m3.1c">32\times C</annotation></semantics></math>.The second CNN model consists of a convolutional layer (<math id="S4.T8.36.36.36.4.4.4.m4.1" class="ltx_Math" alttext="8\times 16\times 1" display="inline"><semantics id="S4.T8.36.36.36.4.4.4.m4.1a"><mrow id="S4.T8.36.36.36.4.4.4.m4.1.1" xref="S4.T8.36.36.36.4.4.4.m4.1.1.cmml"><mn id="S4.T8.36.36.36.4.4.4.m4.1.1.2" xref="S4.T8.36.36.36.4.4.4.m4.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.36.36.36.4.4.4.m4.1.1.1" xref="S4.T8.36.36.36.4.4.4.m4.1.1.1.cmml">×</mo><mn id="S4.T8.36.36.36.4.4.4.m4.1.1.3" xref="S4.T8.36.36.36.4.4.4.m4.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.36.36.36.4.4.4.m4.1.1.1a" xref="S4.T8.36.36.36.4.4.4.m4.1.1.1.cmml">×</mo><mn id="S4.T8.36.36.36.4.4.4.m4.1.1.4" xref="S4.T8.36.36.36.4.4.4.m4.1.1.4.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.36.36.36.4.4.4.m4.1b"><apply id="S4.T8.36.36.36.4.4.4.m4.1.1.cmml" xref="S4.T8.36.36.36.4.4.4.m4.1.1"><times id="S4.T8.36.36.36.4.4.4.m4.1.1.1.cmml" xref="S4.T8.36.36.36.4.4.4.m4.1.1.1"></times><cn type="integer" id="S4.T8.36.36.36.4.4.4.m4.1.1.2.cmml" xref="S4.T8.36.36.36.4.4.4.m4.1.1.2">8</cn><cn type="integer" id="S4.T8.36.36.36.4.4.4.m4.1.1.3.cmml" xref="S4.T8.36.36.36.4.4.4.m4.1.1.3">16</cn><cn type="integer" id="S4.T8.36.36.36.4.4.4.m4.1.1.4.cmml" xref="S4.T8.36.36.36.4.4.4.m4.1.1.4">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.36.36.36.4.4.4.m4.1c">8\times 16\times 1</annotation></semantics></math>) followed by max pooling (<math id="S4.T8.37.37.37.5.5.5.m5.1" class="ltx_Math" alttext="5\times 5" display="inline"><semantics id="S4.T8.37.37.37.5.5.5.m5.1a"><mrow id="S4.T8.37.37.37.5.5.5.m5.1.1" xref="S4.T8.37.37.37.5.5.5.m5.1.1.cmml"><mn id="S4.T8.37.37.37.5.5.5.m5.1.1.2" xref="S4.T8.37.37.37.5.5.5.m5.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.37.37.37.5.5.5.m5.1.1.1" xref="S4.T8.37.37.37.5.5.5.m5.1.1.1.cmml">×</mo><mn id="S4.T8.37.37.37.5.5.5.m5.1.1.3" xref="S4.T8.37.37.37.5.5.5.m5.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.37.37.37.5.5.5.m5.1b"><apply id="S4.T8.37.37.37.5.5.5.m5.1.1.cmml" xref="S4.T8.37.37.37.5.5.5.m5.1.1"><times id="S4.T8.37.37.37.5.5.5.m5.1.1.1.cmml" xref="S4.T8.37.37.37.5.5.5.m5.1.1.1"></times><cn type="integer" id="S4.T8.37.37.37.5.5.5.m5.1.1.2.cmml" xref="S4.T8.37.37.37.5.5.5.m5.1.1.2">5</cn><cn type="integer" id="S4.T8.37.37.37.5.5.5.m5.1.1.3.cmml" xref="S4.T8.37.37.37.5.5.5.m5.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.37.37.37.5.5.5.m5.1c">5\times 5</annotation></semantics></math>) and a fully connected layer of dimension <math id="S4.T8.38.38.38.6.6.6.m6.1" class="ltx_Math" alttext="168\times C" display="inline"><semantics id="S4.T8.38.38.38.6.6.6.m6.1a"><mrow id="S4.T8.38.38.38.6.6.6.m6.1.1" xref="S4.T8.38.38.38.6.6.6.m6.1.1.cmml"><mn id="S4.T8.38.38.38.6.6.6.m6.1.1.2" xref="S4.T8.38.38.38.6.6.6.m6.1.1.2.cmml">168</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.38.38.38.6.6.6.m6.1.1.1" xref="S4.T8.38.38.38.6.6.6.m6.1.1.1.cmml">×</mo><mi id="S4.T8.38.38.38.6.6.6.m6.1.1.3" xref="S4.T8.38.38.38.6.6.6.m6.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.38.38.38.6.6.6.m6.1b"><apply id="S4.T8.38.38.38.6.6.6.m6.1.1.cmml" xref="S4.T8.38.38.38.6.6.6.m6.1.1"><times id="S4.T8.38.38.38.6.6.6.m6.1.1.1.cmml" xref="S4.T8.38.38.38.6.6.6.m6.1.1.1"></times><cn type="integer" id="S4.T8.38.38.38.6.6.6.m6.1.1.2.cmml" xref="S4.T8.38.38.38.6.6.6.m6.1.1.2">168</cn><ci id="S4.T8.38.38.38.6.6.6.m6.1.1.3.cmml" xref="S4.T8.38.38.38.6.6.6.m6.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.38.38.38.6.6.6.m6.1c">168\times C</annotation></semantics></math>.</span>
</span>
</td>
<td id="S4.T8.38.38.38.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.38.38.38.10.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.38.38.38.10.1.1" class="ltx_p" style="width:247.5pt;">A fully decentralized federated learning approach was proposed to minimize global communication rounds and improve convergence. Two schemes such as cooperative federated learning based FedAvg (CFA) and cooperative federated learning based FedAvg with gradient exchange (CFA-GE) were proposed. CFA-GE has shown less validation loss than CFA. Additionally, increasing the number of devices in cooperation also improves performance due to the fact that more devices participate in learning process. Although the proposed scheme can offer several advantages, it will result in additional complexity for performing cooperation between the devices.</span>
</span>
</td>
</tr>
<tr id="S4.T8.42.42.42" class="ltx_tr">
<td id="S4.T8.42.42.42.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.42.42.42.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.42.42.42.5.1.1" class="ltx_p" style="width:28.5pt;">Chen <span id="S4.T8.42.42.42.5.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite></span>
</span>
</td>
<td id="S4.T8.42.42.42.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.42.42.42.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.42.42.42.6.1.1" class="ltx_p" style="width:28.5pt;">CNN</span>
</span>
</td>
<td id="S4.T8.42.42.42.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.42.42.42.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.42.42.42.7.1.1" class="ltx_p" style="width:34.1pt;">Healthcare</span>
</span>
</td>
<td id="S4.T8.42.42.42.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.42.42.42.4.4" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.42.42.42.4.4.4" class="ltx_p" style="width:130.9pt;">The model has <math id="S4.T8.39.39.39.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T8.39.39.39.1.1.1.m1.1a"><mn id="S4.T8.39.39.39.1.1.1.m1.1.1" xref="S4.T8.39.39.39.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T8.39.39.39.1.1.1.m1.1b"><cn type="integer" id="S4.T8.39.39.39.1.1.1.m1.1.1.cmml" xref="S4.T8.39.39.39.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.39.39.39.1.1.1.m1.1c">2</annotation></semantics></math> convolutional layers, <math id="S4.T8.40.40.40.2.2.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T8.40.40.40.2.2.2.m2.1a"><mn id="S4.T8.40.40.40.2.2.2.m2.1.1" xref="S4.T8.40.40.40.2.2.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T8.40.40.40.2.2.2.m2.1b"><cn type="integer" id="S4.T8.40.40.40.2.2.2.m2.1.1.cmml" xref="S4.T8.40.40.40.2.2.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.40.40.40.2.2.2.m2.1c">2</annotation></semantics></math> pooling layers, and <math id="S4.T8.41.41.41.3.3.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.T8.41.41.41.3.3.3.m3.1a"><mn id="S4.T8.41.41.41.3.3.3.m3.1.1" xref="S4.T8.41.41.41.3.3.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.T8.41.41.41.3.3.3.m3.1b"><cn type="integer" id="S4.T8.41.41.41.3.3.3.m3.1.1.cmml" xref="S4.T8.41.41.41.3.3.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.41.41.41.3.3.3.m3.1c">3</annotation></semantics></math> fully connected layers. A convolution size of <math id="S4.T8.42.42.42.4.4.4.m4.1" class="ltx_Math" alttext="1\times 9" display="inline"><semantics id="S4.T8.42.42.42.4.4.4.m4.1a"><mrow id="S4.T8.42.42.42.4.4.4.m4.1.1" xref="S4.T8.42.42.42.4.4.4.m4.1.1.cmml"><mn id="S4.T8.42.42.42.4.4.4.m4.1.1.2" xref="S4.T8.42.42.42.4.4.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.42.42.42.4.4.4.m4.1.1.1" xref="S4.T8.42.42.42.4.4.4.m4.1.1.1.cmml">×</mo><mn id="S4.T8.42.42.42.4.4.4.m4.1.1.3" xref="S4.T8.42.42.42.4.4.4.m4.1.1.3.cmml">9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.42.42.42.4.4.4.m4.1b"><apply id="S4.T8.42.42.42.4.4.4.m4.1.1.cmml" xref="S4.T8.42.42.42.4.4.4.m4.1.1"><times id="S4.T8.42.42.42.4.4.4.m4.1.1.1.cmml" xref="S4.T8.42.42.42.4.4.4.m4.1.1.1"></times><cn type="integer" id="S4.T8.42.42.42.4.4.4.m4.1.1.2.cmml" xref="S4.T8.42.42.42.4.4.4.m4.1.1.2">1</cn><cn type="integer" id="S4.T8.42.42.42.4.4.4.m4.1.1.3.cmml" xref="S4.T8.42.42.42.4.4.4.m4.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.42.42.42.4.4.4.m4.1c">1\times 9</annotation></semantics></math> was used.</span>
</span>
</td>
<td id="S4.T8.42.42.42.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.42.42.42.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.42.42.42.8.1.1" class="ltx_p" style="width:247.5pt;">A federated transfer learning framework was proposed for end-devices with their own local datasets and a public dataset at cloud. The convolutional layers and max-pooling layers are kept frozen (not updated) in model transfer at end-devices due to low-level features extraction characteristic of these layers regarding the end-user activity. Using transfer learning in such as fashion at end-devices results in significant performance improvement. Their proposal out performed support vector machines and k-nearest neighbors algorithm. Furthermore, the proposed framework can be extended with incremental learning for more personalized healthcare.</span>
</span>
</td>
</tr>
<tr id="S4.T8.47.47.47" class="ltx_tr">
<td id="S4.T8.47.47.47.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T8.47.47.47.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.47.6.1.1" class="ltx_p" style="width:28.5pt;">Chen <span id="S4.T8.47.47.47.6.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite></span>
</span>
</td>
<td id="S4.T8.47.47.47.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T8.47.47.47.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.47.7.1.1" class="ltx_p" style="width:28.5pt;">CNN</span>
</span>
</td>
<td id="S4.T8.47.47.47.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T8.47.47.47.8.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.47.8.1.1" class="ltx_p" style="width:34.1pt;">Augmented reality</span>
</span>
</td>
<td id="S4.T8.45.45.45.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T8.45.45.45.3.3" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.45.45.45.3.3.3" class="ltx_p" style="width:130.9pt;">The network has a convolutional layer (i.e., <math id="S4.T8.43.43.43.1.1.1.m1.1" class="ltx_Math" alttext="3\times 6\times 5" display="inline"><semantics id="S4.T8.43.43.43.1.1.1.m1.1a"><mrow id="S4.T8.43.43.43.1.1.1.m1.1.1" xref="S4.T8.43.43.43.1.1.1.m1.1.1.cmml"><mn id="S4.T8.43.43.43.1.1.1.m1.1.1.2" xref="S4.T8.43.43.43.1.1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.43.43.43.1.1.1.m1.1.1.1" xref="S4.T8.43.43.43.1.1.1.m1.1.1.1.cmml">×</mo><mn id="S4.T8.43.43.43.1.1.1.m1.1.1.3" xref="S4.T8.43.43.43.1.1.1.m1.1.1.3.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.43.43.43.1.1.1.m1.1.1.1a" xref="S4.T8.43.43.43.1.1.1.m1.1.1.1.cmml">×</mo><mn id="S4.T8.43.43.43.1.1.1.m1.1.1.4" xref="S4.T8.43.43.43.1.1.1.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.43.43.43.1.1.1.m1.1b"><apply id="S4.T8.43.43.43.1.1.1.m1.1.1.cmml" xref="S4.T8.43.43.43.1.1.1.m1.1.1"><times id="S4.T8.43.43.43.1.1.1.m1.1.1.1.cmml" xref="S4.T8.43.43.43.1.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T8.43.43.43.1.1.1.m1.1.1.2.cmml" xref="S4.T8.43.43.43.1.1.1.m1.1.1.2">3</cn><cn type="integer" id="S4.T8.43.43.43.1.1.1.m1.1.1.3.cmml" xref="S4.T8.43.43.43.1.1.1.m1.1.1.3">6</cn><cn type="integer" id="S4.T8.43.43.43.1.1.1.m1.1.1.4.cmml" xref="S4.T8.43.43.43.1.1.1.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.43.43.43.1.1.1.m1.1c">3\times 6\times 5</annotation></semantics></math>), maxpool layer (i.e., <math id="S4.T8.44.44.44.2.2.2.m2.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S4.T8.44.44.44.2.2.2.m2.1a"><mrow id="S4.T8.44.44.44.2.2.2.m2.1.1" xref="S4.T8.44.44.44.2.2.2.m2.1.1.cmml"><mn id="S4.T8.44.44.44.2.2.2.m2.1.1.2" xref="S4.T8.44.44.44.2.2.2.m2.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.44.44.44.2.2.2.m2.1.1.1" xref="S4.T8.44.44.44.2.2.2.m2.1.1.1.cmml">×</mo><mn id="S4.T8.44.44.44.2.2.2.m2.1.1.3" xref="S4.T8.44.44.44.2.2.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.44.44.44.2.2.2.m2.1b"><apply id="S4.T8.44.44.44.2.2.2.m2.1.1.cmml" xref="S4.T8.44.44.44.2.2.2.m2.1.1"><times id="S4.T8.44.44.44.2.2.2.m2.1.1.1.cmml" xref="S4.T8.44.44.44.2.2.2.m2.1.1.1"></times><cn type="integer" id="S4.T8.44.44.44.2.2.2.m2.1.1.2.cmml" xref="S4.T8.44.44.44.2.2.2.m2.1.1.2">2</cn><cn type="integer" id="S4.T8.44.44.44.2.2.2.m2.1.1.3.cmml" xref="S4.T8.44.44.44.2.2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.44.44.44.2.2.2.m2.1c">2\times 2</annotation></semantics></math> ), convolutional layer (i.e., <math id="S4.T8.45.45.45.3.3.3.m3.1" class="ltx_Math" alttext="6\times 16\times 5" display="inline"><semantics id="S4.T8.45.45.45.3.3.3.m3.1a"><mrow id="S4.T8.45.45.45.3.3.3.m3.1.1" xref="S4.T8.45.45.45.3.3.3.m3.1.1.cmml"><mn id="S4.T8.45.45.45.3.3.3.m3.1.1.2" xref="S4.T8.45.45.45.3.3.3.m3.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.45.45.45.3.3.3.m3.1.1.1" xref="S4.T8.45.45.45.3.3.3.m3.1.1.1.cmml">×</mo><mn id="S4.T8.45.45.45.3.3.3.m3.1.1.3" xref="S4.T8.45.45.45.3.3.3.m3.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T8.45.45.45.3.3.3.m3.1.1.1a" xref="S4.T8.45.45.45.3.3.3.m3.1.1.1.cmml">×</mo><mn id="S4.T8.45.45.45.3.3.3.m3.1.1.4" xref="S4.T8.45.45.45.3.3.3.m3.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.45.45.45.3.3.3.m3.1b"><apply id="S4.T8.45.45.45.3.3.3.m3.1.1.cmml" xref="S4.T8.45.45.45.3.3.3.m3.1.1"><times id="S4.T8.45.45.45.3.3.3.m3.1.1.1.cmml" xref="S4.T8.45.45.45.3.3.3.m3.1.1.1"></times><cn type="integer" id="S4.T8.45.45.45.3.3.3.m3.1.1.2.cmml" xref="S4.T8.45.45.45.3.3.3.m3.1.1.2">6</cn><cn type="integer" id="S4.T8.45.45.45.3.3.3.m3.1.1.3.cmml" xref="S4.T8.45.45.45.3.3.3.m3.1.1.3">16</cn><cn type="integer" id="S4.T8.45.45.45.3.3.3.m3.1.1.4.cmml" xref="S4.T8.45.45.45.3.3.3.m3.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.45.45.45.3.3.3.m3.1c">6\times 16\times 5</annotation></semantics></math> ), and followed by a fully connected network. The activation function used was ReLU.</span>
</span>
</td>
<td id="S4.T8.47.47.47.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T8.47.47.47.5.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.47.47.47.5.2.2" class="ltx_p" style="width:247.5pt;">This work considered a convolutional neural network model and CIFAR-10 dataset. From the analysis, it is revealed that an increase in local iterations will cause a proportional performance improvement. However, the increase will not be more for higher number of local iterations (i.e., for <math id="S4.T8.46.46.46.4.1.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.T8.46.46.46.4.1.1.m1.1a"><mn id="S4.T8.46.46.46.4.1.1.m1.1.1" xref="S4.T8.46.46.46.4.1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.T8.46.46.46.4.1.1.m1.1b"><cn type="integer" id="S4.T8.46.46.46.4.1.1.m1.1.1.cmml" xref="S4.T8.46.46.46.4.1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.46.46.46.4.1.1.m1.1c">15</annotation></semantics></math> and <math id="S4.T8.47.47.47.5.2.2.m2.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.T8.47.47.47.5.2.2.m2.1a"><mn id="S4.T8.47.47.47.5.2.2.m2.1.1" xref="S4.T8.47.47.47.5.2.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.T8.47.47.47.5.2.2.m2.1b"><cn type="integer" id="S4.T8.47.47.47.5.2.2.m2.1.1.cmml" xref="S4.T8.47.47.47.5.2.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.47.47.47.5.2.2.m2.1c">20</annotation></semantics></math>). Simple averaging in the proposed scheme can be replaced by weighted aggregation scheme that will take into account the wireless fairness issues.</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Local Learning Models</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In typical federated learning, two types of nodes such as end-devices and centralized edge/cloud servers are involved. First of all, a local learning model is trained at every device using its local dataset. The choice of local learning model strictly depends on the type of IoT task and end-devices computational power with backup energy. For a particular kind of local learning model (e.g., CNN), selecting the number of hidden layers with activation functions determines its performance. Generally, increasing the number of layers improves the local learning performance. However, considering large models that consist of many hidden layers might not always perform well. The reason for this can be the small size of the considered local dataset. It may happen with deep learning models used for local model computation to cause performance degradation with an increase in a number of hidden layers for small local datasets. Therefore, depending on the type of local dataset and task, we should select wisely the number of hidden layers for the local learning model. Additionally, the activation functions must be chosen properly as already mentioned in Section <a href="#S2.SS3" title="II-C Local Learning Models ‣ II Federated Learning for IoT: Fundamental Concepts ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-C</span></span></a>. Various machine learning schemes: Naive Bayes, SVM, CNN, and LSTM can be used for local model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Summary of local learning models with their IoT application is given in Table <a href="#S4.T8" title="TABLE VIII ‣ IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>. Additionally, Table <a href="#S4.T8" title="TABLE VIII ‣ IV-B Resources ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a> provides details about the local learning model architecture and insights about the performance of federated learning for various applications using these local learning models. The CNN models are used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> for smart object detection, mobile networks, healthcare, augmented reality, and vehicular networks. Other works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> mainly focused on edge intelligence to enable various IoT applications. Typically, end-devices have low computational power and limited backup power. Therefore, running complex deep learning algorithms on end-devices with low computational might not be desirable. To address this issue, one must use some effective local computation complexity reduction approach to minimize the local learning model computation time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. We must modify the existing local learning model algorithms to reduce their computational complexity. However, generally reducing the complexity of the deep learning network results in performance degradation. Therefore, we must make a trade-off between local learning model accuracy and complexity.</p>
</div>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.3.1.1" class="ltx_text" style="font-size:90%;">TABLE IX</span>: </span><span id="S4.T9.4.2" class="ltx_text" style="font-size:90%;">Incentive mechanism for federated learning.</span></figcaption>
<table id="S4.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T9.1.2" class="ltx_tr">
<td id="S4.T9.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T9.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.2.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S4.T9.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T9.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.2.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.1.2.2.1.1.1" class="ltx_text ltx_font_bold">Incentive model</span></span>
</span>
</td>
<td id="S4.T9.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T9.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.2.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T9.1.2.3.1.1.1" class="ltx_text ltx_font_bold">Motivation</span></span>
</span>
</td>
<td id="S4.T9.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T9.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.2.4.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T9.1.2.4.1.1.1" class="ltx_text ltx_font_bold">Device utility/ bid</span></span>
</span>
</td>
<td id="S4.T9.1.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T9.1.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.2.5.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T9.1.2.5.1.1.1" class="ltx_text ltx_font_bold">Aggregation server utility</span></span>
</span>
</td>
</tr>
<tr id="S4.T9.1.1" class="ltx_tr">
<td id="S4.T9.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.1.2.1.1" class="ltx_p" style="width:71.1pt;">Pandey <span id="S4.T9.1.1.2.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite></span>
</span>
</td>
<td id="S4.T9.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.1.3.1.1" class="ltx_p" style="width:71.1pt;">Stackelberg game</span>
</span>
</td>
<td id="S4.T9.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.1.4.1.1" class="ltx_p" style="width:85.4pt;">To enable a high-quality global federated learning model with wireless communication efficiency.</span>
</span>
</td>
<td id="S4.T9.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.1.5.1.1" class="ltx_p" style="width:85.4pt;">Difference between reward
(i.e., $/accuracy level) and cost (i.e., communication and computation cost)</span>
</span>
</td>
<td id="S4.T9.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.1.1.1.1" class="ltx_p" style="width:99.6pt;">Concave function of <math id="S4.T9.1.1.1.1.1.m1.2" class="ltx_Math" alttext="\log(1/global~{}accuracy)" display="inline"><semantics id="S4.T9.1.1.1.1.1.m1.2a"><mrow id="S4.T9.1.1.1.1.1.m1.2.2.1" xref="S4.T9.1.1.1.1.1.m1.2.2.2.cmml"><mi id="S4.T9.1.1.1.1.1.m1.1.1" xref="S4.T9.1.1.1.1.1.m1.1.1.cmml">log</mi><mo id="S4.T9.1.1.1.1.1.m1.2.2.1a" xref="S4.T9.1.1.1.1.1.m1.2.2.2.cmml">⁡</mo><mrow id="S4.T9.1.1.1.1.1.m1.2.2.1.1" xref="S4.T9.1.1.1.1.1.m1.2.2.2.cmml"><mo stretchy="false" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.2" xref="S4.T9.1.1.1.1.1.m1.2.2.2.cmml">(</mo><mrow id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.cmml"><mrow id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.cmml"><mn id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.2" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.2.cmml">1</mn><mo id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.1" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.1.cmml">/</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.3" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.3.cmml">g</mi></mrow><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.3" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1a" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.4" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1b" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.5" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1c" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.6" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1d" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.7" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.7.cmml">l</mi><mo lspace="0.330em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1e" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.8" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1f" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.9" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1g" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.10" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.10.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1h" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.11" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.11.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1i" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.12" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.12.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1j" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.13" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.13.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1k" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.14" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.14.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1l" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.15" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.15.cmml">y</mi></mrow><mo stretchy="false" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.3" xref="S4.T9.1.1.1.1.1.m1.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.1.1.m1.2b"><apply id="S4.T9.1.1.1.1.1.m1.2.2.2.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1"><log id="S4.T9.1.1.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.1.1.m1.1.1"></log><apply id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1"><times id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.1"></times><apply id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2"><divide id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.1.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.1"></divide><cn type="integer" id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.2.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.2">1</cn><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.3.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.2.3">𝑔</ci></apply><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.3.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.3">𝑙</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.4.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.4">𝑜</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.5.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.5">𝑏</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.6.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.6">𝑎</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.7.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.7">𝑙</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.8.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.8">𝑎</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.9.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.9">𝑐</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.10.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.10">𝑐</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.11.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.11">𝑢</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.12.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.12">𝑟</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.13.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.13">𝑎</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.14.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.14">𝑐</ci><ci id="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.15.cmml" xref="S4.T9.1.1.1.1.1.m1.2.2.1.1.1.15">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.1.1.m1.2c">\log(1/global~{}accuracy)</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T9.1.3" class="ltx_tr">
<td id="S4.T9.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.3.1.1.1" class="ltx_p" style="width:71.1pt;">Le <span id="S4.T9.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite></span>
</span>
</td>
<td id="S4.T9.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.3.2.1.1" class="ltx_p" style="width:71.1pt;">Auction theory</span>
</span>
</td>
<td id="S4.T9.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.3.3.1.1" class="ltx_p" style="width:85.4pt;">To minimize social cost which denotes true cost of end-devices bids.</span>
</span>
</td>
<td id="S4.T9.1.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.3.4.1.1" class="ltx_p" style="width:85.4pt;">Difference between reward and cost.</span>
</span>
</td>
<td id="S4.T9.1.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.3.5.1.1" class="ltx_p" style="width:99.6pt;">Minimizes cost of bids.</span>
</span>
</td>
</tr>
<tr id="S4.T9.1.4" class="ltx_tr">
<td id="S4.T9.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T9.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.4.1.1.1" class="ltx_p" style="width:71.1pt;">Kang<span id="S4.T9.1.4.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span>
</td>
<td id="S4.T9.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T9.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.4.2.1.1" class="ltx_p" style="width:71.1pt;">Contract theory</span>
</span>
</td>
<td id="S4.T9.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T9.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.4.3.1.1" class="ltx_p" style="width:85.4pt;">To motivate participation of reliable end-devices in federated learning.</span>
</span>
</td>
<td id="S4.T9.1.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T9.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.4.4.1.1" class="ltx_p" style="width:85.4pt;">Difference between reward and energy consumption.</span>
</span>
</td>
<td id="S4.T9.1.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T9.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.1.4.5.1.1" class="ltx_p" style="width:99.6pt;">Maximize the profit that is given by the difference between total time for global iteration and reward given to end-devices.</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Incentive Mechanism</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In order to ensure large-scale adoption of federated learning, there is a need to devise novel incentive mechanisms. Since there are different ways to implement federated learning (e.g., centralized edge/cloud server-based vanilla federated learning and blockchain-based federated learning), there is a need to design different incentive mechanisms that can be appropriately used for the federated learning implementation of interest.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.2" class="ltx_p">For centralized edge/cloud server-based federated learning, the two players of the federated learning are devices and edge/cloud server, which interact with each other to train the global federated learning model. Numerous ways can be used to model such type of interaction between the devices and edge/cloud server. Several approaches (summary is given in Table <a href="#S4.T9" title="TABLE IX ‣ IV-C Local Learning Models ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IX</span></a>) have been proposed regarding the design of incentive mechanisms for federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib138" title="" class="ltx_ref">138</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>. These approaches can be classified into game theory, contract theory, and auctions theory. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>, a crowdsourcing framework was proposed for federated learning to enable a high-quality global model with wireless communication efficiency. A two-stage Stackelberg game-based incentive mechanism was adopted to jointly maximize the utility of the aggregation server and the end-devices. The utility of the aggregation server was modeled as a concave function of <math id="S4.SS4.p2.1.m1.2" class="ltx_Math" alttext="\log(1/global~{}model~{}accuracy)" display="inline"><semantics id="S4.SS4.p2.1.m1.2a"><mrow id="S4.SS4.p2.1.m1.2.2.1" xref="S4.SS4.p2.1.m1.2.2.2.cmml"><mi id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">log</mi><mo id="S4.SS4.p2.1.m1.2.2.1a" xref="S4.SS4.p2.1.m1.2.2.2.cmml">⁡</mo><mrow id="S4.SS4.p2.1.m1.2.2.1.1" xref="S4.SS4.p2.1.m1.2.2.2.cmml"><mo stretchy="false" id="S4.SS4.p2.1.m1.2.2.1.1.2" xref="S4.SS4.p2.1.m1.2.2.2.cmml">(</mo><mrow id="S4.SS4.p2.1.m1.2.2.1.1.1" xref="S4.SS4.p2.1.m1.2.2.1.1.1.cmml"><mrow id="S4.SS4.p2.1.m1.2.2.1.1.1.2" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.cmml"><mn id="S4.SS4.p2.1.m1.2.2.1.1.1.2.2" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml">1</mn><mo id="S4.SS4.p2.1.m1.2.2.1.1.1.2.1" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.1.cmml">/</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.2.3" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml">g</mi></mrow><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.3" xref="S4.SS4.p2.1.m1.2.2.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1a" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.4" xref="S4.SS4.p2.1.m1.2.2.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1b" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.5" xref="S4.SS4.p2.1.m1.2.2.1.1.1.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1c" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.6" xref="S4.SS4.p2.1.m1.2.2.1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1d" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.7" xref="S4.SS4.p2.1.m1.2.2.1.1.1.7.cmml">l</mi><mo lspace="0.330em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1e" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.8" xref="S4.SS4.p2.1.m1.2.2.1.1.1.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1f" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.9" xref="S4.SS4.p2.1.m1.2.2.1.1.1.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1g" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.10" xref="S4.SS4.p2.1.m1.2.2.1.1.1.10.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1h" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.11" xref="S4.SS4.p2.1.m1.2.2.1.1.1.11.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1i" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.12" xref="S4.SS4.p2.1.m1.2.2.1.1.1.12.cmml">l</mi><mo lspace="0.330em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1j" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.13" xref="S4.SS4.p2.1.m1.2.2.1.1.1.13.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1k" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.14" xref="S4.SS4.p2.1.m1.2.2.1.1.1.14.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1l" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.15" xref="S4.SS4.p2.1.m1.2.2.1.1.1.15.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1m" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.16" xref="S4.SS4.p2.1.m1.2.2.1.1.1.16.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1n" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.17" xref="S4.SS4.p2.1.m1.2.2.1.1.1.17.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1o" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.18" xref="S4.SS4.p2.1.m1.2.2.1.1.1.18.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1p" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.19" xref="S4.SS4.p2.1.m1.2.2.1.1.1.19.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.1.m1.2.2.1.1.1.1q" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml">​</mo><mi id="S4.SS4.p2.1.m1.2.2.1.1.1.20" xref="S4.SS4.p2.1.m1.2.2.1.1.1.20.cmml">y</mi></mrow><mo stretchy="false" id="S4.SS4.p2.1.m1.2.2.1.1.3" xref="S4.SS4.p2.1.m1.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.2b"><apply id="S4.SS4.p2.1.m1.2.2.2.cmml" xref="S4.SS4.p2.1.m1.2.2.1"><log id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"></log><apply id="S4.SS4.p2.1.m1.2.2.1.1.1.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1"><times id="S4.SS4.p2.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.1"></times><apply id="S4.SS4.p2.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2"><divide id="S4.SS4.p2.1.m1.2.2.1.1.1.2.1.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.1"></divide><cn type="integer" id="S4.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.2">1</cn><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.2.3">𝑔</ci></apply><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.3.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.3">𝑙</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.4.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.4">𝑜</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.5.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.5">𝑏</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.6.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.6">𝑎</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.7.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.7">𝑙</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.8.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.8">𝑚</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.9.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.9">𝑜</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.10.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.10">𝑑</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.11.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.11">𝑒</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.12.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.12">𝑙</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.13.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.13">𝑎</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.14.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.14">𝑐</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.15.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.15">𝑐</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.16.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.16">𝑢</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.17.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.17">𝑟</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.18.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.18">𝑎</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.19.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.19">𝑐</ci><ci id="S4.SS4.p2.1.m1.2.2.1.1.1.20.cmml" xref="S4.SS4.p2.1.m1.2.2.1.1.1.20">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.2c">\log(1/global~{}model~{}accuracy)</annotation></semantics></math>, whereas end-device utility was modeled as a difference between reward (i.e., <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="\$" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mo id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">$</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><csymbol cd="latexml" id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">currency-dollar</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">\$</annotation></semantics></math>/accuracy level) and cost (i.e., communication and computation cost). Le <span id="S4.SS4.p2.2.1" class="ltx_text ltx_font_italic">et al.</span> presented an auction-based incentive mechanism for federated learning over cellular networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. Every end-device submits a set of bids to the BS. The bid consists of claimed cost and resources (i.e., local accuracy level, CPU cycle frequency, transmission power, and sub-channel bundle). The authors formulated a social cost minimization problem representing the true cost of user bids. To deal with NP-hard social cost minimization problem, randomized auctions based mechanism was proposed. Next, the BS determines the set of all winner profiles. Finally, the winning end-devices participate in the federated learning process. On the other hand, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> proposed an incentive mechanism for reliable federated learning. The authors defined a reputation-based metric to determine the trustworthiness and reliability of end-devices participating in the federated learning process. Then, a reputation based end-device selection scheme using a multi-weight subjective model was proposed. Moreover, blockchain was considered for secure end-devices reputation management. Finally, they proposed an incentive mechanism based on contract theory to motivate end-devices participation in federated learning.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">On the other hand, blockchain-based federated learning consists of sets of devices and miners <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>, <a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>. First, the devices compute their local learning models and then send the learning model parameters to their associated miners. The miner verifies and exchanges the learning model parameters with other miners and run a consensus algorithm. Once the miners complete the consensus algorithm, a block consisting of verified local learning models is added to the blockchain. The end-device associated with the miners download the block containing the verified local learning models of different devices. Finally, the global federated learning model aggregation is performed at the end-devices. This process of federated learning offers robustness and security but suffers from additional overhead compared to the traditional federated learning approach. Designing an incentive algorithm for such kind of federated learning scheme involves end-devices and miners. The reward of the end-devices must be based on their dataset size and local learning model accuracy. The miners will provide the reward to the end-devices, whereas miners will receive their reward from the blockchain service providers responsible for federated learning model management.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Miners Classification for Federated Learning based on Blockchain</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Federated learning based on blockchain uses miners for secure and trustful exchange of learning model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>, <a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. The miners can be either static (i.e., BS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, mobile (i.e., autonomous cars) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>, and flying (unmanned aerial vehicles (UAV)) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>. There are two main challenges in using miners for blockchain-based federated learning, such as wireless for miners and blockchain consensus design for miners. Wireless for miners deals with the wireless communication design for efficient communication, whereas blockchain consensus for miners deals with the efficient consensus algorithm design. The primary purpose of miners is to enable a trustful exchange of local learning models as shown in Fig. <a href="#S4.F12" title="Figure 12 ‣ IV-E Miners Classification for Federated Learning based on Blockchain ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>. First of all, local learning models are computed for all devices and sent to their corresponding miners. The miners verify the trustfulness of the local learning model to avoid injection of wrong local learning models from a malicious user. Following cross verification, a block of a distributed ledger is generated. The block has two parts body and header. Body stores the local learning model updates and header contains control information, such as pointer to the previous block, output of the consensus algorithm, and block generation rate. Every miner has its block that stores local learning models of its associated devices. Next, every miner generates a hash value repeatedly until their hash value becomes less than the target value. After the miner succeeds in computing the hash value using proof of work (PoW), its block is considered as a candidate block which is transmitted to all other miners. All other miners that receive the newly generated block from the winning miner should stop computing their PoWs. It must be noted that the other miners may broadcast their candidate block after computing a hash value before receiving a candidate block from the other winning miner, and thus there will be two candidate blocks within a blockchain network. This will cause some of the miners to add this second candidate block, and thus will result in global federated learning model error. This event is called forking. After block propagation, the block is downloaded by all the devices and global aggregation is performed. Blockchain-based federated learning avoids the use of a centralized server, and thus offers robustness but at the cost of computational complexity associated with blockchain consensus algorithm. Additionally, more communication resources will be consumed compared to traditional federated learning. Other than these issues, it is necessary to tackle the issue of forking. One way can be to minimize the block generation rate and block transmission delay. Another possible solution can be sending of candidate block by a winning miner with a certain probability. This will reduce the change of forking event, but at the cost of block generation delay. Additionally, setting this probability will be scenario dependent, such as the number of miners and consensus algorithm used. Therefore, we must take proper attention to the design of blockchain-based federated learning.</p>
</div>
<figure id="S4.F12" class="ltx_figure"><img src="/html/2009.13012/assets/x17.png" id="S4.F12.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="242" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S4.F12.3.2" class="ltx_text" style="font-size:90%;">Blockchain-based federated learning: (a) sequence diagram, and (b) forking effect <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>.</span></figcaption>
</figure>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T10.2.1.1" class="ltx_text" style="font-size:90%;">TABLE X</span>: </span><span id="S4.T10.3.2" class="ltx_text" style="font-size:90%;">Comparison of miners used for blockchain-based federated learning.</span></figcaption>
<table id="S4.T10.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T10.4.1" class="ltx_tr">
<td id="S4.T10.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T10.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.1.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T10.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Miner type</span></span>
</span>
</td>
<td id="S4.T10.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T10.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.1.2.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T10.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Available computational power</span></span>
</span>
</td>
<td id="S4.T10.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T10.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T10.4.1.3.1.1.1" class="ltx_text ltx_font_bold">Forking probability</span></span>
</span>
</td>
<td id="S4.T10.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T10.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.1.4.1.1" class="ltx_p" style="width:42.7pt;"><span id="S4.T10.4.1.4.1.1.1" class="ltx_text ltx_font_bold">Block propagation delay</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.4.2" class="ltx_tr">
<td id="S4.T10.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.2.1.1.1" class="ltx_p" style="width:62.6pt;">Static miner (edge server-based BS)</span>
</span>
</td>
<td id="S4.T10.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.2.2.1.1" class="ltx_p" style="width:42.7pt;">Highest</span>
</span>
</td>
<td id="S4.T10.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.2.3.1.1" class="ltx_p" style="width:42.7pt;">Lowest</span>
</span>
</td>
<td id="S4.T10.4.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.2.4.1.1" class="ltx_p" style="width:42.7pt;">Lowest</span>
</span>
</td>
</tr>
<tr id="S4.T10.4.3" class="ltx_tr">
<td id="S4.T10.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.3.1.1.1" class="ltx_p" style="width:62.6pt;">Flying miner (UAVs)</span>
</span>
</td>
<td id="S4.T10.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.3.2.1.1" class="ltx_p" style="width:42.7pt;">Low</span>
</span>
</td>
<td id="S4.T10.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.3.3.1.1" class="ltx_p" style="width:42.7pt;">High</span>
</span>
</td>
<td id="S4.T10.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.3.4.1.1" class="ltx_p" style="width:42.7pt;">Highest</span>
</span>
</td>
</tr>
<tr id="S4.T10.4.4" class="ltx_tr">
<td id="S4.T10.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T10.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.4.1.1.1" class="ltx_p" style="width:62.6pt;">Mobile miner (autonomous car)</span>
</span>
</td>
<td id="S4.T10.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T10.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.4.2.1.1" class="ltx_p" style="width:42.7pt;">High</span>
</span>
</td>
<td id="S4.T10.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T10.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.4.3.1.1" class="ltx_p" style="width:42.7pt;">Low</span>
</span>
</td>
<td id="S4.T10.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T10.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.4.4.4.1.1" class="ltx_p" style="width:42.7pt;">Low</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">For BS-based miners, the association of end-devices has lower complexity than mobile and flying miners. Moreover, BS-based miners can communicate with each other using high-speed optical fiber backhaul links. Using fast back-haul links for transferring blocks among miners as discussed earlier will minimize the forking effect. For flying miners based on UAVs, the forking effect will be more prominent due to the large propagation delay between the miners. Furthermore, the mobility of the flying miners will add further complications to the design due to the fact the miner might get out of the communication range of the other miners. There is a need to optimize radio access network resources for BS-based miners to minimize the blockchain-based federated learning convergence time. On the other hand, mobile miners require more careful design consideration than static BS-based miners. Mobile miners can communicate with each other via fast backhaul or directly using wireless links. Comparison of various miners that can be used for blockchain-based federated learning are given in Table <a href="#S4.T10" title="TABLE X ‣ IV-E Miners Classification for Federated Learning based on Blockchain ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">X</span></a>. For mobile miners’ communication via a wireless channel, there is a need to carefully design resource allocation schemes for carrying out the transfer of learning model updates between miners. Similar to mobile miners, the UAV-based flying miners require a careful design for federated learning. For UAV-based miners, we need to address two kinds of resource allocation problems such as (a) communication of end-devices with UAVs and (b) communication between UAVs. Furthermore, the three-dimensional motion of UAVs imposes more design complexity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>, <a href="#bib.bib144" title="" class="ltx_ref">144</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>, <a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>.</p>
</div>
<figure id="S4.F13" class="ltx_figure"><img src="/html/2009.13012/assets/x18.png" id="S4.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="545" height="393" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F13.2.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="S4.F13.3.2" class="ltx_text" style="font-size:90%;">Edge collaboration categories.</span></figcaption>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Edge Collaboration</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">Training of a cloud-based federated learning model for a massive number of IoT devices results in significant overhead of communication resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. To cope with this issue, one can consider collaboration between edge servers and a cloud. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, a client-edge-cloud hierarchical federated learning framework has been proposed. The framework resolves high communication resources consumption issue associated with the training of cloud-based federated learning models for a massive number of users via collaboration between edge servers and a cloud server. The client-edge-cloud hierarchical federated learning framework performs two levels of aggregations at edge servers and a cloud. Access to the edge servers is easier and requires fewer communication resources than a remote cloud. Therefore, performing edge based-aggregations and then cloud-based aggregation will offer efficient usage of communication resources than the federated learning scheme based on communication between end-devices and cloud. Edge collaboration can be (a) horizontal, (b) vertical, and (c) hybrid (as shown in Fig. <a href="#S4.F13" title="Figure 13 ‣ IV-E Miners Classification for Federated Learning based on Blockchain ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>), depending on the nature of application and available communication resources.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">Although federated learning based on collaboration between edge servers and edge-cloud servers can improve the performance in terms of accuracy, it will face weight divergence issues. For collaboration among edge servers and a cloud, there will be two kinds of weights divergences, such as (a) between end-devices and edge server and (b) between edge servers and cloud. These weight divergences depend on the federated learning scheme used and data heterogeneity. For FedAvg using non-IID data and a fixed product of local iterations and edge aggregations prior to global aggregation, increasing the number of edge aggregations will improve performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>. According <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>, the reason for this weights divergence is more for a higher number of local iterations compared to edge aggregations for a fixed product of local iterations and edge aggregations prior to cloud aggregation. It must be noted here that we should perform extensive analysis for federated learning based on hybrid collaboration as shown in Fig. <a href="#S4.F13" title="Figure 13 ‣ IV-E Miners Classification for Federated Learning based on Blockchain ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>. Additionally, using a federated optimization scheme different than FedAvg might result in different observations than those of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite>. Therefore, there is a need to properly adjust the federated learning parameters and select an optimization scheme for federated learning based on collaboration.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS7.4.1.1" class="ltx_text">IV-G</span> </span><span id="S4.SS7.5.2" class="ltx_text ltx_font_italic">Cloud Server Design</span>
</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">To design federated learning based on the cloud, there is a need to properly plan the design of cloud-based aggregation servers. The cloud-based server will coordinate with devices ranging from hundreds to millions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>. Additionally, the size of collected updates ranges from kilobytes to tens of megabytes. Therefore, to successfully carry out the federated learning process in an economical way, there is a need to optimally use cloud resources. To truly realize cloud as a dynamic micro data center, there is a need to evolve both hardware and software. Other than hardware evolution, we must effectively isolate functionality from the hardware. Micro-services concept can be used in such a type of isolation. The key requirement of micro-services is a similar environment at all run-time locations. To run micro-services, there can be two ways, i.e., containers-based design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> and virtual machine-based design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite>. Containers can be preferably used compared to virtual machines due to their low overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Therefore, we can use containerization and hardware evolution for economical cloud server design to enable federated learning for millions of devices.</p>
</div>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS8.4.1.1" class="ltx_text">IV-H</span> </span><span id="S4.SS8.5.2" class="ltx_text ltx_font_italic">Federated Optimization Schemes</span>
</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">The process of federated learning consists of local model computation by end-devices, which are then sent to the aggregation server. Finally, after global aggregation, the global model parameters are sent back to end-devices. Such a process continues in an iterative fashion until convergence. The goal of federated learning to minimize global loss function that is application dependent. To minimize the global loss function, we need federated optimization schemes. Mainly there are two types of federated optimization schemes depending on the number of tasks: single task federated optimization and multi-task federated optimization. In single task federated learning, the global federated learning model is trained only for a single task. Several works considered the training of the global federated learning model for a single task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. On the other hand, multi-task federated learning involves the training of multiple models for different tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>.</p>
</div>
<div id="S4.SS8.p2" class="ltx_para">
<p id="S4.SS8.p2.5" class="ltx_p">FedAvg and FedProx were proposed for training of a single-task federated learning models. FedAvg was based on simple averaging of local learning models at the aggregation server. However, there exist statistical and system heterogeneity among the end-devices. Therefore, simple averaging in FedAvg might not work well. To cope with this challenge, FedProx was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. The difference in computation steps between FedProx and FedAvg lies in the local device objective function. FedProx uses an additional proximal term for minimizing the impact of heterogeneity of end-device on the global federated learning model. Although FedProx was developed to account for statistical and system heterogeneity, it faces some practical implementations challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. The weighted proximal term in FedProx is difficult to choose for various applications. Furthermore, the answer to the question, that can a FedProx provably improve the convergence rate is not clear <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. A scheme <math id="S4.SS8.p2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS8.p2.1.m1.1a"><mi id="S4.SS8.p2.1.m1.1.1" xref="S4.SS8.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p2.1.m1.1b"><ci id="S4.SS8.p2.1.m1.1.1.cmml" xref="S4.SS8.p2.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p2.1.m1.1c">q</annotation></semantics></math>-FedAvg was proposed to cope with fairness issues due to system heterogeneity (i.e., local model accuracy and wireless resources) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. The <math id="S4.SS8.p2.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS8.p2.2.m2.1a"><mi id="S4.SS8.p2.2.m2.1.1" xref="S4.SS8.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p2.2.m2.1b"><ci id="S4.SS8.p2.2.m2.1.1.cmml" xref="S4.SS8.p2.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p2.2.m2.1c">q</annotation></semantics></math>-FedAvg modifies the objective function of FedAvg by assigning the end-devices with poor performance higher weights than better-performing end-devices. In <math id="S4.SS8.p2.3.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS8.p2.3.m3.1a"><mi id="S4.SS8.p2.3.m3.1.1" xref="S4.SS8.p2.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p2.3.m3.1b"><ci id="S4.SS8.p2.3.m3.1.1.cmml" xref="S4.SS8.p2.3.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p2.3.m3.1c">q</annotation></semantics></math>-FedAvg, the devices with higher values of local loss functions are given more importance using large values of <math id="S4.SS8.p2.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS8.p2.4.m4.1a"><mi id="S4.SS8.p2.4.m4.1.1" xref="S4.SS8.p2.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p2.4.m4.1b"><ci id="S4.SS8.p2.4.m4.1.1.cmml" xref="S4.SS8.p2.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p2.4.m4.1c">q</annotation></semantics></math>. Specifically, the amount of fairness is determined by the values of <math id="S4.SS8.p2.5.m5.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S4.SS8.p2.5.m5.1a"><mi id="S4.SS8.p2.5.m5.1.1" xref="S4.SS8.p2.5.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p2.5.m5.1b"><ci id="S4.SS8.p2.5.m5.1.1.cmml" xref="S4.SS8.p2.5.m5.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p2.5.m5.1c">q</annotation></semantics></math>. In another work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>, a scheme offering a trade-off between the local model update and global model aggregation with the aim of reducing the loss function under resource budget constraints was proposed. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>, all the schemes considered a single task global federated learning model. To offer multi-task learning, federated multi-task learning (FML) was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>. Additionally, the FML scheme considered joint optimization of computational and communication resources while fulfilling the fault tolerance constraint.</p>
</div>
<div id="S4.SS8.p3" class="ltx_para">
<p id="S4.SS8.p3.1" class="ltx_p">The iterative exchange of learning model parameters in the federated optimization schemes via wireless channels requires careful design. It will be necessary to develop a novel federated optimization algorithm that considers significantly the effect of packet errors introduced due to channel uncertainties on the global federated learning model. We must define some threshold regarding the packet error rate to determine whether the devices local learning model parameters should be considered or not in the global federated learning model computation. The devices the higher packet error rates must not be considered in training of the global federated learning model computation. One of possible way to improve the packet error rate is the use of channel coding schemes (e.g., turbo codes, convolutional codes, and linear block codes). Different channel coding schemes have different performance and overhead with complexity. Generally, turbo codes outperforms linear block codes but at the cost of communication overhead. Another feasible way can be the use of URLLC codes, such as BCH codes. Therefore, we must make a trade-off while selecting a channel coding scheme for federated learning.</p>
</div>
<figure id="S4.F14" class="ltx_figure"><img src="/html/2009.13012/assets/x19.png" id="S4.F14.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="242" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="S4.F14.3.2" class="ltx_text" style="font-size:90%;">Collaborative federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</span></figcaption>
</figure>
<figure id="S4.F15" class="ltx_figure"><img src="/html/2009.13012/assets/x20.png" id="S4.F15.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F15.2.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="S4.F15.3.2" class="ltx_text" style="font-size:90%;">Intelligent transportation use case of dispersed federated learning.</span></figcaption>
</figure>
</section>
<section id="S4.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS9.4.1.1" class="ltx_text">IV-I</span> </span><span id="S4.SS9.5.2" class="ltx_text ltx_font_italic">Operation Modes Based on Global Aggregation Fashion</span>
</h3>

<div id="S4.SS9.p1" class="ltx_para">
<p id="S4.SS9.p1.1" class="ltx_p">We can categorize federated learning into five categories depending on the fashion of global aggregation as centralized aggregation-enabled federated learning, distributed aggregation-enabled federated learning, collaborative federated learning, hierarchical federated learning, and dispersed federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. In centralized federated learning, global aggregation takes place only at the centralized edge/cloud server, whereas decentralized aggregation-enabled federated learning avoids the use of a centralized aggregation by performing aggregations at distributed servers. However, hierarchical federated learning involves aggregation of local learning models (e.g., at edge servers) prior to global aggregation at the cloud. In distributed aggregation-enabled federated learning, end-devices are associated with multiple aggregation servers at BSs. The BSs then share the received local learning models from their associated devices with other devices. Finally, aggregation takes place at BSs in a distributed manner. This mode of federated learning can offer robustness but at the cost of additional communication resources associated with sharing of local learning model updates between BSs. Moreover, it will add delay due to sharing of local learning models between BSs. On the other hand, hierarchical federated learning combines both distributed and centralized aggregation-enabled federated learning. Several aggregations of local learning models take place at edge, which is followed by sending the edge aggregated models to the cloud for global aggregation. Hierarchical federated learning offers advantage of using low cost communication for connecting end-devices with the edge servers. At the network edge, one can use easily reuse the already occupied frequency bands by other cellular users while protecting them by keep interference level below the maximum allowed limit.</p>
</div>
<div id="S4.SS9.p2" class="ltx_para">
<p id="S4.SS9.p2.1" class="ltx_p">For scenarios that have massive number of IoT devices and constrained communication resource, it will be difficult for devices to participate in the federated learning process for the aforementioned federated learning schemes. To address this challenge, one can use collaborative federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. The collaborative federated learning was introduced mainly for ensuring participation of devices that are unable to access the centralized BS due to communication resources constraints as shown in Fig. <a href="#S4.F14" title="Figure 14 ‣ IV-H Federated Optimization Schemes ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>. In collaborative federated learning, the devices with insufficient communication resources send their model to other nearby devices with sufficient communication resources. The receiving devices perform aggregation of other devices’ local learning models, with their own models and send the aggregated model parameters to the centralized BS. Some of the devices send their own local learning models directly to the centralized BS. The centralized BS finally performs global aggregation and sends back the global model parameters to the end-devices. Although collaborative federated learning offers benefits of enabling more devices to participate in the federated learning process, there is a need for successful communication between devices for sharing the learning model updates. The primary challenge in enabling collaborative federated learning lies in the network formation that will define the communication among devices for local aggregations as shown in Fig. <a href="#S4.F14" title="Figure 14 ‣ IV-H Federated Optimization Schemes ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>. We can use two types of operation for collaborative federated learning, such as synchronous and asynchronous. In a synchronous fashion, the aggregation server must receive a learning model (i.e., local learning models and locally aggregated models) within a maximum allowed time prior to aggregation. To do so, resource-constrained devices must send their local learning models to nearby devices according to the network formation topology within the allowed time. Next, after local aggregation at receiving devices, the locally aggregated models are sent to the centralized aggregation server. It must be noted that the time from local learning model computation to global aggregation in synchronous collaborative federated learning must be less than or equal to the maximum threshold. On the other hand, asynchronous collaborative federated learning has more freedom of computing locally aggregated models. Here, the resource-constrained devices can send their local learning models to nearby devices where local aggregation takes place. If the locally aggregated models are received by the centralized aggregation server later than the some fixed time, then it will consider the local aggregation model in the next round rather than discarding that happens in synchronous collaborative federated learning. Although asynchronous collaborative federated learning allows freedom of allowing more devices in the learning process, it will offer design challenges. Performance degradation in asynchronous collaborative federated learning might occur due to less number of participating end-devices in one global round. Additionally, asynchronous collaborative federated learning might not converge fast for extreme non-IID conditions with most of the end-devices having a distinct class of data. To resolve this challenge, one can use synchronous collaborative federated learning by using fewer local iterations to reduce the local model training time so as to reduce the overall time consumed (i.e., local training and local aggregations along with transmission delay) before the centralized server aggregation.</p>
</div>
<figure id="S4.T11" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T11.2.1.1" class="ltx_text" style="font-size:90%;">TABLE XI</span>: </span><span id="S4.T11.3.2" class="ltx_text" style="font-size:90%;">Comparison of federated learning schemes based different aggregation fashions.</span></figcaption>
<table id="S4.T11.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T11.4.1" class="ltx_tr">
<td id="S4.T11.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T11.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.1.1.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Federated learning scheme</span></span>
</span>
</td>
<td id="S4.T11.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T11.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.1.2.1.1" class="ltx_p" style="width:76.8pt;"><span id="S4.T11.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Robustness</span></span>
</span>
</td>
<td id="S4.T11.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T11.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.1.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T11.4.1.3.1.1.1" class="ltx_text ltx_font_bold">Communication resources consumption</span></span>
</span>
</td>
<td id="S4.T11.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T11.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.1.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T11.4.1.4.1.1.1" class="ltx_text ltx_font_bold">Implementation complexity</span></span>
</span>
</td>
<td id="S4.T11.4.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T11.4.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.1.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T11.4.1.5.1.1.1" class="ltx_text ltx_font_bold">Global model computation latency</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.4.2" class="ltx_tr">
<td id="S4.T11.4.2.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S4.T11.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.2.2.1.1" class="ltx_p" style="width:76.8pt;">Robustness deals with the successful operation of federated learning scheme in case of failure of aggregation server due to physical damage or security attack.</span>
</span>
</td>
<td id="S4.T11.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.2.3.1.1" class="ltx_p" style="width:71.1pt;">This parameter refers to the use of communication for federated learning global model computation.</span>
</span>
</td>
<td id="S4.T11.4.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.2.4.1.1" class="ltx_p" style="width:71.1pt;">This parameter deals with the implementation complexity of the algorithm used for computing a global federated learning model.</span>
</span>
</td>
<td id="S4.T11.4.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.2.5.1.1" class="ltx_p" style="width:71.1pt;">Global model computation latency is the overall latency in computing global federated learning model for one global round.</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.3" class="ltx_tr">
<td id="S4.T11.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.3.1.1.1" class="ltx_p" style="width:99.6pt;">Centralized aggregation-based federated learning</span>
</span>
</td>
<td id="S4.T11.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.3.2.1.1" class="ltx_p" style="width:76.8pt;">Lowest</span>
</span>
</td>
<td id="S4.T11.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.3.3.1.1" class="ltx_p" style="width:71.1pt;">Low (for edge-based federated learning)</span>
</span>
</td>
<td id="S4.T11.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.3.4.1.1" class="ltx_p" style="width:71.1pt;">Lowest</span>
</span>
</td>
<td id="S4.T11.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.3.5.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.4" class="ltx_tr">
<td id="S4.T11.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.4.1.1.1" class="ltx_p" style="width:99.6pt;">Distributed aggregation-based federated learning</span>
</span>
</td>
<td id="S4.T11.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.4.2.1.1" class="ltx_p" style="width:76.8pt;">High</span>
</span>
</td>
<td id="S4.T11.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.4.3.1.1" class="ltx_p" style="width:71.1pt;">Highest (for blockchain-based federated learning using wireless miners)</span>
</span>
</td>
<td id="S4.T11.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.4.4.1.1" class="ltx_p" style="width:71.1pt;">Highest (for blockchain-based federated learning using wireless miners)</span>
</span>
</td>
<td id="S4.T11.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.4.5.1.1" class="ltx_p" style="width:71.1pt;">High</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.5" class="ltx_tr">
<td id="S4.T11.4.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.5.1.1.1" class="ltx_p" style="width:99.6pt;">Collaborative federated learning</span>
</span>
</td>
<td id="S4.T11.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.5.2.1.1" class="ltx_p" style="width:76.8pt;">Low</span>
</span>
</td>
<td id="S4.T11.4.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.5.3.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
<td id="S4.T11.4.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.5.4.1.1" class="ltx_p" style="width:71.1pt;">High (for mobile nodes)</span>
</span>
</td>
<td id="S4.T11.4.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.5.5.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.6" class="ltx_tr">
<td id="S4.T11.4.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.6.1.1.1" class="ltx_p" style="width:99.6pt;">Hierarchical federated learning</span>
</span>
</td>
<td id="S4.T11.4.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.6.2.1.1" class="ltx_p" style="width:76.8pt;">Low</span>
</span>
</td>
<td id="S4.T11.4.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.6.3.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
<td id="S4.T11.4.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.6.4.1.1" class="ltx_p" style="width:71.1pt;">Low (edge and cloud based)</span>
</span>
</td>
<td id="S4.T11.4.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.6.5.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.7" class="ltx_tr">
<td id="S4.T11.4.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.7.1.1.1" class="ltx_p" style="width:99.6pt;">Dispersed federated learning</span>
</span>
</td>
<td id="S4.T11.4.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.7.2.1.1" class="ltx_p" style="width:76.8pt;">High</span>
</span>
</td>
<td id="S4.T11.4.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.7.3.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
<td id="S4.T11.4.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.7.4.1.1" class="ltx_p" style="width:71.1pt;">Low (edge servers based)</span>
</span>
</td>
<td id="S4.T11.4.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.4.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.4.7.5.1.1" class="ltx_p" style="width:71.1pt;">Low</span>
</span>
</td>
</tr>
<tr id="S4.T11.4.8" class="ltx_tr">
<td id="S4.T11.4.8.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="5">* One sub-global and one-edge aggregation are considered for dispersed federated learning and hierarchical federated learning</td>
</tr>
<tr id="S4.T11.4.9" class="ltx_tr">
<td id="S4.T11.4.9.1" class="ltx_td ltx_align_center ltx_align_top" colspan="5">used for comparison, respectively.</td>
</tr>
</table>
</figure>
<div id="S4.SS9.p3" class="ltx_para">
<p id="S4.SS9.p3.1" class="ltx_p">The aforementioned centralized aggregation-enabled federated learning, hierarchical, and collaborative federated learning faces a robustness challenge. Additionally, these schemes will suffer from privacy leakage due to the end-devices sensitive information inferring capability of a malicious aggregation server/ end-devices. One can enable differential privacy via addition of artificial noise to the learning model parameters prior to sending them to the aggregation server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. However, simultaneously achieving convergence time and high privacy level for federated learning is generally not possible. We must make a tradeoff between the federated learning convergence time and privacy level. Additionally, enabling federated learning with privacy preservation schemes adds extra complexity, which might not be desirable. To cope with the aforementioned issues of federated learning over IoT networks, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, the novel concept of <em id="S4.SS9.p3.1.1" class="ltx_emph ltx_font_italic">dispersed federated learning</em> was proposed. In dispersed federated learning, sub-global federated learning models are computed within different groups, in a fashion similar to that in federated learning. Then, the sub-global models are transferred between different groups. Next, sub-global models are aggregated to yield the global federated learning model. This process of dispersed federated learning takes place in an iterative manner until desirable global federated learning accuracy is achieved. For dispersed federated learning, we can use reuse communication resources within groups used for sub-global model computation to enable communication efficient operation. Additionally, there is a need to efficiently allocate resources for further performance enhancement. In contrast to federated learning global aggregation server, a global aggregation server used to aggregate sub-global models can not easily infer the end-devices private information, and thus offer enhanced privacy preservation. However, within group used for sub-global computation, the sub-global aggregation server can infer the end-devices private information. To add more privacy preservation to dispersed federated learning, there is a need to develop a novel privacy preservation schemes within groups of dispersed federated learning.</p>
</div>
<div id="S4.SS9.p4" class="ltx_para">
<p id="S4.SS9.p4.1" class="ltx_p">Dispersed federated learning can be easily adopted in many practical IoT applications. An intelligent transportation system suffers from frequent addition of data updates which motivated use of federated learning in contrast to centralized machine learning. For instance, according to statistics, autonomous driving cars generate <math id="S4.SS9.p4.1.m1.2" class="ltx_Math" alttext="4,000" display="inline"><semantics id="S4.SS9.p4.1.m1.2a"><mrow id="S4.SS9.p4.1.m1.2.3.2" xref="S4.SS9.p4.1.m1.2.3.1.cmml"><mn id="S4.SS9.p4.1.m1.1.1" xref="S4.SS9.p4.1.m1.1.1.cmml">4</mn><mo id="S4.SS9.p4.1.m1.2.3.2.1" xref="S4.SS9.p4.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS9.p4.1.m1.2.2" xref="S4.SS9.p4.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS9.p4.1.m1.2b"><list id="S4.SS9.p4.1.m1.2.3.1.cmml" xref="S4.SS9.p4.1.m1.2.3.2"><cn type="integer" id="S4.SS9.p4.1.m1.1.1.cmml" xref="S4.SS9.p4.1.m1.1.1">4</cn><cn type="integer" id="S4.SS9.p4.1.m1.2.2.cmml" xref="S4.SS9.p4.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS9.p4.1.m1.2c">4,000</annotation></semantics></math> gigaoctet everyday <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Therefore, transferring the whole data for training is not a feasible solution due to high communication overhead. Instead, we can use federated learning that is based on sending of only learning model updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>. However, autonomous driving cars suffer from high mobility which causes frequent handoffs. An IoT-based smart device inside an autonomous driving car might not be able to maintain seamless connectivity with the RSU during the training process for federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>. To tackle this issue, we can use a dispersed federated learning for autonomous driving cars. Fig. <a href="#S4.F15" title="Figure 15 ‣ IV-H Federated Optimization Schemes ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> shows an overview with a sequence diagram for a smart transportation use case. First of all, a sub-global model is computed within every autonomous car in an iterative manner similar to traditional federated learning model computation. The set of devices within autonomous driving car exchange their local learning modes with the edge computing-based access point. After a particular number of sub-global iterations, the sub-global model updates are sent to the associated RSU by every autonomous driving car. The next step is sharing of the sub-global model updates between different RSUs. The transfer of sub-global model updates is possible using (a) blockchain-based transfer, (b) direct transfer, and (c) light-weight authentication-based transfer. A blockchain-based transfer provides secure transfer and trustful verification of sub-global model updates. However, it suffers from inherent disadvantage of high latency associated with consensus algorithm. The direct transfer of sub-global model updates between different RSUs might suffer from false data injection, and thus prone to error due to malicious attacks. To cope with the aforementioned issues of false data injection and high-latency, we can use light-weight authentication-based scheme for secure transfer of sub-global model updates.</p>
</div>
</section>
<section id="S4.SS10" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS10.4.1.1" class="ltx_text">IV-J</span> </span><span id="S4.SS10.5.2" class="ltx_text ltx_font_italic">End-Device Design for Federated Learning</span>
</h3>

<div id="S4.SS10.p1" class="ltx_para">
<p id="S4.SS10.p1.1" class="ltx_p">On-device learning is the key essence of federated learning. Enabling end-devices with local machine learning requires careful design requirements. Every device is characterized by a fixed maximum computational power (CPU-cycles per) and limited backup power. For fixed dataset points, to minimize local learning model computation time, there is a need to run the device at high CPU-cycles/sec. However, device power consumption increases with an increase in operating frequency. Therefore, there is a need to trade-off between the end-devices operating frequencies and power consumption. The key metrics generally considered for performance evaluation of embedded machine learning are cost, throughput/latency, energy consumption, and learning accuracy. For a fixed dataset, the performance of end-devices involved in federated learning depends on both hardware design and software design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. On the other hand, for a fixed hardware and software design, the performance matrices are strongly dependent on the used dataset and application.</p>
</div>
<div id="S4.SS10.p2" class="ltx_para">
<p id="S4.SS10.p2.1" class="ltx_p">Various datasets and applications offer a variety of complexities to the embedded machine learning design. For instance, MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> dataset used for image classification task has lower complexity than GoogLeNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite> dataset that is used for classification of <math id="S4.SS10.p2.1.m1.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="S4.SS10.p2.1.m1.1a"><mn id="S4.SS10.p2.1.m1.1.1" xref="S4.SS10.p2.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS10.p2.1.m1.1b"><cn type="integer" id="S4.SS10.p2.1.m1.1.1.cmml" xref="S4.SS10.p2.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS10.p2.1.m1.1c">1000</annotation></semantics></math> image classes. Therefore, there is a need for efficient hardware design with programmability for end-devices to handle various applications offering different complexities. The programmable nature enables the use of generic hardware for different models. The requirement of programmability and high dimensionality causes an increase in data movement and computation power consumption due to more generated data, respectively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>. The programmability deals with storage and reading the weights, which results in significant energy consumption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>. Application-specific manycore processors are attractive candidates to enable different designs while fulfilling area, temperature, and energy constraints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>, <a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite>. However, various challenges exist in the implementation of these systems. First of all, fine-tuning is required for implementing effective run-time resource managers. Second, the use case significantly modifies the design objectives and deployment platform. Third, the evaluation of these designs is expensive and slow. Machine learning can be used to provide highly optimized design. Kim <span id="S4.SS10.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>, proposed machine learning to offer computationally efficient hardware design optimization for manycore systems.</p>
</div>
<div id="S4.SS10.p3" class="ltx_para">
<p id="S4.SS10.p3.1" class="ltx_p">For fixed hardware design, we can search different neural architectures for optimal out of available ones. NAS allows us to find the optimal architecture out of many available architectures for a particular dataset and application <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>. NAS can be considered to be a subfield of automated machine learning that deals with the complete process from dataset to its preferable machine learning models without knowing expert-level knowledge of machine learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>. An overview of a NAS is given in Fig. <a href="#S4.F16" title="Figure 16 ‣ IV-J End-Device Design for Federated Learning ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>a <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite>. Several possible neural architectures can be chain-structured, multi-branch networks, and cell search space, are shown in Fig. <a href="#S4.F16" title="Figure 16 ‣ IV-J End-Device Design for Federated Learning ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>b. The chain-structured neural networks consist of a sequence of layers with the first layer as input and last layer as output. Each layer receives an input from the preceding layer. In such a type of neural search space, we can adjust the number of layers, operation at each layer (i.e., convolution, depth-wise separable convolutions, or pooling), and hyperparameters (i.e., number of filters and kernel size and strides for a convolutional layer). The hyperparameters are dependent on operation layer, and thus this search space is conditional. On the other hand, multi-branch networks have nodes that can take their inputs as function of previous layers’ output as shown in Fig. <a href="#S4.F16" title="Figure 16 ‣ IV-J End-Device Design for Federated Learning ‣ IV Taxonomy of Federated Learning for IoT ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>b. The multi-branch networks has more degree of freedom than chain-structured neural networks. To provide more freedom of design, we can use the cell search space approach that involves searching in cells.</p>
</div>
<figure id="S4.F16" class="ltx_figure"><img src="/html/2009.13012/assets/x21.png" id="S4.F16.g1" class="ltx_graphics ltx_centering ltx_img_square" width="242" height="272" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F16.2.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="S4.F16.3.2" class="ltx_text" style="font-size:90%;">Neural architecture search: (a) Overview, and (b) Search spaces <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S4.SS11" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS11.4.1.1" class="ltx_text">IV-K</span> </span><span id="S4.SS11.5.2" class="ltx_text ltx_font_italic">Lessons Learned and Recommendations</span>
</h3>

<div id="S4.SS11.p1" class="ltx_para">
<p id="S4.SS11.p1.1" class="ltx_p">We have provided a taxonomy for federated learning towards enabling IoT-based smart applications. Some of the lessons and future enhancements learned are as follows.</p>
</div>
<div id="S4.SS11.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">It is necessary to adaptively adjust local iterations and global iterations strictly depending on the nature of the application. The end-device in an IoT network with high mobility might not have seamless connectivity with the aggregation server all the time. In these scenarios, it is recommended to consider a high number of local iterations. For a fixed global federated learning model accuracy, an increase in the number of local iterations will require less global iterations. Therefore, a higher number of local iterations with few global iterations are desirable in high mobility networks. A practical example such networks is vehicular networks that have high mobility vehicles.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">A massive number of IoT nodes show a significant amount of heterogeneity in terms of local dataset sizes and distributions, available backup power, computation resource, and communication resources. All of these factors significantly affect the performance of federated learning algorithms (i.e., FedAvg, FedProx, etc.). Therefore, to truly benefit from the deployment of federated learning in IoT networks, it is indispensable to design federated learning algorithms that consider these parameters. For instance, some of the end-devices might have poor performance due to limited computation power, noisy dataset, or limited communication resources. Such a type of end-device will have less influence on the global model than the device with better performance. Coping with these kind of issues due to the heterogeneity of devices, we must propose new federated learning algorithms.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Considering the aforementioned software-aware design and hardware design schemes, it is necessary to consider hardware-software co-design for end-devices involved in federated learning. The hardware-software co-design allows the concurrent design of both hardware and software. Numerous ways that can be used for hardware-software co-design are high-level synthesis, co-verification-based embedded systems, and virtual prototyping. The virtual prototyping-based design leverages computer-aided engineering, computer-aided design, and computing automated design, to validate the design prior to implementation. A high-level synthesis design enables automated digital hardware using an algorithmic description of the desired system. Multiplexer and wired signal delays are prominent challenges in high-level synthesis-based design. In co-verification-based design, embedded systems are designed using testing and debugging of both hardware and software at the same time. Such a design offers better performance.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">A malicious end-device can send a learning model updates to an aggregation server which can result in prolonging the federated learning convergence time. Therefore, one can propose novel federated learning frameworks that enable trust verification of end-device before using its local learning model updates updates. One way is through blockchain-based authentication schemes. Another way is through light-weight authentication schemes.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">As federated learning involves iterative exchange of learning model updates between the end-devices and aggregation, efficient communication resources allocation schemes will be required. The two kinds of communication resources used in federated learning are core network and radio access network. For optical fiber-based core networks, there are enough communication resources. On the other hand, the radio access network has communication resources constraints. Therefore, wireless resources optimization problem will need to be solved for federated learning. Depending on the nature of the formulated problem, we can use various approaches. These approaches include heuristic approaches, matching theory-based schemes, and game theory-based schemes.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i6.p1" class="ltx_para">
<p id="S4.I1.i6.p1.1" class="ltx_p">FML learning was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> to enable learning of multi-tasks whose data are distributed among multiple nodes with federated learning settings (i.e., data and system heterogeneity). To enable federated learning for a different tasks, efficient scheduling over resource-constrained radio access network is required for all tasks. Moreover, resources must be assigned as per the nature of the learning task. For instance, more resources should be assigned to the critical tasks (i.e., industrial control) than ordinary tasks (i.e., keyboard keyword suggestion). Assigning more resources lowers the convergence time for federated learning. Therefore, novel joint scheduling and resource allocation schemes for FML will need to be developed.</p>
</div>
</li>
<li id="S4.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i7.p1" class="ltx_para">
<p id="S4.I1.i7.p1.1" class="ltx_p">In dispersed federated learning, the communication of the sub-global aggregation server with end-devices is more frequent than with the centralized aggregation server. Therefore, we can use high-performance channel coding schemes (i.e., turbo codes) having high overhead for reliable communication between the sub-global aggregation server and the global aggregation server. It must be noted that the sub-global model results from frequent, iterative aggregation and exchange of various local learning models, therefore, it must be provided with more reliable communication. On the other hand, we can use low-overhead linear block codes or convolutional codes for reliable communication between end-devices and sub-global aggregation server due to their frequent communication.</p>
</div>
</li>
<li id="S4.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i8.p1" class="ltx_para">
<p id="S4.I1.i8.p1.1" class="ltx_p">There is a need to propose novel communication resource-efficient federated optimization schemes for dispersed federated learning. One can use D2D communication-assisted dispersed federated learning. In D2D communication assisted dispersed federated learning, a set of closely located devices form clusters which is followed by cluster head selection using some attractive criteria (e.g., socially-aware interaction). The devices within a cluster compute their local learning model and exchange it with a cluster head in an iterative manner to yield a sub-global model. The advantage of sub-global model computation lies in the reuse of the already occupied spectrum by the cluster devices. The sub-global model updates from all the cluster heads are sent to the BS where the global model aggregation takes place. Finally, the global model updates are sent back to the cluster heads which disseminate the global model to the devices.</p>
</div>
</li>
<li id="S4.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i9.p1" class="ltx_para">
<p id="S4.I1.i9.p1.1" class="ltx_p">Mobility management for groups used to compute sub-global models in a dispersed federated learning is of significant importance. A set of devices within a sub-group used for sub-global model computation is desirable to remain within the group until the iterative computation of the sub-global model. Therefore, we must handle the issue of mobility.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Open Research Challenges</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section presents various open challenges that exist in enabling federated learning over IoT networks. The challenges presented in our paper are different than those of existing surveys and tutorials related to federated learning for wireless networks, as given in Table <a href="#S5.T12" title="TABLE XII ‣ V Open Research Challenges ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">XII</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. We present causes and possible solutions to these challenges. Summary of the open research challenges with their possible solutions for federated learning are given in Table <a href="#S5.T13" title="TABLE XIII ‣ V-A Sparsification-Enabled Federated Learning ‣ V Open Research Challenges ‣ Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">XIII</span></a>.</p>
</div>
<figure id="S5.T12" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T12.2.1.1" class="ltx_text" style="font-size:90%;">TABLE XII</span>: </span><span id="S5.T12.3.2" class="ltx_text" style="font-size:90%;">Summary of existing surveys and tutorials open research challenges.</span></figcaption>
<table id="S5.T12.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T12.4.1" class="ltx_tr">
<td id="S5.T12.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T12.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.1.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S5.T12.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S5.T12.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T12.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.1.2.1.1" class="ltx_p" style="width:162.2pt;"><span id="S5.T12.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Challenges</span></span>
</span>
</td>
</tr>
<tr id="S5.T12.4.2" class="ltx_tr">
<td id="S5.T12.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.2.1.1.1" class="ltx_p" style="width:62.6pt;">Lim <span id="S5.T12.4.2.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite></span>
</span>
</td>
<td id="S5.T12.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.2.2.1.1" class="ltx_p" style="width:162.2pt;">Dropped participants, privacy concerns, unlabeled data, interference among mobile devices, communication security, asynchronous FL, comparisons with other distributed learning methods, further studies on learning convergence, usage of tools to quantify statistical heterogeneity, combined algorithms for communication reduction, cooperative mobile crowd ML, applications of FL.</span>
</span>
</td>
</tr>
<tr id="S5.T12.4.3" class="ltx_tr">
<td id="S5.T12.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.3.1.1.1" class="ltx_p" style="width:62.6pt;">Li <span id="S5.T12.4.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span>
</span>
</td>
<td id="S5.T12.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.3.2.1.1" class="ltx_p" style="width:162.2pt;">Extreme communication schemes, communication reduction and pareto frontier, novel models of asynchrony, heterogeneity diagnostics, granular privacy constraints, beyond supervised learning, productionizing federated learning, benchmarks.</span>
</span>
</td>
</tr>
<tr id="S5.T12.4.4" class="ltx_tr">
<td id="S5.T12.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.4.1.1.1" class="ltx_p" style="width:62.6pt;">Wang <span id="S5.T12.4.4.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S5.T12.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T12.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.4.2.1.1" class="ltx_p" style="width:162.2pt;">Accelerating AI tasks by
edge communication and computing systems, efficiency of In-Edge AI for real-time
mobile communication system toward 5G, incentive and business model of In-Edge AI.</span>
</span>
</td>
</tr>
<tr id="S5.T12.4.5" class="ltx_tr">
<td id="S5.T12.4.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T12.4.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.5.1.1.1" class="ltx_p" style="width:62.6pt;">Our Tutorial</span>
</span>
</td>
<td id="S5.T12.4.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T12.4.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T12.4.5.2.1.1" class="ltx_p" style="width:162.2pt;">Sparsification-enabled federated learning, data-heterogeneity-aware-clustering-enabled federated learning, mobility-aware federated learning, homomorphic encryption-enabled federated learning, secure and trustful aggregation-enabled federated learning, interference-aware resource efficient federated learning, interference-aware association for federated learning, quantization-enabled federated learning, adaptive-resource-allocation-enabled federated learning.</span>
</span>
</td>
</tr>
</table>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Sparsification-Enabled Federated Learning</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">How do we enable federated learning for a massive number of heterogeneous devices under strict wireless resource constraints? Optimal use of limited wireless resources in federated learning for a massive number of heterogeneous devices can be enabled via sparsification, which allows only a small set of devices to send their local learning model parameters to edge/cloud server. The criterion for choosing the set of devices to send their data to the edge/cloud server is a challenging task. One way is to choose the devices with gradients of magnitude greater than a certain threshold. However, computing the optimal value of the threshold for a massive number of heterogeneous devices is difficult. Another criterion for the selection of end-devices can be their local learning model accuracy which is affected by many factors such as clean datasets, local computational power, and backup power. Furthermore, devices with degraded performance over wireless channels result in prolonging the federated learning convergence time due to high packet error rates. To address the above challenges, there is a need for novel effective sparsification enabled federated learning protocols.</p>
</div>
<figure id="S5.T13" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T13.2.1.1" class="ltx_text" style="font-size:90%;">TABLE XIII</span>: </span><span id="S5.T13.3.2" class="ltx_text" style="font-size:90%;">Summary of the research challenges and their guidelines.</span></figcaption>
<div id="S5.T13.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:295pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.6pt,29.6pt) scale(0.832597622652246,0.832597622652246) ;">
<table id="S5.T13.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T13.4.1.1" class="ltx_tr">
<td id="S5.T13.4.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T13.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Challenges</span></span>
</span>
</td>
<td id="S5.T13.4.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T13.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.1.2.1.1" class="ltx_p" style="width:99.6pt;"><span id="S5.T13.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Taxonomy relevancy</span></span>
</span>
</td>
<td id="S5.T13.4.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T13.4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T13.4.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Causes</span></span>
</span>
</td>
<td id="S5.T13.4.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T13.4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.1.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T13.4.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Guidelines</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.2" class="ltx_tr">
<td id="S5.T13.4.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.2.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Sparsification-Enabled Federated Learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.2.2.1.1" class="ltx_p" style="width:99.6pt;">Federated optimization schemes (client selection protocol)</span>
</span>
</td>
<td id="S5.T13.4.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.2.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I1" class="ltx_itemize">
<span id="S5.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I1.i1.p1" class="ltx_para">
<span id="S5.I1.i1.p1.1" class="ltx_p">Significant changes in the in end-devices local accuracy performance due to noisy datasets, local computational power, and local energy.</span>
</span></span>
<span id="S5.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I1.i2.p1" class="ltx_para">
<span id="S5.I1.i2.p1.1" class="ltx_p">Wireless resources constraints.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.2.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I2" class="ltx_itemize">
<span id="S5.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I2.i1.p1" class="ltx_para">
<span id="S5.I2.i1.p1.1" class="ltx_p">Gradient-based sparsification scheme.</span>
</span></span>
<span id="S5.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I2.i2.p1" class="ltx_para">
<span id="S5.I2.i2.p1.1" class="ltx_p">Selection of devices with sufficient computational, clean datasets, and communication resources.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.3" class="ltx_tr">
<td id="S5.T13.4.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.3.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Mobility-Aware Federated Learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.3.2.1.1" class="ltx_p" style="width:99.6pt;">Federated optimization schemes</span>
</span>
</td>
<td id="S5.T13.4.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.3.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I3" class="ltx_itemize">
<span id="S5.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I3.i1.p1" class="ltx_para">
<span id="S5.I3.i1.p1.1" class="ltx_p">Connectivity loss due to mobility during training phase.</span>
</span></span>
<span id="S5.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I3.i2.p1" class="ltx_para">
<span id="S5.I3.i2.p1.1" class="ltx_p">Variations in SINR due to mobility.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.3.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I4" class="ltx_itemize">
<span id="S5.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I4.i1.p1" class="ltx_para">
<span id="S5.I4.i1.p1.1" class="ltx_p">Priority in selection of static and low-mobility devices for training.</span>
</span></span>
<span id="S5.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I4.i2.p1" class="ltx_para">
<span id="S5.I4.i2.p1.1" class="ltx_p">Deep learning-based mobility prediction schemes.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.4" class="ltx_tr">
<td id="S5.T13.4.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.4.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Data-Heterogeneity-Aware-Clustering-Enabled Federated Learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.4.2.1.1" class="ltx_p" style="width:99.6pt;">Federated optimization schemes</span>
</span>
</td>
<td id="S5.T13.4.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.4.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I5" class="ltx_itemize">
<span id="S5.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I5.i1.p1" class="ltx_para">
<span id="S5.I5.i1.p1.1" class="ltx_p">Existence of significant statistical heterogeneity among massive number of devices datasets.</span>
</span></span>
<span id="S5.I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I5.i2.p1" class="ltx_para">
<span id="S5.I5.i2.p1.1" class="ltx_p">Statistical heterogeneity significantly degrades the federated learning convergence performance.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.4.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I6" class="ltx_itemize">
<span id="S5.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I6.i1.p1" class="ltx_para">
<span id="S5.I6.i1.p1.1" class="ltx_p">Clustering based on statistical homogeneity.</span>
</span></span>
<span id="S5.I6.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I6.i2.p1" class="ltx_para">
<span id="S5.I6.i2.p1.1" class="ltx_p">Selection of most trustful end-devices acting for aggregation within clusters.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.5" class="ltx_tr">
<td id="S5.T13.4.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.5.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Homomorphic encryption-enabled federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.5.2.1.1" class="ltx_p" style="width:99.6pt;">Security and privacy</span>
</span>
</td>
<td id="S5.T13.4.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.5.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I7" class="ltx_itemize">
<span id="S5.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I7.i1.p1" class="ltx_para">
<span id="S5.I7.i1.p1.1" class="ltx_p">Ability of a malicious user to alter learning model parameters during wireless transfer between the aggregation server and end-devices.</span>
</span></span>
<span id="S5.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I7.i2.p1" class="ltx_para">
<span id="S5.I7.i2.p1.1" class="ltx_p">Ability of man-in-the-middle to infer end-devices sensitive information from learning model parameters.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.5.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I8" class="ltx_itemize">
<span id="S5.I8.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I8.i1.p1" class="ltx_para">
<span id="S5.I8.i1.p1.1" class="ltx_p">Partially homomorphic encryption.</span>
</span></span>
<span id="S5.I8.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I8.i2.p1" class="ltx_para">
<span id="S5.I8.i2.p1.1" class="ltx_p">Somewhat homomorphic encryption.</span>
</span></span>
<span id="S5.I8.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I8.i3.p1" class="ltx_para">
<span id="S5.I8.i3.p1.1" class="ltx_p">Fully homomorphic encryption.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.6" class="ltx_tr">
<td id="S5.T13.4.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.6.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.6.1.1.1.1" class="ltx_text ltx_font_bold">Secure and trustful aggregation-enabled federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.6.2.1.1" class="ltx_p" style="width:99.6pt;">Security and privacy</span>
</span>
</td>
<td id="S5.T13.4.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.6.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I9" class="ltx_itemize">
<span id="S5.I9.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I9.i1.p1" class="ltx_para">
<span id="S5.I9.i1.p1.1" class="ltx_p">Presence of malicious end-devices.</span>
</span></span>
<span id="S5.I9.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I9.i2.p1" class="ltx_para">
<span id="S5.I9.i2.p1.1" class="ltx_p">Wrong local learning model parameters prolong federated learning convergence time.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.6.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I10" class="ltx_itemize">
<span id="S5.I10.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I10.i1.p1" class="ltx_para">
<span id="S5.I10.i1.p1.1" class="ltx_p">Secure aggregation-enabled federated learning scheme.</span>
</span></span>
<span id="S5.I10.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I10.i2.p1" class="ltx_para">
<span id="S5.I10.i2.p1.1" class="ltx_p">Consortium blockchain-based trustful verification of end-devices updates.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.7" class="ltx_tr">
<td id="S5.T13.4.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.7.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.7.1.1.1.1" class="ltx_text ltx_font_bold">Interference-aware resource efficient federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.7.2.1.1" class="ltx_p" style="width:99.6pt;">Resource optimization</span>
</span>
</td>
<td id="S5.T13.4.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.7.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I11" class="ltx_itemize">
<span id="S5.I11.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I11.i1.p1" class="ltx_para">
<span id="S5.I11.i1.p1.1" class="ltx_p">Communication resources constraints.</span>
</span></span>
<span id="S5.I11.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I11.i2.p1" class="ltx_para">
<span id="S5.I11.i2.p1.1" class="ltx_p">Protection of cellular users while reusing frequency by end-devices used in federated learning.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.7.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I12" class="ltx_itemize">
<span id="S5.I12.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I12.i1.p1" class="ltx_para">
<span id="S5.I12.i1.p1.1" class="ltx_p">Game theory-based resource allocation.</span>
</span></span>
<span id="S5.I12.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I12.i2.p1" class="ltx_para">
<span id="S5.I12.i2.p1.1" class="ltx_p">Matching game with externalities for resource allocation.</span>
</span></span>
<span id="S5.I12.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I12.i3.p1" class="ltx_para">
<span id="S5.I12.i3.p1.1" class="ltx_p">Relaxation-enabled resource allocation scheme.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.8" class="ltx_tr">
<td id="S5.T13.4.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.8.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.8.1.1.1.1" class="ltx_text ltx_font_bold">Interference-aware association for federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.8.2.1.1" class="ltx_p" style="width:99.6pt;">Resource optimization</span>
</span>
</td>
<td id="S5.T13.4.1.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.8.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I13" class="ltx_itemize">
<span id="S5.I13.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I13.i1.p1" class="ltx_para">
<span id="S5.I13.i1.p1.1" class="ltx_p">Dependency of SINR on association.</span>
</span></span>
<span id="S5.I13.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I13.i2.p1" class="ltx_para">
<span id="S5.I13.i2.p1.1" class="ltx_p">Proportional effect of association on packet error rate.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.8.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I14" class="ltx_itemize">
<span id="S5.I14.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I14.i1.p1" class="ltx_para">
<span id="S5.I14.i1.p1.1" class="ltx_p">Game theory-based association.</span>
</span></span>
<span id="S5.I14.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I14.i2.p1" class="ltx_para">
<span id="S5.I14.i2.p1.1" class="ltx_p">Relaxation-enabled association scheme.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.9" class="ltx_tr">
<td id="S5.T13.4.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.9.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.9.1.1.1.1" class="ltx_text ltx_font_bold">Quantization-enabled federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.9.2.1.1" class="ltx_p" style="width:99.6pt;">Resource optimization</span>
</span>
</td>
<td id="S5.T13.4.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.9.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I15" class="ltx_itemize">
<span id="S5.I15.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I15.i1.p1" class="ltx_para">
<span id="S5.I15.i1.p1.1" class="ltx_p">Communication resource constraints.</span>
</span></span>
<span id="S5.I15.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I15.i2.p1" class="ltx_para">
<span id="S5.I15.i2.p1.1" class="ltx_p">Massive number of devices are expected in future for federated learning training-enabled IoT applications.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T13.4.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.9.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I16" class="ltx_itemize">
<span id="S5.I16.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I16.i1.p1" class="ltx_para">
<span id="S5.I16.i1.p1.1" class="ltx_p">Gradient-based selective end-devices selection.</span>
</span></span>
<span id="S5.I16.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I16.i2.p1" class="ltx_para">
<span id="S5.I16.i2.p1.1" class="ltx_p">Selection of end-devices with better performance.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S5.T13.4.1.10" class="ltx_tr">
<td id="S5.T13.4.1.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T13.4.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.10.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T13.4.1.10.1.1.1.1" class="ltx_text ltx_font_bold">Adaptive-resource-allocation-enabled federated learning</span></span>
</span>
</td>
<td id="S5.T13.4.1.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T13.4.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.10.2.1.1" class="ltx_p" style="width:99.6pt;">Resource optimization</span>
</span>
</td>
<td id="S5.T13.4.1.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T13.4.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.10.3.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I17" class="ltx_itemize">
<span id="S5.I17.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I17.i1.p1" class="ltx_para">
<span id="S5.I17.i1.p1.1" class="ltx_p">Heterogeneity of computational resources (CPU-cycles/sec), local device energy, and communication resources results in variable local accuracy.</span>
</span></span>
</span></span>
</span>
</td>
<td id="S5.T13.4.1.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T13.4.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T13.4.1.10.4.1.1" class="ltx_p" style="width:142.3pt;">
<span id="S5.I18" class="ltx_itemize">
<span id="S5.I18.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S5.I18.i1.p1" class="ltx_para">
<span id="S5.I18.i1.p1.1" class="ltx_p">Adaptive resource allocation (i.e., more wireless resources to devices with high local model computational time) to minimize the overall federated learning convergence time.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Data-Heterogeneity-Aware-Clustering-Enabled Federated Learning </span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">How does one enable federated learning for massively distributed devices having heterogeneous features? A massive number of IoT devices exhibit a significant amount of statistical heterogeneity in their datasets. FedAvg was developed to yield a global federated learning model using the assumption of synchronous amount of work at end-devices during each global iteration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. However, IoT devices show significant heterogeneity in their datasets and system parameters. To address this issue, FedProx was developed that is based on the addition of a weighted proximal term to the global model of FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. Choosing the weights for FedProx for different applications is challenging. Additionally, it is not clear whether FedProx can provably improve convergence rate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Therefore, there is a need to devise a novel protocol for federated learning to cope with data heterogeneity. One possible solution can be the formation of clusters of end-devices with statistical homogeneity. Within each cluster, a cluster head is selected which acts for aggregation of local learning models. The selection of cluster heads must follow attractive criteria. For instance, the criterion for cluster head selection can be an improvement in the overall throughput of the cluster. Another possible way can be socially-aware clustering. As cluster head has the capability to infer end-devices sensitive information from their local learning model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, it can be desirable to form cluster head with high social trust nature. Within each cluster, a sub-global model can be computed similarly to traditional federated learning. Next, cluster heads send their sub-global models to global aggregation server to yield a global federated learning model, which is then disseminated to cluster heads. Finally, the cluster heads disseminate the global model updates to devices of their corresponding clusters.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.4.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.5.2" class="ltx_text ltx_font_italic">Mobility-Aware Federated Learning</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">How do we enable seamless communication of mobile devices with the centralized edge/cloud server during training phase of federated learning? The set of mobile devices involved in learning must be connected to the edge/cloud server during the training phase. However, mobility of the devices might cause loss in coverage and thus, causes performance degradation of federated learning. Several solutions can be proposed to tackle this issue. One way is modification in the federated learning protocols that should consider the mobility of users in addition to other factors during the devices selection phase. The devices with no mobility or with less mobility than other high mobility nodes must be preferred. This approach seems to be promising in the scenarios where the minimum required number of devices for federated learning have no or limited mobility. However, if the devices have high mobility then it is necessary to predict the mobility of devices during the device selection phase. For this, deep learning-based mobility prediction schemes can be used.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.4.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.5.2" class="ltx_text ltx_font_italic">Homomorphic Encryption-Enabled Federated Learning</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">How does one enable secure exchange of federated learning parameters between devices and the cloud/edge server? Although federated learning has been proposed to enable privacy-aware on-device machine learning in a distributed manner, it suffers from security challenges and privacy challenges. A malicious user can access the learning model updates during their transmission between end-devices and the aggregation server. Then, the malicious user abnormally alters the learning parameters. Moreover, the learning parameters can be used by a malicious user to infer end-device sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Therefore, it is indispensable to ensure secure federated learning over wireless channels. One can use homomorphic encryption for ensuring secure federated learning. In homomorphic encryption-based federated learning, a key-pair is synchronized among all end-devices via a secure channel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>. Initially, all the devices encrypts their local learning model updates and send the ciphertexts to a central server. Next, the server sends back the aggregated result to the end-devices. The advantage of using homomorphic encryption is non-requirement of decryption at the aggregation server. However, generally, homomorphic encryption results in the use of extra computation and communication resources. Homomorphic encryption can be divided into three main categories such as partially homomorphic encryption, somewhat homomorphic encryption, and fully homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite>. These categories of homomorphic encryption offer freedom of performing mathematical operation depending on the type used. For instance, partially homomorphic encryption allows only one type of mathematical operation (i.e., addition or multiplication), whereas fully homomorphic encryption allows a large number of different mathematical operations. On the other hand, ciphertext in homomorphic encryption contains a noise which increases proportionally with mathematical operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite>. Therefore, there is a need to devise a homophobic encryption scheme that accounts for such type of noise.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.4.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.5.2" class="ltx_text ltx_font_italic">Secure and Trustful Aggregation-Enabled Federated Learning</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.2" class="ltx_p">How do we enable aggregation of learning models at the aggregation server in a secure and trustful way? A malicious user can send the wrong local learning model parameters to the aggregation server to slow the federated learning convergence rate. In some cases, the global federated learning model might not converge due to the presence of a malicious user. On the other hand, it is necessary to verify the end-devices’ updates before considering them for global aggregation. Several possible ways can be used to enable secure aggregation. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>, the authors proposed a secure aggregation protocol for federated learning. The protocol can offer security against <math id="S5.SS5.p1.1.m1.1" class="ltx_Math" alttext="1/3" display="inline"><semantics id="S5.SS5.p1.1.m1.1a"><mrow id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml"><mn id="S5.SS5.p1.1.m1.1.1.2" xref="S5.SS5.p1.1.m1.1.1.2.cmml">1</mn><mo id="S5.SS5.p1.1.m1.1.1.1" xref="S5.SS5.p1.1.m1.1.1.1.cmml">/</mo><mn id="S5.SS5.p1.1.m1.1.1.3" xref="S5.SS5.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><apply id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"><divide id="S5.SS5.p1.1.m1.1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1.1"></divide><cn type="integer" id="S5.SS5.p1.1.m1.1.1.2.cmml" xref="S5.SS5.p1.1.m1.1.1.2">1</cn><cn type="integer" id="S5.SS5.p1.1.m1.1.1.3.cmml" xref="S5.SS5.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">1/3</annotation></semantics></math> of the total devices but at the cost of extra communication resources and complexity. Although the protocol in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite> offers reasonable performance, there is a need to propose novel protocols than can handle malicious users more than <math id="S5.SS5.p1.2.m2.1" class="ltx_Math" alttext="1/3" display="inline"><semantics id="S5.SS5.p1.2.m2.1a"><mrow id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml"><mn id="S5.SS5.p1.2.m2.1.1.2" xref="S5.SS5.p1.2.m2.1.1.2.cmml">1</mn><mo id="S5.SS5.p1.2.m2.1.1.1" xref="S5.SS5.p1.2.m2.1.1.1.cmml">/</mo><mn id="S5.SS5.p1.2.m2.1.1.3" xref="S5.SS5.p1.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><apply id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1"><divide id="S5.SS5.p1.2.m2.1.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1.1"></divide><cn type="integer" id="S5.SS5.p1.2.m2.1.1.2.cmml" xref="S5.SS5.p1.2.m2.1.1.2">1</cn><cn type="integer" id="S5.SS5.p1.2.m2.1.1.3.cmml" xref="S5.SS5.p1.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">1/3</annotation></semantics></math> of the total devices. In another work, a reputation-based metric was introduced for the trustful participation of end-devices in the federated learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. Consortium blockchain was then applied to enable efficient reputation management. Although the scheme presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite> can offer resilience against adversaries, it has high-latency associated with blockchain. To address the above challenges, there is a need for federated learning protocols that can offer security and trustful verification using low complexity schemes.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS6.4.1.1" class="ltx_text">V-F</span> </span><span id="S5.SS6.5.2" class="ltx_text ltx_font_italic">Interference-Aware Resource Efficient Federated Learning </span>
</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">How do we reuse the uplink communication resources already in use by other cellular users for federated learning while protecting them? To protect cellular users from interference due to end-devices involved in federated learning, we will require resource allocation schemes. There can be two different ways of allocating resource blocks to end-devices. The first one is to assign a single resource block to only one end-device while fulfilling the constraint the maximum allowed interference. Another approach is to assign multiple end-devices to a single resource block to more effectively reuse the resources. For the later case, we can use one-to-one matching, whereas for this case we can use one-to-many matching theory with externalities for resource allocation due to the fact that preference profiles depend both on resource blocks along with other end-devices assigned to the same resource block <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib173" title="" class="ltx_ref">173</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>, <a href="#bib.bib175" title="" class="ltx_ref">175</a>, <a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS7.4.1.1" class="ltx_text">V-G</span> </span><span id="S5.SS7.5.2" class="ltx_text ltx_font_italic">Interference-Aware Association for Federated Learning</span>
</h3>

<div id="S5.SS7.p1" class="ltx_para">
<p id="S5.SS7.p1.1" class="ltx_p">How does one associate end-devices to the edge servers-enabled small cell BSs (SBSs) to reuse the uplink cellular spectrum while protecting cellular users? For a fixed resource block allocation and fixed transmit power, the end-devices’ association has no impact on interference control for cellular users while reusing their frequencies. However, joint transmit power allocation and device association for end-devices can be performed to simultaneously minimize federated learning cost and cellular user interference. Such kind of joint transmit power allocation and the device-association optimization problem is a mixed-integer non-linear programming problem that can be solved sub-optimally in a variety of ways.</p>
</div>
</section>
<section id="S5.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS8.4.1.1" class="ltx_text">V-H</span> </span><span id="S5.SS8.5.2" class="ltx_text ltx_font_italic">Quantization-Enabled Federated Learning</span>
</h3>

<div id="S5.SS8.p1" class="ltx_para">
<p id="S5.SS8.p1.1" class="ltx_p">How do we enable federated learning for a massive number of devices under communication resource constraints? Although sparsification-enabled federated learning can reduce communication resource consumption, it might not be sufficient alone for a large number of devices and limited communication resources. To address this issue, we can use quantization-enabled federated learning. However, quantization induces errors in global federated learning due to the distortion of the signals. Such kind of errors in the global federated learning model might prolong its convergence time. Therefore, there is a need to make a trade-off between a federated learning convergence time and communication resources consumption during training. Several quantization techniques (i.e., universal vector quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite>, low-precision quantizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>, and hyper-sphere quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite>) can be used for federated learning over IoT networks.</p>
</div>
</section>
<section id="S5.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS9.4.1.1" class="ltx_text">V-I</span> </span><span id="S5.SS9.5.2" class="ltx_text ltx_font_italic">Adaptive-Resource-Allocation-Enabled Federated Learning</span>
</h3>

<div id="S5.SS9.p1" class="ltx_para">
<p id="S5.SS9.p1.1" class="ltx_p">How does one perform training of the federated learning model with low convergence time for end-devices with heterogeneous resources? The devices involved in federated learning are heterogeneous in terms of computational resources (CPU-cycles/sec), local device energy, and communication resources. These heterogeneous parameters have a significant effect on the performance of federated learning. For instance, computation time of local device learning models strictly depends on local model accuracy, local device operating frequency, and dataset size for the local learning model algorithm. On the other hand, synchronous federated learning is based on the computation of all the devices’ local models within fixed time. However, the local computation time for devices with heterogeneous features shows significant variations in local learning model accuracy for fixed local model computation time. Therefore, these challenges of heterogeneity in the devices must be resolved. One way to reduce the impact of heterogeneity on the performance of federated learning is to allocate more computational resources to users with larger local training dataset sizes for achieving certain accuracy within the allowed time and vice versa. Another approach is to assign more communication resources to the end-devices with poor performance due to a lack of computational resources. Allocating resources adaptively can reduce the global federated learning time, and thus offer fast convergence.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and Future Prospects</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we have discussed federated learning for IoT networks. Specifically, we have presented state-of-art-advances of federated learning towards enabling smart IoT applications. We have provided a taxonomy using various parameters. Furthermore, we have identified several important issues (i.e., robustness, privacy, and high-communication resources consumption) with the existing federated learning schemes based on a centralized aggregation server and presented guidelines to solve them. Finally, we have presented several open research challenges along with their causes and guidelines. We have concluded that dispersed federated learning will serve as a key federated learning scheme for future IoT applications using a massive number of end-devices.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.7" class="ltx_p">Although IoT networks enabled by federated learning and fifth-generation (<math id="S6.p2.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.p2.1.m1.1a"><mn id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><cn type="integer" id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">5</annotation></semantics></math>G) of cellular networks, can offer a wide variety of smart applications such as intelligent transportation, smart industry, smart health-care, among others. However, there are several Internet of Everything (IoE) applications that seem difficult to be fulfilled by <math id="S6.p2.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.p2.2.m2.1a"><mn id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><cn type="integer" id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">5</annotation></semantics></math>G. These IoE applications are haptics, flying vehicles, extended reality, brain-computer interfaces, and autonomous connected vehicles. The requirements of these applications seem difficult to be fulfilled by <math id="S6.p2.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.p2.3.m3.1a"><mn id="S6.p2.3.m3.1.1" xref="S6.p2.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.p2.3.m3.1b"><cn type="integer" id="S6.p2.3.m3.1.1.cmml" xref="S6.p2.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.3.m3.1c">5</annotation></semantics></math>G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Therefore, there is a need to propose a new generation of wireless systems, dubbed as sixth-generation (<math id="S6.p2.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S6.p2.4.m4.1a"><mn id="S6.p2.4.m4.1.1" xref="S6.p2.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.p2.4.m4.1b"><cn type="integer" id="S6.p2.4.m4.1.1.cmml" xref="S6.p2.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.4.m4.1c">6</annotation></semantics></math>G) wireless systems. Machine learning will be considered to be an integral part of <math id="S6.p2.5.m5.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S6.p2.5.m5.1a"><mn id="S6.p2.5.m5.1.1" xref="S6.p2.5.m5.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.p2.5.m5.1b"><cn type="integer" id="S6.p2.5.m5.1.1.cmml" xref="S6.p2.5.m5.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.5.m5.1c">6</annotation></semantics></math>G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib181" title="" class="ltx_ref">181</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Additionally, privacy preservation will be given primary importance in <math id="S6.p2.6.m6.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S6.p2.6.m6.1a"><mn id="S6.p2.6.m6.1.1" xref="S6.p2.6.m6.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.p2.6.m6.1b"><cn type="integer" id="S6.p2.6.m6.1.1.cmml" xref="S6.p2.6.m6.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.6.m6.1c">6</annotation></semantics></math>G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite>. Therefore, dispersed federated learning with homomorphic encryption can be a promising candidate for the future <math id="S6.p2.7.m7.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S6.p2.7.m7.1a"><mn id="S6.p2.7.m7.1.1" xref="S6.p2.7.m7.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S6.p2.7.m7.1b"><cn type="integer" id="S6.p2.7.m7.1.1.cmml" xref="S6.p2.7.m7.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.7.m7.1c">6</annotation></semantics></math>G-enabled IoE applications. In dispersed federated learning, homomorphic encryption will give privacy preservation against a malicious sub-global aggregation server, whereas sub-global aggregations will give privacy preservation against malicious global aggregation server.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L. U. Khan, I. Yaqoob, M. Imran, Z. Han, and C. S. Hong, “6G wireless
systems: A vision, architectural elements, and future directions,”
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, August 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. U. Khan, I. Yaqoob, N. H. Tran, S. Kazmi, T. N. Dang, and C. S. Hong, “Edge
computing enabled smart cities: A comprehensive survey,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Internet
of Things Journal, To appear</em>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
R. Sánchez-Corcuera, A. Nuñez-Marcos, J. Sesma-Solance, A. Bilbao-Jayo,
R. Mulero, U. Zulaika, G. Azkune, and A. Almeida, “Smart cities survey:
Technologies, application domains and challenges for the cities of the
future,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">International Journal of Distributed Sensor Networks</em>,
vol. 15, no. 6, p. 1550147719853984, June 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
C. Perera, Y. Qin, J. C. Estrella, S. Reiff-Marganiec, and A. V. Vasilakos,
“Fog computing for sustainable smart cities: A survey,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ACM Computing
Surveys (CSUR)</em>, vol. 50, no. 3, pp. 1–43, June 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, D. Niyato, Z. Han, and C. S. Hong, “Digital-twin-enabled
6g: Vision, architectural trends, and future directions,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2102.12169</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
W. Saad, M. Bennis, and M. Chen, “A vision of 6G wireless systems:
Applications, trends, technologies, and open research problems,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE
Network</em>, vol. 34, no. 3, pp. 134–142, May/June 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari, and M. Ayyash, “Internet
of things: A survey on enabling technologies, protocols, and applications,”
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE communications surveys &amp; tutorials</em>, vol. 17, no. 4, pp.
2347–2376, June 2015.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
C. Perera, A. Zaslavsky, P. Christen, and D. Georgakopoulos, “Context aware
computing for the internet of things: A survey,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE communications
surveys &amp; tutorials</em>, vol. 16, no. 1, pp. 414–454, May 2013.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Number of connected iot devices will surge to 125 billion by 2030. [Online;
Accessed October June 14, 2020;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://sst.semiconductor-digest.com/2017/10/number-of-connected-iot-devices-will-surge-to-125-billion-by-2030/</span>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
The growth in connected iot devices is expected to generate 79.4zb of data in
2025, according to a new idc forecast. [Online; Accessed October June 14,
2020;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.idc.com/getdoc.jsp?containerId=prUS45213219</span>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Qi and C. Yang, “Popularity prediction with federated learning for
proactive caching at wireless edge,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless Communications
and Networking Conference</em>, May 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
I. Raicu, I. Foster, A. Szalay, and G. Turcu, “Astroportal: A science gateway
for large-scale astronomy data analysis,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Teragrid conference</em>,
February 2006, pp. 12–15.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
P. A. Bernstein and E. Newcomer, <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Principles of transaction
processing</em>.   Morgan Kaufmann, 2009.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. Verbraeken, M. Wolting, J. Katzy, J. Kloppenburg, T. Verbelen, and J. S.
Rellermeyer, “A survey on distributed machine learning,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1912.09789</em>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D. Alistarh. Distributed machine learning: A brief overview. [Online; Accessed
March, 2020;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.podc.org/data/podc2018/podc2018-tutorial-alistarh.pdf</span>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
K. Zhang, S. Alqahtani, and M. Demirbas, “A comparison of distributed
machine learning platforms,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Computer
Communication and Networks</em>, Silicon Valley, USA, July-August 2017, pp. 1–9.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Qiu, Q. Wu, G. Ding, Y. Xu, and S. Feng, “A survey of machine learning for
big data processing,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">EURASIP Journal on Advances in Signal
Processing</em>, vol. 2016, no. 1, p. 67, May 2016.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
D. Peteiro-Barral and B. Guijarro-Berdiñas, “A survey of methods for
distributed machine learning,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Progress in Artificial Intelligence</em>,
vol. 2, no. 1, pp. 1–11, November 2013.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, Ft. Lauderdale, FL,
USA, April 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
C. Yang, Q. Wang, M. Xu, S. Wang, K. Bian, and X. Liu, “Heterogeneity-aware
federated learning,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.06983</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z. Chai, H. Fayyaz, Z. Fayyaz, A. Anwar, Y. Zhou, N. Baracaldo, H. Ludwig, and
Y. Cheng, “Towards taming the resource and data heterogeneity in federated
learning,” in <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic"><math id="bib.bib21.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib21.1.1.m1.1a"><mo stretchy="false" id="bib.bib21.1.1.m1.1.1" xref="bib.bib21.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib21.1.1.m1.1b"><ci id="bib.bib21.1.1.m1.1.1.cmml" xref="bib.bib21.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib21.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib21.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib21.2.2.m2.1a"><mo stretchy="false" id="bib.bib21.2.2.m2.1.1" xref="bib.bib21.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib21.2.2.m2.1b"><ci id="bib.bib21.2.2.m2.1.1.cmml" xref="bib.bib21.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib21.2.2.m2.1c">\}</annotation></semantics></math> Conference on Operational Machine
Learning (OpML 19)</em>, Snta Clara, USA, May 2019, pp. 19–21.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication
efficiency,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci, “Wireless sensor
networks: a survey,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Computer networks</em>, vol. 38, no. 4, pp. 393–422,
2002.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. C. Jiang, B. Kantarci, S. Oktug, and T. Soyata, “Federated learning in
smart city sensing: Challenges and opportunities,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20,
no. 21, p. 6230, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
v. D. Nguyen, S. K. Sharma, T. X. Vu, S. Chatzinotas, and B. Ottersten,
“Efficient federated learning algorithm for resource allocation in wireless
iot networks,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys Tutorials</em>,
vol. 22, no. 3, pp. 2031–2063, April 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
L. U. Khan, N. H. Tran, S. R. Pandey, W. Saad, Z. Han, H. N. M. N., and C. S.
Hong, “Federated learning for edge networks: Resource optimization and
incentive mechanism,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv: arXiv:1911.05642</em>, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances
and open problems in federated learning,” <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1912.04977</em>, 2019.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, “In-edge
ai: Intelligentizing mobile edge computing, caching and communication by
federated learning,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 33, no. 5, pp. 156–165, July
2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
“Federated learning, a step closer towards confidential ai,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://medium.com/frstvc/tagged/thoughts</span>, [Online; accessed Jan. 24,
2020].

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em>.   IEEE, 2020, pp.
1–6.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. Chen, H. V. Poor, W. Saad, and S. Cui, “Wireless communications for
collaborative federated learning in the internet of things,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2006.02499</em>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>,
USA, May 2019, pp. 739–753.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
R. C. Geyer, T. Klein, and M. Nabi, “Differentially private federated
learning: A client level perspective,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1712.07557</em>, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
[Online; Accessed Febuary 5, 2021;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.fortunebusinessinsights.com/industry-reports/artificial-intelligence-market-100114</span>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
[Online; Accessed February 6, 2021;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.fortunebusinessinsights.com/industry-reports/internet-of-things-iot-market-100307</span>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1908.07873</em>, 2019.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Q. Li, Z. Wen, and B. He, “Federated learning systems: Vision, hype and
reality for data privacy and protection,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1907.09693</em>, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
<em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, Z. Han, and C. S. Hong, “Dispersed federated learning:
Vision, taxonomy, and future directions,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2008.05189</em>, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
S. A. Rahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi, and
M. Guizani, “A survey on federated learning: The journey from centralized
to distributed on-site learning and beyond,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Journal</em>, pp. 1–1, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated learning: A
survey on enabling technologies, protocols, and applications,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 8, pp. 140 699–140 725, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
F. Hussain, R. Hussain, S. A. Hassan, and E. Hossain, “Machine learning in iot
security: Current solutions and future challenges,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE
Communications Surveys &amp; Tutorials</em>, vol. 22, no. 3, pp. 1686–1721, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
N. Waheed, X. He, M. Ikram, M. Usman, S. S. Hashmi, and M. Usman, “Security
and privacy in iot using machine learning and blockchain: Threats and
countermeasures,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, vol. 53, no. 6, pp.
1–37, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE International
Conference on Communications</em>, Shanghai, China, Mat 2019, pp. 1–7.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
L. U. Khan, M. Alsenwi, Z. Han, and C. S. Hong, “Self organizing federated
learning over wireless networks: A socially aware clustering approach,” in
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">2020 International Conference on Information Networking (ICOIN)</em>,
Barcelona, Spain, March 2020, pp. 453–458.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
L. U. Khan, M. Alsenwi, I. Yaqoob, M. Imran, Z. Han, and C. S. Hong, “Resource
optimized federated learning-enabled cognitive internet of things for smart
industries,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, September 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
L. U. Khan, U. Majeed, and C. S. Hong, “Federated learning for cellular
networks: Joint user association and resource allocation,” in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">2020
21st Asia-Pacific Network Operations and Management Symposium
(APNOMS)</em>.   IEEE, 2020, pp. 405–408.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
M. M. Amiri and D. Gündüz, “Federated learning over wireless fading
channels,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless Communications</em>, vol. 19,
no. 5, pp. 3546–3557, May 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A. R. Elkordy and A. S. Avestimehr, “Secure aggregation with heterogeneous
quantization in federated learning,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.14388</em>,
2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
N. Shlezinger, M. Chen, Y. C. Eldar, H. V. Poor, and S. Cui,
“Federated learning with quantization constraints,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020 -
2020 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>, Barcelona, Spain, May 2020, pp. 8851–8855.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, “Qsgd:
Communication-efficient sgd via gradient quantization and encoding,” in
<em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2017, pp.
1709–1720.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
R. Xu, N. Baracaldo, Y. Zhou, A. Anwar, and H. Ludwig, “Hybridalpha: An
efficient approach for privacy-preserving federated learning,” in
<em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM Workshop on Artificial Intelligence and
Security</em>, 2019, pp. 13–23.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Z. Yang, S. Hu, and K. Chen, “Fpga-based hardware accelerator of homomorphic
encryption for efficient federated learning,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2007.10560</em>, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
J. Tran, F. Farokhi, M. Cantoni, and I. Shames, “Implementing homomorphic
encryption based secure feedback control,” <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Control Engineering
Practice</em>, vol. 97, p. 104350, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
C. Zhang, S. Li, J. Xia, W. Wang, F. Yan, and Y. Liu, “Batchcrypt: Efficient
homomorphic encryption for cross-silo federated learning,” in <em id="bib.bib56.5.5" class="ltx_emph ltx_font_italic">2020
<math id="bib.bib56.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib56.1.1.m1.1a"><mo stretchy="false" id="bib.bib56.1.1.m1.1.1" xref="bib.bib56.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib56.1.1.m1.1b"><ci id="bib.bib56.1.1.m1.1.1.cmml" xref="bib.bib56.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib56.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib56.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib56.2.2.m2.1a"><mo stretchy="false" id="bib.bib56.2.2.m2.1.1" xref="bib.bib56.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib56.2.2.m2.1b"><ci id="bib.bib56.2.2.m2.1.1.cmml" xref="bib.bib56.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib56.2.2.m2.1c">\}</annotation></semantics></math> Annual Technical Conference (<math id="bib.bib56.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib56.3.3.m3.1a"><mo stretchy="false" id="bib.bib56.3.3.m3.1.1" xref="bib.bib56.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib56.3.3.m3.1b"><ci id="bib.bib56.3.3.m3.1.1.cmml" xref="bib.bib56.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib56.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib56.4.4.m4.1" class="ltx_math_unparsed" alttext="\}\{" display="inline"><semantics id="bib.bib56.4.4.m4.1a"><mrow id="bib.bib56.4.4.m4.1b"><mo stretchy="false" id="bib.bib56.4.4.m4.1.1">}</mo><mo stretchy="false" id="bib.bib56.4.4.m4.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="bib.bib56.4.4.m4.1c">\}\{</annotation></semantics></math>ATC<math id="bib.bib56.5.5.m5.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib56.5.5.m5.1a"><mo stretchy="false" id="bib.bib56.5.5.m5.1.1" xref="bib.bib56.5.5.m5.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib56.5.5.m5.1b"><ci id="bib.bib56.5.5.m5.1.1.cmml" xref="bib.bib56.5.5.m5.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib56.5.5.m5.1c">\}</annotation></semantics></math> 20)</em>,
Santa Clara, CA, United States, July 2020, pp. 493–506.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
M. Shirvanimoghaddam, M. S. Mohammadi, R. Abbas, A. Minja, C. Yue, B. Matuz,
G. Han, Z. Lin, W. Liu, Y. Li <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Short block-length codes for
ultra-reliable low latency communications,” <em id="bib.bib57.2.2" class="ltx_emph ltx_font_italic">IEEE Communications
Magazine</em>, vol. 57, no. 2, pp. 130–137, 2018.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
M. Sybis, K. Wesolowski, K. Jayasinghe, V. Venkatasubramanian, and
V. Vukadinovic, “Channel coding for ultra-reliable low-latency communication
in 5g systems,” in <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">2016 IEEE 84th vehicular technology conference
(VTC-Fall)</em>.   IEEE, 2016, pp. 1–5.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
V. Vladyslav, K. Volodymyr, Z. Sergei, and U. Anna, “Adaptive turbo
codes for safety in wireless internet of things,” in <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">2018 IEEE 9th
International Conference on Dependable Systems, Services and Technologies
(DESSERT)</em>, 2018, pp. 188–193.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu, “Flchain: A blockchain for
auditable federated learning with trust and incentive,” in <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">2019 5th
International Conference on Big Data Computing and Communications
(BIGCOM)</em>.   IEEE, 2019, pp. 151–159.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
G. Hua, L. Zhu, J. Wu, C. Shen, L. Zhou, and Q. Lin, “Blockchain-based
federated learning for intelligent control in heavy haul railway,”
<em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp. 176 830–176 839, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
J. Chen, X. Pan, R. Monga, S. Bengio, and R. Jozefowicz, “Revisiting
distributed synchronous sgd,” <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1604.00981</em>, 2016.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning
and communications framework for federated learning over wireless networks,”
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.07972</em>, 2019.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
N. H. Tran, W. Bao, A. Zomaya, and C. S. Hong, “Federated learning over
wireless networks: Optimization model design and analysis,” in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">IEEE
Conference on Computer Communications</em>, Paris, France, April-May 2019, pp.
1387–1395.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
H.-S. Ham, H.-H. Kim, M.-S. Kim, and M.-J. Choi, “Linear svm-based android
malware detection for reliable iot services,” <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Journal of Applied
Mathematics</em>, vol. 2014, 2014.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
S. S. Yadav and S. M. Jadhav, “Deep convolutional neural network based medical
image classification for disease diagnosis,” <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em>,
vol. 6, no. 1, p. 113, 2019.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
A. Ndikumana, N. H. Tran, K. T. Kim, C. S. Hong <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep learning
based caching for self-driving cars in multi-access edge computing,”
<em id="bib.bib68.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</em>, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
X. Du, H. Zhang, H. Van Nguyen, and Z. Han, “Stacked lstm deep learning model
for traffic prediction in vehicle-to-vehicle communication,” in <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">2017
IEEE 86th Vehicular Technology Conference (VTC-Fall)</em>.   IEEE, 2017, pp. 1–5.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
K. Thar, N. H. Tran, T. Z. Oo, and C. S. Hong, “Deepmec: Mobile edge caching
using deep learning,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 6, pp. 78 260–78 275,
2018.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
S. K. Singh, M. M. Salim, J. Cha, Y. Pan, and J. H. Park, “Machine
learning-based network sub-slicing framework in a sustainable 5G
environment,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Sustainability</em>, vol. 12, no. 15, p. 6250, 2020.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
E. Hodo, X. Bellekens, A. Hamilton, P.-L. Dubouilh, E. Iorkyase, C. Tachtatzis,
and R. Atkinson, “Threat analysis of iot networks using artificial neural
network intrusion detection system,” in <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">2016 International Symposium
on Networks, Computers and Communications (ISNCC)</em>.   IEEE, 2016, pp. 1–6.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
L. Li, Y. Xu, Z. Zhang, J. Yin, W. Chen, and Z. Han, “A
prediction-based charging policy and interference mitigation approach in the
wireless powered internet of things,” <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas
in Communications</em>, vol. 37, no. 2, pp. 439–451, 2019.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Y. Liu, Z. Ma, Z. Yan, Z. Wang, X. Liu, and J. Ma, “Privacy-preserving
federated k-means for proactive caching in next generation cellular
networks,” <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em>, vol. 521, pp. 14–31, 2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
H. Hewamalage, C. Bergmeir, and K. Bandara, “Recurrent neural networks for
time series forecasting: Current status and future directions,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1909.00590</em>, 2019.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
C. S. Htwe, Y. M. Thant, and M. M. S. Thwin, “Botnets attack detection using
machine learning approach for iot environment,” in <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Journal of Physics:
Conference Series</em>, vol. 1646, no. 1.   IOP Publishing, 2020, p. 012101.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
M. Bhatia, S. K. Sood, and A. Manocha, “Fog-inspired smart home environment
for domestic animal healthcare,” <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Computer Communications</em>, vol. 160,
pp. 521–533, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
[Online; Accessed January 4, 2021;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/</span>

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
S. Xie, H. Zheng, C. Liu, and L. Lin, “Snas: stochastic neural architecture
search,” <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.09926</em>, 2018.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
C. He, S. Li, J. So, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh,
H. Qiu, L. Shen <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fedml: A research library and benchmark for
federated machine learning,” <em id="bib.bib80.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach, “A generic framework for privacy preserving deep
learning,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
A. Ingerman and K. Ostrowski, “Introducing tensorflow federated,”
<em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">External Links: Link Cited by</em>, vol. 4, 2019.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan,
V. Smith, and A. Talwalkar, “Leaf: A benchmark for federated settings,”
<em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair resource allocation in
federated learning,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.10497</em>, 2019.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor
federated learning,” in <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial
Intelligence and Statistics</em>.   PMLR,
2020, pp. 2938–2948.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Y. Ma, D. Yu, T. Wu, and H. Wang, “Paddlepaddle: An open-source deep learning
platform from industrial practice,” <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Frontiers of Data and Domputing</em>,
vol. 1, no. 1, pp. 105–115, 2019.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
[Online; Accessed January 7, 2021;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/PaddlePaddle/PaddleFL</span>

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan,
“Adaptive federated learning in resource constrained edge computing
systems,” <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, vol. 37,
no. 6, pp. 1205–1221, June 2019.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
A. Feraudo, P. Yadav, V. Safronov, D. A. Popescu, R. Mortier, S. Wang,
P. Bellavista, and J. Crowcroft, “Colearn: enabling federated learning in
mud-compliant iot edge networks,” in <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Third ACM International Workshop
on Edge Systems, Analytics and Networking</em>, Heraklion, Greece, April 2020,
pp. 25–30.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Z. Zhao, C. Feng, H. H. Yang, and X. Luo, “Federated-learning-enabled
intelligent fog radio access networks: Fundamental theory, key techniques,
and future trends,” <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless Communications</em>, vol. 27, no. 2, pp.
22–28, April 2020.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Y. Qu, L. Gao, T. H. Luan, Y. Xiang, S. Yu, B. Li, and G. Zheng,
“Decentralized privacy using blockchain-enabled federated learning in fog
computing,” <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 7, no. 6, pp.
5171–5183, March 2020.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
B. Liu, L. Wang, and M. Liu, “Lifelong federated reinforcement learning: a
learning architecture for navigation in cloud robotic systems,” <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">IEEE
Robotics and Automation Letters</em>, vol. 4, no. 4, pp. 4555–4562, July 2019.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
P. Yu and Y. Liu, “Federated object detection: Optimizing object detection
model with federated learning,” in <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on
Vision, Image and Signal Processing</em>, Vancouver, BC, Canada, August 2019, pp.
1–6.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, Y. Zou, Y. Zhang, and M. Guizani, “Reliable
federated learning for mobile networks,” <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, no. 2, pp. 72–80, April 2020.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
D. Conway-Jones, T. Tuor, S. Wang, and K. K. Leung, “Demonstration of
federated learning in a resource-constrained networked environment,” in
<em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Smart Computing</em>, Washington, DC, USA,
June 2019, pp. 484–486.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
S. Savazzi, M. Nicoli, and V. Rampa, “Federated learning with cooperating
devices: A consensus approach for massive iot networks,” <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">IEEE Internet
of Things Journal</em>, vol. 7, no. 5, May 2020.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated transfer
learning framework for wearable healthcare,” <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems,
early access, DOI: 10.1109/MIS.2020.2988604</em>, 2020.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
D. Chen, L. J. Xie, B. Kim, L. Wang, C. S. Hong, L.-C. Wang, and Z. Han,
“Federated learning based mobile edge computing for augmented reality
applications,” in <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">International Conference on Computing, Networking
and Communications</em>, Big Island, Hawaii, USA, February 2020, pp. 767–773.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
D. Ye, R. Yu, M. Pan, and Z. Han, “Federated learning in vehicular edge
computing: A selective model aggregation approach,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 8, pp. 23 920–23 935, January 2020.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Z. Du, C. Wu, T. Yoshinaga, K.-L. A. Yau, Y. Ji, and J. Li, “Federated
learning for vehicular internet of things: Recent advances and open issues,”
<em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">IEEE Computer Graphics and Applications, early access, doi:
10.1109/OJCS.2020.2992630.</em>, 2020.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
J. Wang, S. Wang, R.-R. Chen, and M. Ji, “Local averaging helps: Hierarchical
federated learning and convergence analysis,” <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2010.12998</em>, 2020.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
U. Majeed, L. U. Khan, I. Yaqoob, S. A. Kazmi, K. Salah, and C. S. Hong,
“Blockchain for iot-based smart cities: Recent advances, requirements, and
future challenges,” <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer Applications</em>, p.
103007, 2021.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
A. Gad. Breaking privacy in federated learning. [Online; Accessed March, 2020;.
[Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://heartbeat.fritz.ai/breaking-privacy-in-federated-learning-77fa08ccac9a</span>

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Y. Zhao, J. Zhao, M. Yang, T. Wang, N. Wang, L. Lyu, D. Niyato, and K. Y. Lam,
“Local differential privacy based federated learning for internet of
things,” <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.08856</em>, 2020.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Differentially private
asynchronous federated learning for mobile edge computing in urban
informatics,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, vol. 16,
no. 3, pp. 2134–2143, 2019.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
S. Truex, N. Baracaldo, A. Anwar, T. Steinke, H. Ludwig, R. Zhang, and Y. Zhou,
“A hybrid approach to privacy-preserving federated learning,” in <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">12th
ACM Workshop on Artificial Intelligence and Security</em>, London, UK, November
2019, pp. 1–11.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. Quek, and
H. V. Poor, “Federated learning with differential privacy: Algorithms and
performance analysis,” <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and
Security</em>, 2020.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
A. Girgis, D. Data, S. Diggavi, P. Kairouz, and A. T. Suresh, “Shuffled model
of differential privacy in federated learning,” in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">International
Conference on Artificial Intelligence and Statistics</em>.   PMLR, 2021, pp. 2521–2529.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
N. Phan, X. Wu, H. Hu, and D. Dou, “Adaptive laplace mechanism: Differential
privacy preservation in deep learning,” in <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International
Conference on Data Mining (ICDM)</em>.   IEEE, 2017, pp. 385–394.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
F. McSherry and K. Talwar, “Mechanism design via differential privacy,” in
<em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">48th Annual IEEE Symposium on Foundations of Computer Science
(FOCS’07)</em>.   IEEE, 2007, pp. 94–103.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
C. Ma, J. Li, M. Ding, H. H. Yang, F. Shu, T. Q. Quek, and H. V. Poor, “On
safeguarding privacy and security in the framework of federated learning,”
<em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, 2020.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
C. Dwork, A. Roth <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “The algorithmic foundations of differential
privacy.” <em id="bib.bib112.2.2" class="ltx_emph ltx_font_italic">Foundations and Trends in Theoretical Computer Science</em>,
vol. 9, no. 3-4, pp. 211–407, 2014.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Kaspersky. What is cyber security? [Online; Accessed January 20, 2021;.
[Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.kaspersky.com/resource-center/definitions/what-is-cyber-security</span>

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
CISCO. What is cyber security? [Online; Accessed January 20, 2021;. [Online].
Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.cisco.com/c/en/us/products/security/what-is-cybersecurity.html</span>

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
J.-Y. Lee, W.-C. Lin, and Y.-H. Huang, “A lightweight authentication protocol
for internet of things,” in <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">2014 International Symposium on
Next-Generation Electronics (ISNE)</em>, Mashhad, Iran, 2014, pp. 1–2.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
E. Lara, L. Aguilar, M. A. Sanchez, and J. A. García, “Lightweight
authentication protocol for m2m communications of resource-constrained
devices in industrial internet of things,” <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20, no. 2,
p. 501, January 2020.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
S. Arasteh, S. F. Aghili, and H. Mala, “A new lightweight authentication and
key agreement protocol for internet of things,” in <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">13th International
Iranian Society of Cryptology Conference on Information Security and
Cryptology</em>, November 2016, pp. 52–59.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
A. Haenel, Y. Haddad, and Z. Zhang, “Lightweight authentication scheme
for internet of things,” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">IEEE Annual Consumer Communications
Networking Conference</em>, London, UK, June 2020, pp. 1–2.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
J. Han and J. Kim, “A lightweight authentication mechanism between iot
devices,” in <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">International Conference on Information and Communication
Technology Convergence</em>, Jeju, South Korea, December 2017, pp. 1153–1155.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
S. Kaushik and C. Gandhi, “Cloud computing security: attacks, threats, risk
and solutions,” <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">International Journal of Networking and Virtual
Organisations</em>, vol. 19, no. 1, pp. 50–71, July 2018.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
H. Li, F. Li, C. Song, and Y. Yan, “Towards smart card based mutual
authentication schemes in cloud computing.” <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">KSII Transactions on
Internet and Information Systems</em>, vol. 9, no. 7, pp. 2719–2735, July 2015.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Q. Jiang, J. Ma, and F. Wei, “On the security of a privacy-aware
authentication scheme for distributed mobile cloud computing services,”
<em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">IEEE systems journal</em>, vol. 12, no. 2, pp. 2039–2042, June 2016.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
L. Barreto, A. Celesti, M. Villari, M. Fazio, and A. Puliafito, “Security and
iot cloud federation: Design of authentication schemes,” in
<em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">International Internet of Things Summit</em>, Rome, Italy, October 2015,
pp. 337–346.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
X. Zhang, X. Zhu, J. Wang, H. Yan, H. Chen, and W. Bao, “Federated learning
with adaptive communication compression under dynamic bandwidth and
unreliable networks,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em>, vol. 540, November 2020.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
S. Niknam, H. S. Dhillon, and J. H. Reed, “Federated learning for wireless
communications: Motivation, opportunities, and challenges,” <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">IEEE
Communications Magazine</em>, vol. 58, no. 6, pp. 46–51, June 2020.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
A. Nagar, “Privacy-preserving blockchain based federated learning with
differential data sharing,” <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04859</em>, 2019.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
X. Qu, S. Wang, Q. Hu, and X. Cheng, “Proof of federated learning: A novel
energy-recycling consensus algorithm,” <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1912.11745</em>, 2019.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
S. Jere, Q. Fan, B. Shang, L. Li, and L. Liu, “Federated learning in mobile
edge computing: An edge-learning perspective for beyond 5G,” <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2007.08030</em>, 2020.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
Y. Zhan, P. Li, and S. Guo, “Experience-driven computational resource
allocation of federated learning by deep reinforcement learning,” in
<em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Proc. of IPDPS</em>, New Orleans, LA, USA, USA, July 2020, pp. 18–22.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui,
“Performance optimization of federated learning over wireless networks,” in
<em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">IEEE Global Communications Conference</em>, Hilton Waikoloa Village, Puako,
Hawaii, United States, December 2019, pp. 1–6.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
A. Ndikumana, N. H. Tran, T. M. Ho, Z. Han, W. Saad, D. Niyato, and C. S. Hong,
“Joint communication, computation, caching, and control in big data
multi-access edge computing,” <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>,
vol. 19, no. 6, pp. 1359–1374, March 2019.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
S. R. Pandey, N. H. Tran, M. Bennis, Y. K. Tun, A. Manzoor, and C. S.
Hong, “A crowdsourcing framework for on-device federated learning,”
<em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless Communications</em>, vol. 19, no. 5, pp.
3241–3256, May 2020.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
H. Kim, J. Park, M. Bennis, and S. Kim, “Blockchained on-device
federated learning,” <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol. 24, no. 6, pp.
1279–1283, June 2020.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
M. M. Wadu, S. Samarakoon, and M. Bennis, “Federated learning under channel
uncertainty: Joint client scheduling and resource allocation,” <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2002.00802</em>, 2020.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, D. Ramage, and P. Richtárik,
“Federated optimization: Distributed machine learning for on-device
intelligence,” <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.02527</em>, 2016.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
J. Konečnỳ, Z. Qu, and P. Richtárik, “Semi-stochastic coordinate
descent,” <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">optimization Methods and Software</em>, vol. 32, no. 5, pp.
993–1005, March 2017.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
F. Ang, L. Chen, N. Zhao, Y. Chen, W. Wang, and F. R. Yu, “Robust federated
learning with noisy communication,” <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Communications</em>, vol. 68, no. 6, March 2020.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
T. H. T. Le, N. H. Tran, Y. K. Tun, Z. Han, and C. S. Hong, “Auction based
incentive design for efficient federated learning in cellular wireless
networks,” in <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless Communications and Networking Conference</em>,
Seoul, South Korea, June 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang, “Incentive
mechanism for reliable federated learning: A joint optimization approach to
combining reputation and contract theory,” <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Journal</em>, vol. 6, no. 6, pp. 10 700–10 714, September 2019.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
P. K. Sharma, J. H. Park, and K. Cho, “Blockchain and federated learning-based
distributed computing defence framework for sustainable society,”
<em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Sustainable Cities and Society</em>, pp. 1–9, August 2020.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
G. Lee, J. Park, W. Saad, and M. Bennis, “Performance analysis of blockchain
systems with wireless mobile miners,” <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">IEEE Networking Letters</em>,
vol. 2, May 2020.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
T. Alladi, V. Chamola, N. Sahu, and M. Guizani, “Applications of blockchain in
unmanned aerial vehicles: A review,” <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">Vehicular Communications</em>,
vol. 23, pp. 1–24, June 2020.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
T. Zeng, O. Semiari, M. Mozaffari, M. Chen, W. Saad, and M. Bennis, “Federated
learning in the sky: Joint power allocation and scheduling with UAV
swarms,” <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.08196</em>, 2020.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
R. Fan, J. Cui, S. Jin, K. Yang, and J. An, “Optimal node placement and
resource allocation for UAV relaying network,” <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">IEEE Communications
Letters</em>, vol. 22, no. 4, pp. 808–811, April 2018.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
M. Mozaffari, A. T. Z. Kasgari, W. Saad, M. Bennis, and M. Debbah, “Beyond
5G with UAVs: Foundations of a 3d wireless cellular network,” <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol. 18, no. 1, pp. 357–372,
January 2018.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
M. Mozaffari, W. Saad, M. Bennis, Y.-H. Nam, and M. Debbah, “A tutorial on
UAVs for wireless networks: Applications, challenges, and open problems,”
<em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>, vol. 21, no. 3, pp.
2334–2360, March 2019.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konečnỳ, S. Mazzocchi, H. B. McMahan <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Towards federated learning at scale: System design,” <em id="bib.bib147.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1902.01046</em>, 2019.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
Y. Park, H. Yang, T. Dinh, and Y. Kim, “Design and implementation of a
container-based virtual client architecture for interactive digital signage
systems,” <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">International Journal of Distributed Sensor Networks</em>,
vol. 13, no. 7, pp. 1–14, July 2017.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
S. Wu, C. Niu, J. Rao, H. Jin, and X. Dai, “Container-based cloud platform for
mobile computation offloading,” in <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">IEEE international parallel and
distributed processing symposium</em>, Orlando, FL, USA, July 2017, pp. 123–132.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
H. Kang, M. Le, and S. Tao, “Container and microservice driven design for
cloud infrastructure DeVops,” in <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on
Cloud Engineering (IC2E)</em>, Berlin, Germany, June 2016, pp. 202–211.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
Z. Zhong, K. Chen, X. Zhai, and S. Zhou, “Virtual machine-based task
scheduling algorithm in a cloud computing environment,” <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Tsinghua
Science and Technology</em>, vol. 21, no. 6, pp. 660–667, December 2016.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
H. A. Lagar-Cavilla, J. A. Whitney, A. M. Scannell, P. Patchin, S. M. Rumble,
E. De Lara, M. Brudno, and M. Satyanarayanan, “Snowflock: rapid virtual
machine cloning for cloud computing,” in <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">4th ACM European conference
on Computer systems</em>, Nuremberg Germany, April 2009, pp. 1–12.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task
learning,” in <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, Long
Beach, CA, USA, December 2017, pp. 4424–4434.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
X. Liang, Y. Liu, T. Chen, M. Liu, and Q. Yang, “Federated transfer
reinforcement learning for autonomous driving,” <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1910.06001</em>, 2019.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
I. Yaqoob, L. U. Khan, S. A. Kazmi, M. Imran, N. Guizani, and C. S. Hong,
“Autonomous driving cars in smart cities: Recent advances, requirements, and
challenges,” <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 34, no. 1, pp. 174–181, 2019.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in
<em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">IEEE conference on computer vision and pattern recognition</em>, Boston,
USA, June 2015, pp. 1–9.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
V. Sze, Y.-H. Chen, J. Emer, A. Suleiman, and Z. Zhang, “Hardware for machine
learning: Challenges and opportunities,” in <em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">IEEE Custom Integrated
Circuits Conference</em>, Texas, USA, March 2017, pp. 1–8.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
M. Horowitz, “1.1 computing’s energy problem (and what we can do about it),”
in <em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">IEEE International Solid-State Circuits Conference Digest of
Technical Papers</em>, March, March 2014, pp. 10–14.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
L. Ceze, M. D. Hill, and T. F. Wenisch, “Arch2030: A vision of computer
architecture research over the next 15 years,” <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1612.03182</em>, 2016.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates,
S. Bhatia, N. Boden, A. Borchers <em id="bib.bib160.2.2" class="ltx_emph ltx_font_italic">et al.</em>, “In-datacenter performance
analysis of a tensor processing unit,” in <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic"><math id="bib.bib160.1.1.m1.1" class="ltx_Math" alttext="44^{th}" display="inline"><semantics id="bib.bib160.1.1.m1.1a"><msup id="bib.bib160.1.1.m1.1.1" xref="bib.bib160.1.1.m1.1.1.cmml"><mn id="bib.bib160.1.1.m1.1.1.2" xref="bib.bib160.1.1.m1.1.1.2.cmml">44</mn><mrow id="bib.bib160.1.1.m1.1.1.3" xref="bib.bib160.1.1.m1.1.1.3.cmml"><mi id="bib.bib160.1.1.m1.1.1.3.2" xref="bib.bib160.1.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="bib.bib160.1.1.m1.1.1.3.1" xref="bib.bib160.1.1.m1.1.1.3.1.cmml">​</mo><mi id="bib.bib160.1.1.m1.1.1.3.3" xref="bib.bib160.1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="bib.bib160.1.1.m1.1b"><apply id="bib.bib160.1.1.m1.1.1.cmml" xref="bib.bib160.1.1.m1.1.1"><csymbol cd="ambiguous" id="bib.bib160.1.1.m1.1.1.1.cmml" xref="bib.bib160.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="bib.bib160.1.1.m1.1.1.2.cmml" xref="bib.bib160.1.1.m1.1.1.2">44</cn><apply id="bib.bib160.1.1.m1.1.1.3.cmml" xref="bib.bib160.1.1.m1.1.1.3"><times id="bib.bib160.1.1.m1.1.1.3.1.cmml" xref="bib.bib160.1.1.m1.1.1.3.1"></times><ci id="bib.bib160.1.1.m1.1.1.3.2.cmml" xref="bib.bib160.1.1.m1.1.1.3.2">𝑡</ci><ci id="bib.bib160.1.1.m1.1.1.3.3.cmml" xref="bib.bib160.1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib160.1.1.m1.1c">44^{th}</annotation></semantics></math> Annual
International Symposium on Computer Architecture</em>, June 2017, pp. 1–12.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
R. G. Kim, J. R. Doppa, and P. P. Pande, “Machine learning for design space
exploration and optimization of manycore systems,” in <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM
International Conference on Computer-Aided Design</em>, San Deigo, USA, November
2018, pp. 1–6.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, L.-J. Li, L. Fei-Fei,
A. Yuille, J. Huang, and K. Murphy, “Progressive neural architecture
search,” in <em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</em>, Munich, Germany, September 2018, pp. 19–34.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
H. Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean, “Efficient neural
architecture search via parameter sharing,” <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1802.03268</em>, 2018.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
C. Ying, A. Klein, E. Christiansen, E. Real, K. Murphy, and F. Hutter,
“Nas-bench-101: Towards reproducible neural architecture search,” in
<em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, Long Beach, California,
USA, 2019, pp. 7105–7114.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
M. A. Rahman. Neural architecture search (nas)- the future of deep learning.
[Online; Accessed October June 14, 2020;. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://towardsdatascience.com/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136</span>

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
T. Elsken, J. H. Metzen, and F. Hutter, “Neural architecture search: A
survey,” <em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.05377</em>, 2018.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and
B. Thorne, “Private federated learning on vertically partitioned data via
entity resolution and additively homomorphic encryption,” <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1711.10677</em>, 2017.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
C. Borrego, M. Amadeo, A. Molinaro, and R. H. Jhaveri, “Privacy-preserving
forwarding using homomorphic encryption for information-centric wireless ad
hoc networks,” <em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol. 23, no. 10, pp.
1708–1711, July 2019.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
X. Li, D. Chen, C. Li, and L. Wang, “Secure data aggregation with fully
homomorphic encryption in large-scale wireless sensor networks,”
<em id="bib.bib169.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 15, no. 7, pp. 15 952–15 973, July 2015.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
R. Shrestha and S. Kim, “Integration of iot with blockchain and homomorphic
encryption: Challenging issues and opportunities,” in <em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">Advances in
Computers</em>, July 2019, vol. 115, pp. 293–331.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
T. Lepoint and M. Naehrig, “A comparison of the homomorphic encryption schemes
fv and yashe,” in <em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">International Conference on Cryptology in Africa</em>,
Marrakesh, Morocco, May 2014, pp. 318–335.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for
privacy-preserving machine learning,” in <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security</em>, CA, USA, December
2017, pp. 1175–1191.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
A. K. Bairagi, M. S. Munir, M. Alsenwi, N. H. Tran, and C. S. Hong, “A
matching based coexistence mechanism between embb and urllc in 5G wireless
networks,” in <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">34th ACM/SIGAPP Symposium on Applied Computing</em>, New
York, NY, United States, April 2019, pp. 2377–2384.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
Q.-V. Pham, T. Leanh, N. H. Tran, B. J. Park, and C. S. Hong, “Decentralized
computation offloading and resource allocation for mobile-edge computing: A
matching game approach,” <em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 6, pp. 75 868–75 885,
November 2018.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
S. A. Kazmi, N. H. Tran, T. M. Ho, and C. S. Hong, “Hierarchical matching game
for service selection and resource purchasing in wireless network
virtualization,” <em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol. 22, no. 1, pp.
121–124, January 2017.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
S. A. Kazmi, N. H. Tran, W. Saad, Z. Han, T. M. Ho, T. Z. Oo, and C. S. Hong,
“Mode selection and resource allocation in device-to-device communications:
A matching game approach,” <em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>,
vol. 16, no. 11, pp. 3126–3141, March 2017.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
N. Shlezinger, M. Chen, Y. C. Eldar, H. V. Poor, and S. Cui, “Uveqfed:
Universal vector quantization for federated learning,” <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2006.03262</em>, 2020.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani,
“Fedpaq: A communication-efficient federated learning method with periodic
averaging and quantization,” in <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial
Intelligence and Statistics</em>, Palermo, Sicily, Italy, August 2020, pp.
2021–2031.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
X. Dai, X. Yan, K. Zhou, K. K. Ng, J. Cheng, and Y. Fan, “Hyper-sphere
quantization: Communication-efficient sgd for federated learning,”
<em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.04655</em>, 2019.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
N. Kato, B. Mao, F. Tang, Y. Kawamoto, and J. Liu, “Ten challenges
in advancing machine learning technologies toward 6G,” <em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, June 2020.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
I. Akyildiz, A. Kak, and S. Nie, “6G and beyond: The future of wireless
communications systems,” <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, July 2020.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
M. Wang, T. Zhu, T. Zhang, J. Zhang, S. Yu, and W. Zhou, “Security and privacy
in 6G networks: new areas and new challenges,” <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">Digital
Communications and Networks, early access,
doi.org/10.1016/j.dcan.2020.07.003</em>, 2020.

</span>
</li>
</ul>
</section>
<figure id="id2" class="ltx_float biography">
<table id="id2.2" class="ltx_tabular">
<tr id="id2.2.2" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td"><img src="/html/2009.13012/assets/latif.jpg" id="id1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="id2.2.2.2" class="ltx_td">
<span id="id2.2.2.2.1" class="ltx_inline-block">
<span id="id2.2.2.2.1.1" class="ltx_p"><span id="id2.2.2.2.1.1.1" class="ltx_text ltx_font_bold">Latif U. Khan</span>  is currently pursuing his Ph.D. degree in Computer Science and Engineering at Kyung Hee University (KHU), South Korea. He is working as a leading researcher in the intelligent Networking Laboratory under a project jointly funded by the prestigious Brain Korea 21st Century Plus and Ministry of Science and ICT, South Korea. He received his MS (Electrical Engineering) degree with distinction from University of Engineering and Technology (UET), Peshawar, Pakistan in 2017. Prior to joining the KHU, he has served as a faculty member and research associate in the UET, Peshawar, Pakistan. He has published his works in highly reputable conferences and journals. He is the author/co-author of two conference best paper awards. He is also author of two books, such as ”Network Slicing for <math id="id2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="id2.2.2.2.1.1.m1.1a"><mn id="id2.2.2.2.1.1.m1.1.1" xref="id2.2.2.2.1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="id2.2.2.2.1.1.m1.1b"><cn type="integer" id="id2.2.2.2.1.1.m1.1.1.cmml" xref="id2.2.2.2.1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.2.1.1.m1.1c">5</annotation></semantics></math>G and Beyond Networks” and ”Federated Learning for Wireless Networks”. His research interests include analytical techniques of optimization and game theory to edge computing, end-to-end network slicing, and federated learning for wireless networks.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id3" class="ltx_float biography">
<table id="id3.1" class="ltx_tabular">
<tr id="id3.1.1" class="ltx_tr">
<td id="id3.1.1.1" class="ltx_td"><img src="/html/2009.13012/assets/walid_saad.jpg" id="id3.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="81" height="125" alt="[Uncaptioned image]"></td>
<td id="id3.1.1.2" class="ltx_td">
<span id="id3.1.1.2.1" class="ltx_inline-block">
<span id="id3.1.1.2.1.1" class="ltx_p"><span id="id3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Walid Saad </span>  (S’07, M’10, SM’15, F’19) received the Ph.D. degree from the University of Oslo, Oslo, Norway, in 2010.,He is currently a Professor with the Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA, where he leads the Network sciEnce, Wireless, and Security (NEWS) Laboratory. His research interests include wireless networks, machine learning, game theory, security, unmanned aerial vehicles (UAV), cyber-physical systems, and network science.,Dr. Saad was named the Stephen O. Lane Junior Faculty Fellow at Virginia Tech, from 2015 to 2017. In 2017, he was named as the College of Engineering Faculty Fellow. He was a recipient of the NSF CAREER Award in 2013, the Air Force Office of Scientific Research (AFOSR) Summer Faculty Fellowship in 2014, and the Young Investigator Award from the Office of Naval Research (ONR) in 2015. He was the author/coauthor of eight conference best paper awards at WiOpt in 2009, the International Conference on Internet Monitoring and Protection (ICIMP) in 2010, the IEEE Wireless Communications and Networking Conference (WCNC) in 2012, the IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) in 2015, IEEE SmartGridComm in 2015, EuCNC in 2017, IEEE GLOBECOM in 2018, and the International Federation for Information Processing (IFIP) International Conference on New Technologies, Mobility and Security (NTMS) in 2019. He was also a recipient of the 2015 Fred W. Ellersick Prize from the IEEE Communications Society, the 2017 IEEE ComSoc Best Young Professional in Academia award, the 2018 IEEE ComSoc Radio Communications Committee Early Achievement Award, and the 2019 IEEE ComSoc Communication Theory Technical Committee. He received the Dean’s Award for Research Excellence from Virginia Tech in 2019. He also serves as an Editor for the IEEE Transactions on Wireless Communications, the IEEE Transactions on Mobile Computing, and the IEEE Transactions on Cognitive Communications and Networking. He is also an Editor-at-Large for the IEEE Transactions on Communications. He is also an IEEE Distinguished Lecturer. (Based on document published on 18 May 2020).</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id4" class="ltx_float biography">
<table id="id4.1" class="ltx_tabular">
<tr id="id4.1.1" class="ltx_tr">
<td id="id4.1.1.1" class="ltx_td"><img src="/html/2009.13012/assets/Zhu_han.jpg" id="id4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="94" height="125" alt="[Uncaptioned image]"></td>
<td id="id4.1.1.2" class="ltx_td">
<span id="id4.1.1.2.1" class="ltx_inline-block">
<span id="id4.1.1.2.1.1" class="ltx_p"><span id="id4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Zhu Han</span> (S’01, M’04, SM’09, F’14) received the B.S. degree in electronic engineering from Tsinghua University, in 1997, and the M.S. and Ph.D. degrees in electrical and computer engineering from the University of Maryland, College Park, in 1999 and 2003, respectively.</span>
<span id="id4.1.1.2.1.2" class="ltx_p">From 2000 to 2002, he was an R&amp;D Engineer of JDSU, Germantown, Maryland. From 2003 to 2006, he was a Research Associate at the University of Maryland. From 2006 to 2008, he was an assistant professor at Boise State University, Idaho. Currently, he is a John and Rebecca Moores Professor in the Electrical and Computer Engineering Department as well as in the Computer Science Department at the University of Houston, Texas. His research interests include wireless resource allocation and management, wireless communications and networking, game theory, big data analysis, security, and smart grid. Dr. Han received an NSF Career Award in 2010, the Fred W. Ellersick Prize of the IEEE Communication Society in 2011, the EURASIP Best Paper Award for the Journal on Advances in Signal Processing in 2015, IEEE Leonard G. Abraham Prize in the field of Communications Systems (best paper award in IEEE JSAC) in 2016, and several best paper awards in IEEE conferences. Dr. Han was an IEEE Communications Society Distinguished Lecturer from 2015-2018, AAAS fellow since 2019 and ACM distinguished Member since 2019. Dr. Han is 1% highly cited researcher since 2017 according to Web of Science. Dr. Han is also the winner of 2021 IEEE Kiyo Tomiyasu Award, for outstanding early to mid-career contributions to technologies holding the promise of innovative applications, with the following citation: ”for contributions to game theory and distributed management of autonomous communication networks.”</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id5" class="ltx_float biography">
<table id="id5.1" class="ltx_tabular">
<tr id="id5.1.1" class="ltx_tr">
<td id="id5.1.1.1" class="ltx_td"><img src="/html/2009.13012/assets/ekram.jpg" id="id5.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="95" height="125" alt="[Uncaptioned image]"></td>
<td id="id5.1.1.2" class="ltx_td">
<span id="id5.1.1.2.1" class="ltx_inline-block">
<span id="id5.1.1.2.1.1" class="ltx_p"><span id="id5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Ekram Hossain</span> (F’15) is a Professor in the Department of Electrical and Computer Engineering at University of Manitoba, Canada (<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://home.cc.umanitoba.ca/~hossaina/</span>). He is a Member (Class of 2016) of the College of the Royal Society of Canada, a Fellow of the Canadian Academy of Engineering, and a Fellow of the Engineering Institute of Canada. He was elevated to an IEEE Fellow “for contributions to spectrum management and resource allocation in cognitive and cellular radio networks”. He was listed as a Clarivate Analytics Highly Cited Researcher in Computer Science in 2017, 2018, 2019, and 2020. Currently he serves as the Editor-in-Chief of IEEE Press. Previously he served as the Editor-in-Chief for the IEEE Communications Surveys and Tutorials (2012–2016).</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id6" class="ltx_float biography">
<table id="id6.1" class="ltx_tabular">
<tr id="id6.1.1" class="ltx_tr">
<td id="id6.1.1.1" class="ltx_td"><img src="/html/2009.13012/assets/CS_Hong.jpg" id="id6.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="id6.1.1.2" class="ltx_td">
<span id="id6.1.1.2.1" class="ltx_inline-block">
<span id="id6.1.1.2.1.1" class="ltx_p"><span id="id6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Choong Seon Hong</span>  (S’95-M’97-SM’11) received the B.S. and M.S. degrees in electronic engineering from Kyung Hee University, Seoul, South Korea, in 1983 and 1985, respectively, and the Ph.D. degree from Keio University, Tokyo, Japan, in 1997. In 1988, he joined KT, Gyeonggi-do, South Korea, where he was involved in broadband networks as a member of the Technical Staff. Since 1993, he has been with Keio University. He was with the Telecommunications Network Laboratory, KT, as a Senior Member of Technical Staff and as the Director of the Networking Research Team until 1999. Since 1999, he has been a Professor with the Department of Computer Science and Engineering, Kyung Hee University. His research interests include future Internet, intelligent edge computing, network management, and network security.
Dr. Hong is a member of the Association for Computing Machinery (ACM), the Institute of Electronics, Information and Communication Engineers (IEICE), the Information Processing Society of Japan (IPSJ), the Korean Institute of Information Scientists and Engineers (KIISE), the Korean Institute of Communications and Information Sciences (KICS), the Korean Information Processing Society (KIPS), and the Open Standards and ICT Association (OSIA). He has served as the General Chair, the TPC Chair/Member, or an Organizing Committee Member of international
conferences, such as the Network Operations and Management Symposium (NOMS), International Symposium on Integrated Network Management (IM), Asia-Pacific Network Operations and Management Symposium (APNOMS), End-to-End Monitoring Techniques and Services (E2EMON), IEEE Consumer Communications and Networking Conference (CCNC), Assurance in Distributed Systems and Networks (ADSN), International Conference on Parallel Processing (ICPP), Data Integration and Mining (DIM), World Conference on Information Security Applications (WISA), Broadband Convergence Network (BcN), Telecommunication Information Networking Architecture (TINA), International Symposium on Applications and the Internet (SAINT), and International Conference on Information Networking (ICOIN). He was an Associate Editor of the IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT and the IEEE JOURNAL OF COMMUNICATIONS AND NETWORKS. He currently serves as an Associate Editor for the International Journal of Network Management.</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2009.13011" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2009.13012" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2009.13012">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2009.13012" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2009.13013" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 09:06:59 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
