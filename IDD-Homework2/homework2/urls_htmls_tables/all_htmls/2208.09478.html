<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.09478] Federated Learning of Neural ODE Models with Different Iteration Counts</title><meta property="og:description" content="Federated learning is a distributed machine learning approach in which
clients train models locally with their own data and upload them to a
server so that their trained results are shared between them without
uploadinâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning of Neural ODE Models with Different Iteration Counts">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning of Neural ODE Models with Different Iteration Counts">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.09478">

<!--Generated on Wed Mar 13 19:46:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning of Neural ODE Models with Different Iteration Counts</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yuto Hoshino
<br class="ltx_break">Keio University
<br class="ltx_break">3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Japan
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">hoshino@arc.ics.keio.ac.jp
<br class="ltx_break"></span>&amp;Hiroki Kawakami
<br class="ltx_break">Keio University
<br class="ltx_break">3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Japan
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">kawakami@arc.ics.keio.ac.jp
<br class="ltx_break"></span>&amp;Hiroki Matsutani 
<br class="ltx_break">Keio University
<br class="ltx_break">3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Japan
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">matutani@arc.ics.keio.ac.jp</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Federated learning is a distributed machine learning approach in which
clients train models locally with their own data and upload them to a
server so that their trained results are shared between them without
uploading raw data to the server.
There are some challenges in federated learning, such as communication
size reduction and client heterogeneity.
The former can mitigate the communication overheads, and the latter
can allow the clients to choose proper models depending on their
available compute resources.
To address these challenges, in this paper, we utilize Neural ODE
based models for federated learning.
The proposed flexible federated learning approach can reduce the
communication size while aggregating models with different iteration
counts or depths.
Our contribution is that we experimentally demonstrate that the
proposed federated learning can aggregate models with different
iteration counts or depths.
It is compared with a different federated learning approach in terms
of the accuracy.
Furthermore, we show that our approach can reduce communication size
by up to 92.4% compared with a baseline ResNet model using CIFAR-10
dataset.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.2" class="ltx_p"><em id="p1.2.1" class="ltx_emph ltx_font_bold ltx_font_italic">K</em><span id="p1.2.2" class="ltx_text ltx_font_bold">eywords</span>â€‚Federated Learning Â <math id="p1.1.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\cdot</annotation></semantics></math>
Neural networks Â <math id="p1.2.m2.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">\cdot</annotation></semantics></math>
Neural ODE</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">In traditional cloud-based machine learning systems, sending personal
data to cloud servers has become problematic from a privacy
perspective.
Federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is a distributed machine learning
approach that can keep privacy-sensitive raw data decentralized.
In the federated learning, clients receive a model from the server.
Then they train the model with their own data and upload trained
parameters to the server.
The server aggregates the trained parameters received from the clients
and sends back the aggregated parameters to the clients.
These steps are repeated until the training process is converged.
This eliminates the need to upload privacy-sensitive raw data to the
server.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">However, there are some challenges in the federated learning, such as
communication size reduction and client heterogeneity.
Communication size affects communication delay and power
consumption of clients.
It is affected by the machine learning model size.
Regarding the client heterogeneity, not all clients always have the
same hardware, compute resources, or training data.
A client may use a deeper model for high accuracy, while another
client may use a shallower model to reduce the computation cost.
In this paper, we exploit Neural ODE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> as a federated
learning model to address these challenges.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">For image recognition tasks, one of methods to improve accuracy is
increasing the number of convolutional layers to build a deeper neural
network.
ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is one of well-known CNN models that stack many
residual blocks that contain convolutional layers and shortcut
connections.
Neural ODE utilizes a similarity to ODE (Ordinary Differential
Equation) to implement deep neural networks consisting of residual
blocks.
Since it can be approximated to a ResNet model by repeatedly using the
same weight parameters, it can reduce the weight parameters.
In addition, it can be approximated to ResNet models with different
depths by changing the iteration counts without increasing the number
of parameters.
dsODENet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> is a lightweight model that combines the ideas
of Neural ODE and depthwise separable convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> to
further reduce the parameter size and computation cost.
These Neural ODE models are smaller than ResNet.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we introduce a flexible federated learning that allows
clients to use models with different iteration counts and reduces the
communication size by using Neural ODE based models.
Our contributions are listed below
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>An early stage of this work appeared in our workshop paper
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
In this paper, we experimentally demonstrate that the proposed
approach can aggregate models with different iteration counts.
It is compared to a federated learning approach that uses knowledge
distillation.</span></span></span>.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose to use the Neural ODE models for federated learning so
that a server can aggregate models with different iteration counts.
This can enhance the client heterogeneity since clients can use
models with different iteration counts.
In addition, using the Neural ODE models can significantly reduce
the communication size.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i2.p1.1" class="ltx_p">We experimentally demonstrate that the proposed flexible
federated learning can aggregate these models with different
iteration counts.
It is compared with a federated learning approach that uses
knowledge distillation.
We discuss the pros and cons of the proposed approach.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">The rest of this paper is organized as follows.
Section <a href="#S2" title="2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> introduces baseline technologies behind our
proposal.
Section <a href="#S3" title="3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> proposes the flexible federated learning
approach and shows the feasibility of the proposed approach.
Section <a href="#S4" title="4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> evaluates the proposed approach in terms of the
accuracy and communication size.
Section <a href="#S5" title="5 Conclusions â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> concludes this paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.17" class="ltx_p">Federated Averaging (FedAvg) is a basic federated learning algorithm
proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
Algorithm <a href="#alg1" title="Algorithm 1 â€£ 2.1 Federated Learning â€£ 2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the server- and
client-side flows, where <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">K</annotation></semantics></math> is the total number of clients, <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">k</annotation></semantics></math>
is their index, and <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{P}_{k}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">ğ’«</mi><mi id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">ğ’«</ci><ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathcal{P}_{k}</annotation></semantics></math> is data at client <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">k</annotation></semantics></math>.
Also, <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">B</annotation></semantics></math> is the size of a local mini-batch, <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">E</annotation></semantics></math> is the number of
epochs to be trained by each client, and <math id="S2.SS1.p1.7.m7.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SS1.p1.7.m7.1a"><mi id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml">Î·</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><ci id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">ğœ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">\eta</annotation></semantics></math> is a given learning
rate.
In this algorithm, the first step is to initialize global weight
parameters of the model.
Then, <math id="S2.SS1.p1.8.m8.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p1.8.m8.1a"><mi id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><ci id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">m</annotation></semantics></math> clients are randomly selected from <math id="S2.SS1.p1.9.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">K</annotation></semantics></math> clients, and the
server sends the global parameters to the selected clients.
The size of <math id="S2.SS1.p1.10.m10.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.p1.10.m10.1a"><mi id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.1b"><ci id="S2.SS1.p1.10.m10.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.1c">m</annotation></semantics></math> is determined by a client fraction parameter <math id="S2.SS1.p1.11.m11.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.11.m11.1a"><mi id="S2.SS1.p1.11.m11.1.1" xref="S2.SS1.p1.11.m11.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m11.1b"><ci id="S2.SS1.p1.11.m11.1.1.cmml" xref="S2.SS1.p1.11.m11.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m11.1c">C</annotation></semantics></math>.
The weight parameters are updated at each epoch (<math id="S2.SS1.p1.12.m12.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.SS1.p1.12.m12.1a"><mi id="S2.SS1.p1.12.m12.1.1" xref="S2.SS1.p1.12.m12.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.12.m12.1b"><ci id="S2.SS1.p1.12.m12.1.1.cmml" xref="S2.SS1.p1.12.m12.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.12.m12.1c">E</annotation></semantics></math> epochs in total)
by each client based on the formula in line <a href="#alg1.l13" title="In Algorithm 1 â€£ 2.1 Federated Learning â€£ 2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.
After <math id="S2.SS1.p1.13.m13.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.SS1.p1.13.m13.1a"><mi id="S2.SS1.p1.13.m13.1.1" xref="S2.SS1.p1.13.m13.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.13.m13.1b"><ci id="S2.SS1.p1.13.m13.1.1.cmml" xref="S2.SS1.p1.13.m13.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.13.m13.1c">E</annotation></semantics></math> updates, the clients send their trained local parameters to
the server.
The server aggregates the received local parameters by taking the
average based on the formula in line <a href="#alg1.l8" title="In Algorithm 1 â€£ 2.1 Federated Learning â€£ 2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, where <math id="S2.SS1.p1.14.m14.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS1.p1.14.m14.1a"><mi id="S2.SS1.p1.14.m14.1.1" xref="S2.SS1.p1.14.m14.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.14.m14.1b"><ci id="S2.SS1.p1.14.m14.1.1.cmml" xref="S2.SS1.p1.14.m14.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.14.m14.1c">n</annotation></semantics></math> is
the total number of data and <math id="S2.SS1.p1.15.m15.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S2.SS1.p1.15.m15.1a"><msub id="S2.SS1.p1.15.m15.1.1" xref="S2.SS1.p1.15.m15.1.1.cmml"><mi id="S2.SS1.p1.15.m15.1.1.2" xref="S2.SS1.p1.15.m15.1.1.2.cmml">n</mi><mi id="S2.SS1.p1.15.m15.1.1.3" xref="S2.SS1.p1.15.m15.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.15.m15.1b"><apply id="S2.SS1.p1.15.m15.1.1.cmml" xref="S2.SS1.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.15.m15.1.1.1.cmml" xref="S2.SS1.p1.15.m15.1.1">subscript</csymbol><ci id="S2.SS1.p1.15.m15.1.1.2.cmml" xref="S2.SS1.p1.15.m15.1.1.2">ğ‘›</ci><ci id="S2.SS1.p1.15.m15.1.1.3.cmml" xref="S2.SS1.p1.15.m15.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.15.m15.1c">n_{k}</annotation></semantics></math> is the total number of data at
client <math id="S2.SS1.p1.16.m16.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p1.16.m16.1a"><mi id="S2.SS1.p1.16.m16.1.1" xref="S2.SS1.p1.16.m16.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.16.m16.1b"><ci id="S2.SS1.p1.16.m16.1.1.cmml" xref="S2.SS1.p1.16.m16.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.16.m16.1c">k</annotation></semantics></math>.
The aggregated parameters are then sent back to the clients as global
parameters.
The above steps are repeated <math id="S2.SS1.p1.17.m17.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.17.m17.1a"><mi id="S2.SS1.p1.17.m17.1.1" xref="S2.SS1.p1.17.m17.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.17.m17.1b"><ci id="S2.SS1.p1.17.m17.1.1.cmml" xref="S2.SS1.p1.17.m17.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.17.m17.1c">t</annotation></semantics></math> rounds.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Federated Averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite></figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1:</span><span id="alg1.l1.1" class="ltx_text ltx_font_bold">function</span>Â ExecuteServer(<span id="alg1.l1.2" class="ltx_text"></span>)

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2:</span>Â Â Â Initialize <math id="alg1.l2.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">w</mi><mn id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">ğ‘¤</ci><cn type="integer" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">w_{0}</annotation></semantics></math>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3:</span>Â Â Â <span id="alg1.l3.1" class="ltx_text ltx_font_bold">for each</span>Â round <math id="alg1.l3.m1.3" class="ltx_Math" alttext="t=1,2,\ldots" display="inline"><semantics id="alg1.l3.m1.3a"><mrow id="alg1.l3.m1.3.4" xref="alg1.l3.m1.3.4.cmml"><mi id="alg1.l3.m1.3.4.2" xref="alg1.l3.m1.3.4.2.cmml">t</mi><mo id="alg1.l3.m1.3.4.1" xref="alg1.l3.m1.3.4.1.cmml">=</mo><mrow id="alg1.l3.m1.3.4.3.2" xref="alg1.l3.m1.3.4.3.1.cmml"><mn id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">1</mn><mo id="alg1.l3.m1.3.4.3.2.1" xref="alg1.l3.m1.3.4.3.1.cmml">,</mo><mn id="alg1.l3.m1.2.2" xref="alg1.l3.m1.2.2.cmml">2</mn><mo id="alg1.l3.m1.3.4.3.2.2" xref="alg1.l3.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l3.m1.3.3" xref="alg1.l3.m1.3.3.cmml">â€¦</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.3b"><apply id="alg1.l3.m1.3.4.cmml" xref="alg1.l3.m1.3.4"><eq id="alg1.l3.m1.3.4.1.cmml" xref="alg1.l3.m1.3.4.1"></eq><ci id="alg1.l3.m1.3.4.2.cmml" xref="alg1.l3.m1.3.4.2">ğ‘¡</ci><list id="alg1.l3.m1.3.4.3.1.cmml" xref="alg1.l3.m1.3.4.3.2"><cn type="integer" id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">1</cn><cn type="integer" id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">2</cn><ci id="alg1.l3.m1.3.3.cmml" xref="alg1.l3.m1.3.3">â€¦</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.3c">t=1,2,\ldots</annotation></semantics></math>Â <span id="alg1.l3.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4:</span>Â Â Â Â Â Â <math id="alg1.l4.m1.3" class="ltx_Math" alttext="m\leftarrow\max(r\cdot K,1)" display="inline"><semantics id="alg1.l4.m1.3a"><mrow id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml"><mi id="alg1.l4.m1.3.3.3" xref="alg1.l4.m1.3.3.3.cmml">m</mi><mo stretchy="false" id="alg1.l4.m1.3.3.2" xref="alg1.l4.m1.3.3.2.cmml">â†</mo><mrow id="alg1.l4.m1.3.3.1.1" xref="alg1.l4.m1.3.3.1.2.cmml"><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">max</mi><mo id="alg1.l4.m1.3.3.1.1a" xref="alg1.l4.m1.3.3.1.2.cmml">â¡</mo><mrow id="alg1.l4.m1.3.3.1.1.1" xref="alg1.l4.m1.3.3.1.2.cmml"><mo stretchy="false" id="alg1.l4.m1.3.3.1.1.1.2" xref="alg1.l4.m1.3.3.1.2.cmml">(</mo><mrow id="alg1.l4.m1.3.3.1.1.1.1" xref="alg1.l4.m1.3.3.1.1.1.1.cmml"><mi id="alg1.l4.m1.3.3.1.1.1.1.2" xref="alg1.l4.m1.3.3.1.1.1.1.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.l4.m1.3.3.1.1.1.1.1" xref="alg1.l4.m1.3.3.1.1.1.1.1.cmml">â‹…</mo><mi id="alg1.l4.m1.3.3.1.1.1.1.3" xref="alg1.l4.m1.3.3.1.1.1.1.3.cmml">K</mi></mrow><mo id="alg1.l4.m1.3.3.1.1.1.3" xref="alg1.l4.m1.3.3.1.2.cmml">,</mo><mn id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">1</mn><mo stretchy="false" id="alg1.l4.m1.3.3.1.1.1.4" xref="alg1.l4.m1.3.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.3b"><apply id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3"><ci id="alg1.l4.m1.3.3.2.cmml" xref="alg1.l4.m1.3.3.2">â†</ci><ci id="alg1.l4.m1.3.3.3.cmml" xref="alg1.l4.m1.3.3.3">ğ‘š</ci><apply id="alg1.l4.m1.3.3.1.2.cmml" xref="alg1.l4.m1.3.3.1.1"><max id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"></max><apply id="alg1.l4.m1.3.3.1.1.1.1.cmml" xref="alg1.l4.m1.3.3.1.1.1.1"><ci id="alg1.l4.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.1">â‹…</ci><ci id="alg1.l4.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.2">ğ‘Ÿ</ci><ci id="alg1.l4.m1.3.3.1.1.1.1.3.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.3">ğ¾</ci></apply><cn type="integer" id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.3c">m\leftarrow\max(r\cdot K,1)</annotation></semantics></math>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5:</span>Â Â Â Â Â Â <math id="alg1.l5.m1.1" class="ltx_Math" alttext="S_{t}\leftarrow\text{(random set of $m$ clients)}" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.2" xref="alg1.l5.m1.1.2.cmml"><msub id="alg1.l5.m1.1.2.2" xref="alg1.l5.m1.1.2.2.cmml"><mi id="alg1.l5.m1.1.2.2.2" xref="alg1.l5.m1.1.2.2.2.cmml">S</mi><mi id="alg1.l5.m1.1.2.2.3" xref="alg1.l5.m1.1.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l5.m1.1.2.1" xref="alg1.l5.m1.1.2.1.cmml">â†</mo><mrow id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1c.cmml"><mtext id="alg1.l5.m1.1.1.1a" xref="alg1.l5.m1.1.1.1c.cmml">(random set ofÂ </mtext><mi id="alg1.l5.m1.1.1.1.m1.1.1" xref="alg1.l5.m1.1.1.1.m1.1.1.cmml">m</mi><mtext id="alg1.l5.m1.1.1.1b" xref="alg1.l5.m1.1.1.1c.cmml">Â clients)</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.2.cmml" xref="alg1.l5.m1.1.2"><ci id="alg1.l5.m1.1.2.1.cmml" xref="alg1.l5.m1.1.2.1">â†</ci><apply id="alg1.l5.m1.1.2.2.cmml" xref="alg1.l5.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l5.m1.1.2.2.1.cmml" xref="alg1.l5.m1.1.2.2">subscript</csymbol><ci id="alg1.l5.m1.1.2.2.2.cmml" xref="alg1.l5.m1.1.2.2.2">ğ‘†</ci><ci id="alg1.l5.m1.1.2.2.3.cmml" xref="alg1.l5.m1.1.2.2.3">ğ‘¡</ci></apply><ci id="alg1.l5.m1.1.1.1c.cmml" xref="alg1.l5.m1.1.1.1"><mrow id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"><mtext id="alg1.l5.m1.1.1.1a.cmml" xref="alg1.l5.m1.1.1.1">(random set ofÂ </mtext><mi id="alg1.l5.m1.1.1.1.m1.1.1.cmml" xref="alg1.l5.m1.1.1.1.m1.1.1">m</mi><mtext id="alg1.l5.m1.1.1.1b.cmml" xref="alg1.l5.m1.1.1.1">Â clients)</mtext></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">S_{t}\leftarrow\text{(random set of $m$ clients)}</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6:</span>Â Â Â Â Â Â <span id="alg1.l6.1" class="ltx_text ltx_font_bold">for each</span>Â client <math id="alg1.l6.m1.1" class="ltx_Math" alttext="k\in S_{t}" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">k</mi><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><in id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></in><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">ğ‘˜</ci><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3">subscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">ğ‘†</ci><ci id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">k\in S_{t}</annotation></semantics></math> in parallelÂ <span id="alg1.l6.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7:</span>Â Â Â Â Â Â Â Â Â <math id="alg1.l7.m1.1" class="ltx_Math" alttext="w_{t+1}^{k}\leftarrow" display="inline"><semantics id="alg1.l7.m1.1a"><mrow id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><msubsup id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml"><mi id="alg1.l7.m1.1.1.2.2.2" xref="alg1.l7.m1.1.1.2.2.2.cmml">w</mi><mrow id="alg1.l7.m1.1.1.2.2.3" xref="alg1.l7.m1.1.1.2.2.3.cmml"><mi id="alg1.l7.m1.1.1.2.2.3.2" xref="alg1.l7.m1.1.1.2.2.3.2.cmml">t</mi><mo id="alg1.l7.m1.1.1.2.2.3.1" xref="alg1.l7.m1.1.1.2.2.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.2.2.3.3" xref="alg1.l7.m1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="alg1.l7.m1.1.1.2.3" xref="alg1.l7.m1.1.1.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="alg1.l7.m1.1.1.1" xref="alg1.l7.m1.1.1.1.cmml">â†</mo><mi id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><ci id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1">â†</ci><apply id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.1.cmml" xref="alg1.l7.m1.1.1.2">superscript</csymbol><apply id="alg1.l7.m1.1.1.2.2.cmml" xref="alg1.l7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.2.1.cmml" xref="alg1.l7.m1.1.1.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.2.2.cmml" xref="alg1.l7.m1.1.1.2.2.2">ğ‘¤</ci><apply id="alg1.l7.m1.1.1.2.2.3.cmml" xref="alg1.l7.m1.1.1.2.2.3"><plus id="alg1.l7.m1.1.1.2.2.3.1.cmml" xref="alg1.l7.m1.1.1.2.2.3.1"></plus><ci id="alg1.l7.m1.1.1.2.2.3.2.cmml" xref="alg1.l7.m1.1.1.2.2.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l7.m1.1.1.2.2.3.3.cmml" xref="alg1.l7.m1.1.1.2.2.3.3">1</cn></apply></apply><ci id="alg1.l7.m1.1.1.2.3.cmml" xref="alg1.l7.m1.1.1.2.3">ğ‘˜</ci></apply><csymbol cd="latexml" id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">w_{t+1}^{k}\leftarrow</annotation></semantics></math> ClientUpdate(<math id="alg1.l7.m2.2" class="ltx_Math" alttext="k,w_{t}" display="inline"><semantics id="alg1.l7.m2.2a"><mrow id="alg1.l7.m2.2.2.1" xref="alg1.l7.m2.2.2.2.cmml"><mi id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml">k</mi><mo id="alg1.l7.m2.2.2.1.2" xref="alg1.l7.m2.2.2.2.cmml">,</mo><msub id="alg1.l7.m2.2.2.1.1" xref="alg1.l7.m2.2.2.1.1.cmml"><mi id="alg1.l7.m2.2.2.1.1.2" xref="alg1.l7.m2.2.2.1.1.2.cmml">w</mi><mi id="alg1.l7.m2.2.2.1.1.3" xref="alg1.l7.m2.2.2.1.1.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.2b"><list id="alg1.l7.m2.2.2.2.cmml" xref="alg1.l7.m2.2.2.1"><ci id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1">ğ‘˜</ci><apply id="alg1.l7.m2.2.2.1.1.cmml" xref="alg1.l7.m2.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l7.m2.2.2.1.1.1.cmml" xref="alg1.l7.m2.2.2.1.1">subscript</csymbol><ci id="alg1.l7.m2.2.2.1.1.2.cmml" xref="alg1.l7.m2.2.2.1.1.2">ğ‘¤</ci><ci id="alg1.l7.m2.2.2.1.1.3.cmml" xref="alg1.l7.m2.2.2.1.1.3">ğ‘¡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.2c">k,w_{t}</annotation></semantics></math>)
Â Â Â Â Â Â 
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8:</span>Â Â Â Â Â Â <math id="alg1.l8.m1.1" class="ltx_Math" alttext="w_{t+1}\leftarrow\displaystyle\sum_{k=1}^{K}\frac{n_{k}}{n}w_{t+1}^{k}" display="inline"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><msub id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml"><mi id="alg1.l8.m1.1.1.2.2" xref="alg1.l8.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l8.m1.1.1.2.3" xref="alg1.l8.m1.1.1.2.3.cmml"><mi id="alg1.l8.m1.1.1.2.3.2" xref="alg1.l8.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l8.m1.1.1.2.3.1" xref="alg1.l8.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l8.m1.1.1.2.3.3" xref="alg1.l8.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">â†</mo><mrow id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"><mstyle displaystyle="true" id="alg1.l8.m1.1.1.3.1" xref="alg1.l8.m1.1.1.3.1.cmml"><munderover id="alg1.l8.m1.1.1.3.1a" xref="alg1.l8.m1.1.1.3.1.cmml"><mo movablelimits="false" id="alg1.l8.m1.1.1.3.1.2.2" xref="alg1.l8.m1.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="alg1.l8.m1.1.1.3.1.2.3" xref="alg1.l8.m1.1.1.3.1.2.3.cmml"><mi id="alg1.l8.m1.1.1.3.1.2.3.2" xref="alg1.l8.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="alg1.l8.m1.1.1.3.1.2.3.1" xref="alg1.l8.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="alg1.l8.m1.1.1.3.1.2.3.3" xref="alg1.l8.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l8.m1.1.1.3.1.3" xref="alg1.l8.m1.1.1.3.1.3.cmml">K</mi></munderover></mstyle><mrow id="alg1.l8.m1.1.1.3.2" xref="alg1.l8.m1.1.1.3.2.cmml"><mstyle displaystyle="true" id="alg1.l8.m1.1.1.3.2.2" xref="alg1.l8.m1.1.1.3.2.2.cmml"><mfrac id="alg1.l8.m1.1.1.3.2.2a" xref="alg1.l8.m1.1.1.3.2.2.cmml"><msub id="alg1.l8.m1.1.1.3.2.2.2" xref="alg1.l8.m1.1.1.3.2.2.2.cmml"><mi id="alg1.l8.m1.1.1.3.2.2.2.2" xref="alg1.l8.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="alg1.l8.m1.1.1.3.2.2.2.3" xref="alg1.l8.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="alg1.l8.m1.1.1.3.2.2.3" xref="alg1.l8.m1.1.1.3.2.2.3.cmml">n</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="alg1.l8.m1.1.1.3.2.1" xref="alg1.l8.m1.1.1.3.2.1.cmml">â€‹</mo><msubsup id="alg1.l8.m1.1.1.3.2.3" xref="alg1.l8.m1.1.1.3.2.3.cmml"><mi id="alg1.l8.m1.1.1.3.2.3.2.2" xref="alg1.l8.m1.1.1.3.2.3.2.2.cmml">w</mi><mrow id="alg1.l8.m1.1.1.3.2.3.2.3" xref="alg1.l8.m1.1.1.3.2.3.2.3.cmml"><mi id="alg1.l8.m1.1.1.3.2.3.2.3.2" xref="alg1.l8.m1.1.1.3.2.3.2.3.2.cmml">t</mi><mo id="alg1.l8.m1.1.1.3.2.3.2.3.1" xref="alg1.l8.m1.1.1.3.2.3.2.3.1.cmml">+</mo><mn id="alg1.l8.m1.1.1.3.2.3.2.3.3" xref="alg1.l8.m1.1.1.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="alg1.l8.m1.1.1.3.2.3.3" xref="alg1.l8.m1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">â†</ci><apply id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.2.1.cmml" xref="alg1.l8.m1.1.1.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.2.2.cmml" xref="alg1.l8.m1.1.1.2.2">ğ‘¤</ci><apply id="alg1.l8.m1.1.1.2.3.cmml" xref="alg1.l8.m1.1.1.2.3"><plus id="alg1.l8.m1.1.1.2.3.1.cmml" xref="alg1.l8.m1.1.1.2.3.1"></plus><ci id="alg1.l8.m1.1.1.2.3.2.cmml" xref="alg1.l8.m1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l8.m1.1.1.2.3.3.cmml" xref="alg1.l8.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3"><apply id="alg1.l8.m1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.1.1.cmml" xref="alg1.l8.m1.1.1.3.1">superscript</csymbol><apply id="alg1.l8.m1.1.1.3.1.2.cmml" xref="alg1.l8.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.1.2.1.cmml" xref="alg1.l8.m1.1.1.3.1">subscript</csymbol><sum id="alg1.l8.m1.1.1.3.1.2.2.cmml" xref="alg1.l8.m1.1.1.3.1.2.2"></sum><apply id="alg1.l8.m1.1.1.3.1.2.3.cmml" xref="alg1.l8.m1.1.1.3.1.2.3"><eq id="alg1.l8.m1.1.1.3.1.2.3.1.cmml" xref="alg1.l8.m1.1.1.3.1.2.3.1"></eq><ci id="alg1.l8.m1.1.1.3.1.2.3.2.cmml" xref="alg1.l8.m1.1.1.3.1.2.3.2">ğ‘˜</ci><cn type="integer" id="alg1.l8.m1.1.1.3.1.2.3.3.cmml" xref="alg1.l8.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l8.m1.1.1.3.1.3.cmml" xref="alg1.l8.m1.1.1.3.1.3">ğ¾</ci></apply><apply id="alg1.l8.m1.1.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.2"><times id="alg1.l8.m1.1.1.3.2.1.cmml" xref="alg1.l8.m1.1.1.3.2.1"></times><apply id="alg1.l8.m1.1.1.3.2.2.cmml" xref="alg1.l8.m1.1.1.3.2.2"><divide id="alg1.l8.m1.1.1.3.2.2.1.cmml" xref="alg1.l8.m1.1.1.3.2.2"></divide><apply id="alg1.l8.m1.1.1.3.2.2.2.cmml" xref="alg1.l8.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.2.2.2.1.cmml" xref="alg1.l8.m1.1.1.3.2.2.2">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.2.2.2.cmml" xref="alg1.l8.m1.1.1.3.2.2.2.2">ğ‘›</ci><ci id="alg1.l8.m1.1.1.3.2.2.2.3.cmml" xref="alg1.l8.m1.1.1.3.2.2.2.3">ğ‘˜</ci></apply><ci id="alg1.l8.m1.1.1.3.2.2.3.cmml" xref="alg1.l8.m1.1.1.3.2.2.3">ğ‘›</ci></apply><apply id="alg1.l8.m1.1.1.3.2.3.cmml" xref="alg1.l8.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.2.3.1.cmml" xref="alg1.l8.m1.1.1.3.2.3">superscript</csymbol><apply id="alg1.l8.m1.1.1.3.2.3.2.cmml" xref="alg1.l8.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.2.3.2.1.cmml" xref="alg1.l8.m1.1.1.3.2.3">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.3.2.2.cmml" xref="alg1.l8.m1.1.1.3.2.3.2.2">ğ‘¤</ci><apply id="alg1.l8.m1.1.1.3.2.3.2.3.cmml" xref="alg1.l8.m1.1.1.3.2.3.2.3"><plus id="alg1.l8.m1.1.1.3.2.3.2.3.1.cmml" xref="alg1.l8.m1.1.1.3.2.3.2.3.1"></plus><ci id="alg1.l8.m1.1.1.3.2.3.2.3.2.cmml" xref="alg1.l8.m1.1.1.3.2.3.2.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l8.m1.1.1.3.2.3.2.3.3.cmml" xref="alg1.l8.m1.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="alg1.l8.m1.1.1.3.2.3.3.cmml" xref="alg1.l8.m1.1.1.3.2.3.3">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">w_{t+1}\leftarrow\displaystyle\sum_{k=1}^{K}\frac{n_{k}}{n}w_{t+1}^{k}</annotation></semantics></math> 
Â Â Â 
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9:</span><span id="alg1.l9.3" class="ltx_text ltx_font_bold">function</span>Â ClientUpdate(<math id="alg1.l9.m1.2" class="ltx_Math" alttext="k,w" display="inline"><semantics id="alg1.l9.m1.2a"><mrow id="alg1.l9.m1.2.3.2" xref="alg1.l9.m1.2.3.1.cmml"><mi id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml">k</mi><mo id="alg1.l9.m1.2.3.2.1" xref="alg1.l9.m1.2.3.1.cmml">,</mo><mi id="alg1.l9.m1.2.2" xref="alg1.l9.m1.2.2.cmml">w</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.2b"><list id="alg1.l9.m1.2.3.1.cmml" xref="alg1.l9.m1.2.3.2"><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">ğ‘˜</ci><ci id="alg1.l9.m1.2.2.cmml" xref="alg1.l9.m1.2.2">ğ‘¤</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.2c">k,w</annotation></semantics></math>) <span id="alg1.l9.2" class="ltx_text" style="float:right;"><math id="alg1.l9.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l9.1.m1.1a"><mo id="alg1.l9.1.m1.1.1" xref="alg1.l9.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg1.l9.1.m1.1b"><ci id="alg1.l9.1.m1.1.1.cmml" xref="alg1.l9.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.1.m1.1c">\triangleright</annotation></semantics></math> <span id="alg1.l9.2.1" class="ltx_text ltx_font_italic">Run on client <math id="alg1.l9.2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l9.2.1.m1.1a"><mi id="alg1.l9.2.1.m1.1.1" xref="alg1.l9.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l9.2.1.m1.1b"><ci id="alg1.l9.2.1.m1.1.1.cmml" xref="alg1.l9.2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.2.1.m1.1c">k</annotation></semantics></math></span>
</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10:</span>Â Â Â <math id="alg1.l10.m1.2" class="ltx_Math" alttext="\mathcal{B}\leftarrow\text{(split $\mathcal{P}_{k}$ into batches of size $B$)}" display="inline"><semantics id="alg1.l10.m1.2a"><mrow id="alg1.l10.m1.2.3" xref="alg1.l10.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.2.3.2" xref="alg1.l10.m1.2.3.2.cmml">â„¬</mi><mo stretchy="false" id="alg1.l10.m1.2.3.1" xref="alg1.l10.m1.2.3.1.cmml">â†</mo><mrow id="alg1.l10.m1.2.2.2" xref="alg1.l10.m1.2.2.2d.cmml"><mtext id="alg1.l10.m1.2.2.2a" xref="alg1.l10.m1.2.2.2d.cmml">(splitÂ </mtext><msub id="alg1.l10.m1.1.1.1.m1.1.1" xref="alg1.l10.m1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.1.1.1.m1.1.1.2" xref="alg1.l10.m1.1.1.1.m1.1.1.2.cmml">ğ’«</mi><mi id="alg1.l10.m1.1.1.1.m1.1.1.3" xref="alg1.l10.m1.1.1.1.m1.1.1.3.cmml">k</mi></msub><mtext id="alg1.l10.m1.2.2.2b" xref="alg1.l10.m1.2.2.2d.cmml">Â into batches of sizeÂ </mtext><mi id="alg1.l10.m1.2.2.2.m2.1.1" xref="alg1.l10.m1.2.2.2.m2.1.1.cmml">B</mi><mtext id="alg1.l10.m1.2.2.2c" xref="alg1.l10.m1.2.2.2d.cmml">)</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.2b"><apply id="alg1.l10.m1.2.3.cmml" xref="alg1.l10.m1.2.3"><ci id="alg1.l10.m1.2.3.1.cmml" xref="alg1.l10.m1.2.3.1">â†</ci><ci id="alg1.l10.m1.2.3.2.cmml" xref="alg1.l10.m1.2.3.2">â„¬</ci><ci id="alg1.l10.m1.2.2.2d.cmml" xref="alg1.l10.m1.2.2.2"><mrow id="alg1.l10.m1.2.2.2.cmml" xref="alg1.l10.m1.2.2.2"><mtext id="alg1.l10.m1.2.2.2a.cmml" xref="alg1.l10.m1.2.2.2">(splitÂ </mtext><msub id="alg1.l10.m1.1.1.1.m1.1.1.cmml" xref="alg1.l10.m1.1.1.1.m1.1.1"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.1.1.1.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.1.m1.1.1.2">ğ’«</mi><mi id="alg1.l10.m1.1.1.1.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.1.m1.1.1.3">k</mi></msub><mtext id="alg1.l10.m1.2.2.2b.cmml" xref="alg1.l10.m1.2.2.2">Â into batches of sizeÂ </mtext><mi id="alg1.l10.m1.2.2.2.m2.1.1.cmml" xref="alg1.l10.m1.2.2.2.m2.1.1">B</mi><mtext id="alg1.l10.m1.2.2.2c.cmml" xref="alg1.l10.m1.2.2.2">)</mtext></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.2c">\mathcal{B}\leftarrow\text{(split $\mathcal{P}_{k}$ into batches of size $B$)}</annotation></semantics></math>

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11:</span>Â Â Â <span id="alg1.l11.1" class="ltx_text ltx_font_bold">for each</span>Â local epoch <math id="alg1.l11.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.l11.m1.1a"><mi id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">i</annotation></semantics></math> from <math id="alg1.l11.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="alg1.l11.m2.1a"><mn id="alg1.l11.m2.1.1" xref="alg1.l11.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b"><cn type="integer" id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m2.1c">1</annotation></semantics></math> to <math id="alg1.l11.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.l11.m3.1a"><mi id="alg1.l11.m3.1.1" xref="alg1.l11.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m3.1b"><ci id="alg1.l11.m3.1.1.cmml" xref="alg1.l11.m3.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m3.1c">E</annotation></semantics></math>Â <span id="alg1.l11.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12:</span>Â Â Â Â Â Â <span id="alg1.l12.1" class="ltx_text ltx_font_bold">for each</span>Â batch <math id="alg1.l12.m1.1" class="ltx_Math" alttext="b\in\mathcal{B}" display="inline"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml">b</mi><mo id="alg1.l12.m1.1.1.1" xref="alg1.l12.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml">â„¬</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><in id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1"></in><ci id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2">ğ‘</ci><ci id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3">â„¬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">b\in\mathcal{B}</annotation></semantics></math>Â <span id="alg1.l12.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13:</span>Â Â Â Â Â Â Â Â Â <math id="alg1.l13.m1.2" class="ltx_Math" alttext="w\leftarrow w-\eta\nabla\ell(w;b)" display="inline"><semantics id="alg1.l13.m1.2a"><mrow id="alg1.l13.m1.2.3" xref="alg1.l13.m1.2.3.cmml"><mi id="alg1.l13.m1.2.3.2" xref="alg1.l13.m1.2.3.2.cmml">w</mi><mo stretchy="false" id="alg1.l13.m1.2.3.1" xref="alg1.l13.m1.2.3.1.cmml">â†</mo><mrow id="alg1.l13.m1.2.3.3" xref="alg1.l13.m1.2.3.3.cmml"><mi id="alg1.l13.m1.2.3.3.2" xref="alg1.l13.m1.2.3.3.2.cmml">w</mi><mo id="alg1.l13.m1.2.3.3.1" xref="alg1.l13.m1.2.3.3.1.cmml">âˆ’</mo><mrow id="alg1.l13.m1.2.3.3.3" xref="alg1.l13.m1.2.3.3.3.cmml"><mi id="alg1.l13.m1.2.3.3.3.2" xref="alg1.l13.m1.2.3.3.3.2.cmml">Î·</mi><mo lspace="0.167em" rspace="0em" id="alg1.l13.m1.2.3.3.3.1" xref="alg1.l13.m1.2.3.3.3.1.cmml">â€‹</mo><mrow id="alg1.l13.m1.2.3.3.3.3" xref="alg1.l13.m1.2.3.3.3.3.cmml"><mo rspace="0.167em" id="alg1.l13.m1.2.3.3.3.3.1" xref="alg1.l13.m1.2.3.3.3.3.1.cmml">âˆ‡</mo><mi mathvariant="normal" id="alg1.l13.m1.2.3.3.3.3.2" xref="alg1.l13.m1.2.3.3.3.3.2.cmml">â„“</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l13.m1.2.3.3.3.1a" xref="alg1.l13.m1.2.3.3.3.1.cmml">â€‹</mo><mrow id="alg1.l13.m1.2.3.3.3.4.2" xref="alg1.l13.m1.2.3.3.3.4.1.cmml"><mo stretchy="false" id="alg1.l13.m1.2.3.3.3.4.2.1" xref="alg1.l13.m1.2.3.3.3.4.1.cmml">(</mo><mi id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml">w</mi><mo id="alg1.l13.m1.2.3.3.3.4.2.2" xref="alg1.l13.m1.2.3.3.3.4.1.cmml">;</mo><mi id="alg1.l13.m1.2.2" xref="alg1.l13.m1.2.2.cmml">b</mi><mo stretchy="false" id="alg1.l13.m1.2.3.3.3.4.2.3" xref="alg1.l13.m1.2.3.3.3.4.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.2b"><apply id="alg1.l13.m1.2.3.cmml" xref="alg1.l13.m1.2.3"><ci id="alg1.l13.m1.2.3.1.cmml" xref="alg1.l13.m1.2.3.1">â†</ci><ci id="alg1.l13.m1.2.3.2.cmml" xref="alg1.l13.m1.2.3.2">ğ‘¤</ci><apply id="alg1.l13.m1.2.3.3.cmml" xref="alg1.l13.m1.2.3.3"><minus id="alg1.l13.m1.2.3.3.1.cmml" xref="alg1.l13.m1.2.3.3.1"></minus><ci id="alg1.l13.m1.2.3.3.2.cmml" xref="alg1.l13.m1.2.3.3.2">ğ‘¤</ci><apply id="alg1.l13.m1.2.3.3.3.cmml" xref="alg1.l13.m1.2.3.3.3"><times id="alg1.l13.m1.2.3.3.3.1.cmml" xref="alg1.l13.m1.2.3.3.3.1"></times><ci id="alg1.l13.m1.2.3.3.3.2.cmml" xref="alg1.l13.m1.2.3.3.3.2">ğœ‚</ci><apply id="alg1.l13.m1.2.3.3.3.3.cmml" xref="alg1.l13.m1.2.3.3.3.3"><ci id="alg1.l13.m1.2.3.3.3.3.1.cmml" xref="alg1.l13.m1.2.3.3.3.3.1">âˆ‡</ci><ci id="alg1.l13.m1.2.3.3.3.3.2.cmml" xref="alg1.l13.m1.2.3.3.3.3.2">â„“</ci></apply><list id="alg1.l13.m1.2.3.3.3.4.1.cmml" xref="alg1.l13.m1.2.3.3.3.4.2"><ci id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1">ğ‘¤</ci><ci id="alg1.l13.m1.2.2.cmml" xref="alg1.l13.m1.2.2">ğ‘</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.2c">w\leftarrow w-\eta\nabla\ell(w;b)</annotation></semantics></math> 
Â Â Â Â Â Â Â Â Â 
</div>
</div>
</figure>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p">Many federated learning technologies have been studied since FedAvg
was proposed in 2016.
These technologies are surveyed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Data heterogeneity is one of important research challenges in these
studies since it is a major cause of accuracy degradation.
For instance, since a local model is optimized toward the local optima
by the client, it may be distant from other clients.
Thus, their averaged global model may be far from a part of clients.
To deal with this problem, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> uses an additional
proximal term to limit the number of local updates, and SCAFFOLD
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> uses a variance reduction to correct local updates.
These algorithms aim to improve the local training step of FedAvg.
In contrast, Personalized Federated Averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and
Adaptive Personalized Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> aim to make
personalized models that can achieve good accuracy in local clients.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p">Another challenge is the clientsâ€™ model heterogeneity.
Since not all clients always have the same compute resources,
selecting a proper model for each client can help the client
heterogeneity.
FedFeNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and FedDF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> address the model
heterogeneity.
In FedHeNN, each client trains its own model but pulls the
representations learned by different clients closer by adding a
proximal term to the clientâ€™s loss function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
FedDF is a federated learning algorithm that utilizes a knowledge
distillation at the model aggregation step of the federated learning
server.
In the knowledge distillation step at the server, instead of averaging
local parameters received from clients, a batch of sample data is
predicted by the local parameters and their output logits are
averaged.
The averaged logits are then used for updating the client models at
the server.
Although FedDF allows a federated leaning of different model
architectures, model training is needed at the aggregation step of the
server in addition to local training at the clients.
This means that all the client models joining the federated learning
are also needed at the server.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>ResNet and Neural ODE</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is a well-known neural network architecture that
can increase the number of stacked layers or building blocks by
introducing shortcut connections.
Using a shortcut connection, an input feature map to a building block
is temporarily saved, and then it is added to the original output of
the building block to generate the final output of the block.
In this paper, one building block in ResNet is called ResBlock.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p">ODE is composed of an unknown function and its ordinary derivatives.
To obtain an approximate numerical solution, an ODE solver such as the
first-order Euler method and higher-order Runge-Kutta method can be
used.
Based on a similarity between the network structure with shortcut
connections and the ODE solver, one building block can be interpreted
as one step in the ODE solver as suggested in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Assuming that the Euler method is used as an ODE solver, it can be
interpreted that the first-order approximation is applied to solve an
output of the building block.
In this paper, one building block is called ODEBlock, and the whole
network architecture consisting of ODEBlocks is called ODENet.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Depthwise Separable Convolution</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.4" class="ltx_p">CNN is composed of multiple layers, such as convolutional layers,
pooling layers, and fully-connected layers.
Although CNN achieves a good accuracy in image recognition tasks, each
convolutional layer has many parameters.
Let <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">N</annotation></semantics></math>, <math id="S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">M</annotation></semantics></math>, and <math id="S2.SS3.p1.3.m3.1" class="ltx_Math" alttext="N_{K}" display="inline"><semantics id="S2.SS3.p1.3.m3.1a"><msub id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml"><mi id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml">N</mi><mi id="S2.SS3.p1.3.m3.1.1.3" xref="S2.SS3.p1.3.m3.1.1.3.cmml">K</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2">ğ‘</ci><ci id="S2.SS3.p1.3.m3.1.1.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">N_{K}</annotation></semantics></math> be the number of input channels, the number of
output channels, and the kernel size of one side, respectively.
The number of parameters in one convolutional layer is <math id="S2.SS3.p1.4.m4.1" class="ltx_Math" alttext="NMN_{K}^{2}" display="inline"><semantics id="S2.SS3.p1.4.m4.1a"><mrow id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml"><mi id="S2.SS3.p1.4.m4.1.1.2" xref="S2.SS3.p1.4.m4.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.4.m4.1.1.1" xref="S2.SS3.p1.4.m4.1.1.1.cmml">â€‹</mo><mi id="S2.SS3.p1.4.m4.1.1.3" xref="S2.SS3.p1.4.m4.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.4.m4.1.1.1a" xref="S2.SS3.p1.4.m4.1.1.1.cmml">â€‹</mo><msubsup id="S2.SS3.p1.4.m4.1.1.4" xref="S2.SS3.p1.4.m4.1.1.4.cmml"><mi id="S2.SS3.p1.4.m4.1.1.4.2.2" xref="S2.SS3.p1.4.m4.1.1.4.2.2.cmml">N</mi><mi id="S2.SS3.p1.4.m4.1.1.4.2.3" xref="S2.SS3.p1.4.m4.1.1.4.2.3.cmml">K</mi><mn id="S2.SS3.p1.4.m4.1.1.4.3" xref="S2.SS3.p1.4.m4.1.1.4.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><apply id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1"><times id="S2.SS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1.1"></times><ci id="S2.SS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.p1.4.m4.1.1.2">ğ‘</ci><ci id="S2.SS3.p1.4.m4.1.1.3.cmml" xref="S2.SS3.p1.4.m4.1.1.3">ğ‘€</ci><apply id="S2.SS3.p1.4.m4.1.1.4.cmml" xref="S2.SS3.p1.4.m4.1.1.4"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.1.1.4.1.cmml" xref="S2.SS3.p1.4.m4.1.1.4">superscript</csymbol><apply id="S2.SS3.p1.4.m4.1.1.4.2.cmml" xref="S2.SS3.p1.4.m4.1.1.4"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.1.1.4.2.1.cmml" xref="S2.SS3.p1.4.m4.1.1.4">subscript</csymbol><ci id="S2.SS3.p1.4.m4.1.1.4.2.2.cmml" xref="S2.SS3.p1.4.m4.1.1.4.2.2">ğ‘</ci><ci id="S2.SS3.p1.4.m4.1.1.4.2.3.cmml" xref="S2.SS3.p1.4.m4.1.1.4.2.3">ğ¾</ci></apply><cn type="integer" id="S2.SS3.p1.4.m4.1.1.4.3.cmml" xref="S2.SS3.p1.4.m4.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">NMN_{K}^{2}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.8" class="ltx_p">Depthwise separable convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> divides this
convolutional layer into two convolutional steps: depthwise
convolutional step and pointwise convolutional step.
In the depthwise convolutional step, a convolutional operation
involving only spatial direction (the size is <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="N_{K}^{2}" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><msubsup id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mi id="S2.SS3.p2.1.m1.1.1.2.2" xref="S2.SS3.p2.1.m1.1.1.2.2.cmml">N</mi><mi id="S2.SS3.p2.1.m1.1.1.2.3" xref="S2.SS3.p2.1.m1.1.1.2.3.cmml">K</mi><mn id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">superscript</csymbol><apply id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.2.1.cmml" xref="S2.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.2.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2.2">ğ‘</ci><ci id="S2.SS3.p2.1.m1.1.1.2.3.cmml" xref="S2.SS3.p2.1.m1.1.1.2.3">ğ¾</ci></apply><cn type="integer" id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">N_{K}^{2}</annotation></semantics></math>) is applied for
each input feature map.
Different weight parameters are used for each of <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">N</annotation></semantics></math> input channels;
thus its weight parameter size is <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="NN_{K}^{2}" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><mrow id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mi id="S2.SS3.p2.3.m3.1.1.2" xref="S2.SS3.p2.3.m3.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.3.m3.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.cmml">â€‹</mo><msubsup id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.3.2.2" xref="S2.SS3.p2.3.m3.1.1.3.2.2.cmml">N</mi><mi id="S2.SS3.p2.3.m3.1.1.3.2.3" xref="S2.SS3.p2.3.m3.1.1.3.2.3.cmml">K</mi><mn id="S2.SS3.p2.3.m3.1.1.3.3" xref="S2.SS3.p2.3.m3.1.1.3.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><times id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1"></times><ci id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2">ğ‘</ci><apply id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3">superscript</csymbol><apply id="S2.SS3.p2.3.m3.1.1.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.3.2.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.3.2.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3.2.2">ğ‘</ci><ci id="S2.SS3.p2.3.m3.1.1.3.2.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.2.3">ğ¾</ci></apply><cn type="integer" id="S2.SS3.p2.3.m3.1.1.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">NN_{K}^{2}</annotation></semantics></math>.
Then, an output feature map of the depthwise convolutional step is fed
to the pointwise convolutional step as an input.
A <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mn id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.4.m4.1.1.1" xref="S2.SS3.p2.4.m4.1.1.1.cmml">Ã—</mo><mn id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><times id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1"></times><cn type="integer" id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">1</cn><cn type="integer" id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">1\times 1</annotation></semantics></math> convolutional operation is applied for each input
feature map and for each output channel; thus its weight parameter
size is <math id="S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="NM" display="inline"><semantics id="S2.SS3.p2.5.m5.1a"><mrow id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml"><mi id="S2.SS3.p2.5.m5.1.1.2" xref="S2.SS3.p2.5.m5.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.5.m5.1.1.1" xref="S2.SS3.p2.5.m5.1.1.1.cmml">â€‹</mo><mi id="S2.SS3.p2.5.m5.1.1.3" xref="S2.SS3.p2.5.m5.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><apply id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1"><times id="S2.SS3.p2.5.m5.1.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1.1"></times><ci id="S2.SS3.p2.5.m5.1.1.2.cmml" xref="S2.SS3.p2.5.m5.1.1.2">ğ‘</ci><ci id="S2.SS3.p2.5.m5.1.1.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">NM</annotation></semantics></math>.
The weight parameter size of the depthwise separable convolution is
<math id="S2.SS3.p2.6.m6.1" class="ltx_Math" alttext="NN_{K}^{2}+NM" display="inline"><semantics id="S2.SS3.p2.6.m6.1a"><mrow id="S2.SS3.p2.6.m6.1.1" xref="S2.SS3.p2.6.m6.1.1.cmml"><mrow id="S2.SS3.p2.6.m6.1.1.2" xref="S2.SS3.p2.6.m6.1.1.2.cmml"><mi id="S2.SS3.p2.6.m6.1.1.2.2" xref="S2.SS3.p2.6.m6.1.1.2.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.1.1.2.1" xref="S2.SS3.p2.6.m6.1.1.2.1.cmml">â€‹</mo><msubsup id="S2.SS3.p2.6.m6.1.1.2.3" xref="S2.SS3.p2.6.m6.1.1.2.3.cmml"><mi id="S2.SS3.p2.6.m6.1.1.2.3.2.2" xref="S2.SS3.p2.6.m6.1.1.2.3.2.2.cmml">N</mi><mi id="S2.SS3.p2.6.m6.1.1.2.3.2.3" xref="S2.SS3.p2.6.m6.1.1.2.3.2.3.cmml">K</mi><mn id="S2.SS3.p2.6.m6.1.1.2.3.3" xref="S2.SS3.p2.6.m6.1.1.2.3.3.cmml">2</mn></msubsup></mrow><mo id="S2.SS3.p2.6.m6.1.1.1" xref="S2.SS3.p2.6.m6.1.1.1.cmml">+</mo><mrow id="S2.SS3.p2.6.m6.1.1.3" xref="S2.SS3.p2.6.m6.1.1.3.cmml"><mi id="S2.SS3.p2.6.m6.1.1.3.2" xref="S2.SS3.p2.6.m6.1.1.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.1.1.3.1" xref="S2.SS3.p2.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.p2.6.m6.1.1.3.3" xref="S2.SS3.p2.6.m6.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m6.1b"><apply id="S2.SS3.p2.6.m6.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1"><plus id="S2.SS3.p2.6.m6.1.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1.1"></plus><apply id="S2.SS3.p2.6.m6.1.1.2.cmml" xref="S2.SS3.p2.6.m6.1.1.2"><times id="S2.SS3.p2.6.m6.1.1.2.1.cmml" xref="S2.SS3.p2.6.m6.1.1.2.1"></times><ci id="S2.SS3.p2.6.m6.1.1.2.2.cmml" xref="S2.SS3.p2.6.m6.1.1.2.2">ğ‘</ci><apply id="S2.SS3.p2.6.m6.1.1.2.3.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.1.1.2.3.1.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3">superscript</csymbol><apply id="S2.SS3.p2.6.m6.1.1.2.3.2.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.1.1.2.3.2.1.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3">subscript</csymbol><ci id="S2.SS3.p2.6.m6.1.1.2.3.2.2.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3.2.2">ğ‘</ci><ci id="S2.SS3.p2.6.m6.1.1.2.3.2.3.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3.2.3">ğ¾</ci></apply><cn type="integer" id="S2.SS3.p2.6.m6.1.1.2.3.3.cmml" xref="S2.SS3.p2.6.m6.1.1.2.3.3">2</cn></apply></apply><apply id="S2.SS3.p2.6.m6.1.1.3.cmml" xref="S2.SS3.p2.6.m6.1.1.3"><times id="S2.SS3.p2.6.m6.1.1.3.1.cmml" xref="S2.SS3.p2.6.m6.1.1.3.1"></times><ci id="S2.SS3.p2.6.m6.1.1.3.2.cmml" xref="S2.SS3.p2.6.m6.1.1.3.2">ğ‘</ci><ci id="S2.SS3.p2.6.m6.1.1.3.3.cmml" xref="S2.SS3.p2.6.m6.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m6.1c">NN_{K}^{2}+NM</annotation></semantics></math> in total, which is approximately <math id="S2.SS3.p2.7.m7.1" class="ltx_Math" alttext="N_{K}^{2}" display="inline"><semantics id="S2.SS3.p2.7.m7.1a"><msubsup id="S2.SS3.p2.7.m7.1.1" xref="S2.SS3.p2.7.m7.1.1.cmml"><mi id="S2.SS3.p2.7.m7.1.1.2.2" xref="S2.SS3.p2.7.m7.1.1.2.2.cmml">N</mi><mi id="S2.SS3.p2.7.m7.1.1.2.3" xref="S2.SS3.p2.7.m7.1.1.2.3.cmml">K</mi><mn id="S2.SS3.p2.7.m7.1.1.3" xref="S2.SS3.p2.7.m7.1.1.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m7.1b"><apply id="S2.SS3.p2.7.m7.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.7.m7.1.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1">superscript</csymbol><apply id="S2.SS3.p2.7.m7.1.1.2.cmml" xref="S2.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.7.m7.1.1.2.1.cmml" xref="S2.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS3.p2.7.m7.1.1.2.2.cmml" xref="S2.SS3.p2.7.m7.1.1.2.2">ğ‘</ci><ci id="S2.SS3.p2.7.m7.1.1.2.3.cmml" xref="S2.SS3.p2.7.m7.1.1.2.3">ğ¾</ci></apply><cn type="integer" id="S2.SS3.p2.7.m7.1.1.3.cmml" xref="S2.SS3.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m7.1c">N_{K}^{2}</annotation></semantics></math> times reduction,
assuming that <math id="S2.SS3.p2.8.m8.2" class="ltx_Math" alttext="N,M\gg N_{K}" display="inline"><semantics id="S2.SS3.p2.8.m8.2a"><mrow id="S2.SS3.p2.8.m8.2.3" xref="S2.SS3.p2.8.m8.2.3.cmml"><mrow id="S2.SS3.p2.8.m8.2.3.2.2" xref="S2.SS3.p2.8.m8.2.3.2.1.cmml"><mi id="S2.SS3.p2.8.m8.1.1" xref="S2.SS3.p2.8.m8.1.1.cmml">N</mi><mo id="S2.SS3.p2.8.m8.2.3.2.2.1" xref="S2.SS3.p2.8.m8.2.3.2.1.cmml">,</mo><mi id="S2.SS3.p2.8.m8.2.2" xref="S2.SS3.p2.8.m8.2.2.cmml">M</mi></mrow><mo id="S2.SS3.p2.8.m8.2.3.1" xref="S2.SS3.p2.8.m8.2.3.1.cmml">â‰«</mo><msub id="S2.SS3.p2.8.m8.2.3.3" xref="S2.SS3.p2.8.m8.2.3.3.cmml"><mi id="S2.SS3.p2.8.m8.2.3.3.2" xref="S2.SS3.p2.8.m8.2.3.3.2.cmml">N</mi><mi id="S2.SS3.p2.8.m8.2.3.3.3" xref="S2.SS3.p2.8.m8.2.3.3.3.cmml">K</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.8.m8.2b"><apply id="S2.SS3.p2.8.m8.2.3.cmml" xref="S2.SS3.p2.8.m8.2.3"><csymbol cd="latexml" id="S2.SS3.p2.8.m8.2.3.1.cmml" xref="S2.SS3.p2.8.m8.2.3.1">much-greater-than</csymbol><list id="S2.SS3.p2.8.m8.2.3.2.1.cmml" xref="S2.SS3.p2.8.m8.2.3.2.2"><ci id="S2.SS3.p2.8.m8.1.1.cmml" xref="S2.SS3.p2.8.m8.1.1">ğ‘</ci><ci id="S2.SS3.p2.8.m8.2.2.cmml" xref="S2.SS3.p2.8.m8.2.2">ğ‘€</ci></list><apply id="S2.SS3.p2.8.m8.2.3.3.cmml" xref="S2.SS3.p2.8.m8.2.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.8.m8.2.3.3.1.cmml" xref="S2.SS3.p2.8.m8.2.3.3">subscript</csymbol><ci id="S2.SS3.p2.8.m8.2.3.3.2.cmml" xref="S2.SS3.p2.8.m8.2.3.3.2">ğ‘</ci><ci id="S2.SS3.p2.8.m8.2.3.3.3.cmml" xref="S2.SS3.p2.8.m8.2.3.3.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.8.m8.2c">N,M\gg N_{K}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para ltx_noindent">
<p id="S2.SS3.p3.1" class="ltx_p">As a low-cost CNN model, dsODENet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> applies the depthwise
separable convolution to convolutional layers of ODEBlocks in order to
further reduce the parameter size.
It was originally proposed to be implemented on resource-limited FPGA
(Field-Programmable Gate Array) devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
In this paper, we use dsODENet as a federated learning model
architecture in addition to ODENet.
Their detailed structures are illustrated in the next section.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Federated Learning</h2>

<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x1.png" id="S3.F2.1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="213" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Structure of 7-block ResNet</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x2.png" id="S3.F2.2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="233" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Structure of 7-block ODENet</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">In the traditional federated learning such as FedAvg, the server and
all clients have to use the same model.
For example, models with different layer depths cannot be averaged
when ResNet is used as a model architecture.
However, in a real environment, client devices are not the same and
are likely to have different compute resources, such as memory
capacity and computation power.
Since the traditional federated learning cannot aggregate models with
different depths, a common model used by all the clients should be
carefully selected.
In addition, it is necessary to reduce the communication size involved
in exchanging weight parameters between the server and clients.
In this paper, we use ODENet and dsODENet to enable a flexible
federated learning between models with different layer iteration
counts and significantly reduce the communication size.
These target models are illustrated in Section <a href="#S3.SS1" title="3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
We discuss the feasibility of the proposed federated learning in
Sections <a href="#S3.SS2" title="3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> and <a href="#S3.SS3" title="3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Target Models</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">In this section, we first illustrate the structures and sizes of
ResNet and ODENet.
Then, we illustrate dsODENet.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.2" class="ltx_p">Figures <a href="#S3.F2" title="Figure 2 â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S3.F2" title="Figure 2 â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show basic
structures of ResNet and the corresponding ODENet.
They consist of seven blocks including conv1 and fc.
In the ResNet model, conv1 performs convolutional operations as a
pre-processing layer, and fc is a post-processing fully-connected layer.
After the conv1, <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">C</annotation></semantics></math> physically-stacked ResBlocks are executed
in block1.
block2_1 is a downsampling ResBlock to reduce the feature map size,
and <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">C</annotation></semantics></math> physically-stacked ResBlocks on the output of block2_1 are
executed in block2_2.
The same operation is performed for block3_1 and block3_2 too.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.3" class="ltx_p">ODENet replaces ResBlocks in Figure <a href="#S3.F2" title="Figure 2 â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> with
ODEBlocks as shown in Figure <a href="#S3.F2" title="Figure 2 â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
In ResNet, <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">C</annotation></semantics></math> ResBlocks are physically-stacked in block1, block2_2,
and block3_2, while ODENet replaces these <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">C</annotation></semantics></math> ResBlocks with a single
ODEBlock.
Instead, ODEBlock is executed <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">C</annotation></semantics></math> times in block1, block2_2, and
block3_2.
A downsampling ODEBlock is executed only once in block2_1 and
block3_1, respectively.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.6" class="ltx_p">Here, we analyze the numbers of parameters of ResNet and ODENet.
Let <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="O(L)" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.2" xref="S3.SS1.p4.1.m1.1.2.cmml"><mi id="S3.SS1.p4.1.m1.1.2.2" xref="S3.SS1.p4.1.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.2.1" xref="S3.SS1.p4.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p4.1.m1.1.2.3.2" xref="S3.SS1.p4.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p4.1.m1.1.2.3.2.1" xref="S3.SS1.p4.1.m1.1.2.cmml">(</mo><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">L</mi><mo stretchy="false" id="S3.SS1.p4.1.m1.1.2.3.2.2" xref="S3.SS1.p4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.2"><times id="S3.SS1.p4.1.m1.1.2.1.cmml" xref="S3.SS1.p4.1.m1.1.2.1"></times><ci id="S3.SS1.p4.1.m1.1.2.2.cmml" xref="S3.SS1.p4.1.m1.1.2.2">ğ‘‚</ci><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">O(L)</annotation></semantics></math> be the number of parameters in one ResBlock and ODEBlock.
In ResNet, <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">C</annotation></semantics></math> ResBlocks are stacked in one block, so the number of
parameters is <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="O(CL)" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mrow id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p4.3.m3.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p4.3.m3.1.1.1.1.2" xref="S3.SS1.p4.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p4.3.m3.1.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.1.1.1.2" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.3.m3.1.1.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p4.3.m3.1.1.1.1.1.3" xref="S3.SS1.p4.3.m3.1.1.1.1.1.3.cmml">L</mi></mrow><mo stretchy="false" id="S3.SS1.p4.3.m3.1.1.1.1.3" xref="S3.SS1.p4.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><times id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2"></times><ci id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">ğ‘‚</ci><apply id="S3.SS1.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1"><times id="S3.SS1.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.1"></times><ci id="S3.SS1.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2">ğ¶</ci><ci id="S3.SS1.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">O(CL)</annotation></semantics></math>.
In contrast, ODENet repeats ODEBlock <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mi id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">C</annotation></semantics></math> times in one block, so the
number of parameters is <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="O(L)" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><mrow id="S3.SS1.p4.5.m5.1.2" xref="S3.SS1.p4.5.m5.1.2.cmml"><mi id="S3.SS1.p4.5.m5.1.2.2" xref="S3.SS1.p4.5.m5.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.5.m5.1.2.1" xref="S3.SS1.p4.5.m5.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p4.5.m5.1.2.3.2" xref="S3.SS1.p4.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS1.p4.5.m5.1.2.3.2.1" xref="S3.SS1.p4.5.m5.1.2.cmml">(</mo><mi id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml">L</mi><mo stretchy="false" id="S3.SS1.p4.5.m5.1.2.3.2.2" xref="S3.SS1.p4.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.2.cmml" xref="S3.SS1.p4.5.m5.1.2"><times id="S3.SS1.p4.5.m5.1.2.1.cmml" xref="S3.SS1.p4.5.m5.1.2.1"></times><ci id="S3.SS1.p4.5.m5.1.2.2.cmml" xref="S3.SS1.p4.5.m5.1.2.2">ğ‘‚</ci><ci id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">O(L)</annotation></semantics></math>.
The parameter size reduction by ODENet becomes large as <math id="S3.SS1.p4.6.m6.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p4.6.m6.1a"><mi id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><ci id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">C</annotation></semantics></math> is
increased.
As shown, the communication size can be reduced by using ODENet as a
federated learning model instead of ResNet.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2208.09478/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="184" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Structures of ODEBlock and dsODEBlock in ODENet and dsODENet</figcaption>
</figure>
<figure id="S3.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.T2.9" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Table 1: </span>Accuracy of ODENet models trained and tested with
same or different depths</figcaption>
<table id="S3.T2.9.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.9.9.10.1" class="ltx_tr">
<th id="S3.T2.9.9.10.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Trained as</th>
<th id="S3.T2.9.9.10.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Teseted as</th>
<th id="S3.T2.9.9.10.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Accuracy [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet-34</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">ODENet-34</td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">75.46 <math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.41</td>
</tr>
<tr id="S3.T2.2.2.2" class="ltx_tr">
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.2.2.2.3" class="ltx_td ltx_align_right ltx_border_r">ODENet-50</td>
<td id="S3.T2.2.2.2.1" class="ltx_td ltx_align_right ltx_border_r">75.36 <math id="S3.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.2.2.2.1.m1.1a"><mo id="S3.T2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">\pm</annotation></semantics></math> 0.43</td>
</tr>
<tr id="S3.T2.3.3.3" class="ltx_tr">
<td id="S3.T2.3.3.3.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_right ltx_border_r">ODENet-101</td>
<td id="S3.T2.3.3.3.1" class="ltx_td ltx_align_right ltx_border_r">75.26 <math id="S3.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.3.3.3.1.m1.1a"><mo id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">\pm</annotation></semantics></math> 0.46</td>
</tr>
<tr id="S3.T2.4.4.4" class="ltx_tr">
<td id="S3.T2.4.4.4.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet-50</td>
<td id="S3.T2.4.4.4.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">ODENet-34</td>
<td id="S3.T2.4.4.4.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">76.13 <math id="S3.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.4.4.4.1.m1.1a"><mo id="S3.T2.4.4.4.1.m1.1.1" xref="S3.T2.4.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S3.T2.4.4.4.1.m1.1.1.cmml" xref="S3.T2.4.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.1.m1.1c">\pm</annotation></semantics></math> 0.42</td>
</tr>
<tr id="S3.T2.5.5.5" class="ltx_tr">
<td id="S3.T2.5.5.5.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.5.5.5.3" class="ltx_td ltx_align_right ltx_border_r">ODENet-50</td>
<td id="S3.T2.5.5.5.1" class="ltx_td ltx_align_right ltx_border_r">76.02 <math id="S3.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.5.5.5.1.m1.1a"><mo id="S3.T2.5.5.5.1.m1.1.1" xref="S3.T2.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S3.T2.5.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">\pm</annotation></semantics></math> 0.42</td>
</tr>
<tr id="S3.T2.6.6.6" class="ltx_tr">
<td id="S3.T2.6.6.6.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.6.6.6.3" class="ltx_td ltx_align_right ltx_border_r">ODENet-101</td>
<td id="S3.T2.6.6.6.1" class="ltx_td ltx_align_right ltx_border_r">75.91 <math id="S3.T2.6.6.6.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.6.6.6.1.m1.1a"><mo id="S3.T2.6.6.6.1.m1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.1.m1.1b"><csymbol cd="latexml" id="S3.T2.6.6.6.1.m1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.1.m1.1c">\pm</annotation></semantics></math> 0.52</td>
</tr>
<tr id="S3.T2.7.7.7" class="ltx_tr">
<td id="S3.T2.7.7.7.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet-101</td>
<td id="S3.T2.7.7.7.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">ODENet-34</td>
<td id="S3.T2.7.7.7.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">76.25 <math id="S3.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.7.7.7.1.m1.1a"><mo id="S3.T2.7.7.7.1.m1.1.1" xref="S3.T2.7.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S3.T2.7.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.1.m1.1c">\pm</annotation></semantics></math> 0.45</td>
</tr>
<tr id="S3.T2.8.8.8" class="ltx_tr">
<td id="S3.T2.8.8.8.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.8.8.8.3" class="ltx_td ltx_align_right ltx_border_r">ODENet-50</td>
<td id="S3.T2.8.8.8.1" class="ltx_td ltx_align_right ltx_border_r">76.14 <math id="S3.T2.8.8.8.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.8.8.8.1.m1.1a"><mo id="S3.T2.8.8.8.1.m1.1.1" xref="S3.T2.8.8.8.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.1.m1.1b"><csymbol cd="latexml" id="S3.T2.8.8.8.1.m1.1.1.cmml" xref="S3.T2.8.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.1.m1.1c">\pm</annotation></semantics></math> 0.47</td>
</tr>
<tr id="S3.T2.9.9.9" class="ltx_tr">
<td id="S3.T2.9.9.9.2" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S3.T2.9.9.9.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">ODENet-101</td>
<td id="S3.T2.9.9.9.1" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">76.13 <math id="S3.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.9.9.9.1.m1.1a"><mo id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">\pm</annotation></semantics></math> 0.45</td>
</tr>
</tbody>
</table>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.T2.18" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Table 2: </span>Accuracy of dsODENet models trained and tested with
same or different depths</figcaption>
<table id="S3.T2.18.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.18.9.10.1" class="ltx_tr">
<th id="S3.T2.18.9.10.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Trained as</th>
<th id="S3.T2.18.9.10.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Tested as</th>
<th id="S3.T2.18.9.10.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Accuracy [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.10.1.1" class="ltx_tr">
<td id="S3.T2.10.1.1.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet-34</td>
<td id="S3.T2.10.1.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">dsODENet-34</td>
<td id="S3.T2.10.1.1.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">71.67 <math id="S3.T2.10.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.10.1.1.1.m1.1a"><mo id="S3.T2.10.1.1.1.m1.1.1" xref="S3.T2.10.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.10.1.1.1.m1.1.1.cmml" xref="S3.T2.10.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.53</td>
</tr>
<tr id="S3.T2.11.2.2" class="ltx_tr">
<td id="S3.T2.11.2.2.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.11.2.2.3" class="ltx_td ltx_align_right ltx_border_r">dsODENet-50</td>
<td id="S3.T2.11.2.2.1" class="ltx_td ltx_align_right ltx_border_r">71.74 <math id="S3.T2.11.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.11.2.2.1.m1.1a"><mo id="S3.T2.11.2.2.1.m1.1.1" xref="S3.T2.11.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.2.2.1.m1.1b"><csymbol cd="latexml" id="S3.T2.11.2.2.1.m1.1.1.cmml" xref="S3.T2.11.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.2.2.1.m1.1c">\pm</annotation></semantics></math> 0.68</td>
</tr>
<tr id="S3.T2.12.3.3" class="ltx_tr">
<td id="S3.T2.12.3.3.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.12.3.3.3" class="ltx_td ltx_align_right ltx_border_r">dsODENet-101</td>
<td id="S3.T2.12.3.3.1" class="ltx_td ltx_align_right ltx_border_r">71.45 <math id="S3.T2.12.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.12.3.3.1.m1.1a"><mo id="S3.T2.12.3.3.1.m1.1.1" xref="S3.T2.12.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.12.3.3.1.m1.1b"><csymbol cd="latexml" id="S3.T2.12.3.3.1.m1.1.1.cmml" xref="S3.T2.12.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.3.3.1.m1.1c">\pm</annotation></semantics></math> 0.68</td>
</tr>
<tr id="S3.T2.13.4.4" class="ltx_tr">
<td id="S3.T2.13.4.4.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet-50</td>
<td id="S3.T2.13.4.4.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">dsODENet-34</td>
<td id="S3.T2.13.4.4.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">72.24 <math id="S3.T2.13.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.13.4.4.1.m1.1a"><mo id="S3.T2.13.4.4.1.m1.1.1" xref="S3.T2.13.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.13.4.4.1.m1.1b"><csymbol cd="latexml" id="S3.T2.13.4.4.1.m1.1.1.cmml" xref="S3.T2.13.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.4.4.1.m1.1c">\pm</annotation></semantics></math> 0.61</td>
</tr>
<tr id="S3.T2.14.5.5" class="ltx_tr">
<td id="S3.T2.14.5.5.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.14.5.5.3" class="ltx_td ltx_align_right ltx_border_r">dsODENet-50</td>
<td id="S3.T2.14.5.5.1" class="ltx_td ltx_align_right ltx_border_r">72.10 <math id="S3.T2.14.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.14.5.5.1.m1.1a"><mo id="S3.T2.14.5.5.1.m1.1.1" xref="S3.T2.14.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.14.5.5.1.m1.1b"><csymbol cd="latexml" id="S3.T2.14.5.5.1.m1.1.1.cmml" xref="S3.T2.14.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.5.5.1.m1.1c">\pm</annotation></semantics></math> 0.62</td>
</tr>
<tr id="S3.T2.15.6.6" class="ltx_tr">
<td id="S3.T2.15.6.6.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.15.6.6.3" class="ltx_td ltx_align_right ltx_border_r">dsODENet-101</td>
<td id="S3.T2.15.6.6.1" class="ltx_td ltx_align_right ltx_border_r">72.00 <math id="S3.T2.15.6.6.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.15.6.6.1.m1.1a"><mo id="S3.T2.15.6.6.1.m1.1.1" xref="S3.T2.15.6.6.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.15.6.6.1.m1.1b"><csymbol cd="latexml" id="S3.T2.15.6.6.1.m1.1.1.cmml" xref="S3.T2.15.6.6.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.6.6.1.m1.1c">\pm</annotation></semantics></math> 0.69</td>
</tr>
<tr id="S3.T2.16.7.7" class="ltx_tr">
<td id="S3.T2.16.7.7.2" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet-101</td>
<td id="S3.T2.16.7.7.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">dsODENet-34</td>
<td id="S3.T2.16.7.7.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">72.28 <math id="S3.T2.16.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.16.7.7.1.m1.1a"><mo id="S3.T2.16.7.7.1.m1.1.1" xref="S3.T2.16.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.16.7.7.1.m1.1b"><csymbol cd="latexml" id="S3.T2.16.7.7.1.m1.1.1.cmml" xref="S3.T2.16.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.7.7.1.m1.1c">\pm</annotation></semantics></math> 0.64</td>
</tr>
<tr id="S3.T2.17.8.8" class="ltx_tr">
<td id="S3.T2.17.8.8.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.17.8.8.3" class="ltx_td ltx_align_right ltx_border_r">dsODENet-50</td>
<td id="S3.T2.17.8.8.1" class="ltx_td ltx_align_right ltx_border_r">72.11 <math id="S3.T2.17.8.8.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.17.8.8.1.m1.1a"><mo id="S3.T2.17.8.8.1.m1.1.1" xref="S3.T2.17.8.8.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.17.8.8.1.m1.1b"><csymbol cd="latexml" id="S3.T2.17.8.8.1.m1.1.1.cmml" xref="S3.T2.17.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.8.8.1.m1.1c">\pm</annotation></semantics></math> 0.62</td>
</tr>
<tr id="S3.T2.18.9.9" class="ltx_tr">
<td id="S3.T2.18.9.9.2" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S3.T2.18.9.9.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">dsODENet-101</td>
<td id="S3.T2.18.9.9.1" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">72.13 <math id="S3.T2.18.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.18.9.9.1.m1.1a"><mo id="S3.T2.18.9.9.1.m1.1.1" xref="S3.T2.18.9.9.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.18.9.9.1.m1.1b"><csymbol cd="latexml" id="S3.T2.18.9.9.1.m1.1.1.cmml" xref="S3.T2.18.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.9.9.1.m1.1c">\pm</annotation></semantics></math> 0.64</td>
</tr>
</tbody>
</table>
</figure>
</div>
</div>
</figure>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p">In addition, the number of parameters can be further reduced by using
dsODENet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> as mentioned in Section <a href="#S2.SS3" title="2.3 Depthwise Separable Convolution â€£ 2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>.
Figure <a href="#S3.F3" title="Figure 3 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> left shows a structure of an ODEBlock in
ODENet.
Figure <a href="#S3.F3" title="Figure 3 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> right shows that of dsODEBlock in dsODENet,
in which each convolutional layer of the ODEBlock is replaced with two
convolutional steps: the depthwise convolutional step and the
pointwise convolutional step.
Conv1 and Conv2 are convolutional layers, and ReLU (Rectified Linear
Unit) is an activation function.
This modification can reduce the model and communication sizes
compared with ODENet.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Weight Compatibility with Different Depths</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.3" class="ltx_p">In the case of ResNet, models with different depths have different
numbers of stacked ResBlocks (i.e., different <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">C</annotation></semantics></math>) in their block1,
block2_2, and block3_2.
If we use FedAvg for federated learning, basically these different
ResNet models cannot be averaged at the server due to the model
incompatibility.
In the case of ODENet, one ODEBlock is repeated <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">C</annotation></semantics></math> times in block1,
block2_2, and block3_2 of ODENet.
In other words, ODENet models with different depths differ only in the
numbers of iterations of ODEBlocks, not in the number of ODEBlocks.
Therefore, the structure of the ODENet models with different <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">C</annotation></semantics></math> is
the same, so their parameters can be averaged at the server.
Using ODENet as a federated learning model enables a flexible
federated learning between models with different iteration counts and
fully utilizes the performance of each client device.
dsODENet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> also enables such a flexible federated learning
between models with different iteration counts for the same reason as
ODENet.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.6" class="ltx_p">Here, we examine if the above observation can work.
This section focuses on the weight parameter compatibility of models
which have different <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">C</annotation></semantics></math> to demonstrate the feasibility of the
proposed federated learning.
Specifically, inference accuracies of ODENet and dsODENet models which
were trained for the same or different <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">C</annotation></semantics></math> are evaluated.
Please note that, in the following, we use the total number of
executed convolutional layers (denoted as <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">N</annotation></semantics></math>) to represent the depths
of the ResNet, ODENet, and dsODENet models.
We assume <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="N=6C+6" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mrow id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">N</mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">=</mo><mrow id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mrow id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml"><mn id="S3.SS2.p2.4.m4.1.1.3.2.2" xref="S3.SS2.p2.4.m4.1.1.3.2.2.cmml">6</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p2.4.m4.1.1.3.2.1" xref="S3.SS2.p2.4.m4.1.1.3.2.1.cmml">â€‹</mo><mi id="S3.SS2.p2.4.m4.1.1.3.2.3" xref="S3.SS2.p2.4.m4.1.1.3.2.3.cmml">C</mi></mrow><mo id="S3.SS2.p2.4.m4.1.1.3.1" xref="S3.SS2.p2.4.m4.1.1.3.1.cmml">+</mo><mn id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml">6</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><eq id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1"></eq><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ‘</ci><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><plus id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.1"></plus><apply id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2"><times id="S3.SS2.p2.4.m4.1.1.3.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2.1"></times><cn type="integer" id="S3.SS2.p2.4.m4.1.1.3.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2.2">6</cn><ci id="S3.SS2.p2.4.m4.1.1.3.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2.3">ğ¶</ci></apply><cn type="integer" id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">N=6C+6</annotation></semantics></math> in this experiment <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In Figure
<a href="#S3.F2" title="Figure 2 â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, ResBlocks are executed <math id="footnote2.m1.1" class="ltx_Math" alttext="3C+2" display="inline"><semantics id="footnote2.m1.1b"><mrow id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml"><mrow id="footnote2.m1.1.1.2" xref="footnote2.m1.1.1.2.cmml"><mn id="footnote2.m1.1.1.2.2" xref="footnote2.m1.1.1.2.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="footnote2.m1.1.1.2.1" xref="footnote2.m1.1.1.2.1.cmml">â€‹</mo><mi id="footnote2.m1.1.1.2.3" xref="footnote2.m1.1.1.2.3.cmml">C</mi></mrow><mo id="footnote2.m1.1.1.1" xref="footnote2.m1.1.1.1.cmml">+</mo><mn id="footnote2.m1.1.1.3" xref="footnote2.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><apply id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1"><plus id="footnote2.m1.1.1.1.cmml" xref="footnote2.m1.1.1.1"></plus><apply id="footnote2.m1.1.1.2.cmml" xref="footnote2.m1.1.1.2"><times id="footnote2.m1.1.1.2.1.cmml" xref="footnote2.m1.1.1.2.1"></times><cn type="integer" id="footnote2.m1.1.1.2.2.cmml" xref="footnote2.m1.1.1.2.2">3</cn><ci id="footnote2.m1.1.1.2.3.cmml" xref="footnote2.m1.1.1.2.3">ğ¶</ci></apply><cn type="integer" id="footnote2.m1.1.1.3.cmml" xref="footnote2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">3C+2</annotation></semantics></math> times, each
contains two convolutional layers.
The pre- and post-processing (conv1 and fc) layers are also included
in <math id="footnote2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" xref="footnote2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">N</annotation></semantics></math>; thus <math id="footnote2.m3.1" class="ltx_Math" alttext="N=2(3C+2)+2" display="inline"><semantics id="footnote2.m3.1b"><mrow id="footnote2.m3.1.1" xref="footnote2.m3.1.1.cmml"><mi id="footnote2.m3.1.1.3" xref="footnote2.m3.1.1.3.cmml">N</mi><mo id="footnote2.m3.1.1.2" xref="footnote2.m3.1.1.2.cmml">=</mo><mrow id="footnote2.m3.1.1.1" xref="footnote2.m3.1.1.1.cmml"><mrow id="footnote2.m3.1.1.1.1" xref="footnote2.m3.1.1.1.1.cmml"><mn id="footnote2.m3.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="footnote2.m3.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.2.cmml">â€‹</mo><mrow id="footnote2.m3.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote2.m3.1.1.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m3.1.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.1.cmml"><mrow id="footnote2.m3.1.1.1.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.1.1.2.cmml"><mn id="footnote2.m3.1.1.1.1.1.1.1.2.2" xref="footnote2.m3.1.1.1.1.1.1.1.2.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="footnote2.m3.1.1.1.1.1.1.1.2.1" xref="footnote2.m3.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="footnote2.m3.1.1.1.1.1.1.1.2.3" xref="footnote2.m3.1.1.1.1.1.1.1.2.3.cmml">C</mi></mrow><mo id="footnote2.m3.1.1.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.1.1.cmml">+</mo><mn id="footnote2.m3.1.1.1.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="footnote2.m3.1.1.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="footnote2.m3.1.1.1.2" xref="footnote2.m3.1.1.1.2.cmml">+</mo><mn id="footnote2.m3.1.1.1.3" xref="footnote2.m3.1.1.1.3.cmml">2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m3.1c"><apply id="footnote2.m3.1.1.cmml" xref="footnote2.m3.1.1"><eq id="footnote2.m3.1.1.2.cmml" xref="footnote2.m3.1.1.2"></eq><ci id="footnote2.m3.1.1.3.cmml" xref="footnote2.m3.1.1.3">ğ‘</ci><apply id="footnote2.m3.1.1.1.cmml" xref="footnote2.m3.1.1.1"><plus id="footnote2.m3.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.2"></plus><apply id="footnote2.m3.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1"><times id="footnote2.m3.1.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.1.2"></times><cn type="integer" id="footnote2.m3.1.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.1.3">2</cn><apply id="footnote2.m3.1.1.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1.1.1"><plus id="footnote2.m3.1.1.1.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.1"></plus><apply id="footnote2.m3.1.1.1.1.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.2"><times id="footnote2.m3.1.1.1.1.1.1.1.2.1.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.2.1"></times><cn type="integer" id="footnote2.m3.1.1.1.1.1.1.1.2.2.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.2.2">3</cn><ci id="footnote2.m3.1.1.1.1.1.1.1.2.3.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.2.3">ğ¶</ci></apply><cn type="integer" id="footnote2.m3.1.1.1.1.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.1.1.1.1.3">2</cn></apply></apply><cn type="integer" id="footnote2.m3.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m3.1d">N=2(3C+2)+2</annotation></semantics></math>.</span></span></span> and use <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">N</annotation></semantics></math> = 34, 50, and 101.
For example, the inference accuracy of ODENet-34 is evaluated using
weight parameters trained as ODENet-50.
We selected two models from <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">N</annotation></semantics></math> = 34, 50, and 101: one for training
and another for inference.
The experiment is performed 100 times for each combination.
CIFAR-10 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> is used for the training and inference.
The same experiment is also performed for dsODENet.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p">Tables <a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show
the inference accuracy of every combination.
Figure <a href="#S3.F5" title="Figure 5 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows box-plots of accuracies of
ODENet-34, 50, and 101 using weight parameters trained as ODENet-50.
Figure <a href="#S3.F5" title="Figure 5 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows those of dsODENet.
The results from Figure <a href="#S3.F5" title="Figure 5 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table
<a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show that the accuracies are almost the same
regardless of the tested models if the trained model is the same.
The results from Figure <a href="#S3.F5" title="Figure 5 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table
<a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> also show the same tendency in dsODENet.
Figure <a href="#S3.F7" title="Figure 7 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows box-plots of accuracies of ODENet-50
using weight parameters trained as ODENet-34, 50, and 101, respectively.
Figure <a href="#S3.F7" title="Figure 7 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows those of dsODENet-50.
The results from Figure <a href="#S3.F7" title="Figure 7 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Table
<a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show that the accuracies depend on <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">N</annotation></semantics></math> of the
trained model.
The results from Figure <a href="#S3.F7" title="Figure 7 â€£ 3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Table
<a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show the same tendency in dsODENet.</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x4.png" id="S3.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Accuracy of ODENet-34, 50, and 101 using parameters
trained as ODENet-50 [%]</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x5.png" id="S3.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Accuracy of dsODENet-34, 50, and 101 using parameters
trained as dsODENet-50 [%]</figcaption>
</figure>
</div>
</div>
</figure>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x6.png" id="S3.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Accuracy of ODENet-50 using parameters trained as
ODENet-34, 50, and 101 [%]</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x7.png" id="S3.F7.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Accuracy of dsODENet-50 using parameters trained as
dsODENet-34, 50, and 101 [%]</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.2" class="ltx_p">As mentioned above, the inference accuracies of the ODENet and
dsODENet models are reasonable even if the trained <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">N</annotation></semantics></math> and tested <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">N</annotation></semantics></math>
are different.
This means that ODENet and dsODENet models have a weight parameter
compatibility with different depths.
Furthermore, Table <a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that the accuracies
of models that were trained as ODENet-101 are higher than those that
were trained as ODENet-34 and ODENet-50.
Table <a href="#S3.T2" title="Table 2 â€£ 3.1 Target Models â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> also shows a similar tendency in
dsODENet.
These results indicate that using a deeper model for training can
help to enhance the accuracy in ODENet and dsODENet models.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Federated Learning with Different Depths</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">In Section <a href="#S3.SS2" title="3.2 Weight Compatibility with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we showed the weight parameter compatibility
in ODENet and dsODENet models with different depths.
In this section, we examine the feasibility of federated learning
between ODENet models with different depths.
Specifically, we perform federated learning of two ODENet models from
among <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">N</annotation></semantics></math> = 34, 50, and 101 to see if it works correctly.
In this experiment, FedAvg is used as a federated learning algorithm.
The number of clients is only 2, the number of local epochs is 5, and
the number of communication rounds is 20.
ODENet-50 is used as a global model.
The same experiment is performed for dsODENet too.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">Figures <a href="#S3.F9" title="Figure 9 â€£ 3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#S3.F9" title="Figure 9 â€£ 3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> show training
curves (epoch number vs. loss value) of the ODENet and dsODENet models,
respectively.
In Figure <a href="#S3.F9" title="Figure 9 â€£ 3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, the black, red, green, and blue lines
show the loss values when federated learning is performed between
ODENet-50 and ODENet-50, between ODENet-34 and ODENet-50, between
ODENet-50 and ODENet-101, and between ODENet-34 and ODENet-101,
respectively.
Similarly, in Figure <a href="#S3.F9" title="Figure 9 â€£ 3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, the black, red, green, and
blue lines show the loss values when federated learning is performed
between dsODENet-50 and dsODENet-50, between dsODENet-34 and
dsODENet-50, between dsODENet-50 and dsODENet-101, and between
dsODENet-34 and dsODENet-101, respectively.
The horizontal axis of these figures represents the number of epochs,
and the vertical axis represents the loss value.
As shown, the loss values decrease as the number of epochs is
increased, and then they are converged around 50 epochs in all the
combinations.
This indicates that these model combinations of different depths can
be trained successfully.
This and previous sections demonstrated that ODENet and dsODENet are
capable of federated learning between models with different depths.</p>
</div>
<figure id="S3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x8.png" id="S3.F9.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Training curve (epoch number vs. loss value) of ODENet</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:212.5pt;"><img src="/html/2208.09478/assets/x9.png" id="S3.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Training curve (epoch number vs. loss value) of dsODENet</figcaption>
</figure>
</div>
</div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluations</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the proposed flexible federated learning
approach that uses FedAvg as a federated learning algorithm and
ODENet, dsODENet, and ResNet as client models.
They are compared with FedDF which is a model agnostic federated
learning approach using a knowledge distillation.
Finally, the proposed approach is evaluated in terms of the model size
and communication cost.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">Python 3.8.5, PyTorch 1.8.1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and torchvision 0.9.1 are
used for the model implementation.
A machine with Ubuntu 18.04.5 LTS (64-bit), Intel Core i7-10700K CPU @
3.8GHz, 32GB DDR4 SDRAM, and NVIDIA GeForce RTX 3090 GPU is used for
the evaluation in this paper.</p>
</div>
<figure id="S4.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F12.3" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:143.1pt;"><img src="/html/2208.09478/assets/x10.png" id="S4.F12.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Data distribution using Dirichlet distribution (<math id="S4.F12.3.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F12.3.2.m1.1b"><mi id="S4.F12.3.2.m1.1.1" xref="S4.F12.3.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.F12.3.2.m1.1c"><ci id="S4.F12.3.2.m1.1.1.cmml" xref="S4.F12.3.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F12.3.2.m1.1d">\alpha</annotation></semantics></math> = 1)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F12.6" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:143.1pt;"><img src="/html/2208.09478/assets/x11.png" id="S4.F12.4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Data distribution using Dirichlet distribution (<math id="S4.F12.6.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F12.6.2.m1.1b"><mi id="S4.F12.6.2.m1.1.1" xref="S4.F12.6.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.F12.6.2.m1.1c"><ci id="S4.F12.6.2.m1.1.1.cmml" xref="S4.F12.6.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F12.6.2.m1.1d">\alpha</annotation></semantics></math> = 10)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F12.9" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:143.1pt;"><img src="/html/2208.09478/assets/x12.png" id="S4.F12.7.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Data distribution using Dirichlet distribution (<math id="S4.F12.9.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F12.9.2.m1.1b"><mi id="S4.F12.9.2.m1.1.1" xref="S4.F12.9.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.F12.9.2.m1.1c"><ci id="S4.F12.9.2.m1.1.1.cmml" xref="S4.F12.9.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F12.9.2.m1.1d">\alpha</annotation></semantics></math> = 100)</figcaption>
</figure>
</div>
</div>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Accuracy</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">Although Section <a href="#S3.SS3" title="3.3 Federated Learning with Different Depths â€£ 3 Proposed Federated Learning â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> showed the feasibility of the
proposed federated learning, only two clients were used in the
experiments.
However, it is expected that more clients participate in a practical
federated learning scenario.
In this section, we increase the number of clients and conduct
additional experiments.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.3" class="ltx_p">In addition, it is expected that there is a bias in the data
distribution for each client in the case of real environments.
This means that the data distribution for each client is non-iid.
In this experiment, Dirichlet distribution is thus used to make non-iid
data environments.
Dirichlet distribution is a kind of continuous multivariate
probability distributions, and its data distribution is controlled by
a vector <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\alpha</annotation></semantics></math>.
We use <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\alpha</annotation></semantics></math> = 1, 10, and 100.
CIFAR-10 is used as a dataset.
Figures <a href="#S4.F12" title="Figure 12 â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>-<a href="#S4.F12" title="Figure 12 â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> show examples of data
distributions with <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mi id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\alpha</annotation></semantics></math> = 1, 10, and 100 as Dirichlet distribution
parameters, respectively.</p>
</div>
<figure id="S4.T5" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Accuracy of ODENet and dsODENet when using FedAvg and FedDF (<math id="S4.T5.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T5.2.m1.1b"><mi id="S4.T5.2.m1.1.1" xref="S4.T5.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T5.2.m1.1c"><ci id="S4.T5.2.m1.1.1.cmml" xref="S4.T5.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.m1.1d">\alpha</annotation></semantics></math> = 1)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T5.7" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.7.1.1" class="ltx_tr">
<th id="S4.T5.7.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S4.T5.7.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Algorithm</th>
<th id="S4.T5.7.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top5 [%]</th>
<th id="S4.T5.7.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top1 [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.7.2.1" class="ltx_tr">
<td id="S4.T5.7.2.1.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet</td>
<td id="S4.T5.7.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.7.2.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">96.33</td>
<td id="S4.T5.7.2.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">66.83</td>
</tr>
<tr id="S4.T5.7.3.2" class="ltx_tr">
<td id="S4.T5.7.3.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S4.T5.7.3.2.2" class="ltx_td ltx_align_right ltx_border_r">FedDF</td>
<td id="S4.T5.7.3.2.3" class="ltx_td ltx_align_right ltx_border_r">98.23</td>
<td id="S4.T5.7.3.2.4" class="ltx_td ltx_align_right ltx_border_r">73.73</td>
</tr>
<tr id="S4.T5.7.4.3" class="ltx_tr">
<td id="S4.T5.7.4.3.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet</td>
<td id="S4.T5.7.4.3.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.7.4.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">96.68</td>
<td id="S4.T5.7.4.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">66.91</td>
</tr>
<tr id="S4.T5.7.5.4" class="ltx_tr">
<td id="S4.T5.7.5.4.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S4.T5.7.5.4.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">FedDF</td>
<td id="S4.T5.7.5.4.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">98.40</td>
<td id="S4.T5.7.5.4.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">75.67</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Accuracy of ODENet and dsODENet when using FedAvg and FedDF (<math id="S4.T5.4.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T5.4.m1.1a"><mi id="S4.T5.4.m1.1.1" xref="S4.T5.4.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T5.4.m1.1b"><ci id="S4.T5.4.m1.1.1.cmml" xref="S4.T5.4.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.m1.1c">\alpha</annotation></semantics></math> = 10)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T5.8" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.8.1.1" class="ltx_tr">
<th id="S4.T5.8.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S4.T5.8.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Algorithm</th>
<th id="S4.T5.8.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top5 [%]</th>
<th id="S4.T5.8.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top1 [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.8.2.1" class="ltx_tr">
<td id="S4.T5.8.2.1.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet</td>
<td id="S4.T5.8.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.8.2.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.25</td>
<td id="S4.T5.8.2.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">69.74</td>
</tr>
<tr id="S4.T5.8.3.2" class="ltx_tr">
<td id="S4.T5.8.3.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S4.T5.8.3.2.2" class="ltx_td ltx_align_right ltx_border_r">FedDF</td>
<td id="S4.T5.8.3.2.3" class="ltx_td ltx_align_right ltx_border_r">98.87</td>
<td id="S4.T5.8.3.2.4" class="ltx_td ltx_align_right ltx_border_r">78.55</td>
</tr>
<tr id="S4.T5.8.4.3" class="ltx_tr">
<td id="S4.T5.8.4.3.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet</td>
<td id="S4.T5.8.4.3.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.8.4.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.27</td>
<td id="S4.T5.8.4.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">69.82</td>
</tr>
<tr id="S4.T5.8.5.4" class="ltx_tr">
<td id="S4.T5.8.5.4.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S4.T5.8.5.4.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">FedDF</td>
<td id="S4.T5.8.5.4.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">98.81</td>
<td id="S4.T5.8.5.4.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">78.63</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Accuracy of ODENet and dsODENet when using FedAvg and FedDF (<math id="S4.T5.6.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T5.6.m1.1a"><mi id="S4.T5.6.m1.1.1" xref="S4.T5.6.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T5.6.m1.1b"><ci id="S4.T5.6.m1.1.1.cmml" xref="S4.T5.6.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.m1.1c">\alpha</annotation></semantics></math> = 100)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T5.9" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.9.1.1" class="ltx_tr">
<th id="S4.T5.9.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S4.T5.9.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Algorithm</th>
<th id="S4.T5.9.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top5 [%]</th>
<th id="S4.T5.9.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top1 [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.9.2.1" class="ltx_tr">
<td id="S4.T5.9.2.1.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet</td>
<td id="S4.T5.9.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.9.2.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.33</td>
<td id="S4.T5.9.2.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">70.48</td>
</tr>
<tr id="S4.T5.9.3.2" class="ltx_tr">
<td id="S4.T5.9.3.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S4.T5.9.3.2.2" class="ltx_td ltx_align_right ltx_border_r">FedDF</td>
<td id="S4.T5.9.3.2.3" class="ltx_td ltx_align_right ltx_border_r">98.78</td>
<td id="S4.T5.9.3.2.4" class="ltx_td ltx_align_right ltx_border_r">78.67</td>
</tr>
<tr id="S4.T5.9.4.3" class="ltx_tr">
<td id="S4.T5.9.4.3.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet</td>
<td id="S4.T5.9.4.3.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">FedAvg</td>
<td id="S4.T5.9.4.3.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.38</td>
<td id="S4.T5.9.4.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">70.06</td>
</tr>
<tr id="S4.T5.9.5.4" class="ltx_tr">
<td id="S4.T5.9.5.4.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S4.T5.9.5.4.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">FedDF</td>
<td id="S4.T5.9.5.4.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">98.89</td>
<td id="S4.T5.9.5.4.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">78.72</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.2" class="ltx_p">In this experiment, the number of clients is 30, the number of local
epochs is 40, and the number of communication rounds is 100.
Among the 30 clients, the numbers of clients that use ODENet-34,
ODENet-50, and ODENet-101 are 10, 10, and 10, respectively.
ODENet-50 is used as a global model.
In Algorithm <a href="#alg1" title="Algorithm 1 â€£ 2.1 Federated Learning â€£ 2 Related Work â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">r</annotation></semantics></math> is the percentage of
clients participating in the aggregation at each communication round.
In this experiment, <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">r</annotation></semantics></math> is set to 0.2, which means that six models
are randomly selected from the 30 clients.
FedAvg is used in the proposed federated learning approach, and the
results are compared with those of FedDF.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.4" class="ltx_p">Tables <a href="#S4.T5" title="Table 5 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>-<a href="#S4.T5" title="Table 5 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> show the accuracies of
ODENet-50 and dsODENet-50 with FedAvg and FedDF when <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\alpha</annotation></semantics></math> = 1, 10,
and 100, respectively.
Top5 accuracies are mostly high regardless of <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mi id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\alpha</annotation></semantics></math> in both
the models.
Top1 accuracies are decreased when <math id="S4.SS1.p4.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p4.3.m3.1a"><mi id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><ci id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">\alpha</annotation></semantics></math> is small (e.g., <math id="S4.SS1.p4.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p4.4.m4.1a"><mi id="S4.SS1.p4.4.m4.1.1" xref="S4.SS1.p4.4.m4.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.1b"><ci id="S4.SS1.p4.4.m4.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.1c">\alpha</annotation></semantics></math> = 1).
In this case, the data distribution is highly biased, and the
biased data distribution negatively affects the accuracy.
Although addressing the data heterogeneity is a crucial challenge in
federated learning, many studies have been conducted to overcome this
issue as mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and thus addressing this is beyond
the scope of this paper.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p">When we compare the proposed approach using FedAvg with FedDF, the
accuracies of the proposed approach are lower than those of FedDF.
This result is reasonable since FedDF introduces additional training
overheads for the knowledge distillation (e.g., prediction and
training of client models) at the server in addition to local training
at the clients while the proposed approach does not impose such
overheads as well as the conventional FedAvg based approach.
To bring the evaluation condition of FedDF closer to that of the
proposed approach, here we limit the number of samples to be used in
the knowledge distillation at the server.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para ltx_noindent">
<p id="S4.SS1.p6.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the results of FedDF when the number
of samples available for the knowledge distillation is varied.
<math id="S4.SS1.p6.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p6.1.m1.1a"><mi id="S4.SS1.p6.1.m1.1.1" xref="S4.SS1.p6.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p6.1.m1.1b"><ci id="S4.SS1.p6.1.m1.1.1.cmml" xref="S4.SS1.p6.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p6.1.m1.1c">\alpha</annotation></semantics></math> is set to 10 as the data distribution parameter.
The other conditions are same as those in Table <a href="#S4.T5" title="Table 5 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
As shown in Table <a href="#S4.T6" title="Table 6 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the accuracy of FedDF increases
as the number of server-side samples used in the knowledge
distillation is increased.
When the number of the available server-side samples is small, the
accuracy of FedDF becomes close to (or lower than) the proposed approach,
as shown in Tables <a href="#S4.T5" title="Table 5 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S4.T6" title="Table 6 â€£ 4.1 Accuracy â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
Please note that server-side overheads of FedDF are larger than those
of the proposed approach since FedDF requires the knowledge
distillation at the server.
In addition, FedDF requires training samples at the server; however,
uploading such samples to the server may not be easy depending on the
application due to data privacy perspective (e.g., medial image data).
On the other hand, the proposed approach can simply aggregate ODENet
based models with different iteration counts without the server-side
training nor uploading training samples to the server.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Accuracy of FedDF when varying the number of samples
used for knowledge distillation (<math id="S4.T6.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T6.2.m1.1b"><mi id="S4.T6.2.m1.1.1" xref="S4.T6.2.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.T6.2.m1.1c"><ci id="S4.T6.2.m1.1.1.cmml" xref="S4.T6.2.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.m1.1d">\alpha</annotation></semantics></math> = 10)</figcaption>
<table id="S4.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.4.3.1" class="ltx_tr">
<th id="S4.T6.4.3.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S4.T6.4.3.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"># of server samples</th>
<th id="S4.T6.4.3.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top5 [%]</th>
<th id="S4.T6.4.3.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Top1 [%]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.4.4.1" class="ltx_tr">
<th id="S4.T6.4.4.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">ODENet</th>
<th id="S4.T6.4.4.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">5</th>
<td id="S4.T6.4.4.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.22</td>
<td id="S4.T6.4.4.1.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">69.53</td>
</tr>
<tr id="S4.T6.4.5.2" class="ltx_tr">
<th id="S4.T6.4.5.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.5.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">10</th>
<td id="S4.T6.4.5.2.3" class="ltx_td ltx_align_right ltx_border_r">97.09</td>
<td id="S4.T6.4.5.2.4" class="ltx_td ltx_align_right ltx_border_r">70.49</td>
</tr>
<tr id="S4.T6.4.6.3" class="ltx_tr">
<th id="S4.T6.4.6.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.6.3.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">100</th>
<td id="S4.T6.4.6.3.3" class="ltx_td ltx_align_right ltx_border_r">97.95</td>
<td id="S4.T6.4.6.3.4" class="ltx_td ltx_align_right ltx_border_r">74.37</td>
</tr>
<tr id="S4.T6.4.7.4" class="ltx_tr">
<th id="S4.T6.4.7.4.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.7.4.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">500</th>
<td id="S4.T6.4.7.4.3" class="ltx_td ltx_align_right ltx_border_r">98.57</td>
<td id="S4.T6.4.7.4.4" class="ltx_td ltx_align_right ltx_border_r">76.48</td>
</tr>
<tr id="S4.T6.4.8.5" class="ltx_tr">
<th id="S4.T6.4.8.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.8.5.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">1000</th>
<td id="S4.T6.4.8.5.3" class="ltx_td ltx_align_right ltx_border_r">98.71</td>
<td id="S4.T6.4.8.5.4" class="ltx_td ltx_align_right ltx_border_r">78.32</td>
</tr>
<tr id="S4.T6.3.1" class="ltx_tr">
<th id="S4.T6.3.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.3.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r"><math id="S4.T6.3.1.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T6.3.1.1.m1.1a"><mi mathvariant="normal" id="S4.T6.3.1.1.m1.1.1" xref="S4.T6.3.1.1.m1.1.1.cmml">âˆ</mi><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.1.m1.1b"><infinity id="S4.T6.3.1.1.m1.1.1.cmml" xref="S4.T6.3.1.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.1.m1.1c">\infty</annotation></semantics></math></th>
<td id="S4.T6.3.1.3" class="ltx_td ltx_align_right ltx_border_r">98.87</td>
<td id="S4.T6.3.1.4" class="ltx_td ltx_align_right ltx_border_r">78.55</td>
</tr>
<tr id="S4.T6.4.9.6" class="ltx_tr">
<th id="S4.T6.4.9.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">dsODENet</th>
<th id="S4.T6.4.9.6.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">5</th>
<td id="S4.T6.4.9.6.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">97.18</td>
<td id="S4.T6.4.9.6.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">69.52</td>
</tr>
<tr id="S4.T6.4.10.7" class="ltx_tr">
<th id="S4.T6.4.10.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.10.7.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">10</th>
<td id="S4.T6.4.10.7.3" class="ltx_td ltx_align_right ltx_border_r">97.16</td>
<td id="S4.T6.4.10.7.4" class="ltx_td ltx_align_right ltx_border_r">69.82</td>
</tr>
<tr id="S4.T6.4.11.8" class="ltx_tr">
<th id="S4.T6.4.11.8.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.11.8.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">100</th>
<td id="S4.T6.4.11.8.3" class="ltx_td ltx_align_right ltx_border_r">97.93</td>
<td id="S4.T6.4.11.8.4" class="ltx_td ltx_align_right ltx_border_r">73.88</td>
</tr>
<tr id="S4.T6.4.12.9" class="ltx_tr">
<th id="S4.T6.4.12.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.12.9.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">500</th>
<td id="S4.T6.4.12.9.3" class="ltx_td ltx_align_right ltx_border_r">98.41</td>
<td id="S4.T6.4.12.9.4" class="ltx_td ltx_align_right ltx_border_r">76.89</td>
</tr>
<tr id="S4.T6.4.13.10" class="ltx_tr">
<th id="S4.T6.4.13.10.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.13.10.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">1000</th>
<td id="S4.T6.4.13.10.3" class="ltx_td ltx_align_right ltx_border_r">98.73</td>
<td id="S4.T6.4.13.10.4" class="ltx_td ltx_align_right ltx_border_r">78.32</td>
</tr>
<tr id="S4.T6.4.2" class="ltx_tr">
<th id="S4.T6.4.2.2" class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"></th>
<th id="S4.T6.4.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_r"><math id="S4.T6.4.2.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S4.T6.4.2.1.m1.1a"><mi mathvariant="normal" id="S4.T6.4.2.1.m1.1.1" xref="S4.T6.4.2.1.m1.1.1.cmml">âˆ</mi><annotation-xml encoding="MathML-Content" id="S4.T6.4.2.1.m1.1b"><infinity id="S4.T6.4.2.1.m1.1.1.cmml" xref="S4.T6.4.2.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.2.1.m1.1c">\infty</annotation></semantics></math></th>
<td id="S4.T6.4.2.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">98.81</td>
<td id="S4.T6.4.2.4" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">78.63</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Communication Size</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">Table <a href="#S4.T7" title="Table 7 â€£ 4.2 Communication Size â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows communication sizes of the ResNet,
ODENet, and dsODENet models with different depths.
Here, the communication size means the sum of the weight parameters of
convolutional layers and fully-connected layers in these models.
The communication is required between the server and clients in each
communication round.
The size is measured by using torchsummary of PyTorch which is a tool
that reports the parameter size information.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Communication size of ResNet, ODENet, and dsODENet</figcaption>
<table id="S4.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S4.T7.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"># of parameters transferred</th>
<th id="S4.T7.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t">Size [MB]</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.1.2.1" class="ltx_tr">
<td id="S4.T7.1.2.1.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ResNet-34</td>
<td id="S4.T7.1.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">21,780,648</td>
<td id="S4.T7.1.2.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">83.09</td>
</tr>
<tr id="S4.T7.1.3.2" class="ltx_tr">
<td id="S4.T7.1.3.2.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r">ResNet-50</td>
<td id="S4.T7.1.3.2.2" class="ltx_td ltx_align_right ltx_border_r">25,505,232</td>
<td id="S4.T7.1.3.2.3" class="ltx_td ltx_align_right ltx_border_r">97.29</td>
</tr>
<tr id="S4.T7.1.4.3" class="ltx_tr">
<td id="S4.T7.1.4.3.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r">ResNet-101</td>
<td id="S4.T7.1.4.3.2" class="ltx_td ltx_align_right ltx_border_r">44,447,912</td>
<td id="S4.T7.1.4.3.3" class="ltx_td ltx_align_right ltx_border_r">169.55</td>
</tr>
<tr id="S4.T7.1.5.4" class="ltx_tr">
<td id="S4.T7.1.5.4.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">ODENet-34</td>
<td id="S4.T7.1.5.4.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">1,937,034</td>
<td id="S4.T7.1.5.4.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">7.39</td>
</tr>
<tr id="S4.T7.1.6.5" class="ltx_tr">
<td id="S4.T7.1.6.5.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r">ODENet-50</td>
<td id="S4.T7.1.6.5.2" class="ltx_td ltx_align_right ltx_border_r">1,937,034</td>
<td id="S4.T7.1.6.5.3" class="ltx_td ltx_align_right ltx_border_r">7.39</td>
</tr>
<tr id="S4.T7.1.7.6" class="ltx_tr">
<td id="S4.T7.1.7.6.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r">ODENet-101</td>
<td id="S4.T7.1.7.6.2" class="ltx_td ltx_align_right ltx_border_r">1,937,034</td>
<td id="S4.T7.1.7.6.3" class="ltx_td ltx_align_right ltx_border_r">7.39</td>
</tr>
<tr id="S4.T7.1.8.7" class="ltx_tr">
<td id="S4.T7.1.8.7.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t">dsODENet-34</td>
<td id="S4.T7.1.8.7.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">1,249,381</td>
<td id="S4.T7.1.8.7.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">4.76</td>
</tr>
<tr id="S4.T7.1.9.8" class="ltx_tr">
<td id="S4.T7.1.9.8.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_r">dsODENet-50</td>
<td id="S4.T7.1.9.8.2" class="ltx_td ltx_align_right ltx_border_r">1,249,381</td>
<td id="S4.T7.1.9.8.3" class="ltx_td ltx_align_right ltx_border_r">4.76</td>
</tr>
<tr id="S4.T7.1.10.9" class="ltx_tr">
<td id="S4.T7.1.10.9.1" class="ltx_td ltx_align_right ltx_border_b ltx_border_l ltx_border_r">dsODENet-101</td>
<td id="S4.T7.1.10.9.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">1,249,381</td>
<td id="S4.T7.1.10.9.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">4.76</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">Table <a href="#S4.T7" title="Table 7 â€£ 4.2 Communication Size â€£ 4 Evaluations â€£ Federated Learning of Neural ODE Models with Different Iteration Counts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows that both the ODENet and dsODENet models
reduce the communication sizes compared with the corresponding ResNet
model.
Compared with ResNet, the communication size of ODENet-50 is
7.6% of the original ResNet model.
In the case of ResNet and dsODENet, the communication size of
dsODENet-50 is 4.9% of the ResNet model.
These results show that the use of ODENet and dsODENet can
significantly reduce the communication size between the server and
clients.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.3" class="ltx_p">The communication size increases as <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">N</annotation></semantics></math> is increased in ResNet.
On the other hand, communication sizes are constant regardless of <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">N</annotation></semantics></math>
in the cases of ODENet and dsODENet.
This is because the number of physically-stacked blocks is the same in
ODENet and dsODENet even if <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">N</annotation></semantics></math> is different, and only the number of
iterations of each block is different.
Please note that, since the model size is small in ODENet and
dsODENet, the required memory capacity can also be reduced by these
models compared with the original ResNet model.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this paper, we proposed a flexible federated learning approach that
can aggregate models with different iteration counts by utilizing
ODENet and dsODENet as federated learning models.
We demonstrated that these models with different iteration counts can
be aggregated correctly (i.e., having the weight compatibility) in the
cases of ODENet and dsODENet.
Then, the proposed approach simply using FedAvg was compared with
FedDF in terms of the accuracy.
The experiment results showed that the higher accuracy of FedDF come
from additional knowledge distillation overheads at the server.
On the other hand, the proposed approach can simply aggregate models
with different iteration counts without the server-side training nor
uploading training samples to the server.
In addition, ODENet and dsODENet were evaluated in terms of the
model and communication sizes.
Compared with ResNet-50, ODENet-50 and dsODENet-50 successfully
reduced the communication sizes by 92.4% and by 95.1%, respectively.
These results showed that our approach can significantly reduce the
communication overhead while enabling the aggregation of models with
different iteration counts.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">As a future work, we will evaluate the feasibility of federated
learning with ANODE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> which is a Neural ODE based approach
that utilizes a checkpointing method.
We are also planning to improve accuracy when <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p2.1.m1.1a"><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\alpha</annotation></semantics></math> is small.
We will combine our approach with state-of-the-art federated
learning algorithms.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera
yÂ Arcas.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized
Data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Artificial
Intelligence and Statistics (AISTATS)</span>, pages 1273â€“1282, April 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Ricky T.Â Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud.

</span>
<span class="ltx_bibblock">Neural Ordinary Differential Equations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS)</span>, pages 6572â€“6583, December 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep Residual Learning for Image Recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, pages 770â€“778, June 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Hiroki Kawakami, Hirohisa Watanabe, Keisuke Sugiura, and Hiroki Matsutani.

</span>
<span class="ltx_bibblock">A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge
Domain Adaptation on FPGAs.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">IEICE Transactions on Information and Systems</span>,
E106-D(7):1186â€“1197, July 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
AndrewÂ G. Howard, Menglong Zhu, BoÂ Chen, Dmitry Kalenichenko, Weijun Wang,
Tobias Weyand, Marco Andreetto, and Hartwig Adam.

</span>
<span class="ltx_bibblock">MobileNets: Efficient Convolutional Neural Networks for Mobile
Vision Applications.

</span>
<span class="ltx_bibblock">arXiv Preprint arXiv:1704.04861, April 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Yuto Hoshino, Hiroki Kawakami, and Hiroki Matsutani.

</span>
<span class="ltx_bibblock">Communication Size Reduction of Federated Learning based on Neural
ODE Model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Symposium on Computing and
Networking (CANDAR) Workshops</span>, pages 55â€“61, November 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, XuÂ Liu, and
Bingsheng He.

</span>
<span class="ltx_bibblock">A Survey on Federated Learning Systems: Vision, Hype and Reality for
Data Privacy and Protection.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>,
35(4):3347â€“3366, April 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated Optimization in Heterogeneous Networks.

</span>
<span class="ltx_bibblock">arXiv Preprint arXiv:1812.06127, April 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
SaiÂ Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
Stich, and AnandaÂ Theertha Suresh.

</span>
<span class="ltx_bibblock">SCAFFOLD: Stochastic Controlled Averaging for Federated Learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Machine
Learning (ICML)</span>, pages 5132â€“5143, July 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with Theoretical Guarantees: A
Model-Agnostic Meta-Learning Approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS)</span>, pages 3557â€“3568, December 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Yuyang Deng, MohammadÂ Mahdi Kamani, and Mehrdad Mahdavi.

</span>
<span class="ltx_bibblock">Adaptive Personalized Federated Learning.

</span>
<span class="ltx_bibblock">arXiv Preprint arXiv:2003.13461, March 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Disha Makhija, Xing Han, Nhat Ho, and Joydeep Ghosh.

</span>
<span class="ltx_bibblock">Architecture Agnostic Federated Learning for Neural Networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Conference on Machine
Learning (ICML)</span>, pages 14860â€“14870, July 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, SebastianÂ U. Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble Distillation for Robust Model Fusion in Federated
Learning.

</span>
<span class="ltx_bibblock">arXiv Preprint arXiv:2006.07242, March 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Alex Krizhevsky.

</span>
<span class="ltx_bibblock">Learning Multiple Layers of Features from Tiny Images, April 2009.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
Tejani, Sasank Chilamkurthy, Benoit Steiner, LuÂ Fang, Junjie Bai, and Soumith
Chintala.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance Deep Learning
Library.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS)</span>, pages 8024â€“8035, December 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Amir Gholaminejad, Kurt Keutzer, and George Biros.

</span>
<span class="ltx_bibblock">ANODE: Unconditionally Accurate Memory-Efficient Gradients for
Neural ODEs.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Joint Conference on
Artificial Intelligence (IJCAI)</span>, pages 730â€“736, August 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.09477" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.09478" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.09478">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.09478" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.09479" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 19:46:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
