<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud</title>
<!--Generated on Tue Oct  8 11:24:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Machine Learning,  ICML" lang="en" name="keywords"/>
<base href="/html/2410.05930v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S1" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>FM threat model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S3" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods to protect FMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Establishing trust in the FM deployment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.SS1" title="In 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Protections against threats</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.SS2" title="In 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Deployment and threat considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.SS3" title="In 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Future directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Lifting FMs into TEEs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5.SS1" title="In 5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Software Guard Extension (SGX)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5.SS2" title="In 5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Trusted Domain Extensions (TDX)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5.SS3" title="In 5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Performance optimizations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Performance of LLMs in TEEs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.SS1" title="In 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Experimental setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.SS2" title="In 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Latency and Generation Speed</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS1" title="In 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Accelerator based TEEs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS2" title="In 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Process or VM TEEs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS3" title="In 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S8" title="In Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcin Chrapek
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anjo Vahldiek-Oberwagner
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcin Spoczynski
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Scott Constable
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mona Vij
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Torsten Hoefler
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Foundation Models (FMs) display exceptional performance in tasks such as natural language processing and are being applied across a growing range of disciplines. Although typically trained on large public datasets, FMs are often fine-tuned or integrated into Retrieval-Augmented Generation (RAG) systems, which rely on private data. This access, along with their size and costly training, heightens the risk of intellectual property theft. Moreover, multimodal FMs may expose sensitive information. In this work, we examine the FM threat model and discuss the practicality and comprehensiveness of various approaches for securing against them, such as ML-based methods and trusted execution environments (TEEs). We demonstrate that TEEs offer an effective balance between strong security properties, usability, and performance. Specifically, we present a solution achieving less than 10% overhead versus bare metal for the full Llama2 7B and 13B inference pipelines running inside Intel<sup class="ltx_sup" id="id1.id1.1">®</sup> SGX and Intel<sup class="ltx_sup" id="id1.id1.2">®</sup> TDX. We also share our configuration files and insights from our implementation. To our knowledge, our work is the first to show the practicality of TEEs for securing FMs.</p>
</div>
<div class="ltx_keywords">Machine Learning, ICML
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break"/>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="S1.F1.g1" src="x1.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples of the types of threats our approach leveraging TEEs protects actively against. We also show our example performance results for baseline inference of Llama2 7B INT8 in two TEE implementations, a Virtual Machine (VM) and an application-based one.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Foundation Models (FMs) are dominating the machine learning (ML) landscape. Exemplified by Large Language Models (LLMs), such as GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib44" title="">OpenAI et al., </a>)</cite>, GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib12" title="">Brown et al., </a>)</cite>, Llama <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib58" title="">a</a>)</cite>, and Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib59" title="">b</a>)</cite>, they displayed impressive in-context learning abilities. FMs such as LLMs achieve human-like capabilities that have revolutionized many ML tasks <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib8" title="">Awais et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib70" title="">Zhao et al., </a>)</cite> and have been successfully applied to disciplines relying on <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">confidential</span> user data such as healthcare <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib52" title="">Sallam, </a>)</cite>, finance <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib67" title="">b</a>)</cite>, sentiment analysis <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib7" title="">Araci, </a>)</cite>, legal cases <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib20" title="">Cui et al., </a>)</cite>, and document translation <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib33" title="">Kocmi &amp; Federmann, </a>)</cite>. Simultaneously, the ever-increasing size of FMs has changed their deployment strategies. FMs reach billions to trillions of parameters, necessitating state-of-the-art hardware to achieve reasonable performance. However, such hardware is frequently unavailable or too expensive for small developers. This results in models not being deployed locally but offered as a service <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib50" title="">Ribeiro et al., </a>)</cite> by major cloud service providers (CSPs). However, CSPs have an interest in using the data users provide for model training. Imagine a situation where you upload health-related documents after an accident for an insurance claim. The insurer uses an LLM deployed in the cloud to parse your data, put it into the correct format for a database, and check for abnormalities. In a couple of weeks, you open a publically available LLM to realize that after inputting a certain sequence of characters <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib14" title="">Carlini et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib46" title="">Patil et al., </a>)</cite>, your name, address, social security number, prior health history, and accident details are visible. Someone stole your data, or the CSP or model owner used it for training. Such a drastic shift in data interest compared to previous ML models <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib69" title="">b</a>)</cite> introduces new types of adversaries we discuss in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Such new adversaries create new threats. The right side of Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">1</span></a> shows example attacks that FMs need to be shielded from. Protection against these threats is becoming increasingly important for FMs, which become abundant in companies and everyday life in a growing number of domains with access to multimodal <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib66" title="">a</a>)</cite> user confidential data. This trend reflects a broader shift in focus toward privacy and security among governments, companies, and users <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib28" title="">Goldfarb &amp; Tucker, </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib47" title="">Petrescu &amp; Krishen, </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib64" title="">Voss, </a>)</cite>. Apart from confidentiality, theft is another threat to FMs. The cost of obtaining the necessary datasets and engineering considerably increases the IP value of FMs. Training and fine-tuning alone can cost tens of millions of dollars <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib54" title="">Sharir et al., </a>)</cite>. Any security breach involving FMs, including the leak of confidential data or IP, is becoming increasingly costly for CSPs (e.g., Azure, AWS, Google Cloud), model providers (e.g., Meta AI, OpenAI), and end-users (e.g., banks, hospitals). As more companies enter the space of personalized AI (e.g., Meta’s AI studio or Adobe Creator), we already observe backlashes from users interested in their data <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib43" title="">Ng, </a>)</cite>, making such threats tangible and requiring immediate attention.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The ML community approached the security and privacy issues associated with third-party evaluated DNNs <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib69" title="">b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib32" title="">Knott et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib25" title="">Dowlin et al., </a>)</cite> using mechanisms such as watermarking or user authentication. A practical alternative to these methods can be trusted execution environments (TEEs). TEEs promise strong security features at the expense of workload-dependent performance. We discuss these and other approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S3" title="3 Methods to protect FMs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">3</span></a>. We show that TEEs provide strong, measurable security properties for FMs against the threats important to industry companies deploying models in the cloud, in line with the model from Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>. Furthermore, besides providing security and privacy, TEEs can be leveraged to assure model-related properties, such as accuracy assurances or dataset content verification. We introduce in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4" title="4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4</span></a> a specific flow for providing security and privacy to FMs deployed within TEEs.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">While TEEs provide strong properties, we investigate whether they matured enough to be a practical solution for ML practitioners interested in protecting their FMs. Past studies <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib40" title="">Mo et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib6" title="">Akram et al., </a>)</cite> have pointed to two issues with using TEEs: <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">programming difficulty</span> and <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">performance overheads</span>. We address both of these in our work. As we show in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5" title="5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a>, we implement an FM inference pipeline within TEEs leveraging virtual machines (VMs) and library operating systems (OSs) such as Gramine <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib62" title="">Tsai et al., </a>)</cite>. We open-source our setup for others to leverage and share the insights we learned throughout the process. To address the performance issues, we run an entire Llama2 inference pipeline within TEEs and, for the first time to the best of our knowledge, present performance numbers for such setup in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.F5" title="Figure 5 ‣ 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a>. The left part of Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">1</span></a> displays our example performance results, showing that TEEs incur only 4-7% throughput reduction as compared to up to 100s% reported in the literature <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib6" title="">Akram et al., </a>)</cite>. Finally, we also discuss training, GPU support, and the choice between different types of TEEs in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7" title="7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>FM threat model</h2>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="570" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of the threats and adversaries that exist when offloading FM deployments to the cloud, together with representative examples.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Three main actors of interest are a part of the modern FM ecosystem: CSPs, model providers, and users. CSPs (e.g., Azure, GCP, AWS) usually only offer a service where models can be deployed and rarely work on FMs. Most FMs are developed by model providers with two forms: AI-focused (e.g., OpenAI, Anthropic) or non-AI-focused (e.g., bank, hospital, insurer). The former focuses on building and offering users proprietary general models (e.g., GPT4) as a website or API. The latter usually leverages public models (e.g., Llama) to build case-dependent proprietary models offering users specific services or interfaces to use them. This is usually achieved by fine-tuning the public models or creating Retrieval-Augmented Generation (RAG) solutions based on the company’s proprietary and sensitive files, which are added to the FM query to provide additional context. From an economic perspective, it is not worth training the model from scratch for these non-AI-oriented companies. We focus our work predominantly on threats to such private company deployments on the cloud infrastructure as these have access to more confidential data than general AI-focused companies. The users in such a case can be private individuals (e.g., insured persons or patients) or company employees (e.g., internally deployed HR model). We discuss other deployment possibilities in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.SS3" title="4.3 Future directions ‣ 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Examples of deployments that we focus on are a bank running an LLM parsing client statements to provide insights (e.g., how much did I spend on groceries this month), an insurer checking medical bills for abnormalities, or healthcare-provider parsing documentation (e.g., for personalized medication). Such high-value industries need IP protection for their deployed models, as not only do they constitute a competitive advantage, but they also may contain company secrets and user data. Even if the model used has not been fine-tuned, as is a vanilla public model, these industries require the confidentiality of user data. Because of these needs, the aforementioned industries cannot leverage efficient CSP scaling of advances in FMs. Promises from the CSPs that the data will not be used for other training or that the models will not be investigated are frequently insufficient guarantees.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In the above setting, we differentiate between three types of threat surfaces and their corresponding adversaries. The first two are connected with malicious actors trying to steal the model, steal user data, or disrupt the service. The third is associated with the dishonest and organized operation of the CSP. From the perspective of the model provider, the only trusted entity is the hardware itself. The end user trusts the model provider. This assumption is reasonable, as end users already do so for institutions such as banks and hospitals or their employers. The operating system, the network, the system administrators, and the CSP are not trusted. We present an overview of these threat surfaces and adversaries in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2.F2" title="Figure 2 ‣ 2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>. We focus only on inference and discuss training in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS3" title="7.3 Training ‣ 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">7.3</span></a>. Finally, we do not consider a distributed setup with multiple computing hosts <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib9" title="">Ben-Nun &amp; Hoefler, </a>)</cite>. This considerably increases the trusted computing base (TCB) and is usually unnecessary for the inference we focus on.</p>
</div>
<div class="ltx_para" id="S2.p4">
<svg class="ltx_picture" height="15.74" id="S2.p4.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#FF0000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.p4.pic1.1.1.1.1.1">1</span></foreignobject></g></g></svg>
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Eavesdropping:</span> The first threat surface represents adversaries that try to eavesdrop on either the models or the user’s confidential data. These adversaries are usually privileged in some way by either being employed by the CSP or having unauthorized access to the cluster. However, they are malicious and do not act in line with the CSP. An example of such attackers would be a rogue system administrator or another tenant within the system. They can obtain the weights or prompts by locating themselves within the network or the system. Furthermore, such adversaries could try to extract sensitive user data from the model by prompting it in the background within the cloud. Finally, the adversary might use certain input/output pairs of the model as their private training data. All these thefts offer potentially large gains with relatively low risks, as detecting such actions at the scale is nontrivial. We do not consider whole model extraction attacks <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib61" title="">Tramèr et al., </a>)</cite> as a big threat as such attacks scale poorly for large models such as FMs.</p>
</div>
<div class="ltx_para" id="S2.p5">
<svg class="ltx_picture" height="15.74" id="S2.p5.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#FF0000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.p5.pic1.1.1.1.1.1">2</span></foreignobject></g></g></svg>
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Tampering:</span> The second type of threat surface corresponds to adversaries not interested in stealing the models but disrupting the service through modifying critical data. Similarly to the first type, they are also malicious and do not act in line with the CSP. Again, examples include system administrators and other malicious software on the system that is trying to disrupt or hinder the program. They might tamper with the model’s weights randomly to lower the prediction accuracy and change the output or the user context, which usually results in service disruption.</p>
</div>
<div class="ltx_para" id="S2.p6">
<svg class="ltx_picture" height="15.74" id="S2.p6.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#FF0000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.p6.pic1.1.1.1.1.1">3</span></foreignobject></g></g></svg>
<p class="ltx_p" id="S2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.p6.1.1">CSP violations:</span> While similar to the second type, we specified the third type of threat surface separately due to the uniqueness of the organized approach of the actors operating on it. Unlike the prior two, the third adversary is not malicious. It is the CSP that is interested in violating different contract agreements by, for example, modifying the deployed model or using the data to train other models. The goal of the modifications might be to improve the performance of their runtimes and save money (e.g., automatic quantization) or reduce the accuracy to make the users migrate to better and newer models. Such modifications without the consent of the users happen in practice <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib15" title="">Chen et al., </a>)</cite>. This adversary is new and did not exist in the prior ML models as their data was rarely in a unified format, and their runtimes were considerably smaller and faster, not requiring as much optimization.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods to protect FMs</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Broadly, three approaches can be applied to protect against security threats in FMs: ML methods, cryptographic methods such as Homomorphic Encryption (HE) and multiparty computation (MPC), and Confidential Computing (CC) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib41" title="">Mulligan et al., </a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">As noted in the literature <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib69" title="">b</a>)</cite>, current ML IP protection methods lack in the space of actively protecting against model theft and instead focus predominantly on model verification and passive protections of already stolen models. The task there is to determine whether an output is coming from a given predefined model. One of the approaches is to use signatures embedded in the model to then submit multiple inputs and using outputs verify that the model is the one that was promised <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib34" title="">Lao et al., </a>)</cite>. This partially covers threats two and three from our threat model. Other methods include approaches such as passport <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib27" title="">Fan et al., </a>)</cite> or backdoor <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib68" title="">a</a>)</cite> based user authentication, and watermarking <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib57" title="">Szyller et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib11" title="">Boenisch, </a>)</cite>, in which a watermark is included in the model’s output or weights, allowing for ownership verification.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">While these protect against certain attacks, the threat model for ML methods does cover the threats we show in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>. Most importantly, they do not provide exhaustive and measurable security properties, making it risky for companies to rely purely on them, considering the cost of losing confidentiality or theft of IP. Additionally, ML methods have other crucial issues. They frequently require expensive FM retraining, change the accuracy of the model, do not secure the confidentiality of user prompts <cite class="ltx_cite ltx_citemacro_citep">(Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib69" title="">b</a>)</cite>, and cannot be combined together <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib56" title="">Szyller &amp; Asokan, </a>)</cite>. Cryptographic approaches such as HE and MPC address these issues with strong cryptographic protocols.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">HE allows to conduct mathematical and logical operations on encrypted data without decrypting it <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib5" title="">Acar et al., </a>)</cite>. HE has been explored in the context of DNNs <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib25" title="">Dowlin et al., </a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib36" title="">b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib65" title="">Wood et al., </a>)</cite>. However, with the exception of a few structured examples <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib18" title="">Chrapek et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib13" title="">Burkhalter et al., </a>)</cite>, the current state-of-the-art HE is not practical. HE approaches do not provide integrity protections (threats two and three). HE operations on encrypted data can also have up to 10,000x performance and size overheads, taking minutes to conduct simple MNIST inference <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib25" title="">Dowlin et al., </a>)</cite> and making FM inference intangible. MPC is close to HE and has similar practicality issues but involves multiple computing parties <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib63" title="">Viand &amp; Shafagh, </a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">CC offers a more practical and time-tested alternative in the form of TEEs by approaching the problem using strong security primitives implemented in hardened hardware. Compared to HE and MPC which rely on obscuring the data and functions, TEEs offer a secure and isolated environment frequently called an <span class="ltx_text ltx_font_italic" id="S3.p5.1.1">enclave</span>. Users can verify enclaves in a secure, hardware enabled process called <span class="ltx_text ltx_font_italic" id="S3.p5.1.2">attestation</span>. TEEs ensure the confidentiality and integrity of a running program and its data, and protect against external and privileged attackers such as system administrators. TEEs ensure these adversaries cannot access or modify the contents of the memory of the running programs <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib51" title="">Sabt et al., </a>)</cite> such as the weights or user confidential data, mitigating risks on the user side and reducing responsibility on the CSP side. TEEs have been implemented by the academic community and industry <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib53" title="">Schneider et al., </a>)</cite>. Only the latter are available widely on CSP platforms with examples such as AMD’s Secure Encrypted Virtualization-Secure Nested Paging (SEV-SNP) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib30" title="">Kaplan, </a>)</cite>, Intel’s<sup class="ltx_sup" id="S3.p5.1.3">®</sup> SGX <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib39" title="">McKeen et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib29" title="">Hoekstra et al., </a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib19" title="">Costan &amp; Devadas, </a>)</cite> and TDX <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib16" title="">a</a>)</cite>, ARM’s TrustZone <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib48" title="">Pinto &amp; Santos, </a>)</cite> and CCA <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib38" title="">Li et al., </a>)</cite>. All of these are CPU-based, but accelerators are also entering the space with notable example of Nvidia <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib42" title="">Nertney, </a>)</cite>. We discuss their current status in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS1" title="7.1 Accelerator based TEEs ‣ 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">7.1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.1">As we show in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4" title="4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4</span></a>, TEEs outperform ML methods by providing real-time, strong, measurable, and active protections against adversaries without any model modifications, ensuring that the model, data, and runtime environment remain secure and tamper-proof. While HE and MPC provide confidentiality, TEEs provide more than just that. They offer integrity checks, attestation, and runtime protections, all of which are absent in HE and MPC. TEEs are more suitable for scenarios where performance (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.F5" title="Figure 5 ‣ 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a>), real-time inference, and ease of use are essential, such as in healthcare, finance, and cloud-based AI services.</p>
</div>
<div class="ltx_para" id="S3.p7">
<p class="ltx_p" id="S3.p7.1">TEEs have been investigated in the past for protecting ML models <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib40" title="">Mo et al., </a>)</cite>. Yet most of these approaches offload only parts of the models to the TEE, usually providing weaker notions of security and claiming the low TEE performance (hundred times slowdown <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib6" title="">Akram et al., </a>)</cite>) as the reason. For example, Slalom <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib60" title="">Tramèr &amp; Boneh, </a>)</cite> would offload all linear layers to the GPU with a probabilistic algorithm guaranteeing some security. Such an approach does not resolve the accessibility issue of TEEs and makes it even harder to use with ML models. Furthermore, none of these previous works explored FMs and focused on simpler models, such as VGG16 or MobileNet, as the necessary model changes are large.</p>
</div>
<div class="ltx_para" id="S3.p8">
<p class="ltx_p" id="S3.p8.1">We address these shortcomings and, compared to previous approaches securing only certain model stages, show that offloading whole FMs to modern TEEs is practical. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4" title="4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4</span></a>, we address TEE accessibility, show the exact control flow of how to implement an entire pipeline for FMs in TEEs, and discuss the provided security. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5" title="5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a> we describe our implementation and the tools we leverage. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.F5" title="Figure 5 ‣ 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a>, we show the performance of our approach and the cost of the achieved security, which is similar or lower to the one noted in the literature.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Establishing trust in the FM deployment</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We cannot rely on techniques suggested in prior work <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib35" title="">a</a>)</cite> to establish trust in the deployment since the involved parties are more complex and deployment options differ. The majority of CSPs now offer TEE-based instances, sometimes referred to as confidential VMs (CVMs). While deploying a TEE on a CSP infrastructure can be done with a click of a button, the whole purpose of using a TEE is lost unless it is verified to be a true TEE. As mentioned earlier, TEEs support attestation <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib10" title="">Birkholz et al., </a>)</cite> that allows them to prove to a remote party that they are indeed a TEE with the correct software state using a generated quote. The verifier can check whether the TEE signer is an actual TEE, and the hash of the code running in a TEE. The model providers can use the CSP attestation service or an independent third-party verifier like Intel Tiber. We discuss the security aspect of this choice in the second part of this section.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="271" id="S4.F3.g1" src="x3.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An overview of a flow to secure FMs relying on properties of TEEs. Here, we assume a secure enclave on an untrusted host operated by the CSP and running some kind of an OS that supports its security features. Green lines show communication channels that are protected using confidentiality and integrity in some way (e.g., TLS or encrypted storage). Black lines are unprotected.</figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We assume there is a model provider who wants to create a service using an FM that is fine-tuned on sensitive proprietary data or handles confidential user data that requires protection against the threats defined in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.F3" title="Figure 3 ‣ 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">3</span></a> shows the overview of the steps the model provider can follow:</p>
</div>
<div class="ltx_para" id="S4.p3">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix1.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix1.1.1.pic1.1.1.1.1.1">1</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1">The model provider requests a TEE instance using the CSPs interface specifying the software that will be run on the instance (e.g., VM image).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix2.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix2.1.1.pic1.1.1.1.1.1">2</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix2.p1">
<p class="ltx_p" id="S4.I1.ix2.p1.1">The CSP allocates the TEE instance and provides the model provider with the associated IP needed to connect to the instance.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix3.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix3.1.1.pic1.1.1.1.1.1">3</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix3.p1">
<p class="ltx_p" id="S4.I1.ix3.p1.1">The model provider requests an attestation report from the TEE instance, which includes a public key for any subsequent communication between the model provider and the TEE.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix4.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix4.1.1.pic1.1.1.1.1.1">4</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix4.p1">
<p class="ltx_p" id="S4.I1.ix4.p1.1">The model provider leverages a verifier service to check that the running instance is a valid TEE.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix5.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix5.1.1.pic1.1.1.1.1.1">5</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix5.p1">
<p class="ltx_p" id="S4.I1.ix5.p1.1">The model provider can verify whether the TEE is running appropriate software and firmware using expected values generated before starting the TEE in the cloud.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix6.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix6.1.1.pic1.1.1.1.1.1">6</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix6.p1">
<p class="ltx_p" id="S4.I1.ix6.p1.1">The model provider provisions the encryption keys for the TEE, allowing it to load all software and the encrypted model.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix7.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix7.1.1.pic1.1.1.1.1.1">7</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix7.p1">
<p class="ltx_p" id="S4.I1.ix7.p1.1">The model provider can then expose the TEE instance running the FM as part of their service.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix8.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix8.1.1.pic1.1.1.1.1.1">8</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix8.p1">
<p class="ltx_p" id="S4.I1.ix8.p1.1">An end-user can open a direct secure channel with the TEE instance and submit inference prompts leveraging a public certificate offered by the model provider.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"> <svg class="ltx_picture" height="15.74" id="S4.I1.ix9.1.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.I1.ix9.1.1.pic1.1.1.1.1.1">9</span></foreignobject></g></g></svg></span>
<div class="ltx_para" id="S4.I1.ix9.p1">
<p class="ltx_p" id="S4.I1.ix9.p1.1">An end-user can also establish that the service is running in a TEE by verifying the attestation. This can happen transparently during secure channel opening if the users leverage a protocol such as Remote Attestation TLS (RA-TLS) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib31" title="">Knauth et al., </a>)</cite>. RA-TLS in such a setup requires granting user access to a verifier service.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Protections against threats</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The above flow protects against the attack vectors defined in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S2" title="2 FM threat model ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">2</span></a>. We discuss how this is achieved and how TEEs offer an advantage over other methods for different threats.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.2.1">Type one and two adversaries:</span> Type one and two adversaries are protected against using the principal integrity and confidentiality properties of TEEs. The model (step  <svg class="ltx_picture" height="15.74" id="S4.SS1.p2.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.SS1.p2.1.pic1.1.1.1.1.1">6</span></foreignobject></g></g></svg>) and users’ data (step  <svg class="ltx_picture" height="15.74" id="S4.SS1.p2.2.pic2" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.SS1.p2.2.pic2.1.1.1.1.1">8</span></foreignobject></g></g></svg>) are protected from access by privileged and non-privileged users of the data center. TEEs prevent unauthorized adversaries from reading plaintext data out of the TEE through, for example, garbling the output or raising memory faults. TEEs also prevent unauthorized adversaries from modifying code/data within the TEE. Some TEEs will simply crash after their data is modified in this manner, notifying the user and closing the connection. Because the user uses TLS for communication and optionally conducts a provably secure attestation, no listener on the communication ports can understand the contents of the sent messages, blocking effective tracking of the input and output.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Type three adversary:</span> TEEs can also assert certain assurances that other methods struggle with. By conducting the attestation mentioned previously and because of TEE’s strong integrity protection, the model provider can ensure they deploy the models they intended without any modifications and usage of their data. They compare the expected secure hash value of the agreed model with the secure hash value coming from the enclave. Such comparison provably ensures the CSP and its employees adhere to their part of the agreement and do not modify the models, no matter how expensive they are to process. TEEs also provide privacy of users’ prompts, where the attestation protects against data or model leakage, ensuring that users’ data is provably not used for training purposes. Such strong protection can be important for legally imposed standards in industries such as healthcare or finance. This allows for a unique method of ensuring the quality of service and eliminates the third type of adversary.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Combining with other protection methods: </span> Businesses have varying needs and sometimes have deployments susceptible to other threats. In such cases, TEEs have another distinct advantage over ML methods. Existing ML protection mechanisms have been shown to eliminate each other’s benefits when combined together <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib56" title="">Szyller &amp; Asokan, </a>)</cite>. TEEs do not modify the model and, thus, are not susceptible to such an issue. TEEs can be joined with at least one other mechanism reinforcing other passive or active ML protections that might defend against a specific threat, such as model extraction. We believe TEEs comprise a secure baseline foundation for any FM deployment that does not interfere with other approaches.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Deployment and threat considerations</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We discuss how, from a practical perspective, the above flow can be leveraged in deploying other services and how the deployment decisions influence its security.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.2.1">RAG:</span> The above flow also applies to retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib37" title="">Lewis et al., </a>)</cite>. In RAG, FMs query a document index that responds to prompts. This directly maps to our above flow with exchanged actors. The model provider would follow the steps  <svg class="ltx_picture" height="15.74" id="S4.SS2.p2.1.pic1" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.SS2.p2.1.pic1.1.1.1.1.1">1</span></foreignobject></g></g></svg> to  <svg class="ltx_picture" height="15.74" id="S4.SS2.p2.2.pic2" overflow="visible" version="1.1" width="15.74"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,7.87)"><g color="#FFFFFF" fill="#000000" stroke="#FFFFFF"><path d="M 7.59 0 C 7.59 4.19 4.19 7.59 0 7.59 C -4.19 7.59 -7.59 4.19 -7.59 0 C -7.59 -4.19 -4.19 -7.59 0 -7.59 C 4.19 -7.59 7.59 -4.19 7.59 0 Z M 0 0"></path></g><g color="#FFFFFF" fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92"><span class="ltx_text ltx_font_sansserif" id="S4.SS2.p2.2.pic2.1.1.1.1.1">7</span></foreignobject></g></g></svg> to deploy an additional RAG service. The details of this service, such as the communication certificate, are then shared with the inference service. The inference service would open a direct, secure connection with the RAG service. Leveraging remote attestation during deployment, encrypted storage, and secure communication ensures the provided RAG documents are not maliciously changed or stolen, similarly to how we described for an inference service in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S4.SS1" title="4.1 Protections against threats ‣ 4 Establishing trust in the FM deployment ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Load balancers and gateways:</span> Frequently, the user would not have direct access to an instance running on the cloud but would be located behind a load balancer or a gateway. Such mechanisms could isolate the user from the ability to attest the TEE if the TLS sessions are terminated at these points.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Choice of verifier service:</span> CSPs offer attestation services for TEEs running in their deployment. To establish trust in these offerings, they should be run inside a TEE, which is attested by a trusted 3rd party. Furthermore, the attestation service implementation needs to be validated. Such offerings allow CSPs to handle attestations for TEE deployments on their infrastructure, with 3rd party required only for the few attestations of the TEEs running CSP attestation service. To further reduce the reliance on the CSP, one can also completely resort to 3rd party attestation services.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Future directions</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">While all the above discussions are on practical systems that can be deployed in TEEs, most of the following paragraphs constitute exciting research possibilities rather than available solutions.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Microservices:</span>
A frequent method to deploy a pipeline of operations is microservices. In such a deployment model, a result of one microservice is provided to the next, which provides its results to the next, and so forth. Microservices form a graph of operations applied to some input. For example, one microservice could be fetching some database data, the other parsing input through LLMs, and the final pushing some data to the database. Frameworks such as Marblerun<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/edgelesssys/marblerun</span></span></span> allow for creating proofs that all microservices are attested. However, verifying such proofs would require knowing how the microservices are structured, a competitive advantage that companies are frequently unwilling to share.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">Wrappers on proprietary models:</span> Our flow focuses on private company deployments leveraging public models. However, some model providers offer their models as simple wrappers over proprietary FMs. For example, an insurance company might prepend some data to a query with additional context and submit that for evaluation to a GPT4 model. CSPs offer such models as deployments on their platforms. While there does not need to be any trust between the FM provider and the CSP like in our deployment flow, there necessarily needs to be trust between the user company and the FM provider. As we discuss in depth in the next paragraph, eliminating such trust would mean that some competitive advantage of the FM provider would need to be eliminated.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">Eliminating the need for trust in the model provider:</span> In our flow, users can attest that their data is processed in a TEE if they directly connect to it. This could be manifested, for example, with a special symbol in a browser like we currently do with TLS. Such a possibility is already a great improvement over the current state-of-the-art, which makes privacy-aware users notice companies that work with TEEs.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">However, the user needs to trust the model provider that they are running the model they have been promised and not using their data maliciously. While in our deployment strategy, this does not matter, it would matter if the model deployed is a public service such as public LLM chats or the aforementioned wrappers over proprietary models. TEEs resolve this by attesting the running software within them. Yet, such code frequently comprises the competitive advantage of FM providers, so it is hard for them or the CSPs to release it.</p>
</div>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">We could create standard codes that could be attested and deploy certain FMs, which would be measured and hashes compared with the promised references. Such a flow would allow the users to verify the code as well as the fact that it is running in a TEE. This problem is part of a larger discussion within the community <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib23" title="">Delignat-Lavaud et al., </a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p7.1.1">Other assurances:</span> The aforementioned ability to have a standardized deployment code would also enable a unique opportunity for publishing official accuracy results of models. One could imagine a marketplace in which models are sold. Leveraging TEEs allows the model provider to prove securely to any third party in such a marketplace that a given model achieves a certain accuracy on standard datasets without the third party needing access to the model. Any of these assurances would be challenging to provably obtain without using TEEs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Lifting FMs into TEEs</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our flow and protections against a modern FM adversary generalize to all TEEs. To show a practical deployment, we select a subset of available TEEs and implement the data pipeline, show the insights we gained, and release our configuration. We limit ourselves to TEEs widely offered by major CSPs due to the practicality of such a choice. This reduces the available options to two types of TEEs from the largest CPU vendors, Intel<sup class="ltx_sup" id="S5.p1.1.1">®</sup> and AMD. We selected Intel’s<sup class="ltx_sup" id="S5.p1.1.2">®</sup> TEEs for two reasons. Firstly, they provide us with the two common ways of implementing TEEs (virtual machine and application-based) while using the same machine, allowing for an apples-to-apples comparison without any performance result scaling. Secondly, they include support of AMX, a specialized, on-chip, AI hardware accelerator introducing CPU native support for formats such as brain floating numbers and 8-bit integers, increasing overall performance. We also discuss GPU-based TEEs in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S7.SS1" title="7.1 Accelerator based TEEs ‣ 7 Discussion ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">7.1</span></a>. We outline the basic properties of these TEEs and show how they can be practically leveraged.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="704" id="S5.F4.g1" src="x4.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>A differentiation between TDX and SGX with an extract from our Gramine manifest template file containing all the information needed to provide security to a Gramine-based TEE running an FM workload.</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Software Guard Extension (SGX)</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">SGX is an application-based TEE. In the security model of SGX, the applications can run on bare metal without any virtualization or within a VM. The TCB involves only parts of the applications and the hardware. The SGX programming model differentiates between SGX non-protected and SGX-protected parts of the program. The protected part of the program is located within an enclave and is safeguarded by SGX capabilities, while the non-protected part is located outside of SGX. All the data in the enclave is protected by memory encryption and integrity checks. Operations requiring leaving the enclave to run the SGX non-protected part of the program (e.g., reading a file) securely save its state for later reuse and clear the caches for security reasons.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">SGX enclaves are frequently deployed on top of library OSs created specifically for TEEs, such as Gramine <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib62" title="">Tsai et al., </a>)</cite> or Occlum <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib55" title="">Shen et al., </a>)</cite>. These are lightweight layers between the host system and an application intercepting any <code class="ltx_verbatim ltx_font_typewriter" id="S5.SS1.p2.1.1">systemcalls</code> to ensure they are conducted securely. These addressed some inconveniences of the original SGX SDK, which required users to rewrite their applications with secure and insecure sections. This implied using the necessary manual instructions for operations such as entering and leaving sections, implementing protections for loading files, and conducting attestation.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Gramine is a well-established, multi-company-backed, open-source project<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/gramineproject/gramine" title="">https://github.com/gramineproject/gramine</a></span></span></span>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5.F4" title="Figure 4 ‣ 5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4</span></a> shows our software stack in which we use Gramine to run PyTorch and Intel Extensions for Pytorch (IPEX) within SGX without major code modifications. It simplifies using common features of TEEs by creating security in the background. For example, it would automatically implement instructions for leaving and entering the enclave. While loading files, it would also conduct integrity and encryption protections for the users and would allow for setting up attestation. While executing, Gramine intercepts and emulates application system calls. Depending on the system call, the functionality can be provided efficiently without exiting the SGX enclave. On the other hand, system calls like file accesses require an exit, which incurs additional costs.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Gramine exposes these features via an application-dependent Manifest file. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S5.F4" title="Figure 4 ‣ 5 Lifting FMs into TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">4</span></a> also shows parts of the Manifest we crafted for our FMs and the layers we moved into SGX. A Manifest allows the users to outline the size of the enclave, the number of threads, what should be run as an entry point binary, which files can be trusted (i.e., loaded without any integrity and confidentiality checks), which files should be allowed (i.e., which files can be accessed), where to obtain the cryptographic decryption keys, and how to conduct attestation. It then uses this information to generate the necessary cryptographic information passed to the enclave. Manifest files are created from templates with examples in the Gramine repository. We release our Manifests to ease adoption of FMs within TEEs.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Trusted Domain Extensions (TDX)</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">TDX is a virtual machine (VM) based TEE that introduces security features using a hardened hardware-enabled hypervisor. In the TDX security model, the entire VM is protected. This considerably simplifies the development as the user does not need to worry about special functions when leaving or entering the enclave. Users also do not need to find all the files their application uses and can run their programs within standard Linux OS such as Ubuntu. Furthermore, this approach fits well with the CSP virtualization trend. For our implementation, VMs enable Deepspeed within the enclave, opening venues for easier accelerator support and multi-node inference. However, the price for this comfort is considerably higher TCB as the whole VM OS must be trusted. Using VMs implies a virtualization performance tax that we will show in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.F5" title="Figure 5 ‣ 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a>, which can be similar to the overheads of SGX.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">To use TDX, one must create an appropriate VM definition file. It specifies details such as what file should be used to boot the VM, how to map the appropriate virtual cores to physical ones, and the available memory. This definition file considerably influences the VM’s performance and can have a larger impact on the final performance than enabling or disabling the security features of TDX. We provide our optimized definition file.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Performance optimizations</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">As our workload does not use many IOs on the critical path, we found that the main driver for the performance of the TEEs for FMs is twofold:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">the ability to use special purpose accelerators inside the CPU like Intel<sup class="ltx_sup" id="S5.I1.i1.p1.1.1">®</sup> Advanced Vector Extension (AVX) or Advanced Matrix Extension (AMX);</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">efficient use of memory controllers and reaching peak memory bandwidth.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S5.SS3.p1.2">The former can be enabled by appropriate configuration and leveraging frameworks such as IPEX. We found that once such accelerators are used, the performance overheads are dominated by the latter, which is optimized by, in general, lowering the memory pressure. Leveraging accelerators such as AMX also allowed us to achieve this goal by moving from <code class="ltx_verbatim ltx_font_typewriter" id="S5.SS3.p1.2.1">float32</code> to a native hardware support of <code class="ltx_verbatim ltx_font_typewriter" id="S5.SS3.p1.2.2">bfloat16</code> and <code class="ltx_verbatim ltx_font_typewriter" id="S5.SS3.p1.2.3">int8</code>.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">For both TDX, and SGX, we also optimized our initial performance results by using TCMalloc <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib26" title="">Durner et al., </a>)</cite>, and an Open MP <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib21" title="">Dagum &amp; Menon, </a>)</cite> version suitable for Intel<sup class="ltx_sup" id="S5.SS3.p2.1.1">®</sup> processors. The former reduces the memory pressure, while the latter makes better use of hardware. Furthermore, we found sub-NUMA clustering to have a large influence on both SGX and TDX. Sub-NUMA clustering in Intel<sup class="ltx_sup" id="S5.SS3.p2.1.2">®</sup> CPUs splits a single CPU into multiple NUMA domains and typically improves the performance for ML workloads. Currently, the TEE drivers and the OS do not support sub-NUMA domains, resulting in inefficient memory placement. Instead, a single NUMA domain per CPU achieves higher performance. As a result, we disabled sub-NUMA clustering during our experiments.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">For TDX specifically, we used huge pages <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib45" title="">Panwar et al., </a>)</cite>, which reduced the number of necessary translation lookaside buffer (TLB) accesses, decreasing memory access latency. We similarly observed higher performance when not exposing a CPU core’s second logical thread (hyper thread) to the VM. In its default configuration, PyTorch only executes on the first logical thread of a core, ignoring the hyperthreads, making the second thread introduce noise.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Performance of LLMs in TEEs</h2>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="386" id="S6.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The TEE generation speed reductions and latency overheads are within 4-10% for TDX and SGX.</figcaption>
</figure>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We run FMs within TDX and SGX using our best performing and optimized configurations, and show the performance of the Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib59" title="">b</a>)</cite> model family as it represents modern FMs well. We show how TEEs are a practical solution for providing security to modern models from a performance perspective with considerably lower overheads than previously reported 100s of percent <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib6" title="">Akram et al., </a>)</cite>. This is even though LLMs are large and complex models, creating considerable memory pressure. As TEE overheads stem from either IO operations or the encryption and decryption of the accessed memory, such models maximize the cost of using TEEs. We focus on user-perceived performance: throughput and latency as measured by the number of tokens per second that our pipeline generates and the time to receive a token in the pipeline. While many metrics were created to measure the performance of ML models <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib22" title="">Dehghani et al., </a>)</cite>, our choice focuses on real-world experience.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Experimental setup</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">In our experiments, we used a dual socket Intel<sup class="ltx_sup" id="S6.SS1.p1.1.1">®</sup> Xeon<sup class="ltx_sup" id="S6.SS1.p1.1.2">®</sup> Platinum GOLD 6530 system with 32 cores and 16x32GiB 4800MHz DDR5 memory. We used Ubuntu 23.10, with Python version 3.10.14, PyTorch version 2.2.0, transformers version 4.35.2, Intel<sup class="ltx_sup" id="S6.SS1.p1.1.3">®</sup> extension for PyTorch (IPEX) version 2.2.0, and oneCCL PyTorch bindings version 2.2.0. We measured the throughput and latency for four setups. Baseline results represent results coming from running the model on the bare metal instance, Gramine SGX represents the results of Gramine v1.7 backend running on SGX, VM the results of running a raw VM without any security features, and TDX the results of running on TDX. The machine is configured with disabled sub-NUMA clustering, and the workload is restricted to a single thread per core in the VM definition or via <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS1.p1.1.4">numactl</code>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">In all experiments, we used batch size six for throughput and batch size one for latency. A larger batch size means increased latency but higher throughput as less data movement is required per token for each computation within the LLM. The different inputs batched together can be computed on each layer of the LLM, and a combined result can be forwarded to the next layer. Each layer takes longer than for a single input (increased latency) but shorter than for <math alttext="N" class="ltx_Math" display="inline" id="S6.SS1.p2.1.m1.1"><semantics id="S6.SS1.p2.1.m1.1a"><mi id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><ci id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p2.1.m1.1d">italic_N</annotation></semantics></math> separate inputs (increased throughput). We used 1024 input and 128 output tokens. We conducted multiple generation runs where, for each model size and system, we measured at least 1000 tokens. For latency, we measured the generation time for each token and plotted these as a distribution. For throughput, we plotted the inverse of each token generation time. We filtered out outlier tokens by excluding times with an absolute Z-score larger than 3. These constitute on average 0.64% of the data ranging from 0.2% to 1.2% and do not contribute to the discussion but create considerable noise on the plots. In all experiments, we used two inference datatypes: brain floating point (<code class="ltx_verbatim ltx_font_typewriter" id="S6.SS1.p2.1.1">bfloat16</code>) and the quantized integers (<code class="ltx_verbatim ltx_font_typewriter" id="S6.SS1.p2.1.2">int8</code>).</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Latency and Generation Speed</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">We compare the next token latency of Llama2 inference running in different configurations. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#S6.F5" title="Figure 5 ‣ 6 Performance of LLMs in TEEs ‣ Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud"><span class="ltx_text ltx_ref_tag">5</span></a> shows the generation speed of tokens (batch size = 6 and beam size = 4) and the next token latency (batch size = 1, beam size = 1). The overhead of Gramine-SGX is between 4.58-6.55% while the TDX overhead is between 5.83-11.14%. These results demonstrate that running inside a VM has a non-negligible performance overhead of 1.85-5.11% to which TDX adds additional overhead of 3.12-7.54%. The performance of SGX is in between a VM and TDX. The results for different data types show that <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p1.1.1">int8</code> generally obtains similar generation speeds as <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p1.1.2">bf16</code> but almost half the latency. However, the overheads for <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p1.1.3">int8</code> are better in the case of generation speed and worse in the case of latency. We believe that this might be because, in the latency case, there is a constant memory access latency overhead due to memory protections that TEEs introduce, which is more pronounced in the higher-performing latency results. For the throughput, because our inference state is in <code class="ltx_verbatim ltx_font_typewriter" id="S6.SS2.p1.1.4">int8</code>, there is less memory movement, which results in lower overheads due to necessary address translations from guest to host memory.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">In our deployment, SGX runs on top of the host OS. The host OS has more privileges than a VM and exposes the hardware more directly to SGX. TDX, on the other hand, does not have direct access to some hardware features and needs to go through virtualization layers, such as guest address translations that are not present in SGX. As these TEEs do not access any network or drive during the computation, most of the overhead comes from the protected memory accesses. It is important to notice that most machines rented from CSPs run VMs. Thus, the visible overheads will be lower as the usual baseline is an already virtualized system and not a bare metal machine like ours. The overheads of SGX over baremetal and TDX over VM are similar. All systems have latency considerably lower than the average human reading speed of 200 ms/word (300 words/min) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib49" title="">Rayner et al., </a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Accelerator based TEEs</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">While an exciting future direction, accelerator TEEs are not yet widespread. At the time of writing, GPU-based TEE offered by Nvidia in the H100 series is the only natively accelerated TEE solution entering the space in scale. Furthermore, even H100s with CC enabled are available only in a single CSP (Azure) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib1" title="">Ann, </a>)</cite>. Given the relative scarcity and cost of these accelerators, CPUs with on-chip accelerators such as AMX might offer a more pragmatic alternative for users who require CC to protect their FM models, queries, and other sensitive data. Our approach applies, in principle, to TEEs with an accelerator. Our software stack, in addition with DeepSpeed, offloads to most accelerators. Accelerators such as H100 require a CPU TEE such as SEV-SNP or TDX and would be brought into the trusted computing base (TCB) leveraging attestation.</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">While deploying practically these accelerators, it is important to consider their threat model, which is currently different from the CPU TEE threat model. For example, H100s do not encrypt their HBM memory <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib24" title="">Dhanuskodi et al., </a>)</cite>, compared to CPUs that do. While in CPU-based systems, communication between different NUMA nodes is transparently encrypted, interconnects such as PCIe and NVLINK do not yet have such a feature <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib24" title="">Dhanuskodi et al., </a>)</cite>. In existing systems, any communication with the accelerator requires using bounce buffers, where data is encrypted and copied such that the accelerator comprehends it. Such a solution introduces performance overhead for workloads with a considerable IO between the CPU and the accelerator.</p>
</div>
<div class="ltx_para" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1">To the best of our knowledge, these and other performance overheads have not yet been widely verified as of the writing of this article. Evaluations of Llama2 7B on H100s in CC mode in literature show overheads of 100-150% of total runtime <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib3" title="">Sec, </a>)</cite>. Vendor-published data quantifying the communication overhead measures it at about 45% <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib42" title="">Nertney, </a>)</cite> for Resnet50 training on H100s with literature noting overheads of up to 90% depending on the buffer size <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib3" title="">Sec, </a>)</cite>. Solutions such as TDX Connect <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib17" title="">b</a>)</cite> and SEV IO <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib2" title="">SEV, </a>)</cite> are in progress to address communication overheads by leveraging PCIe’s Integrity and Data
Encryption (IDE) and TEE Device Interface Security Protocol (TDISP) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib4" title="">TEE, </a>)</cite>. To the best of our knowledge, there also does not exist a solution allowing direct memory access between accelerator-based TEEs without the intermediate CPU involvement, which is crucial for performantly running larger models that might not fit on a single accelerator <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05930v1#bib.bib3" title="">Sec, </a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Process or VM TEEs</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">We discuss the properties of TEEs and compare application- and VM-based TEEs. Both types provide better security than other protection mechanisms at less than 10% performance cost. TEEs can protect the confidentiality, integrity, and privacy of the models and user data while not requiring retraining or modifying the accuracy. While both types provide these features, they differ in some aspects.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">VM-based TEEs provide a well-known and deployed abstraction. They do not require application changes. This results in a known development and deployment life cycle. However, the cost that the user pays for this is twofold: a considerably increased trusted computing base (TCB), and a performance virtualization tax. The TCB for VM-based solutions includes the whole OS, such as Ubuntu. Application-based TEEs are suitable for smaller models as programming them is more challenging and typically requires a library OS to lift and shift applications into the TEE or develop the application from scratch. However, they perform better for a single socket and provide stronger security properties. Their TCB is only a part of a library OS like Gramine, which is considerably smaller than a fully-fetched OS. While the software support for enabling the security is currently better for application-based TEEs, this is rapidly changing with projects such as Gramine adding the necessary support for VM-based TEEs, making the attestation and integrity/confidentiality verification easier.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Training</h3>
<div class="ltx_para" id="S7.SS3.p1">
<p class="ltx_p" id="S7.SS3.p1.1">While in our work, we focus on inference, introducing TEEs to the training process enables similar protections with further assurances that can be put on the training data. TEEs can verify whether a dataset conforms to some standards, such as lack of hate speech, personal information, copyright violations, or gender bias, in a securely provable way. Furthermore, this implies that the resulting model and the data used in the training process can be bound. This can be achieved using a secure hash function, combining the dataset’s hash and FM hash with the certificate provided by the hardware. This method allows the training party to securely prove to any other party that a given dataset has been used during the training of a particular model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusions</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">We presented an emerging threat model for LLMs and discussed how modern TEEs can secure against these adversaries. We showed how TEEs can additionally provide assurances on properties such as accuracy, opening a venue for the next generation quality of service agreements. Furthermore, we have addressed the two common critiques of TEEs: ease of use and large performance overheads. We have implemented an example pipeline for LLMs within TEEs and shared our learnings and code. We have also shown in the example of a state-of-the-art Llama LLM that TEEs impose a manageable performance overhead. We see TEEs opening many exciting research venues in the future, such as enabling assurances on modern LLMs, publically trusted LLM services, and LLM marketplaces where accuracy is proven property. We believe TEEs are the practical and existing solution to the problem of private and secure LLM evaluations that provide the deployments with baseline security on which others can build.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research was conducted as part of the “UrbanTwin: An urban digital twin for climate
action: Assessing policies and solutions for energy, water and infrastructure” project, funded by ETH-Domain Joint Initiative program in the Strategic Area Energy, Climate and Sustainable Environment, with additional support from Intel Corporation. We thank Intel for providing hardware resources, Cory Cornelius for his valuable feedback, and Madlen Koblinger for assisting with the design of figures.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
Announcing Azure confidential VMs with NVIDIA H100 Tensor Core GPUs
in Preview.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://techcommunity.microsoft.com/t5/azure-confidential-computing/announcing-azure-confidential-vms-with-nvidia-h100-tensor-core/ba-p/3975389" title="">https://techcommunity.microsoft.com/t5/azure-confidential-computing/announcing-azure-confidential-vms-with-nvidia-h100-tensor-core/ba-p/3975389</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
SEV-TIO Firmware Interface Specification.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
Securing AI Inference in the Cloud: Is CPU-GPU Confidential Computing
Ready?

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/10643934" title="">https://ieeexplore.ieee.org/document/10643934</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
TEE Device Interface Security Protocol (TDISP) — PCI-SIG.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pcisig.com/tee-device-interface-security-protocol-tdisp" title="">https://pcisig.com/tee-device-interface-security-protocol-tdisp</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Acar, A., Aksu, H., Uluagac, A. S., and Conti, M.

</span>
<span class="ltx_bibblock">A Survey on Homomorphic Encryption Schemes: Theory and
Implementation.

</span>
<span class="ltx_bibblock">51(4):79:1–79:35.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3214303</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3214303" title="">https://dl.acm.org/doi/10.1145/3214303</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
Akram, A., Giannakou, A., Akella, V., Lowe-Power, J., and Peisert, S.

</span>
<span class="ltx_bibblock">Performance Analysis of Scientific Computing Workloads on
General Purpose TEEs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">2021 IEEE International Parallel and Distributed
Processing Symposium (IPDPS)</em>, pp.  1066–1076.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/IPDPS49936.2021.00115</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9460547" title="">https://ieeexplore.ieee.org/document/9460547</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
Araci, D.

</span>
<span class="ltx_bibblock">FinBERT: Financial Sentiment Analysis with Pre-trained
Language Models.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1908.10063" title="">http://arxiv.org/abs/1908.10063</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
Awais, M., Naseer, M., Khan, S., Anwer, R. M., Cholakkal, H., Shah, M., Yang,
M.-H., and Khan, F. S.

</span>
<span class="ltx_bibblock">Foundational Models Defining a New Era in Vision: A
Survey and Outlook.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2307.13721" title="">http://arxiv.org/abs/2307.13721</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Ben-Nun, T. and Hoefler, T.

</span>
<span class="ltx_bibblock">Demystifying Parallel and Distributed Deep Learning: An
In-depth Concurrency Analysis.

</span>
<span class="ltx_bibblock">52(4):65:1–65:43.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3320060</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3320060" title="">https://doi.org/10.1145/3320060</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
Birkholz, H., Thaler, D., Richardson, M., Smith, N., and Pan, W.

</span>
<span class="ltx_bibblock">Remote ATtestation procedureS (RATS) Architecture.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://datatracker.ietf.org/doc/rfc9334" title="">https://datatracker.ietf.org/doc/rfc9334</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
Boenisch, F.

</span>
<span class="ltx_bibblock">A Systematic Review on Model Watermarking for Neural
Networks.

</span>
<span class="ltx_bibblock">4:729663.

</span>
<span class="ltx_bibblock">ISSN 2624-909X.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3389/fdata.2021.729663</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2009.12153" title="">http://arxiv.org/abs/2009.12153</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
I., and Amodei, D.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2005.14165" title="">http://arxiv.org/abs/2005.14165</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
Burkhalter, L., Hithnawi, A., Viand, A., Shafagh, H., and Ratnasamy, S.

</span>
<span class="ltx_bibblock">{<span class="ltx_text ltx_phantom" id="bib.bib13.1.1"><span style="visibility:hidden">}</span></span>TimeCrypt<span class="ltx_text ltx_phantom" id="bib.bib13.2.2"><span style="visibility:hidden">{</span></span>}: Encrypted Data Stream
Processing at Scale with Cryptographic Access Control.

</span>
<span class="ltx_bibblock">pp.  835–850.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-13-7.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/nsdi20/presentation/burkhalter" title="">https://www.usenix.org/conference/nsdi20/presentation/burkhalter</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee,
K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel,
C.

</span>
<span class="ltx_bibblock">Extracting Training Data from Large Language Models.

</span>
<span class="ltx_bibblock">pp.  2633–2650.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-24-3.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting" title="">https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
Chen, L., Zaharia, M., and Zou, J.

</span>
<span class="ltx_bibblock">How is ChatGPT’s behavior changing over time?

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2307.09009" title="">http://arxiv.org/abs/2307.09009</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (a)</span>
<span class="ltx_bibblock">
Cheng, P.-C., Ozga, W., Valdez, E., Ahmed, S., Gu, Z., Jamjoom, H., Franke, H.,
and Bottomley, J.

</span>
<span class="ltx_bibblock">Intel TDX Demystified: A Top-Down Approach, a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.15540" title="">http://arxiv.org/abs/2303.15540</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (b)</span>
<span class="ltx_bibblock">
Cheng, P.-C., Ozga, W., Valdez, E., Ahmed, S., Gu, Z., Jamjoom, H., Franke, H.,
and Bottomley, J.

</span>
<span class="ltx_bibblock">Intel TDX Demystified: A Top-Down Approach.

</span>
<span class="ltx_bibblock">b.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3652597</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3652597" title="">https://dl.acm.org/doi/10.1145/3652597</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
Chrapek, M., Khalilov, M., and Hoefler, T.

</span>
<span class="ltx_bibblock">HEAR: Homomorphically Encrypted Allreduce.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis</em>,
SC ’23, pp.  1–17. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400701092.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3581784.3607099</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3581784.3607099" title="">https://dl.acm.org/doi/10.1145/3581784.3607099</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
Costan, V. and Devadas, S.

</span>
<span class="ltx_bibblock">Intel SGX Explained.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://eprint.iacr.org/2016/086" title="">https://eprint.iacr.org/2016/086</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
Cui, J., Li, Z., Yan, Y., Chen, B., and Yuan, L.

</span>
<span class="ltx_bibblock">ChatLaw: Open-Source Legal Large Language Model with
Integrated External Knowledge Bases.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2306.16092" title="">http://arxiv.org/abs/2306.16092</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
Dagum, L. and Menon, R.

</span>
<span class="ltx_bibblock">OpenMP: An industry standard API for shared-memory
programming.

</span>
<span class="ltx_bibblock">5(1):46–55.

</span>
<span class="ltx_bibblock">ISSN 1558-190X.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/99.660313</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/abstract/document/660313" title="">https://ieeexplore.ieee.org/abstract/document/660313</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
Dehghani, M., Tay, Y., Arnab, A., Beyer, L., and Vaswani, A.

</span>
<span class="ltx_bibblock">The Efficiency Misnomer.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=iulEMLYh1uR" title="">https://openreview.net/forum?id=iulEMLYh1uR</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
Delignat-Lavaud, A., Fournet, C., Vaswani, K., Clebsch, S., Riechert, M.,
Costa, M., and Russinovich, M.

</span>
<span class="ltx_bibblock">Why Should I Trust Your Code? Confidential computing enables
users to authenticate code running in TEEs, but users also need evidence
this code is trustworthy.

</span>
<span class="ltx_bibblock">21(4):Pages 30:94–Pages 30:122.

</span>
<span class="ltx_bibblock">ISSN 1542-7730.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3623460</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3623460" title="">https://dl.acm.org/doi/10.1145/3623460</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
Dhanuskodi, G., Guha, S., Krishnan, V., Manjunatha, A., O’Connor, M., Nertney,
R., and Rogers, P.

</span>
<span class="ltx_bibblock">Creating the First Confidential GPUs: The team at NVIDIA
brings confidentiality and integrity to user code and data for accelerated
computing.

</span>
<span class="ltx_bibblock">21(4):Pages 40:68–Pages 40:93.

</span>
<span class="ltx_bibblock">ISSN 1542-7730.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3623393.3623391</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3623393.3623391" title="">https://dl.acm.org/doi/10.1145/3623393.3623391</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
Dowlin, N., Gilad-Bachrach, R., Laine, K., Lauter, K., Naehrig, M., and
Wernsing, J.

</span>
<span class="ltx_bibblock">CryptoNets: Applying Neural Networks to Encrypted Data
with High Throughput and Accuracy.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
Durner, D., Leis, V., and Neumann, T.

</span>
<span class="ltx_bibblock">On the Impact of Memory Allocation on High-Performance
Query Processing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 15th International Workshop on Data
Management on New Hardware</em>, DaMoN’19, pp.  1–3. Association for
Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-6801-8.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3329785.3329918</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3329785.3329918" title="">https://dl.acm.org/doi/10.1145/3329785.3329918</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(27)</span>
<span class="ltx_bibblock">
Fan, L., Ng, K. W., and Chan, C. S.

</span>
<span class="ltx_bibblock">Rethinking Deep Neural Network Ownership Verification:
Embedding Passports to Defeat Ambiguity Attacks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in Neural Information Processing Systems</em>,
volume 32. Curran Associates, Inc.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2019/hash/75455e062929d32a333868084286bb68-Abstract.html" title="">https://proceedings.neurips.cc/paper_files/paper/2019/hash/75455e062929d32a333868084286bb68-Abstract.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(28)</span>
<span class="ltx_bibblock">
Goldfarb, A. and Tucker, C.

</span>
<span class="ltx_bibblock">Shifts in Privacy Concerns.

</span>
<span class="ltx_bibblock">102(3):349–353.

</span>
<span class="ltx_bibblock">ISSN 0002-8282.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1257/aer.102.3.349</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aeaweb.org/articles?id=10.1257/aer.102.3.349" title="">https://www.aeaweb.org/articles?id=10.1257/aer.102.3.349</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(29)</span>
<span class="ltx_bibblock">
Hoekstra, M., Lal, R., Pappachan, P., Phegade, V., and Del Cuvillo, J.

</span>
<span class="ltx_bibblock">Using innovative instructions to create trustworthy software
solutions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 2nd International Workshop on
Hardware and Architectural Support for Security and Privacy</em>,
HASP ’13, pp.  1. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-2118-1.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/2487726.2488370</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2487726.2488370" title="">https://doi.org/10.1145/2487726.2488370</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(30)</span>
<span class="ltx_bibblock">
Kaplan, D.

</span>
<span class="ltx_bibblock">AMD SEV-SNP: Strengthening VM Isolation with Integrity
Protection and More.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(31)</span>
<span class="ltx_bibblock">
Knauth, T., Steiner, M., Chakrabarti, S., Lei, L., Xing, C., and Vij, M.

</span>
<span class="ltx_bibblock">Integrating Remote Attestation with Transport Layer Security.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1801.05863" title="">http://arxiv.org/abs/1801.05863</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(32)</span>
<span class="ltx_bibblock">
Knott, B., Venkataraman, S., Hannun, A., Sengupta, S., Ibrahim, M., and
family=Maaten, given=Laurens, p. d. u.

</span>
<span class="ltx_bibblock">CrypTen: Secure Multi-Party Computation Meets Machine
Learning.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2109.00984" title="">http://arxiv.org/abs/2109.00984</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(33)</span>
<span class="ltx_bibblock">
Kocmi, T. and Federmann, C.

</span>
<span class="ltx_bibblock">Large Language Models Are State-of-the-Art Evaluators of
Translation Quality.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2302.14520" title="">http://arxiv.org/abs/2302.14520</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
Lao, Y., Zhao, W., Yang, P., and Li, P.

</span>
<span class="ltx_bibblock">DeepAuth: A DNN Authentication Framework by Model-Unique
and Fragile Signature Embedding.

</span>
<span class="ltx_bibblock">36(9):9595–9603.

</span>
<span class="ltx_bibblock">ISSN 2374-3468.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1609/aaai.v36i9.21193</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ojs.aaai.org/index.php/AAAI/article/view/21193" title="">https://ojs.aaai.org/index.php/AAAI/article/view/21193</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (a)</span>
<span class="ltx_bibblock">
Lee, D., Kuvaiskii, D., Vahldiek-Oberwagner, A., and Vij, M.

</span>
<span class="ltx_bibblock">Privacy-Preserving Machine Learning in Untrusted Clouds Made
Simple, a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2009.04390" title="">http://arxiv.org/abs/2009.04390</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (b)</span>
<span class="ltx_bibblock">
Lee, J.-W., Kang, H., Lee, Y., Choi, W., Eom, J., Deryabin, M., Lee, E., Lee,
J., Yoo, D., Kim, Y.-S., and No, J.-S.

</span>
<span class="ltx_bibblock">Privacy-Preserving Machine Learning With Fully Homomorphic
Encryption for Deep Neural Network.

</span>
<span class="ltx_bibblock">10:30039–30054, b.

</span>
<span class="ltx_bibblock">ISSN 2169-3536.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ACCESS.2022.3159694</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/abstract/document/9734024" title="">https://ieeexplore.ieee.org/abstract/document/9734024</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(37)</span>
<span class="ltx_bibblock">
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N.,
Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., Riedel, S., and Kiela,
D.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for Knowledge-Intensive NLP
Tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Advances in Neural Information Processing Systems</em>,
volume 33, pp.  9459–9474. Curran Associates, Inc.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="">https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
Li, X., Li, X., Dall, C., Gu, R., Nieh, J., Sait, Y., and Stockwell, G.

</span>
<span class="ltx_bibblock">Design and Verification of the Arm Confidential Compute
Architecture.

</span>
<span class="ltx_bibblock">pp.  465–484.

</span>
<span class="ltx_bibblock">ISBN 978-1-939133-28-1.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/osdi22/presentation/li" title="">https://www.usenix.org/conference/osdi22/presentation/li</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(39)</span>
<span class="ltx_bibblock">
McKeen, F., Alexandrovich, I., Berenzon, A., Rozas, C. V., Shafi, H.,
Shanbhogue, V., and Savagaonkar, U. R.

</span>
<span class="ltx_bibblock">Innovative instructions and software model for isolated execution.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2nd International Workshop on
Hardware and Architectural Support for Security and Privacy</em>,
HASP ’13, pp.  1. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-2118-1.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/2487726.2488368</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2487726.2488368" title="">https://doi.org/10.1145/2487726.2488368</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(40)</span>
<span class="ltx_bibblock">
Mo, F., Tarkhani, Z., and Haddadi, H.

</span>
<span class="ltx_bibblock">Machine Learning with Confidential Computing: A
Systematization of Knowledge.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2208.10134" title="">http://arxiv.org/abs/2208.10134</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(41)</span>
<span class="ltx_bibblock">
Mulligan, D. P., Petri, G., Spinale, N., Stockwell, G., and Vincent, H. J. M.

</span>
<span class="ltx_bibblock">Confidential Computing—a brave new world.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">2021 International Symposium on Secure and Private
Execution Environment Design (SEED)</em>, pp.  132–138.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/SEED51797.2021.00025</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/document/9604800" title="">https://ieeexplore.ieee.org/document/9604800</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(42)</span>
<span class="ltx_bibblock">
Nertney, R.

</span>
<span class="ltx_bibblock">Confidential Compute on NVIDIA Hopper H100 - Whitepaper.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(43)</span>
<span class="ltx_bibblock">
Ng, T.

</span>
<span class="ltx_bibblock">Adobe Says It Won’t Train AI Using Artists’ Work.
Creatives Aren’t Convinced.

</span>
<span class="ltx_bibblock">ISSN 1059-1028.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.wired.com/story/adobe-says-it-wont-train-ai-using-artists-work-creatives-arent-convinced/" title="">https://www.wired.com/story/adobe-says-it-wont-train-ai-using-artists-work-creatives-arent-convinced/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman,
F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R.,
Babuschkin, I., Balaji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M.,
Belgum, J., Bello, I., Berdine, J., Bernadett-Shapiro, G., Berner, C.,
Bogdonoff, L., Boiko, O., Boyd, M., Brakman, A.-L., Brockman, G., Brooks, T.,
Brundage, M., Button, K., Cai, T., Campbell, R., Cann, A., Carey, B.,
Carlson, C., Carmichael, R., Chan, B., Chang, C., Chantzis, F., Chen, D.,
Chen, S., Chen, R., Chen, J., Chen, M., Chess, B., Cho, C., Chu, C., Chung,
H. W., Cummings, D., Currier, J., Dai, Y., Decareaux, C., Degry, T., Deutsch,
N., Deville, D., Dhar, A., Dohan, D., Dowling, S., Dunning, S., Ecoffet, A.,
Eleti, A., Eloundou, T., Farhi, D., Fedus, L., Felix, N., Fishman, S. P.,
Forte, J., Fulford, I., Gao, L., Georges, E., Gibson, C., Goel, V., Gogineni,
T., Goh, G., Gontijo-Lopes, R., Gordon, J., Grafstein, M., Gray, S., Greene,
R., Gross, J., Gu, S. S., Guo, Y., Hallacy, C., Han, J., Harris, J., He, Y.,
Heaton, M., Heidecke, J., Hesse, C., Hickey, A., Hickey, W., Hoeschele, P.,
Houghton, B., Hsu, K., Hu, S., Hu, X., Huizinga, J., Jain, S., Jain, S.,
Jang, J., Jiang, A., Jiang, R., Jin, H., Jin, D., Jomoto, S., Jonn, B., Jun,
H., Kaftan, T., Kaiser, L., Kamali, A., Kanitscheider, I., Keskar, N. S.,
Khan, T., Kilpatrick, L., Kim, J. W., Kim, C., Kim, Y., Kirchner, H., Kiros,
J., Knight, M., Kokotajlo, D., Kondraciuk, L., Kondrich, A., Konstantinidis,
A., Kosic, K., Krueger, G., Kuo, V., Lampe, M., Lan, I., Lee, T., Leike, J.,
Leung, J., Levy, D., Li, C. M., Lim, R., Lin, M., Lin, S., Litwin, M., Lopez,
T., Lowe, R., Lue, P., Makanju, A., Malfacini, K., Manning, S., Markov, T.,
Markovski, Y., Martin, B., Mayer, K., Mayne, A., McGrew, B., McKinney, S. M.,
McLeavey, C., McMillan, P., McNeil, J., Medina, D., Mehta, A., Menick, J.,
Metz, L., Mishchenko, A., Mishkin, P., Monaco, V., Morikawa, E., Mossing, D.,
Mu, T., Murati, M., Murk, O., Mély, D., Nair, A., Nakano, R., Nayak, R.,
Neelakantan, A., Ngo, R., Noh, H., Ouyang, L., O’Keefe, C., Pachocki, J.,
Paino, A., Palermo, J., Pantuliano, A., Parascandolo, G., Parish, J.,
Parparita, E., Passos, A., Pavlov, M., Peng, A., Perelman, A., Peres, F. d.
A. B., Petrov, M., Pinto, H. P. d. O., Michael, Pokorny, Pokrass, M., Pong,
V., Powell, T., Power, A., Power, B., Proehl, E., Puri, R., Radford, A., Rae,
J., Ramesh, A., Raymond, C., Real, F., Rimbach, K., Ross, C., Rotsted, B.,
Roussez, H., Ryder, N., Saltarelli, M., Sanders, T., Santurkar, S., Sastry,
G., Schmidt, H., Schnurr, D., Schulman, J., Selsam, D., Sheppard, K.,
Sherbakov, T., Shieh, J., Shoker, S., Shyam, P., Sidor, S., Sigler, E.,
Simens, M., Sitkin, J., Slama, K., Sohl, I., Sokolowsky, B., Song, Y.,
Staudacher, N., Such, F. P., Summers, N., Sutskever, I., Tang, J., Tezak, N.,
Thompson, M., Tillet, P., Tootoonchian, A., Tseng, E., Tuggle, P., Turley,
N., Tworek, J., Uribe, J. F. C., Vallone, A., Vijayvergiya, A., Voss, C.,
Wainwright, C., Wang, J. J., Wang, A., Wang, B., Ward, J., Wei, J., Weinmann,
C. J., Welihinda, A., Welinder, P., Weng, J., Weng, L., Wiethoff, M.,
Willner, D., Winter, C., Wolrich, S., Wong, H., Workman, L., Wu, S., Wu, J.,
Wu, M., Xiao, K., Xu, T., Yoo, S., Yu, K., Yuan, Q., Zaremba, W., Zellers,
R., Zhang, C., Zhang, M., Zhao, S., Zheng, T., Zhuang, J., Zhuk, W., and
Zoph, B.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.08774" title="">http://arxiv.org/abs/2303.08774</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(45)</span>
<span class="ltx_bibblock">
Panwar, A., Prasad, A., and Gopinath, K.

</span>
<span class="ltx_bibblock">Making Huge Pages Actually Useful.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the Twenty-Third International Conference
on Architectural Support for Programming Languages and Operating
Systems</em>, ASPLOS ’18, pp.  679–692. Association for Computing
Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-4911-6.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3173162.3173203</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3173162.3173203" title="">https://dl.acm.org/doi/10.1145/3173162.3173203</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(46)</span>
<span class="ltx_bibblock">
Patil, V., Hase, P., and Bansal, M.

</span>
<span class="ltx_bibblock">Can Sensitive Information Be Deleted From LLMs? Objectives
for Defending Against Extraction Attacks.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=7erlRDoaV8" title="">https://openreview.net/forum?id=7erlRDoaV8</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(47)</span>
<span class="ltx_bibblock">
Petrescu, M. and Krishen, A. S.

</span>
<span class="ltx_bibblock">Analyzing the analytics: Data privacy concerns.

</span>
<span class="ltx_bibblock">6(2):41–43.

</span>
<span class="ltx_bibblock">ISSN 2050-3326.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1057/s41270-018-0034-x</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1057/s41270-018-0034-x" title="">https://doi.org/10.1057/s41270-018-0034-x</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(48)</span>
<span class="ltx_bibblock">
Pinto, S. and Santos, N.

</span>
<span class="ltx_bibblock">Demystifying Arm TrustZone: A Comprehensive Survey.

</span>
<span class="ltx_bibblock">51(6):130:1–130:36.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3291047</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3291047" title="">https://dl.acm.org/doi/10.1145/3291047</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(49)</span>
<span class="ltx_bibblock">
Rayner, K., Schotter, E. R., Masson, M. E. J., Potter, M. C., and Treiman, R.

</span>
<span class="ltx_bibblock">So Much to Read, So Little Time: How Do We Read, and
Can Speed Reading Help?

</span>
<span class="ltx_bibblock">17(1):4–34.

</span>
<span class="ltx_bibblock">ISSN 1529-1006.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1177/1529100615623267</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1177/1529100615623267" title="">https://doi.org/10.1177/1529100615623267</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(50)</span>
<span class="ltx_bibblock">
Ribeiro, M., Grolinger, K., and Capretz, M. A.

</span>
<span class="ltx_bibblock">MLaaS: Machine Learning as a Service.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">2015 IEEE 14th International Conference on Machine
Learning and Applications (ICMLA)</em>, pp.  896–902.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICMLA.2015.152</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/abstract/document/7424435" title="">https://ieeexplore.ieee.org/abstract/document/7424435</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(51)</span>
<span class="ltx_bibblock">
Sabt, M., Achemlal, M., and Bouabdallah, A.

</span>
<span class="ltx_bibblock">Trusted Execution Environment: What It is, and What It is
Not.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">2015 IEEE Trustcom/BigDataSE/ISPA</em>, volume 1,
pp.  57–64.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/Trustcom.2015.357</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/abstract/document/7345265" title="">https://ieeexplore.ieee.org/abstract/document/7345265</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(52)</span>
<span class="ltx_bibblock">
Sallam, M.

</span>
<span class="ltx_bibblock">ChatGPT Utility in Healthcare Education, Research, and
Practice: Systematic Review on the Promising Perspectives and
Valid Concerns.

</span>
<span class="ltx_bibblock">11(6):887.

</span>
<span class="ltx_bibblock">ISSN 2227-9032.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3390/healthcare11060887</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mdpi.com/2227-9032/11/6/887" title="">https://www.mdpi.com/2227-9032/11/6/887</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(53)</span>
<span class="ltx_bibblock">
Schneider, M., Masti, R. J., Shinde, S., Capkun, S., and Perez, R.

</span>
<span class="ltx_bibblock">SoK: Hardware-supported Trusted Execution Environments.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2205.12742" title="">http://arxiv.org/abs/2205.12742</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(54)</span>
<span class="ltx_bibblock">
Sharir, O., Peleg, B., and Shoham, Y.

</span>
<span class="ltx_bibblock">The Cost of Training NLP Models: A Concise Overview.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2004.08900" title="">http://arxiv.org/abs/2004.08900</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(55)</span>
<span class="ltx_bibblock">
Shen, Y., Tian, H., Chen, Y., Chen, K., Wang, R., Xu, Y., Xia, Y., and Yan, S.

</span>
<span class="ltx_bibblock">Occlum: Secure and Efficient Multitasking Inside a Single
Enclave of Intel SGX.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the Twenty-Fifth International Conference
on Architectural Support for Programming Languages and Operating
Systems</em>, ASPLOS ’20, pp.  955–970. Association for Computing
Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-7102-5.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3373376.3378469</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3373376.3378469" title="">https://dl.acm.org/doi/10.1145/3373376.3378469</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(56)</span>
<span class="ltx_bibblock">
Szyller, S. and Asokan, N.

</span>
<span class="ltx_bibblock">Conflicting interactions among protection mechanisms for machine
learning models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the Thirty-Seventh AAAI Conference on
Artificial Intelligence and Thirty-Fifth Conference on Innovative
Applications of Artificial Intelligence and Thirteenth Symposium on
Educational Advances in Artificial Intelligence</em>, volume 37 of
<em class="ltx_emph ltx_font_italic" id="bib.bib56.2.2">AAAI’23/IAAI’23/EAAI’23</em>, pp.  15179–15187. AAAI Press.

</span>
<span class="ltx_bibblock">ISBN 978-1-57735-880-0.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1609/aaai.v37i12.26771</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aaai.v37i12.26771" title="">https://doi.org/10.1609/aaai.v37i12.26771</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(57)</span>
<span class="ltx_bibblock">
Szyller, S., Atli, B. G., Marchal, S., and Asokan, N.

</span>
<span class="ltx_bibblock">DAWN: Dynamic Adversarial Watermarking of Neural
Networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 29th ACM International Conference on
Multimedia</em>, MM ’21, pp.  4417–4425. Association for Computing
Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-8651-7.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3474085.3475591</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3474085.3475591" title="">https://dl.acm.org/doi/10.1145/3474085.3475591</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (a)</span>
<span class="ltx_bibblock">
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin,
A., Grave, E., and Lample, G.

</span>
<span class="ltx_bibblock">LLaMA: Open and Efficient Foundation Language Models,
a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2302.13971" title="">http://arxiv.org/abs/2302.13971</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (b)</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L.,
Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu,
W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S.,
Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev,
A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y.,
Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y.,
Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva,
R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R.,
Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A.,
Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and
Scialom, T.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models,
b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2307.09288" title="">http://arxiv.org/abs/2307.09288</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(60)</span>
<span class="ltx_bibblock">
Tramèr, F. and Boneh, D.

</span>
<span class="ltx_bibblock">Slalom: Fast, Verifiable and Private Execution of
Neural Networks in Trusted Hardware.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1806.03287" title="">http://arxiv.org/abs/1806.03287</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(61)</span>
<span class="ltx_bibblock">
Tramèr, F., Zhang, F., Juels, A., Reiter, M. K., and Ristenpart, T.

</span>
<span class="ltx_bibblock">Stealing Machine Learning Models via Prediction
{<span class="ltx_text ltx_phantom" id="bib.bib61.1.1"><span style="visibility:hidden">}</span></span>APIs<span class="ltx_text ltx_phantom" id="bib.bib61.2.2"><span style="visibility:hidden">{</span></span>}.

</span>
<span class="ltx_bibblock">pp.  601–618.

</span>
<span class="ltx_bibblock">ISBN 978-1-931971-32-4.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer?" title="">https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(62)</span>
<span class="ltx_bibblock">
Tsai, C.-C., Porter, D. E., and Vij, M.

</span>
<span class="ltx_bibblock">{<span class="ltx_text ltx_phantom" id="bib.bib62.1.1"><span style="visibility:hidden">}</span></span>Graphene-SGX<span class="ltx_text ltx_phantom" id="bib.bib62.2.2"><span style="visibility:hidden">{</span></span>}: A Practical Library
{<span class="ltx_text ltx_phantom" id="bib.bib62.3.3"><span style="visibility:hidden">}</span></span>OS<span class="ltx_text ltx_phantom" id="bib.bib62.4.4"><span style="visibility:hidden">{</span></span>} for Unmodified Applications on
{<span class="ltx_text ltx_phantom" id="bib.bib62.5.5"><span style="visibility:hidden">}</span></span>SGX<span class="ltx_text ltx_phantom" id="bib.bib62.6.6"><span style="visibility:hidden">{</span></span>}.

</span>
<span class="ltx_bibblock">pp.  645–658.

</span>
<span class="ltx_bibblock">ISBN 978-1-931971-38-6.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.usenix.org/conference/atc17/technical-sessions/presentation/tsai" title="">https://www.usenix.org/conference/atc17/technical-sessions/presentation/tsai</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(63)</span>
<span class="ltx_bibblock">
Viand, A. and Shafagh, H.

</span>
<span class="ltx_bibblock">Marble: Making Fully Homomorphic Encryption Accessible to
All.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Proceedings of the 6th Workshop on Encrypted
Computing &amp; Applied Homomorphic Cryptography</em>, WAHC ’18, pp. 49–60. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-5987-0.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3267973.3267978</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3267973.3267978" title="">https://doi.org/10.1145/3267973.3267978</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(64)</span>
<span class="ltx_bibblock">
Voss, W. G.

</span>
<span class="ltx_bibblock">European Union Data Privacy Law Reform: General Data Protection
Regulation, Privacy Shield, and the Right to Delisting.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://papers.ssrn.com/abstract=2894571" title="">https://papers.ssrn.com/abstract=2894571</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(65)</span>
<span class="ltx_bibblock">
Wood, A., Najarian, K., and Kahrobaei, D.

</span>
<span class="ltx_bibblock">Homomorphic Encryption for Machine Learning in Medicine
and Bioinformatics.

</span>
<span class="ltx_bibblock">53(4):70:1–70:35.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3394658</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3394658" title="">https://dl.acm.org/doi/10.1145/3394658</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (a)</span>
<span class="ltx_bibblock">
Wu, S., Fei, H., Qu, L., Ji, W., and Chua, T.-S.

</span>
<span class="ltx_bibblock">NExT-GPT: Any-to-Any Multimodal LLM, a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2309.05519" title="">http://arxiv.org/abs/2309.05519</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (b)</span>
<span class="ltx_bibblock">
Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur,
P., Rosenberg, D., and Mann, G.

</span>
<span class="ltx_bibblock">BloombergGPT: A Large Language Model for Finance,
b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.17564" title="">http://arxiv.org/abs/2303.17564</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (a)</span>
<span class="ltx_bibblock">
Xue, M., Wu, Z., He, C., Wang, J., and Liu, W.

</span>
<span class="ltx_bibblock">Active DNN IP Protection: A Novel User Fingerprint Management
and DNN Authorization Control Technique.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">2020 IEEE 19th International Conference on
Trust, Security and Privacy in Computing and
Communications (TrustCom)</em>, pp.  975–982, a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TrustCom50675.2020.00130</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org/abstract/document/9343023" title="">https://ieeexplore.ieee.org/abstract/document/9343023</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (b)</span>
<span class="ltx_bibblock">
Xue, M., Zhang, Y., Wang, J., and Liu, W.

</span>
<span class="ltx_bibblock">Intellectual Property Protection for Deep Learning Models:
Taxonomy, Methods, Attacks, and Evaluations.

</span>
<span class="ltx_bibblock">3(06):908–923, b.

</span>
<span class="ltx_bibblock">ISSN 2691-4581.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TAI.2021.3133824</span>.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.computer.org/csdl/journal/ai/2022/06/09645219/1zc6IpBDlfi" title="">https://www.computer.org/csdl/journal/ai/2022/06/09645219/1zc6IpBDlfi</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(70)</span>
<span class="ltx_bibblock">
Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B.,
Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren,
R., Li, Y., Tang, X., Liu, Z., Liu, P., Nie, J.-Y., and Wen, J.-R.

</span>
<span class="ltx_bibblock">A Survey of Large Language Models.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.18223" title="">http://arxiv.org/abs/2303.18223</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 11:24:37 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
