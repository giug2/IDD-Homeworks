<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic</title>
<!--Generated on Tue Dec 12 01:34:46 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.06926v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S2" title="2 Related Work ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS1" title="3.1 Spanish-French to Arabic Levantine-Gulf (SF-ArLG) Dataset ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Spanish-French to Arabic Levantine-Gulf (SF-ArLG) Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS2" title="3.2 Transformers based Neural Machine Translation ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Transformers based Neural Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS3" title="3.3 Online Social Behavior (OSB) Modeling ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Online Social Behavior (OSB) Modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S4" title="4 Experiment Design and Evaluation Metrics ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment Design and Evaluation Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S4.SS1" title="4.1 Datasets and Preprocessing ‣ 4 Experiment Design and Evaluation Metrics ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets and Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S4.SS2" title="4.2 Experimental Design and Evaluation Protocol ‣ 4 Experiment Design and Evaluation Metrics ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experimental Design and Evaluation Protocol</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S5" title="5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results and Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS1" title="5.1 Performance of the Proposed NMT Models ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Performance of the Proposed NMT Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS2" title="5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Performance of Sentiment Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS3" title="5.3 Performance of Hate Speech Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Performance of Hate Speech Classification</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S6" title="6 Conclusion ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="”Conversion" been="" class="package-alerts ltx_document" errors="" found”="" have="" role="“status”">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: arabtex</li>
<li>failed: utf8</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of <a href="https://corpora.mathweb.org/corpus/arxmliv/tex_to_html/info/loaded_file" target="_blank">supported packages</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2312.06926v1 [cs.CL] 12 Dec 2023</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\setcode</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">utf8


</p>
</div>
<h1 class="ltx_title ltx_title_document">Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Fatimah Alzamzami 
<br class="ltx_break"/>School of Electrical Engineering and Computer Science
<br class="ltx_break"/>University of Ottawa
<br class="ltx_break"/>Ottawa, Ontario, Canada 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">falza094@uottawa.ca</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id2.2.id2">\And</span>Abdulmotaleb El Saddik 
<br class="ltx_break"/>School of Electrical Engineering and Computer Science
<br class="ltx_break"/>University of Ottawa
<br class="ltx_break"/>Ottawa, Ontario, Canada 
<br class="ltx_break"/>Mohamed bin Zayed University of Artifcial Intelligence
<br class="ltx_break"/>Abu Dhabi, UAE
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">elsaddik@uottawa.ca</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">Resources in high-resource languages have not been efficiently exploited in low-resource languages to solve language-dependent research problems. Spanish and French are considered high resource languages in which an adequate level of data resources for informal online social behavior modeling, is observed. However, a machine translation system to access those data resources and transfer their context and tone to a low-resource language like dialectal Arabic, does not exist. In response, we propose a framework that localizes contents of high-resource languages to a low-resource language/dialects by utilizing AI power. To the best of our knowledge, we are the first work to provide a parallel translation dataset from/to informal Spanish and French to/from informal Arabic dialects. Using this, we aim to enrich the under-resource status of dialectal Arabic and fast-track the research of diverse online social behaviors within and across smart cities in different geo-regions. The experimental results have illustrated the capability of our proposed solution in exploiting the resources between high and low resource languages and dialects. Not only this, but it has also been proven that ignoring dialects within the same language could lead to misleading analysis of online social behavior.
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_text ltx_font_bold" id="footnote1.1">Disclaimer:</span> This work uses terms, sentences, or language that are considered foul or offensive by some readers. Owing to the topic studied in this thesis, quoting toxic language is academically justified but I do not endorse the use of these contents of the quotes. Likewise, the quotes do not represent my opinions and I condemn online toxic language.</span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.8"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="p2.8.1">K</em><span class="ltx_text ltx_font_bold" id="p2.8.2">eywords</span> Neural Machine Translation <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.1.m1.1"><semantics id="p2.1.m1.1a"><mo id="p2.1.m1.1.1" xref="p2.1.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.1.m1.1b"><ci id="p2.1.m1.1.1.cmml" xref="p2.1.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.1.m1.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.1.m1.1d">⋅</annotation></semantics></math>
Content Localization  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.2.m2.1"><semantics id="p2.2.m2.1a"><mo id="p2.2.m2.1.1" xref="p2.2.m2.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.2.m2.1b"><ci id="p2.2.m2.1.1.cmml" xref="p2.2.m2.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.2.m2.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.2.m2.1d">⋅</annotation></semantics></math>
Low-Resource Languages  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.3.m3.1"><semantics id="p2.3.m3.1a"><mo id="p2.3.m3.1.1" xref="p2.3.m3.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.3.m3.1b"><ci id="p2.3.m3.1.1.cmml" xref="p2.3.m3.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.3.m3.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.3.m3.1d">⋅</annotation></semantics></math>
Arabic Dialects  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.4.m4.1"><semantics id="p2.4.m4.1a"><mo id="p2.4.m4.1.1" xref="p2.4.m4.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.4.m4.1b"><ci id="p2.4.m4.1.1.cmml" xref="p2.4.m4.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.4.m4.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.4.m4.1d">⋅</annotation></semantics></math>
Sentiment  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.5.m5.1"><semantics id="p2.5.m5.1a"><mo id="p2.5.m5.1.1" xref="p2.5.m5.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.5.m5.1b"><ci id="p2.5.m5.1.1.cmml" xref="p2.5.m5.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.5.m5.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.5.m5.1d">⋅</annotation></semantics></math>
Hate Speech  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.6.m6.1"><semantics id="p2.6.m6.1a"><mo id="p2.6.m6.1.1" xref="p2.6.m6.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.6.m6.1b"><ci id="p2.6.m6.1.1.cmml" xref="p2.6.m6.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.6.m6.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.6.m6.1d">⋅</annotation></semantics></math>
Topic Modeling  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.7.m7.1"><semantics id="p2.7.m7.1a"><mo id="p2.7.m7.1.1" xref="p2.7.m7.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.7.m7.1b"><ci id="p2.7.m7.1.1.cmml" xref="p2.7.m7.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.7.m7.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.7.m7.1d">⋅</annotation></semantics></math>
Topic Phrase Extraction  <math alttext="\cdot" class="ltx_Math" display="inline" id="p2.8.m8.1"><semantics id="p2.8.m8.1a"><mo id="p2.8.m8.1.1" xref="p2.8.m8.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.8.m8.1b"><ci id="p2.8.m8.1.1.cmml" xref="p2.8.m8.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.8.m8.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.8.m8.1d">⋅</annotation></semantics></math>
COVID-19</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">With the ever-growing amount of user-generated multilingual content on social media, uncovering the valuable knowledge hidden within this information is crucial <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>. Examining such multilingual (i.e., including various dialects within the very same language) online social interactions is an essential tool for analyzing the social and cultural fabric of smart cities, allowing for informed planning and development strategies. Research trend, however, tends to solve a specific problem in a specific language or dialect, instead of utilizing the already existing resources to analyze online social behaviors (OSB), like sentiment and hate speech <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>, <a class="ltx_ref" href="#bib.bib4" title="">4</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>, in low-resource languages and dialects. This can be seen in the huge discrepancy of resources between languages, where very few have a high-resource status while many others are low-resource. Spanish and French are high-resource languages while Arabic is still considered a low-resource language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite> despite the fact that Arabic is among the top used languages on social media following Spanish and French. This research trend encourages building resources for every problem in every language and dialect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>
and limits exploiting the already existing resources -especially in high-resource languages- to other different languages and even dialects to solve tasks like online social behavior analysis in low-resource languages. Moreover, the expensive cost (i.e. in terms of HW/SW requirements, time, efforts, cost, and human labor) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite> for building a resource for each language/dialect to solve each OSB task has definitely contributed to the under-resource status of existing multi-lingual-dialectal OSB systems. Researchers are obligated to address the shortcomings of this current practice and study reliable yet inexpensive solutions that minimizes the dependency of languages/dialects in modeling online social behaviors (e.g. sentiment and hate speech).</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Machine translation is a medium to bridge the informal-communication gap between high and low resource languages on social media; however, word-to-word translation does not ensure transferring the context and tone of messages from a language/dialect to another language/dialect. Further, the unavailability of informal parallel datasets has contributed to the sub-optimal performance of machine translation in low-resource languages. This paper addresses this issue and proposes a content-localization based translation dataset (SF-ArLG) that provides parallel translations from/to informal Spanish and French to/from two informal Arabic dialects: Levantine and Gulf. This dataset is customized for informal communications on social media; it does not only consider the dialectal aspect of a language but also considers the social media culture for communications. We propose our SF-ArLG dataset as an attempt to minimize the dependency of languages/dialects in modeling online social behaviors in low-resource languages, through efficiently allowing the exploitation of existing resources especially in high-resource languages like Spanish and French. This is done through localizing the informal content of those existing resources into the low-resource informal dialectal Arabic without the need to construct and annotate new data resources from scratch.
To the best of our knowledge, we are the first to construct an informal translation dataset from/to Spanish and French to/from Arabic Levantine and Gulf dialects.
This paper is designed to answer the following questions: (1) Can we transfer the context and tone of social-informal messages between languages and dialects using AI power?, (2) Can we exploit existing OSB resources from a high-resource language/dialect to solve an online social behavior problem in a low-resource language/dialect using content-localization translation approach?. To the best of our knowledge, this is the first work that proposes a content-localization based machine translation framework to model online social behavior in low-resource languages/dialects.
We summarize the contributions of this work as follows:
<br class="ltx_break"/>(1) Design a content-localization based machine translation framework for online social behavior modeling in different language and dialects. 
<br class="ltx_break"/>(2) Construct a parallel social-informal translation dataset between Spanish, French and dialectal Arabic.
<br class="ltx_break"/>(3) Develop neural machine translation models from/to French, Spanish to/from dialectal Arabic (i.e. Levantine and Gulf in this paper).
<br class="ltx_break"/>(4) Conduct comprehensive experiments to evaluate the performance of our proposed content-localize models on two classifications problems: sentiment classification and hate speech classification.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The rest of the paper is organized as follows. Section <a class="ltx_ref" href="#S2" title="2 Related Work ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a>
presents the related work. Our proposed method is presented in
Section <a class="ltx_ref" href="#S3" title="3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">3</span></a>. Section <a class="ltx_ref" href="#S4" title="4 Experiment Design and Evaluation Metrics ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">4</span></a> explains
the experiment design and evaluation protocol followed in
this work whereas the results and analysis are discussed
in Section <a class="ltx_ref" href="#S5" title="5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">5</span></a>. Finally, in Section <a class="ltx_ref" href="#S6" title="6 Conclusion ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">6</span></a> we conclude our
proposed work and findings. Future directions are discussed in the limitation section.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Neural machine translation (NMT) has grown rapidly in the last ten years; it has shown a tremendous performance on high-resource language pairs, however, NMT is still inaccurate on low-resource languages due to the unavailability of large parallel datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>.
Even though the accuracy of translation from/to Arabic into/from French and Spanish is significantly lower than the accuracy for other language pairs such as English-French and English-Spanish <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>, <a class="ltx_ref" href="#bib.bib17" title="">17</a>]</cite>, there has been a notable progress in the development of machine translation from/to modern standard Arabic (MSA) into/from English language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>, <a class="ltx_ref" href="#bib.bib19" title="">19</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>. However, dialectal Arabic has not received the same level of attention as MSA in machine translation from different languages despite its dominant use over MSA on social media <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>. Little effort has been noticed in dialectal Arabic machine translation from English language including Zbib etal <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite> (English-Levantine and English-Egyptian), MDC corpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite> (English-Levantine/NorthAfrican/Egyptian), MADAR Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> (English-Gulf/Levantine/Egyptian-NortAfrican), QAraC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite> (English-Gulf), The Bible <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span> https://www.biblesociety.ma</span></span></span>, <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span> https://www.bible.com</span></span></span> (English-North_African). To the best of our knowledge, there is no existing dataset that provides parallel translation between informal Spanish, French, and dialectal Arabic. This paper proposes the first translation dataset from informal Spanish and French to informal Arabic dialects (i.e. Levantine and Gulf dialects in this paper).</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Figure. <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">1</span></a> presents the proposed framework for content-localization based neural machine translation approach for modeling online social behaviors (i.e. sentiment and hate speech as case studies in this work) in two low-resource Arabic dialects: Levantine and Gulf.
The framework depicted in Figure. <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">1</span></a> is proposed as an attempt to enrich the Arabic under-resource status so we can expand the spectrum of online social behavior analysis by minimizing the dependency of languages and dialects in modeling online social behaviors. This framework is designed in a way that reduces the cost of building resources (i.e. data and/or models) for every language and dialect to perform OSB-related tasks by allowing efficient exploitation of existing resources (i.e. data and/or models) between low-resource (like Arabic and its dialects) and high-resource languages (like French and Spanish).</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="263" id="S3.F1.g1" src="x1.png" width="354"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Proposed framework.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">To achieve this, we propose translating social media data, namely messages, using content-localization approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>. Content localization goes beyond translation which converts messages from one language to another. Content localization takes into account that context and tone of contents are transferred to the language and even to the dialect of interest; hence, we can exploit existing resources to solve the problem in hand without building the needed resources from scratch. This can be done through localizing the contents of an existing data resource (i.e. collected, cleaned, filtered, and annotated dataset) to a low-resource target language/dialect and using the localized content to train and build an OSB model in the language and/or dialect of interest.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Spanish-French to Arabic Levantine-Gulf (SF-ArLG) Dataset</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Tweets in native Spanish and native French have been translated into Levantine and Gulf Arabic dialects. We require that all participants are professional translators, native in the Arabic dialects, and native or fluent in Spanish and French. Also, the translators are required to have a social involvement on social media (i.e. Twitter, Facebook, YouTube or any other platform). It is important to mention that the native Spanish and French tweets were originally translated from English tweets in DFMSD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">For our translation, we adopt the content localization translation approach where translating the texts does not only convey a near-equivalent meaning but also addresses and integrates linguistic, cultural, tone, and contextual components of the texts. Same words might convey different meaning in different dialects; for example, the word “chips” refers to fried thin potato chips in North American English while it refers to “fries” in UK English.
The same applies for different dialects in Arabic language. An example of this, the word
"<span class="ltx_ERROR undefined" id="S3.SS1.p2.1.1">\&lt;</span>صاحبي&gt;" in Gulf dialect refers to a friend while in Lebanese (i.e. Levantine) dialect it refers to boyfriend.
Since the dataset has been constructed based on social media (i.e. Twitter in this work) and
the tweets are mostly expressed in a day-to-day spoken language, the translations are customized to OSN cultural language. Thus, we take into consideration a number of additional criteria (i.e. in addition to the content localization based translation approach): (1) Consideration of OSN cultural language and expressions: iconic emotion (e.g. emoticons, emojis), slang abbreviations, and hashtag words. Hashtag
words are translated into the corresponding Arabic dialect while preserving their occurrence order and their context, (2) Consideration of Informal Language: informal language is used in casual settings like in daily-informal conversations; this includes slang words like "lol", "Oh mon dieu", or "bouffer", (3) Consideration of language code borrowing: code borrowing refers to using one primary language but mixing in words from another language to fit the primary language. For example, the word "lol" is used and written using the Arabic alphabet as "<span class="ltx_ERROR undefined" id="S3.SS1.p2.1.2">\&lt;</span>لول&gt;".</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The qualified Translators are provided with a subset of sentences and translation guidelines that cover the above criteria. In addition, they are advised to convert
mainly proper nouns into Arabic letters where applicable; for example names of people ("John" to "<span class="ltx_ERROR undefined" id="S3.SS1.p3.1.1">\&lt;</span>جون&gt;"), and names of places ("UK" to "<span class="ltx_ERROR undefined" id="S3.SS1.p3.1.2">\&lt;</span>بريطانيا&gt;"). The translators are also
advised to pay attention to the spelling as any misspelling would harm the quality of the
translation. Upon the completion of the translation task, the translators are asked to do a
round of proofreading before they submit the final translations. Note that the translation
is done for each dialect individually with the corresponding dialect translators. We have a total of <math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mo id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><approx id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">≈</annotation></semantics></math> 36,000 localized pairs (12,000 for each of French-Levantine, Spanish-Levantine, and Spanish-Gulf). The choice to study the two Arabic dialects is due to availability of some public native Levantine and Gulf OSB datasets like sentiment and hate speech that can be used to evaluate our proposed approach. In addition, the choice of three language-dialect pair is to meet the scope of this study
while respecting the writing space constraint of the paper.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_pagination ltx_centering ltx_role_start_2_columns"></div>
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="1332" id="S3.F2.g1" src="x2.png" width="1494"/>
<div class="ltx_pagination ltx_centering ltx_role_end_2_columns"></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Sequence-to-sequence Transformers architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite> used in training our multi-lingual-dialectal NMT models.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Transformers based Neural Machine Translation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Figure. <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.2 Transformers based Neural Machine Translation ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the methodology we follow in our neural machine translation modeling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>. Data is fed into the data preprocessing and preparation component; a set of filters are applied to clean unnecessary noise. The clean data is then fed into the neural machine translation (NMT) training component to start learning the translation between source language texts and their translation in the target language/dialect. Finally, the learnt model is evaluated and tested till it yields the best performance before it is ready to be used to translate new unseen data.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="S3.F3.g1" src="x3.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Proposed methodology for neural machine translation.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We use the sequence-to-sequence Transformers architecture depicted in Figure. <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.1 Spanish-French to Arabic Levantine-Gulf (SF-ArLG) Dataset ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>. It consists of 12 layers of encoder and 12 layers of decoders with model dimension of 1024 on 16 heads. On top of both encoder and decoder, there is an additional normalization layer that was found to stabilize the training. We use pretrained weights from mBART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite> model that was pre-trained on 25 languages. It has been proven that transfer learning offers a rich set of benefits including improving the efficiency of model training and saving of time and resources since building a high-performance model from a scratch requires a large amount of data, time, resources, and efforts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>, <a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>. Therefore, we use the fine-tuning learning approach to train Transformers machine translation models as an attempt to solve the limitations of small datasets. For our Arabic dialects models, we use our proposed dataset to finetune the mBART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite> pretrained model. The model learns parallel translation from informal and slang French and Spanish to informal and dialectal Arabic. We have three models corresponding to two Arabic dialects: French-Levantine, Spanish-Levantine, and Spanish-Gulf.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Online Social Behavior (OSB) Modeling</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Our study focuses on two types of online social behavior: sentiment and hate behaviors. Figure. <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.3 Online Social Behavior (OSB) Modeling ‣ 3 Method ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the proposed methodology followed in order to build sentiment and hate analyzers. Supervised classification approach is adopted in the modeling of OSB. The data preprocessing is performed first before the preprocessed data is fed into the training component. The Classifier Training component demonstrates the proposed neural network architecture. The BERT layer consists of BERT pre-trained embeddings which are representations of words and their relation to each other in n-dimension. BERT pre-trained model is fine-tuned by training the entire BERT architecture on our localized datasets in order to alleviate possible biases resulted from pre-training on Wikipedia corpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>. BERT-base-arabic-camelbert-mix model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib32" title="">32</a>]</cite> is used in this work;
It consists of twelve layers and uses 110M parameters. The optimizer used is Adam with a learning rate of 1e-4, a weight decay of 0.01, learning rate warmup for 10,000 steps and linear decay of the learning rate after.
the model is pre-trained on a mix of Modern Standard Arabic (MSA), dialectal Arabic (DA), and classical Arabic (CA).
A feed-forward neural network layer -used as a classification layer- is appended to the BERT layer. This classification layer produces logits that indicate the likelihood of a message belonging to a class. Soft max layer is used to normalize the logits and computes the probability of classes. The training is conducted by back propagating the errors throughout our architecture and updating the weights of the pre-trained weights and the weights of the appended layer based on our datasets. Early Stopping Approach is utilized to prevent over-fitting the neural network on the training data and improve the generalization of the models. Adams optimizer is used to optimize our models. Finally, we validate and test our models on the validation and test sets before generating the final result predictions. The prediction of sentiment analyzer is one of two polarity classes: positive or negative sentiments, whereas the hate analyzer predicts the existent or non-existent of hate content.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S3.F4.g1" src="x4.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Proposed methodology for online social behavior modeling.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment Design and Evaluation Metrics</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Preprocessing</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We list below the datasets we have used for modeling and evaluating our proposed approach:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">French Twitter Sentiment Analysis Dataset (FTSAD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite></span>:
We have randomly sampled 20,000 tweets with a balanced distribution between positive and negative classes. This dataset is used for modeling purposes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">ArSentD-Lev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite></span>:
This dataset consists of 4,000 tweets (i.e. 1,232 positive tweets and 1,884 negative tweets) collected from the Arabic Levant region, and manually annotated through the crowd-sourcing approach. This dataset is used for evaluation purposes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">OCLAR datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite></span>:
OCLAR is an opinion corpus for Lebanese (i.e. Levantine) Arabic reviews.</p>
</div>
<div class="ltx_para" id="S4.I1.i3.p2">
<p class="ltx_p" id="S4.I1.i3.p2.1">The positive class contains all reviews rating from 1 to 3 (3,465 reviews), while the negative class contains the reviews with rating values from 1 to 2 (451 reviews). This dataset is used for evaluation purposes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">Spanish HateSpeech Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite></span>:
This dataset is a subset of a bigger multilingual hate speech dataset that consists of 13 languages, one of which is Spanish. We extracted the Spanish samples of total number of 12,423 texts, out of which 4,239 are labeled as hate speech.</p>
</div>
<div class="ltx_para" id="S4.I1.i4.p2">
<p class="ltx_p" id="S4.I1.i4.p2.1">This dataset is used for modeling purposes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">L-HSAB datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite></span>:
This dataset has been constructed and manually annotated for Levantine hate speech detection on social media. It contains a total of 5846 tweets, out of which 3,650 do not contain hate contents while 2,196 contain hate speech content. This dataset is used for evaluation purposes.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">A list of preprocessing steps have been implemented to prepare the data before the modeling the stage. For neural machine translation, we have applied: (1) Removing extra white-spaces, (2) Removing encoding symbols, (3) Removing URLs, (4) Converting text to lower case, (5) Removing tashkeel and harakat: tashkeel or harakat refer to all the diacritics placed over or below letters, (6) Normalizing Hamza.
For sentiment and hate speech modeling, the mentioned steps have been applied along with: (7) Removing user mention, (8) Removing special characters and numbers, (9) Removing stop-words.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Design and Evaluation Protocol</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We design three scenarios to conduct the experiments of this paper as follows:
<br class="ltx_break"/>(1) We use our proposed (SF-ArLG) dataset to train three neural machine translation models: French-Levantine, Spanish-Levantine, and Spanish-Gulf. We randomly divided SF-ArLG into two groups: 90% for training and 10%for testing. Our training has been conducted through fine-tuning mBart <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite> and using its default parameters.
For the evaluation metrics, we use BLEU and ROUGE metrics. BLEU metric is recommended for the translation tasks as it conducts robust assessment over the quality of translation fairly quickly. ROUGE complements BLEU in terms of evaluation where it focuses on recall; while BLEU is precision oriented. Therefore, we use F-score of BLEU and ROUGE.
<br class="ltx_break"/>(2) We localize an existing annotated sentiment dataset in French into a target language/dialect (i.e Arabic Levantine). Note that we preserve the source annotations of the source dataset. Then, we train a sentiment model using this localized dataset. Finally, we evaluate the trained model on an external dataset under the condition that the contents of the external dataset should be in the native target language/dialect. In this experiment, we translate the French sentiment dataset (FTSAD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite> to Arabic-Levantine using our proposed NMT French-Levant model. The localized dataset will be used later to train an Arabic-Levantine sentiment classifier. The purpose of this experiment is to examine the validity of our proposed approach that aims to minimize the dependency of language/dialects in modeling online social behavior (i.e. sentiment in this experiment).
<br class="ltx_break"/>(3) We localize an existing annotated hate speech dataset in Spanish into two target Arabic dialects, Levantine and Gulf, using our proposed NMT models. Note that we preserve the source annotations of the source dataset. Then, we train two hate classifiers using these localized datasets, one for each dialect. After that, we choose an external dataset of Arabic Levantine dialect. Finally, we evaluate the trained models on the external native Levantine dataset. The contents of this external dataset have been written and annotated in native Levantine dialect by native speakers. In this experiment, the Spanish hate dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite> is localize to Arabic-Levantine and Arabic-Gulf dialects to be used later for training Arabic-Levantine and Arabic-Gulf hate classifiers. The purpose of this experiment is to investigate the effect of different dialects of the same language on the modeling and analysis of the online social behaviors on social media (i.e. hate speech in this experiment).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">For sentiment and hate speech modeling, the corresponding datasets have been randomly split into 80% for training and 20% for validation. We evaluate our models on the validation set during training- every 100 steps- to track its learning progress. We have implemented early-stopping approach to regularize the learning of the model during training in order to prevent any potential over-fitting to the training data. For evaluation measures, we have used accuracy, precision, recall, commonly used for classification evaluation, as evaluation metrics. Precision, recall give a better view of model performance than accuracy alone does.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Analysis</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Performance of the Proposed NMT Models</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Table. <a class="ltx_ref" href="#S5.T1" title="Table 1 ‣ 5.1 Performance of the Proposed NMT Models ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">1</span></a> presents the results of our Transformers-based NMT models for French and Spanish to Arabic Levantine and Gulf dialects. Transformers models trained through fine-tuning a pretrained model (i.e. mBART in this work) are shown to yield a superior translation performance with at least F-score of 35 points.
Spanish to Arabic-Gulf NMT model is shown to have the highest learning performance (F-score of 37 points) followed by Spanish to Arabic-Gulf (F-scoe of 36 points) and then French to Arabic-Levantine (F-score of 35 points). The nature of Transformers that use multi-head self-attention allows the models to learn word contextualization, and hence yield solid performance results in terms of F-score of BLUE and ROUGE. The self-attention enables contextualizing every word in various positions with respect to the whole sequence. This solves the homonym problem where similar words might have different meanings in different contexts. In addition, learning a model from scratch requires a huge size of data so that the model can converge properly. However, transfer learning technique has solved the problem related to limited and/or small data resources. As seen in Table. <a class="ltx_ref" href="#S5.T1" title="Table 1 ‣ 5.1 Performance of the Proposed NMT Models ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">1</span></a>, leveraging the transfer learning in learning our NMT models has tremendously yielded a high translation learning performance.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance results of three NMT models -in terms of F-score(BLEU, ROUGE)- using our propose dataset. The three models represents French to Arabic-Levantine, Spanish to Arabic-Levantine, and Spanish to Arabic-Gulf.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.1" style="width:173.4pt;height:61.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.5pt,5.4pt) scale(0.848776168556409,0.848776168556409) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_bb ltx_border_r ltx_border_tt" id="S5.T1.1.1.1.1.1" rowspan="4"><span class="ltx_text" id="S5.T1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T1.1.1.1.1.1.1.1" style="width:6.9pt;height:27.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:27.2pt;transform:translate(-10.14pt,-10.14pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T1.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.1.1.1.1.1">Model</span></span>
</span></span></span></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T1.1.1.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1.3.1">F-Score(BLEU, ROUGE)</span></th>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.2.1">Fr-&gt; Ar-Levantine</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.2.2.2">35.2</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.3.3.1">Es -&gt; Ar-Levantine</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.3.3.2">37.1</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T1.1.1.4.4.1">Es -&gt; Ar-Gulf</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T1.1.1.4.4.2">36.2</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Figure. <a class="ltx_ref" href="#Ax1.F6" title="Figure 6 ‣ Appendix ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">6</span></a> in the appendix, illustrates a sample of translations (i.e. generated by our proposed models) from/to French and Spanish to/from Arabic dialects (i.e. Levantine and Gulf in this study). It is important to note that all the sample translations were examined and approved by bilingual users with native to near-native bilingual language proficiency. The participant users approved that the contexts of the original messages were properly transferred -along with the corresponding dialect expression- into our generated translations. "Oh mon Dieu!" is an informal expression to say "oh my god or for god sake!" which was correctly translated into the Levantine expression "<span class="ltx_ERROR undefined" id="S5.SS1.p2.1.1">\&lt;</span>ياربي!&gt;" that indicates an exclamation of anger, annoyance, or surprise. "bizarre", a common French word to describe someone or something as "weird or strange", was also correctly translated into a Levant term "<span class="ltx_ERROR undefined" id="S5.SS1.p2.1.2">\&lt;</span>غريبة&gt;" meaning weird. The expression "<span class="ltx_ERROR undefined" id="S5.SS1.p2.1.3">\&lt;</span>الفحص&gt;" is a very local way of saying "exam" in Levantine dialect, which could mean "check or examine" in other dialects like Gulf. Our Levantine model could successfully recognize it as "exam" and generate the sentence translation as "L’examen était très facile". "L’examen" in French refers to "exam" in English. Similarly, with expression "<span class="ltx_ERROR undefined" id="S5.SS1.p2.1.4">\&lt;</span>تشتي&gt;" which means "raining" in the informal Levantine dialect; our model correctly translated it into French as "il pleuve tellement". "pleuve" is the French word for "raining".</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Performance of Sentiment Classification</h3>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The performance of sentiment and hate models on the validation set in terms of accuracy, precision, and recall. The models represent French to Arabic-Levantine, Spanish to Arabic-Levantine, and Spanish to Arabic-Gulf.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:206.0pt;height:40.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-94.7pt,18.8pt) scale(0.520898046401274,0.520898046401274) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.2"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.4">
<span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.1.1.1.1.4.1">Validation 
<br class="ltx_break"/>Precision</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.5">
<span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.1.1.1.1.5.1">Validation Recall</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.6">
<span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.1.1.1.1.6.1">Validation F-Score</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.7">
<span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.1.1.1.1.7.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.1.1.2.1.1" rowspan="3">
<span class="ltx_text" id="S5.T2.1.1.2.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T2.1.1.2.1.1.1.1" style="width:6.9pt;height:27.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:27.2pt;transform:translate(-10.14pt,-10.14pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T2.1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.1.1.1.1.1.1">Model</span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.2">
<span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.1.1.2.1.2.1">Sentiment</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.3" style="width:71.7pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.1.1.2.1.3.1">Fr-&gt;Ar-Gulf</p>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.4">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.5">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.6">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.1.7">75</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.1" rowspan="2">
<span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.2.1.1">Hate</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.2" style="width:71.7pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.1.1.3.2.2.1">Es-&gt;Ar-Levantine</p>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.3">0.69</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.4">0.68</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.5">0.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.2.6">69</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.1" style="width:71.7pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.1.1.4.3.1.1">Es-&gt;Ar-Gulf</p>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.2">0.69</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.3">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.4">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.4.3.5">71</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The results in Table. <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a> present the performance of the proposed sentiment and hate models that were trained using the translated dataset (i.e. translated from Spanish and French to Arabic Levantine and Gulf dialects using our proposed NMT models). The results in Table. <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a> depict the models’ performances using the validation set split of the same data that the models were trained on.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The French to Arabic-Levantine sentiment model is shown to have effectively learnt the sentiment classes (i.e. positive and negative) using the translated dataset (i.e. by our proposed NMT models). The sentiment model has scored 75% of accuracy, 0.75 points of precision and recall. Figure. <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the high frequency words used for positive and negative classes predicted by our sentiment model. The words in the figure corresponding to the positive class (Figure. <a class="ltx_ref" href="#S5.F4.sf1" title="4(a) ‣ Figure 5 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">4(a)</span></a>))-, reflect positive sentiment such as "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.1">\&lt;</span>رائعة&gt;" meaning "spectacular", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.2">\&lt;</span>الخير&gt;" meaning "good", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.3">\&lt;</span>رفيقي&gt;" meaning "my friend", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.4">\&lt;</span>أهلا وسهلا&gt;" meaning "greetings or welcome", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.5">\&lt;</span>هاهاها&gt;" meaning "hahaha", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.6">\&lt;</span>أفضل&gt;" meaning "better", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.7">\&lt;</span>الحلو&gt;" meaning "beautiful", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.8">\&lt;</span>بالتوفيق&gt;" meaning "good luck". Figure related to the negative class (Figure. <a class="ltx_ref" href="#S5.F4.sf2" title="4(b) ‣ Figure 5 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">4(b)</span></a>) also reflect negative sentiment such as "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.9">\&lt;</span>محزن&gt;" meaning "saddening", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.10">\&lt;</span>للأسف&gt;" meaning "unfortunately", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.11">\&lt;</span>أسوأ&gt;" meaning "worse", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.12">\&lt;</span>زعلان&gt;" meaning "sad or upset", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.13">\&lt;</span>صعب&gt;" meaning "difficult", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.14">\&lt;</span>غبي&gt;" meaning "stupid or dumb", "<span class="ltx_ERROR undefined" id="S5.SS2.p2.1.15">\&lt;</span>أبكي&gt;" meaning "crying".</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S5.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S5.F4.sf1.g1" src="extracted/5256711/images/wc_pos_sent_fr_lev_model1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span> Word-cloud for positive messages.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S5.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S5.F4.sf2.g1" src="extracted/5256711/images/wc_neg_sent_fr_lev_model1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span> Word-cloud for negative messages.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Word-cloud generated from messages classified as positive or negative sentiment by our French to Arabic-Levantine sentiment model, using the translated French sentiment dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">While Table. <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a> presents the performance of the models using the validation set, Table. <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performance of the sentiment model using an external dataset. The Levantine datasets (ArSentD-Lev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite> and OCLAR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>) are used to evaluate our Levantine sentiment model. The results show that the model is able to distinguish between positive and negative classes in both datasets; it has performed at a positive f-score of 0.81, negative f-score of 0.7, and over all accuracy of 77%.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The performance of French to Arabic-Levantine sentiment model, on external sentiment dataset, in terms of accuracy, precision, and recall.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1" style="width:208.1pt;height:22.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-166.8pt,17.8pt) scale(0.384249882946527,0.384249882946527) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.3.1">F-Score (Positive)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.4.1">F-Score (Negative)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.5.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1.1" rowspan="4"><span class="ltx_text" id="S5.T3.1.1.2.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T3.1.1.2.1.1.1.1" style="width:6.9pt;height:27.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:27.2pt;transform:translate(-10.14pt,-10.14pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T3.1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.1.1.1.1.1.1">Model</span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1.2" style="width:134.2pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.1.1.2.1.2.1">Fr-&gt;Ar-Levantine
<br class="ltx_break"/> evaluated on 
<br class="ltx_break"/>ArSentD-Lev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite> + OCLAR datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite></p>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1.3">0.81</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1.4">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.1.2.1.5">77</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Performance of Hate Speech Classification</h3>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>The performance of Spanish to Arabic-Levantine and Spanish to Arabic-Gulf hate models on an external hate speech dataset in Levantine dialect, in terms of accuracy, precision, and recall.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.1" style="width:208.1pt;height:57.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.9pt,16.3pt) scale(0.638669866044172,0.638669866044172) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T4.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.1.1" rowspan="5"><span class="ltx_text" id="S5.T4.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T4.1.1.1.1.1.1.1" style="width:6.9pt;height:27.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:27.2pt;transform:translate(-10.14pt,-10.14pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T4.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1.1.1.1.1.1">Model</span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="8" id="S5.T4.1.1.1.1.2">
<span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1.2.1">Es –&gt; Ar-Levantine evaluated on L-HSAB dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.2.2">
<td class="ltx_td ltx_border_r ltx_border_t" id="S5.T4.1.1.2.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.1.1.2.2.2">
<span class="ltx_text ltx_font_bold" id="S5.T4.1.1.2.2.2.1">Hate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S5.T4.1.1.2.2.3">
<span class="ltx_text ltx_font_bold" id="S5.T4.1.1.2.2.3.1">No-Hate</span></td>
<td class="ltx_td ltx_border_t" id="S5.T4.1.1.2.2.4"></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.3.3">
<td class="ltx_td ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.2.1">Precision</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.3.1">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.4.1">F-Score</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.5.1">Precision</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.6"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.6.1">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3.7"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.7.1">F-Score</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.3.8"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.3.8.1">Accuracy</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.4.4">
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.1" style="width:39.1pt;">
<p class="ltx_p ltx_align_top" id="S5.T4.1.1.4.4.1.1">Es-&gt;Ar-Levantine</p>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.2">0.66</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.3">0.68</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.4">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.5">0.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.6">0.79</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.1.1.4.4.7">0.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.4.4.8">75</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.5.5">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.1" style="width:39.1pt;">
<p class="ltx_p ltx_align_top" id="S5.T4.1.1.5.5.1.1">Es-&gt;Ar-Gulf</p>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.2">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.3">0.54</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.4">0.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.5">0.76</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.6">0.86</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.5.5.7">0.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T4.1.1.5.5.8">74</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">As seen in Table. <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Performance of Sentiment Classification ‣ 5 Results and Analysis ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">2</span></a>, our hate classifiers (i.e. Spanish-Arabic hate classifiers) have yielded solid performances using validation set split, in terms of accuracy
between 69%-71%. The overall precision and recall for both hate and non-hate classes are
quite high (i.e. at least 0.68 scores), which indicates that the classifiers have efficiently
learnt representative features that are able to detect the hate content correctly from the
data. We take a step further to assess our hate classifiers on real dataset that has been constructed and annotated manually in a native language and dialect; the Levantine L-HSAB dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>, whose content is native Arabic Levant and has been collected from Levant geo-regions. The Spanish-Gulf model has shown a lower capability of detecting hate contents expressed in Levant dialect than its own dialect (i.e. Gulf). The Spanish-Gulf classifier has been able to recall only 54% of hate messages compared to the Spanish-Levantine classifier that has recalled 67% of hate contents at a precision score of 66% while simultaneously keeping a high performance in distinguishing non-hate messages with as high as 80% of f-score of precision and recall. Figure. <a class="ltx_ref" href="#Ax1.F7" title="Figure 7 ‣ Appendix ‣ Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic"><span class="ltx_text ltx_ref_tag">7</span></a> in the appendix, lists example hate-sentences expressed in Arabic-Levantine dialect, which the Spanish-Gulf classifier has classified as non-hate contents, while our Spanish-Levantine classifier has been able to correctly classify as hate contents.
As seen in the examples listed in the table, the same language has got different localized dialects; an expression in a certain dialect might mean something else in another and it might be used in a different context. Ignoring such a feature can negatively impact the learning models so much that they end up generating misleading outputs. For instance, the Levantine idiom "<span class="ltx_ERROR undefined" id="S5.SS3.p1.1.1">\&lt;</span>كول هوا&gt;" -which means "eat dirt"- is a very local expression that Levantine people use in a negative situation (i.e. usually when in anger or disagreeing and it is used for swearing). The same applies to the toxic expressions "<span class="ltx_ERROR undefined" id="S5.SS3.p1.1.2">\&lt;</span>مجرور, صباط, وعساك ما تطيب, هبيلة, ابو شحاطة, ازعر&gt;" - literally translated as "sewage, shoes, wish you stay unwell, dumb, father of thong-sandal, troubling person"- are used exclusively by Levantine people to express anger or dissatisfaction.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This work proposes a framework to localize contents of messages between high and low resource languages/dialects. The proposed framework ensures transferring the context from a source language to target language/dialects. We propose the first of its kind -to the best of our knowledge- an informal parallel translation dataset (SF-ArLG dataset) from/to Spanish and French to/from Arabic Levantine and Gulf dialects; it is an attempt to minimize the dependency of languages in modeling online social behaviors on social media. By using the localized resources of high-resource languages, we have been able to build reliable sentiment and hate speech classifiers for low-resource language/dialects (i.e. Arabic Leavantine and Gulf dialects in this study) without building new Levant and Gulf resources from scratch.
The results of our comprehensive experiments confirm the quality of our proposed dataset and that is shown in the NMT models’ ability to learn the translation of the dialectal Arabic. Moreover, our localized sentiment and hate models are shown to be able to effectively learn sentiment and hate speech from our localized data, and to successfully distinguish between positive and negative classes as well as detecting hate content from data which, in turn, proves the effectiveness of our NMT models that have shown solid capability of transferring the context of informal-social messages from a language to another language/dialects. Also, our finding highlights the importance of distinguishing dialects of the same language and their localized contextual meanings. Overlooking those differences results in inaccurate understanding of the target dialect, which in turn leads to misleading and imprecise analysis of online social behaviors as seen in our Levant hate model being able to detect hate content from Levant messages while the Gulf hate model has struggled to do so. The results and findings of this study have shown the potential of the proposed approach to expand the range of online social behavior analysis in languages/dialects that lack proper data resources for online social behaviors.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
<figure class="ltx_figure" id="Ax1.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="865" id="Ax1.F6.g1" src="x5.png" width="822"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>A sample of generated translations by our proposed NMT models using the transitive translation approach. The translations are from three models: French to/from Arabic-Levantine, Spanish to/from Arabic-Levantine, and Spanish to/from Arabic-Gulf.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="Ax1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="461" id="Ax1.F7.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>A sample of tweets correctly classified as hate speech by our Levant hate classifier and incorrectly classified and non-hate speech by Gulf hate classifier.</figcaption>
</figure>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Mukesh Kumar Saini, Fatimah Al-Zamzami, and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Towards storytelling by extracting social information from osn photo’s metadata.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Proceedings of the First International Workshop on Internet-Scale Multimedia Management</span>, pages 15–20, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami, Mukesh Saini, and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Dst: days spent together using soft sensory information on osns—a case study on facebook.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Soft Computing</span>, 21(15):4227–4238, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Vineet John and Olga Vechtomova.

</span>
<span class="ltx_bibblock">Sentiment analysis on financial news headlines using training dataset augmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:1707.09448</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Hind Saleh Alatawi, Areej Maatog Alhothali, and Kawthar Mustafa Moria.

</span>
<span class="ltx_bibblock">Detecting white supremacist hate speech using domain specific word embedding with deep learning and bert.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">arXiv e-prints</span>, pages arXiv–2010, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Meshrif Alruily and Osama R Shahin.

</span>
<span class="ltx_bibblock">Sentiment analysis of twitter data for saudi universities.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">International Journal of Machine Learning and Computing</span>, 10(1), 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Monitoring cyber sentihate social behavior during covid-19 pandemic in north america.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">IEEE Access</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Hassan Sajjad, Ahmed Abdelali, Nadir Durrani, and Fahim Dalvi.

</span>
<span class="ltx_bibblock">Arabench: Benchmarking dialectal arabic-english machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 28th International Conference on Computational Linguistics</span>, pages 5094–5107, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Hadry.

</span>
<span class="ltx_bibblock">French twitter sentiment analysis.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kaggle.com/hbaflast/french-twitter-sentiment-analysis" title="">https://kaggle.com/hbaflast/french-twitter-sentiment-analysis</a>, 2020.

</span>
<span class="ltx_bibblock">Accessed: (August 15, 2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Ramy Baly, Alaa Khaddaj, Hazem Hajj, Wassim El-Hajj, and Khaled Bashir Shaban.

</span>
<span class="ltx_bibblock">Arsentd-lev: A multi-topic corpus for target-based sentiment analysis in arabic levantine tweets.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1906.01830</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Rana Abaalkhail, Fatimah Alzamzami, Samah Aloufi, Rajwa Alharthi, and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Affectional ontology and multimedia dataset for sentiment analysis.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">International Conference on Smart Multimedia</span>, pages 15–28. Springer, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Hatem Haddad, Hala Mulki, and Asma Oueslati.

</span>
<span class="ltx_bibblock">T-hsab: A tunisian hate speech and abusive dataset.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">International Conference on Arabic Language Processing</span>, pages 251–263. Springer, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Ibrahim Abu Farha and Walid Magdy.

</span>
<span class="ltx_bibblock">From arabic sentiment analysis to sarcasm detection: The arsarcasm dataset.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</span>, pages 32–39, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Muhammad Abdul-Mageed and Mona T Diab.

</span>
<span class="ltx_bibblock">Sana: A large scale multi-genre, multi-dialect lexicon for arabic subjectivity and sentiment analysis.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">LREC</span>, pages 1162–1169, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Hala Mulki and Bilal Ghanem.

</span>
<span class="ltx_bibblock">Let-mi: an arabic levantine twitter dataset for misogynistic language.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2103.10195</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami, Mohamad Hoda, and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Light gradient boosting machine for general sentiment classification on short texts: A comparative evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">IEEE Access</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Surangika Ranathunga, En-Shiun Annie Lee, Marjana Prifti Skenduli, Ravi Shekhar, Mehreen Alam, and Rishemjit Kaur.

</span>
<span class="ltx_bibblock">Neural machine translation for low-resource languages: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">ACM Computing Surveys</span>, 55(11):1–37, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Mohamed El-Madkouri and Beatriz Soto Aranda.

</span>
<span class="ltx_bibblock">Readability and communication in machine translation of arabic phraseologisms into spanish.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">International Conference on Computational and Corpus-Based Phraseology</span>, pages 78–89. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Arwa Alqudsi, Nazlia Omar, and Khalid Shaker.

</span>
<span class="ltx_bibblock">A hybrid rules and statistical method for arabic to english machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">2019 2nd International Conference on Computer Applications &amp; Information Security (ICCAIS)</span>, pages 1–7. IEEE, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Arwa Alqudsi, Nazlia Omar, and Khalid Shaker.

</span>
<span class="ltx_bibblock">Arabic machine translation: a survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Artificial Intelligence Review</span>, 42:549–572, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Jezia Zakraoui, Moutaz Saleh, Somaya Al-Maadeed, and Jihad Mohamad AlJa’am.

</span>
<span class="ltx_bibblock">Evaluation of arabic to english machine translation systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">2020 11th International Conference on Information and Communication Systems (ICICS)</span>, pages 185–190. IEEE, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar Zaidan, and Chris Callison-Burch.

</span>
<span class="ltx_bibblock">Machine translation of arabic dialects.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 2012 conference of the north american chapter of the association for computational linguistics: Human language technologies</span>, pages 49–59, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Houda Bouamor, Nizar Habash, and Kemal Oflazer.

</span>
<span class="ltx_bibblock">A multidialectal parallel corpus of arabic.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">LREC</span>, pages 1240–1245, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Houda Bouamor, Nizar Habash, Mohammad Salameh, Wajdi Zaghouani, Owen Rambow, Dana Abdulrahim, Ossama Obeid, Salam Khalifa, Fadhl Eryani, Alexander Erdmann, et al.

</span>
<span class="ltx_bibblock">The madar arabic dialect corpus and lexicon.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018)</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Mohamed Elmahdy, Mark Hasegawa-Johnson, and Eiman Mustafawi.

</span>
<span class="ltx_bibblock">Development of a tv broadcasts speech recognition system for qatari arabic.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">LREC</span>, volume 14, pages 3057–3061, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Osn-mdad: Machine translation dataset for arabic multi-dialectal conversations on online social media.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2309.12137</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Content-localization based system for analyzing sentiment and hate behaviors in low-resource dialectal arabic: English to levantine and gulf.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2312.03727</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Advances in neural information processing systems</span>, pages 5998–6008, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Multilingual denoising pre-training for neural machine translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">Transactions of the Association for Computational Linguistics</span>, 8:726–742, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, and Angela Fan.

</span>
<span class="ltx_bibblock">Multilingual translation with extensible multilingual pretraining and finetuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2008.00401</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Fatimah Alzamzami and Abdulmotaleb El Saddik.

</span>
<span class="ltx_bibblock">Transformer-based feature fusion approach for multimodal visual sentiment recognition using tweets in the wild.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">IEEE Access</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Alexander Rietzler, Sebastian Stabinger, Paul Opitz, and Stefan Engl.

</span>
<span class="ltx_bibblock">Adapt or get left behind: Domain adaptation through bert language model finetuning for aspect-target sentiment classification.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:1908.11860</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Go Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda Bouamor, and Nizar Habash.

</span>
<span class="ltx_bibblock">The interplay of variant, size, and task type in Arabic pre-trained language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">Proceedings of the Sixth Arabic Natural Language Processing Workshop</span>, Kyiv, Ukraine (Online), April 2021. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Marwan Al Omari.

</span>
<span class="ltx_bibblock">Oclar: logistic regression optimisation for arabic customers’ reviews.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">International Journal of Business Intelligence and Data Mining</span>, 20(3):251–273, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Wajid Hassan Moosa and Najiba.

</span>
<span class="ltx_bibblock">Multi-lingual hatespeech dataset, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Hala Mulki, Hatem Haddad, Chedi Bechikh Ali, and Halima Alshabani.

</span>
<span class="ltx_bibblock">L-hsab: A levantine twitter dataset for hate speech and abusive language.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Proceedings of the third workshop on abusive language online</span>, pages 111–118, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Dec 12 01:34:46 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
