<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.14514] Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation</title><meta property="og:description" content="In this paper, we introduce a data-driven approach for Formality-Sensitive Machine Translation (FSMT) that caters to the unique linguistic properties of four target languages. Our methodology centers on two core strate‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.14514">

<!--Generated on Wed Feb 28 22:09:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Machine Learning,  ICML">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Seugnjun Lee
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hyeonseok Moon
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chanjun Park
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Heuiseok Lim
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">In this paper, we introduce a data-driven approach for Formality-Sensitive Machine Translation (FSMT) that caters to the unique linguistic properties of four target languages. Our methodology centers on two core strategies: 1) language-specific data handling, and 2) synthetic data generation using large-scale language models and empirical prompt engineering. This approach demonstrates a considerable improvement over the baseline, highlighting the effectiveness of data-centric techniques. Our prompt engineering strategy further improves performance by producing superior synthetic translation examples.</p>
</div>
<div class="ltx_keywords">Machine Learning, ICML
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Neural machine translation (NMT) models, despite their impressive progress, often overlook the role of style and pragmatic aspects in translation, such as formality or politeness¬†<cite class="ltx_cite ltx_citemacro_citep">(Britz et¬†al., <a href="#bib.bib2" title="" class="ltx_ref">2017</a>; Stahlberg, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>. This has given rise to the field of formality-sensitive machine translation (FSMT), which aims to control the level of formality in translated text across languages.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, managing formality in MT is a challenging endeavor due to the lack of gold standard translations with different formality levels and the diverse formality markers across languages¬†<cite class="ltx_cite ltx_citemacro_citep">(NƒÉdejde et¬†al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>. For example, in many Indo-European languages, personal pronouns and verb agreement denote formality. Meanwhile, in Korean, formality control is complex due to the common use of morphological markers to express polite, respectful, and humble speech, making it an intriguing test case for FSMT.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose a data-centric approach to FSMT for the English-Korean (EN-KO) and English-Vietnamese (EN-VI) language pairs. Our approach comprises two primary strategies: 1) a language-specific data-driven technique, and 2) synthetic data generation using large-scale language models and prompt engineering.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<div id="S1.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:316.5pt;height:121.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-76.5pt,29.3pt) scale(0.674099581567089,0.674099581567089) ;">
<table id="S1.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S1.T1.1.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S1.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S1.T1.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EN-KO</span></td>
<td id="S1.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S1.T1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EN-VI</span></td>
</tr>
<tr id="S1.T1.1.1.2" class="ltx_tr">
<td id="S1.T1.1.1.2.1" class="ltx_td"></td>
<td id="S1.T1.1.1.2.2" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.2.2.1" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="font-size:90%;">Method</span></td>
<td id="S1.T1.1.1.2.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">BLEU</span></td>
<td id="S1.T1.1.1.2.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">COMET</span></td>
<td id="S1.T1.1.1.2.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%M-Acc</span></td>
<td id="S1.T1.1.1.2.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.6.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%C-F</span></td>
<td id="S1.T1.1.1.2.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.7.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">BLEU</span></td>
<td id="S1.T1.1.1.2.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.8.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">COMET</span></td>
<td id="S1.T1.1.1.2.9" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.9.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%M-Acc</span></td>
<td id="S1.T1.1.1.2.10" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.2.10.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%C-F</span></td>
</tr>
<tr id="S1.T1.1.1.3" class="ltx_tr">
<td id="S1.T1.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S1.T1.1.1.3.1.1" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.1.1.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:27.7pt;vertical-align:-10.7pt;"><span class="ltx_transformed_inner" style="width:27.7pt;transform:translate(-10.7pt,0pt) rotate(-90deg) ;">
<span id="S1.T1.1.1.3.1.1.1.1" class="ltx_p"><span id="S1.T1.1.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Formal</span></span>
</span></span></span></td>
<td id="S1.T1.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.1.1.3.2.1" class="ltx_text" style="font-size:90%;">Official Baseline</span></td>
<td id="S1.T1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.3.1" class="ltx_text" style="font-size:90%;">4.91</span></td>
<td id="S1.T1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.4.1" class="ltx_text" style="font-size:90%;">0.211</span></td>
<td id="S1.T1.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.5.1" class="ltx_text" style="font-size:90%;">78.3</span></td>
<td id="S1.T1.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.6.1" class="ltx_text" style="font-size:90%;">98.6</span></td>
<td id="S1.T1.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.7.1" class="ltx_text" style="font-size:90%;">26.71</span></td>
<td id="S1.T1.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.8.1" class="ltx_text" style="font-size:90%;">0.363</span></td>
<td id="S1.T1.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.9.1" class="ltx_text" style="font-size:90%;">96.0</span></td>
<td id="S1.T1.1.1.3.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S1.T1.1.1.3.10.1" class="ltx_text" style="font-size:90%;">99.7</span></td>
</tr>
<tr id="S1.T1.1.1.4" class="ltx_tr">
<td id="S1.T1.1.1.4.1" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.4.1.1" class="ltx_text" style="font-size:90%;">ChatGPT</span></td>
<td id="S1.T1.1.1.4.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.2.1" class="ltx_text" style="font-size:90%;">5.65</span></td>
<td id="S1.T1.1.1.4.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.3.1" class="ltx_text" style="font-size:90%;">0.524</span></td>
<td id="S1.T1.1.1.4.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.4.1" class="ltx_text" style="font-size:90%;">83.3</span></td>
<td id="S1.T1.1.1.4.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.4.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.6.1" class="ltx_text" style="font-size:90%;">27.07</span></td>
<td id="S1.T1.1.1.4.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.7.1" class="ltx_text" style="font-size:90%;">0.510</span></td>
<td id="S1.T1.1.1.4.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.4.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.4.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.4.9.1" class="ltx_text" style="font-size:90%;">98.0</span></td>
</tr>
<tr id="S1.T1.1.1.5" class="ltx_tr">
<td id="S1.T1.1.1.5.1" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.5.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S1.T1.1.1.5.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">26.60</span></td>
<td id="S1.T1.1.1.5.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.727</span></td>
<td id="S1.T1.1.1.5.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">87.0</span></td>
<td id="S1.T1.1.1.5.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.5.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">47.00</span></td>
<td id="S1.T1.1.1.5.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.669</span></td>
<td id="S1.T1.1.1.5.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.5.8.1" class="ltx_text" style="font-size:90%;">99.4</span></td>
<td id="S1.T1.1.1.5.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.5.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
<tr id="S1.T1.1.1.6" class="ltx_tr">
<td id="S1.T1.1.1.6.1" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.6.1.1" class="ltx_text" style="font-size:90%;">Ours + Augmentation</span></td>
<td id="S1.T1.1.1.6.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.2.1" class="ltx_text" style="font-size:90%;">17.09</span></td>
<td id="S1.T1.1.1.6.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.3.1" class="ltx_text" style="font-size:90%;">0.667</span></td>
<td id="S1.T1.1.1.6.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.4.1" class="ltx_text" style="font-size:90%;">79.4</span></td>
<td id="S1.T1.1.1.6.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.5.1" class="ltx_text" style="font-size:90%;">99.5</span></td>
<td id="S1.T1.1.1.6.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.6.1" class="ltx_text" style="font-size:90%;">41.57</span></td>
<td id="S1.T1.1.1.6.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.7.1" class="ltx_text" style="font-size:90%;">0.653</span></td>
<td id="S1.T1.1.1.6.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.6.8.1" class="ltx_text" style="font-size:90%;">99.4</span></td>
<td id="S1.T1.1.1.6.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.6.9.1" class="ltx_text" style="font-size:90%;">99.7</span></td>
</tr>
<tr id="S1.T1.1.1.7" class="ltx_tr">
<td id="S1.T1.1.1.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="4"><span id="S1.T1.1.1.7.1.1" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.1.1.7.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:33.5pt;vertical-align:-13.6pt;"><span class="ltx_transformed_inner" style="width:33.5pt;transform:translate(-13.64pt,0pt) rotate(-90deg) ;">
<span id="S1.T1.1.1.7.1.1.1.1" class="ltx_p"><span id="S1.T1.1.1.7.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Informal</span></span>
</span></span></span></td>
<td id="S1.T1.1.1.7.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.1.1.7.2.1" class="ltx_text" style="font-size:90%;">Official Baseline</span></td>
<td id="S1.T1.1.1.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.3.1" class="ltx_text" style="font-size:90%;">4.85</span></td>
<td id="S1.T1.1.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.4.1" class="ltx_text" style="font-size:90%;">0.170</span></td>
<td id="S1.T1.1.1.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.5.1" class="ltx_text" style="font-size:90%;">97.6</span></td>
<td id="S1.T1.1.1.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.6.1" class="ltx_text" style="font-size:90%;">99.5</span></td>
<td id="S1.T1.1.1.7.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.7.1" class="ltx_text" style="font-size:90%;">25.28</span></td>
<td id="S1.T1.1.1.7.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.8.1" class="ltx_text" style="font-size:90%;">0.345</span></td>
<td id="S1.T1.1.1.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.9.1" class="ltx_text" style="font-size:90%;">96.0</span></td>
<td id="S1.T1.1.1.7.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S1.T1.1.1.7.10.1" class="ltx_text" style="font-size:90%;">98.2</span></td>
</tr>
<tr id="S1.T1.1.1.8" class="ltx_tr">
<td id="S1.T1.1.1.8.1" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.8.1.1" class="ltx_text" style="font-size:90%;">ChatGPT</span></td>
<td id="S1.T1.1.1.8.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.2.1" class="ltx_text" style="font-size:90%;">5.60</span></td>
<td id="S1.T1.1.1.8.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.3.1" class="ltx_text" style="font-size:90%;">0.564</span></td>
<td id="S1.T1.1.1.8.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.8.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.8.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.6.1" class="ltx_text" style="font-size:90%;">25.83</span></td>
<td id="S1.T1.1.1.8.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.7.1" class="ltx_text" style="font-size:90%;">0.482</span></td>
<td id="S1.T1.1.1.8.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.8.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T1.1.1.8.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.8.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
<tr id="S1.T1.1.1.9" class="ltx_tr">
<td id="S1.T1.1.1.9.1" class="ltx_td ltx_align_left"><span id="S1.T1.1.1.9.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S1.T1.1.1.9.2" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">27.10</span></td>
<td id="S1.T1.1.1.9.3" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.715</span></td>
<td id="S1.T1.1.1.9.4" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.4.1" class="ltx_text" style="font-size:90%;">98.0</span></td>
<td id="S1.T1.1.1.9.5" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.5.1" class="ltx_text" style="font-size:90%;">95.0</span></td>
<td id="S1.T1.1.1.9.6" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">45.60</span></td>
<td id="S1.T1.1.1.9.7" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.637</span></td>
<td id="S1.T1.1.1.9.8" class="ltx_td ltx_align_center"><span id="S1.T1.1.1.9.8.1" class="ltx_text" style="font-size:90%;">98.8</span></td>
<td id="S1.T1.1.1.9.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.1.1.9.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
<tr id="S1.T1.1.1.10" class="ltx_tr">
<td id="S1.T1.1.1.10.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S1.T1.1.1.10.1.1" class="ltx_text" style="font-size:90%;">Ours + Augmentation</span></td>
<td id="S1.T1.1.1.10.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.2.1" class="ltx_text" style="font-size:90%;">20.35</span></td>
<td id="S1.T1.1.1.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.3.1" class="ltx_text" style="font-size:90%;">0.621</span></td>
<td id="S1.T1.1.1.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.4.1" class="ltx_text" style="font-size:90%;">98.5</span></td>
<td id="S1.T1.1.1.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.5.1" class="ltx_text" style="font-size:90%;">98.8</span></td>
<td id="S1.T1.1.1.10.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.6.1" class="ltx_text" style="font-size:90%;">40.46</span></td>
<td id="S1.T1.1.1.10.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.7.1" class="ltx_text" style="font-size:90%;">0.484</span></td>
<td id="S1.T1.1.1.10.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.8.1" class="ltx_text" style="font-size:90%;">98.7</span></td>
<td id="S1.T1.1.1.10.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S1.T1.1.1.10.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results on the test set of Formality Dataset for formal and informal supervised settings.</figcaption>
</figure>
<figure id="S1.T2" class="ltx_table">
<div id="S1.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:316.5pt;height:102.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-64.4pt,20.8pt) scale(0.710647892650612,0.710647892650612) ;">
<table id="S1.T2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T2.1.1.1" class="ltx_tr">
<td id="S1.T2.1.1.1.1" class="ltx_td ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S1.T2.1.1.1.2" class="ltx_td ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S1.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;" colspan="4"><span id="S1.T2.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EN-PT</span></td>
<td id="S1.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.9pt;padding-bottom:0.9pt;" colspan="4"><span id="S1.T2.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EN-RU</span></td>
</tr>
<tr id="S1.T2.1.1.2" class="ltx_tr">
<td id="S1.T2.1.1.2.1" class="ltx_td" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td id="S1.T2.1.1.2.2" class="ltx_td ltx_align_left" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.2.1" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="font-size:90%;">Method</span></td>
<td id="S1.T2.1.1.2.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.3.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">BLEU</span></td>
<td id="S1.T2.1.1.2.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.4.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">COMET</span></td>
<td id="S1.T2.1.1.2.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.5.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%M-Acc</span></td>
<td id="S1.T2.1.1.2.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.6.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%C-F</span></td>
<td id="S1.T2.1.1.2.7" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.7.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">BLEU</span></td>
<td id="S1.T2.1.1.2.8" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.8.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">COMET</span></td>
<td id="S1.T2.1.1.2.9" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.9.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%M-Acc</span></td>
<td id="S1.T2.1.1.2.10" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.2.10.1" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">%C-F</span></td>
</tr>
<tr id="S1.T2.1.1.3" class="ltx_tr">
<td id="S1.T2.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;" rowspan="3"><span id="S1.T2.1.1.3.1.1" class="ltx_text" style="font-size:90%;">
<span id="S1.T2.1.1.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:27.7pt;vertical-align:-10.7pt;"><span class="ltx_transformed_inner" style="width:27.7pt;transform:translate(-10.7pt,0pt) rotate(-90deg) ;">
<span id="S1.T2.1.1.3.1.1.1.1" class="ltx_p"><span id="S1.T2.1.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Formal</span></span>
</span></span></span></td>
<td id="S1.T2.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.2.1" class="ltx_text" style="font-size:90%;">Official Baseline</span></td>
<td id="S1.T2.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.3.1" class="ltx_text" style="font-size:90%;">27.29</span></td>
<td id="S1.T2.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.4.1" class="ltx_text" style="font-size:90%;">0.448</span></td>
<td id="S1.T2.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.5.1" class="ltx_text" style="font-size:90%;">96.3</span></td>
<td id="S1.T2.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.6.1" class="ltx_text" style="font-size:90%;">97.7</span></td>
<td id="S1.T2.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.7.1" class="ltx_text" style="font-size:90%;">21.96</span></td>
<td id="S1.T2.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.8.1" class="ltx_text" style="font-size:90%;">0.349</span></td>
<td id="S1.T2.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.9.1" class="ltx_text" style="font-size:90%;">96.2</span></td>
<td id="S1.T2.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.3.10.1" class="ltx_text" style="font-size:90%;">92.0</span></td>
</tr>
<tr id="S1.T2.1.1.4" class="ltx_tr">
<td id="S1.T2.1.1.4.1" class="ltx_td ltx_align_left" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.1.1" class="ltx_text" style="font-size:90%;">ChatGPT</span></td>
<td id="S1.T2.1.1.4.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">31.25</span></td>
<td id="S1.T2.1.1.4.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.655</span></td>
<td id="S1.T2.1.1.4.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.4.1" class="ltx_text" style="font-size:90%;">92.0</span></td>
<td id="S1.T2.1.1.4.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.5.1" class="ltx_text" style="font-size:90%;">96.0</span></td>
<td id="S1.T2.1.1.4.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">31.25</span></td>
<td id="S1.T2.1.1.4.7" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.7.1" class="ltx_text" style="font-size:90%;">0.655</span></td>
<td id="S1.T2.1.1.4.8" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.8.1" class="ltx_text" style="font-size:90%;">92.0</span></td>
<td id="S1.T2.1.1.4.9" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.4.9.1" class="ltx_text" style="font-size:90%;">96.0</span></td>
</tr>
<tr id="S1.T2.1.1.5" class="ltx_tr">
<td id="S1.T2.1.1.5.1" class="ltx_td ltx_align_left" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S1.T2.1.1.5.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.2.1" class="ltx_text" style="font-size:90%;">31.00</span></td>
<td id="S1.T2.1.1.5.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.3.1" class="ltx_text" style="font-size:90%;">0.525</span></td>
<td id="S1.T2.1.1.5.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T2.1.1.5.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T2.1.1.5.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.6.1" class="ltx_text" style="font-size:90%;">25.80</span></td>
<td id="S1.T2.1.1.5.7" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.7.1" class="ltx_text" style="font-size:90%;">0.445</span></td>
<td id="S1.T2.1.1.5.8" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T2.1.1.5.9" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.5.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
<tr id="S1.T2.1.1.6" class="ltx_tr">
<td id="S1.T2.1.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;" rowspan="3"><span id="S1.T2.1.1.6.1.1" class="ltx_text" style="font-size:90%;">
<span id="S1.T2.1.1.6.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.3pt;height:33.5pt;vertical-align:-13.6pt;"><span class="ltx_transformed_inner" style="width:33.5pt;transform:translate(-13.64pt,0pt) rotate(-90deg) ;">
<span id="S1.T2.1.1.6.1.1.1.1" class="ltx_p"><span id="S1.T2.1.1.6.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Informal</span></span>
</span></span></span></td>
<td id="S1.T2.1.1.6.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.2.1" class="ltx_text" style="font-size:90%;">Official Baseline</span></td>
<td id="S1.T2.1.1.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">30.93</span></td>
<td id="S1.T2.1.1.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.4.1" class="ltx_text" style="font-size:90%;">0.416</span></td>
<td id="S1.T2.1.1.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">93.2</span></td>
<td id="S1.T2.1.1.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">90.8</span></td>
<td id="S1.T2.1.1.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.7.1" class="ltx_text" style="font-size:90%;">21.63</span></td>
<td id="S1.T2.1.1.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.8.1" class="ltx_text" style="font-size:90%;">0.348</span></td>
<td id="S1.T2.1.1.6.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.9.1" class="ltx_text" style="font-size:90%;">84.1</span></td>
<td id="S1.T2.1.1.6.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.6.10.1" class="ltx_text" style="font-size:90%;">85.2</span></td>
</tr>
<tr id="S1.T2.1.1.7" class="ltx_tr">
<td id="S1.T2.1.1.7.1" class="ltx_td ltx_align_left" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.1.1" class="ltx_text" style="font-size:90%;">ChatGPT</span></td>
<td id="S1.T2.1.1.7.2" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.2.1" class="ltx_text" style="font-size:90%;">27.38</span></td>
<td id="S1.T2.1.1.7.3" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.512</span></td>
<td id="S1.T2.1.1.7.4" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.4.1" class="ltx_text" style="font-size:90%;">48.4</span></td>
<td id="S1.T2.1.1.7.5" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.5.1" class="ltx_text" style="font-size:90%;">46.0</span></td>
<td id="S1.T2.1.1.7.6" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">31.25</span></td>
<td id="S1.T2.1.1.7.7" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.655</span></td>
<td id="S1.T2.1.1.7.8" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.8.1" class="ltx_text" style="font-size:90%;">92.0</span></td>
<td id="S1.T2.1.1.7.9" class="ltx_td ltx_align_center" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.7.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
<tr id="S1.T2.1.1.8" class="ltx_tr">
<td id="S1.T2.1.1.8.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S1.T2.1.1.8.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.2.1" class="ltx_text" style="font-size:90%;">19.90</span></td>
<td id="S1.T2.1.1.8.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.3.1" class="ltx_text" style="font-size:90%;">0.249</span></td>
<td id="S1.T2.1.1.8.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.4.1" class="ltx_text" style="font-size:90%;">68.0</span></td>
<td id="S1.T2.1.1.8.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.5.1" class="ltx_text" style="font-size:90%;">90.0</span></td>
<td id="S1.T2.1.1.8.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.6.1" class="ltx_text" style="font-size:90%;">26.30</span></td>
<td id="S1.T2.1.1.8.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.7.1" class="ltx_text" style="font-size:90%;">0.418</span></td>
<td id="S1.T2.1.1.8.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
<td id="S1.T2.1.1.8.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span id="S1.T2.1.1.8.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">100.0</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results on the test set of Formality Dataset for formal and informal zero-shot settings.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Proposed Method</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Language Specialized Data-Centric Approach</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We employ a language-specialized, data-centric approach that merges transfer learning techniques¬†<cite class="ltx_cite ltx_citemacro_citep">(Zoph et¬†al., <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite> with language-specific subword methods, resulting in improved translation performance¬†<cite class="ltx_cite ltx_citemacro_citep">(Zoph et¬†al., <a href="#bib.bib15" title="" class="ltx_ref">2016</a>; Bojanowski et¬†al., <a href="#bib.bib1" title="" class="ltx_ref">2017</a>; Park et¬†al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>, <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>. The pre-trained model (PLM) is fine-tuned on the supervised train set for each language pair.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">For both EN-KO and EN-VI translations, we adopt a data-centric approach emphasizing pre-training and fine-tuning on high-quality, language-specific datasets. For EN-KO, we use a Transformer model and a morpheme-aware subword tokenization method¬†<cite class="ltx_cite ltx_citemacro_citep">(Park et¬†al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>, enhancing performance by addressing linguistic peculiarities of Korean. Similarly, for EN-VI, we utilize the specialized EnViT5¬†<cite class="ltx_cite ltx_citemacro_citep">(Ngo et¬†al., <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite> model, with training conducted on the expanded CC100¬†<cite class="ltx_cite ltx_citemacro_citep">(Wenzek et¬†al., <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>, MTet¬†<cite class="ltx_cite ltx_citemacro_citep">(Ngo et¬†al., <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>, and PhoMT¬†<cite class="ltx_cite ltx_citemacro_citep">(Doan et¬†al., <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> datasets, improving translation in low-resource settings and underrepresented domains.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic Data Generation and Data-Centric Approach</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To enhance translation quality, especially in low-resource settings, we utilize a data-centric approach by generating synthetic examples using ChatGPT with the GPT-4 engine¬†<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>. Our synthetic data are created through a conditioned translation generation task and refined using a formality classifier¬†<cite class="ltx_cite ltx_citemacro_citep">(Rippeth et¬†al., <a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite>, thus ensuring accurate formality control.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Supervised Setting</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">We leverage a prompt-based method, incorporating <math id="S2.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">ùëõ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">n</annotation></semantics></math> randomly selected shots from the English training set of various language pairs for context. These prompts guide ChatGPT to produce translations in either informal or formal target language. The translated examples are filtered using a formality classifier, and those meeting the formality criteria are integrated into the training sets for EN-KO and EN-VI fine-tuning. This data augmentation strategy and its impact are further evaluated through comparative experiments.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Zero-shot Setting</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">In the zero-shot scenarios (EN-PT and EN-RU), we generate synthetic examples using the <cite class="ltx_cite ltx_citemacro_citet">Gopalakrishnan et¬†al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>. As in the supervised setting, prompts guide the model to produce translations in either formal or informal target language. The examples are filtered for accurate formality before being used to fine-tune the pre-trained multilingual translation model. This approach maximizes the model‚Äôs generalization ability across languages and formality levels, demonstrating the utility of synthetic data in expanding pre-trained language models‚Äô capabilities.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Settings</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We conducted experiments using the Formality dataset¬†<cite class="ltx_cite ltx_citemacro_citep">(NƒÉdejde et¬†al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> for the language pairs EN-{KO, VI} in the supervised setting and EN-{PT, RU} in the zero-shot setting. Prompt engineering was applied for EN-{KO, VI}, and synthetic examples were generated for fine-tuning on EN-{PT, RU}. Training details varied for each language pair, with EN-KO utilizing morpheme-aware tokenization and pre-training with a Transformer model. EN-{VI, PT, RU} pairs were fine-tuned using mBART-50¬†<cite class="ltx_cite ltx_citemacro_citep">(Liu et¬†al., <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> model.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Experimental Results</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our data-centric approach yielded promising results, as evidenced in Table¬†<a href="#S1.T1" title="Table 1 ‚Ä£ 1 Introduction ‚Ä£ Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table¬†<a href="#S1.T2" title="Table 2 ‚Ä£ 1 Introduction ‚Ä£ Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for supervised and zero-shot settings, respectively. Our model, trained on the Formality Dataset, demonstrated near-perfect formality control, with high translation accuracy for most tasks, especially in the EN-KO and EN-VI language pairs. However, data augmentation with ChatGPT sometimes led to subpar performance, hinting at the requirement for more elaborate prompts considering formality control. Notably, the zero-shot EN-PT task results were significantly low, suggesting a need for specialized techniques for formality control per language pair and revealing a potential training data bias in ChatGPT.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We propose a data-centric approach for FSMT, incorporating language-specific techniques and synthetic data generation. Our approach achieves superior performance in EN-KO and EN-VI translations, delivering high-quality formality translations. While EN-PT informal exhibits lower performance, other pairs surpass the baseline, showcasing the translation capabilities of ChatGPT. For future work, we suggest exploring larger translation models, analyzing shot examples in more depth, employing linguistic-based data augmentation, and further investigating zero-shot transfer to enhance FSMT performance.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by Institute for Information &amp; communications Technology Planning &amp; Evaluation(IITP) grant funded by the Korea government(MSIT) (No. 2022-0-00369, (Part 4) Development of AI Technology to support Expert Decision-making that can Explain the Reasons/Grounds for Judgment Results based on Expert Knowledge) and supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT)(No. 2022R1A5A7026673). The authors would like to acknowledge that this paper is an abstract version of the paper titled ‚ÄùImproving Formality-Sensitive Machine Translation using Data-Centric Approaches and Prompt Engineering,‚Äù which was submitted to the Formality Control for Spoken Language Translation Shared Task at the International Workshop on Spoken Language Translation (IWSLT) 2023.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojanowski et¬†al. (2017)</span>
<span class="ltx_bibblock">
Bojanowski, P., Grave, E., Joulin, A., and Mikolov, T.

</span>
<span class="ltx_bibblock">Enriching word vectors with subword information.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Transactions of the association for computational linguistics</em>,
5:135‚Äì146, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Britz et¬†al. (2017)</span>
<span class="ltx_bibblock">
Britz, D., Goldie, A., Luong, M.-T., and Le, Q.

</span>
<span class="ltx_bibblock">Massive exploration of neural machine translation architectures.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1703.03906</em>, 2017.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doan et¬†al. (2021)</span>
<span class="ltx_bibblock">
Doan, L., Nguyen, L.¬†T., Tran, N.¬†L., Hoang, T., and Nguyen, D.¬†Q.

</span>
<span class="ltx_bibblock">PhoMT: A high-quality and large-scale benchmark dataset for
Vietnamese-English machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pp.¬† 4495‚Äì4503, Online and Punta Cana,
Dominican Republic, November 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2021.emnlp-main.369</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2021.emnlp-main.369" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2021.emnlp-main.369</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gopalakrishnan et¬†al. (2019)</span>
<span class="ltx_bibblock">
Gopalakrishnan, K., Hedayatnia, B., Chen, Q., Gottardi, A., Kwatra, S.,
Venkatesh, A., Gabriel, R., and Hakkani-T√ºr, D.

</span>
<span class="ltx_bibblock">Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pp.¬† 1891‚Äì1895, 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2019-3079</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.21437/Interspeech.2019-3079" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.21437/Interspeech.2019-3079</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Langley (2000)</span>
<span class="ltx_bibblock">
Langley, P.

</span>
<span class="ltx_bibblock">Crafting papers on machine learning.

</span>
<span class="ltx_bibblock">In Langley, P. (ed.), <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th International
Conference on Machine Learning (ICML 2000)</em>, pp.¬† 1207‚Äì1216, Stanford, CA,
2000. Morgan Kaufmann.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et¬†al. (2020)</span>
<span class="ltx_bibblock">
Liu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M.,
and Zettlemoyer, L.

</span>
<span class="ltx_bibblock">Multilingual denoising pre-training for neural machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
8:726‚Äì742, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NƒÉdejde et¬†al. (2022)</span>
<span class="ltx_bibblock">
NƒÉdejde, M., Currey, A., Hsu, B., Niu, X., Federico, M., and Dinu, G.

</span>
<span class="ltx_bibblock">Cocoa-mt: A dataset and benchmark for contrastive controlled mt with
application to formality.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.04022</em>, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ngo et¬†al. (2022)</span>
<span class="ltx_bibblock">
Ngo, C., Trinh, T.¬†H., Phan, L., Tran, H., Dang, T., Nguyen, H., Nguyen, M.,
and Luong, M.-T.

</span>
<span class="ltx_bibblock">Mtet: Multi-domain translation for english and vietnamese.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.05610</em>, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et¬†al. (2021)</span>
<span class="ltx_bibblock">
Park, C., Eo, S., Moon, H., and Lim, H.-S.

</span>
<span class="ltx_bibblock">Should we find another model?: Improving neural machine translation
performance with one-piece tokenization method without model modification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies: Industry Papers</em>, pp.¬† 97‚Äì104, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et¬†al. (2020)</span>
<span class="ltx_bibblock">
Park, K., Lee, J., Jang, S., and Jung, D.

</span>
<span class="ltx_bibblock">An empirical study of tokenization strategies for various korean nlp
tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.02534</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rippeth et¬†al. (2022)</span>
<span class="ltx_bibblock">
Rippeth, E., Agrawal, S., and Carpuat, M.

</span>
<span class="ltx_bibblock">Controlling translation formality using pre-trained multilingual
language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.06644</em>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stahlberg (2020)</span>
<span class="ltx_bibblock">
Stahlberg, F.

</span>
<span class="ltx_bibblock">Neural machine translation: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of Artificial Intelligence Research</em>, 69:343‚Äì418, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenzek et¬†al. (2020)</span>
<span class="ltx_bibblock">
Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzm√°n, F., Joulin,
A., and Grave, E.

</span>
<span class="ltx_bibblock">CCNet: Extracting high quality monolingual datasets from web crawl
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation
Conference</em>, pp.¬† 4003‚Äì4012, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2020.lrec-1.494" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.lrec-1.494</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph et¬†al. (2016)</span>
<span class="ltx_bibblock">
Zoph, B., Yuret, D., May, J., and Knight, K.

</span>
<span class="ltx_bibblock">Transfer learning for low-resource neural machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1604.02201</em>, 2016.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.14513" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.14514" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.14514">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.14514" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.14515" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 22:09:08 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
