<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1911.05642] Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism</title><meta property="og:description" content="Recent years have witnessed a rapid proliferation of smart Internet of Things (IoT) devices. IoT devices with intelligence require the use of effective machine learning paradigms. Federated learning can be a promising …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1911.05642">

<!--Generated on Fri Mar  8 09:25:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  Internet of Things,  Stackelberg game,  edge networks.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\justify</span>
</div>
<h1 class="ltx_title ltx_title_document">Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Latif U. Khan<sup id="id3.3.id1" class="ltx_sup">†</sup>, Shashi Raj Pandey<sup id="id4.4.id2" class="ltx_sup">†</sup>, Nguyen H. Tran, Walid Saad, , Zhu Han, , Minh N. H. Nguyen, and Choong Seon Hong
</span><span class="ltx_author_notes">
L. U. Khan, S. R. Pandey, M. N. H. Nguyen and C. S. Hong are with the Department of Computer Science &amp; Engineering, Kyung Hee University, Yongin-si 17104, South Korea.
N. H. Tran is with School of Computer Science, The University of Sydney, Sydney, NSW 2006, Australia.
Walid Saad is with the Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA 24061 USA.
Zhu Han is with the Electrical and Computer Engineering Department, University of Houston, Houston, TX 77004 USA, and also with the Computer Science Department, University of Houston, Houston, TX 77004 USA, and the Department of Computer Science and Engineering, Kyung Hee University, South Korea.
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">Recent years have witnessed a rapid proliferation of smart Internet of Things (IoT) devices. IoT devices with intelligence require the use of effective machine learning paradigms. Federated learning can be a promising solution for enabling IoT-based smart applications. In this paper, we present the primary design aspects for enabling federated learning at network edge. We model the incentive-based interaction between a global server and participating devices for federated learning via a Stackelberg game to motivate the participation of the devices in the federated learning process. We present several open research challenges with their possible solutions. Finally, we provide an outlook on future research.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, Internet of Things, Stackelberg game, edge networks.

</div>
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup id="footnote1.1" class="ltx_sup">†</sup> These authors contributed equally.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Emerging Internet of Things (IoT) applications such as augmented reality, autonomous driving, surveillance, and industry 4.0 generate significant amount of data. The effective deployment of such applications is thus reliant on the use of advanced machine learning techniques so as to properly exploit the generated data. However, traditional machine learning schemes use centralized training data at a data center which requires data transfer from a massive number of distributed IoT devices to a third-party location which raises serious privacy concerns and can be inefficient in its use of communication resources. To overcome these privacy and communication concerns, it is important to introduce distributed, edge-deployed learning algorithms such as <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">federated learning</em> (<em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">FL</em>). FL allows privacy preservation by enabling distributed training without raw data transfer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">An overview of how FL can enable IoT-based applications is presented in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. To benefit from FL at the network edge, several challenges must be addressed that include resource management and incentive mechanism design to motivate the participation of users in the learning of a global FL model. Learning in the IoT has been studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> rely on centralized learning solutions that have limited scalability and privacy-preservation. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, the authors presented the challenges of FL along with its existing solutions and applications in mobile edge network optimization. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, the authors proposed an FL framework to provide efficient resource management at the network edge. However, the works in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> do not discuss the important challenges pertaining to incentive design and network optimization under edge-based FL. In contrast, the overarching goal of this article is to comprehensively review resource optimization and incentive mechanism for FL. In contrast to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> which focuses only at high-level challenges, we present a new perspective related to the development of incentive-based FL over edge networks using game theory. We also identify new challenges and open problems, different from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Our key contributions include:</p>
</div>
<div id="S1.p3" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present the key design aspects for implementing FL in edge networks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present a Stackelberg game-based approach to develop an FL incentive mechanism. In this game, FL users can strategically set the number of local iterations to maximize their utility. Meanwhile, the base station (BS), acting as leader, uses the best response strategies of the users to maximize the FL performance. The BS’s utility is modeled as a function of key performance metrics such as the number of global iterations and global accuracy level in the FL setting.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Finally, we present some key open research challenges along with guidelines pertaining to FL in edge networks.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1911.05642/assets/Federated_Learning_enabled_Smart_City.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="510" height="510" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">An overview of FL in enabling IoT-based smart applications</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning at the Edge: Key Design Aspects</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Resource Optimization</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Optimization of communication and computation resources is necessary to enable the main phases of FL local computation, communication, and global computation. When optimizing FL computational and communication resources, the original problem whose goal is to minimize the federated learning cost function can have a dual formulation without constraints. Moreover, if the original problem is convex, then dual problem has the same solution. Thus, the dual problem can be decoupled for obtaining a distributed solution in FL. Computation resources can be either those of a local device or of an edge server, whereas communication resources are mainly radio resources of the access network. In the local computation phase, every selected device iteratively performs a local model update using its dataset. The allocation of local device computational resources strongly depends on the device energy consumption, local learning time, and local learning accuracy. Further, the heterogeneity of the local dataset sizes significantly affects the allocation of local computational resources. Device energy consumption and local learning time are strongly dependent on the CPU capability. Increasing the device CPU frequency can increase the energy consumption and decrease the learning time. Similarly, the local computing latency increases for a fixed frequency with an increase in local learning accuracy. Evidently, there is a need to study the tradeoff between computation energy consumption, computational latency, learning time, and learning accuracy. Moreover, the access network and core network resources must be allocated optimally during the communication phase.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/1911.05642/assets/x1.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="454" height="242" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Federated learning sequence diagram</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Learning Algorithm Design</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">FL uses local and global computation resources along with communication resources. Several machine learning techniques, such as long short-term memory, convolutional neural network, and Naive Bayes schemes can be used at each local device. To enable FL, numerous optimization schemes, such as federated averaging (FedAvg) and FedProx can be used to train non-convex FL models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. FedProx is a modified version of FedAvg that captures both statistical and system heterogeneity among end-devices. FedAvg runs stochastic gradient descent (SGD) on a set of devices to yield local model weights. Subsequently, an averaging of the local weights is performed at the edge computing server located at BS. FedProx has similar steps as FedAvg, but the difference lies in local device minimizing of objective function that considers the objective function of FedAvg with an additional proximal term. By doing so, FedProx limits the impact of non-independent and identically distributed (non-IID) device data on the global learning model. FedAvg does not guarantee theoretical convergence, while FedProx shows theoretical convergence.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">In FedAvg and FedProx, all devices are weighted equally in global FL model computation without considering fairness, despite the differences in the device capabilities (e.g., hardware). To capture such fairness among devices, a so-called fairness enabled FedAvg algorithm was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Fairness enabled FedAvg assigns higher weights to devices with poor performance by modifying the objective function of the typical FedAvg algorithm. To introduce potential fairness and reduce training accuracy variance, local devices having a high empirical loss (local loss function) are emphasized by assigning higher relative weight in the fairness enabled FedAvg. Meanwhile, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> an adaptive control scheme was proposed to adapt the global FL aggregation frequency. This adaptive control scheme offers a desirable tradeoff between global model aggregation and local model update to minimize the loss function with resource budget constraint. All of the above-discussed methods are used for a single task global FL model. In real-world IoT systems, it is also of interest to use multi-task FL for handling multiple tasks, whose data is distributed among multiple edge nodes. A federated multi-task learning scheme was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> by modifying the so-called communication-efficient distributed dual coordinate ascent (CoCoA) framework. To enable a wide variety of machine learning models, CoCoA supports objectives for linear reguarlized loss minimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. In CoCoA, partial results from local computation are effectively combined using optimization problems primal-dual structure. In each round, CoCoA enables the use of any arbitrary optimization algorithm on a local dataset to solve a local learning problem by using distributed optimization for coping with system-level and statistical heterogeneity.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Hardware-Software Co-Design for Federated Learning</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">For a fixed hardware design, one can find optimal software design by searching for different architectures. However, this approach poses limitations on the design because neural network design is strongly dependent on the used dataset. Therefore, there is a need to jointly consider both hardware design space and neural architecture search space for a more flexible design of the end-device for FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. One promising approach for efficient design of end-devices involved in FL is hardware-software co-design. Several approaches such as high-level synthesis, co-verification-based embedded systems, and virtual prototyping can be used for hardware-software co-design of IoT devices. A design based on the virtual prototyping uses computer-aided engineering, computer-automated design, and computer-aided design for the validation of a design before prototype implementation, whereas a high-level synthesis offers an automated design process by creating digital hardware based on the algorithmic description for the desired behavior. The prominent challenges of high-level synthesis-based design are wired signal and multiplexer delays. Moreover, co-verification-based embedded systems enable concurrent testing and debugging of both software and hardware design, however, such designs require successful interactions between hardware and software teams.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.4.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.5.2" class="ltx_text ltx_font_italic">Incentive Mechanism Design</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">The design of mechanisms that incentivize users to participate in FL is a key challenge. Incentives are possible in different forms, such as user-defined utility and money-based rewards. Several frameworks such as game theory and auction theory can be used in the design of FL incentives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. One can design an incentive mechanism using game theory while considering both communication and computation costs. The communication cost can be defined as the total number of rounds used for the interactions between the edge server and end-devices, whereas the computational cost can be the number of local iterations required to compute the local learning model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. For synchronous aggregation, given a fixed number of global FL rounds between end-devices and edge server, the convergence rate of the global FL model has a proportional relationship with the number of local iterations. An increase in the number of local iterations minimizes the local learning model error and thus, few global FL rounds are required to reach a certain global FL model accuracy. Therefore, for a fixed global FL model accuracy, an increase in computational cost reduces communication cost and vice versa. For instance, consider a incentive mechanism game whose players are the edge server and edge users. The edge server announces a reward as an incentive to the participating users while maximizing its benefits in terms of improving global FL model accuracy. Meanwhile, the edge users maximize their individual utilities to improve their benefit. One example of a user utility could be the improvement of local learning model accuracy within the allowed communication time during FL training. An improvement in the local learning model accuracy of the end-user increases its incentive from the edge server and vice versa. This process of incentive-based sharing of model parameters continues until convergence to some global model accuracy level.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Incentive Based Federated Learning Over Edge Networks</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">System Model</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Consider a multi-user system comprised of a BS and a set of user devices with non-IID and heterogeneous data sizes. Enabling FL over such edge networks involves the use of the computational resources at both device and cloud levels, as well as network communication resources. In a typical FL environment, participating user equipment (UE) must iterate over their local (possibly non-IID) data to train a global model. However, UEs are generally reluctant to participate in FL due to limited computing and communication resources. Thus, enabling FL requires some careful design considerations:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">First, to motivate UEs for participation, it is necessary to model the economic interaction between the BS and the UEs. Within each global iteration, the BS can offer a reward rate (e.g., $/iterations) to the UEs for selecting the optimal local iteration strategy (i.e., CPU-frequency cycle) that can minimize the overall energy consumption of FL, with a minimal learning time.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">The set of resource-constrained UEs involved in FL has numerous heterogeneous parameters: Computational capacity, training data size, and channel conditions. This heterogeneity significantly affects the local learning model computation time for a certain fixed local model accuracy level. For a synchronous FL setting, the local learning model accuracy will be different for different UEs due to both data and system heterogeneity. Therefore, it is necessary to tackle the challenge of heterogeneous local learning model accuracy for the UEs in synchronous FL.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">One approach for handling the communication-computation tradeoff in FL is via an appropriate client selection strategy. Selecting the IoT devices with sufficient computing power and training data, jointly improves FL model accuracy and training costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In our previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, we jointly optimized the computing time and energy consumption of FL over wireless networks. The problem studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> captures two tradeoffs: (a) UE energy consumption and FL time via variations in device CPU-cycles/sec and (b) computational and communication latencies for FL accuracy. However, here, we use a Stackelberg game-based incentive mechanism to select a set of IoT devices willing to join the model training process. Then, the selected set will collaboratively train a global model while minimizing the overall training costs, i.e., computation and communication cost.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Stackelberg Game Solution</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The BS employs an incentive mechanism for motivating the set of UEs to participate in global FL model training. However, heterogeneous UEs have different computational and communication costs for training and, thus, they expect different rewards. Moreover, the BS seeks to minimize the learning time while maximizing the accuracy level of the learning model. This complex interaction between the BS and the UEs can be cast as a Stackelberg game with one leader (BS) and multiple followers (UEs). For the offered reward, the BS maximizes its utility modeled as a function of key FL performance metrics such as the number of communication rounds needed to reach a desirable global FL model accuracy level. Correspondingly, the UEs will respond to the BS-offered reward and choose their local iteration strategy (i.e., select a CPU-frequency cycle for local computation) to maximize their own benefits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Evaluating the responses from the UEs, the BS will adjust its reward rate, and the process repeats until a desired accuracy level is obtained. To this end, the BS must design an incentive mechanism to influence available UEs for training the global model. In this framework, the sequence of interactions between the BS and the UEs to reach a Stackelberg equilibrium is as follows:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">Initially, each UE submits its best response (i.e., optimal CPU-frequency) to the BS for the offered reward rate, to maximize its local utility. Specifically, each UE considers the viability of the offered reward rate for their incurred computational and communication costs in FL.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Next, the BS evaluates these responses, updates the global model, and broadcasts its offered reward rate to the UEs to maximize its own utility function. The utility of the BS is modeled as strictly concave function of key FL performance metrics such as the number of global iterations required to reach global accuracy for a given local relative accuracy.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">Given the optimal offered reward, the UEs will correspondingly tune their strategy and update response that solves their individual utility maximization problem. This iterative process continues in each round of interaction between the BS and UEs.</p>
</div>
</li>
</ul>
<p id="S3.SS2.p1.2" class="ltx_p">In summary, we follow the best response algorithm to achieve the Stackelberg equilibrium. For this, with the first-order condition, we first find a unique Nash equilibrium at the lower-level problem (among UEs), and, then, use a backward induction method to solve the upper-level BS problem.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/1911.05642/assets/x2.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="168" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/1911.05642/assets/x3.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="168" height="110" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/1911.05642/assets/x4.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_img_landscape" width="169" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Impact of (a) offered reward rate on client’s (UEs) iteration strategy for corresponding relative local accuracy, (b) communication time with relative accuracy, (c) offered reward rate, normalized BS utility versus local relative accuracy.</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Performance Evaluation</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We now evaluate the performance of our incentive-based FL model by examining the contributions of each FL-participating UE. We investigate the impact of communication channel conditions and local computational characteristics on the accuracy of global federated learning model. We evaluate the impact of the offered reward in terms of communication cost versus local relative accuracy to characterize the system performance in FL. For FL, we adopt a classification task using multinomial logistic regression and distribute the MNIST dataset among participating UEs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. For federated optimization, we use the modified CoCoA framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. The distributed federated optimization scheme of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> allows us to tackle both system-level and statistical heterogeneity efficiently. We consider five participating UEs having different channel conditions and an equal local data size. At each UE, we define the mean square error of the learning problem, i.e., the local relative accuracy metric. For the UEs utility, we choose a concave function of the local relative accuracy and the BS-offered reward.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">In Fig. <a href="#S3.F3" title="Figure 3 ‣ III-B Stackelberg Game Solution ‣ III Incentive Based Federated Learning Over Edge Networks ‣ Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>a, the impact of the offered reward rate on the relative accuracy for five UEs is shown. The accuracy improves when the relative accuracy value (x-axis) is smaller. Intuitively, an increase in the offered reward rate will motivate UEs to iterate more within one global iteration, resulting in a better accuracy. The heterogeneous UE responses is the result of individual computational limitations, local data size, and communication channel conditions. The impact of the communication channel conditions on local relative accuracy for a randomly chosen UE, with defined computational characteristics and local data size is illustrated in Fig. <a href="#S3.F3" title="Figure 3 ‣ III-B Stackelberg Game Solution ‣ III Incentive Based Federated Learning Over Edge Networks ‣ Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>b. For clarity, we use a normalized communication time to quantify the adversity of channel conditions. Here, a unit value for the normalized communication time signifies poor channel conditions. As the communication time increases, the UEs perform more local iterations to avoid expensive communication costs. Fig. <a href="#S3.F3" title="Figure 3 ‣ III-B Stackelberg Game Solution ‣ III Incentive Based Federated Learning Over Edge Networks ‣ Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>c presents the relationship between the offered reward rate and the local relative accuracy at the UEs. The offered reward rate reveals the optimal response of the UEs that maximizes their own utilities for given channel conditions. Here, we have consistency in the normalized BS utility function for various response behaviors of the UEs to the offered reward rate. Thus, it is crucial to have an appropriate incentive design to align the responses of the participating UEs for improving the FL performance.
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Open Research Challenges</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Resource Optimization for Blockchain based Federated Learning</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">An attacker might attack the centralized FL server in order to alter global model parameters. In addition, a malicious user might alter FL parameters during communication. To cope with such security and robustness issues, blockchain based FL (BFL) can be used. BFL does not require central coordination in the learning of the global model which yields enhanced robust operation. In BFL, all users send their local model parameters to their associated miners, which are responsible for sharing local model updates through a distributed ledger. Finally, local model updates of all the devices involved in learning are sent back by miners to their associated devices for the local models aggregation. Although BFL provides benefits of security and robustness, it faces significant challenge of computational and communication resource optimization to reach a consensus among all miners. Static miners can be implemented at the BS, whereas wireless mobile miners can be implemented using drones. However, drone-based mobile miners pose more serious resource allocation challenges than static miners at the BS.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Context-Aware Federated Learning</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">How does one enable more specialized FL according to users contextual information? Context-awareness is the ability of a devices/system to sense, understand, and adopt its surrounding environment. To enable intelligent context-aware applications, FL is a viable solution. For instance, consider keyboard search suggestion in smartphones in which the use of FL is a promising solution. In such type of design, we must consider context-awareness for enhanced performance. Unique globally shared FL model must be used separately for regions with different languages to enable more effective operation. Therefore, the location of the global model must be considered near that region (i.e., micro data center) rather than a central cloud.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Mobility-Aware Federated Learning</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">How does one enable seamless communication of smart mobile devices with an edge server during the learning phase of a global FL model? A seamless connectivity of the devices with a centralized server during the training phase must be maintained. Mobility of devices must be considered during the device selection phase of FL protocol. Deep learning-based mobility prediction schemes can be used to ensure the connectivity of devices during FL training.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and Future Recommendations</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we have presented the key design aspects, incentive mechanism, and open research challenges, for enabling FL in edge networks. We have identified four key design aspects: resource optimization, incentive mechanism, learning algorithm design, and hardware-software co-design-based end-devices, for FL at the network edge. We have shown that game-theoretic incentive mechanisms can be used to effectively model interaction between devices and edge server for FL. This work can potentially make FL amenable for implementation in diverse 5G-enabled smart IoT applications such as intelligent transportation systems, industry 4.0, and digital health care. Finally, we present several recommendations for future research:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Generally, FL involves training of a global FL model via an exchange of learning model updates between a centralized server and geographically distributed devices. However, wireless devices will have heterogeneous energy and processing power (CPU-cycles/sec) capabilities. Some of the devices might have noisy local datasets. Therefore, there is a need for novel FL protocols that will provide criteria for the selection of a set of local devices having sufficient resources. The selection criteria of the devices must include long-lasting backup power, sufficient memory, accurate data, and higher processing power.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">A set of densely populated devices involved in FL might not be able to have real-time access to the edge server located at the BS due to a lack of communication resources. To cope with this challenge, one can develop new FL protocols based on socially-aware device-to-device (D2D) communication. Socially-aware D2D communication has an advantage of reusing the occupied bandwidth by other users while protecting them by keeping the interference level below the maximum allowed limit. Initially, multiple clusters based on social relationships and the distance between devices should be created. Then, a cluster head is selected for every cluster based on its highest social relationship with other devices. Within every cluster, a sub-global FL model is trained iteratively by exchanging the model parameters between the cluster head and its associated devices. Then, the sub-global FL model parameters from all cluster heads are sent to the BS for global model aggregation. Finally, the global FL parameters are sent back to cluster heads which in turn disseminate them to their associated cluster devices.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Exchange of learning model updates via blockchain offers enhanced security. However, reaching consensus via traditional consensus algorithms among blockchain nodes can add more latency to the learning time. Therefore, it is recommended to design novel consensus algorithms with low latency.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. B. E. Moore, D. Ramage, S. Hampson, and B. A. Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.05629</em>, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
K. Guo, Y. Lu, H. Gao, and R. Cao, “Artificial intelligence-based semantic
internet of things in a user-centric smart city,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 18,
no. 5, p. 1341, April 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Chen, M. Mozaffari, W. Saad, C. Yin, M. Debbah, and C. S. Hong, “Caching in
the sky: Proactive deployment of cache-enabled unmanned aerial vehicles for
optimized quality-of-experience,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in
Communications</em>, vol. 35, no. 5, pp. 1046–1061, May 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys Tutorials</em>,
vol. 22, no. 3, pp. 2031–2063, April 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Park, S. Samarakoon, M. Bennis, and M. Debbah, “Wireless network
intelligence at the edge,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.02858</em>, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, “In-Edge
AI: Intelligentizing mobile edge computing, caching and communication by
federated learning,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 33, no. 5, pp. 156–165, July
2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Nilsson, S. Smith, G. Ulm, E. Gustavsson, and M. Jirstrand, “A performance
evaluation of federated learning algorithms,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Second Workshop on Distributed Infrastructures for Deep Learning</em>, New York,
USA, December 2018, pp. 1–8.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair resource allocation in
federated learning,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.10497</em>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and
K. Chan, “Adaptive federated learning in resource constrained edge
computing systems,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>,
vol. 37, no. 6, pp. 1205–1221, June 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task
learning,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing
Systems 30</em>, Long Beach, CA, USA, May 2017, pp. 4424–4434.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Jaggi, V. Smith, M. Takác, J. Terhorst, S. Krishnan, T. Hofmann, and
M. I. Jordan, “Communication-efficient distributed dual coordinate ascent,”
in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 2014, pp.
3068–3076.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
K. Guo, S. Han, S. Yao, Y. Wang, Y. Xie, and H. Yang,
“Software-hardware codesign for efficient neural network acceleration,”
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Micro</em>, vol. 37, no. 2, pp. 18–25, March 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Z. Han, D. Niyato, W. Saad, T. Başar, and A. Hjørungnes, <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Game
theory in wireless and communication networks: theory, models, and
applications</em>.   Cambridge university
press, 2012.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S. R. Pandey, N. H. Tran, M. Bennis, Y. K. Tun, A. Manzoor, and C. S. Hong, “A
crowdsourcing framework for on-device federated learning,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol. 19, no. 5, pp. 3241–3256, May
2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
C. Dinh, N. H. Tran, M. N. Nguyen, C. S. Hong, W. Bao, A. Zomaya, and
V. Gramoli, “Federated learning over wireless networks: Convergence analysis
and resource allocation,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.13067</em>, 2019.

</span>
</li>
</ul>
</section>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td"></td>
<td id="tab1.1.1.2" class="ltx_td">
<span id="tab1.1.1.2.1" class="ltx_inline-block">
<span id="tab1.1.1.2.1.1" class="ltx_p"><span id="tab1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Latif U. Khan</span>  is pursuing his Ph.D. degree in Computer Engineering at Kyung Hee University (KHU), South Korea. He received his MS (Electrical Engineering) degree with distinction from University of Engineering and Technology (UET), Peshawar, Pakistan in 2017. His research interests include analytical techniques of optimization and game theory to edge computing, federated learning, and end-to-end network slicing.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td"></td>
<td id="tab2.1.1.2" class="ltx_td">
<span id="tab2.1.1.2.1" class="ltx_inline-block">
<span id="tab2.1.1.2.1.1" class="ltx_p"><span id="tab2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Shashi Raj Pandey </span>  is currently pursuing his Ph.D. degree from Computer Engineering Department at Kyung Hee University (KHU), South Korea. He received the B.E degree in Electrical and Electronics with specialization in Communication from Kathmandu University, Nepal in 2013. His research interests include network economics, game theory, wireless communications and networking, edge computing, and machine learning.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab3" class="ltx_float biography">
<table id="tab3.1" class="ltx_tabular">
<tr id="tab3.1.1" class="ltx_tr">
<td id="tab3.1.1.1" class="ltx_td"></td>
<td id="tab3.1.1.2" class="ltx_td">
<span id="tab3.1.1.2.1" class="ltx_inline-block">
<span id="tab3.1.1.2.1.1" class="ltx_p"><span id="tab3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Nguyen H. Tran</span> (S’10-M’11-SM’18) is currently working as a senior lecturer in School of Computer Science, The University of Sydney. He received the BS degree from Hochiminh City University of Technology and Ph.D. degree from Kyung Hee University, in electrical and computer engineering, in 2005 and 2011, respectively. His research interest is to applying analytic techniques of optimization and game theory to cutting-edge applications.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab4" class="ltx_float biography">
<table id="tab4.1" class="ltx_tabular">
<tr id="tab4.1.1" class="ltx_tr">
<td id="tab4.1.1.1" class="ltx_td"></td>
<td id="tab4.1.1.2" class="ltx_td">
<span id="tab4.1.1.2.1" class="ltx_inline-block">
<span id="tab4.1.1.2.1.1" class="ltx_p"><span id="tab4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Walid Saad </span>  (S’07, M’10, SM’15, F’19) received his Ph.D. degree from the University of Oslo in 2010. Currently, he is a professor in the Department of Electrical and Computer Engineering at Virginia Tech. His research interests include wireless networks, machine learning, game theory, cybersecurity, unmanned aerial vehicles, and cyber-physical systems. He is the author/co-author of eight conference best paper awards and of the 2015 IEEE ComSoc Fred W. Ellersick Prize.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab5" class="ltx_float biography">
<table id="tab5.1" class="ltx_tabular">
<tr id="tab5.1.1" class="ltx_tr">
<td id="tab5.1.1.1" class="ltx_td"></td>
<td id="tab5.1.1.2" class="ltx_td">
<span id="tab5.1.1.2.1" class="ltx_inline-block">
<span id="tab5.1.1.2.1.1" class="ltx_p"><span id="tab5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Zhu Han</span>  (S’01, M’04, SM’09, F’14) received his Ph.D. degree in electrical and computer engineering from the University of Maryland, College Park. Currently, he is a professor in the Electrical and Computer Engineering Department as well as in the Computer Science Department at the University of Houston, Texas. Dr. Han is an AAAS fellow since 2019. Dr. Han is 1% highly cited researcher since 2017 according to Web of Science.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab6" class="ltx_float biography">
<table id="tab6.1" class="ltx_tabular">
<tr id="tab6.1.1" class="ltx_tr">
<td id="tab6.1.1.1" class="ltx_td"></td>
<td id="tab6.1.1.2" class="ltx_td">
<span id="tab6.1.1.2.1" class="ltx_inline-block">
<span id="tab6.1.1.2.1.1" class="ltx_p"><span id="tab6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Minh N. H. Nguyen </span>  is currently pursuing his Ph.D. degree from Computer Engineering at Kyung Hee University (KHU), South Korea. He received the BE degree in Computer Science and Engineering from the Hochiminh City University of Technology in 2013. His research interest includes Network Optimization, Mobile Edge Computing, Internet of Things.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab7" class="ltx_float biography">
<table id="tab7.1" class="ltx_tabular">
<tr id="tab7.1.1" class="ltx_tr">
<td id="tab7.1.1.1" class="ltx_td"></td>
<td id="tab7.1.1.2" class="ltx_td">
<span id="tab7.1.1.2.1" class="ltx_inline-block">
<span id="tab7.1.1.2.1.1" class="ltx_p"><span id="tab7.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Choong Seon Hong</span>  (S’95-M’97-SM’11) is working as a professor with the Department of Computer Science and Engineering, Kyung Hee University. He is currently an Associate Editor of the Future Internet, International Journal of Network Management, and Journal of Communications and Networks and an Associate Technical Editor of the IEEE Communications Magazine. His research interests include machine learning, edge computing, future internet and UAV networks.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1911.05641" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1911.05642" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1911.05642">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1911.05642" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1911.05643" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 09:25:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
