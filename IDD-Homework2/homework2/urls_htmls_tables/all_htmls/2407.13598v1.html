<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>\name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration</title>
<!--Generated on Thu Jul 18 15:35:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.13598v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S1" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S1.SS1" title="In 1 Related Work ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Improving the Usability of LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S1.SS2" title="In 1 Related Work ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Visualizing Graph-based Knowledge</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Informing the Design</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.SS1" title="In 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Design Requirements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.SS2" title="In 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Three Forms of Knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.SS3" title="In 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>System Overview</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Integrating Knowledge Graph</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.SS1" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Respond to current query (<span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.1</span></span>, <span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.2</span></span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.SS2" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Recommend further explorations (<span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.4</span></span>, <span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span>)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Visual Interface</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS1" title="In 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Information Seeking with <span class="ltx_ERROR undefined">\name</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS1.SSS1" title="In 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Connecting LLM with KG</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS1.SSS2" title="In 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Verification with Evidence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS1.SSS3" title="In 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Next Step Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS1.SSS4" title="In 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.4 </span>Progress Tracking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS2" title="In 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Account Management and Chat Histories</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.SS3" title="In 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Implementation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1" title="In 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Use Cases</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1.SSS1" title="In 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Case One: Verification via Literature</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1.SSS2" title="In 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Case Two: Integrating Information from LLM and KG</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1.SSS3" title="In 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Case Three: Guided Exploration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1.SSS4" title="In 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.4 </span>Observations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS2" title="In 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Expert Interview</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S6" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S7" title="In \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.3">\onlineid</span>
<p class="ltx_p" id="p1.2">0
<span class="ltx_ERROR undefined" id="p1.2.1">\vgtccategory</span>Research
<span class="ltx_ERROR undefined" id="p1.2.2">\vgtcpapertype</span>please specify


<span class="ltx_ERROR undefined" id="p1.2.3">\authorfooter</span>
<math alttext="\ast" class="ltx_Math" display="inline" id="p1.1.m1.1"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">∗</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\ast</annotation><annotation encoding="application/x-llamapun" id="p1.1.m1.1d">∗</annotation></semantics></math> equal contribution, <math alttext="{\ddagger}" class="ltx_Math" display="inline" id="p1.2.m2.1"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p1.2.m2.1d">‡</annotation></semantics></math> co-corresponding authors
Youfu Yan, and Qianwen Wang are with the Department of Computer Science and Engineering, University of Minnesota, Twin Cities, MN, USA. E-mail: yan00111, qianwen@umn.edu
Yu Hou, Yongkang Xiao, Rui Zhang are with the Medical School, University of Minnesota, Twin Cities, MN, USA.
E-mail: hou00127, xiao0290, zhan1386@umn.edu</p>
</div>
<h1 class="ltx_title ltx_title_document">
<span class="ltx_ERROR undefined" id="3.1">\name</span>: Guided Health Information Seeking from LLMs 
<br class="ltx_break"/>via Knowledge Graph Integration</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Youfu Yan *
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_ERROR undefined" id="4.1.1">\authororcid</span>Yu Hou *0009-0009-7184-6592
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yongkang Xiao
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Rui Zhang <sup class="ltx_sup" id="5.2.1"><span class="ltx_text ltx_font_italic" id="5.2.1.1">‡</span></sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_ERROR undefined" id="6.2.1">\authororcid</span>Qianwen Wang <sup class="ltx_sup" id="7.3.2"><span class="ltx_text ltx_font_italic" id="7.3.2.1">‡</span></sup>0000-0003-1728-4102
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="8.1">The increasing reliance on Large Language Models (LLMs) for health information seeking can pose severe risks due to the potential for misinformation and the complexity of these topics.
This paper introduces <span class="ltx_ERROR undefined" id="8.1.1">\name</span>  a visualization system that integrates LLMs with Knowledge Graphs (KG) to provide enhanced accuracy and structured exploration.
Specifically, for enhanced accuracy, <span class="ltx_ERROR undefined" id="8.1.2">\name</span> extracts triples (<span class="ltx_ERROR undefined" id="8.1.3">\eg</span>, entities and their relations) from LLM outputs and maps them into the validated information and supported evidence in external KGs.
For structured exploration, <span class="ltx_ERROR undefined" id="8.1.4">\name</span> provides next-step recommendations based on the neighborhood of the currently explored entities in KGs, aiming to guide a comprehensive understanding without overlooking critical aspects.
To enable reasoning with both the structured data in KGs and the unstructured outputs from LLMs, <span class="ltx_ERROR undefined" id="8.1.5">\name</span> conceptualizes the understanding of a subject as the gradual construction of graph visualization.
A progressive graph visualization is introduced to monitor past inquiries, and bridge the current query with the exploration history and next-step recommendations.
We demonstrate the effectiveness of our system via use cases and expert interviews.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Human-AI interactions, knowledge graph, conversational agent, large language model, progressive visualization
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\teaser</span><img alt="A view of a city with buildings peeking out of the clouds." class="ltx_graphics ltx_centering ltx_img_landscape" height="348" id="p2.g1" src="x1.png" width="830"/>
<p class="ltx_p ltx_align_center" id="p2.2"><span class="ltx_text ltx_caption" id="p2.2.1">In contrast to traditional LLM question-answering (left), which often generate lengthy and unverified text, <span class="ltx_ERROR undefined" id="p2.2.1.1">\name</span> (right) leverages external knowledge graph (KG) to enhance health information seeking with LLM.
<span class="ltx_ERROR undefined" id="p2.2.1.2">\name</span> provides validation through literature for accuracy, next-step recommendations for comprehensive exploration, and step-by-step graph visualization for a progressive understanding of the topic.
</span>
</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">Introduction</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">Recently, Large Language Models (LLMs) have shown exceptional proficiency in a wide range of tasks and domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib4" title="">4</a>]</cite>, significantly transforming our approach to information seeking.
More and more people are now turning to LLMs to acquire the desired information on diverse topics.
Despite their advanced capabilities, the interactions with LLMs has been criticized for their insufficient factual accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib19" title="">19</a>]</cite>, lack of guidance in exploration <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib54" title="">54</a>]</cite>, and inadequate support in representing intricate information structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>]</cite>.
These issues are particularly critical when seeking health-related information, where accuracy and clarity are paramount.</p>
</div>
<div class="ltx_para" id="p5">
<p class="ltx_p" id="p5.1">One primary reason for these issues is that LLMs encode knowledge from the training corpus in the form of model parameters, which are difficult to interpret, validate, and align with users’ cognitive processes.
As a result, one promising solution is to enhance LLMs with external knowledge that can be inspected and interpreted <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib34" title="">34</a>]</cite>.
Among various formats of external knowledge, knowledge graphs (KG) are attracting increasing attention due to their decisive knowledge representation and symbolic reasoning ability.
A knowledge graph stores structured knowledge as a network of entities and their relations, serving a broad range of domain applications including drug development <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib16" title="">16</a>]</cite>, children education <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib23" title="">23</a>]</cite>, and pedigree networks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib33" title="">33</a>]</cite>.
Incorporating knowledge graphs in LLMs can provide structured knowledge when training the model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib1" title="">1</a>]</cite>, retrieve pertinent information when responding to specific queries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib26" title="">26</a>]</cite>, and offer evidence when reasoning the outputs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib36" title="">36</a>]</cite>.
Such integration have been shown to significantly boost performance in domain-specific and knowledge-intensive tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<div class="ltx_para" id="p6">
<p class="ltx_p" id="p6.1">While integrating knowledge graphs can markedly enhance the quality of LLM outputs, this enhancement is underutilized with current purely text-based interfaces.
These interfaces, which typically rely on linear text formats like extended paragraphs, limit the user’s ability to collect, organize, and synthesize information from the structured external knowledge, which has the potential to greatly facilitate the user’s cognitive process.
Recently, a growing body of studies are exploring innovative interfaces for LLM via text-visualization coordination <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>]</cite>, multi-level abstractions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib39" title="">39</a>]</cite>, node-link diagrams <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib2" title="">2</a>]</cite>.
However, these studies mainly focused on enriching human-LLM interactions through prompt engineering, providing little discussion about the integration of external knowledge bases.
Meanwhile, many visual analytics methods have been proposed in the past decades to facilitate the interpretation of graphs for both domain-specific (<span class="ltx_ERROR undefined" id="p6.1.1">\eg</span>, biomedical knowledge graphs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib27" title="">27</a>]</cite>, neural network architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib47" title="">47</a>]</cite>) and general purposes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib28" title="">28</a>]</cite>.
But these visualization techniques mainly support information seeking through queries about graph structures (<span class="ltx_ERROR undefined" id="p6.1.2">\eg</span>, paths connecting nodes A and B, nodes with the highest degree) and cannot be directly applied to complex tasks that require iterative conversations.
There is a gap in effectively leveraging external knowledge graphs for more comprehensive and interactive visual interfaces for LLM.</p>
</div>
<div class="ltx_para" id="p7">
<p class="ltx_p" id="p7.1">This study proposes <span class="ltx_ERROR undefined" id="p7.1.1">\name</span>, a visualization system for health information retrieval by improving the traditional LLM-based with enhanced accuracy and structured exploration via integrating external KGs.
To enhance accuracy, we extracted triples (e.g., entities and their
relations) from LLM outputs and mapped them into the validated information and supported evidence in external KGs.
For structured exploration, <span class="ltx_ERROR undefined" id="p7.1.2">\name</span> provides recommendations for further inquiry to help form a comprehensive understanding without overlooking critical aspects.
Considering a multi-step exploration might introduce information overwhelming, <span class="ltx_ERROR undefined" id="p7.1.3">\name</span> follows the focus+context design and proposes a progressive graph visualization to track previous inquiries, and connect this history with current queries and next-step recommendations.
We demonstrate the effectiveness of our system via use cases and expert interviews
While we probed its capabilities initially within the context of dietary supplements (<span class="ltx_ERROR undefined" id="p7.1.4">\eg</span>, vitamins, minerals, herbs), an area where scientifically validated information is partially important given the prevalence of exaggerated claims and misinformation, the proposed approach is applicable to a wide array of applications.
The source code and documentations for <span class="ltx_ERROR undefined" id="p7.1.5">\name</span> are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://visual-intelligence-umn.github.io/KNOWNET/" title="">https://visual-intelligence-umn.github.io/KNOWNET/</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Related Work</h2>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Improving the Usability of LLM</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">As LLMs are increasingly employed, there is growing concern about their usability limitations stemming from both the inherent characteristics of LLMs and the design of current interfaces. Various research efforts are being undertaken to mitigate these issues.</p>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">One approach focuses on offering controllability through tailored guidance, especially via prompt designs.
Many studies have observed that, without further guidance, users tended to interact with LLMs opportunistically and struggle to make robust progress <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib6" title="">6</a>]</cite>.
A list of tools has been proposed to guide the design of prompts for support LLM interactions.
For instance, AI Chains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib51" title="">51</a>]</cite> provides an interactive system that chains LLM prompts and enables users to modify these chains in a modular way.
Promptify <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib6" title="">6</a>]</cite> and PromptMagician <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib13" title="">13</a>]</cite> utilizes a suggestion engine to help users quickly explore, craft, and organize diverse prompts.
Zamfirescu-Pereira <span class="ltx_text ltx_font_italic" id="S1.SS1.p2.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib55" title="">55</a>]</cite> suggested strategies such as the use of example input/output pairs and the use of repetition within prompts.
Even though these studies have contributed valuable insights, it remains a challenge to design them effectively as there is no one-size-fits-all solution.
In a recent study, Su-Fang <span class="ltx_text ltx_font_italic" id="S1.SS1.p2.1.2">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib54" title="">54</a>]</cite> investigated the effects of two guidance types and four guidance timings. Their study indicated there is no clear best choice for guidance type or timing, but depends on the specific goals of the guidance.</p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1">Meanwhile, a parallel research branch explores integrating graphical representations to complement traditional text interface.
For instance, ChatGPT has included multiple plug-ins, such as Lucid GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib29" title="">29</a>]</cite> and ChatGPT Diagrams <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib15" title="">15</a>]</cite>, that translate textual outputs into visual diagrams.
However, these visual outputs are usually static images with limited or no interactivity.
To address this issue, Graphologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>]</cite> constructs interactive graphical charts using novel prompt strategies.
Sensecape <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib39" title="">39</a>]</cite> further enhanced these graphical charts by introducing hierarchical abstracts among which users can easily navigate.
The integration of graphical representation has also been demonstrated to improve task performance and user satisfaction in various domain applications, including argumentative writing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib57" title="">57</a>]</cite> and creative coding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib2" title="">2</a>]</cite>.
Unlike prior studies that merely converted LLM text outputs to visual representations, our study aims to integrate external knowledge graphs to enhance the interactions with LLMs.</p>
</div>
<div class="ltx_para" id="S1.SS1.p4">
<p class="ltx_p" id="S1.SS1.p4.1">In spite of the great success of the above efforts, they cannot improve task performance in which LLMs have limited knowledge.
As a result, researchers proposed harnessing external knowledge to improve the output quality, known as retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib26" title="">26</a>]</cite>.
RAG can enhance LLMs by querying relevant information from an external dataset for generating outputs, ensuring that the responses are grounded in retrieved evidence and include up-to-date knowledge.
Among different types of external knowledge bases, knowledge graphs are widely used due to their symbolic reasoning ability, as discussed in the survey paper of Pan <span class="ltx_text ltx_font_italic" id="S1.SS1.p4.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib34" title="">34</a>]</cite>.
For example, Ashby <span class="ltx_text ltx_font_italic" id="S1.SS1.p4.1.2">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib3" title="">3</a>]</cite> generated fluent and coherent dialogue for role-playing games by incorporating LLMs with a hand-crafted knowledge graph about the game world.
However, these studies mainly use external knowledge graphs for improving LLM outputs and do not explicitly elucidate how the integration can improve human-LLM interfaces, which is the main focus of our paper.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Visualizing Graph-based Knowledge</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">Graph visualization for knowledge communication has received extensive attention within the visualization community. A diverse array of visual analytics systems has been developed, covering diverse domains such as biology networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib27" title="">27</a>]</cite>, neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib47" title="">47</a>]</cite>, and pedigree networks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib33" title="">33</a>]</cite>.
The principal challenge lies in effectively uncovering patterns within large graphs.
A variety of visualization techniques have been proposed for uncovering different types of patterns, including layout algorithms designed to expose communities within graphs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib48" title="">48</a>]</cite>, techniques for path querying and organization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>]</cite>, and methods for conducting visual comparisons across different graphs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib47" title="">47</a>]</cite>.
For example, Wang <span class="ltx_text ltx_font_italic" id="S1.SS2.p1.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>]</cite> proposed a novel design, MetaMatrix, to help users organize and compare explanation paths in a biomedical knowledge graph at different levels of granularity.
In spite of the effectiveness of these methods, the challenges in graph exploration often extend beyond merely generating a static visualization but necessitate interaction techniques, leading to a set of popular interaction techniques such as focus + context and semantic zoom.
Focus + context techniques, such as fish-eye <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib37" title="">37</a>]</cite>, display the object of interest in detail (focus) with an overview of surrounding information (context).
Semantic zoom <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib30" title="">30</a>]</cite> adjusts the visual representations dynamically based on the level of details.
Once patterns are identified, efficiently communicating them also poses another complex challenge, leading to investigations into the use of natural language interfaces and narrative techniques.
For instance, GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib38" title="">38</a>]</cite> facilitates the articulation of visual insights in graph visualizations through natural language. NetworkNarratives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib28" title="">28</a>]</cite> introduces semi-automatic data tours that elucidate network facts via slideshows with visualizations and textual annotations.</p>
</div>
<div class="ltx_para" id="S1.SS2.p2">
<p class="ltx_p" id="S1.SS2.p2.1">Our study is built upon previous studies on graph visualization, examining various visualization techniques for facilitating human-LLM interactions with the integration of external knowledge graphs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Informing the Design</h2>
<div class="ltx_para" id="S2.p1">
<span class="ltx_ERROR undefined" id="S2.p1.1">\name</span>
<p class="ltx_p" id="S2.p1.2">is designed to aid users in searching for health-related information by seamlessly integrating LLM outputs with external KG.
It targets individuals who require access to such information and possess the ability to grasp complex medical concepts and interpret research findings.
Primary users of this tool include medical researcher, health science students, and patient advocates.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Design Requirements</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">We identify the design challenge based on discussion with domain experts and review of literature, following the practices in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib45" title="">45</a>]</cite>.
Specifically, three authors are experts in computational health sciences with extensive experience, including a professor with 15 years of research in health AI, knowledge graphs, and clinical NLP; a postdoc researcher with 6 years of experience in knowledge graphs and EHR data analysis; and a PhD candidate with 3 years of experience in knowledge graphs and health informatics.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Four authors, including two domain and two visualization experts, first collaboratively built a list of relevant papers that examined, applied, or improved LLMs for various information-seeking tasks, including but not limited to writing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib22" title="">22</a>]</cite>, coding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib2" title="">2</a>]</cite>, and healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib53" title="">53</a>]</cite>.
Each paper was then independently reviewed by at least two authors. Drawing on the findings from the literature review, the author team held weekly meetings to refine the design requirements, update the design, and test the developed tool.
Through this iterative process, we identified five key design challenges.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.1.1.1">C.1</span></span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Linear Response to Hierarchical Information:</span> LLMs, by design, generate responses in a linear fashion, presenting information in a single continuous stream.
However, the structure of knowledge itself is intrinsically marked by complex and multifaceted relationships among concepts.
Taking a common dietary supplementary vitamin D as an example.
At a basic level, understanding vitamin D involves understanding its various forms (<span class="ltx_ERROR undefined" id="S2.I1.i1.p1.1.2">\eg</span>, D2, D3), sources (<span class="ltx_ERROR undefined" id="S2.I1.i1.p1.1.3">\eg</span>, sunlight, food), and its role in the human body, such as supporting bone health and immune function.
Delving deeper reveals a web of interconnected details that spans nutrition, biochemistry, and public health, such as its involvement in calcium absorption and the implications of its deficiency.
As a result, the current linear presentation off LLMs can represent users to grasp the complex structure and navigate intricate topics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib57" title="">57</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.1.1.1">C.2</span></span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Limited Support for Verification:</span>
LLMs often suffer from hallucination, wherein an LLM generates incorrect information but presents it as it was a fact, which can potentially deceive users who lack the expertise to assess the information accuracy.
This can lead to potential deception among users who may not have prior knowledge to evaluate the accuracy of the information.
Several LLM-based chatbots have integrated internet search to alleviate this issue, but the referred online resources have various reliability.
In a critical context, such as medicine and healthcare, users have expressed a preference for AI tools that function similarly to knowledgeable colleagues that can reference reliable evidence, such as biomedical research, to support their responses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib53" title="">53</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.1.1.1">C.3</span></span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Information Overload:</span>
LLMs are often designed to generate a verbose, long-form answers that includes extensive information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib25" title="">25</a>]</cite>.
Users can be overloaded, feel that <span class="ltx_text ltx_font_italic" id="S2.I1.i3.p1.1.2">“there is too much to read”</span>, and find it challenging to efficiently interpret the response and comprehend the underlying reasoning chain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib24" title="">24</a>]</cite>.
Additionally, these long-term responses tend to include redundant information and utilize pompous language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib8" title="">8</a>]</cite>, which further hampers the user’s comprehension process.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.1.1.1">C.4</span></span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Lack of Exploration Guidance:</span> LLMs excel at supporting free-form exploration, with their extensive knowledge base enabling them to answer a wide variety of user questions.
However, their propensity for broad exploration can sometimes be overwhelming.
Without guidance, users often find themselves confused about <span class="ltx_text ltx_font_italic" id="S2.I1.i4.p1.1.2">"what to ask next, and how?"</span> due to the sheer volume of content available for inquiry <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib55" title="">55</a>]</cite>.
This issue is especially salient for complex topics that cannot be fully addressed with one single question, but requires iterative follow-up conversations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.1.1.1">C.5</span></span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Absence of Goal-Achieving Indicator:</span>
LLMs typically do not have an inherent mechanism for aligning its outputs with the user’s goal of understanding a specific topic, which often varies from person to person.
Users might find themselves navigating through an abundance of information without a clear sense of <span class="ltx_text ltx_font_italic" id="S2.I1.i5.p1.1.2">“how much more information is needed”</span> for forming a desired level of understanding.
Often, they might quit the information seeking after asking the one or two questions (<span class="ltx_ERROR undefined" id="S2.I1.i5.p1.1.3">\eg</span>, whether a drug can be used for a disease), overlooking other important related information (<span class="ltx_ERROR undefined" id="S2.I1.i5.p1.1.4">\eg</span>, the side effort of this drug).</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S2.F1.g1" src="x2.png" width="746"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_ERROR undefined" id="S2.F1.4.2">\name</span><span class="ltx_text" id="S2.F1.5.3" style="font-size:90%;"> is designed to support the communication among three distinct forms of knowledge: the knowledge users apply in their reasoning process, the knowledge contained within LLMs, and the knowledge stored in KGs.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Three Forms of Knowledge</h3>
<div class="ltx_para" id="S2.SS2.p1">
<span class="ltx_ERROR undefined" id="S2.SS2.p1.1">\name</span>
<p class="ltx_p" id="S2.SS2.p1.2">aims to provide a systematic solution to the identified challenges in information seeking via the integration of KGs.
Therefore, <span class="ltx_ERROR undefined" id="S2.SS2.p1.2.1">\name</span> needs to enable the communication among three distinct forms of knowledge, the one used in users’ reasoning process, the one stored in LLM, and the one contained in KG (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.F1" title="In 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>).
We consider the process of understanding an object as progressively forming a knowledge graph about it.
The external knowledge graph serves as a scaffold for organizing information, assessing LLM response, guiding exploration, and tracking the exploration progress.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">This idea is driven by the observation that knowledge graphs, by nature, align with the principles of symbolic cognitive modeling, a classic approach for modeling human cognitive process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib50" title="">50</a>]</cite>.
Knowledge graphs represent information in a structured, symbolized format, using nodes to represent entities (<span class="ltx_ERROR undefined" id="S2.SS2.p2.1.1">\eg</span>, objects) and edges to represent the relationships between these entities.
This structured representation mirrors the symbolic cognitive model, which posits that human cognition operates through the manipulation of discrete symbols, represented by the nodes and edges in knowledge graphs.
For example, understanding the node <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.2">[Paris]</span> involves recognizing its connection through a <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.3">[capital_of]</span> edge to the node <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.4">[France]</span>.
By actively, progressively constructing a knowledge graph around the object of interest, users engage in a symbolic manipulation process, drawing connections and making inferences that enhance their understanding in a manner akin to typical human reasoning.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="373" id="S2.F2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S2.F2.4.2" style="font-size:90%;">System Overview.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>System Overview</h3>
<div class="ltx_para" id="S2.SS3.p1">
<span class="ltx_ERROR undefined" id="S2.SS3.p1.1">\name</span>
<p class="ltx_p" id="S2.SS3.p1.2">consists of three main modules, a knowledge base, an exploration tracking module, and a user interface, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.F2" title="In 2.2 Three Forms of Knowledge ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>.
The knowledge base merges LLM and KG capabilities to deliver structured and verified responses to user inquiries.
Based on the current query, <span class="ltx_ERROR undefined" id="S2.SS3.p1.2.1">\name</span> extracts pertinent information from the KG and generates recommendations for next-step exploration, which are then sent to the exploration tracking module.
The user interface enables users to interact with both the knowledge base and the exploration tracking module.
Users can validate responses, explore recommendations, and adjust their exploration goals, determining whether to proceed with the current conversation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Integrating Knowledge Graph</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we outline our approach for integrating external KG with LLMs to address the identified design challenges (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i1" title="Item C.1 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.1</span></span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i5" title="Item C.5 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span></a>). <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F3" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows the overview of the back-end structure.
We focus on using KG to enhance user interactions with LLMs, complementing existing studies that have used KGs to improve the pre-training, fine-tuning, and inference processes of LLMs.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">For the LLM, we selected GPT4 as it is the state-of-the-art method.
For the KG, we utilized ADInt<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib52" title="">52</a>]</cite>, a KG we developed in earlier studies by extracting information on Non-pharmaceutical interventions and Alzheimer’s Disease from biomedical literature.
This comprehensive KG comprises 162,212 nodes (15 types of entities such as drug, disease, symptoms) and 1,017,284 edges (the relation between entities), incorporating a total of 754,224 pieces of scientific literature.
ADInt serves as a testbed in this study and the proposed method is designed for easy adaptation with other knowledge graphs, especially considering the broad availability of knowledge graph datasets across various domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="488" id="S3.F3.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.5.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.6.2" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S3.F3.6.2.1">An overview of the back-end</span>. <span class="ltx_ERROR undefined" id="S3.F3.6.2.2">\name</span> accepts text inputs (a), maps entities in the LLM response to corresponding nodes in the KG based on their embeddings (b), and identifies related entities in the KG neighborhood to generate recommendations based on user exploration histories (c). Finally, <span class="ltx_ERROR undefined" id="S3.F3.6.2.3">\name</span> outputs text responses and visualizations that organize the main relationships, provide evidence from the KG, and suggest next-step recommendations (d).
</span></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Respond to current query (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i1" title="Item C.1 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.1</span></span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i2" title="Item C.2 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.2</span></span></a>)</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">After a user poses a question, <span class="ltx_ERROR undefined" id="S3.SS1.p1.1.1">\name</span> responds by combining the LLM outputs and the related information from KG (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F3" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(b)).</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.5">The LLM will first determine whether the user question falls within the scope of the KG. If the query is outside the KG’s scope, <span class="ltx_ERROR undefined" id="S3.SS1.p2.5.1">\name</span>will function the same way as a standard LLM chat. Otherwise, the LLM will be prompted to annotate triples for extracting structured information from the unstructured text (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i1" title="Item C.1 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.1</span></span></a>).

One triple consist of two entities and their relation.
Inspired by the prompting strategies in Graphologue<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>]</cite>, we prompted the LLM to assign a unique identifier for each entity (<math alttext="n_{1},n_{2},..." class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.3"><semantics id="S3.SS1.p2.1.m1.3a"><mrow id="S3.SS1.p2.1.m1.3.3.2" xref="S3.SS1.p2.1.m1.3.3.3.cmml"><msub id="S3.SS1.p2.1.m1.2.2.1.1" xref="S3.SS1.p2.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p2.1.m1.2.2.1.1.2" xref="S3.SS1.p2.1.m1.2.2.1.1.2.cmml">n</mi><mn id="S3.SS1.p2.1.m1.2.2.1.1.3" xref="S3.SS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.2.3" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.1.m1.3.3.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p2.1.m1.3.3.2.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.2.cmml">n</mi><mn id="S3.SS1.p2.1.m1.3.3.2.2.3" xref="S3.SS1.p2.1.m1.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.2.4" xref="S3.SS1.p2.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS1.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p2.1.m1.1.1.cmml">…</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.3b"><list id="S3.SS1.p2.1.m1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.2"><apply id="S3.SS1.p2.1.m1.2.2.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.2">𝑛</ci><cn id="S3.SS1.p2.1.m1.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p2.1.m1.3.3.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2">𝑛</ci><cn id="S3.SS1.p2.1.m1.3.3.2.2.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">…</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.3c">n_{1},n_{2},...</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.3d">italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , …</annotation></semantics></math>) and their relations (<math alttext="r_{1},r_{2},..." class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.3"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.3.2" xref="S3.SS1.p2.2.m2.3.3.3.cmml"><msub id="S3.SS1.p2.2.m2.2.2.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.2" xref="S3.SS1.p2.2.m2.2.2.1.1.2.cmml">r</mi><mn id="S3.SS1.p2.2.m2.2.2.1.1.3" xref="S3.SS1.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.2.m2.3.3.2.3" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS1.p2.2.m2.3.3.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS1.p2.2.m2.3.3.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.cmml">r</mi><mn id="S3.SS1.p2.2.m2.3.3.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.2.m2.3.3.2.4" xref="S3.SS1.p2.2.m2.3.3.3.cmml">,</mo><mi id="S3.SS1.p2.2.m2.1.1" mathvariant="normal" xref="S3.SS1.p2.2.m2.1.1.cmml">…</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><list id="S3.SS1.p2.2.m2.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2"><apply id="S3.SS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.2">𝑟</ci><cn id="S3.SS1.p2.2.m2.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p2.2.m2.3.3.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2">𝑟</ci><cn id="S3.SS1.p2.2.m2.3.3.2.2.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">…</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">r_{1},r_{2},...</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.3d">italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , …</annotation></semantics></math>) simultaneously during text generation.
For example, in the response
<span class="ltx_text ltx_font_italic" id="S3.SS1.p2.5.2">“[fish oil]($n1) is known for [containing]($r1, $n1, $n2) a rich content of [Omega-3 fatty acids]($n2)”</span>, GPT identifies one triple with two entities: <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.5.3">fish oil</span>, denoted as <math alttext="n_{1}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">n</mi><mn id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑛</ci><cn id="S3.SS1.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">n_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.5.4">Omega-3 fatty acids</span>, denoted as <math alttext="n_{2}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">n</mi><mn id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝑛</ci><cn id="S3.SS1.p2.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.p2.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">n_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>, and their relation, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.5.5">containing</span>, denoted as <math alttext="r_{1}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">r</mi><mn id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝑟</ci><cn id="S3.SS1.p2.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">r_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We then match these triples with the KG to extract related literature and provide assistance in verification (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i2" title="Item C.2 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.2</span></span></a>).
Specifically, we generate embedding vectors for the nodes in the KG and the entities in the LLM outputs using the same embedding model, the <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.1">text-embedding-ada-002</span> model from OpenAI.
Given a new LLM triple <math alttext="(n_{i},r,n_{k})" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.3"><semantics id="S3.SS1.p3.1.m1.3a"><mrow id="S3.SS1.p3.1.m1.3.3.2" xref="S3.SS1.p3.1.m1.3.3.3.cmml"><mo id="S3.SS1.p3.1.m1.3.3.2.3" stretchy="false" xref="S3.SS1.p3.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS1.p3.1.m1.2.2.1.1" xref="S3.SS1.p3.1.m1.2.2.1.1.cmml"><mi id="S3.SS1.p3.1.m1.2.2.1.1.2" xref="S3.SS1.p3.1.m1.2.2.1.1.2.cmml">n</mi><mi id="S3.SS1.p3.1.m1.2.2.1.1.3" xref="S3.SS1.p3.1.m1.2.2.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p3.1.m1.3.3.2.4" xref="S3.SS1.p3.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">r</mi><mo id="S3.SS1.p3.1.m1.3.3.2.5" xref="S3.SS1.p3.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS1.p3.1.m1.3.3.2.2" xref="S3.SS1.p3.1.m1.3.3.2.2.cmml"><mi id="S3.SS1.p3.1.m1.3.3.2.2.2" xref="S3.SS1.p3.1.m1.3.3.2.2.2.cmml">n</mi><mi id="S3.SS1.p3.1.m1.3.3.2.2.3" xref="S3.SS1.p3.1.m1.3.3.2.2.3.cmml">k</mi></msub><mo id="S3.SS1.p3.1.m1.3.3.2.6" stretchy="false" xref="S3.SS1.p3.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.3b"><vector id="S3.SS1.p3.1.m1.3.3.3.cmml" xref="S3.SS1.p3.1.m1.3.3.2"><apply id="S3.SS1.p3.1.m1.2.2.1.1.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1.2">𝑛</ci><ci id="S3.SS1.p3.1.m1.2.2.1.1.3.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑟</ci><apply id="S3.SS1.p3.1.m1.3.3.2.2.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.3.3.2.2.1.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.2">𝑛</ci><ci id="S3.SS1.p3.1.m1.3.3.2.2.3.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.3">𝑘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.3c">(n_{i},r,n_{k})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.3d">( italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r , italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math>, we identify the corresponding KG nodes by calculating and comparing the cosine similarity of their embeddings to those of the nodes within the triple, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F3" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(b).
We then search in the KG to find whether the two entities are connected via either one- or two-hop paths.
These paths connecting entities are derived from mining biomedical literature, providing useful insights for interpreting and validating LLM responses.
New knowledge can be integrated into <span class="ltx_ERROR undefined" id="S3.SS1.p3.1.2">\name</span>by updating the KG through the insertion of new entities and paths.

As noted in previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>]</cite>, the biomedical literature is a preferred resource to calibrate user trust with AI tools.
It is important to note that KG paths between two entities do not always imply the same relation in the LLM triple.
This discrepancy is particularly pronounced due to the ambiguity of text.
For example, “slow the progress” does not equal to “treating” a disease.
Similarly to node matching, we applied text embedding to compare relations suggested by LLM with those identified in the KG.
We consider these relations to be equivalent if the cosine similarity of their embedding vectors exceeds a certain threshold, which may need refinement based on the specific KGs and embedding methods used. In our implementation, we set the threshold at 0.94 based on experiments.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S3.F4.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.6.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F4.7.2" style="font-size:90%;">Interface of <span class="ltx_ERROR undefined" id="S3.F4.7.2.1">\name</span><span class="ltx_text ltx_font_medium" id="S3.F4.7.2.2">. Users can log into the tool via GitHub or Google account and securely store their chat history (A1-A2). The main interface consists of a <span class="ltx_text ltx_font_italic" id="S3.F4.7.2.2.1">Text Dialogue</span> (B), a <span class="ltx_text ltx_font_italic" id="S3.F4.7.2.2.2">Graphical Explorer</span> (C), and a <span class="ltx_text ltx_font_italic" id="S3.F4.7.2.2.3">Navigator</span> (D). Information validation (E) and next-step recommendations (F) are provided to facilitate the exploration. </span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Recommend further explorations (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i4" title="Item C.4 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.4</span></span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i5" title="Item C.5 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span></a>)</h3>
<div class="ltx_para" id="S3.SS2.p1">
<span class="ltx_ERROR undefined" id="S3.SS2.p1.1">\name</span>
<p class="ltx_p" id="S3.SS2.p1.2">generates recommendations considering both the KG structured neighborhood and the user exploration history (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i4" title="Item C.4 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.4</span></span></a>), as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F3" title="In 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(c).
Even though we can generate next-step recommendations by prompting GPT, <span class="ltx_ERROR undefined" id="S3.SS2.p1.2.1">\eg</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.2.2">“please suggest relevant questions for further exploration.”</span>, it offers limited control to the users.
Therefore, we used the structured information in KG to provide customizable recommendation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We categorize user queries <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_Q</annotation></semantics></math> into two main categories based on the format: the relation between a node and a node type , or the relation between a node and another node.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Q=(N,\{T|N^{\prime}\})" class="ltx_Math" display="block" id="S3.Ex1.m1.3"><semantics id="S3.Ex1.m1.3a"><mrow id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml"><mi id="S3.Ex1.m1.3.3.3" xref="S3.Ex1.m1.3.3.3.cmml">Q</mi><mo id="S3.Ex1.m1.3.3.2" xref="S3.Ex1.m1.3.3.2.cmml">=</mo><mrow id="S3.Ex1.m1.3.3.1.1" xref="S3.Ex1.m1.3.3.1.2.cmml"><mo id="S3.Ex1.m1.3.3.1.1.2" stretchy="false" xref="S3.Ex1.m1.3.3.1.2.cmml">(</mo><mi id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml">N</mi><mo id="S3.Ex1.m1.3.3.1.1.3" xref="S3.Ex1.m1.3.3.1.2.cmml">,</mo><mrow id="S3.Ex1.m1.3.3.1.1.1.1" xref="S3.Ex1.m1.3.3.1.1.1.2.cmml"><mo id="S3.Ex1.m1.3.3.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.3.3.1.1.1.2.1.cmml">{</mo><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">T</mi><mo id="S3.Ex1.m1.3.3.1.1.1.1.3" lspace="0em" rspace="0em" xref="S3.Ex1.m1.3.3.1.1.1.2.1.cmml">|</mo><msup id="S3.Ex1.m1.3.3.1.1.1.1.1" xref="S3.Ex1.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.3.3.1.1.1.1.1.2" xref="S3.Ex1.m1.3.3.1.1.1.1.1.2.cmml">N</mi><mo id="S3.Ex1.m1.3.3.1.1.1.1.1.3" xref="S3.Ex1.m1.3.3.1.1.1.1.1.3.cmml">′</mo></msup><mo id="S3.Ex1.m1.3.3.1.1.1.1.4" stretchy="false" xref="S3.Ex1.m1.3.3.1.1.1.2.1.cmml">}</mo></mrow><mo id="S3.Ex1.m1.3.3.1.1.4" stretchy="false" xref="S3.Ex1.m1.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.3b"><apply id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3"><eq id="S3.Ex1.m1.3.3.2.cmml" xref="S3.Ex1.m1.3.3.2"></eq><ci id="S3.Ex1.m1.3.3.3.cmml" xref="S3.Ex1.m1.3.3.3">𝑄</ci><interval closure="open" id="S3.Ex1.m1.3.3.1.2.cmml" xref="S3.Ex1.m1.3.3.1.1"><ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">𝑁</ci><apply id="S3.Ex1.m1.3.3.1.1.1.2.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.3.3.1.1.1.2.1.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1.2">conditional-set</csymbol><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">𝑇</ci><apply id="S3.Ex1.m1.3.3.1.1.1.1.1.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1.1.2">𝑁</ci><ci id="S3.Ex1.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.3.3.1.1.1.1.1.3">′</ci></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.3c">Q=(N,\{T|N^{\prime}\})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.3d">italic_Q = ( italic_N , { italic_T | italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT } )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.3">where <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m1.1"><semantics id="S3.SS2.p2.2.m1.1a"><mi id="S3.SS2.p2.2.m1.1.1" xref="S3.SS2.p2.2.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.1b"><ci id="S3.SS2.p2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m1.1d">italic_T</annotation></semantics></math> represent node types and <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m2.1"><semantics id="S3.SS2.p2.3.m2.1a"><mi id="S3.SS2.p2.3.m2.1.1" xref="S3.SS2.p2.3.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.1b"><ci id="S3.SS2.p2.3.m2.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m2.1d">italic_N</annotation></semantics></math> represent nodes.
For example, with vitamin E as the node, query examples include “which disorders can vitamin E improve” (a node and a node type), “is vitamin E helpful for Alzheimer’s disease” (a node and another node).
Our recommendations are crafted following such query patterns.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3">We model user state based on their exploration history following the n-context analysis outlined by Milo and Somech <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib31" title="">31</a>]</cite>.
We denote the user’s current state using the previous queries posed by users,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="context_{t}=(q_{0},q_{1},...,q_{t})" class="ltx_Math" display="block" id="S3.Ex2.m1.4"><semantics id="S3.Ex2.m1.4a"><mrow id="S3.Ex2.m1.4.4" xref="S3.Ex2.m1.4.4.cmml"><mrow id="S3.Ex2.m1.4.4.5" xref="S3.Ex2.m1.4.4.5.cmml"><mi id="S3.Ex2.m1.4.4.5.2" xref="S3.Ex2.m1.4.4.5.2.cmml">c</mi><mo id="S3.Ex2.m1.4.4.5.1" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><mi id="S3.Ex2.m1.4.4.5.3" xref="S3.Ex2.m1.4.4.5.3.cmml">o</mi><mo id="S3.Ex2.m1.4.4.5.1a" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><mi id="S3.Ex2.m1.4.4.5.4" xref="S3.Ex2.m1.4.4.5.4.cmml">n</mi><mo id="S3.Ex2.m1.4.4.5.1b" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><mi id="S3.Ex2.m1.4.4.5.5" xref="S3.Ex2.m1.4.4.5.5.cmml">t</mi><mo id="S3.Ex2.m1.4.4.5.1c" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><mi id="S3.Ex2.m1.4.4.5.6" xref="S3.Ex2.m1.4.4.5.6.cmml">e</mi><mo id="S3.Ex2.m1.4.4.5.1d" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><mi id="S3.Ex2.m1.4.4.5.7" xref="S3.Ex2.m1.4.4.5.7.cmml">x</mi><mo id="S3.Ex2.m1.4.4.5.1e" xref="S3.Ex2.m1.4.4.5.1.cmml">⁢</mo><msub id="S3.Ex2.m1.4.4.5.8" xref="S3.Ex2.m1.4.4.5.8.cmml"><mi id="S3.Ex2.m1.4.4.5.8.2" xref="S3.Ex2.m1.4.4.5.8.2.cmml">t</mi><mi id="S3.Ex2.m1.4.4.5.8.3" xref="S3.Ex2.m1.4.4.5.8.3.cmml">t</mi></msub></mrow><mo id="S3.Ex2.m1.4.4.4" xref="S3.Ex2.m1.4.4.4.cmml">=</mo><mrow id="S3.Ex2.m1.4.4.3.3" xref="S3.Ex2.m1.4.4.3.4.cmml"><mo id="S3.Ex2.m1.4.4.3.3.4" stretchy="false" xref="S3.Ex2.m1.4.4.3.4.cmml">(</mo><msub id="S3.Ex2.m1.2.2.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.cmml"><mi id="S3.Ex2.m1.2.2.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.2.cmml">q</mi><mn id="S3.Ex2.m1.2.2.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S3.Ex2.m1.4.4.3.3.5" xref="S3.Ex2.m1.4.4.3.4.cmml">,</mo><msub id="S3.Ex2.m1.3.3.2.2.2" xref="S3.Ex2.m1.3.3.2.2.2.cmml"><mi id="S3.Ex2.m1.3.3.2.2.2.2" xref="S3.Ex2.m1.3.3.2.2.2.2.cmml">q</mi><mn id="S3.Ex2.m1.3.3.2.2.2.3" xref="S3.Ex2.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S3.Ex2.m1.4.4.3.3.6" xref="S3.Ex2.m1.4.4.3.4.cmml">,</mo><mi id="S3.Ex2.m1.1.1" mathvariant="normal" xref="S3.Ex2.m1.1.1.cmml">…</mi><mo id="S3.Ex2.m1.4.4.3.3.7" xref="S3.Ex2.m1.4.4.3.4.cmml">,</mo><msub id="S3.Ex2.m1.4.4.3.3.3" xref="S3.Ex2.m1.4.4.3.3.3.cmml"><mi id="S3.Ex2.m1.4.4.3.3.3.2" xref="S3.Ex2.m1.4.4.3.3.3.2.cmml">q</mi><mi id="S3.Ex2.m1.4.4.3.3.3.3" xref="S3.Ex2.m1.4.4.3.3.3.3.cmml">t</mi></msub><mo id="S3.Ex2.m1.4.4.3.3.8" stretchy="false" xref="S3.Ex2.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.4b"><apply id="S3.Ex2.m1.4.4.cmml" xref="S3.Ex2.m1.4.4"><eq id="S3.Ex2.m1.4.4.4.cmml" xref="S3.Ex2.m1.4.4.4"></eq><apply id="S3.Ex2.m1.4.4.5.cmml" xref="S3.Ex2.m1.4.4.5"><times id="S3.Ex2.m1.4.4.5.1.cmml" xref="S3.Ex2.m1.4.4.5.1"></times><ci id="S3.Ex2.m1.4.4.5.2.cmml" xref="S3.Ex2.m1.4.4.5.2">𝑐</ci><ci id="S3.Ex2.m1.4.4.5.3.cmml" xref="S3.Ex2.m1.4.4.5.3">𝑜</ci><ci id="S3.Ex2.m1.4.4.5.4.cmml" xref="S3.Ex2.m1.4.4.5.4">𝑛</ci><ci id="S3.Ex2.m1.4.4.5.5.cmml" xref="S3.Ex2.m1.4.4.5.5">𝑡</ci><ci id="S3.Ex2.m1.4.4.5.6.cmml" xref="S3.Ex2.m1.4.4.5.6">𝑒</ci><ci id="S3.Ex2.m1.4.4.5.7.cmml" xref="S3.Ex2.m1.4.4.5.7">𝑥</ci><apply id="S3.Ex2.m1.4.4.5.8.cmml" xref="S3.Ex2.m1.4.4.5.8"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.5.8.1.cmml" xref="S3.Ex2.m1.4.4.5.8">subscript</csymbol><ci id="S3.Ex2.m1.4.4.5.8.2.cmml" xref="S3.Ex2.m1.4.4.5.8.2">𝑡</ci><ci id="S3.Ex2.m1.4.4.5.8.3.cmml" xref="S3.Ex2.m1.4.4.5.8.3">𝑡</ci></apply></apply><vector id="S3.Ex2.m1.4.4.3.4.cmml" xref="S3.Ex2.m1.4.4.3.3"><apply id="S3.Ex2.m1.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.2">𝑞</ci><cn id="S3.Ex2.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.Ex2.m1.2.2.1.1.1.3">0</cn></apply><apply id="S3.Ex2.m1.3.3.2.2.2.cmml" xref="S3.Ex2.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.3.3.2.2.2.1.cmml" xref="S3.Ex2.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.Ex2.m1.3.3.2.2.2.2.cmml" xref="S3.Ex2.m1.3.3.2.2.2.2">𝑞</ci><cn id="S3.Ex2.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.Ex2.m1.3.3.2.2.2.3">1</cn></apply><ci id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1">…</ci><apply id="S3.Ex2.m1.4.4.3.3.3.cmml" xref="S3.Ex2.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.3.3.3.1.cmml" xref="S3.Ex2.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.Ex2.m1.4.4.3.3.3.2.cmml" xref="S3.Ex2.m1.4.4.3.3.3.2">𝑞</ci><ci id="S3.Ex2.m1.4.4.3.3.3.3.cmml" xref="S3.Ex2.m1.4.4.3.3.3.3">𝑡</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.4c">context_{t}=(q_{0},q_{1},...,q_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.4d">italic_c italic_o italic_n italic_t italic_e italic_x italic_t start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.2">where <math alttext="q_{0},q_{1},...,q_{t}\in Q" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.4"><semantics id="S3.SS2.p3.1.m1.4a"><mrow id="S3.SS2.p3.1.m1.4.4" xref="S3.SS2.p3.1.m1.4.4.cmml"><mrow id="S3.SS2.p3.1.m1.4.4.3.3" xref="S3.SS2.p3.1.m1.4.4.3.4.cmml"><msub id="S3.SS2.p3.1.m1.2.2.1.1.1" xref="S3.SS2.p3.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.2.2.1.1.1.2" xref="S3.SS2.p3.1.m1.2.2.1.1.1.2.cmml">q</mi><mn id="S3.SS2.p3.1.m1.2.2.1.1.1.3" xref="S3.SS2.p3.1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.p3.1.m1.4.4.3.3.4" xref="S3.SS2.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p3.1.m1.3.3.2.2.2" xref="S3.SS2.p3.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.3.3.2.2.2.2" xref="S3.SS2.p3.1.m1.3.3.2.2.2.2.cmml">q</mi><mn id="S3.SS2.p3.1.m1.3.3.2.2.2.3" xref="S3.SS2.p3.1.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S3.SS2.p3.1.m1.4.4.3.3.5" xref="S3.SS2.p3.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p3.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p3.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.p3.1.m1.4.4.3.3.6" xref="S3.SS2.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p3.1.m1.4.4.3.3.3" xref="S3.SS2.p3.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS2.p3.1.m1.4.4.3.3.3.2" xref="S3.SS2.p3.1.m1.4.4.3.3.3.2.cmml">q</mi><mi id="S3.SS2.p3.1.m1.4.4.3.3.3.3" xref="S3.SS2.p3.1.m1.4.4.3.3.3.3.cmml">t</mi></msub></mrow><mo id="S3.SS2.p3.1.m1.4.4.4" xref="S3.SS2.p3.1.m1.4.4.4.cmml">∈</mo><mi id="S3.SS2.p3.1.m1.4.4.5" xref="S3.SS2.p3.1.m1.4.4.5.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.4b"><apply id="S3.SS2.p3.1.m1.4.4.cmml" xref="S3.SS2.p3.1.m1.4.4"><in id="S3.SS2.p3.1.m1.4.4.4.cmml" xref="S3.SS2.p3.1.m1.4.4.4"></in><list id="S3.SS2.p3.1.m1.4.4.3.4.cmml" xref="S3.SS2.p3.1.m1.4.4.3.3"><apply id="S3.SS2.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1.2">𝑞</ci><cn id="S3.SS2.p3.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.2.2.1.1.1.3">0</cn></apply><apply id="S3.SS2.p3.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p3.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.3.3.2.2.2.2">𝑞</ci><cn id="S3.SS2.p3.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.3.3.2.2.2.3">1</cn></apply><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">…</ci><apply id="S3.SS2.p3.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p3.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p3.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p3.1.m1.4.4.3.3.3.2">𝑞</ci><ci id="S3.SS2.p3.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.p3.1.m1.4.4.3.3.3.3">𝑡</ci></apply></list><ci id="S3.SS2.p3.1.m1.4.4.5.cmml" xref="S3.SS2.p3.1.m1.4.4.5">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.4c">q_{0},q_{1},...,q_{t}\in Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.4d">italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ italic_Q</annotation></semantics></math> represent the query at corresponding time steps <math alttext="0,1,...t" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.3"><semantics id="S3.SS2.p3.2.m2.3a"><mrow id="S3.SS2.p3.2.m2.3.3.1" xref="S3.SS2.p3.2.m2.3.3.2.cmml"><mn id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">0</mn><mo id="S3.SS2.p3.2.m2.3.3.1.2" xref="S3.SS2.p3.2.m2.3.3.2.cmml">,</mo><mn id="S3.SS2.p3.2.m2.2.2" xref="S3.SS2.p3.2.m2.2.2.cmml">1</mn><mo id="S3.SS2.p3.2.m2.3.3.1.3" xref="S3.SS2.p3.2.m2.3.3.2.cmml">,</mo><mrow id="S3.SS2.p3.2.m2.3.3.1.1" xref="S3.SS2.p3.2.m2.3.3.1.1.cmml"><mi id="S3.SS2.p3.2.m2.3.3.1.1.2" mathvariant="normal" xref="S3.SS2.p3.2.m2.3.3.1.1.2.cmml">…</mi><mo id="S3.SS2.p3.2.m2.3.3.1.1.1" xref="S3.SS2.p3.2.m2.3.3.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p3.2.m2.3.3.1.1.3" xref="S3.SS2.p3.2.m2.3.3.1.1.3.cmml">t</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.3b"><list id="S3.SS2.p3.2.m2.3.3.2.cmml" xref="S3.SS2.p3.2.m2.3.3.1"><cn id="S3.SS2.p3.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p3.2.m2.1.1">0</cn><cn id="S3.SS2.p3.2.m2.2.2.cmml" type="integer" xref="S3.SS2.p3.2.m2.2.2">1</cn><apply id="S3.SS2.p3.2.m2.3.3.1.1.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1"><times id="S3.SS2.p3.2.m2.3.3.1.1.1.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.1"></times><ci id="S3.SS2.p3.2.m2.3.3.1.1.2.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.2">…</ci><ci id="S3.SS2.p3.2.m2.3.3.1.1.3.cmml" xref="S3.SS2.p3.2.m2.3.3.1.1.3">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.3c">0,1,...t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.3d">0 , 1 , … italic_t</annotation></semantics></math>.
With this modeling, we are able to map users’ current state as a sequence of nodes or node types and map them into the KG, which serves as a foundation for recommending queries for further exploration.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.3">To model of the goal of an information seeking process (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i5" title="Item C.5 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span></a>), we extract the one-hop neighbors of the entities mentioned in the user’s initial query from the KG, assuming the initial query reflects the primary objective of their information search.
In other words,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Subgraph_{Q}=\bigcup_{n_{i}\in{n_{1},n_{2},..,n_{k}}}Neighbor(n_{i})" class="ltx_math_unparsed" display="block" id="S3.Ex3.m1.1"><semantics id="S3.Ex3.m1.1a"><mrow id="S3.Ex3.m1.1.1"><mrow id="S3.Ex3.m1.1.1.3"><mi id="S3.Ex3.m1.1.1.3.2">S</mi><mo id="S3.Ex3.m1.1.1.3.1">⁢</mo><mi id="S3.Ex3.m1.1.1.3.3">u</mi><mo id="S3.Ex3.m1.1.1.3.1a">⁢</mo><mi id="S3.Ex3.m1.1.1.3.4">b</mi><mo id="S3.Ex3.m1.1.1.3.1b">⁢</mo><mi id="S3.Ex3.m1.1.1.3.5">g</mi><mo id="S3.Ex3.m1.1.1.3.1c">⁢</mo><mi id="S3.Ex3.m1.1.1.3.6">r</mi><mo id="S3.Ex3.m1.1.1.3.1d">⁢</mo><mi id="S3.Ex3.m1.1.1.3.7">a</mi><mo id="S3.Ex3.m1.1.1.3.1e">⁢</mo><mi id="S3.Ex3.m1.1.1.3.8">p</mi><mo id="S3.Ex3.m1.1.1.3.1f">⁢</mo><msub id="S3.Ex3.m1.1.1.3.9"><mi id="S3.Ex3.m1.1.1.3.9.2">h</mi><mi id="S3.Ex3.m1.1.1.3.9.3">Q</mi></msub></mrow><mo id="S3.Ex3.m1.1.1.2" rspace="0.111em">=</mo><mrow id="S3.Ex3.m1.1.1.1"><munder id="S3.Ex3.m1.1.1.1.2"><mo id="S3.Ex3.m1.1.1.1.2.2" movablelimits="false">⋃</mo><mrow id="S3.Ex3.m1.1.1.1.2.3"><msub id="S3.Ex3.m1.1.1.1.2.3.1"><mi id="S3.Ex3.m1.1.1.1.2.3.1.2">n</mi><mi id="S3.Ex3.m1.1.1.1.2.3.1.3">i</mi></msub><mo id="S3.Ex3.m1.1.1.1.2.3.2">∈</mo><msub id="S3.Ex3.m1.1.1.1.2.3.3"><mi id="S3.Ex3.m1.1.1.1.2.3.3.2">n</mi><mn id="S3.Ex3.m1.1.1.1.2.3.3.3">1</mn></msub><mo id="S3.Ex3.m1.1.1.1.2.3.4">,</mo><msub id="S3.Ex3.m1.1.1.1.2.3.5"><mi id="S3.Ex3.m1.1.1.1.2.3.5.2">n</mi><mn id="S3.Ex3.m1.1.1.1.2.3.5.3">2</mn></msub><mo id="S3.Ex3.m1.1.1.1.2.3.6">,</mo><mo id="S3.Ex3.m1.1.1.1.2.3.7" lspace="0em" rspace="0.0835em">.</mo><mo id="S3.Ex3.m1.1.1.1.2.3.8" lspace="0.0835em" rspace="0.167em">.</mo><mo id="S3.Ex3.m1.1.1.1.2.3.9">,</mo><msub id="S3.Ex3.m1.1.1.1.2.3.10"><mi id="S3.Ex3.m1.1.1.1.2.3.10.2">n</mi><mi id="S3.Ex3.m1.1.1.1.2.3.10.3">k</mi></msub></mrow></munder><mrow id="S3.Ex3.m1.1.1.1.1"><mi id="S3.Ex3.m1.1.1.1.1.3">N</mi><mo id="S3.Ex3.m1.1.1.1.1.2">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.4">e</mi><mo id="S3.Ex3.m1.1.1.1.1.2a">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.5">i</mi><mo id="S3.Ex3.m1.1.1.1.1.2b">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.6">g</mi><mo id="S3.Ex3.m1.1.1.1.1.2c">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.7">h</mi><mo id="S3.Ex3.m1.1.1.1.1.2d">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.8">b</mi><mo id="S3.Ex3.m1.1.1.1.1.2e">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.9">o</mi><mo id="S3.Ex3.m1.1.1.1.1.2f">⁢</mo><mi id="S3.Ex3.m1.1.1.1.1.10">r</mi><mo id="S3.Ex3.m1.1.1.1.1.2g">⁢</mo><mrow id="S3.Ex3.m1.1.1.1.1.1.1"><mo id="S3.Ex3.m1.1.1.1.1.1.1.2" stretchy="false">(</mo><msub id="S3.Ex3.m1.1.1.1.1.1.1.1"><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.2">n</mi><mi id="S3.Ex3.m1.1.1.1.1.1.1.1.3">i</mi></msub><mo id="S3.Ex3.m1.1.1.1.1.1.1.3" stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.Ex3.m1.1b">Subgraph_{Q}=\bigcup_{n_{i}\in{n_{1},n_{2},..,n_{k}}}Neighbor(n_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex3.m1.1c">italic_S italic_u italic_b italic_g italic_r italic_a italic_p italic_h start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT = ⋃ start_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , . . , italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_N italic_e italic_i italic_g italic_h italic_b italic_o italic_r ( italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.2">where <math alttext="{n_{1},n_{2},n_{k}}\in N" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.3"><semantics id="S3.SS2.p4.1.m1.3a"><mrow id="S3.SS2.p4.1.m1.3.3" xref="S3.SS2.p4.1.m1.3.3.cmml"><mrow id="S3.SS2.p4.1.m1.3.3.3.3" xref="S3.SS2.p4.1.m1.3.3.3.4.cmml"><msub id="S3.SS2.p4.1.m1.1.1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="S3.SS2.p4.1.m1.1.1.1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p4.1.m1.3.3.3.3.4" xref="S3.SS2.p4.1.m1.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.1.m1.2.2.2.2.2" xref="S3.SS2.p4.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p4.1.m1.2.2.2.2.2.2" xref="S3.SS2.p4.1.m1.2.2.2.2.2.2.cmml">n</mi><mn id="S3.SS2.p4.1.m1.2.2.2.2.2.3" xref="S3.SS2.p4.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p4.1.m1.3.3.3.3.5" xref="S3.SS2.p4.1.m1.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.1.m1.3.3.3.3.3" xref="S3.SS2.p4.1.m1.3.3.3.3.3.cmml"><mi id="S3.SS2.p4.1.m1.3.3.3.3.3.2" xref="S3.SS2.p4.1.m1.3.3.3.3.3.2.cmml">n</mi><mi id="S3.SS2.p4.1.m1.3.3.3.3.3.3" xref="S3.SS2.p4.1.m1.3.3.3.3.3.3.cmml">k</mi></msub></mrow><mo id="S3.SS2.p4.1.m1.3.3.4" xref="S3.SS2.p4.1.m1.3.3.4.cmml">∈</mo><mi id="S3.SS2.p4.1.m1.3.3.5" xref="S3.SS2.p4.1.m1.3.3.5.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.3b"><apply id="S3.SS2.p4.1.m1.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3"><in id="S3.SS2.p4.1.m1.3.3.4.cmml" xref="S3.SS2.p4.1.m1.3.3.4"></in><list id="S3.SS2.p4.1.m1.3.3.3.4.cmml" xref="S3.SS2.p4.1.m1.3.3.3.3"><apply id="S3.SS2.p4.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.1.1.1.2">𝑛</ci><cn id="S3.SS2.p4.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p4.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p4.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p4.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.2.2.2.2.2.2">𝑛</ci><cn id="S3.SS2.p4.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="S3.SS2.p4.1.m1.2.2.2.2.2.3">2</cn></apply><apply id="S3.SS2.p4.1.m1.3.3.3.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.3.3.3.1.cmml" xref="S3.SS2.p4.1.m1.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p4.1.m1.3.3.3.3.3.2.cmml" xref="S3.SS2.p4.1.m1.3.3.3.3.3.2">𝑛</ci><ci id="S3.SS2.p4.1.m1.3.3.3.3.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3.3.3.3.3">𝑘</ci></apply></list><ci id="S3.SS2.p4.1.m1.3.3.5.cmml" xref="S3.SS2.p4.1.m1.3.3.5">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.3c">{n_{1},n_{2},n_{k}}\in N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.3d">italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ italic_N</annotation></semantics></math> are the entities mentioned by the users in the initial query, <math alttext="Subgraph_{Q}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">S</mi><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">u</mi><mo id="S3.SS2.p4.2.m2.1.1.1a" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.4" xref="S3.SS2.p4.2.m2.1.1.4.cmml">b</mi><mo id="S3.SS2.p4.2.m2.1.1.1b" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.5" xref="S3.SS2.p4.2.m2.1.1.5.cmml">g</mi><mo id="S3.SS2.p4.2.m2.1.1.1c" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.6" xref="S3.SS2.p4.2.m2.1.1.6.cmml">r</mi><mo id="S3.SS2.p4.2.m2.1.1.1d" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.7" xref="S3.SS2.p4.2.m2.1.1.7.cmml">a</mi><mo id="S3.SS2.p4.2.m2.1.1.1e" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.8" xref="S3.SS2.p4.2.m2.1.1.8.cmml">p</mi><mo id="S3.SS2.p4.2.m2.1.1.1f" xref="S3.SS2.p4.2.m2.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p4.2.m2.1.1.9" xref="S3.SS2.p4.2.m2.1.1.9.cmml"><mi id="S3.SS2.p4.2.m2.1.1.9.2" xref="S3.SS2.p4.2.m2.1.1.9.2.cmml">h</mi><mi id="S3.SS2.p4.2.m2.1.1.9.3" xref="S3.SS2.p4.2.m2.1.1.9.3.cmml">Q</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><times id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></times><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝑆</ci><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">𝑢</ci><ci id="S3.SS2.p4.2.m2.1.1.4.cmml" xref="S3.SS2.p4.2.m2.1.1.4">𝑏</ci><ci id="S3.SS2.p4.2.m2.1.1.5.cmml" xref="S3.SS2.p4.2.m2.1.1.5">𝑔</ci><ci id="S3.SS2.p4.2.m2.1.1.6.cmml" xref="S3.SS2.p4.2.m2.1.1.6">𝑟</ci><ci id="S3.SS2.p4.2.m2.1.1.7.cmml" xref="S3.SS2.p4.2.m2.1.1.7">𝑎</ci><ci id="S3.SS2.p4.2.m2.1.1.8.cmml" xref="S3.SS2.p4.2.m2.1.1.8">𝑝</ci><apply id="S3.SS2.p4.2.m2.1.1.9.cmml" xref="S3.SS2.p4.2.m2.1.1.9"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.9.1.cmml" xref="S3.SS2.p4.2.m2.1.1.9">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.9.2.cmml" xref="S3.SS2.p4.2.m2.1.1.9.2">ℎ</ci><ci id="S3.SS2.p4.2.m2.1.1.9.3.cmml" xref="S3.SS2.p4.2.m2.1.1.9.3">𝑄</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">Subgraph_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_S italic_u italic_b italic_g italic_r italic_a italic_p italic_h start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> is the neighborhood in KG that contains potential subjects for exploration.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Recommendations=\bigcup_{n_{i}\in context\land\{n_{j}|t_{k}\}\in Subgraph_{Q}}%
(n_{i},n_{j}|t_{k})" class="ltx_Math" display="block" id="S3.Ex4.m1.4"><semantics id="S3.Ex4.m1.4a"><mrow id="S3.Ex4.m1.4.4" xref="S3.Ex4.m1.4.4.cmml"><mrow id="S3.Ex4.m1.4.4.4" xref="S3.Ex4.m1.4.4.4.cmml"><mi id="S3.Ex4.m1.4.4.4.2" xref="S3.Ex4.m1.4.4.4.2.cmml">R</mi><mo id="S3.Ex4.m1.4.4.4.1" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.3" xref="S3.Ex4.m1.4.4.4.3.cmml">e</mi><mo id="S3.Ex4.m1.4.4.4.1a" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.4" xref="S3.Ex4.m1.4.4.4.4.cmml">c</mi><mo id="S3.Ex4.m1.4.4.4.1b" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.5" xref="S3.Ex4.m1.4.4.4.5.cmml">o</mi><mo id="S3.Ex4.m1.4.4.4.1c" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.6" xref="S3.Ex4.m1.4.4.4.6.cmml">m</mi><mo id="S3.Ex4.m1.4.4.4.1d" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.7" xref="S3.Ex4.m1.4.4.4.7.cmml">m</mi><mo id="S3.Ex4.m1.4.4.4.1e" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.8" xref="S3.Ex4.m1.4.4.4.8.cmml">e</mi><mo id="S3.Ex4.m1.4.4.4.1f" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.9" xref="S3.Ex4.m1.4.4.4.9.cmml">n</mi><mo id="S3.Ex4.m1.4.4.4.1g" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.10" xref="S3.Ex4.m1.4.4.4.10.cmml">d</mi><mo id="S3.Ex4.m1.4.4.4.1h" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.11" xref="S3.Ex4.m1.4.4.4.11.cmml">a</mi><mo id="S3.Ex4.m1.4.4.4.1i" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.12" xref="S3.Ex4.m1.4.4.4.12.cmml">t</mi><mo id="S3.Ex4.m1.4.4.4.1j" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.13" xref="S3.Ex4.m1.4.4.4.13.cmml">i</mi><mo id="S3.Ex4.m1.4.4.4.1k" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.14" xref="S3.Ex4.m1.4.4.4.14.cmml">o</mi><mo id="S3.Ex4.m1.4.4.4.1l" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.15" xref="S3.Ex4.m1.4.4.4.15.cmml">n</mi><mo id="S3.Ex4.m1.4.4.4.1m" xref="S3.Ex4.m1.4.4.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.4.16" xref="S3.Ex4.m1.4.4.4.16.cmml">s</mi></mrow><mo id="S3.Ex4.m1.4.4.3" rspace="0.111em" xref="S3.Ex4.m1.4.4.3.cmml">=</mo><mrow id="S3.Ex4.m1.4.4.2" xref="S3.Ex4.m1.4.4.2.cmml"><munder id="S3.Ex4.m1.4.4.2.3" xref="S3.Ex4.m1.4.4.2.3.cmml"><mo id="S3.Ex4.m1.4.4.2.3.2" movablelimits="false" rspace="0em" xref="S3.Ex4.m1.4.4.2.3.2.cmml">⋃</mo><mrow id="S3.Ex4.m1.2.2.2" xref="S3.Ex4.m1.2.2.2.cmml"><msub id="S3.Ex4.m1.2.2.2.4" xref="S3.Ex4.m1.2.2.2.4.cmml"><mi id="S3.Ex4.m1.2.2.2.4.2" xref="S3.Ex4.m1.2.2.2.4.2.cmml">n</mi><mi id="S3.Ex4.m1.2.2.2.4.3" xref="S3.Ex4.m1.2.2.2.4.3.cmml">i</mi></msub><mo id="S3.Ex4.m1.2.2.2.5" xref="S3.Ex4.m1.2.2.2.5.cmml">∈</mo><mrow id="S3.Ex4.m1.2.2.2.2" xref="S3.Ex4.m1.2.2.2.2.cmml"><mrow id="S3.Ex4.m1.2.2.2.2.4" xref="S3.Ex4.m1.2.2.2.2.4.cmml"><mi id="S3.Ex4.m1.2.2.2.2.4.2" xref="S3.Ex4.m1.2.2.2.2.4.2.cmml">c</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.3" xref="S3.Ex4.m1.2.2.2.2.4.3.cmml">o</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1a" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.4" xref="S3.Ex4.m1.2.2.2.2.4.4.cmml">n</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1b" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.5" xref="S3.Ex4.m1.2.2.2.2.4.5.cmml">t</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1c" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.6" xref="S3.Ex4.m1.2.2.2.2.4.6.cmml">e</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1d" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.7" xref="S3.Ex4.m1.2.2.2.2.4.7.cmml">x</mi><mo id="S3.Ex4.m1.2.2.2.2.4.1e" xref="S3.Ex4.m1.2.2.2.2.4.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.2.4.8" xref="S3.Ex4.m1.2.2.2.2.4.8.cmml">t</mi></mrow><mo id="S3.Ex4.m1.2.2.2.2.3" xref="S3.Ex4.m1.2.2.2.2.3.cmml">∧</mo><mrow id="S3.Ex4.m1.2.2.2.2.2.2" xref="S3.Ex4.m1.2.2.2.2.2.3.cmml"><mo id="S3.Ex4.m1.2.2.2.2.2.2.3" stretchy="false" xref="S3.Ex4.m1.2.2.2.2.2.3.1.cmml">{</mo><msub id="S3.Ex4.m1.1.1.1.1.1.1.1" xref="S3.Ex4.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex4.m1.1.1.1.1.1.1.1.2" xref="S3.Ex4.m1.1.1.1.1.1.1.1.2.cmml">n</mi><mi id="S3.Ex4.m1.1.1.1.1.1.1.1.3" xref="S3.Ex4.m1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.Ex4.m1.2.2.2.2.2.2.4" lspace="0em" rspace="0em" xref="S3.Ex4.m1.2.2.2.2.2.3.1.cmml">|</mo><msub id="S3.Ex4.m1.2.2.2.2.2.2.2" xref="S3.Ex4.m1.2.2.2.2.2.2.2.cmml"><mi id="S3.Ex4.m1.2.2.2.2.2.2.2.2" xref="S3.Ex4.m1.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.Ex4.m1.2.2.2.2.2.2.2.3" xref="S3.Ex4.m1.2.2.2.2.2.2.2.3.cmml">k</mi></msub><mo id="S3.Ex4.m1.2.2.2.2.2.2.5" stretchy="false" xref="S3.Ex4.m1.2.2.2.2.2.3.1.cmml">}</mo></mrow></mrow><mo id="S3.Ex4.m1.2.2.2.6" xref="S3.Ex4.m1.2.2.2.6.cmml">∈</mo><mrow id="S3.Ex4.m1.2.2.2.7" xref="S3.Ex4.m1.2.2.2.7.cmml"><mi id="S3.Ex4.m1.2.2.2.7.2" xref="S3.Ex4.m1.2.2.2.7.2.cmml">S</mi><mo id="S3.Ex4.m1.2.2.2.7.1" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.3" xref="S3.Ex4.m1.2.2.2.7.3.cmml">u</mi><mo id="S3.Ex4.m1.2.2.2.7.1a" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.4" xref="S3.Ex4.m1.2.2.2.7.4.cmml">b</mi><mo id="S3.Ex4.m1.2.2.2.7.1b" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.5" xref="S3.Ex4.m1.2.2.2.7.5.cmml">g</mi><mo id="S3.Ex4.m1.2.2.2.7.1c" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.6" xref="S3.Ex4.m1.2.2.2.7.6.cmml">r</mi><mo id="S3.Ex4.m1.2.2.2.7.1d" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.7" xref="S3.Ex4.m1.2.2.2.7.7.cmml">a</mi><mo id="S3.Ex4.m1.2.2.2.7.1e" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><mi id="S3.Ex4.m1.2.2.2.7.8" xref="S3.Ex4.m1.2.2.2.7.8.cmml">p</mi><mo id="S3.Ex4.m1.2.2.2.7.1f" xref="S3.Ex4.m1.2.2.2.7.1.cmml">⁢</mo><msub id="S3.Ex4.m1.2.2.2.7.9" xref="S3.Ex4.m1.2.2.2.7.9.cmml"><mi id="S3.Ex4.m1.2.2.2.7.9.2" xref="S3.Ex4.m1.2.2.2.7.9.2.cmml">h</mi><mi id="S3.Ex4.m1.2.2.2.7.9.3" xref="S3.Ex4.m1.2.2.2.7.9.3.cmml">Q</mi></msub></mrow></mrow></munder><mrow id="S3.Ex4.m1.4.4.2.2.2" xref="S3.Ex4.m1.4.4.2.2.3.cmml"><mo id="S3.Ex4.m1.4.4.2.2.2.3" stretchy="false" xref="S3.Ex4.m1.4.4.2.2.3.cmml">(</mo><msub id="S3.Ex4.m1.3.3.1.1.1.1" xref="S3.Ex4.m1.3.3.1.1.1.1.cmml"><mi id="S3.Ex4.m1.3.3.1.1.1.1.2" xref="S3.Ex4.m1.3.3.1.1.1.1.2.cmml">n</mi><mi id="S3.Ex4.m1.3.3.1.1.1.1.3" xref="S3.Ex4.m1.3.3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.Ex4.m1.4.4.2.2.2.4" xref="S3.Ex4.m1.4.4.2.2.3.cmml">,</mo><mrow id="S3.Ex4.m1.4.4.2.2.2.2" xref="S3.Ex4.m1.4.4.2.2.2.2.cmml"><msub id="S3.Ex4.m1.4.4.2.2.2.2.2" xref="S3.Ex4.m1.4.4.2.2.2.2.2.cmml"><mi id="S3.Ex4.m1.4.4.2.2.2.2.2.2" xref="S3.Ex4.m1.4.4.2.2.2.2.2.2.cmml">n</mi><mi id="S3.Ex4.m1.4.4.2.2.2.2.2.3" xref="S3.Ex4.m1.4.4.2.2.2.2.2.3.cmml">j</mi></msub><mo fence="false" id="S3.Ex4.m1.4.4.2.2.2.2.1" xref="S3.Ex4.m1.4.4.2.2.2.2.1.cmml">|</mo><msub id="S3.Ex4.m1.4.4.2.2.2.2.3" xref="S3.Ex4.m1.4.4.2.2.2.2.3.cmml"><mi id="S3.Ex4.m1.4.4.2.2.2.2.3.2" xref="S3.Ex4.m1.4.4.2.2.2.2.3.2.cmml">t</mi><mi id="S3.Ex4.m1.4.4.2.2.2.2.3.3" xref="S3.Ex4.m1.4.4.2.2.2.2.3.3.cmml">k</mi></msub></mrow><mo id="S3.Ex4.m1.4.4.2.2.2.5" stretchy="false" xref="S3.Ex4.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex4.m1.4b"><apply id="S3.Ex4.m1.4.4.cmml" xref="S3.Ex4.m1.4.4"><eq id="S3.Ex4.m1.4.4.3.cmml" xref="S3.Ex4.m1.4.4.3"></eq><apply id="S3.Ex4.m1.4.4.4.cmml" xref="S3.Ex4.m1.4.4.4"><times id="S3.Ex4.m1.4.4.4.1.cmml" xref="S3.Ex4.m1.4.4.4.1"></times><ci id="S3.Ex4.m1.4.4.4.2.cmml" xref="S3.Ex4.m1.4.4.4.2">𝑅</ci><ci id="S3.Ex4.m1.4.4.4.3.cmml" xref="S3.Ex4.m1.4.4.4.3">𝑒</ci><ci id="S3.Ex4.m1.4.4.4.4.cmml" xref="S3.Ex4.m1.4.4.4.4">𝑐</ci><ci id="S3.Ex4.m1.4.4.4.5.cmml" xref="S3.Ex4.m1.4.4.4.5">𝑜</ci><ci id="S3.Ex4.m1.4.4.4.6.cmml" xref="S3.Ex4.m1.4.4.4.6">𝑚</ci><ci id="S3.Ex4.m1.4.4.4.7.cmml" xref="S3.Ex4.m1.4.4.4.7">𝑚</ci><ci id="S3.Ex4.m1.4.4.4.8.cmml" xref="S3.Ex4.m1.4.4.4.8">𝑒</ci><ci id="S3.Ex4.m1.4.4.4.9.cmml" xref="S3.Ex4.m1.4.4.4.9">𝑛</ci><ci id="S3.Ex4.m1.4.4.4.10.cmml" xref="S3.Ex4.m1.4.4.4.10">𝑑</ci><ci id="S3.Ex4.m1.4.4.4.11.cmml" xref="S3.Ex4.m1.4.4.4.11">𝑎</ci><ci id="S3.Ex4.m1.4.4.4.12.cmml" xref="S3.Ex4.m1.4.4.4.12">𝑡</ci><ci id="S3.Ex4.m1.4.4.4.13.cmml" xref="S3.Ex4.m1.4.4.4.13">𝑖</ci><ci id="S3.Ex4.m1.4.4.4.14.cmml" xref="S3.Ex4.m1.4.4.4.14">𝑜</ci><ci id="S3.Ex4.m1.4.4.4.15.cmml" xref="S3.Ex4.m1.4.4.4.15">𝑛</ci><ci id="S3.Ex4.m1.4.4.4.16.cmml" xref="S3.Ex4.m1.4.4.4.16">𝑠</ci></apply><apply id="S3.Ex4.m1.4.4.2.cmml" xref="S3.Ex4.m1.4.4.2"><apply id="S3.Ex4.m1.4.4.2.3.cmml" xref="S3.Ex4.m1.4.4.2.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.2.3.1.cmml" xref="S3.Ex4.m1.4.4.2.3">subscript</csymbol><union id="S3.Ex4.m1.4.4.2.3.2.cmml" xref="S3.Ex4.m1.4.4.2.3.2"></union><apply id="S3.Ex4.m1.2.2.2.cmml" xref="S3.Ex4.m1.2.2.2"><and id="S3.Ex4.m1.2.2.2a.cmml" xref="S3.Ex4.m1.2.2.2"></and><apply id="S3.Ex4.m1.2.2.2b.cmml" xref="S3.Ex4.m1.2.2.2"><in id="S3.Ex4.m1.2.2.2.5.cmml" xref="S3.Ex4.m1.2.2.2.5"></in><apply id="S3.Ex4.m1.2.2.2.4.cmml" xref="S3.Ex4.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.Ex4.m1.2.2.2.4.1.cmml" xref="S3.Ex4.m1.2.2.2.4">subscript</csymbol><ci id="S3.Ex4.m1.2.2.2.4.2.cmml" xref="S3.Ex4.m1.2.2.2.4.2">𝑛</ci><ci id="S3.Ex4.m1.2.2.2.4.3.cmml" xref="S3.Ex4.m1.2.2.2.4.3">𝑖</ci></apply><apply id="S3.Ex4.m1.2.2.2.2.cmml" xref="S3.Ex4.m1.2.2.2.2"><and id="S3.Ex4.m1.2.2.2.2.3.cmml" xref="S3.Ex4.m1.2.2.2.2.3"></and><apply id="S3.Ex4.m1.2.2.2.2.4.cmml" xref="S3.Ex4.m1.2.2.2.2.4"><times id="S3.Ex4.m1.2.2.2.2.4.1.cmml" xref="S3.Ex4.m1.2.2.2.2.4.1"></times><ci id="S3.Ex4.m1.2.2.2.2.4.2.cmml" xref="S3.Ex4.m1.2.2.2.2.4.2">𝑐</ci><ci id="S3.Ex4.m1.2.2.2.2.4.3.cmml" xref="S3.Ex4.m1.2.2.2.2.4.3">𝑜</ci><ci id="S3.Ex4.m1.2.2.2.2.4.4.cmml" xref="S3.Ex4.m1.2.2.2.2.4.4">𝑛</ci><ci id="S3.Ex4.m1.2.2.2.2.4.5.cmml" xref="S3.Ex4.m1.2.2.2.2.4.5">𝑡</ci><ci id="S3.Ex4.m1.2.2.2.2.4.6.cmml" xref="S3.Ex4.m1.2.2.2.2.4.6">𝑒</ci><ci id="S3.Ex4.m1.2.2.2.2.4.7.cmml" xref="S3.Ex4.m1.2.2.2.2.4.7">𝑥</ci><ci id="S3.Ex4.m1.2.2.2.2.4.8.cmml" xref="S3.Ex4.m1.2.2.2.2.4.8">𝑡</ci></apply><apply id="S3.Ex4.m1.2.2.2.2.2.3.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2"><csymbol cd="latexml" id="S3.Ex4.m1.2.2.2.2.2.3.1.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2.3">conditional-set</csymbol><apply id="S3.Ex4.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.1.2">𝑛</ci><ci id="S3.Ex4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.Ex4.m1.2.2.2.2.2.2.2.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex4.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2.2.2">𝑡</ci><ci id="S3.Ex4.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.Ex4.m1.2.2.2.2.2.2.2.3">𝑘</ci></apply></apply></apply></apply><apply id="S3.Ex4.m1.2.2.2c.cmml" xref="S3.Ex4.m1.2.2.2"><in id="S3.Ex4.m1.2.2.2.6.cmml" xref="S3.Ex4.m1.2.2.2.6"></in><share href="https://arxiv.org/html/2407.13598v1#S3.Ex4.m1.2.2.2.2.cmml" id="S3.Ex4.m1.2.2.2d.cmml" xref="S3.Ex4.m1.2.2.2"></share><apply id="S3.Ex4.m1.2.2.2.7.cmml" xref="S3.Ex4.m1.2.2.2.7"><times id="S3.Ex4.m1.2.2.2.7.1.cmml" xref="S3.Ex4.m1.2.2.2.7.1"></times><ci id="S3.Ex4.m1.2.2.2.7.2.cmml" xref="S3.Ex4.m1.2.2.2.7.2">𝑆</ci><ci id="S3.Ex4.m1.2.2.2.7.3.cmml" xref="S3.Ex4.m1.2.2.2.7.3">𝑢</ci><ci id="S3.Ex4.m1.2.2.2.7.4.cmml" xref="S3.Ex4.m1.2.2.2.7.4">𝑏</ci><ci id="S3.Ex4.m1.2.2.2.7.5.cmml" xref="S3.Ex4.m1.2.2.2.7.5">𝑔</ci><ci id="S3.Ex4.m1.2.2.2.7.6.cmml" xref="S3.Ex4.m1.2.2.2.7.6">𝑟</ci><ci id="S3.Ex4.m1.2.2.2.7.7.cmml" xref="S3.Ex4.m1.2.2.2.7.7">𝑎</ci><ci id="S3.Ex4.m1.2.2.2.7.8.cmml" xref="S3.Ex4.m1.2.2.2.7.8">𝑝</ci><apply id="S3.Ex4.m1.2.2.2.7.9.cmml" xref="S3.Ex4.m1.2.2.2.7.9"><csymbol cd="ambiguous" id="S3.Ex4.m1.2.2.2.7.9.1.cmml" xref="S3.Ex4.m1.2.2.2.7.9">subscript</csymbol><ci id="S3.Ex4.m1.2.2.2.7.9.2.cmml" xref="S3.Ex4.m1.2.2.2.7.9.2">ℎ</ci><ci id="S3.Ex4.m1.2.2.2.7.9.3.cmml" xref="S3.Ex4.m1.2.2.2.7.9.3">𝑄</ci></apply></apply></apply></apply></apply><interval closure="open" id="S3.Ex4.m1.4.4.2.2.3.cmml" xref="S3.Ex4.m1.4.4.2.2.2"><apply id="S3.Ex4.m1.3.3.1.1.1.1.cmml" xref="S3.Ex4.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex4.m1.3.3.1.1.1.1.1.cmml" xref="S3.Ex4.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.Ex4.m1.3.3.1.1.1.1.2.cmml" xref="S3.Ex4.m1.3.3.1.1.1.1.2">𝑛</ci><ci id="S3.Ex4.m1.3.3.1.1.1.1.3.cmml" xref="S3.Ex4.m1.3.3.1.1.1.1.3">𝑖</ci></apply><apply id="S3.Ex4.m1.4.4.2.2.2.2.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2"><csymbol cd="latexml" id="S3.Ex4.m1.4.4.2.2.2.2.1.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.1">conditional</csymbol><apply id="S3.Ex4.m1.4.4.2.2.2.2.2.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.2.2.2.2.2.1.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex4.m1.4.4.2.2.2.2.2.2.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.2.2">𝑛</ci><ci id="S3.Ex4.m1.4.4.2.2.2.2.2.3.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.2.3">𝑗</ci></apply><apply id="S3.Ex4.m1.4.4.2.2.2.2.3.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.2.2.2.2.3.1.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.3">subscript</csymbol><ci id="S3.Ex4.m1.4.4.2.2.2.2.3.2.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.3.2">𝑡</ci><ci id="S3.Ex4.m1.4.4.2.2.2.2.3.3.cmml" xref="S3.Ex4.m1.4.4.2.2.2.2.3.3">𝑘</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex4.m1.4c">Recommendations=\bigcup_{n_{i}\in context\land\{n_{j}|t_{k}\}\in Subgraph_{Q}}%
(n_{i},n_{j}|t_{k})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex4.m1.4d">italic_R italic_e italic_c italic_o italic_m italic_m italic_e italic_n italic_d italic_a italic_t italic_i italic_o italic_n italic_s = ⋃ start_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_c italic_o italic_n italic_t italic_e italic_x italic_t ∧ { italic_n start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } ∈ italic_S italic_u italic_b italic_g italic_r italic_a italic_p italic_h start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.4">We then use a rule-based template to convert the candidate queries into natural language questions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">This recommendation mechanism may not always align with unique goal of individual users in their information seeking.
For example, users may only care about the benefits of vitamin E but not its physiology aspect, even though both aspects are treated as equally important in the KG.
To address this issue, we update the recommendation pool based on two types of user feedback. First, users can remove recommendations that don’t capture their interest. Second, they can pose new, highly relevant questions that are not in the recommendations.
The recommendation pool is dynamically updated, removing these less relevant queries and incorporating new suggestions by updating the <math alttext="Sgubgraph_{Q}" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mrow id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml">S</mi><mo id="S3.SS2.p5.1.m1.1.1.1" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">g</mi><mo id="S3.SS2.p5.1.m1.1.1.1a" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.4" xref="S3.SS2.p5.1.m1.1.1.4.cmml">u</mi><mo id="S3.SS2.p5.1.m1.1.1.1b" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.5" xref="S3.SS2.p5.1.m1.1.1.5.cmml">b</mi><mo id="S3.SS2.p5.1.m1.1.1.1c" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.6" xref="S3.SS2.p5.1.m1.1.1.6.cmml">g</mi><mo id="S3.SS2.p5.1.m1.1.1.1d" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.7" xref="S3.SS2.p5.1.m1.1.1.7.cmml">r</mi><mo id="S3.SS2.p5.1.m1.1.1.1e" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.8" xref="S3.SS2.p5.1.m1.1.1.8.cmml">a</mi><mo id="S3.SS2.p5.1.m1.1.1.1f" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p5.1.m1.1.1.9" xref="S3.SS2.p5.1.m1.1.1.9.cmml">p</mi><mo id="S3.SS2.p5.1.m1.1.1.1g" xref="S3.SS2.p5.1.m1.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p5.1.m1.1.1.10" xref="S3.SS2.p5.1.m1.1.1.10.cmml"><mi id="S3.SS2.p5.1.m1.1.1.10.2" xref="S3.SS2.p5.1.m1.1.1.10.2.cmml">h</mi><mi id="S3.SS2.p5.1.m1.1.1.10.3" xref="S3.SS2.p5.1.m1.1.1.10.3.cmml">Q</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><times id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1.1"></times><ci id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2">𝑆</ci><ci id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">𝑔</ci><ci id="S3.SS2.p5.1.m1.1.1.4.cmml" xref="S3.SS2.p5.1.m1.1.1.4">𝑢</ci><ci id="S3.SS2.p5.1.m1.1.1.5.cmml" xref="S3.SS2.p5.1.m1.1.1.5">𝑏</ci><ci id="S3.SS2.p5.1.m1.1.1.6.cmml" xref="S3.SS2.p5.1.m1.1.1.6">𝑔</ci><ci id="S3.SS2.p5.1.m1.1.1.7.cmml" xref="S3.SS2.p5.1.m1.1.1.7">𝑟</ci><ci id="S3.SS2.p5.1.m1.1.1.8.cmml" xref="S3.SS2.p5.1.m1.1.1.8">𝑎</ci><ci id="S3.SS2.p5.1.m1.1.1.9.cmml" xref="S3.SS2.p5.1.m1.1.1.9">𝑝</ci><apply id="S3.SS2.p5.1.m1.1.1.10.cmml" xref="S3.SS2.p5.1.m1.1.1.10"><csymbol cd="ambiguous" id="S3.SS2.p5.1.m1.1.1.10.1.cmml" xref="S3.SS2.p5.1.m1.1.1.10">subscript</csymbol><ci id="S3.SS2.p5.1.m1.1.1.10.2.cmml" xref="S3.SS2.p5.1.m1.1.1.10.2">ℎ</ci><ci id="S3.SS2.p5.1.m1.1.1.10.3.cmml" xref="S3.SS2.p5.1.m1.1.1.10.3">𝑄</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">Sgubgraph_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_S italic_g italic_u italic_b italic_g italic_r italic_a italic_p italic_h start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> with new entities in user-added questions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Visual Interface</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, the interface of <span class="ltx_ERROR undefined" id="S4.p1.1.1">\name</span> consists of three main components, a <span class="ltx_text ltx_font_italic" id="S4.p1.1.2">Text Dialogue</span> (B), a <span class="ltx_text ltx_font_italic" id="S4.p1.1.3">Graphical Explorer</span> (C), and a <span class="ltx_text ltx_font_italic" id="S4.p1.1.4">Navigator</span> (D).
The <span class="ltx_text ltx_font_italic" id="S4.p1.1.5">Text Dialogue</span> presents the text response to the current query, highlighting related entities and their relations for seamless integration with the <span class="ltx_text ltx_font_italic" id="S4.p1.1.6">Graph Explorer</span>.
The <span class="ltx_text ltx_font_italic" id="S4.p1.1.7">Graph Explorer</span> not only represents the text responses as graphical representations but also enables easy validation of these responses by matching the information with evidence in the KG.
Previous exploration is also summarized in the <span class="ltx_text ltx_font_italic" id="S4.p1.1.8">Graph Explorer</span>, enabling users to easily connect the current query to previous explorations and next-step recommendations.
The <span class="ltx_text ltx_font_italic" id="S4.p1.1.9">Graph Explorer</span> is updated according to the <span class="ltx_text ltx_font_italic" id="S4.p1.1.10">Navigator</span> module.
The <span class="ltx_text ltx_font_italic" id="S4.p1.1.11">Navigator</span> allows users to revisit previous queries, gauge their progress in exploration, and submit queries based on recommendations.
Although we describe the interface as three separate modules for clarity, they are seamlessly integrated with one another.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Information Seeking with <span class="ltx_ERROR undefined" id="S4.SS1.1.1">\name</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We introduce the components and interactions in <span class="ltx_ERROR undefined" id="S4.SS1.p1.1.1">\name</span>  demonstrating how it can guide users in information seeking and solve the design challenges.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Connecting LLM with KG</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">To start with, users will post a question about an object of interest, such as <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p1.1.1">“what are the benefits of taking vitamin D?”</span>.
As outlined in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.SS1" title="3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>, we extract triples (<span class="ltx_ERROR undefined" id="S4.SS1.SSS1.p1.1.2">\eg</span>, entities and their relationships) from the GPT outputs and match them with KG data.
During the streaming generation process, identified entities are highlighted in gray and their relations are underlined (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>(B)).</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">Upon successfully matching these entities within the KG, the identified entities and their relations are updated to <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p2.1.1">Graph Explorer</span> as a node-link diagram.
We apply color coding to indicate differentiate node types, such as drugs, diseases, and physiological aspects.
Entities in the Text Dialogue and the Graph Explorer share the same color coding and are synchronized, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>(C).
Hovering over an entity in one view will highlight the corresponding entity in the other view.
This coordination between <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p2.1.2">Text Dialogue</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p2.1.3">Graph Explorer</span> enables an intuitive presentation of nonlinear entity relations (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i1" title="Item C.1 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.1</span></span></a>) and provides a concise representation of the main message in potentially long texts (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i3" title="Item C.3 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.3</span></span></a>).

Unlike Graphologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib17" title="">17</a>]</cite>, we choose not to update the graph simultaneously for two main reasons.
First, the sheer size of the KG may introduce delays.
Second, the complex structure of responses to medical queries makes simultaneous monitoring of both text and graph potentially overwhelming for users.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p3">
<p class="ltx_p" id="S4.SS1.SSS1.p3.1">Users can click on the node in <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS1.p3.1.1">Graph Explorer</span> to highlight the corresponding entities in the GPT outputs.
Users can also move nodes through drag-and-drop to better organize the node layout.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S4.F5.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.14.6.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F5.10.5" style="font-size:90%;">Edge labels<span class="ltx_text ltx_font_medium" id="S4.F5.10.5.5">. <span class="ltx_ERROR undefined" id="S4.F5.10.5.5.1">\name</span> suggests three different edge labels, support, relevant, and unsure, based on the matching between KG and LLM. <math alttext="sim(n_{1},n_{1}^{\prime})" class="ltx_Math" display="inline" id="S4.F5.6.1.1.m1.2"><semantics id="S4.F5.6.1.1.m1.2b"><mrow id="S4.F5.6.1.1.m1.2.2" xref="S4.F5.6.1.1.m1.2.2.cmml"><mi id="S4.F5.6.1.1.m1.2.2.4" xref="S4.F5.6.1.1.m1.2.2.4.cmml">s</mi><mo id="S4.F5.6.1.1.m1.2.2.3" xref="S4.F5.6.1.1.m1.2.2.3.cmml">⁢</mo><mi id="S4.F5.6.1.1.m1.2.2.5" xref="S4.F5.6.1.1.m1.2.2.5.cmml">i</mi><mo id="S4.F5.6.1.1.m1.2.2.3b" xref="S4.F5.6.1.1.m1.2.2.3.cmml">⁢</mo><mi id="S4.F5.6.1.1.m1.2.2.6" xref="S4.F5.6.1.1.m1.2.2.6.cmml">m</mi><mo id="S4.F5.6.1.1.m1.2.2.3c" xref="S4.F5.6.1.1.m1.2.2.3.cmml">⁢</mo><mrow id="S4.F5.6.1.1.m1.2.2.2.2" xref="S4.F5.6.1.1.m1.2.2.2.3.cmml"><mo id="S4.F5.6.1.1.m1.2.2.2.2.3" stretchy="false" xref="S4.F5.6.1.1.m1.2.2.2.3.cmml">(</mo><msub id="S4.F5.6.1.1.m1.1.1.1.1.1" xref="S4.F5.6.1.1.m1.1.1.1.1.1.cmml"><mi id="S4.F5.6.1.1.m1.1.1.1.1.1.2" xref="S4.F5.6.1.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="S4.F5.6.1.1.m1.1.1.1.1.1.3" xref="S4.F5.6.1.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.F5.6.1.1.m1.2.2.2.2.4" xref="S4.F5.6.1.1.m1.2.2.2.3.cmml">,</mo><msubsup id="S4.F5.6.1.1.m1.2.2.2.2.2" xref="S4.F5.6.1.1.m1.2.2.2.2.2.cmml"><mi id="S4.F5.6.1.1.m1.2.2.2.2.2.2.2" xref="S4.F5.6.1.1.m1.2.2.2.2.2.2.2.cmml">n</mi><mn id="S4.F5.6.1.1.m1.2.2.2.2.2.2.3" xref="S4.F5.6.1.1.m1.2.2.2.2.2.2.3.cmml">1</mn><mo id="S4.F5.6.1.1.m1.2.2.2.2.2.3" xref="S4.F5.6.1.1.m1.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="S4.F5.6.1.1.m1.2.2.2.2.5" stretchy="false" xref="S4.F5.6.1.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.6.1.1.m1.2c"><apply id="S4.F5.6.1.1.m1.2.2.cmml" xref="S4.F5.6.1.1.m1.2.2"><times id="S4.F5.6.1.1.m1.2.2.3.cmml" xref="S4.F5.6.1.1.m1.2.2.3"></times><ci id="S4.F5.6.1.1.m1.2.2.4.cmml" xref="S4.F5.6.1.1.m1.2.2.4">𝑠</ci><ci id="S4.F5.6.1.1.m1.2.2.5.cmml" xref="S4.F5.6.1.1.m1.2.2.5">𝑖</ci><ci id="S4.F5.6.1.1.m1.2.2.6.cmml" xref="S4.F5.6.1.1.m1.2.2.6">𝑚</ci><interval closure="open" id="S4.F5.6.1.1.m1.2.2.2.3.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2"><apply id="S4.F5.6.1.1.m1.1.1.1.1.1.cmml" xref="S4.F5.6.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F5.6.1.1.m1.1.1.1.1.1.1.cmml" xref="S4.F5.6.1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.F5.6.1.1.m1.1.1.1.1.1.2.cmml" xref="S4.F5.6.1.1.m1.1.1.1.1.1.2">𝑛</ci><cn id="S4.F5.6.1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S4.F5.6.1.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S4.F5.6.1.1.m1.2.2.2.2.2.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.F5.6.1.1.m1.2.2.2.2.2.1.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2">superscript</csymbol><apply id="S4.F5.6.1.1.m1.2.2.2.2.2.2.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.F5.6.1.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.F5.6.1.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2.2.2">𝑛</ci><cn id="S4.F5.6.1.1.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.F5.6.1.1.m1.2.2.2.2.2.2.3">1</cn></apply><ci id="S4.F5.6.1.1.m1.2.2.2.2.2.3.cmml" xref="S4.F5.6.1.1.m1.2.2.2.2.2.3">′</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.6.1.1.m1.2d">sim(n_{1},n_{1}^{\prime})</annotation><annotation encoding="application/x-llamapun" id="S4.F5.6.1.1.m1.2e">italic_s italic_i italic_m ( italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )</annotation></semantics></math> indicates the cosine similarity between the the entity identified in LLM (<math alttext="n_{1}" class="ltx_Math" display="inline" id="S4.F5.7.2.2.m2.1"><semantics id="S4.F5.7.2.2.m2.1b"><msub id="S4.F5.7.2.2.m2.1.1" xref="S4.F5.7.2.2.m2.1.1.cmml"><mi id="S4.F5.7.2.2.m2.1.1.2" xref="S4.F5.7.2.2.m2.1.1.2.cmml">n</mi><mn id="S4.F5.7.2.2.m2.1.1.3" xref="S4.F5.7.2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F5.7.2.2.m2.1c"><apply id="S4.F5.7.2.2.m2.1.1.cmml" xref="S4.F5.7.2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F5.7.2.2.m2.1.1.1.cmml" xref="S4.F5.7.2.2.m2.1.1">subscript</csymbol><ci id="S4.F5.7.2.2.m2.1.1.2.cmml" xref="S4.F5.7.2.2.m2.1.1.2">𝑛</ci><cn id="S4.F5.7.2.2.m2.1.1.3.cmml" type="integer" xref="S4.F5.7.2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.7.2.2.m2.1d">n_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.7.2.2.m2.1e">italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>) and the nodes in KG (<math alttext="n_{1}^{\prime}" class="ltx_Math" display="inline" id="S4.F5.8.3.3.m3.1"><semantics id="S4.F5.8.3.3.m3.1b"><msubsup id="S4.F5.8.3.3.m3.1.1" xref="S4.F5.8.3.3.m3.1.1.cmml"><mi id="S4.F5.8.3.3.m3.1.1.2.2" xref="S4.F5.8.3.3.m3.1.1.2.2.cmml">n</mi><mn id="S4.F5.8.3.3.m3.1.1.2.3" xref="S4.F5.8.3.3.m3.1.1.2.3.cmml">1</mn><mo id="S4.F5.8.3.3.m3.1.1.3" xref="S4.F5.8.3.3.m3.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S4.F5.8.3.3.m3.1c"><apply id="S4.F5.8.3.3.m3.1.1.cmml" xref="S4.F5.8.3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.F5.8.3.3.m3.1.1.1.cmml" xref="S4.F5.8.3.3.m3.1.1">superscript</csymbol><apply id="S4.F5.8.3.3.m3.1.1.2.cmml" xref="S4.F5.8.3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.F5.8.3.3.m3.1.1.2.1.cmml" xref="S4.F5.8.3.3.m3.1.1">subscript</csymbol><ci id="S4.F5.8.3.3.m3.1.1.2.2.cmml" xref="S4.F5.8.3.3.m3.1.1.2.2">𝑛</ci><cn id="S4.F5.8.3.3.m3.1.1.2.3.cmml" type="integer" xref="S4.F5.8.3.3.m3.1.1.2.3">1</cn></apply><ci id="S4.F5.8.3.3.m3.1.1.3.cmml" xref="S4.F5.8.3.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.8.3.3.m3.1d">n_{1}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.8.3.3.m3.1e">italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>). <math alttext="\theta_{n}" class="ltx_Math" display="inline" id="S4.F5.9.4.4.m4.1"><semantics id="S4.F5.9.4.4.m4.1b"><msub id="S4.F5.9.4.4.m4.1.1" xref="S4.F5.9.4.4.m4.1.1.cmml"><mi id="S4.F5.9.4.4.m4.1.1.2" xref="S4.F5.9.4.4.m4.1.1.2.cmml">θ</mi><mi id="S4.F5.9.4.4.m4.1.1.3" xref="S4.F5.9.4.4.m4.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F5.9.4.4.m4.1c"><apply id="S4.F5.9.4.4.m4.1.1.cmml" xref="S4.F5.9.4.4.m4.1.1"><csymbol cd="ambiguous" id="S4.F5.9.4.4.m4.1.1.1.cmml" xref="S4.F5.9.4.4.m4.1.1">subscript</csymbol><ci id="S4.F5.9.4.4.m4.1.1.2.cmml" xref="S4.F5.9.4.4.m4.1.1.2">𝜃</ci><ci id="S4.F5.9.4.4.m4.1.1.3.cmml" xref="S4.F5.9.4.4.m4.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.9.4.4.m4.1d">\theta_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.9.4.4.m4.1e">italic_θ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\theta_{r}" class="ltx_Math" display="inline" id="S4.F5.10.5.5.m5.1"><semantics id="S4.F5.10.5.5.m5.1b"><msub id="S4.F5.10.5.5.m5.1.1" xref="S4.F5.10.5.5.m5.1.1.cmml"><mi id="S4.F5.10.5.5.m5.1.1.2" xref="S4.F5.10.5.5.m5.1.1.2.cmml">θ</mi><mi id="S4.F5.10.5.5.m5.1.1.3" xref="S4.F5.10.5.5.m5.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F5.10.5.5.m5.1c"><apply id="S4.F5.10.5.5.m5.1.1.cmml" xref="S4.F5.10.5.5.m5.1.1"><csymbol cd="ambiguous" id="S4.F5.10.5.5.m5.1.1.1.cmml" xref="S4.F5.10.5.5.m5.1.1">subscript</csymbol><ci id="S4.F5.10.5.5.m5.1.1.2.cmml" xref="S4.F5.10.5.5.m5.1.1.2">𝜃</ci><ci id="S4.F5.10.5.5.m5.1.1.3.cmml" xref="S4.F5.10.5.5.m5.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.10.5.5.m5.1d">\theta_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.10.5.5.m5.1e">italic_θ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> are the thresholds for entity and relation matching. </span></span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Verification with Evidence</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">We provide various edge labels and pop-up details in <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p1.1.1">Graph Explorer</span> to aid users in evaluating the quality of a relation (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i2" title="Item C.2 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.2</span></span></a>).
As shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F5" title="In 4.1.1 Connecting LLM with KG ‣ 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>(a), each label consists of three components: the name of the relation, one of three classifications (Support, Relevant, or Unsure), and the number of related literature found in the KG.
Clicking on the label opens a pop-up window that lists the relevant literature and allows users to dive deeper into these evidences, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>(E).</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.3">We classify the quality of the relations as support, relevant, and unsure, based on the matching between KG and LLM (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F5" title="In 4.1.1 Connecting LLM with KG ‣ 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a>(b-c)).
The support label  <svg class="ltx_picture" height="16.95" id="S4.SS1.SSS2.p2.1.pic1" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S4.SS1.SSS2.p2.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg> is assigned when GPT-mentioned relations can be directly corroborated with evidence found in the KG.
The relevant label  <svg class="ltx_picture" height="11.83" id="S4.SS1.SSS2.p2.2.pic2" overflow="visible" version="1.1" width="11.83"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,11.83) matrix(1 0 0 -1 0 0) translate(5.91,0) translate(0,5.91)"><path d="M 5.91 0 C 5.91 3.27 3.27 5.91 0 5.91 C -3.27 5.91 -5.91 3.27 -5.91 0 C -5.91 -3.27 -3.27 -5.91 0 -5.91 C 3.27 -5.91 5.91 -3.27 5.91 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -1.92 -4.62)"><foreignobject height="9.24" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="3.84"><span class="ltx_text" id="S4.SS1.SSS2.p2.2.pic2.1.1.1.1.1" style="color:#FFFFFF;">i</span></foreignobject></g></g></svg> will be assigned in two scenarios.
First, this label will be assigned if a similar but not identical relation is found in the KG compared to what GPT mentioned.
For example, GPT might suggest that a drug can slow the progression of a condition, but the KG shows the drug can prevent a condition.
Secondly, this label will be assigned if no direct link exists between two entities, but a two-hop path is discoverable in the KG, suggesting potential underlying mechanisms that could support the relation.
The unsure label  <svg class="ltx_picture" height="13.53" id="S4.SS1.SSS2.p2.3.pic3" overflow="visible" version="1.1" width="13.53"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13.53) matrix(1 0 0 -1 0 0) translate(6.76,0) translate(0,6.76)"><path d="M 6.76 0 C 6.76 3.74 3.74 6.76 0 6.76 C -3.74 6.76 -6.76 3.74 -6.76 0 C -6.76 -3.74 -3.74 -6.76 0 -6.76 C 3.74 -6.76 6.76 -3.74 6.76 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.27 -4.8)"><foreignobject height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.53"><span class="ltx_text" id="S4.SS1.SSS2.p2.3.pic3.1.1.1.1.1" style="color:#FFFFFF;">?</span></foreignobject></g></g></svg> will be assigned to relations to which neither the Support nor Relevant labels apply.
In addition to adding the question icons, we distinguish unsure relations with a dashed line, enhancing user understanding of the relation’s credibility.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Next Step Recommendation</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<span class="ltx_ERROR undefined" id="S4.SS1.SSS3.p1.1">\name</span>
<p class="ltx_p" id="S4.SS1.SSS3.p1.2">offers next-step recommendations in both the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p1.2.1">Navigator</span> and the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p1.2.2">Graph Explorer</span> to encourage further exploration (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i4" title="Item C.4 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.4</span></span></a>), as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>(F).
In the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p1.2.3">Navigator</span>, recommendations are displayed above the input box, with the top three suggestions presented as individual buttons.
Additional recommendations become visible upon hovering over the “More” button. Meanwhile, in the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p1.2.4">Graph Explorer</span>, recommendations are linked to relevant nodes in the graph, aiding users in integrating these suggestions into the context of their ongoing exploration.
Clicking on a button will automatically submit the corresponding recommended query to <span class="ltx_ERROR undefined" id="S4.SS1.SSS3.p1.2.5">\name</span>.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1">There may be instances where the recommendations do not fully align with the unique goals of individual users, particularly when there is a limited chat history available.
In such cases, users have the option to dismiss recommendations by clicking on the cross icon or to enter their own query into the input box.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="459" id="S4.F6.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.4.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F6.5.2" style="font-size:90%;">Step by step exploration<span class="ltx_text ltx_font_medium" id="S4.F6.5.2.1">. In <span class="ltx_ERROR undefined" id="S4.F6.5.2.1.1">\name</span>, users seek information while progressively constructing a graph about it. With each step, newly added edges and nodes are highlighted, whereas elements from previous steps are faded. This design aims to help users concentrate on the current query while still retaining an awareness of the overall context.</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Progress Tracking</h4>
<div class="ltx_para" id="S4.SS1.SSS4.p1">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">As users ask questions and progressively build a comprehensive understanding, the process can also result in an overwhelming amount of information, causing them to lose track of the query process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib43" title="">43</a>]</cite>
Therefore,
we provide a <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS4.p1.1.1">Navigator</span> that both structurally organizes exploration histories (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i3" title="Item C.3 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.3</span></span></a>) and indicates the ratio of explored area within the knowledge graph neighborhood (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i5" title="Item C.5 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span></a>).</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS4.p2">
<p class="ltx_p" id="S4.SS1.SSS4.p2.1">In the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS4.p2.1.1">Navigator</span> (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S3.F4" title="In 3.1 Respond to current query (C.1, C.2) ‣ 3 Integrating Knowledge Graph ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>(D)),
each dot in the stepper indicates a query.
<span class="ltx_ERROR undefined" id="S4.SS1.SSS4.p2.1.2">\name</span> uses a linear Navigator to prioritize a familiar and straightforward navigation experience for users.
Hovering on a dot will reveal the corresponding query text in a tooltip, and clicking on the dot navigates to the page of this query.
In the query’s page, <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS4.p2.1.3">Text Dialogue</span> shows the text response to this query and <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS4.p2.1.4">Graph Explorer</span> will highlight the relevant nodes and their relations, fading previous explorations, and hiding explorations after this query, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F6" title="In 4.1.3 Next Step Recommendation ‣ 4.1 Information Seeking with \name ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>.
Compared to the scrolling-down layout of traditional conversational chatbot, this design enable users to focus one specific query without losing the context (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i3" title="Item C.3 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.3</span></span></a>), embodying the focus+context design principle prevalent in visualization.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS4.p3">
<p class="ltx_p" id="S4.SS1.SSS4.p3.1">Additionally, a circular progress bar on the stepper’s right side shows the proportion of the neighboring area in KG explored by the user (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S2.I1.i5" title="Item C.5 ‣ 2.1 Design Requirements ‣ 2 Informing the Design ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_bold">C.5</span></span></a>).
This target neighborhood is dynamically updated as users dismiss recommendations or introduce new queries, ensuring a tailored and manageable exploration experience.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Account Management and Chat Histories</h3>
<div class="ltx_para" id="S4.SS2.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.p1.1">\name</span>
<p class="ltx_p" id="S4.SS2.p1.2">allows users to sign in using either their GitHub or Google accounts and requires an OpenAI API key at the sign-in page. This integration is achieved through NextAuth.js<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib10" title="">10</a>]</cite>, a library for Next.js that provides a simple and secure solution for handling authentication in server-side rendering and static site generation applications. By using OAuth providers like GitHub and Google, we offer users a convenient way to access <span class="ltx_ERROR undefined" id="S4.SS2.p1.2.1">\name</span> and maintain user data security.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Chat histories are stored on Vercel KV <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib41" title="">41</a>]</cite>, a durable Redis database that enables the storage and retrieval of JSON data. Storing chat histories ensure that users’ conversation histories are preserved across sessions.
Users can revisit previous conversations and continue their research from where they left off.
More importantly, these histories can be used for generating a more personalized recommendation pool.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Overall, the account management and chat histories in <span class="ltx_ERROR undefined" id="S4.SS2.p3.1.1">\name</span> enhance the usability and effectiveness of the system, providing users with a more personalized and continuous research experience.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The implementation of <span class="ltx_ERROR undefined" id="S4.SS3.p1.1.1">\name</span> involves a front-end for user interaction and a back-end for data processing and AI model integration. The front-end is developed using Next.js<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib40" title="">40</a>]</cite> to enable server-side rendering and static site generation. The chat functionality is powered by the Vercel AI SDK<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib40" title="">40</a>]</cite>, which provides a streamlined way to integrate AI chat models, such as OpenAI’s GPT-4, into the application. Chat history and sessions are stored on Vercel KV<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib40" title="">40</a>]</cite>, ensuring that the user’s conversation history is preserved across sessions. For authentication, NextAuth.js<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib10" title="">10</a>]</cite> is integrated into the application, providing a simple and secure solution for managing user authentication and session management.
The back-end of is built using Flask <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib14" title="">14</a>]</cite>, a lightweight Python web framework. Flask serves as the bridge between the front-end and the graph database, where Neo4j<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib32" title="">32</a>]</cite> is utilized to store and retrieve knowledge graph data. The source code and documentation for <span class="ltx_ERROR undefined" id="S4.SS3.p1.1.2">\name</span> are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://visual-intelligence-umn.github.io/KNOWNET/" title="">https://visual-intelligence-umn.github.io/KNOWNET/</a>.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="537" id="S4.F7.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.3.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F7.4.2" style="font-size:90%;">Three typical use cases<span class="ltx_text ltx_font_medium" id="S4.F7.4.2.1">. The blue chat bubble represents recommended questions, and the white chat bubble represents free questions. </span></span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">A total of 15 use cases were conducted to showcase the utility and usability of <span class="ltx_ERROR undefined" id="S5.p1.1.1">\name</span>, performed by the three domain experts on our author team.
Each use case involved a series of dialogues centered on one specific question related to dietary supplements.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In this section, we first present three representative use cases from the set of 15.
Following this, we discuss our observations and the errors encountered across all use cases.
Lastly, we conducted expert interviews with two additional domain experts who are not paper authors, further enriching our analysis and findings.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Use Cases</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We first report three representative cases that simulated different usage scenarios, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>, and then discuss our observations from conducting the 15 cases.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Case One: Verification via Literature</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">This case (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>(a)) demonstrates how <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p1.1.1">\name</span> can help users verify information. The user inquired about the impact of one specific dietary supplement on Alzheimer’s disease.
In response to the query <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS1.p1.1.2">“Can Procaine slow the progression of Alzheimer’s disease?”</span>, <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p1.1.3">\name</span> stated that: <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS1.p1.1.4">“Procaine may have potential benefits in slowing the progression of Alzheimer’s disease.</span>
The retrieved triple ([Procaine]-[prevents]-&gt;[Alzheimer’s Disease]) was incorporated into the <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS1.p1.1.5">Graph Explorer</span>, with a support label  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS1.p1.1.pic1" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS1.p1.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg> and corresponding literature evidence.
The user can then read the corresponding paper to seek further information about the relation between Procaine and Alzheimer’s disease.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Case Two: Integrating Information from LLM and KG</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.3">This case (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>(b)) shows how <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.3.1">\name</span> integrates information from both LLM and KG for effective information seeking. The user investigated different drugs by beginning with, “Can rivastigmine treat AD?” stemming from a recent drug advertisement they encountered.
<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.3.2">\name</span> confirmed the treatment possibility with a support label  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS2.p1.1.pic1" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS2.p1.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg> and provided relevant evidence to support this claim.
Curious for more details about this supplement, the user pursued a recommended query, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS2.p1.3.3">“Can you tell me more about Rivastigmine and Disorders?”</span>.
<span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.3.4">\name</span> indicated that <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS2.p1.3.5">“Rivastigmine is also used to treat Parkinson’s disease dementia.”</span>
However, <span class="ltx_ERROR undefined" id="S5.SS1.SSS2.p1.3.6">\name</span> did not find a direct edge between Parkinson’s disease and Rivastigmine, resulting in number 0 on the edge label.
On the other hand, the KG found that Parkinson’s disease can be connected to Rivastigmine via the node Alzheimer’s disease (B2), leading to a relevant label  <svg class="ltx_picture" height="11.83" id="S5.SS1.SSS2.p1.2.pic2" overflow="visible" version="1.1" width="11.83"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,11.83) matrix(1 0 0 -1 0 0) translate(5.91,0) translate(0,5.91)"><path d="M 5.91 0 C 5.91 3.27 3.27 5.91 0 5.91 C -3.27 5.91 -5.91 3.27 -5.91 0 C -5.91 -3.27 -3.27 -5.91 0 -5.91 C 3.27 -5.91 5.91 -3.27 5.91 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -1.92 -4.62)"><foreignobject height="9.24" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="3.84"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p1.2.pic2.1.1.1.1.1" style="color:#FFFFFF;">i</span></foreignobject></g></g></svg> rather than an unsure label  <svg class="ltx_picture" height="13.53" id="S5.SS1.SSS2.p1.3.pic3" overflow="visible" version="1.1" width="13.53"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13.53) matrix(1 0 0 -1 0 0) translate(6.76,0) translate(0,6.76)"><path d="M 6.76 0 C 6.76 3.74 3.74 6.76 0 6.76 C -3.74 6.76 -6.76 3.74 -6.76 0 C -6.76 -3.74 -3.74 -6.76 0 -6.76 C 3.74 -6.76 6.76 -3.74 6.76 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.27 -4.8)"><foreignobject height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.53"><span class="ltx_text" id="S5.SS1.SSS2.p1.3.pic3.1.1.1.1.1" style="color:#FFFFFF;">?</span></foreignobject></g></g></svg>.
Users further examined the two-hop path via Alzheimer’s disease and believed it cannot help verify the relation between Parkinson’s disease and Rivastigmine.
This observation suggested potential inaccuracies in the information provided by the LLM.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Case Three: Guided Exploration</h4>
<div class="ltx_para" id="S5.SS1.SSS3.p1">
<p class="ltx_p" id="S5.SS1.SSS3.p1.2">This case (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>(c)) shows how <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p1.2.1">\name</span> supports guided exploration with recommendations and progressive visualizations. The user started with asking <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.2">“Which supplement may slow the progression of Alzheimer’s disease?”</span>
<span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p1.2.3">\name</span> suggested Omega-3 fatty acids and vitamin E, noting that <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.4">“Omega-3 fatty acids may slow the progression of Alzheimer’s disease”</span> and <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.5">“Vitamin E has been studied for its potential to slow cognitive decline in Alzheimer’s disease”</span>.
The retrieved triples ([Omega-3 fatty acids]-[affects]-&gt;[Alzheimer’s Disease]) and ([Vitamin E]-[affects]-&gt;[Alzheimer’s Disease]) were also updated in the graph with support edge labels  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS3.p1.1.pic1" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS3.p1.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg>.
Based on the previous answer, the user was interested in one supplement, Omega-3 fatty acids, proposed by <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p1.2.6">\name</span>, and want to know which other disorders can benefit from taking this supplement. This question was exactly recommended by <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p1.2.7">\name</span> and displayed above the input box as “Omega-3 fatty acids and Disorders.”
The user clicked on the responding button and <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p1.2.8">\name</span> generated responses accordingly: <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.9">omega-3 fatty acids can be used for reducing heart disorders, slowing down the progression of neurodegenerative disorders and managing mood disorders</span>.

These relations were also updated to the <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.10">Graph Explorer</span> with supporting edge labels  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS3.p1.2.pic2" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS3.p1.2.pic2.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg>.

In <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.2.11">Graph Explorer</span>, nodes relevant to the current query (i.e., mood disorders, neurodegenerative disorders) are highlighted, aiding users in maintaining focus without getting overwhelmed by other nodes in the graph.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p2">
<p class="ltx_p" id="S5.SS1.SSS3.p2.2">The user then revisited earlier steps to inquire about another recommended supplement, vitamin E.
The user selected the recommended question from <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p2.2.1">\name</span>, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p2.2.2">“why vitamin E can be helpful for Alzheimer’s?”</span>.
<span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p2.2.3">\name</span> responded with “Antioxidant properties” and their effect on “neurons” to explain why vitamin E was recommended.
As show in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>(C3),

a relevant label  <svg class="ltx_picture" height="11.83" id="S5.SS1.SSS3.p2.1.pic1" overflow="visible" version="1.1" width="11.83"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,11.83) matrix(1 0 0 -1 0 0) translate(5.91,0) translate(0,5.91)"><path d="M 5.91 0 C 5.91 3.27 3.27 5.91 0 5.91 C -3.27 5.91 -5.91 3.27 -5.91 0 C -5.91 -3.27 -3.27 -5.91 0 -5.91 C 3.27 -5.91 5.91 -3.27 5.91 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -1.92 -4.62)"><foreignobject height="9.24" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="3.84"><span class="ltx_text" id="S5.SS1.SSS3.p2.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">i</span></foreignobject></g></g></svg> on the edge indicated that there are no direct edges, but there are two-hop paths in the KG connecting the two nodes.

Consequently, the user pursued further clarification by selecting a <span class="ltx_ERROR undefined" id="S5.SS1.SSS3.p2.2.4">\name</span> suggested question, asking, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p2.2.5">“Can you tell me more about Antioxidant properties and neurons?”</span>
The answer introduced a new concept (<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S4.F7" title="In 4.3 Implementation ‣ 4 Visual Interface ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>(C4)), “Oxidative stress”, which was linked to both “Antioxidant properties” and “neurons” with support edge labels  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS3.p2.2.pic2" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS3.p2.2.pic2.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg>. These links helped validate the relation between “Antioxidant properties” and “neurons”.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4 </span>Observations</h4>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS4.p1">
<p class="ltx_p" id="S5.SS1.SSS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p1.1.1">Complementarity between LLM and KG:</span>
LLMs can add context and details to the abstract and inflexible structures of KG, while KGs can enhance LLMs with accuracy and structured knowledge.
The use cases show how LLM and KG can mutually enhance each other’s capabilities.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p2">
<p class="ltx_p" id="S5.SS1.SSS4.p2.1">First, LLM and KG can complement each other by providing information from different resources.
An instance of KG enhancing LLM occurs in the first Q&amp;A of Case 1, where the LLM’s response regarding the efficacy of Procaine in Alzheimer’s treatment was marked by uncertainty, indicated by phrases like <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p2.1.1">“some research suggests that Procaine may have potential benefits in…”</span>
Here, KG plays a crucial role in affirming this connection, supplementing the claim with supporting literature.
Conversely, an example of LLM augmenting KG is observed in the second Q&amp;A of Case 2.
The LLM introduces a triple ([Rivastigmine]-[treats]-&gt; [Parkinson’s disease dementia]) that is not previously recorded in the KG.
Therefore, the KG leveraged a two-hop path ([Rivastigmine]-[treats]-&gt;[Alzheimer’s disease]-[coexists with]-&gt;[Parkinson’s disease dementia]) to suggest Rivastigmine’s applicability in treating a closely related disease.
This strategy is frequently employed in drug repurposing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib42" title="">42</a>]</cite>.
Although the validity of this relation requires further verification, it underscores the significant potential of LLMs to enhance the quality of the KG.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p3">
<p class="ltx_p" id="S5.SS1.SSS4.p3.1">Second, the integration of text and graphical representation through LLM and KG collaboration enables varied perspectives for data interpretation. The textual descriptions generated by LLMs can offer nuanced explanations and background information.
Take the Omega-3 fatty acids in Case 3 as an example, the text description included information about its resource <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p3.1.1">“rich in fish oil”</span> and main properties <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p3.1.2">“anti-inflammatory and neuroprotective properties”</span>.
At the same time, the visual graphs provide a clear, immediate summary of the connection between Omega-3 fatty acids and Alzheimer’s disease.
More importantly, the abstract nature of the graph facilitates easier recall of previous explorations, offering a contextual backdrop for understanding the current query. In contrast, extensive text segments tend to focus narrowly on information pertinent to the immediate query.</p>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="524" id="S5.F8.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F8.3.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S5.F8.4.2" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S5.F8.4.2.1">Error cases</span>: (a) The LLM uses vague terms that can’t be accurately mapped to domain-specific terms in the KG; (b) The KG has a limited scope and does not include common-sense knowledge that is not explicitly detailed in research articles.
</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS4.p4">
<p class="ltx_p" id="S5.SS1.SSS4.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p4.1.1">Common Issues:</span>

Analysis of the 15 cases also revealed various issues in the integration of LLM and KG, which we summarize as below.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p5">
<p class="ltx_p" id="S5.SS1.SSS4.p5.1">First, aligning general language terms from LLM output to these standardized terms in KG can lead to inaccuracies.
The inherent ambiguity of natural language can lead to LLM-generated entity and relation names being broad and nonspecific.
At the same time, domains requiring high precision often rely on standardized terminology for clarity and consistency, such as the Unified Medical Language System (UMLS)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib5" title="">5</a>]</cite> used in <span class="ltx_ERROR undefined" id="S5.SS1.SSS4.p5.1.1">\name</span>.
It is possible that a term used by an LLM is vague and can match multiple nodes in KG.

For example, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.F8" title="In 5.1.4 Observations ‣ 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a>(a), even though the KG contains evidence to support the relation [Ginkgo biloba extract]-&gt;[benefit]-&gt;[Alzheimer’s Disease], LLM use a broder term “Ginkgo biloba”, which was matched to the node “Ginkgo biloba” rather than “Ginkgo biloba extract” in KG. This results in a unsure label  <svg class="ltx_picture" height="13.53" id="S5.SS1.SSS4.p5.1.pic1" overflow="visible" version="1.1" width="13.53"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13.53) matrix(1 0 0 -1 0 0) translate(6.76,0) translate(0,6.76)"><path d="M 6.76 0 C 6.76 3.74 3.74 6.76 0 6.76 C -3.74 6.76 -6.76 3.74 -6.76 0 C -6.76 -3.74 -3.74 -6.76 0 -6.76 C 3.74 -6.76 6.76 -3.74 6.76 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.27 -4.8)"><foreignobject height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.53"><span class="ltx_text" id="S5.SS1.SSS4.p5.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">?</span></foreignobject></g></g></svg> for the relation.

</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p6">
<p class="ltx_p" id="S5.SS1.SSS4.p6.2">Second, KGs are usually limited to specific domains and cannot be used to validate information outside those domains.
In the current implementation, the <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p6.2.1">Graph Explorer</span> will not be updated if LLM determines that a question falls outside the KG’s scope.
However, this approach can fall short for common-sense knowledge within a field, which is often not explicitly detailed in research articles.
For example, the widely recognized fact that <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p6.2.2">“fish oil is rich in Omega-3 fatty acids”</span> is labeled as relevant  <svg class="ltx_picture" height="11.83" id="S5.SS1.SSS4.p6.1.pic1" overflow="visible" version="1.1" width="11.83"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,11.83) matrix(1 0 0 -1 0 0) translate(5.91,0) translate(0,5.91)"><path d="M 5.91 0 C 5.91 3.27 3.27 5.91 0 5.91 C -3.27 5.91 -5.91 3.27 -5.91 0 C -5.91 -3.27 -3.27 -5.91 0 -5.91 C 3.27 -5.91 5.91 -3.27 5.91 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -1.92 -4.62)"><foreignobject height="9.24" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="3.84"><span class="ltx_text" id="S5.SS1.SSS4.p6.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">i</span></foreignobject></g></g></svg> rather than support  <svg class="ltx_picture" height="16.95" id="S5.SS1.SSS4.p6.2.pic2" overflow="visible" version="1.1" width="16.95"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,16.95) matrix(1 0 0 -1 0 0) translate(8.48,0) translate(0,8.48)"><path d="M 8.48 0 C 8.48 4.68 4.68 8.48 0 8.48 C -4.68 8.48 -8.48 4.68 -8.48 0 C -8.48 -4.68 -4.68 -8.48 0 -8.48 C 4.68 -8.48 8.48 -4.68 8.48 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -5.77 -4.79)"><foreignobject height="9.58" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.53"><span class="ltx_text" id="S5.SS1.SSS4.p6.2.pic2.1.1.1.1.1" style="color:#FFFFFF;">✓</span></foreignobject></g></g></svg>, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.F8" title="In 5.1.4 Observations ‣ 5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a>(b).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p7">
<p class="ltx_p" id="S5.SS1.SSS4.p7.1">Third, GPT4 tend to be overly cautious, often using vague terms and occasionally refusing to answer certain questions. For instance, when queried about the connection between Procaine and Alzheimer’s Disease, an LLM responded with the statement, “Procaine may have potential benefits in slowing the progression of Alzheimer’s Disease.”
This cautious approach of GPT can sometimes make <span class="ltx_ERROR undefined" id="S5.SS1.SSS4.p7.1.1">\name</span> unresponsive to user questions. However, it can also result in fewer instances than expected of uncertain edge labels  <svg class="ltx_picture" height="13.53" id="S5.SS1.SSS4.p7.1.pic1" overflow="visible" version="1.1" width="13.53"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13.53) matrix(1 0 0 -1 0 0) translate(6.76,0) translate(0,6.76)"><path d="M 6.76 0 C 6.76 3.74 3.74 6.76 0 6.76 C -3.74 6.76 -6.76 3.74 -6.76 0 C -6.76 -3.74 -3.74 -6.76 0 -6.76 C 3.74 -6.76 6.76 -3.74 6.76 0 Z M 0 0" style="stroke:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.27 -4.8)"><foreignobject height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.53"><span class="ltx_text" id="S5.SS1.SSS4.p7.1.pic1.1.1.1.1.1" style="color:#FFFFFF;">?</span></foreignobject></g></g></svg> in the use cases.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p8">
<p class="ltx_p" id="S5.SS1.SSS4.p8.1">Fourth, even though integrating the additional graphical format can significantly address the issues in traditional linear textual description, not all knowledge can be effectively represented as graphs.
For example, consider the sentence <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS4.p8.1.1">“Oxidative stress is related to the process of neuronal damage, as it involves the accumulation of harmful reactive oxygen species that can damage neurons”</span>.
This sentence involves multiple triples, such as [Oxidative stress]-[related to]-&gt;[neuronal damage], [reactive oxygen species]-[damage]-&gt;[neurons], [Oxidative stress]-[damage]-&gt;[neurons], [Oxidative stress]-[accumulate]-&gt;[harmful reactive oxygen species].
Representing all these triples can be overwhelming. To tackle this issue, in the current implementation, we prompted GPT to annotate the most important triple from each sentence for validation with KG. However, these annotations are not always accurate and can lead to the oversight of critical knowledge.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Expert Interview</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">In addition to the three domain experts on our author team, we conducted interviews with two further experts (E1, E2) specializing in computational health informatics and medical research.
E1 is a research scientist in medical informatics, holds a PhD degree, and has 8 years of experience in pharmacy and EHR data analysis. E2 is a PhD candidate in health informatics with 4 years of research experience. E2 has a strong clinical background with an MBBS degree, which is equivalent to an MD in the US.

These interviews aimed to obtain insights into the usability, effectiveness, and areas for improvement of <span class="ltx_ERROR undefined" id="S5.SS2.p1.1.1">\name</span>.
The two additional experts are not authors of this paper.
Each interview lasted approximately 60 minutes.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Introduction (10 minutes). We began by providing a background overview and demonstrating the various components and functionalities of <span class="ltx_ERROR undefined" id="S5.I1.i1.p1.1.1">\name</span>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Case Presentation (20 minutes). Following this introduction, we presented two specific use cases, Case 2 and Case 3 as detailed in <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#S5.SS1" title="5.1 Use Cases ‣ 5 Evaluation ‣ \name: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5.1</span></a>. We also provided the responses from GPT-4 of the same questions for comparison. This segment was designed to familiarize the experts with <span class="ltx_ERROR undefined" id="S5.I1.i2.p1.1.1">\name</span>’s usage and work flow. During the demonstration, experts were encouraged to interrupt with questions and comments.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Free Exploration (15 minutes). We allowed the experts 15 minutes of free exploration of the system, during which they were encouraged to think aloud and vocalize their thoughts.
This interactive session was closely observed, with our team taking detailed notes on the experts’ interactions with <span class="ltx_ERROR undefined" id="S5.I1.i3.p1.1.1">\name</span>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">Discussion (15 minutes). The interview concluded with a semi-structured discussion, during which we collected feedback on five critical aspects: the accuracy of information provided, clarity of explanations, relevance of responses and recommendations, coverage of essential topics, and the system’s overall ease of use.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Usability.</span>
Both experts commented that it was easy and intuitive to use the system without further assistance from the interviewers, stating all these features <span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.2">“basically have no learning curve involved”</span> (E1).
They were particularly impressed with <span class="ltx_ERROR undefined" id="S5.SS2.p3.1.3">\name</span>’s ability in elucidating the connections between entities and surfacing pertinent literature.
They also expressed that the progressive visualization and ext-step recommendations are useful features to guide exploration.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">Willing to Use.</span>
The experts emphasized their frequent reliance on evidence-based resources like UpToDate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib21" title="">21</a>]</cite> for accessing drug and medical information, underscoring the importance of accuracy and credibility in their work. For instance, E1 highlighted a hesitancy to utilize GPT, <span class="ltx_text ltx_font_italic" id="S5.SS2.p4.1.2">“I rarely used GPT for those questions, due to concerns about its accuracy.”</span>
Both experts stated that tools like <span class="ltx_ERROR undefined" id="S5.SS2.p4.1.3">\name</span>  which integrate literature for supporting evidence, could dramatically shift their perspective on the utilization of AI-powered tools in their professional activities.
The ability of <span class="ltx_ERROR undefined" id="S5.SS2.p4.1.4">\name</span> to directly link to and leverage verified scientific articles not only bolsters the trustworthiness of the information provided but also aligns with the experts’ existing practices of evidence-based verification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib53" title="">53</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p5.1.1">Comparing <span class="ltx_ERROR undefined" id="S5.SS2.p5.1.1.1">\name</span> with GPT-4.</span>
Both experts commented on the differences between <span class="ltx_ERROR undefined" id="S5.SS2.p5.1.2">\name</span> and GPT.
First, compared with the well-structured response from <span class="ltx_ERROR undefined" id="S5.SS2.p5.1.3">\name</span>, GPT responses are much longer and redundant, with several sentences repeating similar points.
For the same question <span class="ltx_text ltx_font_italic" id="S5.SS2.p5.1.4">“Which factors can trigger Alzheimer’s to get worse?”</span>, GPT responses include more than 10 factors while <span class="ltx_ERROR undefined" id="S5.SS2.p5.1.5">\name</span> typical try to focus on the most important two or three factors.
Apart from the amount of the information, E1 also appreciated that the graph works as an effective scaffold to help track and organize the information, especially when dealing with multiple entities.
Second, E2 noted that GPT often employs an uncertain tone, for instance, characterizing a factor by saying it “has been studied for its potential in slowing the progression of…” Such phrasing might mitigate the risk of providing inaccurate responses, but tends to render the information “less useful”(E2) in making decisions or gaining insights.
Third, both experts mentioned that highlighting relevant entities and relations in the text can help them effectively grasp the main points, offering a clear advantage over the undifferentiated text produced by GPT.</p>
</div>
<div class="ltx_para" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.1">Suggested Improvements.</span>
The experts offered insightful suggestions for enhancing <span class="ltx_ERROR undefined" id="S5.SS2.p6.1.2">\name</span>.
E1 proposed allowing the integration of user-provided KGs into the system to help <span class="ltx_ERROR undefined" id="S5.SS2.p6.1.3">\name</span> comprehensively identify reference articles and broaden the scope of supported evidences.
E1 also suggested granting users the capability to evaluate the quality of the KGs integrated in <span class="ltx_ERROR undefined" id="S5.SS2.p6.1.4">\name</span>.
These suggests are made considering the critical links between KG quality and the reliability of <span class="ltx_ERROR undefined" id="S5.SS2.p6.1.5">\name</span>’s outputs.
Meanwhile, E2 recommended providing users with the option to customize the verbosity and detail level of textual responses.
This feature would accommodate varying user preferences and capacities for processing information, ensuring <span class="ltx_ERROR undefined" id="S5.SS2.p6.1.6">\name</span> can cater to a diverse range of needs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Generality:</span>
We developed and assessed <span class="ltx_ERROR undefined" id="S6.p1.1.2">\name</span> within the domain of dietary supplements, a field where access to scientifically validated information is crucial due to widespread exaggerated claims and misinformation.
Our evaluation highlights <span class="ltx_ERROR undefined" id="S6.p1.1.3">\name</span>’s efficacy in this particular context, and we are confident that our approach can be broadly applied to other areas. Firstly, <span class="ltx_ERROR undefined" id="S6.p1.1.4">\name</span> is well-suited for domains where users typically use evidence-backed knowledge from scholarly literature for reasoning and decision making.
Secondly, it is applicable to information-seeking scenarios where data can be effectively organized as a graph, and the understanding can benefit from a step-by-step exploration.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Scalability:</span>
Even though the proposed method represents a significant improvement over traditional linear conversation methods, challenges may arise as the volume of content increases.
Specifically, managing and navigating within a graph that contains large number of nodes and edges may become cumbersome for users.
To tackle this problem, forthcoming improvements could aim at incorporating hierarchical structures and offering multiple abstraction levels. This would allow users to initially engage with a broad overview, delve into detailed information for areas of interest, and seamlessly transition between different abstraction layers.
Adaptive interface is another promising research direction for addressing this issue.
By learning the desired level of abstraction from interaction logs, the interface can dynamically adjust accordingly to suit the exploration needs of different users.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Inherent limitations related to KG:</span>
Inherent limitations associated with KGs must be acknowledged despite their effectiveness in representing structured knowledge.
While KGs offer a powerful means of organizing and manipulating knowledge, they may not fully capture the complexity of human cognition, especially aspects that are less structured or context-dependent. In future research, we plan to investigate the integration of other formats of knowledge (<span class="ltx_ERROR undefined" id="S6.p3.1.2">\eg</span>, images, tabluar data, maps) to further facilitate the information seeking with LLMs.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">Meanwhile, it’s crucial to recognize the information validation supported in <span class="ltx_ERROR undefined" id="S6.p4.1.1">\name</span> is confined to the scope of the integrated KG.
When a relation cannot be validated within the KG, it does not necessarily imply that the relation is untrue.
As a result, users should be careful when interpreting the validation information derived from KGs. A promising future direction would be to dynamically integrate user knowledge into the system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13598v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p5">
<p class="ltx_p" id="S6.p5.1"><span class="ltx_text ltx_font_bold" id="S6.p5.1.1">Further Enhancement of the Interface:</span>
While the effectiveness of the current <span class="ltx_ERROR undefined" id="S6.p5.1.2">\name</span> interface is demonstrated in our evaluation, its focus on intuitiveness and familiarity presents opportunities for further improvement of advanced feature in future studies.
For instance, the current linear navigator could be expanded to include a tree-based option. This would allow users to more effectively track and compare different exploration paths related to a specific question. Additionally, the layout can be improved to a more semantic design that incorporates the embedding of graph nodes and supports focus + context interactions, which would facilitate the interpretation of larger and more complex knowledge relationships.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p6">
<p class="ltx_p" id="S6.p6.1"><span class="ltx_text ltx_font_bold" id="S6.p6.1.1">Limitations of the Evaluation: </span>
The evaluation of <span class="ltx_ERROR undefined" id="S6.p6.1.2">\name</span> has limited user data, making it challenging to conduct quantitative assessments for both the whole system and the critical components such as entity matching and recommendation.
To mitigate this limitation, our study emphasizes a close involvement of domain experts, gathering timely feedback during weekly meetings.
The use cases and the expert interview demonstrate the effectiveness and usability of the proposed system.

At the same time, we recognize limitations in the current evaluation, such as restricted perspectives and limited generalizability. To address these issues, we plan to expand user participation in follow-up studies. Increasing the number of participants will enhance the robustness of our evaluation and provide a more comprehensive understanding of user behaviors through the analysis of chat texts and interaction logs.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In conclusion, this paper presents <span class="ltx_ERROR undefined" id="S7.p1.1.1">\name</span>, a visualization system that integrates LLMs with KGs to address the challenges of accuracy and structured exploration in health information seeking.
<span class="ltx_ERROR undefined" id="S7.p1.1.2">\name</span> tackles these issues of accuracy through the extraction and mapping of triples from LLM outputs to validated information in external KGs.
It facilitates structured step-by-step exploration by providing recommendation based on KG neighborhood analysis, ensuring a comprehensive understanding without overlooking critical aspects.
Furthermore, to mitigate information overload during multi-step exploration, <span class="ltx_ERROR undefined" id="S7.p1.1.3">\name</span> employs a focus+context design and introduces progressive graph visualization to track previous inquiries and connect them with current queries and next-step recommendations.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Our study demonstrates the effectiveness of <span class="ltx_ERROR undefined" id="S7.p2.1.1">\name</span> in one critical application, dietary supplements, through use cases and expert interviews.
We believe the proposed methods can be generalized to other similar application where structured exploration and validation through literature are essential.

</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6> The authors thank the anonymous reviewers and the study participants for their valuable comments.
This work was partially supported by the National Institutes of Health’s National Center for Complementary and Integrative Health under grant number R01AT009457, National Institute on Aging under grant number R01AG078154 and National Cancer Institute under grant number R01CA287413. The content is solely the responsibility of the authors and does not represent the official views of the National Institutes of Health.



</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
O. Agarwal, H. Ge, S. Shakeri, and R. Al-Rfou.

</span>
<span class="ltx_bibblock">Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, pp. 3554–3565. Association for Computational Linguistics, Online, June 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Angert, M. Suzara, J. Han, C. Pondoc, and H. Subramonyam.

</span>
<span class="ltx_bibblock">Spellburst: A node-based interface for exploratory creative coding with natural language prompts.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</span>, pp. 1–22, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T. Ashby, B. K. Webb, G. Knapp, J. Searle, and N. Fulda.

</span>
<span class="ltx_bibblock">Personalized quest and dialogue generation in role-playing games: A knowledge graph- and language model-based approach.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, article no. 290, 20 pages. Association for Computing Machinery, New York, NY, USA, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Birhane, A. Kasirzadeh, D. Leslie, and S. Wachter.

</span>
<span class="ltx_bibblock">Science in the age of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Nature Reviews Physics</span>, pp. 1–4, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
O. Bodenreider.

</span>
<span class="ltx_bibblock">The unified medical language system (umls): integrating biomedical terminology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Nucleic acids research</span>, 32(suppl_1):D267–D270, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Brade, B. Wang, M. Sousa, S. Oore, and T. Grossman.

</span>
<span class="ltx_bibblock">Promptify: Text-to-image generation through interactive prompt exploration with large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</span>, pp. 1–14, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Chen, Y. Lu, S. Zhang, B. Yao, Y. Dong, Y. Xu, Y. Li, Q. Wang, D. Wang, and Y. Sun.

</span>
<span class="ltx_bibblock">Fairytalecqa: Integrating a commonsense knowledge graph into children’s storybook narratives.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2311.09756</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
L. Chen, M. Zaharia, and J. Zou.

</span>
<span class="ltx_bibblock">How is chatgpt’s behavior changing over time?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2307.09009</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
F. Cheng, M. S. Keller, H. Qu, N. Gehlenborg, and Q. Wang.

</span>
<span class="ltx_bibblock">Polyphony: An interactive transfer learning framework for single-cell data analysis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 29(1):591–601, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
I. Collins.

</span>
<span class="ltx_bibblock">Nextauth.js, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
L. De Angelis, F. Baglivo, G. Arzilli, G. P. Privitera, P. Ferragina, A. E. Tozzi, and C. Rizzo.

</span>
<span class="ltx_bibblock">Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Frontiers in Public Health</span>, 11:1166120, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Fan, L. Li, Z. Ma, S. Lee, H. Yu, and L. Hemphill.

</span>
<span class="ltx_bibblock">A bibliometric review of large language models research from 2017 to 2023.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2304.02020</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, and W. Chen.

</span>
<span class="ltx_bibblock">Promptmagician: Interactive prompt engineering for text-to-image creation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Grinberg.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Flask web development</span>.

</span>
<span class="ltx_bibblock">" O’Reilly Media, Inc.", 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Helpful AI Tools.

</span>
<span class="ltx_bibblock">Chatgpt diagrams.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
K. Huang, P. Chandak, Q. Wang, S. Havaldar, A. Vaid, J. Leskovec, G. Nadkarni, B. S. Glicksberg, N. Gehlenborg, and M. Zitnik.

</span>
<span class="ltx_bibblock">Zero-shot prediction of therapeutic use with geometric deep learning and clinician centered design.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">medRxiv</span>, pp. 2023–03, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P. Jiang, J. Rayan, S. P. Dow, and H. Xia.

</span>
<span class="ltx_bibblock">Graphologue: Exploring large language model responses with interactive diagrams.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2305.11473</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Z. Jin, Y. Wang, Q. Wang, Y. Ming, T. Ma, and H. Qu.

</span>
<span class="ltx_bibblock">Gnnlens: A visual analytics approach for prediction error diagnosis of graph neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, and R. McHardy.

</span>
<span class="ltx_bibblock">Challenges and applications of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2307.10169</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T. S. Kim, Y. Lee, M. Chang, and J. Kim.

</span>
<span class="ltx_bibblock">Cells, generators, and lenses: Design framework for object-oriented interaction with large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</span>, pp. 1–18, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
W. Kluwer.

</span>
<span class="ltx_bibblock">UpToDate: Trusted, evidence-based solutions for modern healthcare.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.wolterskluwer.com/en/solutions/uptodate" title="">https://www.wolterskluwer.com/en/solutions/uptodate</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-03-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Lee, P. Liang, and Q. Yang.

</span>
<span class="ltx_bibblock">Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2022 CHI conference on human factors in computing systems</span>, pp. 1–19, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Lee, J. J. Y. Chung, T. S. Kim, J. Y. Song, and J. Kim.

</span>
<span class="ltx_bibblock">Promptiverse: Scalable generation of scaffolding prompts through human-ai hybrid knowledge graph annotation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–18, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Y. Lee, T. S. Kim, S. Kim, Y. Yun, and J. Kim.

</span>
<span class="ltx_bibblock">Dapie: Interactive step-by-step explanatory dialogues to answer children’s why and how questions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–22, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer.

</span>
<span class="ltx_bibblock">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:1910.13461</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Advances in Neural Information Processing Systems</span>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Lex, C. Partl, D. Kalkofen, M. Streit, S. Gratzl, A. M. Wassermann, D. Schmalstieg, and H. Pfister.

</span>
<span class="ltx_bibblock">Entourage: Visualizing relationships between biological pathways using contextual subsets.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 19(12):2536–2545, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
W. Li, S. Schöttler, J. Scott-Brown, Y. Wang, S. Chen, H. Qu, and B. Bach.

</span>
<span class="ltx_bibblock">Networknarratives: Data tours for visual network exploration and analysis.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–15, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Lucid Software.

</span>
<span class="ltx_bibblock">Lucid chatgpt plugin.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. LYi, Q. Wang, F. Lekschas, and N. Gehlenborg.

</span>
<span class="ltx_bibblock">Gosling: A grammar-based toolkit for scalable and interactive genomics data visualization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 28(1):140–150, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
T. Milo and A. Somech.

</span>
<span class="ltx_bibblock">Next-step suggestions for modern interactive data analysis platforms.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</span>, pp. 576–585, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Neo4j.

</span>
<span class="ltx_bibblock">Neo4j graph platform, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
C. Nobre, N. Gehlenborg, H. Coon, and A. Lex.

</span>
<span class="ltx_bibblock">Lineage: Visualizing multivariate clinical data in genealogy graphs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 25(3):1543–1558, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu.

</span>
<span class="ltx_bibblock">Unifying large language models and knowledge graphs: A roadmap.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">IEEE Transactions on Knowledge and Data Engineering</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
C. Partl, S. Gratzl, M. Streit, A. M. Wassermann, H. Pfister, D. Schmalstieg, and A. Lex.

</span>
<span class="ltx_bibblock">Pathfinder: Visual analysis of paths in graphs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Computer Graphics Forum</span>, vol. 35, pp. 71–80. Wiley Online Library, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
F. Petroni, T. Rocktäschel, P. Lewis, A. Bakhtin, Y. Wu, A. H. Miller, and S. Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:1909.01066</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
M. Sarkar and M. H. Brown.

</span>
<span class="ltx_bibblock">Graphical fisheye views of graphs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">Proceedings of the SIGCHI conference on Human factors in computing systems</span>, pp. 83–91, 1992.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
S. Song, J. Chen, C. Li, and C. Wang.

</span>
<span class="ltx_bibblock">Gvqa: Learning to answer questions about graphs with visualizations via knowledge base.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–16, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
S. Suh, B. Min, S. Palani, and H. Xia.

</span>
<span class="ltx_bibblock">Sensecape: Enabling multilevel exploration and sensemaking with large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2305.11483</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Vercel.

</span>
<span class="ltx_bibblock">Next.js, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Vercel.

</span>
<span class="ltx_bibblock">Vercel kv, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Q. Wang, K. Huang, P. Chandak, M. Zitnik, and N. Gehlenborg.

</span>
<span class="ltx_bibblock">Extending the nested model for user-centric xai: A design study on gnn-based drug repurposing.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 29(1):1266–1276, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Q. Wang, Z. Li, S. Fu, W. Cui, and H. Qu.

</span>
<span class="ltx_bibblock">Narvis: Authoring narrative slideshows for introducing data visualization designs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 25(1):779–788, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Q. Wang, S. L’Yi, and N. Gehlenborg.

</span>
<span class="ltx_bibblock">Drava: Aligning human concepts with machine learning latent dimensions for the visual exploration of small multiples.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–15, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Q. Wang, T. Mazor, T. A. Harbig, E. Cerami, and N. Gehlenborg.

</span>
<span class="ltx_bibblock">Threadstates: State-based visual analysis of disease progression.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 28(1):238–247, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Q. Wang, Z. Xu, Z. Chen, Y. Wang, S. Liu, and H. Qu.

</span>
<span class="ltx_bibblock">Visual analysis of discrimination in machine learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 27(2):1470–1480, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Q. Wang, J. Yuan, S. Chen, H. Su, H. Qu, and S. Liu.

</span>
<span class="ltx_bibblock">Visual genealogy of deep neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 26(11):3340–3352, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Y. Wang, Z. Jin, Q. Wang, W. Cui, T. Ma, and H. Qu.

</span>
<span class="ltx_bibblock">Deepdrawing: A deep learning approach to graph drawing.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">IEEE Transactions on Visualization and Computer Graphics</span>, 26(1):676–686, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
V. Wiens, S. Lohmann, and S. Auer.

</span>
<span class="ltx_bibblock">Semantic zooming for ontology graph visualizations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">Proceedings of the Knowledge Capture Conference</span>, pp. 1–8, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
R. A. Wilson and F. C. Keil.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">The MIT Encyclopedia of the cognitive sciences (MITECS)</span>.

</span>
<span class="ltx_bibblock">MIT press, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
T. Wu, M. Terry, and C. J. Cai.

</span>
<span class="ltx_bibblock">Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 2022 CHI conference on human factors in computing systems</span>, pp. 1–22, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Y. Xiao, Y. Hou, H. Zhou, G. Diallo, M. Fiszman, J. Wolfson, H. Kilicoglu, Y. Chen, C. Su, H. Xu, et al.

</span>
<span class="ltx_bibblock">Repurposing non-pharmacological interventions for alzheimer’s diseases through link prediction on biomedical literature.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">medRxiv</span>, pp. 2023–05, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Hao, K. Quan, S. Yang, Y. Zhao, V. Kuleshov, and F. Wang.

</span>
<span class="ltx_bibblock">Harnessing biomedical literature to calibrate clinicians’ trust in ai decision support systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–14, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
S.-F. Yeh, M.-H. Wu, T.-Y. Chen, Y.-C. Lin, X. Chang, Y.-H. Chiang, and Y.-J. Chang.

</span>
<span class="ltx_bibblock">How to guide task-oriented chatbot users, and when: A mixed-methods study of combinations of chatbot guidance types and timings.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–16, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
J. Zamfirescu-Pereira, R. Y. Wong, B. Hartmann, and Q. Yang.

</span>
<span class="ltx_bibblock">Why johnny can’t prompt: how non-ai experts try (and fail) to design llm prompts.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, pp. 1–21, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao, Y. Zhang, Y. Chen, et al.

</span>
<span class="ltx_bibblock">Siren’s song in the ai ocean: a survey on hallucination in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2309.01219</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Z. Zhang, J. Gao, R. S. Dhaliwal, and T. J.-J. Li.

</span>
<span class="ltx_bibblock">Visar: A human-ai argumentative writing assistant with visual programming and rapid draft prototyping.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2304.07810</span>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jul 18 15:35:20 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
