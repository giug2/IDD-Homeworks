<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2101.02373] Architectural Patterns for the Design of Federated Learning Systems</title><meta property="og:description" content="Federated learning has received fast-growing interests from academia and industry to tackle the challenges of data hungriness and privacy in machine learning. A federated learning system can be viewed as a large-scale …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Architectural Patterns for the Design of Federated Learning Systems">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Architectural Patterns for the Design of Federated Learning Systems">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2101.02373">

<!--Generated on Sat Mar  9 04:10:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">[type=editor,
auid=000,bioid=1,
orcid=0000-0002-9156-3225]
<span id="p1.1.1" class="ltx_ERROR undefined">\cormark</span>[1]</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">[type=editor,
auid=000,bioid=1,
orcid=0000-0002-7783-5183]</p>
</div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p">[type=editor,
auid=000,bioid=1,]</p>
</div>
<div id="p4" class="ltx_para">
<p id="p4.1" class="ltx_p">[type=editor,
auid=000,bioid=1,
orcid=0000-0003-4425-7388]</p>
</div>
<div id="p5" class="ltx_para">
<p id="p5.1" class="ltx_p">[type=editor,
auid=000,bioid=1,
orcid=0000-0002-2273-1862]</p>
</div>
<div id="p6" class="ltx_para">
<p id="p6.1" class="ltx_p">[type=editor,
auid=000,bioid=1,
orcid=0000-0002-3119-4763]</p>
</div>
<h1 class="ltx_title ltx_title_document">Architectural Patterns for the Design of Federated Learning Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sin Kit Lo
</span><span class="ltx_author_notes">Kit.Lo@data61.csiro.au</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qinghua Lu
</span><span class="ltx_author_notes">Qinghua.Lu@data61.csiro.au</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liming Zhu
</span><span class="ltx_author_notes">liming.zhu@data61.csiro.au</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hye-Young Paik
</span><span class="ltx_author_notes">h.paik@unsw.edu.au</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiwei Xu
</span><span class="ltx_author_notes">Xiwei.Xu@data61.csiro.au</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chen Wang
</span><span class="ltx_author_notes">Chen.Wang@data61.csiro.au
<span class="ltx_contact ltx_role_address">Data61, CSIRO, Australia
</span>
<span class="ltx_contact ltx_role_address">University of New South Wales, Australia
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated learning has received fast-growing interests from academia and industry to tackle the challenges of data hungriness and privacy in machine learning. A federated learning system can be viewed as a large-scale distributed system with different components and stakeholders as numerous client devices participate in federated learning. Designing a federated learning system requires software system design thinking apart from the machine learning knowledge. Although much effort has been put into federated learning from the machine learning technique aspects, the software architecture design concerns in building federated learning systems have been largely ignored. Therefore, in this paper, we present a collection of architectural patterns to deal with the design challenges of federated learning systems. Architectural patterns present reusable solutions to a commonly occurring problem within a given context during software architecture design. The presented patterns are based on the results of a systematic literature review and include three client management patterns, four model management patterns, three model training patterns, and four model aggregation patterns. The patterns are associated to the particular state transitions in a federated learning model lifecycle, serving as a guidance for effective use of the patterns in the design of federated learning systems.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Federated Learning <span id="id2.id1" class="ltx_ERROR undefined">\sep</span>Pattern <span id="id3.id2" class="ltx_ERROR undefined">\sep</span>Software Architecture <span id="id4.id3" class="ltx_ERROR undefined">\sep</span>Machine Learning <span id="id5.id4" class="ltx_ERROR undefined">\sep</span>Artificial Intelligence

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<section id="S1.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Federated Learning Overview</h3>

<div id="S1.SSx1.p1" class="ltx_para">
<p id="S1.SSx1.p1.1" class="ltx_p">The ever-growing use of big data systems, industrial-scale IoT platforms, and smart devices contribute to the exponential growth in data dimensions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">30</span></a>]</cite>. This exponential growth of data has accelerated the adoption of machine learning in many areas, such as natural language processing and computer vision. However, many machine learning systems suffer from insufficient training data. The reason is mainly due to the increasing concerns on data privacy, e.g., restrictions on data sharing with external systems for machine learning purposes. For instance, the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> stipulate a range of data protection measures, and data privacy is now one of the most important ethical principles expected of machine learning systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">22</span></a>]</cite>. Furthermore, raw data collected are unable to be used directly for model training for most circumstances. The raw data needs to be studied and pre-processed before being used for model training and data sharing restrictions increase the difficulty to obtain training data. Moreover, concept drift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">27</span></a>]</cite> also occurs when new data is constantly collected, replacing the outdated data. This makes the model trained on previous data degrades at a much faster rate. Hence, a new technique that can swiftly produce models that adapt to the concept drift when different data is discovered in clients is essential.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2101.02373/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="295" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Federated Learning Overview.</figcaption>
</figure>
<div id="S1.SSx1.p2" class="ltx_para">
<p id="S1.SSx1.p2.1" class="ltx_p">To effectively address the lack of training data limitations, concept drift, and the data-sharing restriction while still enabling effective data inferences by the data-hungry machine learning models, Google introduced the concept of federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">33</span></a>]</cite> in 2016. Fig. <a href="#S1.F1" title="Figure 1 ‣ Federated Learning Overview ‣ 1 Introduction ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the overview of federated learning. There are three stakeholders in a federated learning system: (1) learning coordinator (i.e., system owner), (2) contributor client - data contributor &amp; local model trainer, and (3) user client - model user. Note that a contributor client can also be a user client. There are two types of system nodes (i.e., hardware components): (1) central server, (2) client device.</p>
</div>
</section>
<section id="S1.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">A Motivation Example</h3>

<div id="S1.SSx2.p1" class="ltx_para">
<p id="S1.SSx2.p1.1" class="ltx_p">Imagine we use federated learning to train the next-word prediction model in a mobile phone keyboard application. The learning coordinator is the provider of the keyboard application, while contributor clients are the mobile phone users. The user clients will be the new or existing mobile phone users of the keyboard application. The differences in ownership, geolocation, and usage pattern cause the local data to possess non-IID<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Non-Identically and Independently Distribution: Highly-skewed and personalised data distribution that vary heavily between different clients and affects the model performance and generalisation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">37</span></a>]</cite>.</span></span></span> characteristics, which is a design challenge of federated learning systems. The federated learning process starts when a training task is created by the learning coordinator. For instance, the keyboard application provider produces and embeds an initial global model into the keyboard applications. The initial global model (includes task scripts &amp; training hyperparameters) is broadcast to the participating client devices. After receiving the initial model, the model training is performed locally across the client devices, without the centralised collection of raw client data. Here, the smartphones that have the keyboard application installed receive the model to be trained. The client devices typically run on different operating systems and have diverse communication and computation resources, which is defined as the system heterogeneity challenges.</p>
</div>
<div id="S1.SSx2.p2" class="ltx_para">
<p id="S1.SSx2.p2.1" class="ltx_p">Each training round takes one step of gradient descent on the current model using each client’s local data. In this case, the smartphones optimise the model using the keyboard typing data. After each round, the model update is submitted by each participating client device to the central server. The central server collects all the model updates and performs model aggregation to form a new version of the global model. The new global model is re-distributed to the client devices for the next training round. This entire process iterates until the global model converges. As a result, communication and computation efficiency are crucial as many local computation and communication rounds are required for the global model to converge. Moreover, due to the limited resources available on each device, the device owners might be reluctant to participate in the federated learning process. Therefore, client motivatability becomes a design challenge. Furthermore, the central server communicates with multiple devices for the model exchange which makes it vulnerable to the single-point-of-failure. The trustworthiness of the central server and the possibility of adversarial nodes participating in the training process also creates system reliability and security challenges. After the completion of training, the learning coordinator stores the converged model and deploys it to the user clients. For instance, the keyboard application provider stores the converged model and embeds it to the latest version of the application for existing or new application users. Here, the different versions of the local models associated with the global model created need to be maintained.</p>
</div>
</section>
<section id="S1.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Design Challenges</h3>

<div id="S1.SSx3.p1" class="ltx_para">
<p id="S1.SSx3.p1.1" class="ltx_p">Compared to centralised machine learning, federated learning is more advantageous from the data privacy perspective and dealing with the lack of training data. However, a federated learning system, as a large-scale distributed system, presents more architectural design challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">31</span></a>]</cite>, especially when dealing with the interactions between the central server and client devices and managing trade-offs of software quality attributes. The main design challenges are summarised as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Global models might have low accuracy, and lack generality when client devices generate non-IID data. Centralising and randomising the data is the approach adopted by conventional machine learning to deal with data heterogeneity but the inherent privacy-preserving nature of federated learning render such techniques inappropriate.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">To generate high-quality global models that are adaptive to concept drift, multiple rounds of communication are required to exchange local model updates, which could incur high communication costs.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Client devices have limited resources to perform the multiple rounds of model training and communications required by the system, which may affect the model quality.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">As numerous client devices participate in federated learning, it is challenging to coordinate the learning process and ensure model provenance, system reliability and security.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SSx3.p2" class="ltx_para">
<p id="S1.SSx3.p2.1" class="ltx_p">How to select appropriate designs to fulfill different software quality requirements and design constraints is non-trivial for such a complex distributed system. Although much effort has been put into federated learning from the machine learning techniques side, there is still a gap on the architectural design considerations of the federated learning systems. A systematic guidance on architecture design of federated learning systems is required to better leverage the existing solutions and promote federated learning to enterprise-level adoption.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2101.02373/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="122" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Pattern Collection Process.</figcaption>
</figure>
</section>
<section id="S1.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Research Contribution</h3>

<div id="S1.SSx4.p1" class="ltx_para">
<p id="S1.SSx4.p1.1" class="ltx_p">In this paper, we present a collection of patterns for the design of federated learning systems. In software engineering, an architectural pattern is a reusable solution to a problem that occurs commonly within a given context in software design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Our pattern collection includes three client management patterns, four model management patterns, three model training patterns, and four model aggregation patterns. We define the lifecycle of a model in a federated learning system and associate each identified pattern to a particular state transition in the lifecycle.</p>
</div>
<div id="S1.SSx4.p2" class="ltx_para">
<p id="S1.SSx4.p2.1" class="ltx_p">The main contribution of this paper includes:</p>
</div>
<div id="S1.SSx4.p3" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">The collection of architectural patterns provides a design solution pool for practitioners to select from for real-world federated learning system development.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">The federated learning model lifecycle with architectural pattern annotations, which serves as a systematic guide for practitioners during the design and development of a federated learning system.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SSx5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Paper Structure</h3>

<div id="S1.SSx5.p1" class="ltx_para">
<p id="S1.SSx5.p1.1" class="ltx_p">The remainder of the study is organised as follows. Section <a href="#S2" title="2 Methodology ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> introduces the research methodology. Section <a href="#S3" title="3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides an overview of the patterns in the federated learning lifecycle, followed by the detailed discussions on each pattern. Section <a href="#S4" title="4 Discussion ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarises and discusses some repeating challenges of federated learning systems and Section <a href="#S5" title="5 Related Work ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the related work. Finally, Section <a href="#S6" title="6 Conclusion ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> concludes the paper.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Sources of Patterns.</figcaption>
<table id="S1.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.3.1" class="ltx_tr">
<td id="S1.T1.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Category</span></td>
<td id="S1.T1.3.1.2" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.3.1.2.1" class="ltx_text"></span><span id="S1.T1.3.1.2.2" class="ltx_text ltx_font_bold" style="font-size:70%;"> <span id="S1.T1.3.1.2.2.1" class="ltx_text">
<span id="S1.T1.3.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.3.1.2.2.1.1.1" class="ltx_tr">
<span id="S1.T1.3.1.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.3.1.2.2.1.1.1.1.1" class="ltx_text" style="font-size:114%;">Pattern</span></span></span>
</span></span><span id="S1.T1.3.1.2.2.2" class="ltx_text"></span></span>
</td>
<td id="S1.T1.3.1.3" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.3.1.3.1" class="ltx_text"></span><span id="S1.T1.3.1.3.2" class="ltx_text ltx_font_bold" style="font-size:70%;">
<span id="S1.T1.3.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.3.1.3.2.1.1" class="ltx_tr">
<span id="S1.T1.3.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.3.1.3.2.1.1.1.1" class="ltx_text" style="font-size:114%;">SLR papers</span></span></span>
</span></span><span id="S1.T1.3.1.3.3" class="ltx_text"></span><span id="S1.T1.3.1.3.4" class="ltx_text ltx_font_bold" style="font-size:70%;"></span>
</td>
<td id="S1.T1.3.1.4" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.3.1.4.1" class="ltx_text"></span><span id="S1.T1.3.1.4.2" class="ltx_text ltx_font_bold" style="font-size:70%;">
<span id="S1.T1.3.1.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.3.1.4.2.1.1" class="ltx_tr">
<span id="S1.T1.3.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.3.1.4.2.1.1.1.1" class="ltx_text" style="font-size:114%;">ML/FL papers</span></span></span>
</span></span><span id="S1.T1.3.1.4.3" class="ltx_text"></span><span id="S1.T1.3.1.4.4" class="ltx_text ltx_font_bold" style="font-size:70%;"></span>
</td>
<td id="S1.T1.3.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.3.1.5.1" class="ltx_text"></span><span id="S1.T1.3.1.5.2" class="ltx_text ltx_font_bold" style="font-size:70%;">
<span id="S1.T1.3.1.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.3.1.5.2.1.1" class="ltx_tr">
<span id="S1.T1.3.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.3.1.5.2.1.1.1.1" class="ltx_text" style="font-size:114%;">Real-world applications</span></span></span>
</span></span><span id="S1.T1.3.1.5.3" class="ltx_text"></span><span id="S1.T1.3.1.5.4" class="ltx_text ltx_font_bold" style="font-size:70%;"></span>
</td>
</tr>
<tr id="S1.T1.3.2" class="ltx_tr">
<td id="S1.T1.3.2.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S1.T1.3.2.1.1" class="ltx_text" style="font-size:70%;">Client management patterns</span></td>
<td id="S1.T1.3.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.3.2.2.1" class="ltx_text" style="font-size:70%;">Pattern 1: Client registry</span></td>
<td id="S1.T1.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.2.3.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.2.4.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.2.5.1" class="ltx_text" style="font-size:70%;">3</span></td>
</tr>
<tr id="S1.T1.3.3" class="ltx_tr">
<td id="S1.T1.3.3.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.3.1.1" class="ltx_text" style="font-size:70%;">Pattern 2: Client selector</span></td>
<td id="S1.T1.3.3.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.3.2.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S1.T1.3.3.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.3.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.3.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.3.4.1" class="ltx_text" style="font-size:70%;">1</span></td>
</tr>
<tr id="S1.T1.3.4" class="ltx_tr">
<td id="S1.T1.3.4.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.4.1.1" class="ltx_text" style="font-size:70%;">Pattern 3: Client cluster</span></td>
<td id="S1.T1.3.4.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.4.2.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.4.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.4.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.4.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.4.4.1" class="ltx_text" style="font-size:70%;">2</span></td>
</tr>
<tr id="S1.T1.3.5" class="ltx_tr">
<td id="S1.T1.3.5.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S1.T1.3.5.1.1" class="ltx_text" style="font-size:70%;">Model management patterns</span></td>
<td id="S1.T1.3.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.3.5.2.1" class="ltx_text" style="font-size:70%;">Pattern 4: Message compressor</span></td>
<td id="S1.T1.3.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.5.3.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S1.T1.3.5.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.5.4.1" class="ltx_text" style="font-size:70%;">6</span></td>
<td id="S1.T1.3.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.5.5.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.6" class="ltx_tr">
<td id="S1.T1.3.6.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.6.1.1" class="ltx_text" style="font-size:70%;">Pattern 5: Model co-versioning registry</span></td>
<td id="S1.T1.3.6.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.6.2.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.6.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.6.3.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.6.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.6.4.1" class="ltx_text" style="font-size:70%;">4</span></td>
</tr>
<tr id="S1.T1.3.7" class="ltx_tr">
<td id="S1.T1.3.7.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.7.1.1" class="ltx_text" style="font-size:70%;">Pattern 6: Model replacement trigger</span></td>
<td id="S1.T1.3.7.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.7.2.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.7.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.7.3.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S1.T1.3.7.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.7.4.1" class="ltx_text" style="font-size:70%;">3</span></td>
</tr>
<tr id="S1.T1.3.8" class="ltx_tr">
<td id="S1.T1.3.8.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.8.1.1" class="ltx_text" style="font-size:70%;">Pattern 7: Deployment selector</span></td>
<td id="S1.T1.3.8.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.8.2.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.8.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.8.3.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.8.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.8.4.1" class="ltx_text" style="font-size:70%;">3</span></td>
</tr>
<tr id="S1.T1.3.9" class="ltx_tr">
<td id="S1.T1.3.9.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S1.T1.3.9.1.1" class="ltx_text" style="font-size:70%;">Model training patterns</span></td>
<td id="S1.T1.3.9.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.3.9.2.1" class="ltx_text" style="font-size:70%;">Pattern 8: Multi-task model trainer</span></td>
<td id="S1.T1.3.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.9.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.9.4.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S1.T1.3.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.9.5.1" class="ltx_text" style="font-size:70%;">3</span></td>
</tr>
<tr id="S1.T1.3.10" class="ltx_tr">
<td id="S1.T1.3.10.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.10.1.1" class="ltx_text" style="font-size:70%;">Pattern 9: Heterogeneous data handler</span></td>
<td id="S1.T1.3.10.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.10.2.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S1.T1.3.10.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.10.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.10.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.10.4.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.11" class="ltx_tr">
<td id="S1.T1.3.11.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.11.1.1" class="ltx_text" style="font-size:70%;">Pattern 10: Incentive registry</span></td>
<td id="S1.T1.3.11.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.11.2.1" class="ltx_text" style="font-size:70%;">18</span></td>
<td id="S1.T1.3.11.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.11.3.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S1.T1.3.11.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.11.4.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.12" class="ltx_tr">
<td id="S1.T1.3.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="4"><span id="S1.T1.3.12.1.1" class="ltx_text" style="font-size:70%;">Model aggregation patterns</span></td>
<td id="S1.T1.3.12.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.3.12.2.1" class="ltx_text" style="font-size:70%;">Pattern 11: Asynchronous aggregator</span></td>
<td id="S1.T1.3.12.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.12.3.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S1.T1.3.12.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.12.4.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S1.T1.3.12.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.12.5.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.13" class="ltx_tr">
<td id="S1.T1.3.13.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.13.1.1" class="ltx_text" style="font-size:70%;">Pattern 12: Decentralised aggregator</span></td>
<td id="S1.T1.3.13.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.13.2.1" class="ltx_text" style="font-size:70%;">5</span></td>
<td id="S1.T1.3.13.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.13.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.13.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.13.4.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.14" class="ltx_tr">
<td id="S1.T1.3.14.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.14.1.1" class="ltx_text" style="font-size:70%;">Pattern 13: Hierarchical aggregator</span></td>
<td id="S1.T1.3.14.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.14.2.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S1.T1.3.14.3" class="ltx_td ltx_align_center"><span id="S1.T1.3.14.3.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S1.T1.3.14.4" class="ltx_td ltx_align_center"><span id="S1.T1.3.14.4.1" class="ltx_text" style="font-size:70%;">0</span></td>
</tr>
<tr id="S1.T1.3.15" class="ltx_tr">
<td id="S1.T1.3.15.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S1.T1.3.15.1.1" class="ltx_text" style="font-size:70%;">Pattern 14: Secure aggregator</span></td>
<td id="S1.T1.3.15.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.3.15.2.1" class="ltx_text" style="font-size:70%;">31</span></td>
<td id="S1.T1.3.15.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.3.15.3.1" class="ltx_text" style="font-size:70%;">0</span></td>
<td id="S1.T1.3.15.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.3.15.4.1" class="ltx_text" style="font-size:70%;">3</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Fig. <a href="#S1.F2" title="Figure 2 ‣ Design Challenges ‣ 1 Introduction ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the federated learning pattern extraction and collection process. Firstly, the patterns are collected based on the results of our previous systematic literature review (SLR) on federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">31</span></a>]</cite>. SLR and situational method engineering (SME) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> are some of the renowned systematic methodologies for derivation of pattern languages. For instance, several pattern derivations on cloud migration and software architecture have used SLR (e.g., Zdun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">48</span></a>]</cite>, Aakash Ahmad et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, and Jamshidi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">18</span></a>]</cite>). Moreover, Balalaie et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> have derived the pattern languages in the context of cloud-native and microservices using situational method engineering.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">For this work, we have adopted the SLR method as the currently available materials and research works on federated learning are still highly academic-based. Secondly, we intend to propose design patterns for software architectural design aspects of building federated learning systems rather than for their development/engineering processes. This is because, during the SLR work, we have identified many architectural design challenges and lack of systematic design approaches to federated learning. Furthermore, while SME has the benefit of offering a systematic methodology for selecting appropriate method components from a repository of reusable method components, it is more suitable for pattern extraction of an information system development (ISD) process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">35</span></a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The SLR was performed according to Kitchenham’s SLR guideline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">23</span></a>]</cite>, and the number of final studied papers is 231. During the SLR, we developed a comprehensive mapping between federated learning challenges and approaches. Additionally, we reviewed 22 machine learning and federated learning papers published after the SLR search cut-off date (31st Jan 2020) and 22 real-world applications. The additional literature review on machine learning and federated learning, and the review of the real-world applications are conducted based on our past real-world project implementation experience. Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:mapping</span> shows a mapping between each pattern with its respective number of source papers and real-world applications. Twelve patterns were initially collected from SLR or additional literature review, whereas the remaining two patterns were identified through real-world applications.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">We discussed the proposed patterns according to the pattern form presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">34</span></a>]</cite>. The form comprehensively describes the patterns by discussing the <span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Context</span>, <span id="S2.p4.1.2" class="ltx_text ltx_font_bold">Problem</span>, <span id="S2.p4.1.3" class="ltx_text ltx_font_bold">Forces</span>, <span id="S2.p4.1.4" class="ltx_text ltx_font_bold">Solution</span>, <span id="S2.p4.1.5" class="ltx_text ltx_font_bold">Consequences</span>, <span id="S2.p4.1.6" class="ltx_text ltx_font_bold">Related patterns</span>, and <span id="S2.p4.1.7" class="ltx_text ltx_font_bold">Known-uses</span> of the pattern.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">The <span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Context</span> is the description of the situation where a problem occurs, in which the solution proposed is applicable, or the problem is solvable by the pattern. <span id="S2.p5.1.2" class="ltx_text ltx_font_bold">Problem</span> comprehensively elicits the challenges and limitations that occur under the defined context. <span id="S2.p5.1.3" class="ltx_text ltx_font_bold">Forces</span> describe the reasons and causes for a specific design or pattern decision to be made to resolve the problem. <span id="S2.p5.1.4" class="ltx_text ltx_font_bold">Solution</span> describes how the problem and the conflict of forces can be resolved by a specific pattern. <span id="S2.p5.1.5" class="ltx_text ltx_font_bold">Consequences</span> reason about the impact of applying a solution, specifically on the contradictions among the benefits, costs, drawbacks, tradeoffs, and liabilities of the solution. <span id="S2.p5.1.6" class="ltx_text ltx_font_bold">Related patterns</span> record the other patterns from this paper that are related to the current pattern. <span id="S2.p5.1.7" class="ltx_text ltx_font_bold">Known-uses</span> refer to empirical evidence that the solution has been used in the real world.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Learning Patterns</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Fig. <a href="#S3.F3" title="Figure 3 ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the lifecycle of a model in a federated learning system. The lifecycle covers the deployment of the completely trained global model to the client devices (i.e., model users) for data inference. The deployment process involves the communication between the central server and the client devices. We categorise the federated learning patterns as shown in Table <a href="#S3.T2" title="Table 2 ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> to provide an overview. There are four main groups: (1) client management patterns, (2) model management patterns, (3) model training patterns, and (4) model aggregation patterns.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Overview of architectural patterns for federated learning</figcaption>
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.3.1" class="ltx_tr">
<td id="S3.T2.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T2.3.1.1.1.1.1" class="ltx_text"></span><span id="S3.T2.3.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:70%;">
<span id="S3.T2.3.1.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.3.1.1.1.1.2.1.1" class="ltx_tr">
<span id="S3.T2.3.1.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T2.3.1.1.1.1.2.1.1.1.1" class="ltx_text" style="font-size:114%;">Category</span></span></span>
</span></span><span id="S3.T2.3.1.1.1.1.3" class="ltx_text"></span><span id="S3.T2.3.1.1.1.1.4" class="ltx_text ltx_font_bold" style="font-size:70%;"></span></span>
</span>
</td>
<td id="S3.T2.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.1.2.1.1.1" class="ltx_text"></span><span id="S3.T2.3.1.2.1.1.2" class="ltx_text ltx_font_bold" style="font-size:70%;"> <span id="S3.T2.3.1.2.1.1.2.1" class="ltx_text">
<span id="S3.T2.3.1.2.1.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.3.1.2.1.1.2.1.1.1" class="ltx_tr">
<span id="S3.T2.3.1.2.1.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.3.1.2.1.1.2.1.1.1.1.1" class="ltx_text" style="font-size:114%;">Name</span></span></span>
</span></span><span id="S3.T2.3.1.2.1.1.2.2" class="ltx_text"></span></span></span>
</span>
</td>
<td id="S3.T2.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.1.3.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.1.3.1.1.1" class="ltx_text"></span><span id="S3.T2.3.1.3.1.1.2" class="ltx_text ltx_font_bold" style="font-size:70%;"> <span id="S3.T2.3.1.3.1.1.2.1" class="ltx_text">
<span id="S3.T2.3.1.3.1.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.3.1.3.1.1.2.1.1.1" class="ltx_tr">
<span id="S3.T2.3.1.3.1.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.3.1.3.1.1.2.1.1.1.1.1" class="ltx_text" style="font-size:114%;">Summary</span></span></span>
</span></span><span id="S3.T2.3.1.3.1.1.2.2" class="ltx_text"></span></span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.2" class="ltx_tr">
<td id="S3.T2.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="3">
<span id="S3.T2.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T2.3.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Client management patterns</span></span>
</span>
</td>
<td id="S3.T2.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.2.2.1.1.1" class="ltx_text" style="font-size:70%;">Client registry</span></span>
</span>
</td>
<td id="S3.T2.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.2.3.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.2.3.1.1.1" class="ltx_text" style="font-size:70%;">Maintains the information of all the participating client devices for client management.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.3" class="ltx_tr">
<td id="S3.T2.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Client selector</span></span>
</span>
</td>
<td id="S3.T2.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.3.2.1.1.1" class="ltx_text" style="font-size:70%;">Actively selects the client devices for a certain round of training according to the predefined criteria to increase model performance and system efficiency.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.4" class="ltx_tr">
<td id="S3.T2.3.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Client cluster</span></span>
</span>
</td>
<td id="S3.T2.3.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.4.2.1.1.1" class="ltx_text" style="font-size:70%;">Groups the client devices (i.e., model trainers) based on their similarity of certain characteristics (e.g., available resources, data distribution, features, geolocation) to increase the model performance and training efficiency.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.5" class="ltx_tr">
<td id="S3.T2.3.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" rowspan="4">
<span id="S3.T2.3.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T2.3.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Model management patterns</span></span>
</span>
</td>
<td id="S3.T2.3.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.5.2.1.1.1" class="ltx_text" style="font-size:70%;">Message compressor</span></span>
</span>
</td>
<td id="S3.T2.3.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.3.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.5.3.1.1.1" class="ltx_text" style="font-size:70%;">Compresses and reduces the message data size before every round of model exchange to increase the communication efficiency.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.6" class="ltx_tr">
<td id="S3.T2.3.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.6.1.1.1.1" class="ltx_text" style="font-size:70%;">Model co-versioning registry</span></span>
</span>
</td>
<td id="S3.T2.3.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.6.2.1.1.1" class="ltx_text" style="font-size:70%;">Stores and aligns the local models from each client with the corresponding global model versions for model provenance and model performance tracking.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.7" class="ltx_tr">
<td id="S3.T2.3.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.7.1.1.1.1" class="ltx_text" style="font-size:70%;">Model replacement trigger</span></span>
</span>
</td>
<td id="S3.T2.3.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.7.2.1.1.1" class="ltx_text" style="font-size:70%;">Triggers model replacement when the degradation in model performance is detected.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.8" class="ltx_tr">
<td id="S3.T2.3.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.8.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.8.1.1.1.1" class="ltx_text" style="font-size:70%;">Deployment selector</span></span>
</span>
</td>
<td id="S3.T2.3.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.8.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.8.2.1.1.1" class="ltx_text" style="font-size:70%;">Selects and matches the converged global models to suitable client devices to maximise the global models’ performance for different applications and tasks.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.9" class="ltx_tr">
<td id="S3.T2.3.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" rowspan="3">
<span id="S3.T2.3.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T2.3.9.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Model training patterns</span></span>
</span>
</td>
<td id="S3.T2.3.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.9.2.1.1.1" class="ltx_text" style="font-size:70%;">Multi-task model trainer</span></span>
</span>
</td>
<td id="S3.T2.3.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.3.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.9.3.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.9.3.1.1.1" class="ltx_text" style="font-size:70%;">Utilises data from separate but related models on local client devices to improve learning efficiency and model performance.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.10" class="ltx_tr">
<td id="S3.T2.3.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.10.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.10.1.1.1.1" class="ltx_text" style="font-size:70%;">Heterogeneous data handler</span></span>
</span>
</td>
<td id="S3.T2.3.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.10.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.10.2.1.1.1" class="ltx_text" style="font-size:70%;">Solves the non-IID and skewed data distribution issues through data volume and data class addition while maintaining the local data privacy.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.11" class="ltx_tr">
<td id="S3.T2.3.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.11.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.11.1.1.1.1" class="ltx_text" style="font-size:70%;">Incentive registry</span></span>
</span>
</td>
<td id="S3.T2.3.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.11.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.11.2.1.1.1" class="ltx_text" style="font-size:70%;">Measures and records the performance and contributions of each client and provides incentives to motivate clients’ participation.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.12" class="ltx_tr">
<td id="S3.T2.3.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" rowspan="8">
<span id="S3.T2.3.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T2.3.12.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Model aggregation patterns</span></span>
</span>
</td>
<td id="S3.T2.3.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.12.2.1.1.1" class="ltx_text" style="font-size:70%;">Asynchronous aggregator</span></span>
</span>
</td>
<td id="S3.T2.3.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.12.3.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.12.3.1.1.1" class="ltx_text" style="font-size:70%;">Performs aggregation asynchronously whenever a model update arrives without waiting for all the model updates every round to reduce aggregation latency.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.13" class="ltx_tr">
<td id="S3.T2.3.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.13.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.13.1.1.1.1" class="ltx_text" style="font-size:70%;">Decentralised aggregator</span></span>
</span>
</td>
<td id="S3.T2.3.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.13.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.13.2.1.1.1" class="ltx_text" style="font-size:70%;">Removes the central server from the system and decentralizes its role to prevent single-point-of-failure and increase system reliability.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.14" class="ltx_tr">
<td id="S3.T2.3.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.14.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.14.1.1.1.1" class="ltx_text" style="font-size:70%;">Hierarchical aggregator</span></span>
</span>
</td>
<td id="S3.T2.3.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.3.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.14.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.14.2.1.1.1" class="ltx_text" style="font-size:70%;">Adds an edge layer to perform partial aggregation of local models from closely-related client devices to improve model quality and system efficiency.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.15" class="ltx_tr">
<td id="S3.T2.3.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.3.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.15.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T2.3.15.1.1.1.1" class="ltx_text" style="font-size:70%;">Secure aggregator</span></span>
</span>
</td>
<td id="S3.T2.3.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.3.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.15.2.1.1" class="ltx_p" style="width:520.3pt;"><span id="S3.T2.3.15.2.1.1.1" class="ltx_text" style="font-size:70%;">The adoption of secure multiparty computation (MPC) protocols that manages the model exchange and aggregation security to protect model security.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2101.02373/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A Model’s Lifecycle in Federated Learning.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_bold">Client Management Patterns</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Client management patterns describe the patterns that manage the client devices’ information and their interaction with the central server. A <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">client registry</span> manages the information of all the participating client devices. <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">Client selector</span> selects client devices for a specific training task, while <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">client cluster</span> increases the model performance and training efficiency through grouping client devices based on the similarity of certain characteristics (e.g., available resources, data distribution).</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span><span id="S3.SS1.SSS1.1.1" class="ltx_text ltx_font_bold">Pattern 1: Client Registry</span>
</h4>

<figure id="S3.F4" class="ltx_figure"><img src="/html/2101.02373/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="323" height="308" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Client Registry.</figcaption>
</figure>
<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p"><span id="S3.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A client registry maintains the information of all the participating client devices for client management. According to Fig. <a href="#S3.F4" title="Figure 4 ‣ 3.1.1 Pattern 1: Client Registry ‣ 3.1 Client Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the client registry is maintained in the central server. The central server sends the request for information to the client devices. The client devices then send the requested information together with the first local model updates.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p"><span id="S3.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Client management is centralised, and global and local models are exchanged between the central server the massive number of distributed client devices with dynamic connectivity and diverse resources.</p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para">
<p id="S3.SS1.SSS1.p3.1" class="ltx_p"><span id="S3.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> It is challenging for a federated learning system to track any dishonest, failed, or dropout node. This is crucial to secure the central server and client devices from adversarial threats. Moreover, to effectively align the model training process of each client device for each aggregation round, a record of the connection and training information of each client device that has interacted with the central server is required.</p>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para">
<p id="S3.SS1.SSS1.p4.1" class="ltx_p"><span id="S3.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS1.SSS1.p5" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Updatability.</span> The ability to keep track of the participating devices is necessary to ensure the information recorded is up-to-date.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> The records of client information expose the clients to data privacy issues. For instance, the device usage pattern of users may be inferred from the device connection up-time, device information, resources, etc.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS1.p6" class="ltx_para">
<p id="S3.SS1.SSS1.p6.1" class="ltx_p"><span id="S3.SS1.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A client registry records all the information of client devices that are connected to the system from the first time. The information includes device ID, connection up &amp; downtime, device resource information (computation, communication, power &amp; storage). The access to the client registry could be restricted according to the agreement between the central server and participating client devices.</p>
</div>
<div id="S3.SS1.SSS1.p7" class="ltx_para">
<p id="S3.SS1.SSS1.p7.1" class="ltx_p"><span id="S3.SS1.SSS1.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS1.SSS1.p8" class="ltx_para">
<p id="S3.SS1.SSS1.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">Maintainability.</span> The client registry enables the system to effectively manage the dynamically connecting and disconnecting clients.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">Reliability.</span> The client registry provides status tracking for all the devices, which is essential for problematic node identification.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS1.p9" class="ltx_para">
<p id="S3.SS1.SSS1.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS1.SSS1.p10" class="ltx_para">
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><span id="S3.I3.i1.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> The recording of the device information on the central server leads to client data privacy issues.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.p1.1.1" class="ltx_text ltx_font_italic">Cost.</span> The maintenance of client device information requires extra communication cost and storage cost, which further surges when the number of client devices increases.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS1.p11" class="ltx_para">
<p id="S3.SS1.SSS1.p11.1" class="ltx_p"><span id="S3.SS1.SSS1.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS1.SSS1.p11.1.2" class="ltx_text ltx_font_italic">Model Co-Versioning Registry, Client Selector, Client Cluster, Asynchronous Aggregator, Hierarchical Aggregator</span></p>
</div>
<div id="S3.SS1.SSS1.p12" class="ltx_para">
<p id="S3.SS1.SSS1.p12.1" class="ltx_p"><span id="S3.SS1.SSS1.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p"><span id="S3.I4.i1.p1.1.1" class="ltx_text ltx_font_italic">IBM Federated Learning<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnote2.1.1.1" class="ltx_text ltx_font_upright">2</span></span><a target="_blank" href="https://github.com/IBM/federated-learning-lib" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/IBM/federated-learning-lib</a></span></span></span></span>: <span id="S3.I4.i1.p1.1.2" class="ltx_text ltx_font_italic">Party Stack</span> component manages the client parties of IBM federated learning framework, that contains sub-components such as protocol handler, connection, model, local training, and data handler for client devices registration and management.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p">doc.ai<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://doc.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doc.ai/</a></span></span></span>: Client registry is designed for medical research applications to ensure that updates received apply to a current version of the global model, and not a deprecated global model.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p"><span id="S3.I4.i3.p1.1.1" class="ltx_text ltx_font_italic">SIEMENS Mindsphere Asset Manager <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><a target="_blank" href="https://documentation.mindsphere.io/resources/html/asset-manager/en-US/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://documentation.mindsphere.io/resources/html/asset-manager/en-US/index.html</a></span></span></span></span>:To support the collaboration of federated learning clients in industrial IoT environment, <span id="S3.I4.i3.p1.1.2" class="ltx_text ltx_font_italic">Industrial Metadata Management</span> is introduced as a device metadata and asset data manager.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span><span id="S3.SS1.SSS2.1.1" class="ltx_text ltx_font_bold">Pattern 2: Client Selector</span>
</h4>

<figure id="S3.F5" class="ltx_figure"><img src="/html/2101.02373/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Client Selector.</figcaption>
</figure>
<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p"><span id="S3.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A client selector actively selects the client devices for a certain round of training according to the predefined criteria to increase model performance and system efficiency. As shown in Fig. <a href="#S3.F5" title="Figure 5 ‣ 3.1.2 Pattern 2: Client Selector ‣ 3.1 Client Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the central server assesses the performance of each client according to the information received. Based on the assessment results, the second client is excluded from receiving the global model.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p"><span id="S3.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Multiple rounds of model exchanges are performed and communication cost becomes a bottleneck. Furthermore, multiple iterations of aggregations are performed and consume high computation resources.</p>
</div>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.1" class="ltx_p"><span id="S3.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> The central server is burdensome to accommodate the communication with massive number of widely-distributed client devices every round.</p>
</div>
<div id="S3.SS1.SSS2.p4" class="ltx_para">
<p id="S3.SS1.SSS2.p4.1" class="ltx_p"><span id="S3.SS1.SSS2.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires the following forces to be balanced:</p>
<ul id="S3.I5" class="ltx_itemize">
<li id="S3.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i1.p1" class="ltx_para">
<p id="S3.I5.i1.p1.1" class="ltx_p"><span id="S3.I5.i1.p1.1.1" class="ltx_text ltx_font_italic">Latency.</span> Client devices have system heterogeneity (difference in computation, communication, &amp; energy resources) that affect the local model training and global model aggregation time.</p>
</div>
</li>
<li id="S3.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i2.p1" class="ltx_para">
<p id="S3.I5.i2.p1.1" class="ltx_p"><span id="S3.I5.i2.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> Local data are statistically heterogeneous (different data distribution/quality) which produce local models that overfit the local data.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS2.p5" class="ltx_para">
<p id="S3.SS1.SSS2.p5.1" class="ltx_p"><span id="S3.SS1.SSS2.p5.1.1" class="ltx_text ltx_font_bold">Solution:</span> Selecting client devices with predefined criteria can optimise the formation of the global model. The client selector on the central server performs client selection every round to include the best fitting client devices for global model aggregation. The selection criteria can be configured as follows:</p>
<ul id="S3.I6" class="ltx_itemize">
<li id="S3.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i1.p1" class="ltx_para">
<p id="S3.I6.i1.p1.1" class="ltx_p">Resource-based: The central server assesses the resources available on each client devices every training round and selects the client devices with the satisfied resource status (e.g., WiFi connection, pending status, sleep time)</p>
</div>
</li>
<li id="S3.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i2.p1" class="ltx_para">
<p id="S3.I6.i2.p1.1" class="ltx_p">Data-based: The central server examines the information of the data collected by each client, specifically on the number of data classes, distribution of data sample volume per class, and data quality. Based on these assessments, the model training process includes devices with high-quality data, higher data volume per class, and excludes the devices with low-quality data, or data that are highly heterogeneous in comparison with other devices.</p>
</div>
</li>
<li id="S3.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i3.p1" class="ltx_para">
<p id="S3.I6.i3.p1.1" class="ltx_p">Performance-based: Performance-based client selection can be conducted through local model performance assessment (e.g., performance of the latest local model or the historical records of local model performance).</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS2.p6" class="ltx_para">
<p id="S3.SS1.SSS2.p6.1" class="ltx_p"><span id="S3.SS1.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS1.SSS2.p7" class="ltx_para">
<p id="S3.SS1.SSS2.p7.1" class="ltx_p">Benefits:</p>
<ul id="S3.I7" class="ltx_itemize">
<li id="S3.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i1.p1" class="ltx_para">
<p id="S3.I7.i1.p1.1" class="ltx_p"><span id="S3.I7.i1.p1.1.1" class="ltx_text ltx_font_italic">Resource optimisation.</span> The client selection optimises the resource usage of the central server to compute and communicate with suitable client devices for each aggregation round, without wasting resources to aggregate the low-quality models.</p>
</div>
</li>
<li id="S3.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i2.p1" class="ltx_para">
<p id="S3.I7.i2.p1.1" class="ltx_p"><span id="S3.I7.i2.p1.1.1" class="ltx_text ltx_font_italic">System performance.</span> Selecting clients with sufficient power and network bandwidth greatly reduces the chances of clients dropping out and lowers the communication latency.</p>
</div>
</li>
<li id="S3.I7.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i3.p1" class="ltx_para">
<p id="S3.I7.i3.p1.1" class="ltx_p"><span id="S3.I7.i3.p1.1.1" class="ltx_text ltx_font_italic">Model performance.</span> Selecting clients with the higher local model performance or lower data heterogeneity increases the global model quality.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS2.p8" class="ltx_para">
<p id="S3.SS1.SSS2.p8.1" class="ltx_p">Drawbacks:</p>
<ul id="S3.I8" class="ltx_itemize">
<li id="S3.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i1.p1" class="ltx_para">
<p id="S3.I8.i1.p1.1" class="ltx_p"><span id="S3.I8.i1.p1.1.1" class="ltx_text ltx_font_italic">Model generality.</span> The exclusion of models from certain client devices may lead to the missing of essential data features and the loss of the global model generality.</p>
</div>
</li>
<li id="S3.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i2.p1" class="ltx_para">
<p id="S3.I8.i2.p1.1" class="ltx_p"><span id="S3.I8.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> The central server needs to acquire the system and resource information (processor’s capacity, network availability, bandwidth, online status, etc.) every round to perform devices ranking and selection. Access to client devices’ information creates data privacy issues.</p>
</div>
</li>
<li id="S3.I8.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i3.p1" class="ltx_para">
<p id="S3.I8.i3.p1.1" class="ltx_p"><span id="S3.I8.i3.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> Extra resources are spent on transferring of the required information for selection decision-making.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS2.p9" class="ltx_para">
<p id="S3.SS1.SSS2.p9.1" class="ltx_p"><span id="S3.SS1.SSS2.p9.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS1.SSS2.p9.1.2" class="ltx_text ltx_font_italic">Client Registry, Deployment Selector</span></p>
</div>
<div id="S3.SS1.SSS2.p10" class="ltx_para">
<p id="S3.SS1.SSS2.p10.1" class="ltx_p"><span id="S3.SS1.SSS2.p10.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I9" class="ltx_itemize">
<li id="S3.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i1.p1" class="ltx_para">
<p id="S3.I9.i1.p1.1" class="ltx_p"><span id="S3.I9.i1.p1.1.1" class="ltx_text ltx_font_italic">Google’s FedAvg</span>: <span id="S3.I9.i1.p1.1.2" class="ltx_text ltx_font_italic">FedAvg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">33</span></a>]</cite> algorithm includes client selection that randomly selects a subset of clients for each round based on predefined environment conditions and device specification of the client devices.</p>
</div>
</li>
<li id="S3.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i2.p1" class="ltx_para">
<p id="S3.I9.i2.p1.1" class="ltx_p">In <span id="S3.I9.i2.p1.1.1" class="ltx_text ltx_font_italic">IBM’s Helios</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">45</span></a>]</cite>, there is a training consumption profiling function that fully profiles the resource consumption for model training on client devices. Based on that profiling, a resource-aware soft-training scheme is designed to accelerate local model training on heterogeneous devices and prevent stragglers from delaying the collaborative learning process.</p>
</div>
</li>
<li id="S3.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i3.p1" class="ltx_para">
<p id="S3.I9.i3.p1.1" class="ltx_p"><span id="S3.I9.i3.p1.1.1" class="ltx_text ltx_font_italic">FedCS</span> suggested by OMRON SINIC X Corporation<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://www.omron.com/sinicx/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.omron.com/sinicx/</a></span></span></span> sets a certain deadline for clients to upload the model updates.</p>
</div>
</li>
<li id="S3.I9.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i4.p1" class="ltx_para">
<p id="S3.I9.i4.p1.1" class="ltx_p"><span id="S3.I9.i4.p1.1.1" class="ltx_text ltx_font_italic">Communication-Mitigated Federated Learning (CMFL)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">40</span></a>]</cite> excludes the irrelevant local updates by identifying the relevance of a client update by comparing its global tendency of model updating with all the other clients.</p>
</div>
</li>
<li id="S3.I9.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i5.p1" class="ltx_para">
<p id="S3.I9.i5.p1.1" class="ltx_p"><span id="S3.I9.i5.p1.1.1" class="ltx_text ltx_font_italic">CDW_FedAvg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">49</span></a>]</cite> takes the centroid distance between the positive and negative classes of each client dataset into account for aggregation.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span><span id="S3.SS1.SSS3.1.1" class="ltx_text ltx_font_bold">Pattern 3: Client Cluster</span>
</h4>

<figure id="S3.F6" class="ltx_figure"><img src="/html/2101.02373/assets/x6.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="276" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Client Cluster.</figcaption>
</figure>
<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p"><span id="S3.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A client cluster groups the client devices (i.e., model trainers) based on their similarity of certain characteristics (e.g., available resources, data distribution, features, geolocation) to increase the model performance and training efficiency. In Fig. <a href="#S3.F6" title="Figure 6 ‣ 3.1.3 Pattern 3: Client Cluster ‣ 3.1 Client Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the client devices are clustered into 2 groups by the central server, and the central server will broadcast the global model that is more related to the clusters accordingly.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.1" class="ltx_p"><span id="S3.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The system trains models over client devices which have diverse communication and computation resources, resulted in statistical and system heterogeneity challenges.</p>
</div>
<div id="S3.SS1.SSS3.p3" class="ltx_para">
<p id="S3.SS1.SSS3.p3.1" class="ltx_p"><span id="S3.SS1.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Federated learning models generated under non-IID data properties are deemed to be less generalised. This is due to the lack of significantly representative data labels from the client devices. Furthermore, local models may drift significantly from each other.</p>
</div>
<div id="S3.SS1.SSS3.p4" class="ltx_para">
<p id="S3.SS1.SSS3.p4.1" class="ltx_p"><span id="S3.SS1.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS1.SSS3.p5" class="ltx_para">
<ul id="S3.I10" class="ltx_itemize">
<li id="S3.I10.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i1.p1" class="ltx_para">
<p id="S3.I10.i1.p1.1" class="ltx_p"><span id="S3.I10.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost and training time.</span> More computation costs and longer training time are required to overcome the non-IID issue of client devices.</p>
</div>
</li>
<li id="S3.I10.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i2.p1" class="ltx_para">
<p id="S3.I10.i2.p1.1" class="ltx_p"><span id="S3.I10.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> Data privacy contradicts with the Access to the entire or parts of the client’s raw data is needed by the learning coordinator to resolve the non-IID issue which creates data privacy risks.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS3.p6" class="ltx_para">
<p id="S3.SS1.SSS3.p6.1" class="ltx_p"><span id="S3.SS1.SSS3.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> Client devices are clustered into different groups according to their properties (e.g., data distribution, features similarities, gradient loss). By creating clusters of clients with similar data patterns, the global model generated will have better performance for the non-IID-severe client network, without accessing the local data.</p>
</div>
<div id="S3.SS1.SSS3.p7" class="ltx_para">
<p id="S3.SS1.SSS3.p7.1" class="ltx_p"><span id="S3.SS1.SSS3.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS1.SSS3.p8" class="ltx_para">
<p id="S3.SS1.SSS3.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I11" class="ltx_itemize">
<li id="S3.I11.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I11.i1.p1" class="ltx_para">
<p id="S3.I11.i1.p1.1" class="ltx_p"><span id="S3.I11.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> The global model created by client clusters can have a higher model performance for highly personalised prediction tasks.</p>
</div>
</li>
<li id="S3.I11.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I11.i2.p1" class="ltx_para">
<p id="S3.I11.i2.p1.1" class="ltx_p"><span id="S3.I11.i2.p1.1.1" class="ltx_text ltx_font_italic">Convergence speed.</span> The consequent deployed global models can have faster convergence speed as the models of the same cluster can identify the gradient’s minima much faster when the clients’ data distribution and IIDness are similar.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS3.p9" class="ltx_para">
<p id="S3.SS1.SSS3.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS1.SSS3.p10" class="ltx_para">
<ul id="S3.I12" class="ltx_itemize">
<li id="S3.I12.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I12.i1.p1" class="ltx_para">
<p id="S3.I12.i1.p1.1" class="ltx_p"><span id="S3.I12.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> The central server consumes extra computation cost and time for client clustering and relationship quantification.</p>
</div>
</li>
<li id="S3.I12.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I12.i2.p1" class="ltx_para">
<p id="S3.I12.i2.p1.1" class="ltx_p"><span id="S3.I12.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> The learning coordinator (i.e., central server) requires extra client device information (e.g., data distribution, feature similarities, gradient loss) to perform clustering. This exposes the client devices to the possible risk of private data leakage.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.SSS3.p11" class="ltx_para">
<p id="S3.SS1.SSS3.p11.1" class="ltx_p"><span id="S3.SS1.SSS3.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS1.SSS3.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector, Deployment Selector</span></p>
</div>
<div id="S3.SS1.SSS3.p12" class="ltx_para">
<p id="S3.SS1.SSS3.p12.1" class="ltx_p"><span id="S3.SS1.SSS3.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I13" class="ltx_itemize">
<li id="S3.I13.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I13.i1.p1" class="ltx_para">
<p id="S3.I13.i1.p1.1" class="ltx_p">Iterative Federated Clustering Algorithm (<span id="S3.I13.i1.p1.1.1" class="ltx_text ltx_font_italic">IFCA</span>)<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/jichan3751/ifca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jichan3751/ifca</a></span></span></span> is a 
<br class="ltx_break">framework introduced by UC Berkley and Google to cluster client devices based on the loss values of the client’s gradient.</p>
</div>
</li>
<li id="S3.I13.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I13.i2.p1" class="ltx_para">
<p id="S3.I13.i2.p1.1" class="ltx_p">Clustered Federated Learning (<span id="S3.I13.i2.p1.1.1" class="ltx_text ltx_font_italic">CFL</span>)<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/felisat/clustered-federated-learning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/felisat/clustered-federated-learning</a></span></span></span>
uses a cosine simila
<br class="ltx_break">rity-based clustering method that creates a bi-partitioning to group client devices with the same data generating distribution into the same cluster.</p>
</div>
</li>
<li id="S3.I13.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I13.i3.p1" class="ltx_para">
<p id="S3.I13.i3.p1.1" class="ltx_p"><span id="S3.I13.i3.p1.1.1" class="ltx_text ltx_font_italic">TiFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> is a tier-based federated learning system that adaptively groups client devices with similar training time per round to mitigate the heterogeneity problem without affecting the model accuracy.</p>
</div>
</li>
<li id="S3.I13.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I13.i4.p1" class="ltx_para">
<p id="S3.I13.i4.p1.1" class="ltx_p">Patient clustering in a federated learning system is implemented by Massachusetts General Hospital to improve efficiency in predicting mortality and hospital stay time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">17</span></a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_bold">Model Management Patterns</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Model management patterns include patterns that handle mo
<br class="ltx_break">-del transmission, deployment, and governance. A <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">message compressor</span> reduces the transmitted message size. A <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">model co-versioning registry</span> records all local model versions from each client and aligns them with their corresponding global model. A <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">model replacement trigger</span> initiates a new model training task when the converged global model’s performance degrades. A <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">deployment selector</span> deploys the global model to the selected clients to improve the model quality for personalised tasks.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span><span id="S3.SS2.SSS1.1.1" class="ltx_text ltx_font_bold">Pattern 4: Message Compressor</span>
</h4>

<figure id="S3.F7" class="ltx_figure"><img src="/html/2101.02373/assets/x7.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="134" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Message Compressor.</figcaption>
</figure>
<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p"><span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A message compressor reduces the message data size before every round of model exchange to increase the communication efficiency. Fig. <a href="#S3.F7" title="Figure 7 ‣ 3.2.1 Pattern 4: Message Compressor ‣ 3.2 Model Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates the operation of the pattern on both ends of the system (client device and central server).</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p"><span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Multiple rounds of model exchanges occurs between a central server and many client devices to complete the model training.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p"><span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Communication cost for model communication (e.g., transferring model parameters or gradients) is often a critical bottleneck when the system scales up, especially for bandwidth-limited client devices.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p"><span id="S3.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<ul id="S3.I14" class="ltx_itemize">
<li id="S3.I14.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I14.i1.p1" class="ltx_para">
<p id="S3.I14.i1.p1.1" class="ltx_p"><span id="S3.I14.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> High computation costs are required by the central server to aggregate all the bulky model parameters collected every round.</p>
</div>
</li>
<li id="S3.I14.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I14.i2.p1" class="ltx_para">
<p id="S3.I14.i2.p1.1" class="ltx_p"><span id="S3.I14.i2.p1.1.1" class="ltx_text ltx_font_italic">Communication cost.</span> Communication costs are scarce to communicate the model parameters and gradients between resource-limited client devices and the central server.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<p id="S3.SS2.SSS1.p6.1" class="ltx_p"><span id="S3.SS2.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> The model parameters and the training task script as one message package is compressed before being transferred between the central server and client devices.</p>
</div>
<div id="S3.SS2.SSS1.p7" class="ltx_para">
<p id="S3.SS2.SSS1.p7.1" class="ltx_p"><span id="S3.SS2.SSS1.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS2.SSS1.p8" class="ltx_para">
<p id="S3.SS2.SSS1.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I15" class="ltx_itemize">
<li id="S3.I15.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I15.i1.p1" class="ltx_para">
<p id="S3.I15.i1.p1.1" class="ltx_p"><span id="S3.I15.i1.p1.1.1" class="ltx_text ltx_font_italic">Communication efficiency.</span> The compression of model parameters reduces the communication cost and network
<br class="ltx_break">throughput for model exchanges.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.p9" class="ltx_para">
<p id="S3.SS2.SSS1.p9.1" class="ltx_p">Drawbacks:</p>
<ul id="S3.I16" class="ltx_itemize">
<li id="S3.I16.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I16.i1.p1" class="ltx_para">
<p id="S3.I16.i1.p1.1" class="ltx_p"><span id="S3.I16.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> Extra computation is required for message compression and decompression every round.</p>
</div>
</li>
<li id="S3.I16.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I16.i2.p1" class="ltx_para">
<p id="S3.I16.i2.p1.1" class="ltx_p"><span id="S3.I16.i2.p1.1.1" class="ltx_text ltx_font_italic">Loss of information.</span> The downsizing of the model parameters might cause the loss of essential information.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.p10" class="ltx_para">
<p id="S3.SS2.SSS1.p10.1" class="ltx_p"><span id="S3.SS2.SSS1.p10.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS2.SSS1.p10.1.2" class="ltx_text ltx_font_italic">Client Registry, Model Co-Versioning Registry</span></p>
</div>
<div id="S3.SS2.SSS1.p11" class="ltx_para">
<p id="S3.SS2.SSS1.p11.1" class="ltx_p"><span id="S3.SS2.SSS1.p11.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I17" class="ltx_itemize">
<li id="S3.I17.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I17.i1.p1" class="ltx_para">
<p id="S3.I17.i1.p1.1" class="ltx_p"><span id="S3.I17.i1.p1.1.1" class="ltx_text ltx_font_italic">Google Sketched Update</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">24</span></a>]</cite>: Google proposes two communication efficient update approaches: structured update and sketched update. Structured update directly learns an update from a restricted space that can be parametrised using a smaller number of variables, whereas sketched update compresses the model before sending it to the central server.</p>
</div>
</li>
<li id="S3.I17.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I17.i2.p1" class="ltx_para">
<p id="S3.I17.i2.p1.1" class="ltx_p"><span id="S3.I17.i2.p1.1.1" class="ltx_text ltx_font_italic">IBM PruneFL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">21</span></a>]</cite> adaptively prunes the distributed parameters of the models, including initial pruning at a selected client and further pruning as part of the federated learning process.</p>
</div>
</li>
<li id="S3.I17.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I17.i3.p1" class="ltx_para">
<p id="S3.I17.i3.p1.1" class="ltx_p"><span id="S3.I17.i3.p1.1.1" class="ltx_text ltx_font_italic">FedCom</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">15</span></a>]</cite> compresses messages for uplink communication from the client device to the central server. The central server produces a convex combination of the previous global model and the average of updated local models to retain the essential information of the compressed model parameters.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span><span id="S3.SS2.SSS2.1.1" class="ltx_text ltx_font_bold">Pattern 5: Model Co-versioning Registry</span>
</h4>

<figure id="S3.F8" class="ltx_figure"><img src="/html/2101.02373/assets/x8.png" id="S3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Model Co-versioning Registry.</figcaption>
</figure>
<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p"><span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A model co-versioning registry records all local model versions from each client and aligns them with their corresponding global model. This enables the tracing of model quality and adversarial client devices at any specific point of the training to improve system accountability. Fig. <a href="#S3.F8" title="Figure 8 ‣ 3.2.2 Pattern 5: Model Co-versioning Registry ‣ 3.2 Model Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows that the registry collects and maps the local model updates to the associated global model versions.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p"><span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Multiple new versions of local models are generated from different client devices and one global model aggregated each round. For instance, a federated learning task that runs for 100 rounds on 100 devices will create 10,000 local models and 100 global models in total.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p"><span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> With high numbers of local models created each round, it is challenging to keep track of which local models contributed to the global model of a specific round. Furthermore, the system needs to handle the challenges of asynchronous updates, client dropouts, model selection, etc.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.1" class="ltx_p"><span id="S3.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS2.SSS2.p5" class="ltx_para">
<ul id="S3.I18" class="ltx_itemize">
<li id="S3.I18.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i1.p1" class="ltx_para">
<p id="S3.I18.i1.p1.1" class="ltx_p"><span id="S3.I18.i1.p1.1.1" class="ltx_text ltx_font_italic">Updatability.</span> The system needs to keep track of the local and global models concerning each client device’s updates (application’s version or device OS/firmware updates) and ensure that the information recorded is up-to-date.</p>
</div>
</li>
<li id="S3.I18.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I18.i2.p1" class="ltx_para">
<p id="S3.I18.i2.p1.1" class="ltx_p"><span id="S3.I18.i2.p1.1.1" class="ltx_text ltx_font_italic">Immutability.</span> The records and storage of the models co-versions and client IDs needs to be immutable.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS2.p6" class="ltx_para">
<p id="S3.SS2.SSS2.p6.1" class="ltx_p"><span id="S3.SS2.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A model co-versioning registry records the local model version of each client device and the global model it corresponds to. This enables seamless synchronous and asynchronous model updates and aggregation. Furthermore, the model co-versioning registry enables the early-stopping of complex model training (stop training when the local model overfits and retrieve the best performing model previously). This can be done by observing the performance of the aggregated global model. Moreover, to provide accountable model provenance and co-versioning, blockchain is considered as one alternative to the central server due to immutability and decentralisation properties.</p>
</div>
<div id="S3.SS2.SSS2.p7" class="ltx_para">
<p id="S3.SS2.SSS2.p7.1" class="ltx_p"><span id="S3.SS2.SSS2.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS2.SSS2.p8" class="ltx_para">
<p id="S3.SS2.SSS2.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I19" class="ltx_itemize">
<li id="S3.I19.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I19.i1.p1" class="ltx_para">
<p id="S3.I19.i1.p1.1" class="ltx_p"><span id="S3.I19.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> The mapping of local models with their corresponding version of the global model allows the study of the effect of each local model quality on the global model.</p>
</div>
</li>
<li id="S3.I19.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I19.i2.p1" class="ltx_para">
<p id="S3.I19.i2.p1.1" class="ltx_p"><span id="S3.I19.i2.p1.1.1" class="ltx_text ltx_font_italic">Accountability.</span> System accountability improves as stakeholders can trace the local models that correspond to the current or previous global model versions.</p>
</div>
</li>
<li id="S3.I19.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I19.i3.p1" class="ltx_para">
<p id="S3.I19.i3.p1.1" class="ltx_p"><span id="S3.I19.i3.p1.1.1" class="ltx_text ltx_font_italic">System security.</span> It enables the detection of adversarial or dishonest clients and tracks the local models that poisons the global model or causes system failure.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS2.p9" class="ltx_para">
<p id="S3.SS2.SSS2.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS2.SSS2.p10" class="ltx_para">
<ul id="S3.I20" class="ltx_itemize">
<li id="S3.I20.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I20.i1.p1" class="ltx_para">
<p id="S3.I20.i1.p1.1" class="ltx_p"><span id="S3.I20.i1.p1.1.1" class="ltx_text ltx_font_italic">Storage cost.</span> Extra storage cost is incurred to store all the local and global models and their mutual relationships. The record also needs to be easily retrievable and it is challenging if the central server host more task.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS2.p11" class="ltx_para">
<p id="S3.SS2.SSS2.p11.1" class="ltx_p"><span id="S3.SS2.SSS2.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS2.SSS2.p11.1.2" class="ltx_text ltx_font_italic">Client Registry</span></p>
</div>
<div id="S3.SS2.SSS2.p12" class="ltx_para">
<p id="S3.SS2.SSS2.p12.1" class="ltx_p"><span id="S3.SS2.SSS2.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I21" class="ltx_itemize">
<li id="S3.I21.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I21.i1.p1" class="ltx_para">
<p id="S3.I21.i1.p1.1" class="ltx_p"><span id="S3.I21.i1.p1.1.1" class="ltx_text ltx_font_italic">DVC<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note"><span id="footnote8.1.1.1" class="ltx_text ltx_font_upright">8</span></span><a target="_blank" href="https://dvc.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://dvc.org/</a></span></span></span></span> is an online machine learning version control platform built to make models shareable and reproducible.</p>
</div>
</li>
<li id="S3.I21.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I21.i2.p1" class="ltx_para">
<p id="S3.I21.i2.p1.1" class="ltx_p"><span id="S3.I21.i2.p1.1.1" class="ltx_text ltx_font_italic">MLflow Model Registry<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note"><span id="footnote9.1.1.1" class="ltx_text ltx_font_upright">9</span></span><a target="_blank" href="https://docs.databricks.com/applications/mlflow/model-registry.html" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://docs.databricks.com/applications/mlflow/model-registry.html</a></span></span></span></span> on Databricks is a centralized model store that provides chronological model lineage, model versioning, stage transitions, and descriptions.</p>
</div>
</li>
<li id="S3.I21.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I21.i3.p1" class="ltx_para">
<p id="S3.I21.i3.p1.1" class="ltx_p"><span id="S3.I21.i3.p1.1.1" class="ltx_text ltx_font_italic">Replicate.ai<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note"><span id="footnote10.1.1.1" class="ltx_text ltx_font_upright">10</span></span><a target="_blank" href="https://replicate.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://replicate.ai/</a></span></span></span></span> is an open-source version control platform for machine learning that automatically tracks code, hyperparameters, training data, weights, metrics, and system dependencies.</p>
</div>
</li>
<li id="S3.I21.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I21.i4.p1" class="ltx_para">
<p id="S3.I21.i4.p1.1" class="ltx_p"><span id="S3.I21.i4.p1.1.1" class="ltx_text ltx_font_italic">Pachyderm<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note"><span id="footnote11.1.1.1" class="ltx_text ltx_font_upright">11</span></span><a target="_blank" href="https://www.pachyderm.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://www.pachyderm.com/</a></span></span></span></span> is an online machine learning pipeline platform that uses containers to execute the different steps of the pipeline and also solves the data versioning provenance issues.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span><span id="S3.SS2.SSS3.1.1" class="ltx_text ltx_font_bold">Pattern 6: Model Replacement Trigger</span>
</h4>

<figure id="S3.F9" class="ltx_figure"><img src="/html/2101.02373/assets/x9.png" id="S3.F9.g1" class="ltx_graphics ltx_centering ltx_img_square" width="322" height="279" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Model Replacement Trigger.</figcaption>
</figure>
<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p"><span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> Fig. <a href="#S3.F9" title="Figure 9 ‣ 3.2.3 Pattern 6: Model Replacement Trigger ‣ 3.2 Model Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> illustrates a model replacement trigger that initiates a new model training task when the current global model’s performance drops below the threshold value or when a degrade on model prediction accuracy is detected.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p"><span id="S3.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The client devices use converged global models for inference or prediction.</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<p id="S3.SS2.SSS3.p3.1" class="ltx_p"><span id="S3.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> As new data is introduced to the system, the global model accuracy might reduce gradually. Eventually, with the degrading performance, the model is no longer be suitable for the application.</p>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p id="S3.SS2.SSS3.p4.1" class="ltx_p"><span id="S3.SS2.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS2.SSS3.p5" class="ltx_para">
<ul id="S3.I22" class="ltx_itemize">
<li id="S3.I22.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I22.i1.p1" class="ltx_para">
<p id="S3.I22.i1.p1.1" class="ltx_p"><span id="S3.I22.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> The global model deployed might experience a performance drop when new data are used for inference and prediction.</p>
</div>
</li>
<li id="S3.I22.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I22.i2.p1" class="ltx_para">
<p id="S3.I22.i2.p1.1" class="ltx_p"><span id="S3.I22.i2.p1.1.1" class="ltx_text ltx_font_italic">Performance degradation detection.</span> The system needs to effectively determine the reason for the global model’s performance degradation before deciding whether to activate a new global model generation.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS3.p6" class="ltx_para">
<p id="S3.SS2.SSS3.p6.1" class="ltx_p"><span id="S3.SS2.SSS3.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A model replacement trigger initiates a new model training task when the acting global model’s performance drops below the threshold value. It will compare the performance of the deployed global model on a certain number of client devices to determine if the degradation is a global event. When the global model performance is lower than the preset threshold value for more than a fixed number of consecutive times, given that performance degradation is a global event, a new model training task is triggered.</p>
</div>
<div id="S3.SS2.SSS3.p7" class="ltx_para">
<p id="S3.SS2.SSS3.p7.1" class="ltx_p"><span id="S3.SS2.SSS3.p7.1.1" class="ltx_text ltx_font_bold">Consequences: </span></p>
</div>
<div id="S3.SS2.SSS3.p8" class="ltx_para">
<p id="S3.SS2.SSS3.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I23" class="ltx_itemize">
<li id="S3.I23.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I23.i1.p1" class="ltx_para">
<p id="S3.I23.i1.p1.1" class="ltx_p"><span id="S3.I23.i1.p1.1.1" class="ltx_text ltx_font_italic">Updatability.</span> The consistent updatability of the global model helps to maintain system performance and reduces the non-IID data effect. It is especially effective for clients that generate highly personalised data that causes the effectiveness of the global model to reduce much faster as new data is generated.</p>
</div>
</li>
<li id="S3.I23.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I23.i2.p1" class="ltx_para">
<p id="S3.I23.i2.p1.1" class="ltx_p"><span id="S3.I23.i2.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> The ongoing model performance monitoring is effective to maintain the high quality of the global model used by the clients.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS3.p9" class="ltx_para">
<p id="S3.SS2.SSS3.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS2.SSS3.p10" class="ltx_para">
<ul id="S3.I24" class="ltx_itemize">
<li id="S3.I24.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I24.i1.p1" class="ltx_para">
<p id="S3.I24.i1.p1.1" class="ltx_p"><span id="S3.I24.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> The client devices will need to perform model evaluation periodically that imposes extra computational costs.</p>
</div>
</li>
<li id="S3.I24.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I24.i2.p1" class="ltx_para">
<p id="S3.I24.i2.p1.1" class="ltx_p"><span id="S3.I24.i2.p1.1.1" class="ltx_text ltx_font_italic">Communication cost.</span> The sharing of the evaluation results among clients to know if performance degradation is a global event is communication costly.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS3.p11" class="ltx_para">
<p id="S3.SS2.SSS3.p11.1" class="ltx_p"><span id="S3.SS2.SSS3.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS2.SSS3.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector, Model Co-versioning Registry</span></p>
</div>
<div id="S3.SS2.SSS3.p12" class="ltx_para">
<p id="S3.SS2.SSS3.p12.1" class="ltx_p"><span id="S3.SS2.SSS3.p12.1.1" class="ltx_text ltx_font_bold">Known uses: </span></p>
<ul id="S3.I25" class="ltx_itemize">
<li id="S3.I25.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I25.i1.p1" class="ltx_para">
<p id="S3.I25.i1.p1.1" class="ltx_p"><span id="S3.I25.i1.p1.1.1" class="ltx_text ltx_font_italic">Microsoft Azure Machine Learning Designer<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note"><span id="footnote12.1.1.1" class="ltx_text ltx_font_upright">12</span></span><a target="_blank" href="https://azure.microsoft.com/en-au/services/machine-learning/designer/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://azure.microsoft.com/en-au/services/machine-learning/designer/</a></span></span></span></span> provides a platform for machine learning pipeline creation that enables models to be retrained on new data.</p>
</div>
</li>
<li id="S3.I25.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I25.i2.p1" class="ltx_para">
<p id="S3.I25.i2.p1.1" class="ltx_p"><span id="S3.I25.i2.p1.1.1" class="ltx_text ltx_font_italic">Amazon SageMaker<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note"><span id="footnote13.1.1.1" class="ltx_text ltx_font_upright">13</span></span><a target="_blank" href="https://aws.amazon.com/sagemaker/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://aws.amazon.com/sagemaker/</a></span></span></span></span> provides model deployment and monitoring services to maintain the accuracy of the deployed models.</p>
</div>
</li>
<li id="S3.I25.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I25.i3.p1" class="ltx_para">
<p id="S3.I25.i3.p1.1" class="ltx_p"><span id="S3.I25.i3.p1.1.1" class="ltx_text ltx_font_italic">Alibaba Machine Learning Platform<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note"><span id="footnote14.1.1.1" class="ltx_text ltx_font_upright">14</span></span><a target="_blank" href="https://www.alibabacloud.com/product/machine-learning" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://www.alibabacloud.com/product/machine-learning</a></span></span></span></span> provides end-to-end machine learning services, including data processing, feature engineering, model training, model prediction, and model evaluation.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span><span id="S3.SS2.SSS4.1.1" class="ltx_text ltx_font_bold">Pattern 7: Deployment Selector</span>
</h4>

<figure id="S3.F10" class="ltx_figure"><img src="/html/2101.02373/assets/x10.png" id="S3.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="313" height="303" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Deployment Selector.</figcaption>
</figure>
<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p"><span id="S3.SS2.SSS4.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A deployment selector deploys the converged global model to the selected model users to improve the prediction quality for different applications and tasks. As shown in Fig. <a href="#S3.F10" title="Figure 10 ‣ 3.2.4 Pattern 7: Deployment Selector ‣ 3.2 Model Management Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, different versions of converged models are deployed to different groups of clients after evaluation.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p"><span id="S3.SS2.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Client devices train local models using multitask federated learning settings (a model is trained using data from multiple applications to perform similar and related tasks). These models need to be deployed to suitable groups of client devices.</p>
</div>
<div id="S3.SS2.SSS4.p3" class="ltx_para">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p"><span id="S3.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Due to the inherent diversity and non-IID distribution among local data, the globally trained model may not be accurate enough for all clients or tasks.</p>
</div>
<div id="S3.SS2.SSS4.p4" class="ltx_para">
<p id="S3.SS2.SSS4.p4.1" class="ltx_p"><span id="S3.SS2.SSS4.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS2.SSS4.p5" class="ltx_para">
<ul id="S3.I26" class="ltx_itemize">
<li id="S3.I26.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I26.i1.p1" class="ltx_para">
<p id="S3.I26.i1.p1.1" class="ltx_p"><span id="S3.I26.i1.p1.1.1" class="ltx_text ltx_font_italic">Identification of clients.</span> The central server needs to match and deploy the global models to the different groups of client devices.</p>
</div>
</li>
<li id="S3.I26.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I26.i2.p1" class="ltx_para">
<p id="S3.I26.i2.p1.1" class="ltx_p"><span id="S3.I26.i2.p1.1.1" class="ltx_text ltx_font_italic">Training and storage of different models.</span> The central server needs to train and store different global models for diverse clients or applications.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS4.p6" class="ltx_para">
<p id="S3.SS2.SSS4.p6.1" class="ltx_p"><span id="S3.SS2.SSS4.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A deployment selector examines and selects clients (i.e., model users) to receive the trained global model specified for them based on their data characteristics or applications. The deployment selector deploys the model to the client devices once the global model is completely trained.</p>
</div>
<div id="S3.SS2.SSS4.p7" class="ltx_para">
<p id="S3.SS2.SSS4.p7.1" class="ltx_p"><span id="S3.SS2.SSS4.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS2.SSS4.p8" class="ltx_para">
<p id="S3.SS2.SSS4.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I27" class="ltx_itemize">
<li id="S3.I27.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I27.i1.p1" class="ltx_para">
<p id="S3.I27.i1.p1.1" class="ltx_p"><span id="S3.I27.i1.p1.1.1" class="ltx_text ltx_font_italic">Model performance.</span> Deploying converged global models to suitable groups of client devices enhances the model performance to the specific groups of clients or applications.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS4.p9" class="ltx_para">
<p id="S3.SS2.SSS4.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS2.SSS4.p10" class="ltx_para">
<ul id="S3.I28" class="ltx_itemize">
<li id="S3.I28.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I28.i1.p1" class="ltx_para">
<p id="S3.I28.i1.p1.1" class="ltx_p"><span id="S3.I28.i1.p1.1.1" class="ltx_text ltx_font_italic">Cost.</span> There are extra costs for training of multiple personalised global models, deployment selection, storage of multiple global models.</p>
</div>
</li>
<li id="S3.I28.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I28.i2.p1" class="ltx_para">
<p id="S3.I28.i2.p1.1" class="ltx_p"><span id="S3.I28.i2.p1.1.1" class="ltx_text ltx_font_italic">Model performance.</span> The statistical heterogeneity of model trainers produces personalised local models, which is then generalised through <span id="S3.I28.i2.p1.1.2" class="ltx_text ltx_font_italic">FedAvg</span> aggregation. We need to consider the performance trade-off of the generalised global model deployed for different model users and applications.</p>
</div>
</li>
<li id="S3.I28.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I28.i3.p1" class="ltx_para">
<p id="S3.I28.i3.p1.1" class="ltx_p"><span id="S3.I28.i3.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> Data privacy challenges exist when the central server collects the client information to identify suitable models for different clients. Moreover, the global model might be deployed to model users that have never joined the model training process.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS4.p11" class="ltx_para">
<p id="S3.SS2.SSS4.p11.1" class="ltx_p"><span id="S3.SS2.SSS4.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS2.SSS4.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector</span></p>
</div>
<div id="S3.SS2.SSS4.p12" class="ltx_para">
<p id="S3.SS2.SSS4.p12.1" class="ltx_p"><span id="S3.SS2.SSS4.p12.1.1" class="ltx_text ltx_font_bold">Known uses: </span></p>
<ul id="S3.I29" class="ltx_itemize">
<li id="S3.I29.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I29.i1.p1" class="ltx_para">
<p id="S3.I29.i1.p1.1" class="ltx_p"><span id="S3.I29.i1.p1.1.1" class="ltx_text ltx_font_italic">Azure Machine Learning<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note"><span id="footnote15.1.1.1" class="ltx_text ltx_font_upright">15</span></span><a target="_blank" href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment</a></span></span></span></span> supports mass deployment with a step of compute target selection.</p>
</div>
</li>
<li id="S3.I29.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I29.i2.p1" class="ltx_para">
<p id="S3.I29.i2.p1.1" class="ltx_p"><span id="S3.I29.i2.p1.1.1" class="ltx_text ltx_font_italic">Amazon SageMaker<span id="footnote16" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note"><span id="footnote16.1.1.1" class="ltx_text ltx_font_upright">16</span></span><a target="_blank" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html</a></span></span></span></span> can host multiple models with multi-model endpoints.</p>
</div>
</li>
<li id="S3.I29.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I29.i3.p1" class="ltx_para">
<p id="S3.I29.i3.p1.1" class="ltx_p"><span id="S3.I29.i3.p1.1.1" class="ltx_text ltx_font_italic">Google Cloud<span id="footnote17" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note"><span id="footnote17.1.1.1" class="ltx_text ltx_font_upright">17</span></span><a target="_blank" href="https://cloud.google.com/ai-platform/prediction/docs/deploying-models" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://cloud.google.com/ai-platform/prediction/docs/deploying-models</a></span></span></span></span> uses model resources to manage different versions of models.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_bold">Model Training Patterns</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Patterns about the model training and data preprocessing are group together as model training patterns, including <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">multi-task model trainer</span> that tackles non-IID data characteristics, <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">heterogeneous data handler</span> that deals with data heterogeneity in training datasets, and <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_italic">incentive registry</span> that increases the client’s motivatability through rewards.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span><span id="S3.SS3.SSS1.1.1" class="ltx_text ltx_font_bold">Pattern 8: Multi-Task Model Trainer</span>
</h4>

<figure id="S3.F11" class="ltx_figure"><img src="/html/2101.02373/assets/x11.png" id="S3.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="290" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Multi-Task Model Trainer.</figcaption>
</figure>
<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p"><span id="S3.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> In federated learning, a multi-task model trainer trains separated but related models on local client devices to improve learning efficiency and model performance. As shown in Fig. <a href="#S3.F11" title="Figure 11 ‣ 3.3.1 Pattern 8: Multi-Task Model Trainer ‣ 3.3 Model Training Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, there are two groups of applications: (i) text-related applications (e.g., messaging, email, etc.), and (ii) image-related applications (camera, video, etc.). The related models are trained on client devices using data of related tasks.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p"><span id="S3.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Local data has statistical heterogeneity property where the data distribution among different clients is skewed and a global model cannot capture the data pattern of each client.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p"><span id="S3.SS3.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Federated learning models trained with non-IID data suffer from low accuracy and are less generalised to the entire dataset. Furthermore, the local data that is highly personalised to the device users’ usage pattern creates local models that diverge in different directions. Hence, the global model may have relatively low averaged accuracy.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.1" class="ltx_p"><span id="S3.SS3.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS3.SSS1.p5" class="ltx_para">
<ul id="S3.I30" class="ltx_itemize">
<li id="S3.I30.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I30.i1.p1" class="ltx_para">
<p id="S3.I30.i1.p1.1" class="ltx_p"><span id="S3.I30.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> The complex model that solves the non-IID issue consumes more computation and energy resources every round compared to general federated model training. It also takes longer to compute all the training results from the different tasks before submitting them to the central server.</p>
</div>
</li>
<li id="S3.I30.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I30.i2.p1" class="ltx_para">
<p id="S3.I30.i2.p1.1" class="ltx_p"><span id="S3.I30.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> To address the non-IID issue, more information from the local data needs to be explored to understand the data distribution pattern. This ultimately exposes client devices to local data privacy threats.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS1.p6" class="ltx_para">
<p id="S3.SS3.SSS1.p6.1" class="ltx_p"><span id="S3.SS3.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> The multi-task model trainer performs similar-but-related machine learning tasks on client devices. This enables the local model to learn from more local data that fit naturally to the related local models for different tasks. For instance, a multi-task model for the next-word prediction task is trained using the on-device text messages, web browser search strings, and emails with similar mobile keyboard usage patterns. <span id="S3.SS3.SSS1.p6.1.2" class="ltx_text ltx_font_italic">MOCHA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">38</span></a>]</cite> is a state-of-the-art federated multi-task learning algorithm that realises distributed multi-task learning on federated settings.</p>
</div>
<div id="S3.SS3.SSS1.p7" class="ltx_para">
<p id="S3.SS3.SSS1.p7.1" class="ltx_p"><span id="S3.SS3.SSS1.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS3.SSS1.p8" class="ltx_para">
<p id="S3.SS3.SSS1.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I31" class="ltx_itemize">
<li id="S3.I31.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I31.i1.p1" class="ltx_para">
<p id="S3.I31.i1.p1.1" class="ltx_p"><span id="S3.I31.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> Multi-task learning improves the model performance by considering local data and loss in optimization and obtaining a local weight matrix through this process. The local model fits for non-IID data in each node better than a global model.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS1.p9" class="ltx_para">
<p id="S3.SS3.SSS1.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS3.SSS1.p10" class="ltx_para">
<ul id="S3.I32" class="ltx_itemize">
<li id="S3.I32.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I32.i1.p1" class="ltx_para">
<p id="S3.I32.i1.p1.1" class="ltx_p"><span id="S3.I32.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> Multi-task training often works only with convex loss functions and performs weak on non-convex loss functions.</p>
</div>
</li>
<li id="S3.I32.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I32.i2.p1" class="ltx_para">
<p id="S3.I32.i2.p1.1" class="ltx_p"><span id="S3.I32.i2.p1.1.1" class="ltx_text ltx_font_italic">Model portability.</span> As each client has a different model, the model’s portability is a problem that makes it hard to apply multi-task training on cross-device FL.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS1.p11" class="ltx_para">
<p id="S3.SS3.SSS1.p11.1" class="ltx_p"><span id="S3.SS3.SSS1.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS3.SSS1.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Model Co-versioning Registry, Client Cluster, Deployment Selector</span></p>
</div>
<div id="S3.SS3.SSS1.p12" class="ltx_para">
<p id="S3.SS3.SSS1.p12.1" class="ltx_p"><span id="S3.SS3.SSS1.p12.1.1" class="ltx_text ltx_font_bold">Known uses: </span></p>
<ul id="S3.I33" class="ltx_itemize">
<li id="S3.I33.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I33.i1.p1" class="ltx_para">
<p id="S3.I33.i1.p1.1" class="ltx_p"><span id="S3.I33.i1.p1.1.1" class="ltx_text ltx_font_italic">MultiModel<span id="footnote18" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note"><span id="footnote18.1.1.1" class="ltx_text ltx_font_upright">18</span></span><a target="_blank" href="https://ai.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://ai.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html</a></span></span></span></span> is a neural network architecture by Google that simultaneously solves several problems spanning multiple domains, including image recognition, translation, and speech recognition.</p>
</div>
</li>
<li id="S3.I33.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I33.i2.p1" class="ltx_para">
<p id="S3.I33.i2.p1.1" class="ltx_p"><span id="S3.I33.i2.p1.1.1" class="ltx_text ltx_font_italic">MT-DNN<span id="footnote19" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note"><span id="footnote19.1.1.1" class="ltx_text ltx_font_upright">19</span></span><a target="_blank" href="https://github.com/microsoft/MT-DNN" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/microsoft/MT-DNN</a></span></span></span></span> is an open-source natural language understanding toolkit by Microsoft to train customized deep learning models.</p>
</div>
</li>
<li id="S3.I33.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I33.i3.p1" class="ltx_para">
<p id="S3.I33.i3.p1.1" class="ltx_p"><span id="S3.I33.i3.p1.1.1" class="ltx_text ltx_font_italic">Yahoo Multi-Task Learning for Web Ranking</span> is a multi-task learning framework developed by Yahoo! Labs to rank in web search.</p>
</div>
</li>
<li id="S3.I33.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I33.i4.p1" class="ltx_para">
<p id="S3.I33.i4.p1.1" class="ltx_p"><span id="S3.I33.i4.p1.1.1" class="ltx_text ltx_font_italic">VIRTUAL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">12</span></a>]</cite> is an algorithm for federated multi-task learning with non-convex models. The server and devices are treated as a star-shaped bayesian network, and model learning is performed on the network using approximated variational inference.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span><span id="S3.SS3.SSS2.1.1" class="ltx_text ltx_font_bold">Pattern 9: Heterogeneous Data Handler</span>
</h4>

<figure id="S3.F12" class="ltx_figure"><img src="/html/2101.02373/assets/x12.png" id="S3.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Heterogeneous Data Handler.</figcaption>
</figure>
<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p"><span id="S3.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> Heterogeneous data handler solves the non-IID and skewed data distribution issues through data volume and data class addition (e.g., data augmentation or generative adversarial network) while maintaining the local data privacy. The pattern is illustrated in Fig. <a href="#S3.F12" title="Figure 12 ‣ 3.3.2 Pattern 9: Heterogeneous Data Handler ‣ 3.3 Model Training Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, where the heterogeneous data handler operates at both ends of the system.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p"><span id="S3.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> Client devices possess heterogeneous data characteristics due to the highly personalized data generation pattern. Furthermore, the raw local data cannot be shared so the data balancing task becomes extremely challenging.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p"><span id="S3.SS3.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> The imbalanced and skewed data distribution of client devices produces local models that are not generalised to the entire client network. The aggregation of these local models reduces global model accuracy.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p"><span id="S3.SS3.SSS2.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires the following forces to be balanced:</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<ul id="S3.I34" class="ltx_itemize">
<li id="S3.I34.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I34.i1.p1" class="ltx_para">
<p id="S3.I34.i1.p1.1" class="ltx_p"><span id="S3.I34.i1.p1.1.1" class="ltx_text ltx_font_italic">Data efficiency.</span> It is challenging to articulate the suitable data volume and classes to be augmented to solve data heterogeneity on local client devices.</p>
</div>
</li>
<li id="S3.I34.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I34.i2.p1" class="ltx_para">
<p id="S3.I34.i2.p1.1" class="ltx_p"><span id="S3.I34.i2.p1.1.1" class="ltx_text ltx_font_italic">Data accessibility.</span> The heterogeneous data issue that exists within the client device can be solved by collecting all the data under a centralized location. However, this violates the data privacy of client devices.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.p6" class="ltx_para">
<p id="S3.SS3.SSS2.p6.1" class="ltx_p"><span id="S3.SS3.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A heterogeneous data handler balances the data distribution and solves the data heterogeneity issue in the client devices through data augmentation and federated distillation. Data augmentation solves data heterogeneity by generating augmented data locally until the data volume is the same across all client devices. Furthermore, the classes in the datasets are also populated equally across all client devices. Federated distillation enables the client devices to obtain knowledge from other devices periodically without directly accessing the data of other client devices. Other methods includes taking the quantified data heterogeneity weightage (e.g, Pearson’s correlation, centroid averaging-distance, etc.) into account for model aggregation.</p>
</div>
<div id="S3.SS3.SSS2.p7" class="ltx_para">
<p id="S3.SS3.SSS2.p7.1" class="ltx_p"><span id="S3.SS3.SSS2.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS3.SSS2.p8" class="ltx_para">
<p id="S3.SS3.SSS2.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I35" class="ltx_itemize">
<li id="S3.I35.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I35.i1.p1" class="ltx_para">
<p id="S3.I35.i1.p1.1" class="ltx_p"><span id="S3.I35.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> By solving the non-IID issue of local datasets, the performance and generality of the global model are improved.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.p9" class="ltx_para">
<p id="S3.SS3.SSS2.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS3.SSS2.p10" class="ltx_para">
<ul id="S3.I36" class="ltx_itemize">
<li id="S3.I36.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I36.i1.p1" class="ltx_para">
<p id="S3.I36.i1.p1.1" class="ltx_p"><span id="S3.I36.i1.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> It is computationally costly to deal with data heterogeneity together with the local model training.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.p11" class="ltx_para">
<p id="S3.SS3.SSS2.p11.1" class="ltx_p"><span id="S3.SS3.SSS2.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS3.SSS2.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector, Client Cluster</span></p>
</div>
<div id="S3.SS3.SSS2.p12" class="ltx_para">
<p id="S3.SS3.SSS2.p12.1" class="ltx_p"><span id="S3.SS3.SSS2.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I37" class="ltx_itemize">
<li id="S3.I37.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I37.i1.p1" class="ltx_para">
<p id="S3.I37.i1.p1.1" class="ltx_p"><span id="S3.I37.i1.p1.1.1" class="ltx_text ltx_font_italic">Astreae</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">13</span></a>]</cite> is a self-balancing federated learning framework that alleviates the imbalances by performing global data distribution-based data augmentation.</p>
</div>
</li>
<li id="S3.I37.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I37.i2.p1" class="ltx_para">
<p id="S3.I37.i2.p1.1" class="ltx_p">Federated Augmentation (<span id="S3.I37.i2.p1.1.1" class="ltx_text ltx_font_italic">FAug</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">19</span></a>]</cite> is a data augmentation scheme that utilises a generative adversarial network (GAN) which is collectively trained under the trade-off between privacy leakage and communication overhead.</p>
</div>
</li>
<li id="S3.I37.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I37.i3.p1" class="ltx_para">
<p id="S3.I37.i3.p1.1" class="ltx_p">Federated Distillation (<span id="S3.I37.i3.p1.1.1" class="ltx_text ltx_font_italic">FD</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is a method that adopted knowledge distillation approaches to tackle the non-IID issue by obtaining the knowledge from other devices during the distributed training process, without accessing the raw data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span><span id="S3.SS3.SSS3.1.1" class="ltx_text ltx_font_bold">Pattern 10: Incentive Registry</span>
</h4>

<figure id="S3.F13" class="ltx_figure"><img src="/html/2101.02373/assets/x13.png" id="S3.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="276" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Incentive Registry.</figcaption>
</figure>
<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p"><span id="S3.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> An incentive registry maintains the list of participating clients and their rewards that correspond to clients’ contributions (e.g., data volume, model performance, computation resources, etc.) to motivate clients’ participation. Fig. <a href="#S3.F13" title="Figure 13 ‣ 3.3.3 Pattern 10: Incentive Registry ‣ 3.3 Model Training Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> illustrates a blockchain &amp; smart contract-based incentive mechanism.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p"><span id="S3.SS3.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The model training participation rate of client devices is low while the high participation rate is crucial for the global model performance.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p"><span id="S3.SS3.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Although the system relies greatly on the participation of clients to produce high-quality global models, clients are not mandatory to join the model training and contribute their data/resources.</p>
</div>
<div id="S3.SS3.SSS3.p4" class="ltx_para">
<p id="S3.SS3.SSS3.p4.1" class="ltx_p"><span id="S3.SS3.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS3.SSS3.p5" class="ltx_para">
<ul id="S3.I38" class="ltx_itemize">
<li id="S3.I38.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I38.i1.p1" class="ltx_para">
<p id="S3.I38.i1.p1.1" class="ltx_p"><span id="S3.I38.i1.p1.1.1" class="ltx_text ltx_font_italic">Incentive scheme.</span> It is challenging to formulate the form of rewards to attract different clients with different participation motives. Furthermore, the incentive scheme needs to be agreed upon by both the learning coordinator and the clients, e.g., performance-based, data-contribution-based, resource-contribution-based, and provision-frequency-
<br class="ltx_break">based.</p>
</div>
</li>
<li id="S3.I38.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I38.i2.p1" class="ltx_para">
<p id="S3.I38.i2.p1.1" class="ltx_p"><span id="S3.I38.i2.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> To identify the contribution of each client device, the local data and client information is required to be studied and analysed by the central server. This exposes the client devices’ local data to privacy threats.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS3.p6" class="ltx_para">
<p id="S3.SS3.SSS3.p6.1" class="ltx_p"><span id="S3.SS3.SSS3.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> An incentive registry records all client’s contributions and incentives based on the rate agreed. There are various ways to formulate the incentive scheme, e.g., deep reinforcement learning, blockchain/smart contracts, and the Stackelberg game model.</p>
</div>
<div id="S3.SS3.SSS3.p7" class="ltx_para">
<p id="S3.SS3.SSS3.p7.1" class="ltx_p"><span id="S3.SS3.SSS3.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS3.SSS3.p8" class="ltx_para">
<p id="S3.SS3.SSS3.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I39" class="ltx_itemize">
<li id="S3.I39.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I39.i1.p1" class="ltx_para">
<p id="S3.I39.i1.p1.1" class="ltx_p"><span id="S3.I39.i1.p1.1.1" class="ltx_text ltx_font_italic">Client motivatability.</span> The incentive mechanism is effective in attracting clients to contribute data and resources to the training process.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS3.p9" class="ltx_para">
<p id="S3.SS3.SSS3.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS3.SSS3.p10" class="ltx_para">
<ul id="S3.I40" class="ltx_itemize">
<li id="S3.I40.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I40.i1.p1" class="ltx_para">
<p id="S3.I40.i1.p1.1" class="ltx_p"><span id="S3.I40.i1.p1.1.1" class="ltx_text ltx_font_italic">System security.</span> There might be dishonest clients that submit fraudulent results to earn rewards illegally and harm the training process.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS3.p11" class="ltx_para">
<p id="S3.SS3.SSS3.p11.1" class="ltx_p"><span id="S3.SS3.SSS3.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS3.SSS3.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector</span></p>
</div>
<div id="S3.SS3.SSS3.p12" class="ltx_para">
<p id="S3.SS3.SSS3.p12.1" class="ltx_p"><span id="S3.SS3.SSS3.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I41" class="ltx_itemize">
<li id="S3.I41.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I41.i1.p1" class="ltx_para">
<p id="S3.I41.i1.p1.1" class="ltx_p"><span id="S3.I41.i1.p1.1.1" class="ltx_text ltx_font_italic">FLChain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> is a federated learning blockchain providing an incentive scheme for collaborative training and a market place for model trading.</p>
</div>
</li>
<li id="S3.I41.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I41.i2.p1" class="ltx_para">
<p id="S3.I41.i2.p1.1" class="ltx_p"><span id="S3.I41.i2.p1.1.1" class="ltx_text ltx_font_italic">DeepChain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">42</span></a>]</cite> is a blockchain-based collaborative training framework with an incentive mechanism that encourages parties to participate in the deep learning model training and share the obtained local gradients.</p>
</div>
</li>
<li id="S3.I41.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I41.i3.p1" class="ltx_para">
<p id="S3.I41.i3.p1.1" class="ltx_p"><span id="S3.I41.i3.p1.1.1" class="ltx_text ltx_font_italic">FedCoin</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">29</span></a>]</cite> is a blockchain-based peer-to-peer payment system for federated learning to enable Shapley Value (SV) based reward distribution.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span id="S3.SS4.1.1" class="ltx_text ltx_font_bold">Model Aggregation Patterns</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Model aggregation patterns are design solutions of model aggregation used for different purposes. <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">Asynchronous aggregator</span> aims to reduce aggregation latency and increase system efficiency, whereas <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_italic">decentralised aggregator</span> targets to increase system reliability and accountability. <span id="S3.SS4.p1.1.3" class="ltx_text ltx_font_italic">Hierarchical aggregator</span> is adopted to improve model quality and optimises resources. <span id="S3.SS4.p1.1.4" class="ltx_text ltx_font_italic">Secure aggregator</span> is designed to protect the models’ security.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span><span id="S3.SS4.SSS1.1.1" class="ltx_text ltx_font_bold">Pattern 11: Asynchronous Aggregator</span>
</h4>

<figure id="S3.F14" class="ltx_figure"><img src="/html/2101.02373/assets/x14.png" id="S3.F14.g1" class="ltx_graphics ltx_centering ltx_img_square" width="322" height="314" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Asynchronous Aggregator.</figcaption>
</figure>
<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p"><span id="S3.SS4.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> To increase the global model aggregation speed every round, the central server can perform model aggregation asynchronously whenever a model update arrives without waiting for all the model updates every round. In Fig. <a href="#S3.F14" title="Figure 14 ‣ 3.4.1 Pattern 11: Asynchronous Aggregator ‣ 3.4 Model Aggregation Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>, the asynchronous aggregator pattern is demonstrated as the first client device asynchronously uploads its local model during the second aggregation round while skipping the first aggregation round.</p>
</div>
<div id="S3.SS4.SSS1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.p2.1" class="ltx_p"><span id="S3.SS4.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> In conventional federated learning, the central server receives all local model updates from the distributed client devices synchronously and performs model aggregation every round. The central server needs to wait for every model to arrive before performing the model aggregation for that round. Hence, the aggregation time depends on the last model update that reaches the central server.</p>
</div>
<div id="S3.SS4.SSS1.p3" class="ltx_para">
<p id="S3.SS4.SSS1.p3.1" class="ltx_p"><span id="S3.SS4.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> Due to the difference in computation resources, the model training lead time is different per device. Furthermore, the difference in bandwidth availability, communication efficiency affects the model’s transfer rate. Therefore, the delay in model training and transfer increases the latency in global model aggregation.</p>
</div>
<div id="S3.SS4.SSS1.p4" class="ltx_para">
<p id="S3.SS4.SSS1.p4.1" class="ltx_p"><span id="S3.SS4.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires the following forces to be balanced:</p>
</div>
<div id="S3.SS4.SSS1.p5" class="ltx_para">
<ul id="S3.I42" class="ltx_itemize">
<li id="S3.I42.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I42.i1.p1" class="ltx_para">
<p id="S3.I42.i1.p1.1" class="ltx_p"><span id="S3.I42.i1.p1.1.1" class="ltx_text ltx_font_italic">Model quality.</span> There will be possible bias in the global model if not all local model updates are aggregated in every iteration as important information or features might be left out.</p>
</div>
</li>
<li id="S3.I42.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I42.i2.p1" class="ltx_para">
<p id="S3.I42.i2.p1.1" class="ltx_p"><span id="S3.I42.i2.p1.1.1" class="ltx_text ltx_font_italic">Aggregation latency.</span> The aggregation of local models can only be performed when all the model updates are collected. Therefore, the latency of the aggregation process is affected by the slowest model update that arrives at the central server.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.p6" class="ltx_para">
<p id="S3.SS4.SSS1.p6.1" class="ltx_p"><span id="S3.SS4.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> The global model aggregation is conducted whenever a model update is received, without being delayed by other clients. Then the server starts the next iteration and distributes the new central model to the clients that are ready for training. The delayed model updates that are not included in the current aggregation round will be added in the next round with some reduction in the weightage, proportioned to their respective delayed time.</p>
</div>
<div id="S3.SS4.SSS1.p7" class="ltx_para">
<p id="S3.SS4.SSS1.p7.1" class="ltx_p"><span id="S3.SS4.SSS1.p7.1.1" class="ltx_text ltx_font_bold">Consequences:</span></p>
</div>
<div id="S3.SS4.SSS1.p8" class="ltx_para">
<p id="S3.SS4.SSS1.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I43" class="ltx_itemize">
<li id="S3.I43.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I43.i1.p1" class="ltx_para">
<p id="S3.I43.i1.p1.1" class="ltx_p"><span id="S3.I43.i1.p1.1.1" class="ltx_text ltx_font_italic">Low aggregation latency.</span> Faster aggregation time per round is achievable as there is no need to wait for the model updates from other clients for the aggregation round. The bandwidth usage per iteration is reduced as fewer local model updates are transferred and receive simultaneously every round.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.p9" class="ltx_para">
<p id="S3.SS4.SSS1.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS4.SSS1.p10" class="ltx_para">
<ul id="S3.I44" class="ltx_itemize">
<li id="S3.I44.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I44.i1.p1" class="ltx_para">
<p id="S3.I44.i1.p1.1" class="ltx_p"><span id="S3.I44.i1.p1.1.1" class="ltx_text ltx_font_italic">Communication cost.</span> The number of iteration to collect all local mode updates increases for the asynchronous approach. More iterations are required for the entire training process to train the model till convergence compares to synchronous global model aggregation.</p>
</div>
</li>
<li id="S3.I44.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I44.i2.p1" class="ltx_para">
<p id="S3.I44.i2.p1.1" class="ltx_p"><span id="S3.I44.i2.p1.1.1" class="ltx_text ltx_font_italic">Model bias.</span> The global model of each round does not contain all the features and information of every local model update. Hence the global model might have a certain level of bias in prediction.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.p11" class="ltx_para">
<p id="S3.SS4.SSS1.p11.1" class="ltx_p"><span id="S3.SS4.SSS1.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS4.SSS1.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Selector, Model Co-versioning Registry, Client Update Scheduler</span></p>
</div>
<div id="S3.SS4.SSS1.p12" class="ltx_para">
<p id="S3.SS4.SSS1.p12.1" class="ltx_p"><span id="S3.SS4.SSS1.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I45" class="ltx_itemize">
<li id="S3.I45.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I45.i1.p1" class="ltx_para">
<p id="S3.I45.i1.p1.1" class="ltx_p">Asynchronous Online Federated Learning (<span id="S3.I45.i1.p1.1.1" class="ltx_text ltx_font_italic">ASO-fed</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is a framework for federated learning that adopted asynchronous aggregation. The central server update the global model whenever it receives a local update from one client device (or several client devices if the local updates are received simultaneously). On the client device side, online-learning is performed as data continue to arrive during the global iterations.</p>
</div>
</li>
<li id="S3.I45.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I45.i2.p1" class="ltx_para">
<p id="S3.I45.i2.p1.1" class="ltx_p">Asynchronous federated SGD-Vertical Partitioned (<span id="S3.I45.i2.p1.1.1" class="ltx_text ltx_font_italic">AFSGD-VP</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">14</span></a>]</cite> algorithm uses a tree-structured communication scheme to perform asynchronous aggregation. The algorithm does not need to align the iteration number of the model aggregation from different client devices to compute the global model.</p>
</div>
</li>
<li id="S3.I45.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I45.i3.p1" class="ltx_para">
<p id="S3.I45.i3.p1.1" class="ltx_p">Asynchronous Federated Optimization (<span id="S3.I45.i3.p1.1.1" class="ltx_text ltx_font_italic">FedAsync</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">43</span></a>]</cite> is an approach that leverages asynchronous updating technique and avoids server-side timeouts and abandoned rounds while requires no synchronous model broadcast to all the selected client devices.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span><span id="S3.SS4.SSS2.1.1" class="ltx_text ltx_font_bold">Pattern 12: Decentralised Aggregator</span>
</h4>

<figure id="S3.F15" class="ltx_figure"><img src="/html/2101.02373/assets/x15.png" id="S3.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="300" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Decentralised Aggregator.</figcaption>
</figure>
<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p"><span id="S3.SS4.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A decentralised aggregator improves system reliability and accountability by removing the central server that is a possible single-point-of-failure. Fig. <a href="#S3.F15" title="Figure 15 ‣ 3.4.2 Pattern 12: Decentralised Aggregator ‣ 3.4 Model Aggregation Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> illustrates the decentralised federated learning system built using blockchain and smart contract, while the model updates are performed through the exchange between neighbour devices.</p>
</div>
<div id="S3.SS4.SSS2.p2" class="ltx_para">
<p id="S3.SS4.SSS2.p2.1" class="ltx_p"><span id="S3.SS4.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The model training and aggregation are coordinated by a central server and both the central server and the owner may not be trusted by all the client devices that join the training process.</p>
</div>
<div id="S3.SS4.SSS2.p3" class="ltx_para">
<p id="S3.SS4.SSS2.p3.1" class="ltx_p"><span id="S3.SS4.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> In <span id="S3.SS4.SSS2.p3.1.2" class="ltx_text ltx_font_italic">FedAvg</span>, all the chosen devices have to submit the model parameters to one central server every round. This is extremely burdensome to the central server and network congestion may occur. Furthermore, centralised federated learning possesses a single-point-of-failure. Data privacy threats may also occur if the central server is compromised by any unauthorised entity. The mutual trust between the client devices and the central server may not be specifically established.</p>
</div>
<div id="S3.SS4.SSS2.p4" class="ltx_para">
<p id="S3.SS4.SSS2.p4.1" class="ltx_p"><span id="S3.SS4.SSS2.p4.1.1" class="ltx_text ltx_font_bold">Forces: </span>The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS4.SSS2.p5" class="ltx_para">
<ul id="S3.I46" class="ltx_itemize">
<li id="S3.I46.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I46.i1.p1" class="ltx_para">
<p id="S3.I46.i1.p1.1" class="ltx_p"><span id="S3.I46.i1.p1.1.1" class="ltx_text ltx_font_italic">Decentralised model management.</span> The federated learning systems face challenges to collect, store, examine, and aggregate the local models due to the removal of the central server.</p>
</div>
</li>
<li id="S3.I46.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I46.i2.p1" class="ltx_para">
<p id="S3.I46.i2.p1.1" class="ltx_p"><span id="S3.I46.i2.p1.1.1" class="ltx_text ltx_font_italic">System ownership.</span> Currently, the central server is own by the learning coordinator that creates the federated learning jobs. The removal of the central server requires the re-definition of system ownership. It includes the authority and accessibility of learning coordinator in the federated learning systems.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS2.p6" class="ltx_para">
<p id="S3.SS4.SSS2.p6.1" class="ltx_p"><span id="S3.SS4.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A decentralised aggregator replaces the central server’s role in a federated learning system. The aggregation and update of the models can be performed through peer-to-peer exchanges between client devices. First, a random client from the system can be an aggregator by requesting the model updates from the other clients that are close to it. Simultaneously, the client devices conduct local model training in parallel and send the trained local models to the aggregator. The aggregator then produces a new global model and sends it to the client network. Blockchain is the alternative to the central server for model storage that prevents single-point-of-failure. The ownership of the blockchain belongs to the learning coordinator that creates the new training tasks and maintains the blockchain. Furthermore, the record of models on a blockchain is immutable that increases the reliability of the system. It also increases the trust of the system as the record is transparent and accessible by all the client devices.</p>
</div>
<div id="S3.SS4.SSS2.p7" class="ltx_para">
<p id="S3.SS4.SSS2.p7.1" class="ltx_p"><span id="S3.SS4.SSS2.p7.1.1" class="ltx_text ltx_font_bold">Consequences: </span></p>
</div>
<div id="S3.SS4.SSS2.p8" class="ltx_para">
<p id="S3.SS4.SSS2.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I47" class="ltx_itemize">
<li id="S3.I47.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I47.i1.p1" class="ltx_para">
<p id="S3.I47.i1.p1.1" class="ltx_p"><span id="S3.I47.i1.p1.1.1" class="ltx_text ltx_font_italic">System reliability.</span> The removal of single-point-of-failure increases the system reliability by reducing the security risk of the central server from any adversarial attack or the failure of the entire training process due to the malfunction of the central server.</p>
</div>
</li>
<li id="S3.I47.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I47.i2.p1" class="ltx_para">
<p id="S3.I47.i2.p1.1" class="ltx_p"><span id="S3.I47.i2.p1.1.1" class="ltx_text ltx_font_italic">System accountability.</span> The adoption of blockchain promotes accountability as the records on a blockchain is immutable and transparent to all the stakeholders.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS2.p9" class="ltx_para">
<p id="S3.SS4.SSS2.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS4.SSS2.p10" class="ltx_para">
<ul id="S3.I48" class="ltx_itemize">
<li id="S3.I48.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I48.i1.p1" class="ltx_para">
<p id="S3.I48.i1.p1.1" class="ltx_p"><span id="S3.I48.i1.p1.1.1" class="ltx_text ltx_font_italic">Latency.</span> Client device as a replacement of the central server for model aggregation is not ideal for direct communication with multiple devices (star-topology). This may cause latency in the model aggregation process due to blockchain consensus protocols.</p>
</div>
</li>
<li id="S3.I48.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I48.i2.p1" class="ltx_para">
<p id="S3.I48.i2.p1.1" class="ltx_p"><span id="S3.I48.i2.p1.1.1" class="ltx_text ltx_font_italic">Computation cost.</span> Client devices have limited computation power and resource to perform model training and aggregation parallel. Even if the training process and the aggregation is performed sequentially, the energy consumption to perform multiple rounds of aggregation is very high.</p>
</div>
</li>
<li id="S3.I48.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I48.i3.p1" class="ltx_para">
<p id="S3.I48.i3.p1.1" class="ltx_p"><span id="S3.I48.i3.p1.1.1" class="ltx_text ltx_font_italic">Storage cost.</span> High storage cost is required to store all the local and global models on storage-limited client devices or blockchain.</p>
</div>
</li>
<li id="S3.I48.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I48.i4.p1" class="ltx_para">
<p id="S3.I48.i4.p1.1" class="ltx_p"><span id="S3.I48.i4.p1.1.1" class="ltx_text ltx_font_italic">Data privacy.</span> Client devices can access the record of all the models under decentralised aggregation and blockchain settings. This might expose the privacy-sensitive information of the client devices to other parties.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS2.p11" class="ltx_para">
<p id="S3.SS4.SSS2.p11.1" class="ltx_p"><span id="S3.SS4.SSS2.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS4.SSS2.p11.1.2" class="ltx_text ltx_font_italic">Model Co-versioning Registry, Incentive Registry</span></p>
</div>
<div id="S3.SS4.SSS2.p12" class="ltx_para">
<p id="S3.SS4.SSS2.p12.1" class="ltx_p"><span id="S3.SS4.SSS2.p12.1.1" class="ltx_text ltx_font_bold">Known uses:</span></p>
<ul id="S3.I49" class="ltx_itemize">
<li id="S3.I49.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I49.i1.p1" class="ltx_para">
<p id="S3.I49.i1.p1.1" class="ltx_p"><span id="S3.I49.i1.p1.1.1" class="ltx_text ltx_font_italic">BrainTorrent</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">36</span></a>]</cite> is a server-less, peer-to-peer approach to perform federated learning where clients communicate directly among themselves, specifically for federated learning in medical centers.</p>
</div>
</li>
<li id="S3.I49.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I49.i2.p1" class="ltx_para">
<p id="S3.I49.i2.p1.1" class="ltx_p"><span id="S3.I49.i2.p1.1.1" class="ltx_text ltx_font_italic">FedPGA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">20</span></a>]</cite> is a decentralised aggregation algorithm developed from <span id="S3.I49.i2.p1.1.2" class="ltx_text ltx_font_italic">FedAvg</span>. The devices in <span id="S3.I49.i2.p1.1.3" class="ltx_text ltx_font_italic">FedPGA</span> exchange partial gradients rather than full model weights. The partial gradient exchange pulls and merges the different slice of the updates from different devices and rebuild a mixed update for aggregation.</p>
</div>
</li>
<li id="S3.I49.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I49.i3.p1" class="ltx_para">
<p id="S3.I49.i3.p1.1" class="ltx_p">A fully decentralised framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">26</span></a>]</cite> is an algorithm in which users update their beliefs by aggregate information from their one-hop neighbors to learn a model that best fits the observations over the entire network.</p>
</div>
</li>
<li id="S3.I49.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I49.i4.p1" class="ltx_para">
<p id="S3.I49.i4.p1.1" class="ltx_p">A Segmented gossip approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">16</span></a>]</cite> splits a model into segmentation that contains the same number of non-overlapping model parameters. Then, the gossip protocol is adopted where each client stochastically selects a few other clients to exchange the model segmentation for each training iteration without the orchestration of a central server.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3 </span><span id="S3.SS4.SSS3.1.1" class="ltx_text ltx_font_bold">Pattern 13: Hierarchical Aggregator</span>
</h4>

<figure id="S3.F16" class="ltx_figure"><img src="/html/2101.02373/assets/x16.png" id="S3.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="369" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Hierarchical Aggregator.</figcaption>
</figure>
<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p"><span id="S3.SS4.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> To reduce non-IID effects on the global model and increase system efficiency, a hierarchical aggregator adds an intermediate layer (e.g., edge server) to perform partial aggregations using the local model parameters from closely-related client devices before the global aggregation. In Fig. <a href="#S3.F16" title="Figure 16 ‣ 3.4.3 Pattern 13: Hierarchical Aggregator ‣ 3.4 Model Aggregation Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>, edge servers are added as an intermediate layer between the central server and client devices to serve the client devices that are closer to them.</p>
</div>
<div id="S3.SS4.SSS3.p2" class="ltx_para">
<p id="S3.SS4.SSS3.p2.1" class="ltx_p"><span id="S3.SS4.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The communication between the central server and the client devices is slowed down or frequently disrupted due to being physically distant from each other and are wirelessly connected.</p>
</div>
<div id="S3.SS4.SSS3.p3" class="ltx_para">
<p id="S3.SS4.SSS3.p3.1" class="ltx_p"><span id="S3.SS4.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> The central server can access and store more data but requires high communication overhead and suffers from latency due to being physically distant from the client devices. Moreover, client devices possess non-IID characteristics that affect global model performance.</p>
</div>
<div id="S3.SS4.SSS3.p4" class="ltx_para">
<p id="S3.SS4.SSS3.p4.1" class="ltx_p"><span id="S3.SS4.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires the following forces to be balanced:</p>
</div>
<div id="S3.SS4.SSS3.p5" class="ltx_para">
<ul id="S3.I50" class="ltx_itemize">
<li id="S3.I50.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I50.i1.p1" class="ltx_para">
<p id="S3.I50.i1.p1.1" class="ltx_p"><span id="S3.I50.i1.p1.1.1" class="ltx_text ltx_font_italic">System efficiency.</span> The system efficiency of the server-client setting to perform federated learning is low, as the central server is burdensome to accommodate the communication and the model aggregations of the widely-distributed client devices.</p>
</div>
</li>
<li id="S3.I50.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I50.i2.p1" class="ltx_para">
<p id="S3.I50.i2.p1.1" class="ltx_p"><span id="S3.I50.i2.p1.1.1" class="ltx_text ltx_font_italic">Data heterogeneity.</span> In the server-client setting of a federated learning system, the data heterogeneity characteristics of client devices become influential and dominant to the global model production, as the central server deals with all the client devices that generate non-IID data.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS3.p6" class="ltx_para">
<p id="S3.SS4.SSS3.p6.1" class="ltx_p"><span id="S3.SS4.SSS3.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A hierarchical aggregator adds edge servers between the central server and client devices. The combination of server-edge-client architecture can improve both computation and communication efficiency of the federated model training process. Edge servers collect local models from the nearest client devices, a subset of all the client devices. After every k1 round of local training on each client, each edge server aggregates its clients’ models. After every k2 edge model aggregations, the cloud server aggregates all the edge servers’ models, which means the communication with the central server happens every k1k2 local updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">28</span></a>]</cite>.</p>
</div>
<div id="S3.SS4.SSS3.p7" class="ltx_para">
<p id="S3.SS4.SSS3.p7.1" class="ltx_p"><span id="S3.SS4.SSS3.p7.1.1" class="ltx_text ltx_font_bold">Consequences: </span></p>
</div>
<div id="S3.SS4.SSS3.p8" class="ltx_para">
<p id="S3.SS4.SSS3.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I51" class="ltx_itemize">
<li id="S3.I51.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I51.i1.p1" class="ltx_para">
<p id="S3.I51.i1.p1.1" class="ltx_p"><span id="S3.I51.i1.p1.1.1" class="ltx_text ltx_font_italic">Communication efficiency.</span> The hierarchical aggregators speed up the global model aggregation and improve communication efficiency.</p>
</div>
</li>
<li id="S3.I51.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I51.i2.p1" class="ltx_para">
<p id="S3.I51.i2.p1.1" class="ltx_p"><span id="S3.I51.i2.p1.1.1" class="ltx_text ltx_font_italic">Scalability.</span> Adding an edge layer helps to scale the system by improving the system’s ability to handling more client devices.</p>
</div>
</li>
<li id="S3.I51.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I51.i3.p1" class="ltx_para">
<p id="S3.I51.i3.p1.1" class="ltx_p"><span id="S3.I51.i3.p1.1.1" class="ltx_text ltx_font_italic">Data heterogeneity and non-IID reduction.</span> The partial aggregation in a hierarchical manner aggregates local models that have similar data heterogeneity and non-IIDness before the global aggregation on the central server. This greatly reduces the effect of data heterogeneity and non-IIDness on global models.</p>
</div>
</li>
<li id="S3.I51.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I51.i4.p1" class="ltx_para">
<p id="S3.I51.i4.p1.1" class="ltx_p"><span id="S3.I51.i4.p1.1.1" class="ltx_text ltx_font_italic">Computation and storage efficiency.</span> The edge devices are rich with computation and storage resources to perform partial model aggregation. Furthermore, edge devices are nearer to the client devices which increase the model aggregation and computation efficiency.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS3.p9" class="ltx_para">
<p id="S3.SS4.SSS3.p9.1" class="ltx_p">Drawbacks:</p>
</div>
<div id="S3.SS4.SSS3.p10" class="ltx_para">
<ul id="S3.I52" class="ltx_itemize">
<li id="S3.I52.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I52.i1.p1" class="ltx_para">
<p id="S3.I52.i1.p1.1" class="ltx_p"><span id="S3.I52.i1.p1.1.1" class="ltx_text ltx_font_italic">System reliability.</span> The failure of edge devices may cause the disconnection of all the client devices under those edge servers and affect the model training process, model performance, and system reliability.</p>
</div>
</li>
<li id="S3.I52.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I52.i2.p1" class="ltx_para">
<p id="S3.I52.i2.p1.1" class="ltx_p"><span id="S3.I52.i2.p1.1.1" class="ltx_text ltx_font_italic">System security.</span> Edge servers could become security breach points as they have lower security setups than the central server and the client devices. Hence, they are more prone to network security threats or becoming possible points-of-failure of the system.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS3.p11" class="ltx_para">
<p id="S3.SS4.SSS3.p11.1" class="ltx_p"><span id="S3.SS4.SSS3.p11.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS4.SSS3.p11.1.2" class="ltx_text ltx_font_italic">Client Registry, Client Cluster, Model Co-versioning Registry</span></p>
</div>
<div id="S3.SS4.SSS3.p12" class="ltx_para">
<p id="S3.SS4.SSS3.p12.1" class="ltx_p"><span id="S3.SS4.SSS3.p12.1.1" class="ltx_text ltx_font_bold">Known uses: </span></p>
<ul id="S3.I53" class="ltx_itemize">
<li id="S3.I53.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I53.i1.p1" class="ltx_para">
<p id="S3.I53.i1.p1.1" class="ltx_p"><span id="S3.I53.i1.p1.1.1" class="ltx_text ltx_font_italic">HierFAVG</span>
is an algorithm that allows multiple edge servers to perform partial model aggregation incrementally from the collected updates from the client devices.</p>
</div>
</li>
<li id="S3.I53.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I53.i2.p1" class="ltx_para">
<p id="S3.I53.i2.p1.1" class="ltx_p">Hierarchical Federated Learning (<span id="S3.I53.i2.p1.1.1" class="ltx_text ltx_font_italic">HFL</span>) enables hierarchical model aggregation in large scale networks of client devices where communication latency is prohibitively large due to limited bandwidth. The <span id="S3.I53.i2.p1.1.2" class="ltx_text ltx_font_italic">HFL</span> seeks a consensus on the model and uses edge servers to aggregate model updates from client devices that are geographically near.</p>
</div>
</li>
<li id="S3.I53.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I53.i3.p1" class="ltx_para">
<p id="S3.I53.i3.p1.1" class="ltx_p">Federated Learning + Hierarchical Clustering (<span id="S3.I53.i3.p1.1.1" class="ltx_text ltx_font_italic">FL+HC</span>) is the addition of a hierarchical clustering algorithm to the federated learning system. The cluster is formed according to the data distributions similarity based on the following distance metrics: (1) Manhattan, (2) Euclidean, (3) Cosine distance metrics.</p>
</div>
</li>
<li id="S3.I53.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I53.i4.p1" class="ltx_para">
<p id="S3.I53.i4.p1.1" class="ltx_p"><span id="S3.I53.i4.p1.1.1" class="ltx_text ltx_font_italic">Astraea</span> is a federated learning framework that tackles non-IID characteristics of federated clients. The framework introduces a mediator to the central server and the client devices to balance the skewed client data distributions. The mediator performs the z-score-based data augmentation and downsampling to relieve the global imbalanced of training data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.4 </span><span id="S3.SS4.SSS4.1.1" class="ltx_text ltx_font_bold">Pattern 14: Secure Aggregator</span>
</h4>

<figure id="S3.F17" class="ltx_figure"><img src="/html/2101.02373/assets/x17.png" id="S3.F17.g1" class="ltx_graphics ltx_centering ltx_img_square" width="313" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Secure Aggregator.</figcaption>
</figure>
<div id="S3.SS4.SSS4.p1" class="ltx_para">
<p id="S3.SS4.SSS4.p1.1" class="ltx_p"><span id="S3.SS4.SSS4.p1.1.1" class="ltx_text ltx_font_bold">Summary:</span> A security aggregator manages the model exchange and aggregation security protocols to protect model security. Fig. <a href="#S3.F17" title="Figure 17 ‣ 3.4.4 Pattern 14: Secure Aggregator ‣ 3.4 Model Aggregation Patterns ‣ 3 Federated Learning Patterns ‣ Architectural Patterns for the Design of Federated Learning Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a> illustrates the security aggregator on each components with the security protocols embedded in them.</p>
</div>
<div id="S3.SS4.SSS4.p2" class="ltx_para">
<p id="S3.SS4.SSS4.p2.1" class="ltx_p"><span id="S3.SS4.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Context:</span> The central server sends global models to any existing or unknown device every round with no data privacy and security protocols that protect the communication from unauthorised access. Furthermore, model parameters contain pieces of private user information that can be inferred by the data-hungry machine learning algorithms.</p>
</div>
<div id="S3.SS4.SSS4.p3" class="ltx_para">
<p id="S3.SS4.SSS4.p3.1" class="ltx_p"><span id="S3.SS4.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Problem:</span> There are no security measures to tackle the honest-but-curious and active adversary security threats which exist in federated learning systems.</p>
</div>
<div id="S3.SS4.SSS4.p4" class="ltx_para">
<p id="S3.SS4.SSS4.p4.1" class="ltx_p"><span id="S3.SS4.SSS4.p4.1.1" class="ltx_text ltx_font_bold">Forces:</span> The problem requires to balance the following forces:</p>
</div>
<div id="S3.SS4.SSS4.p5" class="ltx_para">
<ul id="S3.I54" class="ltx_itemize">
<li id="S3.I54.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I54.i1.p1" class="ltx_para">
<p id="S3.I54.i1.p1.1" class="ltx_p"><span id="S3.I54.i1.p1.1.1" class="ltx_text ltx_font_italic">Client device security.</span> Client device security issues exist when dishonest and malicious client devices join the training process and poison the overall model performance by disrupting the training process or providing false updates to the central server.</p>
</div>
</li>
<li id="S3.I54.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I54.i2.p1" class="ltx_para">
<p id="S3.I54.i2.p1.1" class="ltx_p"><span id="S3.I54.i2.p1.1.1" class="ltx_text ltx_font_italic">Data security.</span> Data security of the client devices is challenged when the gradients or model parameters are inferred by unauthorised parties through the data-hungry machine learning algorithms.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS4.p6" class="ltx_para">
<p id="S3.SS4.SSS4.p6.1" class="ltx_p"><span id="S3.SS4.SSS4.p6.1.1" class="ltx_text ltx_font_bold">Solution:</span> A security aggregator handles the secure multiparty computation (SMC) protocols for model exchanges and aggregations. The protocols provide security proof to guarantee that each party knows only its input and output. For instance, homomorphic encryption is a method to encrypt the models and only allow authorised client devices and the central server to decrypt and access the models. Pairwise masking and differential privacy (DP) methods are applied to reduce the interpretability of the model by unauthorised party <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">46</span></a>]</cite>. The technique involves adding noise to the parameters or gradient or uses a generalised method.</p>
</div>
<div id="S3.SS4.SSS4.p7" class="ltx_para">
<p id="S3.SS4.SSS4.p7.1" class="ltx_p"><span id="S3.SS4.SSS4.p7.1.1" class="ltx_text ltx_font_bold">Consequences: </span></p>
</div>
<div id="S3.SS4.SSS4.p8" class="ltx_para">
<p id="S3.SS4.SSS4.p8.1" class="ltx_p">Benefits:</p>
<ul id="S3.I55" class="ltx_itemize">
<li id="S3.I55.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I55.i1.p1" class="ltx_para">
<p id="S3.I55.i1.p1.1" class="ltx_p"><span id="S3.I55.i1.p1.1.1" class="ltx_text ltx_font_italic">Data security.</span> The secure aggregator protects the model from being access by adversarial and unauthorised parties through homomorphic encryptions and prevents information leakage due to the data-hungry property of machine learning models.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS4.p9" class="ltx_para">
<p id="S3.SS4.SSS4.p9.1" class="ltx_p">Drawbacks:</p>
<ul id="S3.I56" class="ltx_itemize">
<li id="S3.I56.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I56.i1.p1" class="ltx_para">
<p id="S3.I56.i1.p1.1" class="ltx_p"><span id="S3.I56.i1.p1.1.1" class="ltx_text ltx_font_italic">System efficiency.</span> The extra security processes affect the system efficiency if excessive security steps are required every round for every device. It also lowers the training and aggregation speed due to encryption and decryption time.</p>
</div>
</li>
<li id="S3.I56.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I56.i2.p1" class="ltx_para">
<p id="S3.I56.i2.p1.1" class="ltx_p"><span id="S3.I56.i2.p1.1.1" class="ltx_text ltx_font_italic">Model performance-privacy trade-off.</span> The model performance is affected if the model privacy methods aggressively interfere with the model’s interpretability due to being excessively obscure.</p>
</div>
</li>
<li id="S3.I56.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I56.i3.p1" class="ltx_para">
<p id="S3.I56.i3.p1.1" class="ltx_p"><span id="S3.I56.i3.p1.1.1" class="ltx_text ltx_font_italic">Compromised key.</span> For encryption and decryption functions, the possible compromise of the security keys increases the privacy threat.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS4.p10" class="ltx_para">
<p id="S3.SS4.SSS4.p10.1" class="ltx_p"><span id="S3.SS4.SSS4.p10.1.1" class="ltx_text ltx_font_bold">Related patterns:</span> <span id="S3.SS4.SSS4.p10.1.2" class="ltx_text ltx_font_italic">Client Registry, Model Co-versioning Registry</span></p>
</div>
<div id="S3.SS4.SSS4.p11" class="ltx_para">
<p id="S3.SS4.SSS4.p11.1" class="ltx_p"><span id="S3.SS4.SSS4.p11.1.1" class="ltx_text ltx_font_bold">Known uses: </span></p>
<ul id="S3.I57" class="ltx_itemize">
<li id="S3.I57.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I57.i1.p1" class="ltx_para">
<p id="S3.I57.i1.p1.1" class="ltx_p"><span id="S3.I57.i1.p1.1.1" class="ltx_text ltx_font_italic">SecAgg<cite class="ltx_cite ltx_citemacro_cite"><span id="S3.I57.i1.p1.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S3.I57.i1.p1.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> a practical protocol by Google for secure aggregation in the federated learning settings.</p>
</div>
</li>
<li id="S3.I57.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I57.i2.p1" class="ltx_para">
<p id="S3.I57.i2.p1.1" class="ltx_p"><span id="S3.I57.i2.p1.1.1" class="ltx_text ltx_font_italic">HybridAlpha</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">44</span></a>]</cite> is a framework that manages the client devices that join the federated learning process. The security operation includes functional encryption, DP, and SMC.</p>
</div>
</li>
<li id="S3.I57.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I57.i3.p1" class="ltx_para">
<p id="S3.I57.i3.p1.1" class="ltx_p"><span id="S3.I57.i3.p1.1.1" class="ltx_text ltx_font_italic">TensorFlow Privacy Library<span id="footnote20" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note"><span id="footnote20.1.1.1" class="ltx_text ltx_font_upright">20</span></span><a target="_blank" href="https://github.com/tensorflow/privacy/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/tensorflow/privacy/</a></span></span></span></span> provides an implementation of DP-SGD machine learning.</p>
</div>
</li>
<li id="S3.I57.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I57.i4.p1" class="ltx_para">
<p id="S3.I57.i4.p1.1" class="ltx_p"><span id="S3.I57.i4.p1.1.1" class="ltx_text ltx_font_italic">ZamaAI<span id="footnote21" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note"><span id="footnote21.1.1.1" class="ltx_text ltx_font_upright">21</span></span><a target="_blank" href="https://zama.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://zama.ai/</a></span></span></span></span> is an AI service platform that provides encryption technology that uses a homomorphic compiler to convert the model into an end-to-end encrypted parameters.</p>
</div>
</li>
<li id="S3.I57.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I57.i5.p1" class="ltx_para">
<p id="S3.I57.i5.p1.1" class="ltx_p">Simple Encrypted Arithmetic Library (<span id="S3.I57.i5.p1.1.1" class="ltx_text ltx_font_italic">SEAL<span id="footnote22" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note"><span id="footnote22.1.1.1" class="ltx_text ltx_font_upright">22</span></span><a target="_blank" href="https://www.microsoft.com/en-us/research/project/microsoft-seal/" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://www.microsoft.com/en-us/research/project/microsoft-seal/</a></span></span></span></span>) is a homomorphic encryption API introduced by Microsoft AI to allow computations to be performed directly on encrypted data.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Various patterns are proposed to improve the architectural design challenges of a federated learning system. The main challenges include communication &amp; computation efficiency, data privacy, model performance, system security, and reliability. First, <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">client registry</span>, <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">client selector</span>, and <span id="S4.p1.1.3" class="ltx_text ltx_font_italic">client cluster</span> are proposed for client device management in the job creation stage. These patterns manage client devices to improve model performance, system, and training efficiency.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">During the model training stage, the performance trade-off often occurs due to the non-IID nature of the local data. The patterns proposed to address this issue are <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">heterogeneous data handler</span> and <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">incentive registry</span>. Furthermore, the non-IID data that enhances the local personalisation of the model also hurts the generalisation of the global model produced. The patterns proposed to address this issue are <span id="S4.p2.1.3" class="ltx_text ltx_font_italic">client cluster</span>, <span id="S4.p2.1.4" class="ltx_text ltx_font_italic">hierarchical aggregator</span>, <span id="S4.p2.1.5" class="ltx_text ltx_font_italic">multi-task model trainer</span>, and <span id="S4.p2.1.6" class="ltx_text ltx_font_italic">deployment selector</span>. Specifically, <span id="S4.p2.1.7" class="ltx_text ltx_font_italic">multi-task model trainer</span> adopts multi-task or transfer learning techniques to learn different models or personalise a global model on local data to optimise the model performance for clients with different local data characteristics, whereas the <span id="S4.p2.1.8" class="ltx_text ltx_font_italic">deployment selector</span> effectively selects the user clients to receive the personalised models that fit their local data.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">For the model exchange and aggregation stages, communication and computation efficiency become a system bottleneck. To effectively tackle these issues, <span id="S4.p3.1.1" class="ltx_text ltx_font_italic">client selector</span>, <span id="S4.p3.1.2" class="ltx_text ltx_font_italic">client cluster</span>, <span id="S4.p3.1.3" class="ltx_text ltx_font_italic">deployment selector</span>, <span id="S4.p3.1.4" class="ltx_text ltx_font_italic">asynchronous aggregator</span>, and <span id="S4.p3.1.5" class="ltx_text ltx_font_italic">hierarchical aggregator</span> are embedded in the system to optimise resource consumption. However, these patterns require extra client information (i.e., resource or performance) to perform the selection or scheduling of updates. Intuitively, the collection and analysis of the client information on the central server may lead to another form of data privacy violation. Furthermore, extra computation and communication resources are consumed to collect and analyse the client information, in addition to the model training task and the fundamental tasks of the client devices. Hence, <span id="S4.p3.1.6" class="ltx_text ltx_font_italic">message compressor</span> and <span id="S4.p3.1.7" class="ltx_text ltx_font_italic">hierarchical aggregator</span> are proposed to tackle these issues. Moreover, <span id="S4.p3.1.8" class="ltx_text ltx_font_italic">incentive registry</span> is proposed to encourage more client devices to join the training to improve the model performance.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">The system security issue is present due to the distributed ownership of federated learning system components. The client nodes are mostly owned by different parties which are not governed by the system owner. Therefore, unauthorised clients may join the system and obtain model parameters from the system. Furthermore, adversarial clients may harm the model or system performance by uploading dishonest updates. <span id="S4.p4.1.1" class="ltx_text ltx_font_italic">Secure aggregator</span>, <span id="S4.p4.1.2" class="ltx_text ltx_font_italic">model co-versioning registry</span>, and <span id="S4.p4.1.3" class="ltx_text ltx_font_italic">client registry</span> aim to solve these challenges. Lastly, the trustworthiness between the client devices and the central server is also a challenge to gain the participation of clients. The central server may also be a single-point-of-failure that may affect the reliability of the system. Hence, <span id="S4.p4.1.4" class="ltx_text ltx_font_italic">decentralised aggregator</span> is proposed to solve the issue.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In many real-world scenarios, machine learning applications are usually embedded as a software component to a larger software system at enterprise level. Hence, to promote enterprise level adoption of machine learning-based applications, many researchers view machine learning models as a component of a software system so that the challenges in building machine learning models can be tackled through systematic software engineering approaches.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Wan et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">39</span></a>]</cite> studied how the adoption of machine learning changes software development practices. The work characterises the differences in various aspects of software engineering and task involved for machine learning system development and traditional software development. Lwakatare et al.
 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">32</span></a>]</cite> propose a taxonomy that depicts maturity stages of use of machine learning components in the industrial software system and mapped the challenges to the machine learning pipeline stages.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Building machine learning models is becoming an engineering discipline where practitioners take advantage of tried-and-proven methods to address recurring problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">25</span></a>]</cite>.
<br class="ltx_break">Washizaki et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">41</span></a>]</cite> studies the machine learning design patterns and architectural patterns. The authors also proposed an architectural pattern for machine learning for improving operational stability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text ltx_font_typewriter">47</span></a>]</cite>. The work separates machine learning systems’ components into business logic and machine learning components and focuses on the machine learning pipeline management, data management, and machine learning model versioning operations.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">The research on federated learning system design was first done by Bonawitz et. al <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, focusing on the high-level design of a basic federated learning system and its protocol definition. However, there is no study on the definition of architecture patterns or reusable solutions to address federated learning design challenges currently. Our work addresses this particular gap with respect to software architecture designs for federated learning as a distributed software system. To the best of our knowledge, this is the first comprehensive and systematic collection of federated learning architectural patterns. The outcomes are intended to provide architectural guidance for practitioners to better design and develop federated learning systems.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Federated learning is a data privacy-preserving, distributed machine learning approach to fully utilise the data and resources on IoT and smart mobile devices. Being a distributed system with multiple components and different stakeholders, architectural challenges need to be solved before federated learning can be effectively adopted in the real-world. In this paper, we present 14 federated learning architectural patterns associated with the lifecycle of a model in federated learning. The pattern collection is provided as architectural guidance for architects to better design and develop federated learning systems. In our future work, we will explore the architectural designs that help improve the trust in federated learning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
, 2019.

</span>
<span class="ltx_bibblock">General data protection regulation gdpr.

</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="https://gdpr-info.eu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gdpr-info.eu/</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et al. [2014]</span>
<span class="ltx_bibblock">
Ahmad, A., Jamshidi, P.,
Pahl, C., Khaliq, F.,
2014.

</span>
<span class="ltx_bibblock">A pattern language for the evolution of
component-based software architectures.

</span>
<span class="ltx_bibblock">Electronic Communications of the EASST
59.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahn et al. [2019]</span>
<span class="ltx_bibblock">
Ahn, J., Simeone, O.,
Kang, J., 2019.

</span>
<span class="ltx_bibblock">Wireless federated distillation for distributed edge
learning with heterogeneous data, in: 2019 IEEE 30th
Annual International Symposium on Personal, Indoor and Mobile Radio
Communications (PIMRC), pp. 1–6.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balalaie et al. [2018]</span>
<span class="ltx_bibblock">
Balalaie, A., Heydarnoori, A.,
Jamshidi, P., Tamburri, D.A.,
Lynn, T., 2018.

</span>
<span class="ltx_bibblock">Microservices migration patterns.

</span>
<span class="ltx_bibblock">Software: Practice and Experience
48, 2019–2042.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. [2019]</span>
<span class="ltx_bibblock">
Bao, X., Su, C.,
Xiong, Y., Huang, W.,
Hu, Y., 2019.

</span>
<span class="ltx_bibblock">Flchain: A blockchain for auditable federated
learning with trust and incentive, in: 2019 5th
International Conference on Big Data Computing and Communications (BIGCOM),
pp. 151–159.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beck and Cunningham [1987]</span>
<span class="ltx_bibblock">
Beck, K., Cunningham, W.,
1987.

</span>
<span class="ltx_bibblock">Using pattern languages for object oriented
programs, in: Conference on Object-Oriented Programming,
Systems, Languages, and Applications (OOPSLA).

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2017]</span>
<span class="ltx_bibblock">
Bonawitz, K., Ivanov, V.,
Kreuter, B., Marcedone, A.,
McMahan, H.B., Patel, S.,
Ramage, D., Segal, A.,
Seth, K., 2017.

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving
machine learning, Association for Computing Machinery,
New York, NY, USA.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2019]</span>
<span class="ltx_bibblock">
Bonawitz, K.A., Eichner, H.,
Grieskamp, W., Huba, D.,
Ingerman, A., Ivanov, V.,
Kiddon, C.M., Konečný, J.,
Mazzocchi, S., McMahan, B.,
Overveldt, T.V., Petrou, D.,
Ramage, D., Roselander, J.,
2019.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design,
in: SysML 2019.

</span>
<span class="ltx_bibblock">To appear.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brinkkemper [1996]</span>
<span class="ltx_bibblock">
Brinkkemper, S., 1996.

</span>
<span class="ltx_bibblock">Method engineering: engineering of information
systems development methods and tools.

</span>
<span class="ltx_bibblock">Information and Software Technology
38, 275–280.

</span>
<span class="ltx_bibblock">Method Engineering and Meta-Modelling.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et al. [2020]</span>
<span class="ltx_bibblock">
Chai, Z., Ali, A., Zawad,
S., Truex, S., Anwar, A.,
Baracaldo, N., Zhou, Y.,
Ludwig, H., Yan, F.,
Cheng, Y., 2020.

</span>
<span class="ltx_bibblock">Tifl: A tier-based federated learning system, in:
Proceedings of the 29th International Symposium on
High-Performance Parallel and Distributed Computing,
Association for Computing Machinery,
New York, NY, USA. p. 125–136.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
Chen, Y., Ning, Y.,
Slawski, M., Rangwala, H.,
2020.

</span>
<span class="ltx_bibblock">Asynchronous online federated learning for edge
devices with non-iid data.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1911.02134" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1911.02134</a><span id="bib.bib11.1.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.4.4.1" class="ltx_text ltx_font_typewriter">Corinzia and Buhmann [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text ltx_font_typewriter">
Corinzia, L., Buhmann, J.M.,
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text ltx_font_typewriter">Variational federated multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1906.06268" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1906.06268</a><span id="bib.bib12.8.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text ltx_font_typewriter">Duan et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text ltx_font_typewriter">
Duan, M., Liu, D.,
Chen, X., Tan, Y.,
Ren, J., Qiao, L.,
Liang, L., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text ltx_font_typewriter">Astraea: Self-balancing federated learning for
improving classification accuracy of mobile deep learning applications, in:
2019 IEEE 37th International Conference on Computer
Design (ICCD), pp. 246--254.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text ltx_font_typewriter">Gu et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text ltx_font_typewriter">
Gu, B., Xu, A., Huo, Z.,
Deng, C., Huang, H.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text ltx_font_typewriter">Privacy-preserving asynchronous federated learning
algorithms for multi-party vertically collaborative learning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2008.06233" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:2008.06233</a><span id="bib.bib14.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text ltx_font_typewriter">Haddadpour et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text ltx_font_typewriter">
Haddadpour, F., Kamani, M.M.,
Mokhtari, A., Mahdavi, M.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text ltx_font_typewriter">Federated learning with compression: Unified analysis
and sharp guarantees.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2007.01154" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:2007.01154</a><span id="bib.bib15.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text ltx_font_typewriter">Hu et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text ltx_font_typewriter">
Hu, C., Jiang, J., Wang,
Z., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text ltx_font_typewriter">Decentralized federated learning: A segmented gossip
approach.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1908.07782" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1908.07782</a><span id="bib.bib16.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text ltx_font_typewriter">Huang et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text ltx_font_typewriter">
Huang, L., Shea, A.L.,
Qian, H., Masurkar, A.,
Deng, H., Liu, D., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text ltx_font_typewriter">Patient clustering improves efficiency of federated
machine learning to predict mortality and hospital stay time using
distributed electronic medical records.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text ltx_font_typewriter">Journal of Biomedical Informatics
99, 103291.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text ltx_font_typewriter">Jamshidi et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text ltx_font_typewriter">
Jamshidi, P., Pahl, C.,
Mendonça, N.C., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text ltx_font_typewriter">Pattern-based multi-cloud architecture migration.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text ltx_font_typewriter">Software: Practice and Experience
47, 1159--1184.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text ltx_font_typewriter">Jeong et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text ltx_font_typewriter">
Jeong, E., Oh, S., Kim,
H., Park, J., Bennis, M.,
Kim, S.L., 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text ltx_font_typewriter">Communication-efficient on-device machine learning:
Federated distillation and augmentation under non-iid private data.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1811.11479" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1811.11479</a><span id="bib.bib19.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.4.4.1" class="ltx_text ltx_font_typewriter">Jiang and Hu [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text ltx_font_typewriter">
Jiang, J., Hu, L.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text ltx_font_typewriter">Decentralised federated learning with adaptive
partial gradient aggregation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text ltx_font_typewriter">CAAI Transactions on Intelligence Technology
5, 230--236.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text ltx_font_typewriter">Jiang et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text ltx_font_typewriter">
Jiang, Y., Wang, S.,
Valls, V., Ko, B.J.,
Lee, W.H., Leung, K.K.,
Tassiulas, L., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text ltx_font_typewriter">Model pruning enables efficient federated learning on
edge devices.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1909.12326" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1909.12326</a><span id="bib.bib21.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text ltx_font_typewriter">Jobin et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text ltx_font_typewriter">
Jobin, A., Ienca, M.,
Vayena, E., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text ltx_font_typewriter">The global landscape of AI ethics guidelines.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text ltx_font_typewriter">Nature Machine Intelligence 1,
389--399.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.4.4.1" class="ltx_text ltx_font_typewriter">Kitchenham and Charters [2007]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.6.1" class="ltx_text ltx_font_typewriter">
Kitchenham, B., Charters, S.,
2007.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text ltx_font_typewriter">Guidelines for performing systematic literature
reviews in software engineering.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text ltx_font_typewriter">Konečný et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text ltx_font_typewriter">
Konečný, J., McMahan, H.B.,
Yu, F.X., Richtárik, P.,
Suresh, A.T., Bacon, D.,
2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text ltx_font_typewriter">Federated learning: Strategies for improving
communication efficiency.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1610.05492" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1610.05492</a><span id="bib.bib24.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text ltx_font_typewriter">Lakshmanan et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text ltx_font_typewriter">
Lakshmanan, L.V., Munn, M.,
Robinson, S., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text ltx_font_typewriter">Machine Learning Design Patterns.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text ltx_font_typewriter">Lalitha et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text ltx_font_typewriter">
Lalitha, A., Shekhar, S.,
Javidi, T., Koushanfar, F.,
2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text ltx_font_typewriter">Fully decentralized federated learning, in:
Third workshop on Bayesian Deep Learning (NeurIPS).
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text ltx_font_typewriter">Li et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text ltx_font_typewriter">
Li, T., Sahu, A.K.,
Talwalkar, A., Smith, V.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text ltx_font_typewriter">Federated learning: Challenges, methods, and future
directions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text ltx_font_typewriter">IEEE Signal Processing Magazine
37, 50--60.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text ltx_font_typewriter">Liu et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text ltx_font_typewriter">
Liu, L., Zhang, J.,
Song, S.H., Letaief, K.B.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text ltx_font_typewriter">Client-edge-cloud hierarchical federated learning,
in: ICC 2020 - 2020 IEEE International Conference on
Communications (ICC), pp. 1--6.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text ltx_font_typewriter">Liu et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text ltx_font_typewriter">
Liu, Y., Ai, Z., Sun, S.,
Zhang, S., Liu, Z., Yu,
H., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text ltx_font_typewriter">FedCoin: A Peer-to-Peer Payment System for Federated
Learning. Springer International Publishing,
Cham.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text ltx_font_typewriter">pp. 125--138.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text ltx_font_typewriter">Lo et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text ltx_font_typewriter">
Lo, S.K., Liew, C.S., Tey,
K.S., Mekhilef, S., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text ltx_font_typewriter">An interoperable component-based architecture for
data-driven iot system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text ltx_font_typewriter">Sensors 19.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text ltx_font_typewriter">Lo et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text ltx_font_typewriter">
Lo, S.K., Lu, Q., Wang,
C., Paik, H.Y., Zhu, L.,
2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text ltx_font_typewriter">A systematic literature review on federated machine
learning: From a software engineering perspective.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text ltx_font_typewriter">ACM Comput. Surv. 54.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text ltx_font_typewriter">Lwakatare et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text ltx_font_typewriter">
Lwakatare, L.E., Raj, A.,
Bosch, J., Olsson, H.H.,
Crnkovic, I., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text ltx_font_typewriter">A taxonomy of software engineering challenges for
machine learning systems: An empirical investigation, in:
Kruchten, P., Fraser, S.,
Coallier, F. (Eds.), Agile Processes in
Software Engineering and Extreme Programming, Springer
International Publishing, Cham. pp.
227--243.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text ltx_font_typewriter">McMahan et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text ltx_font_typewriter">
McMahan, H.B., Moore, E.,
Ramage, D., Hampson, S.,
y Arcas, B.A., 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text ltx_font_typewriter">Communication-efficient learning of deep networks
from decentralized data.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1602.05629" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1602.05629</a><span id="bib.bib33.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.4.4.1" class="ltx_text ltx_font_typewriter">Meszaros and Doble [1997]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text ltx_font_typewriter">
Meszaros, G., Doble, J.,
1997.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text ltx_font_typewriter">A Pattern Language for Pattern Writing.
Addison-Wesley Longman Publishing Co., Inc.,
USA.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text ltx_font_typewriter">p. 529–574.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.4.4.1" class="ltx_text ltx_font_typewriter">Mirbel and Ralyté [2006]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.6.1" class="ltx_text ltx_font_typewriter">
Mirbel, I., Ralyté, J.,
2006.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text ltx_font_typewriter">Situational method engineering: combining
assembly-based and roadmap-driven approaches.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text ltx_font_typewriter">Requirements Engineering 11,
58--78.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text ltx_font_typewriter">Roy et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text ltx_font_typewriter">
Roy, A.G., Siddiqui, S.,
Pölsterl, S., Navab, N.,
Wachinger, C., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text ltx_font_typewriter">Braintorrent: A peer-to-peer environment for
decentralized federated learning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1905.06731" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1905.06731</a><span id="bib.bib36.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text ltx_font_typewriter">Sattler et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text ltx_font_typewriter">
Sattler, F., Wiedemann, S.,
Müller, K.R., Samek, W.,
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text ltx_font_typewriter">Robust and communication-efficient federated learning
from non-i.i.d. data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text ltx_font_typewriter">IEEE Transactions on Neural Networks and Learning
Systems 31, 3400--3413.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text ltx_font_typewriter">Smith et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text ltx_font_typewriter">
Smith, V., Chiang, C.K.,
Sanjabi, M., Talwalkar, A.,
2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text ltx_font_typewriter">Federated multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1705.10467" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1705.10467</a><span id="bib.bib38.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text ltx_font_typewriter">Wan et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text ltx_font_typewriter">
Wan, Z., Xia, X.,
Lo, D., Murphy, G.C.,
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text ltx_font_typewriter">How does machine learning change software development
practices?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text ltx_font_typewriter">IEEE Transactions on Software Engineering ,
1--1.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text ltx_font_typewriter">WANG et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text ltx_font_typewriter">
WANG, L., WANG, W.,
LI, B., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text ltx_font_typewriter">Cmfl: Mitigating communication overhead for federated
learning, in: 2019 IEEE 39th International Conference on
Distributed Computing Systems (ICDCS), pp. 954--964.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text ltx_font_typewriter">Washizaki et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text ltx_font_typewriter">
Washizaki, H., Uchida, H.,
Khomh, F., Guéhéneuc, Y.,
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text ltx_font_typewriter">Studying software engineering patterns for designing
machine learning systems, in: 2019 10th International
Workshop on Empirical Software Engineering in Practice (IWESEP), pp.
49--495.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text ltx_font_typewriter">Weng et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text ltx_font_typewriter">
Weng, J., Weng, J.,
Zhang, J., Li, M.,
Zhang, Y., Luo, W.,
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text ltx_font_typewriter">Deepchain: Auditable and privacy-preserving deep
learning with blockchain-based incentive.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text ltx_font_typewriter">IEEE Transactions on Dependable and Secure
Computing , 1--1.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text ltx_font_typewriter">Xie et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text ltx_font_typewriter">
Xie, C., Koyejo, S.,
Gupta, I., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text ltx_font_typewriter">Asynchronous federated optimization.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1903.03934" title="" class="ltx_ref ltx_href ltx_font_typewriter">arXiv:1903.03934</a><span id="bib.bib43.9.1" class="ltx_text ltx_font_typewriter">.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text ltx_font_typewriter">Xu et al. [2019a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text ltx_font_typewriter">
Xu, R., Baracaldo, N.,
Zhou, Y., Anwar, A.,
Ludwig, H., 2019a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text ltx_font_typewriter">Hybridalpha: An efficient approach for
privacy-preserving federated learning, in: Proceedings
of the 12th ACM Workshop on Artificial Intelligence and Security,
Association for Computing Machinery,
New York, NY, USA. p. 13–23.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text ltx_font_typewriter">Xu et al. [2019b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text ltx_font_typewriter">
Xu, Z., Yu, F., Xiong,
J., Chen, X., 2019b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text ltx_font_typewriter">Helios: Heterogeneity-aware federated learning with
dynamically balanced collaboration.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text ltx_font_typewriter">arXiv preprint arXiv:1912.01684 .
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text ltx_font_typewriter">Yang et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text ltx_font_typewriter">
Yang, Q., Liu, Y., Chen,
T., Tong, Y., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text ltx_font_typewriter">Federated machine learning: Concept and
applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text ltx_font_typewriter">ACM Trans. Intell. Syst. Technol.
10.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.4.4.1" class="ltx_text ltx_font_typewriter">Yokoyama [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text ltx_font_typewriter">
Yokoyama, H., 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text ltx_font_typewriter">Machine learning system architectural pattern for
improving operational stability, in: 2019 IEEE
International Conference on Software Architecture Companion (ICSA-C), pp.
267--274.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.4.4.1" class="ltx_text ltx_font_typewriter">Zdun [2007]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text ltx_font_typewriter">
Zdun, U., 2007.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text ltx_font_typewriter">Systematic pattern selection using pattern language
grammars and design space analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text ltx_font_typewriter">Software: Practice and Experience
37, 983--1016.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text ltx_font_typewriter">Zhang et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text ltx_font_typewriter">
Zhang, W., Lu, Q.,
Yu, Q., Li, Z.,
Liu, Y., Lo, S.K.,
Chen, S., Xu, X.,
Zhu, L., 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text ltx_font_typewriter">Blockchain-based federated learning for device
failure detection in industrial iot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text ltx_font_typewriter">IEEE Internet of Things Journal ,
1--12.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2101.02371" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2101.02373" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2101.02373">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2101.02373" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2101.02374" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 04:10:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
