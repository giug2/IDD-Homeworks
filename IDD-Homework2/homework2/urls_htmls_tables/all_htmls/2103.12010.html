<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2103.12010] Federated Quantum Machine Learning</title><meta property="og:description" content="Distributed training across several quantum computers could significantly improve the training time and if we could share the learned model, not the data, it could potentially improve the data privacy as the training w…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Quantum Machine Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Quantum Machine Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2103.12010">

<!--Generated on Tue Mar 12 15:18:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Quantum Machine Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Samuel Yen-Chi Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:ychen@bnl.gov">ychen@bnl.gov</a>
</span>
<span class="ltx_contact ltx_role_affiliation">Computational Science Initiative, Brookhaven National Laboratory, Upton, NY 11973, USA

</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shinjae Yoo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:sjyoo@bnl.gov">sjyoo@bnl.gov</a>
</span>
<span class="ltx_contact ltx_role_affiliation">Computational Science Initiative, Brookhaven National Laboratory, Upton, NY 11973, USA

</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Distributed training across several quantum computers could significantly improve the training time and if we could share the learned model, not the data, it could potentially improve the data privacy as the training would happen where the data is located.
However, to the best of our knowledge, no work has been done in quantum machine learning (QML) in federation setting yet.
In this work, we present the federated training on hybrid quantum-classical machine learning models although our framework could be generalized to pure quantum machine learning model. Specifically, we consider the quantum neural network (QNN) coupled with classical pre-trained convolutional model.
Our distributed federated learning scheme demonstrated almost the same level of trained model accuracies and yet significantly faster distributed training. It demonstrates a promising future research direction for scaling and privacy aspects.
</p>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_preprint"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">preprint: </span>BNL</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recently advances in machine learning (ML), in particular deep learning (DL), has found significant success in a wide variety of challenging tasks such as computer vision <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">simonyan2014very </a>; <a href="#bib.bib2" title="" class="ltx_ref">Szegedy2014GoingConvolutions </a>; <a href="#bib.bib3" title="" class="ltx_ref">Voulodimos2018DeepReview </a></cite>, natural language processing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">Sutskever2014SequenceNetworks </a></cite>, and even playing the game of Go with superhuman performance <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref">Silver2016MasteringSearch </a></cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In the meantime, quantum computers are introduced to the general public by several technology companies such as IBM <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">cross2018ibm </a></cite>, Google <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">arute2019quantum </a></cite>, IonQ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">grzesiak2020efficient </a></cite>
and D-Wave <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">lanting2014entanglement </a></cite>. Theoretically, quantum computing can provide exponential speedup to certain classes of hard problems that are intractable on classical computers <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">harrow2017quantum </a>; <a href="#bib.bib11" title="" class="ltx_ref">nielsen2002quantum </a></cite>. The most famous example is the factorization of large numbers via Shor algorithm <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">shor1999polynomial </a></cite> which can provide exponential speedup. While the search in unstructured database via Grover algorithm <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref">grover1997quantum </a></cite> can provide quadratic speedup. However, currently available quantum computers are not equipped with quantum error correction <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref">gottesman1997stabilizer </a>; <a href="#bib.bib15" title="" class="ltx_ref">gottesman1998theory </a></cite> and would suffer from the device noise. Quantum computation tasks or quantum circuits with a large number of qubits and/or a long circuit depth cannot be faithfully implemented on these so-called noisy intermediate-scale quantum (NISQ) devices <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">preskill2018quantum </a></cite>. Therefore, it is a highly challenging task to design applications with moderate quantum resources requirements which can leverage the quantum advantages on these NISQ devices.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">With the above-mentioned two rapid growing fields, it is then natural to consider the combination of them. Especially the machine learning applications which can be implemented on NISQ devices. Indeed, the area <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">quantum machine learning</em> (QML) draws a lot of attention recently and there are several promising breakthroughs. The most notable progress is the development of variational algorithms <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">peruzzo2014variational </a>; <a href="#bib.bib18" title="" class="ltx_ref">cerezo2020variational </a>; <a href="#bib.bib19" title="" class="ltx_ref">bharti2021noisy </a></cite> which enable the quantum machine learning on NISQ devices <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">mitarai2018quantum </a></cite>. Recent efforts have demonstrated the promising application of NISQ devices in several machine learning tasks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">schuld2018circuit </a>; <a href="#bib.bib22" title="" class="ltx_ref">Farhi2018ClassificationProcessors </a>; <a href="#bib.bib23" title="" class="ltx_ref">benedetti2019parameterized </a>; <a href="#bib.bib24" title="" class="ltx_ref">mari2019transfer </a>; <a href="#bib.bib25" title="" class="ltx_ref">abohashima2020classification </a>; <a href="#bib.bib26" title="" class="ltx_ref">easom2020towards </a>; <a href="#bib.bib27" title="" class="ltx_ref">sarma2019quantum </a>; <a href="#bib.bib28" title="" class="ltx_ref">chen2020hybrid </a>; <a href="#bib.bib29" title="" class="ltx_ref">stein2020hybrid </a>; <a href="#bib.bib30" title="" class="ltx_ref">chen2020quantum </a>; <a href="#bib.bib31" title="" class="ltx_ref">kyriienko2020solving </a>; <a href="#bib.bib32" title="" class="ltx_ref">dallaire2018quantum </a>; <a href="#bib.bib33" title="" class="ltx_ref">li2021quantum </a>; <a href="#bib.bib34" title="" class="ltx_ref">stein2020qugan </a>; <a href="#bib.bib35" title="" class="ltx_ref">zoufal2019quantum </a>; <a href="#bib.bib36" title="" class="ltx_ref">situ2018quantum </a>; <a href="#bib.bib37" title="" class="ltx_ref">nakaji2020quantum </a>; <a href="#bib.bib38" title="" class="ltx_ref">lloyd2020quantum </a>; <a href="#bib.bib39" title="" class="ltx_ref">nghiem2020unified </a>; <a href="#bib.bib40" title="" class="ltx_ref">chen19 </a>; <a href="#bib.bib41" title="" class="ltx_ref">lockwood2020reinforcement </a>; <a href="#bib.bib42" title="" class="ltx_ref">wu2020quantum </a>; <a href="#bib.bib43" title="" class="ltx_ref">jerbi2019quantum </a>; <a href="#bib.bib44" title="" class="ltx_ref">Chih-ChiehCHEN2020 </a>; <a href="#bib.bib45" title="" class="ltx_ref">bausch2020recurrent </a>; <a href="#bib.bib46" title="" class="ltx_ref">yang2020decentralizing </a></cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">One of the common features of these successful ML models is that they are data-driven. To build a successful deep learning model, it requires a huge amount of data. Although there are several public datasets for research purpose, most advanced and personalized models largely depend on the collected data from users’ mobile devices and other personal data (e.g. medical record, browsing habits and etc). For example, ML/DL approaches also succeed in the field of medical imaging <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib47" title="" class="ltx_ref">suzuki2017overview </a>; <a href="#bib.bib48" title="" class="ltx_ref">lundervold2019overview </a></cite>, speech recognition <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib49" title="" class="ltx_ref">deng2013new </a>; <a href="#bib.bib50" title="" class="ltx_ref">amodei2016deep </a>; <a href="#bib.bib51" title="" class="ltx_ref">hannun2014deep </a></cite>, to name a few. These fields rely critically on the massive dataset collected from the population and these data should not be accessed by unauthorized third-party. The use of these sensitive and personally identifiable information raises several concerns.
One of the concerns is that the channel used to exchange with the cloud service providers can be compromised, leading to the leakage of high-value personal or commercial data. Even if the communication channel can be secured, the cloud service provider is also risky as malicious adversaries can potentially invade the computing infrastructure. There are several solutions to deal with such issues. One of them is called <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">federated learning</em> (FL), which focuses on the decentralized computing architecture. For example, users can train a speech recognition model on his cell phone and upload the model to the cloud in exchange of the global model without upload the recordings directly. Such framework is made possible due to the fact of recent advances in hardware development, making even the small devices so powerful.
This concept not only help the privacy-preserving practice in classical machine learning but also in the rapid emerging <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">quantum machine learning</em> as researchers are trying to expand the machine learning capabilities by leveraging the power of quantum computers.
To harvest the power of quantum computers in the NISQ era, the key challenge is how to distribute the computational tasks to different quantum machines with limited quantum capabilities. Another challenge is the rising privacy concern in the use of large scale machine learning infrastructure. We address these two challenges by providing the framework of training quantum machine learning models in a federated manner.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this paper, we propose the federated training on hybrid quantum-classical classifiers. We show that with the federated training, the performance in terms of the testing accuracy does not decrease. In addition, the model still converges quickly compared to the non-federated training. Our efforts not only help building secure QML infrastructure but also help the distributed QML training which is to better utilize available NISQ devices.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This paper is organized as follows. In Section <a href="#S2" title="II Federated Machine Learning ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we introduce the concept of federated machine learning. In Section <a href="#S3" title="III Variational Quantum Circuits ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we describe the variational quantum circuit architecture in details. In Section <a href="#S4" title="IV Hybrid Quantum-Classical Transfer Learning ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we describe the transfer learning in hybrid quantum-classical models. Section <a href="#S5" title="V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> shows the performance of the proposed federated quantum learning on the experimental data, followed by further discussions in Section <a href="#S6" title="VI Discussion ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>. Finally we conclude in Section <a href="#S7" title="VII Conclusion ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span>Federated Machine Learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref">mcmahan2017communication </a></cite> emerges recently along with the rising privacy concerns in the use of large-scale dataset and cloud-based deep learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib53" title="" class="ltx_ref">shokri2015privacy </a></cite>. The basic components in a federated learning process are a <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">central node</em> and several <em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">client nodes</em>. The central node holds the <em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">global model</em> and receives the trained parameters from client devices. The central node performs the <em id="S2.p1.1.4" class="ltx_emph ltx_font_italic">aggregation</em> process to generate the new global model and share this new model to all of its client nodes. The client nodes will train locally with the received model with their own part of data, which in general is only a small portion.
In our proposed framework, the local clients are quantum computers or quantum simulators with the circuit parameters trained via hybrid quantum-classical manner. In each training round, a specified number of client nodes will be selected to perform the local training. Once the client training is finished, the circuit parameters from all the client nodes will be aggregated by the central node. There are various methods to aggregate the model. In this work, we choose the <em id="S2.p1.1.5" class="ltx_emph ltx_font_italic">mean</em> of the client models.
The scheme of federated quantum machine learning is shown in Figure <a href="#S2.F1" title="Figure 1 ‣ II Federated Machine Learning ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2103.12010/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="326" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S2.F1.2.1" class="ltx_text ltx_font_bold">Federated Quantum Machine Learning.</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">For further discussion and advanced settings on federated learning, we refer to <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">kulkarni2020survey </a>; <a href="#bib.bib55" title="" class="ltx_ref">kairouz2019advances </a>; <a href="#bib.bib56" title="" class="ltx_ref">lim2020federated </a>; <a href="#bib.bib57" title="" class="ltx_ref">yang2019federated </a>; <a href="#bib.bib58" title="" class="ltx_ref">li2020federated </a>; <a href="#bib.bib59" title="" class="ltx_ref">li2019federated </a>; <a href="#bib.bib60" title="" class="ltx_ref">wang2020convergence </a>; <a href="#bib.bib61" title="" class="ltx_ref">semwal2020fedperf </a></cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span>Variational Quantum Circuits</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">Variational quantum circuits (VQC) or quantum neural networks (QNN) are a special kind of quantum circuits with adjustable circuit parameters subject to optimization procedures developed by the classical machine learning community. In Figure <a href="#S3.F2" title="Figure 2 ‣ III Variational Quantum Circuits ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we introduce the general setting of a VQC in which the <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="E(\mathbf{x})" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.2" xref="S3.p1.1.m1.1.2.cmml"><mi id="S3.p1.1.m1.1.2.2" xref="S3.p1.1.m1.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.p1.1.m1.1.2.1" xref="S3.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S3.p1.1.m1.1.2.3.2" xref="S3.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.p1.1.m1.1.2.3.2.1" xref="S3.p1.1.m1.1.2.cmml">(</mo><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S3.p1.1.m1.1.2.3.2.2" xref="S3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.2.cmml" xref="S3.p1.1.m1.1.2"><times id="S3.p1.1.m1.1.2.1.cmml" xref="S3.p1.1.m1.1.2.1"></times><ci id="S3.p1.1.m1.1.2.2.cmml" xref="S3.p1.1.m1.1.2.2">𝐸</ci><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">E(\mathbf{x})</annotation></semantics></math> encodes the classical data into a quantum state which the quantum gates can actually operate on and the <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="W(\phi)" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.2" xref="S3.p1.2.m2.1.2.cmml"><mi id="S3.p1.2.m2.1.2.2" xref="S3.p1.2.m2.1.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.p1.2.m2.1.2.1" xref="S3.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S3.p1.2.m2.1.2.3.2" xref="S3.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S3.p1.2.m2.1.2.3.2.1" xref="S3.p1.2.m2.1.2.cmml">(</mo><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">ϕ</mi><mo stretchy="false" id="S3.p1.2.m2.1.2.3.2.2" xref="S3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.2.cmml" xref="S3.p1.2.m2.1.2"><times id="S3.p1.2.m2.1.2.1.cmml" xref="S3.p1.2.m2.1.2.1"></times><ci id="S3.p1.2.m2.1.2.2.cmml" xref="S3.p1.2.m2.1.2.2">𝑊</ci><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">W(\phi)</annotation></semantics></math> is the learnable block which can be seen as the <em id="S3.p1.2.1" class="ltx_emph ltx_font_italic">weights</em> in classical neural network. There are <em id="S3.p1.2.2" class="ltx_emph ltx_font_italic">quantum measurements</em> in the final part of VQC which is to <em id="S3.p1.2.3" class="ltx_emph ltx_font_italic">readout</em> the information from a quantum circuit and these classical numbers can be further processed with other classical or quantum components.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div id="S3.F2.3.3" class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" style="width:284.5pt;">
<span id="S3.F2.3.3.4" class="ltx_ERROR undefined">\Qcircuit</span>
<p id="S3.F2.1.1.1" class="ltx_p">@C=1em @R=1em 
<span id="S3.F2.1.1.1.2" class="ltx_ERROR undefined">\lstick</span>—0⟩ &amp; <span id="S3.F2.1.1.1.3" class="ltx_ERROR undefined">\multigate</span>3E(<span id="S3.F2.1.1.1.4" class="ltx_text ltx_font_bold">x</span>)  <span id="S3.F2.1.1.1.5" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.1.1.1.6" class="ltx_ERROR undefined">\multigate</span>3W(<span id="S3.F2.1.1.1.7" class="ltx_text ltx_font_bold ltx_font_italic">ϕ</span>)  <span id="S3.F2.1.1.1.8" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.1.1.1.9" class="ltx_ERROR undefined">\meter</span><span id="S3.F2.1.1.1.10" class="ltx_ERROR undefined">\qw</span></p>
<span id="S3.F2.3.3.5" class="ltx_ERROR undefined">\lstick</span>—0⟩<span id="S3.F2.3.3.6" class="ltx_ERROR undefined">\ghost</span>
<p id="S3.F2.3.3.7" class="ltx_p">F(<span id="S3.F2.3.3.7.1" class="ltx_text ltx_font_bold">x</span>)  <span id="S3.F2.3.3.7.2" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.3.3.7.3" class="ltx_ERROR undefined">\ghost</span>V(<span id="S3.F2.3.3.7.4" class="ltx_text ltx_font_bold ltx_font_italic">θ</span>)  <span id="S3.F2.3.3.7.5" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.3.3.7.6" class="ltx_ERROR undefined">\meter</span><span id="S3.F2.3.3.7.7" class="ltx_ERROR undefined">\qw</span></p>
<span id="S3.F2.3.3.8" class="ltx_ERROR undefined">\lstick</span>
<p id="S3.F2.3.3.9" class="ltx_p">⋮  <span id="S3.F2.3.3.9.1" class="ltx_ERROR undefined">\ghost</span>F(<span id="S3.F2.3.3.9.2" class="ltx_text ltx_font_bold">x</span>)  <span id="S3.F2.3.3.9.3" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.3.3.9.4" class="ltx_ERROR undefined">\ghost</span>V(<span id="S3.F2.3.3.9.5" class="ltx_text ltx_font_bold ltx_font_italic">θ</span>)  <span id="S3.F2.3.3.9.6" class="ltx_ERROR undefined">\qw</span> ⋮</p>
<span id="S3.F2.3.3.10" class="ltx_ERROR undefined">\lstick</span>—0⟩<span id="S3.F2.3.3.11" class="ltx_ERROR undefined">\ghost</span>
<p id="S3.F2.3.3.12" class="ltx_p">F(<span id="S3.F2.3.3.12.1" class="ltx_text ltx_font_bold">x</span>)  <span id="S3.F2.3.3.12.2" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.3.3.12.3" class="ltx_ERROR undefined">\ghost</span>V(<span id="S3.F2.3.3.12.4" class="ltx_text ltx_font_bold ltx_font_italic">θ</span>)  <span id="S3.F2.3.3.12.5" class="ltx_ERROR undefined">\qw</span> <span id="S3.F2.3.3.12.6" class="ltx_ERROR undefined">\meter</span><span id="S3.F2.3.3.12.7" class="ltx_ERROR undefined">\qw</span></p>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S3.F2.7.1" class="ltx_text ltx_font_bold">General structure for the variational quantum circuit (VQC).</span>
The <math id="S3.F2.4.m1.1" class="ltx_Math" alttext="E(\mathbf{x})" display="inline"><semantics id="S3.F2.4.m1.1b"><mrow id="S3.F2.4.m1.1.2" xref="S3.F2.4.m1.1.2.cmml"><mi id="S3.F2.4.m1.1.2.2" xref="S3.F2.4.m1.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m1.1.2.1" xref="S3.F2.4.m1.1.2.1.cmml">​</mo><mrow id="S3.F2.4.m1.1.2.3.2" xref="S3.F2.4.m1.1.2.cmml"><mo stretchy="false" id="S3.F2.4.m1.1.2.3.2.1" xref="S3.F2.4.m1.1.2.cmml">(</mo><mi id="S3.F2.4.m1.1.1" xref="S3.F2.4.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S3.F2.4.m1.1.2.3.2.2" xref="S3.F2.4.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.4.m1.1c"><apply id="S3.F2.4.m1.1.2.cmml" xref="S3.F2.4.m1.1.2"><times id="S3.F2.4.m1.1.2.1.cmml" xref="S3.F2.4.m1.1.2.1"></times><ci id="S3.F2.4.m1.1.2.2.cmml" xref="S3.F2.4.m1.1.2.2">𝐸</ci><ci id="S3.F2.4.m1.1.1.cmml" xref="S3.F2.4.m1.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m1.1d">E(\mathbf{x})</annotation></semantics></math> is the quantum routine for encoding the classical data into the quantum state and <math id="S3.F2.5.m2.1" class="ltx_Math" alttext="W(\bm{\theta})" display="inline"><semantics id="S3.F2.5.m2.1b"><mrow id="S3.F2.5.m2.1.2" xref="S3.F2.5.m2.1.2.cmml"><mi id="S3.F2.5.m2.1.2.2" xref="S3.F2.5.m2.1.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.F2.5.m2.1.2.1" xref="S3.F2.5.m2.1.2.1.cmml">​</mo><mrow id="S3.F2.5.m2.1.2.3.2" xref="S3.F2.5.m2.1.2.cmml"><mo stretchy="false" id="S3.F2.5.m2.1.2.3.2.1" xref="S3.F2.5.m2.1.2.cmml">(</mo><mi id="S3.F2.5.m2.1.1" xref="S3.F2.5.m2.1.1.cmml">𝜽</mi><mo stretchy="false" id="S3.F2.5.m2.1.2.3.2.2" xref="S3.F2.5.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.5.m2.1c"><apply id="S3.F2.5.m2.1.2.cmml" xref="S3.F2.5.m2.1.2"><times id="S3.F2.5.m2.1.2.1.cmml" xref="S3.F2.5.m2.1.2.1"></times><ci id="S3.F2.5.m2.1.2.2.cmml" xref="S3.F2.5.m2.1.2.2">𝑊</ci><ci id="S3.F2.5.m2.1.1.cmml" xref="S3.F2.5.m2.1.1">𝜽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m2.1d">W(\bm{\theta})</annotation></semantics></math> is the variational quantum circuit block with the learnable parameters <math id="S3.F2.6.m3.1" class="ltx_Math" alttext="\bm{\phi}" display="inline"><semantics id="S3.F2.6.m3.1b"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S3.F2.6.m3.1.1" xref="S3.F2.6.m3.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.6.m3.1c"><ci id="S3.F2.6.m3.1.1.cmml" xref="S3.F2.6.m3.1.1">bold-italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m3.1d">\bm{\phi}</annotation></semantics></math>. After the quantum operation, the quantum state is <em id="S3.F2.8.2" class="ltx_emph ltx_font_italic">measured</em> to retrieve classical numbers for further processing.
</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The general idea of VQC or QNN is that the circuit parameters are updated via iterative methods on a classical computer.
Recent theoretical studies have also demonstrated that VQCs are more expressive than conventional neural networks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib62" title="" class="ltx_ref">sim2019expressibility </a>; <a href="#bib.bib9" title="" class="ltx_ref">lanting2014entanglement </a>; <a href="#bib.bib63" title="" class="ltx_ref">du2018expressive </a>; <a href="#bib.bib64" title="" class="ltx_ref">abbas2020power </a></cite> with respect to the number of parameters or the learning speed. In addition, in the work <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">chen2020quantum </a></cite> and <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib65" title="" class="ltx_ref">chen2020qcnn </a>; <a href="#bib.bib66" title="" class="ltx_ref">chen2021hybrid </a></cite>, it has been demonstrated via numerical simulation that certain hybrid quantum-classical architectures reach higher accuracies than classical neural networks with similar number of parameters.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div id="S3.F3.4.4" class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" style="width:284.5pt;">
<span id="S3.F3.4.4.5" class="ltx_ERROR undefined">\Qcircuit</span>
<p id="S3.F3.1.1.1" class="ltx_p">@C=1em @R=1em 
<span id="S3.F3.1.1.1.2" class="ltx_ERROR undefined">\lstick</span>—0⟩ &amp; <span id="S3.F3.1.1.1.3" class="ltx_ERROR undefined">\gate</span>R_y(arctan(x_1))  <span id="S3.F3.1.1.1.4" class="ltx_ERROR undefined">\gate</span>R_z(arctan(x_1^2))  <span id="S3.F3.1.1.1.5" class="ltx_ERROR undefined">\ctrl</span>1  <span id="S3.F3.1.1.1.6" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.1.1.1.7" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.1.1.1.8" class="ltx_ERROR undefined">\targ</span> <span id="S3.F3.1.1.1.9" class="ltx_ERROR undefined">\gate</span>R(<span id="S3.F3.1.1.1.10" class="ltx_text ltx_font_italic">α</span>_1, <span id="S3.F3.1.1.1.11" class="ltx_text ltx_font_italic">β</span>_1, <span id="S3.F3.1.1.1.12" class="ltx_text ltx_font_italic">γ</span>_1)  <span id="S3.F3.1.1.1.13" class="ltx_ERROR undefined">\meter</span><span id="S3.F3.1.1.1.14" class="ltx_ERROR undefined">\qw</span></p>
<span id="S3.F3.4.4.6" class="ltx_ERROR undefined">\lstick</span>—0⟩<span id="S3.F3.4.4.7" class="ltx_ERROR undefined">\gate</span>
<p id="S3.F3.4.4.8" class="ltx_p">R_y(arctan(x_2))  <span id="S3.F3.4.4.8.1" class="ltx_ERROR undefined">\gate</span>R_z(arctan(x_2^2))  <span id="S3.F3.4.4.8.2" class="ltx_ERROR undefined">\targ</span> <span id="S3.F3.4.4.8.3" class="ltx_ERROR undefined">\ctrl</span>1  <span id="S3.F3.4.4.8.4" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.8.5" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.8.6" class="ltx_ERROR undefined">\gate</span>R(<span id="S3.F3.4.4.8.7" class="ltx_text ltx_font_italic">α</span>_2, <span id="S3.F3.4.4.8.8" class="ltx_text ltx_font_italic">β</span>_2, <span id="S3.F3.4.4.8.9" class="ltx_text ltx_font_italic">γ</span>_2)  <span id="S3.F3.4.4.8.10" class="ltx_ERROR undefined">\meter</span><span id="S3.F3.4.4.8.11" class="ltx_ERROR undefined">\qw</span></p>
<span id="S3.F3.4.4.9" class="ltx_ERROR undefined">\lstick</span>—0⟩<span id="S3.F3.4.4.10" class="ltx_ERROR undefined">\gate</span>
<p id="S3.F3.4.4.11" class="ltx_p">R_y(arctan(x_3))  <span id="S3.F3.4.4.11.1" class="ltx_ERROR undefined">\gate</span>R_z(arctan(x_3^2))  <span id="S3.F3.4.4.11.2" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.11.3" class="ltx_ERROR undefined">\targ</span> <span id="S3.F3.4.4.11.4" class="ltx_ERROR undefined">\ctrl</span>1  <span id="S3.F3.4.4.11.5" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.11.6" class="ltx_ERROR undefined">\gate</span>R(<span id="S3.F3.4.4.11.7" class="ltx_text ltx_font_italic">α</span>_3, <span id="S3.F3.4.4.11.8" class="ltx_text ltx_font_italic">β</span>_3, <span id="S3.F3.4.4.11.9" class="ltx_text ltx_font_italic">γ</span>_3)  <span id="S3.F3.4.4.11.10" class="ltx_ERROR undefined">\qw</span></p>
<span id="S3.F3.4.4.12" class="ltx_ERROR undefined">\lstick</span>—0⟩<span id="S3.F3.4.4.13" class="ltx_ERROR undefined">\gate</span>
<p id="S3.F3.4.4.14" class="ltx_p">R_y(arctan(x_4))  <span id="S3.F3.4.4.14.1" class="ltx_ERROR undefined">\gate</span>R_z(arctan(x_4^2))  <span id="S3.F3.4.4.14.2" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.14.3" class="ltx_ERROR undefined">\qw</span> <span id="S3.F3.4.4.14.4" class="ltx_ERROR undefined">\targ</span> <span id="S3.F3.4.4.14.5" class="ltx_ERROR undefined">\ctrl</span>-3 <span id="S3.F3.4.4.14.6" class="ltx_ERROR undefined">\gate</span>R(<span id="S3.F3.4.4.14.7" class="ltx_text ltx_font_italic">α</span>_4, <span id="S3.F3.4.4.14.8" class="ltx_text ltx_font_italic">β</span>_4, <span id="S3.F3.4.4.14.9" class="ltx_text ltx_font_italic">γ</span>_4)  <span id="S3.F3.4.4.14.10" class="ltx_ERROR undefined">\qw</span><span id="S3.F3.4.4.14.11" class="ltx_ERROR undefined">\gategroup</span>1448.7em–<span id="S3.F3.4.4.14.12" class="ltx_ERROR undefined">\qw</span></p>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S3.F3.20.1" class="ltx_text ltx_font_bold">Variational quantum classifier.</span>
The variational quantum classifier includes three components: <em id="S3.F3.21.2" class="ltx_emph ltx_font_italic">encoder</em>, <em id="S3.F3.22.3" class="ltx_emph ltx_font_italic">variational layer</em> and <em id="S3.F3.23.4" class="ltx_emph ltx_font_italic">quantum measurement</em>. The encoder consists of several single-qubit gates <math id="S3.F3.5.m1.2" class="ltx_Math" alttext="R_{y}(\arctan(x_{i}))" display="inline"><semantics id="S3.F3.5.m1.2b"><mrow id="S3.F3.5.m1.2.2" xref="S3.F3.5.m1.2.2.cmml"><msub id="S3.F3.5.m1.2.2.3" xref="S3.F3.5.m1.2.2.3.cmml"><mi id="S3.F3.5.m1.2.2.3.2" xref="S3.F3.5.m1.2.2.3.2.cmml">R</mi><mi id="S3.F3.5.m1.2.2.3.3" xref="S3.F3.5.m1.2.2.3.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S3.F3.5.m1.2.2.2" xref="S3.F3.5.m1.2.2.2.cmml">​</mo><mrow id="S3.F3.5.m1.2.2.1.1" xref="S3.F3.5.m1.2.2.cmml"><mo stretchy="false" id="S3.F3.5.m1.2.2.1.1.2" xref="S3.F3.5.m1.2.2.cmml">(</mo><mrow id="S3.F3.5.m1.2.2.1.1.1.1" xref="S3.F3.5.m1.2.2.1.1.1.2.cmml"><mi id="S3.F3.5.m1.1.1" xref="S3.F3.5.m1.1.1.cmml">arctan</mi><mo id="S3.F3.5.m1.2.2.1.1.1.1b" xref="S3.F3.5.m1.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.F3.5.m1.2.2.1.1.1.1.1" xref="S3.F3.5.m1.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.F3.5.m1.2.2.1.1.1.1.1.2" xref="S3.F3.5.m1.2.2.1.1.1.2.cmml">(</mo><msub id="S3.F3.5.m1.2.2.1.1.1.1.1.1" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.F3.5.m1.2.2.1.1.1.1.1.1.2" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.F3.5.m1.2.2.1.1.1.1.1.1.3" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.F3.5.m1.2.2.1.1.1.1.1.3" xref="S3.F3.5.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.F3.5.m1.2.2.1.1.3" xref="S3.F3.5.m1.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.5.m1.2c"><apply id="S3.F3.5.m1.2.2.cmml" xref="S3.F3.5.m1.2.2"><times id="S3.F3.5.m1.2.2.2.cmml" xref="S3.F3.5.m1.2.2.2"></times><apply id="S3.F3.5.m1.2.2.3.cmml" xref="S3.F3.5.m1.2.2.3"><csymbol cd="ambiguous" id="S3.F3.5.m1.2.2.3.1.cmml" xref="S3.F3.5.m1.2.2.3">subscript</csymbol><ci id="S3.F3.5.m1.2.2.3.2.cmml" xref="S3.F3.5.m1.2.2.3.2">𝑅</ci><ci id="S3.F3.5.m1.2.2.3.3.cmml" xref="S3.F3.5.m1.2.2.3.3">𝑦</ci></apply><apply id="S3.F3.5.m1.2.2.1.1.1.2.cmml" xref="S3.F3.5.m1.2.2.1.1.1.1"><arctan id="S3.F3.5.m1.1.1.cmml" xref="S3.F3.5.m1.1.1"></arctan><apply id="S3.F3.5.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.F3.5.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.F3.5.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.F3.5.m1.2.2.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m1.2d">R_{y}(\arctan(x_{i}))</annotation></semantics></math> and <math id="S3.F3.6.m2.2" class="ltx_Math" alttext="R_{z}(\arctan(x_{i}^{2}))" display="inline"><semantics id="S3.F3.6.m2.2b"><mrow id="S3.F3.6.m2.2.2" xref="S3.F3.6.m2.2.2.cmml"><msub id="S3.F3.6.m2.2.2.3" xref="S3.F3.6.m2.2.2.3.cmml"><mi id="S3.F3.6.m2.2.2.3.2" xref="S3.F3.6.m2.2.2.3.2.cmml">R</mi><mi id="S3.F3.6.m2.2.2.3.3" xref="S3.F3.6.m2.2.2.3.3.cmml">z</mi></msub><mo lspace="0em" rspace="0em" id="S3.F3.6.m2.2.2.2" xref="S3.F3.6.m2.2.2.2.cmml">​</mo><mrow id="S3.F3.6.m2.2.2.1.1" xref="S3.F3.6.m2.2.2.cmml"><mo stretchy="false" id="S3.F3.6.m2.2.2.1.1.2" xref="S3.F3.6.m2.2.2.cmml">(</mo><mrow id="S3.F3.6.m2.2.2.1.1.1.1" xref="S3.F3.6.m2.2.2.1.1.1.2.cmml"><mi id="S3.F3.6.m2.1.1" xref="S3.F3.6.m2.1.1.cmml">arctan</mi><mo id="S3.F3.6.m2.2.2.1.1.1.1b" xref="S3.F3.6.m2.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.F3.6.m2.2.2.1.1.1.1.1" xref="S3.F3.6.m2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.F3.6.m2.2.2.1.1.1.1.1.2" xref="S3.F3.6.m2.2.2.1.1.1.2.cmml">(</mo><msubsup id="S3.F3.6.m2.2.2.1.1.1.1.1.1" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.2" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.3" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.3.cmml">i</mi><mn id="S3.F3.6.m2.2.2.1.1.1.1.1.1.3" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S3.F3.6.m2.2.2.1.1.1.1.1.3" xref="S3.F3.6.m2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.F3.6.m2.2.2.1.1.3" xref="S3.F3.6.m2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.6.m2.2c"><apply id="S3.F3.6.m2.2.2.cmml" xref="S3.F3.6.m2.2.2"><times id="S3.F3.6.m2.2.2.2.cmml" xref="S3.F3.6.m2.2.2.2"></times><apply id="S3.F3.6.m2.2.2.3.cmml" xref="S3.F3.6.m2.2.2.3"><csymbol cd="ambiguous" id="S3.F3.6.m2.2.2.3.1.cmml" xref="S3.F3.6.m2.2.2.3">subscript</csymbol><ci id="S3.F3.6.m2.2.2.3.2.cmml" xref="S3.F3.6.m2.2.2.3.2">𝑅</ci><ci id="S3.F3.6.m2.2.2.3.3.cmml" xref="S3.F3.6.m2.2.2.3.3">𝑧</ci></apply><apply id="S3.F3.6.m2.2.2.1.1.1.2.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1"><arctan id="S3.F3.6.m2.1.1.cmml" xref="S3.F3.6.m2.1.1"></arctan><apply id="S3.F3.6.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.6.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.F3.6.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.F3.6.m2.2.2.1.1.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m2.2d">R_{z}(\arctan(x_{i}^{2}))</annotation></semantics></math> which represent rotations along <math id="S3.F3.7.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.F3.7.m3.1b"><mi id="S3.F3.7.m3.1.1" xref="S3.F3.7.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.F3.7.m3.1c"><ci id="S3.F3.7.m3.1.1.cmml" xref="S3.F3.7.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.7.m3.1d">y</annotation></semantics></math>-axis and <math id="S3.F3.8.m4.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.F3.8.m4.1b"><mi id="S3.F3.8.m4.1.1" xref="S3.F3.8.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.F3.8.m4.1c"><ci id="S3.F3.8.m4.1.1.cmml" xref="S3.F3.8.m4.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.8.m4.1d">z</annotation></semantics></math>-axis by the given angle <math id="S3.F3.9.m5.2" class="ltx_Math" alttext="\arctan(x_{i})" display="inline"><semantics id="S3.F3.9.m5.2b"><mrow id="S3.F3.9.m5.2.2.1" xref="S3.F3.9.m5.2.2.2.cmml"><mi id="S3.F3.9.m5.1.1" xref="S3.F3.9.m5.1.1.cmml">arctan</mi><mo id="S3.F3.9.m5.2.2.1b" xref="S3.F3.9.m5.2.2.2.cmml">⁡</mo><mrow id="S3.F3.9.m5.2.2.1.1" xref="S3.F3.9.m5.2.2.2.cmml"><mo stretchy="false" id="S3.F3.9.m5.2.2.1.1.2" xref="S3.F3.9.m5.2.2.2.cmml">(</mo><msub id="S3.F3.9.m5.2.2.1.1.1" xref="S3.F3.9.m5.2.2.1.1.1.cmml"><mi id="S3.F3.9.m5.2.2.1.1.1.2" xref="S3.F3.9.m5.2.2.1.1.1.2.cmml">x</mi><mi id="S3.F3.9.m5.2.2.1.1.1.3" xref="S3.F3.9.m5.2.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.F3.9.m5.2.2.1.1.3" xref="S3.F3.9.m5.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.9.m5.2c"><apply id="S3.F3.9.m5.2.2.2.cmml" xref="S3.F3.9.m5.2.2.1"><arctan id="S3.F3.9.m5.1.1.cmml" xref="S3.F3.9.m5.1.1"></arctan><apply id="S3.F3.9.m5.2.2.1.1.1.cmml" xref="S3.F3.9.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.F3.9.m5.2.2.1.1.1.1.cmml" xref="S3.F3.9.m5.2.2.1.1.1">subscript</csymbol><ci id="S3.F3.9.m5.2.2.1.1.1.2.cmml" xref="S3.F3.9.m5.2.2.1.1.1.2">𝑥</ci><ci id="S3.F3.9.m5.2.2.1.1.1.3.cmml" xref="S3.F3.9.m5.2.2.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.9.m5.2d">\arctan(x_{i})</annotation></semantics></math> and <math id="S3.F3.10.m6.2" class="ltx_Math" alttext="\arctan(x_{i}^{2})" display="inline"><semantics id="S3.F3.10.m6.2b"><mrow id="S3.F3.10.m6.2.2.1" xref="S3.F3.10.m6.2.2.2.cmml"><mi id="S3.F3.10.m6.1.1" xref="S3.F3.10.m6.1.1.cmml">arctan</mi><mo id="S3.F3.10.m6.2.2.1b" xref="S3.F3.10.m6.2.2.2.cmml">⁡</mo><mrow id="S3.F3.10.m6.2.2.1.1" xref="S3.F3.10.m6.2.2.2.cmml"><mo stretchy="false" id="S3.F3.10.m6.2.2.1.1.2" xref="S3.F3.10.m6.2.2.2.cmml">(</mo><msubsup id="S3.F3.10.m6.2.2.1.1.1" xref="S3.F3.10.m6.2.2.1.1.1.cmml"><mi id="S3.F3.10.m6.2.2.1.1.1.2.2" xref="S3.F3.10.m6.2.2.1.1.1.2.2.cmml">x</mi><mi id="S3.F3.10.m6.2.2.1.1.1.2.3" xref="S3.F3.10.m6.2.2.1.1.1.2.3.cmml">i</mi><mn id="S3.F3.10.m6.2.2.1.1.1.3" xref="S3.F3.10.m6.2.2.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S3.F3.10.m6.2.2.1.1.3" xref="S3.F3.10.m6.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.10.m6.2c"><apply id="S3.F3.10.m6.2.2.2.cmml" xref="S3.F3.10.m6.2.2.1"><arctan id="S3.F3.10.m6.1.1.cmml" xref="S3.F3.10.m6.1.1"></arctan><apply id="S3.F3.10.m6.2.2.1.1.1.cmml" xref="S3.F3.10.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.F3.10.m6.2.2.1.1.1.1.cmml" xref="S3.F3.10.m6.2.2.1.1.1">superscript</csymbol><apply id="S3.F3.10.m6.2.2.1.1.1.2.cmml" xref="S3.F3.10.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.F3.10.m6.2.2.1.1.1.2.1.cmml" xref="S3.F3.10.m6.2.2.1.1.1">subscript</csymbol><ci id="S3.F3.10.m6.2.2.1.1.1.2.2.cmml" xref="S3.F3.10.m6.2.2.1.1.1.2.2">𝑥</ci><ci id="S3.F3.10.m6.2.2.1.1.1.2.3.cmml" xref="S3.F3.10.m6.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.F3.10.m6.2.2.1.1.1.3.cmml" xref="S3.F3.10.m6.2.2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.10.m6.2d">\arctan(x_{i}^{2})</annotation></semantics></math>, respectively. These rotation angles are derived from the input values <math id="S3.F3.11.m7.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.F3.11.m7.1b"><msub id="S3.F3.11.m7.1.1" xref="S3.F3.11.m7.1.1.cmml"><mi id="S3.F3.11.m7.1.1.2" xref="S3.F3.11.m7.1.1.2.cmml">x</mi><mi id="S3.F3.11.m7.1.1.3" xref="S3.F3.11.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.11.m7.1c"><apply id="S3.F3.11.m7.1.1.cmml" xref="S3.F3.11.m7.1.1"><csymbol cd="ambiguous" id="S3.F3.11.m7.1.1.1.cmml" xref="S3.F3.11.m7.1.1">subscript</csymbol><ci id="S3.F3.11.m7.1.1.2.cmml" xref="S3.F3.11.m7.1.1.2">𝑥</ci><ci id="S3.F3.11.m7.1.1.3.cmml" xref="S3.F3.11.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.11.m7.1d">x_{i}</annotation></semantics></math> and are not subject to iterative optimization.
The variational layer consists of CNOT gates between each pair of neighbouring qubits which are used to entangle quantum states from each qubit and general single qubit unitary gates <math id="S3.F3.12.m8.3" class="ltx_Math" alttext="R(\alpha,\beta,\gamma)" display="inline"><semantics id="S3.F3.12.m8.3b"><mrow id="S3.F3.12.m8.3.4" xref="S3.F3.12.m8.3.4.cmml"><mi id="S3.F3.12.m8.3.4.2" xref="S3.F3.12.m8.3.4.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.F3.12.m8.3.4.1" xref="S3.F3.12.m8.3.4.1.cmml">​</mo><mrow id="S3.F3.12.m8.3.4.3.2" xref="S3.F3.12.m8.3.4.3.1.cmml"><mo stretchy="false" id="S3.F3.12.m8.3.4.3.2.1" xref="S3.F3.12.m8.3.4.3.1.cmml">(</mo><mi id="S3.F3.12.m8.1.1" xref="S3.F3.12.m8.1.1.cmml">α</mi><mo id="S3.F3.12.m8.3.4.3.2.2" xref="S3.F3.12.m8.3.4.3.1.cmml">,</mo><mi id="S3.F3.12.m8.2.2" xref="S3.F3.12.m8.2.2.cmml">β</mi><mo id="S3.F3.12.m8.3.4.3.2.3" xref="S3.F3.12.m8.3.4.3.1.cmml">,</mo><mi id="S3.F3.12.m8.3.3" xref="S3.F3.12.m8.3.3.cmml">γ</mi><mo stretchy="false" id="S3.F3.12.m8.3.4.3.2.4" xref="S3.F3.12.m8.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.12.m8.3c"><apply id="S3.F3.12.m8.3.4.cmml" xref="S3.F3.12.m8.3.4"><times id="S3.F3.12.m8.3.4.1.cmml" xref="S3.F3.12.m8.3.4.1"></times><ci id="S3.F3.12.m8.3.4.2.cmml" xref="S3.F3.12.m8.3.4.2">𝑅</ci><vector id="S3.F3.12.m8.3.4.3.1.cmml" xref="S3.F3.12.m8.3.4.3.2"><ci id="S3.F3.12.m8.1.1.cmml" xref="S3.F3.12.m8.1.1">𝛼</ci><ci id="S3.F3.12.m8.2.2.cmml" xref="S3.F3.12.m8.2.2">𝛽</ci><ci id="S3.F3.12.m8.3.3.cmml" xref="S3.F3.12.m8.3.3">𝛾</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.12.m8.3d">R(\alpha,\beta,\gamma)</annotation></semantics></math> with three parameters <math id="S3.F3.13.m9.3" class="ltx_Math" alttext="\alpha,\beta,\gamma" display="inline"><semantics id="S3.F3.13.m9.3b"><mrow id="S3.F3.13.m9.3.4.2" xref="S3.F3.13.m9.3.4.1.cmml"><mi id="S3.F3.13.m9.1.1" xref="S3.F3.13.m9.1.1.cmml">α</mi><mo id="S3.F3.13.m9.3.4.2.1" xref="S3.F3.13.m9.3.4.1.cmml">,</mo><mi id="S3.F3.13.m9.2.2" xref="S3.F3.13.m9.2.2.cmml">β</mi><mo id="S3.F3.13.m9.3.4.2.2" xref="S3.F3.13.m9.3.4.1.cmml">,</mo><mi id="S3.F3.13.m9.3.3" xref="S3.F3.13.m9.3.3.cmml">γ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.13.m9.3c"><list id="S3.F3.13.m9.3.4.1.cmml" xref="S3.F3.13.m9.3.4.2"><ci id="S3.F3.13.m9.1.1.cmml" xref="S3.F3.13.m9.1.1">𝛼</ci><ci id="S3.F3.13.m9.2.2.cmml" xref="S3.F3.13.m9.2.2">𝛽</ci><ci id="S3.F3.13.m9.3.3.cmml" xref="S3.F3.13.m9.3.3">𝛾</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.13.m9.3d">\alpha,\beta,\gamma</annotation></semantics></math>. Parameters labeled <math id="S3.F3.14.m10.1" class="ltx_Math" alttext="\alpha_{i}" display="inline"><semantics id="S3.F3.14.m10.1b"><msub id="S3.F3.14.m10.1.1" xref="S3.F3.14.m10.1.1.cmml"><mi id="S3.F3.14.m10.1.1.2" xref="S3.F3.14.m10.1.1.2.cmml">α</mi><mi id="S3.F3.14.m10.1.1.3" xref="S3.F3.14.m10.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.14.m10.1c"><apply id="S3.F3.14.m10.1.1.cmml" xref="S3.F3.14.m10.1.1"><csymbol cd="ambiguous" id="S3.F3.14.m10.1.1.1.cmml" xref="S3.F3.14.m10.1.1">subscript</csymbol><ci id="S3.F3.14.m10.1.1.2.cmml" xref="S3.F3.14.m10.1.1.2">𝛼</ci><ci id="S3.F3.14.m10.1.1.3.cmml" xref="S3.F3.14.m10.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.14.m10.1d">\alpha_{i}</annotation></semantics></math>, <math id="S3.F3.15.m11.1" class="ltx_Math" alttext="\beta_{i}" display="inline"><semantics id="S3.F3.15.m11.1b"><msub id="S3.F3.15.m11.1.1" xref="S3.F3.15.m11.1.1.cmml"><mi id="S3.F3.15.m11.1.1.2" xref="S3.F3.15.m11.1.1.2.cmml">β</mi><mi id="S3.F3.15.m11.1.1.3" xref="S3.F3.15.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.15.m11.1c"><apply id="S3.F3.15.m11.1.1.cmml" xref="S3.F3.15.m11.1.1"><csymbol cd="ambiguous" id="S3.F3.15.m11.1.1.1.cmml" xref="S3.F3.15.m11.1.1">subscript</csymbol><ci id="S3.F3.15.m11.1.1.2.cmml" xref="S3.F3.15.m11.1.1.2">𝛽</ci><ci id="S3.F3.15.m11.1.1.3.cmml" xref="S3.F3.15.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.15.m11.1d">\beta_{i}</annotation></semantics></math> and <math id="S3.F3.16.m12.1" class="ltx_Math" alttext="\gamma_{i}" display="inline"><semantics id="S3.F3.16.m12.1b"><msub id="S3.F3.16.m12.1.1" xref="S3.F3.16.m12.1.1.cmml"><mi id="S3.F3.16.m12.1.1.2" xref="S3.F3.16.m12.1.1.2.cmml">γ</mi><mi id="S3.F3.16.m12.1.1.3" xref="S3.F3.16.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.16.m12.1c"><apply id="S3.F3.16.m12.1.1.cmml" xref="S3.F3.16.m12.1.1"><csymbol cd="ambiguous" id="S3.F3.16.m12.1.1.1.cmml" xref="S3.F3.16.m12.1.1">subscript</csymbol><ci id="S3.F3.16.m12.1.1.2.cmml" xref="S3.F3.16.m12.1.1.2">𝛾</ci><ci id="S3.F3.16.m12.1.1.3.cmml" xref="S3.F3.16.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.16.m12.1d">\gamma_{i}</annotation></semantics></math> are the ones for iterative optimization. The quantum measurement component will output the Pauli-<math id="S3.F3.17.m13.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S3.F3.17.m13.1b"><mi id="S3.F3.17.m13.1.1" xref="S3.F3.17.m13.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.F3.17.m13.1c"><ci id="S3.F3.17.m13.1.1.cmml" xref="S3.F3.17.m13.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.17.m13.1d">Z</annotation></semantics></math> expectation values of designated qubits.
The number of qubits and the number of measurements can be adjusted to fit the problem of interest. In this work, we use the VQC as the final classifier layer, therefore the number of qubits equals to the latent vector size which is <math id="S3.F3.18.m14.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.F3.18.m14.1b"><mn id="S3.F3.18.m14.1.1" xref="S3.F3.18.m14.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.F3.18.m14.1c"><cn type="integer" id="S3.F3.18.m14.1.1.cmml" xref="S3.F3.18.m14.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.18.m14.1d">4</annotation></semantics></math> and we only consider the measurement on the first two qubits for binary classification. The grouped box in the VQC may repeat several times to increase the number of parameters, subject to the capacity and capability of the available quantum computers or simulation software used for the experiments. In this work, the grouped box repeats for <math id="S3.F3.19.m15.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F3.19.m15.1b"><mn id="S3.F3.19.m15.1.1" xref="S3.F3.19.m15.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F3.19.m15.1c"><cn type="integer" id="S3.F3.19.m15.1.1.cmml" xref="S3.F3.19.m15.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.19.m15.1d">2</annotation></semantics></math> times.</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Recent advances in VQC have demonstrated various applications in a wide variety of machine learning tasks. For example, VQC has been shown to be successful in the task of classification <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">mitarai2018quantum </a>; <a href="#bib.bib21" title="" class="ltx_ref">schuld2018circuit </a>; <a href="#bib.bib22" title="" class="ltx_ref">Farhi2018ClassificationProcessors </a>; <a href="#bib.bib23" title="" class="ltx_ref">benedetti2019parameterized </a>; <a href="#bib.bib24" title="" class="ltx_ref">mari2019transfer </a>; <a href="#bib.bib25" title="" class="ltx_ref">abohashima2020classification </a>; <a href="#bib.bib26" title="" class="ltx_ref">easom2020towards </a>; <a href="#bib.bib27" title="" class="ltx_ref">sarma2019quantum </a>; <a href="#bib.bib28" title="" class="ltx_ref">chen2020hybrid </a>; <a href="#bib.bib29" title="" class="ltx_ref">stein2020hybrid </a>; <a href="#bib.bib67" title="" class="ltx_ref">sierra2020dementia </a>; <a href="#bib.bib65" title="" class="ltx_ref">chen2020qcnn </a>; <a href="#bib.bib68" title="" class="ltx_ref">wu2020application </a></cite>, function approximation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">chen2020quantum </a>; <a href="#bib.bib20" title="" class="ltx_ref">mitarai2018quantum </a>; <a href="#bib.bib31" title="" class="ltx_ref">kyriienko2020solving </a></cite>, generative machine learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref">dallaire2018quantum </a>; <a href="#bib.bib34" title="" class="ltx_ref">stein2020qugan </a>; <a href="#bib.bib35" title="" class="ltx_ref">zoufal2019quantum </a>; <a href="#bib.bib36" title="" class="ltx_ref">situ2018quantum </a>; <a href="#bib.bib37" title="" class="ltx_ref">nakaji2020quantum </a>; <a href="#bib.bib33" title="" class="ltx_ref">li2021quantum </a></cite>, metric learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">lloyd2020quantum </a>; <a href="#bib.bib39" title="" class="ltx_ref">nghiem2020unified </a></cite>, deep reinforcement learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">chen19 </a>; <a href="#bib.bib41" title="" class="ltx_ref">lockwood2020reinforcement </a>; <a href="#bib.bib43" title="" class="ltx_ref">jerbi2019quantum </a>; <a href="#bib.bib44" title="" class="ltx_ref">Chih-ChiehCHEN2020 </a>; <a href="#bib.bib42" title="" class="ltx_ref">wu2020quantum </a>; <a href="#bib.bib69" title="" class="ltx_ref">jerbi2021variational </a></cite>, sequential learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">chen2020quantum </a>; <a href="#bib.bib45" title="" class="ltx_ref">bausch2020recurrent </a>; <a href="#bib.bib70" title="" class="ltx_ref">takaki2020learning </a></cite> and speech recognition <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">yang2020decentralizing </a></cite>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">III.1 </span>Quantum Encoder</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For a quantum circuit to operate on a classical dataset, the critical step is to define the <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">encoding</em> method which is to transform the classical vector into a quantum state. The encoding scheme is important as it is relevant to the efficiency of hardware implementation and potential quantum advantages. In NISQ era, the number of qubits as well as the circuit-depth are limited. Therefore, we need to encode the classical values with small number of qubits and without too many quantum operations. For more in-depth introduction of various kinds of encoding methods used in QML, refer to <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib71" title="" class="ltx_ref">Schuld2018InformationEncoding </a></cite>.
A general <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">N</annotation></semantics></math>-qubit quantum state can be represented as:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.15" class="ltx_Math" alttext="\ket{\psi}=\sum_{(q_{1},q_{2},...,q_{N})\in\{0,1\}^{N}}c_{q_{1},...,q_{N}}\ket{q_{1}}\otimes\ket{q_{2}}\otimes\ket{q_{3}}\otimes...\otimes\ket{q_{N}}," display="block"><semantics id="S3.E1.m1.15a"><mrow id="S3.E1.m1.15.15.1" xref="S3.E1.m1.15.15.1.1.cmml"><mrow id="S3.E1.m1.15.15.1.1" xref="S3.E1.m1.15.15.1.1.cmml"><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.2.1.cmml">|</mo><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">ψ</mi><mo stretchy="false" id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.2.1.cmml">⟩</mo></mrow><mo rspace="0.111em" id="S3.E1.m1.15.15.1.1.1" xref="S3.E1.m1.15.15.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.15.15.1.1.2" xref="S3.E1.m1.15.15.1.1.2.cmml"><munder id="S3.E1.m1.15.15.1.1.2.1" xref="S3.E1.m1.15.15.1.1.2.1.cmml"><mo movablelimits="false" id="S3.E1.m1.15.15.1.1.2.1.2" xref="S3.E1.m1.15.15.1.1.2.1.2.cmml">∑</mo><mrow id="S3.E1.m1.11.11.6" xref="S3.E1.m1.11.11.6.cmml"><mrow id="S3.E1.m1.11.11.6.6.3" xref="S3.E1.m1.11.11.6.6.4.cmml"><mo stretchy="false" id="S3.E1.m1.11.11.6.6.3.4" xref="S3.E1.m1.11.11.6.6.4.cmml">(</mo><msub id="S3.E1.m1.9.9.4.4.1.1" xref="S3.E1.m1.9.9.4.4.1.1.cmml"><mi id="S3.E1.m1.9.9.4.4.1.1.2" xref="S3.E1.m1.9.9.4.4.1.1.2.cmml">q</mi><mn id="S3.E1.m1.9.9.4.4.1.1.3" xref="S3.E1.m1.9.9.4.4.1.1.3.cmml">1</mn></msub><mo id="S3.E1.m1.11.11.6.6.3.5" xref="S3.E1.m1.11.11.6.6.4.cmml">,</mo><msub id="S3.E1.m1.10.10.5.5.2.2" xref="S3.E1.m1.10.10.5.5.2.2.cmml"><mi id="S3.E1.m1.10.10.5.5.2.2.2" xref="S3.E1.m1.10.10.5.5.2.2.2.cmml">q</mi><mn id="S3.E1.m1.10.10.5.5.2.2.3" xref="S3.E1.m1.10.10.5.5.2.2.3.cmml">2</mn></msub><mo id="S3.E1.m1.11.11.6.6.3.6" xref="S3.E1.m1.11.11.6.6.4.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.6.6.1.1" xref="S3.E1.m1.6.6.1.1.cmml">…</mi><mo id="S3.E1.m1.11.11.6.6.3.7" xref="S3.E1.m1.11.11.6.6.4.cmml">,</mo><msub id="S3.E1.m1.11.11.6.6.3.3" xref="S3.E1.m1.11.11.6.6.3.3.cmml"><mi id="S3.E1.m1.11.11.6.6.3.3.2" xref="S3.E1.m1.11.11.6.6.3.3.2.cmml">q</mi><mi id="S3.E1.m1.11.11.6.6.3.3.3" xref="S3.E1.m1.11.11.6.6.3.3.3.cmml">N</mi></msub><mo stretchy="false" id="S3.E1.m1.11.11.6.6.3.8" xref="S3.E1.m1.11.11.6.6.4.cmml">)</mo></mrow><mo id="S3.E1.m1.11.11.6.7" xref="S3.E1.m1.11.11.6.7.cmml">∈</mo><msup id="S3.E1.m1.11.11.6.8" xref="S3.E1.m1.11.11.6.8.cmml"><mrow id="S3.E1.m1.11.11.6.8.2.2" xref="S3.E1.m1.11.11.6.8.2.1.cmml"><mo stretchy="false" id="S3.E1.m1.11.11.6.8.2.2.1" xref="S3.E1.m1.11.11.6.8.2.1.cmml">{</mo><mn id="S3.E1.m1.7.7.2.2" xref="S3.E1.m1.7.7.2.2.cmml">0</mn><mo id="S3.E1.m1.11.11.6.8.2.2.2" xref="S3.E1.m1.11.11.6.8.2.1.cmml">,</mo><mn id="S3.E1.m1.8.8.3.3" xref="S3.E1.m1.8.8.3.3.cmml">1</mn><mo stretchy="false" id="S3.E1.m1.11.11.6.8.2.2.3" xref="S3.E1.m1.11.11.6.8.2.1.cmml">}</mo></mrow><mi id="S3.E1.m1.11.11.6.8.3" xref="S3.E1.m1.11.11.6.8.3.cmml">N</mi></msup></mrow></munder><mrow id="S3.E1.m1.15.15.1.1.2.2" xref="S3.E1.m1.15.15.1.1.2.2.cmml"><mrow id="S3.E1.m1.15.15.1.1.2.2.2" xref="S3.E1.m1.15.15.1.1.2.2.2.cmml"><msub id="S3.E1.m1.15.15.1.1.2.2.2.2" xref="S3.E1.m1.15.15.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.15.15.1.1.2.2.2.2.2" xref="S3.E1.m1.15.15.1.1.2.2.2.2.2.cmml">c</mi><mrow id="S3.E1.m1.14.14.3.3" xref="S3.E1.m1.14.14.3.4.cmml"><msub id="S3.E1.m1.13.13.2.2.1" xref="S3.E1.m1.13.13.2.2.1.cmml"><mi id="S3.E1.m1.13.13.2.2.1.2" xref="S3.E1.m1.13.13.2.2.1.2.cmml">q</mi><mn id="S3.E1.m1.13.13.2.2.1.3" xref="S3.E1.m1.13.13.2.2.1.3.cmml">1</mn></msub><mo id="S3.E1.m1.14.14.3.3.3" xref="S3.E1.m1.14.14.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.12.12.1.1" xref="S3.E1.m1.12.12.1.1.cmml">…</mi><mo id="S3.E1.m1.14.14.3.3.4" xref="S3.E1.m1.14.14.3.4.cmml">,</mo><msub id="S3.E1.m1.14.14.3.3.2" xref="S3.E1.m1.14.14.3.3.2.cmml"><mi id="S3.E1.m1.14.14.3.3.2.2" xref="S3.E1.m1.14.14.3.3.2.2.cmml">q</mi><mi id="S3.E1.m1.14.14.3.3.2.3" xref="S3.E1.m1.14.14.3.3.2.3.cmml">N</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.15.15.1.1.2.2.2.1" xref="S3.E1.m1.15.15.1.1.2.2.2.1.cmml">​</mo><mrow id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.3.1" xref="S3.E1.m1.2.2.2.1.cmml">|</mo><msub id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml">q</mi><mn id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml">1</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.2.2.3.2" xref="S3.E1.m1.2.2.2.1.cmml">⟩</mo></mrow></mrow><mo rspace="0.222em" id="S3.E1.m1.15.15.1.1.2.2.1" xref="S3.E1.m1.15.15.1.1.2.2.1.cmml">⊗</mo><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1" xref="S3.E1.m1.3.3.2.1.cmml">|</mo><msub id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">q</mi><mn id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml">2</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.2.1.cmml">⟩</mo></mrow><mo rspace="0.222em" id="S3.E1.m1.15.15.1.1.2.2.1a" xref="S3.E1.m1.15.15.1.1.2.2.1.cmml">⊗</mo><mrow id="S3.E1.m1.4.4.3" xref="S3.E1.m1.4.4.2.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.3.1" xref="S3.E1.m1.4.4.2.1.cmml">|</mo><msub id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml">q</mi><mn id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">3</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.4.4.3.2" xref="S3.E1.m1.4.4.2.1.cmml">⟩</mo></mrow><mo rspace="0.222em" id="S3.E1.m1.15.15.1.1.2.2.1b" xref="S3.E1.m1.15.15.1.1.2.2.1.cmml">⊗</mo><mi mathvariant="normal" id="S3.E1.m1.15.15.1.1.2.2.3" xref="S3.E1.m1.15.15.1.1.2.2.3.cmml">…</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.15.15.1.1.2.2.1c" xref="S3.E1.m1.15.15.1.1.2.2.1.cmml">⊗</mo><mrow id="S3.E1.m1.5.5.3" xref="S3.E1.m1.5.5.2.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.3.1" xref="S3.E1.m1.5.5.2.1.cmml">|</mo><msub id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.1.2.cmml">q</mi><mi id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml">N</mi></msub><mo stretchy="false" id="S3.E1.m1.5.5.3.2" xref="S3.E1.m1.5.5.2.1.cmml">⟩</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.15.15.1.2" xref="S3.E1.m1.15.15.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.15b"><apply id="S3.E1.m1.15.15.1.1.cmml" xref="S3.E1.m1.15.15.1"><eq id="S3.E1.m1.15.15.1.1.1.cmml" xref="S3.E1.m1.15.15.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.3"><csymbol cd="latexml" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.3.1">ket</csymbol><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝜓</ci></apply><apply id="S3.E1.m1.15.15.1.1.2.cmml" xref="S3.E1.m1.15.15.1.1.2"><apply id="S3.E1.m1.15.15.1.1.2.1.cmml" xref="S3.E1.m1.15.15.1.1.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.15.15.1.1.2.1.1.cmml" xref="S3.E1.m1.15.15.1.1.2.1">subscript</csymbol><sum id="S3.E1.m1.15.15.1.1.2.1.2.cmml" xref="S3.E1.m1.15.15.1.1.2.1.2"></sum><apply id="S3.E1.m1.11.11.6.cmml" xref="S3.E1.m1.11.11.6"><in id="S3.E1.m1.11.11.6.7.cmml" xref="S3.E1.m1.11.11.6.7"></in><vector id="S3.E1.m1.11.11.6.6.4.cmml" xref="S3.E1.m1.11.11.6.6.3"><apply id="S3.E1.m1.9.9.4.4.1.1.cmml" xref="S3.E1.m1.9.9.4.4.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.4.4.1.1.1.cmml" xref="S3.E1.m1.9.9.4.4.1.1">subscript</csymbol><ci id="S3.E1.m1.9.9.4.4.1.1.2.cmml" xref="S3.E1.m1.9.9.4.4.1.1.2">𝑞</ci><cn type="integer" id="S3.E1.m1.9.9.4.4.1.1.3.cmml" xref="S3.E1.m1.9.9.4.4.1.1.3">1</cn></apply><apply id="S3.E1.m1.10.10.5.5.2.2.cmml" xref="S3.E1.m1.10.10.5.5.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.10.10.5.5.2.2.1.cmml" xref="S3.E1.m1.10.10.5.5.2.2">subscript</csymbol><ci id="S3.E1.m1.10.10.5.5.2.2.2.cmml" xref="S3.E1.m1.10.10.5.5.2.2.2">𝑞</ci><cn type="integer" id="S3.E1.m1.10.10.5.5.2.2.3.cmml" xref="S3.E1.m1.10.10.5.5.2.2.3">2</cn></apply><ci id="S3.E1.m1.6.6.1.1.cmml" xref="S3.E1.m1.6.6.1.1">…</ci><apply id="S3.E1.m1.11.11.6.6.3.3.cmml" xref="S3.E1.m1.11.11.6.6.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.11.11.6.6.3.3.1.cmml" xref="S3.E1.m1.11.11.6.6.3.3">subscript</csymbol><ci id="S3.E1.m1.11.11.6.6.3.3.2.cmml" xref="S3.E1.m1.11.11.6.6.3.3.2">𝑞</ci><ci id="S3.E1.m1.11.11.6.6.3.3.3.cmml" xref="S3.E1.m1.11.11.6.6.3.3.3">𝑁</ci></apply></vector><apply id="S3.E1.m1.11.11.6.8.cmml" xref="S3.E1.m1.11.11.6.8"><csymbol cd="ambiguous" id="S3.E1.m1.11.11.6.8.1.cmml" xref="S3.E1.m1.11.11.6.8">superscript</csymbol><set id="S3.E1.m1.11.11.6.8.2.1.cmml" xref="S3.E1.m1.11.11.6.8.2.2"><cn type="integer" id="S3.E1.m1.7.7.2.2.cmml" xref="S3.E1.m1.7.7.2.2">0</cn><cn type="integer" id="S3.E1.m1.8.8.3.3.cmml" xref="S3.E1.m1.8.8.3.3">1</cn></set><ci id="S3.E1.m1.11.11.6.8.3.cmml" xref="S3.E1.m1.11.11.6.8.3">𝑁</ci></apply></apply></apply><apply id="S3.E1.m1.15.15.1.1.2.2.cmml" xref="S3.E1.m1.15.15.1.1.2.2"><csymbol cd="latexml" id="S3.E1.m1.15.15.1.1.2.2.1.cmml" xref="S3.E1.m1.15.15.1.1.2.2.1">tensor-product</csymbol><apply id="S3.E1.m1.15.15.1.1.2.2.2.cmml" xref="S3.E1.m1.15.15.1.1.2.2.2"><times id="S3.E1.m1.15.15.1.1.2.2.2.1.cmml" xref="S3.E1.m1.15.15.1.1.2.2.2.1"></times><apply id="S3.E1.m1.15.15.1.1.2.2.2.2.cmml" xref="S3.E1.m1.15.15.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.15.15.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.15.15.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.15.15.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.15.15.1.1.2.2.2.2.2">𝑐</ci><list id="S3.E1.m1.14.14.3.4.cmml" xref="S3.E1.m1.14.14.3.3"><apply id="S3.E1.m1.13.13.2.2.1.cmml" xref="S3.E1.m1.13.13.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.13.13.2.2.1.1.cmml" xref="S3.E1.m1.13.13.2.2.1">subscript</csymbol><ci id="S3.E1.m1.13.13.2.2.1.2.cmml" xref="S3.E1.m1.13.13.2.2.1.2">𝑞</ci><cn type="integer" id="S3.E1.m1.13.13.2.2.1.3.cmml" xref="S3.E1.m1.13.13.2.2.1.3">1</cn></apply><ci id="S3.E1.m1.12.12.1.1.cmml" xref="S3.E1.m1.12.12.1.1">…</ci><apply id="S3.E1.m1.14.14.3.3.2.cmml" xref="S3.E1.m1.14.14.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.14.14.3.3.2.1.cmml" xref="S3.E1.m1.14.14.3.3.2">subscript</csymbol><ci id="S3.E1.m1.14.14.3.3.2.2.cmml" xref="S3.E1.m1.14.14.3.3.2.2">𝑞</ci><ci id="S3.E1.m1.14.14.3.3.2.3.cmml" xref="S3.E1.m1.14.14.3.3.2.3">𝑁</ci></apply></list></apply><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.3"><csymbol cd="latexml" id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.3.1">ket</csymbol><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2">𝑞</ci><cn type="integer" id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3">1</cn></apply></apply></apply><apply id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.3"><csymbol cd="latexml" id="S3.E1.m1.3.3.2.1.cmml" xref="S3.E1.m1.3.3.3.1">ket</csymbol><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2">𝑞</ci><cn type="integer" id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3">2</cn></apply></apply><apply id="S3.E1.m1.4.4.2.cmml" xref="S3.E1.m1.4.4.3"><csymbol cd="latexml" id="S3.E1.m1.4.4.2.1.cmml" xref="S3.E1.m1.4.4.3.1">ket</csymbol><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2">𝑞</ci><cn type="integer" id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3">3</cn></apply></apply><ci id="S3.E1.m1.15.15.1.1.2.2.3.cmml" xref="S3.E1.m1.15.15.1.1.2.2.3">…</ci><apply id="S3.E1.m1.5.5.2.cmml" xref="S3.E1.m1.5.5.3"><csymbol cd="latexml" id="S3.E1.m1.5.5.2.1.cmml" xref="S3.E1.m1.5.5.3.1">ket</csymbol><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2">𝑞</ci><ci id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3">𝑁</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.15c">\ket{\psi}=\sum_{(q_{1},q_{2},...,q_{N})\in\{0,1\}^{N}}c_{q_{1},...,q_{N}}\ket{q_{1}}\otimes\ket{q_{2}}\otimes\ket{q_{3}}\otimes...\otimes\ket{q_{N}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.6" class="ltx_p">where <math id="S3.SS1.p1.2.m1.3" class="ltx_Math" alttext="c_{q_{1},...,q_{N}}\in\mathbb{C}" display="inline"><semantics id="S3.SS1.p1.2.m1.3a"><mrow id="S3.SS1.p1.2.m1.3.4" xref="S3.SS1.p1.2.m1.3.4.cmml"><msub id="S3.SS1.p1.2.m1.3.4.2" xref="S3.SS1.p1.2.m1.3.4.2.cmml"><mi id="S3.SS1.p1.2.m1.3.4.2.2" xref="S3.SS1.p1.2.m1.3.4.2.2.cmml">c</mi><mrow id="S3.SS1.p1.2.m1.3.3.3.3" xref="S3.SS1.p1.2.m1.3.3.3.4.cmml"><msub id="S3.SS1.p1.2.m1.2.2.2.2.1" xref="S3.SS1.p1.2.m1.2.2.2.2.1.cmml"><mi id="S3.SS1.p1.2.m1.2.2.2.2.1.2" xref="S3.SS1.p1.2.m1.2.2.2.2.1.2.cmml">q</mi><mn id="S3.SS1.p1.2.m1.2.2.2.2.1.3" xref="S3.SS1.p1.2.m1.2.2.2.2.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m1.3.3.3.3.3" xref="S3.SS1.p1.2.m1.3.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m1.1.1.1.1" xref="S3.SS1.p1.2.m1.1.1.1.1.cmml">…</mi><mo id="S3.SS1.p1.2.m1.3.3.3.3.4" xref="S3.SS1.p1.2.m1.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.2.m1.3.3.3.3.2" xref="S3.SS1.p1.2.m1.3.3.3.3.2.cmml"><mi id="S3.SS1.p1.2.m1.3.3.3.3.2.2" xref="S3.SS1.p1.2.m1.3.3.3.3.2.2.cmml">q</mi><mi id="S3.SS1.p1.2.m1.3.3.3.3.2.3" xref="S3.SS1.p1.2.m1.3.3.3.3.2.3.cmml">N</mi></msub></mrow></msub><mo id="S3.SS1.p1.2.m1.3.4.1" xref="S3.SS1.p1.2.m1.3.4.1.cmml">∈</mo><mi id="S3.SS1.p1.2.m1.3.4.3" xref="S3.SS1.p1.2.m1.3.4.3.cmml">ℂ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m1.3b"><apply id="S3.SS1.p1.2.m1.3.4.cmml" xref="S3.SS1.p1.2.m1.3.4"><in id="S3.SS1.p1.2.m1.3.4.1.cmml" xref="S3.SS1.p1.2.m1.3.4.1"></in><apply id="S3.SS1.p1.2.m1.3.4.2.cmml" xref="S3.SS1.p1.2.m1.3.4.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m1.3.4.2.1.cmml" xref="S3.SS1.p1.2.m1.3.4.2">subscript</csymbol><ci id="S3.SS1.p1.2.m1.3.4.2.2.cmml" xref="S3.SS1.p1.2.m1.3.4.2.2">𝑐</ci><list id="S3.SS1.p1.2.m1.3.3.3.4.cmml" xref="S3.SS1.p1.2.m1.3.3.3.3"><apply id="S3.SS1.p1.2.m1.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m1.2.2.2.2.1.1.cmml" xref="S3.SS1.p1.2.m1.2.2.2.2.1">subscript</csymbol><ci id="S3.SS1.p1.2.m1.2.2.2.2.1.2.cmml" xref="S3.SS1.p1.2.m1.2.2.2.2.1.2">𝑞</ci><cn type="integer" id="S3.SS1.p1.2.m1.2.2.2.2.1.3.cmml" xref="S3.SS1.p1.2.m1.2.2.2.2.1.3">1</cn></apply><ci id="S3.SS1.p1.2.m1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m1.1.1.1.1">…</ci><apply id="S3.SS1.p1.2.m1.3.3.3.3.2.cmml" xref="S3.SS1.p1.2.m1.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m1.3.3.3.3.2.1.cmml" xref="S3.SS1.p1.2.m1.3.3.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.2.m1.3.3.3.3.2.2.cmml" xref="S3.SS1.p1.2.m1.3.3.3.3.2.2">𝑞</ci><ci id="S3.SS1.p1.2.m1.3.3.3.3.2.3.cmml" xref="S3.SS1.p1.2.m1.3.3.3.3.2.3">𝑁</ci></apply></list></apply><ci id="S3.SS1.p1.2.m1.3.4.3.cmml" xref="S3.SS1.p1.2.m1.3.4.3">ℂ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m1.3c">c_{q_{1},...,q_{N}}\in\mathbb{C}</annotation></semantics></math> is the <em id="S3.SS1.p1.6.1" class="ltx_emph ltx_font_italic">amplitude</em> of each quantum state and <math id="S3.SS1.p1.3.m2.2" class="ltx_Math" alttext="q_{i}\in\{0,1\}" display="inline"><semantics id="S3.SS1.p1.3.m2.2a"><mrow id="S3.SS1.p1.3.m2.2.3" xref="S3.SS1.p1.3.m2.2.3.cmml"><msub id="S3.SS1.p1.3.m2.2.3.2" xref="S3.SS1.p1.3.m2.2.3.2.cmml"><mi id="S3.SS1.p1.3.m2.2.3.2.2" xref="S3.SS1.p1.3.m2.2.3.2.2.cmml">q</mi><mi id="S3.SS1.p1.3.m2.2.3.2.3" xref="S3.SS1.p1.3.m2.2.3.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.3.m2.2.3.1" xref="S3.SS1.p1.3.m2.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p1.3.m2.2.3.3.2" xref="S3.SS1.p1.3.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.3.m2.2.3.3.2.1" xref="S3.SS1.p1.3.m2.2.3.3.1.cmml">{</mo><mn id="S3.SS1.p1.3.m2.1.1" xref="S3.SS1.p1.3.m2.1.1.cmml">0</mn><mo id="S3.SS1.p1.3.m2.2.3.3.2.2" xref="S3.SS1.p1.3.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p1.3.m2.2.2" xref="S3.SS1.p1.3.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p1.3.m2.2.3.3.2.3" xref="S3.SS1.p1.3.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m2.2b"><apply id="S3.SS1.p1.3.m2.2.3.cmml" xref="S3.SS1.p1.3.m2.2.3"><in id="S3.SS1.p1.3.m2.2.3.1.cmml" xref="S3.SS1.p1.3.m2.2.3.1"></in><apply id="S3.SS1.p1.3.m2.2.3.2.cmml" xref="S3.SS1.p1.3.m2.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m2.2.3.2.1.cmml" xref="S3.SS1.p1.3.m2.2.3.2">subscript</csymbol><ci id="S3.SS1.p1.3.m2.2.3.2.2.cmml" xref="S3.SS1.p1.3.m2.2.3.2.2">𝑞</ci><ci id="S3.SS1.p1.3.m2.2.3.2.3.cmml" xref="S3.SS1.p1.3.m2.2.3.2.3">𝑖</ci></apply><set id="S3.SS1.p1.3.m2.2.3.3.1.cmml" xref="S3.SS1.p1.3.m2.2.3.3.2"><cn type="integer" id="S3.SS1.p1.3.m2.1.1.cmml" xref="S3.SS1.p1.3.m2.1.1">0</cn><cn type="integer" id="S3.SS1.p1.3.m2.2.2.cmml" xref="S3.SS1.p1.3.m2.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m2.2c">q_{i}\in\{0,1\}</annotation></semantics></math>.
The square of the amplitude <math id="S3.SS1.p1.4.m3.3" class="ltx_Math" alttext="c_{q_{1},...,q_{N}}" display="inline"><semantics id="S3.SS1.p1.4.m3.3a"><msub id="S3.SS1.p1.4.m3.3.4" xref="S3.SS1.p1.4.m3.3.4.cmml"><mi id="S3.SS1.p1.4.m3.3.4.2" xref="S3.SS1.p1.4.m3.3.4.2.cmml">c</mi><mrow id="S3.SS1.p1.4.m3.3.3.3.3" xref="S3.SS1.p1.4.m3.3.3.3.4.cmml"><msub id="S3.SS1.p1.4.m3.2.2.2.2.1" xref="S3.SS1.p1.4.m3.2.2.2.2.1.cmml"><mi id="S3.SS1.p1.4.m3.2.2.2.2.1.2" xref="S3.SS1.p1.4.m3.2.2.2.2.1.2.cmml">q</mi><mn id="S3.SS1.p1.4.m3.2.2.2.2.1.3" xref="S3.SS1.p1.4.m3.2.2.2.2.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.4.m3.3.3.3.3.3" xref="S3.SS1.p1.4.m3.3.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.4.m3.1.1.1.1" xref="S3.SS1.p1.4.m3.1.1.1.1.cmml">…</mi><mo id="S3.SS1.p1.4.m3.3.3.3.3.4" xref="S3.SS1.p1.4.m3.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.4.m3.3.3.3.3.2" xref="S3.SS1.p1.4.m3.3.3.3.3.2.cmml"><mi id="S3.SS1.p1.4.m3.3.3.3.3.2.2" xref="S3.SS1.p1.4.m3.3.3.3.3.2.2.cmml">q</mi><mi id="S3.SS1.p1.4.m3.3.3.3.3.2.3" xref="S3.SS1.p1.4.m3.3.3.3.3.2.3.cmml">N</mi></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m3.3b"><apply id="S3.SS1.p1.4.m3.3.4.cmml" xref="S3.SS1.p1.4.m3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m3.3.4.1.cmml" xref="S3.SS1.p1.4.m3.3.4">subscript</csymbol><ci id="S3.SS1.p1.4.m3.3.4.2.cmml" xref="S3.SS1.p1.4.m3.3.4.2">𝑐</ci><list id="S3.SS1.p1.4.m3.3.3.3.4.cmml" xref="S3.SS1.p1.4.m3.3.3.3.3"><apply id="S3.SS1.p1.4.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.4.m3.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m3.2.2.2.2.1.1.cmml" xref="S3.SS1.p1.4.m3.2.2.2.2.1">subscript</csymbol><ci id="S3.SS1.p1.4.m3.2.2.2.2.1.2.cmml" xref="S3.SS1.p1.4.m3.2.2.2.2.1.2">𝑞</ci><cn type="integer" id="S3.SS1.p1.4.m3.2.2.2.2.1.3.cmml" xref="S3.SS1.p1.4.m3.2.2.2.2.1.3">1</cn></apply><ci id="S3.SS1.p1.4.m3.1.1.1.1.cmml" xref="S3.SS1.p1.4.m3.1.1.1.1">…</ci><apply id="S3.SS1.p1.4.m3.3.3.3.3.2.cmml" xref="S3.SS1.p1.4.m3.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m3.3.3.3.3.2.1.cmml" xref="S3.SS1.p1.4.m3.3.3.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.4.m3.3.3.3.3.2.2.cmml" xref="S3.SS1.p1.4.m3.3.3.3.3.2.2">𝑞</ci><ci id="S3.SS1.p1.4.m3.3.3.3.3.2.3.cmml" xref="S3.SS1.p1.4.m3.3.3.3.3.2.3">𝑁</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m3.3c">c_{q_{1},...,q_{N}}</annotation></semantics></math> is the <em id="S3.SS1.p1.6.2" class="ltx_emph ltx_font_italic">probability</em> of measurement with the post-measurement state in <math id="S3.SS1.p1.5.m4.4" class="ltx_Math" alttext="\ket{q_{1}}\otimes\ket{q_{2}}\otimes\ket{q_{3}}\otimes...\otimes\ket{q_{N}}" display="inline"><semantics id="S3.SS1.p1.5.m4.4a"><mrow id="S3.SS1.p1.5.m4.4.5" xref="S3.SS1.p1.5.m4.4.5.cmml"><mrow id="S3.SS1.p1.5.m4.1.1.3" xref="S3.SS1.p1.5.m4.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m4.1.1.3.1" xref="S3.SS1.p1.5.m4.1.1.2.1.cmml">|</mo><msub id="S3.SS1.p1.5.m4.1.1.1.1" xref="S3.SS1.p1.5.m4.1.1.1.1.cmml"><mi id="S3.SS1.p1.5.m4.1.1.1.1.2" xref="S3.SS1.p1.5.m4.1.1.1.1.2.cmml">q</mi><mn id="S3.SS1.p1.5.m4.1.1.1.1.3" xref="S3.SS1.p1.5.m4.1.1.1.1.3.cmml">1</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.SS1.p1.5.m4.1.1.3.2" xref="S3.SS1.p1.5.m4.1.1.2.1.cmml">⟩</mo></mrow><mo rspace="0.222em" id="S3.SS1.p1.5.m4.4.5.1" xref="S3.SS1.p1.5.m4.4.5.1.cmml">⊗</mo><mrow id="S3.SS1.p1.5.m4.2.2.3" xref="S3.SS1.p1.5.m4.2.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m4.2.2.3.1" xref="S3.SS1.p1.5.m4.2.2.2.1.cmml">|</mo><msub id="S3.SS1.p1.5.m4.2.2.1.1" xref="S3.SS1.p1.5.m4.2.2.1.1.cmml"><mi id="S3.SS1.p1.5.m4.2.2.1.1.2" xref="S3.SS1.p1.5.m4.2.2.1.1.2.cmml">q</mi><mn id="S3.SS1.p1.5.m4.2.2.1.1.3" xref="S3.SS1.p1.5.m4.2.2.1.1.3.cmml">2</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.SS1.p1.5.m4.2.2.3.2" xref="S3.SS1.p1.5.m4.2.2.2.1.cmml">⟩</mo></mrow><mo rspace="0.222em" id="S3.SS1.p1.5.m4.4.5.1a" xref="S3.SS1.p1.5.m4.4.5.1.cmml">⊗</mo><mrow id="S3.SS1.p1.5.m4.3.3.3" xref="S3.SS1.p1.5.m4.3.3.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m4.3.3.3.1" xref="S3.SS1.p1.5.m4.3.3.2.1.cmml">|</mo><msub id="S3.SS1.p1.5.m4.3.3.1.1" xref="S3.SS1.p1.5.m4.3.3.1.1.cmml"><mi id="S3.SS1.p1.5.m4.3.3.1.1.2" xref="S3.SS1.p1.5.m4.3.3.1.1.2.cmml">q</mi><mn id="S3.SS1.p1.5.m4.3.3.1.1.3" xref="S3.SS1.p1.5.m4.3.3.1.1.3.cmml">3</mn></msub><mo rspace="0.055em" stretchy="false" id="S3.SS1.p1.5.m4.3.3.3.2" xref="S3.SS1.p1.5.m4.3.3.2.1.cmml">⟩</mo></mrow><mo rspace="0.222em" id="S3.SS1.p1.5.m4.4.5.1b" xref="S3.SS1.p1.5.m4.4.5.1.cmml">⊗</mo><mi mathvariant="normal" id="S3.SS1.p1.5.m4.4.5.2" xref="S3.SS1.p1.5.m4.4.5.2.cmml">…</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.5.m4.4.5.1c" xref="S3.SS1.p1.5.m4.4.5.1.cmml">⊗</mo><mrow id="S3.SS1.p1.5.m4.4.4.3" xref="S3.SS1.p1.5.m4.4.4.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m4.4.4.3.1" xref="S3.SS1.p1.5.m4.4.4.2.1.cmml">|</mo><msub id="S3.SS1.p1.5.m4.4.4.1.1" xref="S3.SS1.p1.5.m4.4.4.1.1.cmml"><mi id="S3.SS1.p1.5.m4.4.4.1.1.2" xref="S3.SS1.p1.5.m4.4.4.1.1.2.cmml">q</mi><mi id="S3.SS1.p1.5.m4.4.4.1.1.3" xref="S3.SS1.p1.5.m4.4.4.1.1.3.cmml">N</mi></msub><mo stretchy="false" id="S3.SS1.p1.5.m4.4.4.3.2" xref="S3.SS1.p1.5.m4.4.4.2.1.cmml">⟩</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m4.4b"><apply id="S3.SS1.p1.5.m4.4.5.cmml" xref="S3.SS1.p1.5.m4.4.5"><csymbol cd="latexml" id="S3.SS1.p1.5.m4.4.5.1.cmml" xref="S3.SS1.p1.5.m4.4.5.1">tensor-product</csymbol><apply id="S3.SS1.p1.5.m4.1.1.2.cmml" xref="S3.SS1.p1.5.m4.1.1.3"><csymbol cd="latexml" id="S3.SS1.p1.5.m4.1.1.2.1.cmml" xref="S3.SS1.p1.5.m4.1.1.3.1">ket</csymbol><apply id="S3.SS1.p1.5.m4.1.1.1.1.cmml" xref="S3.SS1.p1.5.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m4.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m4.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m4.1.1.1.1.2">𝑞</ci><cn type="integer" id="S3.SS1.p1.5.m4.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m4.1.1.1.1.3">1</cn></apply></apply><apply id="S3.SS1.p1.5.m4.2.2.2.cmml" xref="S3.SS1.p1.5.m4.2.2.3"><csymbol cd="latexml" id="S3.SS1.p1.5.m4.2.2.2.1.cmml" xref="S3.SS1.p1.5.m4.2.2.3.1">ket</csymbol><apply id="S3.SS1.p1.5.m4.2.2.1.1.cmml" xref="S3.SS1.p1.5.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m4.2.2.1.1.1.cmml" xref="S3.SS1.p1.5.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m4.2.2.1.1.2.cmml" xref="S3.SS1.p1.5.m4.2.2.1.1.2">𝑞</ci><cn type="integer" id="S3.SS1.p1.5.m4.2.2.1.1.3.cmml" xref="S3.SS1.p1.5.m4.2.2.1.1.3">2</cn></apply></apply><apply id="S3.SS1.p1.5.m4.3.3.2.cmml" xref="S3.SS1.p1.5.m4.3.3.3"><csymbol cd="latexml" id="S3.SS1.p1.5.m4.3.3.2.1.cmml" xref="S3.SS1.p1.5.m4.3.3.3.1">ket</csymbol><apply id="S3.SS1.p1.5.m4.3.3.1.1.cmml" xref="S3.SS1.p1.5.m4.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m4.3.3.1.1.1.cmml" xref="S3.SS1.p1.5.m4.3.3.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m4.3.3.1.1.2.cmml" xref="S3.SS1.p1.5.m4.3.3.1.1.2">𝑞</ci><cn type="integer" id="S3.SS1.p1.5.m4.3.3.1.1.3.cmml" xref="S3.SS1.p1.5.m4.3.3.1.1.3">3</cn></apply></apply><ci id="S3.SS1.p1.5.m4.4.5.2.cmml" xref="S3.SS1.p1.5.m4.4.5.2">…</ci><apply id="S3.SS1.p1.5.m4.4.4.2.cmml" xref="S3.SS1.p1.5.m4.4.4.3"><csymbol cd="latexml" id="S3.SS1.p1.5.m4.4.4.2.1.cmml" xref="S3.SS1.p1.5.m4.4.4.3.1">ket</csymbol><apply id="S3.SS1.p1.5.m4.4.4.1.1.cmml" xref="S3.SS1.p1.5.m4.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m4.4.4.1.1.1.cmml" xref="S3.SS1.p1.5.m4.4.4.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m4.4.4.1.1.2.cmml" xref="S3.SS1.p1.5.m4.4.4.1.1.2">𝑞</ci><ci id="S3.SS1.p1.5.m4.4.4.1.1.3.cmml" xref="S3.SS1.p1.5.m4.4.4.1.1.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m4.4c">\ket{q_{1}}\otimes\ket{q_{2}}\otimes\ket{q_{3}}\otimes...\otimes\ket{q_{N}}</annotation></semantics></math>, and the total probability should sum to <math id="S3.SS1.p1.6.m5.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS1.p1.6.m5.1a"><mn id="S3.SS1.p1.6.m5.1.1" xref="S3.SS1.p1.6.m5.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m5.1b"><cn type="integer" id="S3.SS1.p1.6.m5.1.1.cmml" xref="S3.SS1.p1.6.m5.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m5.1c">1</annotation></semantics></math>, i.e.,</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.10" class="ltx_Math" alttext="\sum_{(q_{1},q_{2},...,q_{N})\in\{0,1\}^{N}}||c_{q_{1},...,q_{N}}||^{2}=1." display="block"><semantics id="S3.E2.m1.10a"><mrow id="S3.E2.m1.10.10.1" xref="S3.E2.m1.10.10.1.1.cmml"><mrow id="S3.E2.m1.10.10.1.1" xref="S3.E2.m1.10.10.1.1.cmml"><mrow id="S3.E2.m1.10.10.1.1.1" xref="S3.E2.m1.10.10.1.1.1.cmml"><munder id="S3.E2.m1.10.10.1.1.1.2" xref="S3.E2.m1.10.10.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E2.m1.10.10.1.1.1.2.2" xref="S3.E2.m1.10.10.1.1.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.6.6.6" xref="S3.E2.m1.6.6.6.cmml"><mrow id="S3.E2.m1.6.6.6.6.3" xref="S3.E2.m1.6.6.6.6.4.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.6.6.3.4" xref="S3.E2.m1.6.6.6.6.4.cmml">(</mo><msub id="S3.E2.m1.4.4.4.4.1.1" xref="S3.E2.m1.4.4.4.4.1.1.cmml"><mi id="S3.E2.m1.4.4.4.4.1.1.2" xref="S3.E2.m1.4.4.4.4.1.1.2.cmml">q</mi><mn id="S3.E2.m1.4.4.4.4.1.1.3" xref="S3.E2.m1.4.4.4.4.1.1.3.cmml">1</mn></msub><mo id="S3.E2.m1.6.6.6.6.3.5" xref="S3.E2.m1.6.6.6.6.4.cmml">,</mo><msub id="S3.E2.m1.5.5.5.5.2.2" xref="S3.E2.m1.5.5.5.5.2.2.cmml"><mi id="S3.E2.m1.5.5.5.5.2.2.2" xref="S3.E2.m1.5.5.5.5.2.2.2.cmml">q</mi><mn id="S3.E2.m1.5.5.5.5.2.2.3" xref="S3.E2.m1.5.5.5.5.2.2.3.cmml">2</mn></msub><mo id="S3.E2.m1.6.6.6.6.3.6" xref="S3.E2.m1.6.6.6.6.4.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">…</mi><mo id="S3.E2.m1.6.6.6.6.3.7" xref="S3.E2.m1.6.6.6.6.4.cmml">,</mo><msub id="S3.E2.m1.6.6.6.6.3.3" xref="S3.E2.m1.6.6.6.6.3.3.cmml"><mi id="S3.E2.m1.6.6.6.6.3.3.2" xref="S3.E2.m1.6.6.6.6.3.3.2.cmml">q</mi><mi id="S3.E2.m1.6.6.6.6.3.3.3" xref="S3.E2.m1.6.6.6.6.3.3.3.cmml">N</mi></msub><mo stretchy="false" id="S3.E2.m1.6.6.6.6.3.8" xref="S3.E2.m1.6.6.6.6.4.cmml">)</mo></mrow><mo id="S3.E2.m1.6.6.6.7" xref="S3.E2.m1.6.6.6.7.cmml">∈</mo><msup id="S3.E2.m1.6.6.6.8" xref="S3.E2.m1.6.6.6.8.cmml"><mrow id="S3.E2.m1.6.6.6.8.2.2" xref="S3.E2.m1.6.6.6.8.2.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.6.8.2.2.1" xref="S3.E2.m1.6.6.6.8.2.1.cmml">{</mo><mn id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">0</mn><mo id="S3.E2.m1.6.6.6.8.2.2.2" xref="S3.E2.m1.6.6.6.8.2.1.cmml">,</mo><mn id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.3.cmml">1</mn><mo stretchy="false" id="S3.E2.m1.6.6.6.8.2.2.3" xref="S3.E2.m1.6.6.6.8.2.1.cmml">}</mo></mrow><mi id="S3.E2.m1.6.6.6.8.3" xref="S3.E2.m1.6.6.6.8.3.cmml">N</mi></msup></mrow></munder><msup id="S3.E2.m1.10.10.1.1.1.1" xref="S3.E2.m1.10.10.1.1.1.1.cmml"><mrow id="S3.E2.m1.10.10.1.1.1.1.1.1" xref="S3.E2.m1.10.10.1.1.1.1.1.2.cmml"><mo lspace="0em" stretchy="false" id="S3.E2.m1.10.10.1.1.1.1.1.1.2" xref="S3.E2.m1.10.10.1.1.1.1.1.2.1.cmml">‖</mo><msub id="S3.E2.m1.10.10.1.1.1.1.1.1.1" xref="S3.E2.m1.10.10.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.10.10.1.1.1.1.1.1.1.2" xref="S3.E2.m1.10.10.1.1.1.1.1.1.1.2.cmml">c</mi><mrow id="S3.E2.m1.9.9.3.3" xref="S3.E2.m1.9.9.3.4.cmml"><msub id="S3.E2.m1.8.8.2.2.1" xref="S3.E2.m1.8.8.2.2.1.cmml"><mi id="S3.E2.m1.8.8.2.2.1.2" xref="S3.E2.m1.8.8.2.2.1.2.cmml">q</mi><mn id="S3.E2.m1.8.8.2.2.1.3" xref="S3.E2.m1.8.8.2.2.1.3.cmml">1</mn></msub><mo id="S3.E2.m1.9.9.3.3.3" xref="S3.E2.m1.9.9.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml">…</mi><mo id="S3.E2.m1.9.9.3.3.4" xref="S3.E2.m1.9.9.3.4.cmml">,</mo><msub id="S3.E2.m1.9.9.3.3.2" xref="S3.E2.m1.9.9.3.3.2.cmml"><mi id="S3.E2.m1.9.9.3.3.2.2" xref="S3.E2.m1.9.9.3.3.2.2.cmml">q</mi><mi id="S3.E2.m1.9.9.3.3.2.3" xref="S3.E2.m1.9.9.3.3.2.3.cmml">N</mi></msub></mrow></msub><mo stretchy="false" id="S3.E2.m1.10.10.1.1.1.1.1.1.3" xref="S3.E2.m1.10.10.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E2.m1.10.10.1.1.1.1.3" xref="S3.E2.m1.10.10.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.E2.m1.10.10.1.1.2" xref="S3.E2.m1.10.10.1.1.2.cmml">=</mo><mn id="S3.E2.m1.10.10.1.1.3" xref="S3.E2.m1.10.10.1.1.3.cmml">1</mn></mrow><mo lspace="0em" id="S3.E2.m1.10.10.1.2" xref="S3.E2.m1.10.10.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.10b"><apply id="S3.E2.m1.10.10.1.1.cmml" xref="S3.E2.m1.10.10.1"><eq id="S3.E2.m1.10.10.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.2"></eq><apply id="S3.E2.m1.10.10.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1"><apply id="S3.E2.m1.10.10.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.1.1.2.1.cmml" xref="S3.E2.m1.10.10.1.1.1.2">subscript</csymbol><sum id="S3.E2.m1.10.10.1.1.1.2.2.cmml" xref="S3.E2.m1.10.10.1.1.1.2.2"></sum><apply id="S3.E2.m1.6.6.6.cmml" xref="S3.E2.m1.6.6.6"><in id="S3.E2.m1.6.6.6.7.cmml" xref="S3.E2.m1.6.6.6.7"></in><vector id="S3.E2.m1.6.6.6.6.4.cmml" xref="S3.E2.m1.6.6.6.6.3"><apply id="S3.E2.m1.4.4.4.4.1.1.cmml" xref="S3.E2.m1.4.4.4.4.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.4.4.1.1.1.cmml" xref="S3.E2.m1.4.4.4.4.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.4.4.1.1.2">𝑞</ci><cn type="integer" id="S3.E2.m1.4.4.4.4.1.1.3.cmml" xref="S3.E2.m1.4.4.4.4.1.1.3">1</cn></apply><apply id="S3.E2.m1.5.5.5.5.2.2.cmml" xref="S3.E2.m1.5.5.5.5.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.5.5.2.2.1.cmml" xref="S3.E2.m1.5.5.5.5.2.2">subscript</csymbol><ci id="S3.E2.m1.5.5.5.5.2.2.2.cmml" xref="S3.E2.m1.5.5.5.5.2.2.2">𝑞</ci><cn type="integer" id="S3.E2.m1.5.5.5.5.2.2.3.cmml" xref="S3.E2.m1.5.5.5.5.2.2.3">2</cn></apply><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">…</ci><apply id="S3.E2.m1.6.6.6.6.3.3.cmml" xref="S3.E2.m1.6.6.6.6.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.6.3.3.1.cmml" xref="S3.E2.m1.6.6.6.6.3.3">subscript</csymbol><ci id="S3.E2.m1.6.6.6.6.3.3.2.cmml" xref="S3.E2.m1.6.6.6.6.3.3.2">𝑞</ci><ci id="S3.E2.m1.6.6.6.6.3.3.3.cmml" xref="S3.E2.m1.6.6.6.6.3.3.3">𝑁</ci></apply></vector><apply id="S3.E2.m1.6.6.6.8.cmml" xref="S3.E2.m1.6.6.6.8"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.8.1.cmml" xref="S3.E2.m1.6.6.6.8">superscript</csymbol><set id="S3.E2.m1.6.6.6.8.2.1.cmml" xref="S3.E2.m1.6.6.6.8.2.2"><cn type="integer" id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">0</cn><cn type="integer" id="S3.E2.m1.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3">1</cn></set><ci id="S3.E2.m1.6.6.6.8.3.cmml" xref="S3.E2.m1.6.6.6.8.3">𝑁</ci></apply></apply></apply><apply id="S3.E2.m1.10.10.1.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.10.10.1.1.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.10.10.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.10.10.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.10.10.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.1.2">𝑐</ci><list id="S3.E2.m1.9.9.3.4.cmml" xref="S3.E2.m1.9.9.3.3"><apply id="S3.E2.m1.8.8.2.2.1.cmml" xref="S3.E2.m1.8.8.2.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.2.2.1.1.cmml" xref="S3.E2.m1.8.8.2.2.1">subscript</csymbol><ci id="S3.E2.m1.8.8.2.2.1.2.cmml" xref="S3.E2.m1.8.8.2.2.1.2">𝑞</ci><cn type="integer" id="S3.E2.m1.8.8.2.2.1.3.cmml" xref="S3.E2.m1.8.8.2.2.1.3">1</cn></apply><ci id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1.1">…</ci><apply id="S3.E2.m1.9.9.3.3.2.cmml" xref="S3.E2.m1.9.9.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.3.3.2.1.cmml" xref="S3.E2.m1.9.9.3.3.2">subscript</csymbol><ci id="S3.E2.m1.9.9.3.3.2.2.cmml" xref="S3.E2.m1.9.9.3.3.2.2">𝑞</ci><ci id="S3.E2.m1.9.9.3.3.2.3.cmml" xref="S3.E2.m1.9.9.3.3.2.3">𝑁</ci></apply></list></apply></apply><cn type="integer" id="S3.E2.m1.10.10.1.1.1.1.3.cmml" xref="S3.E2.m1.10.10.1.1.1.1.3">2</cn></apply></apply><cn type="integer" id="S3.E2.m1.10.10.1.1.3.cmml" xref="S3.E2.m1.10.10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.10c">\sum_{(q_{1},q_{2},...,q_{N})\in\{0,1\}^{N}}||c_{q_{1},...,q_{N}}||^{2}=1.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.10" class="ltx_p">In this work, we use use the <em id="S3.SS1.p1.10.1" class="ltx_emph ltx_font_italic">variational encoding</em> scheme to encode the classical values into a quantum state. The basic idea behind this encoding scheme is to use the input values or their transformation as rotation angles for the quantum rotation gate. As shown in Figure <a href="#S3.F3" title="Figure 3 ‣ III Variational Quantum Circuits ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the encoding parts consist of single-qubit rotation gates <math id="S3.SS1.p1.7.m1.1" class="ltx_Math" alttext="R_{y}" display="inline"><semantics id="S3.SS1.p1.7.m1.1a"><msub id="S3.SS1.p1.7.m1.1.1" xref="S3.SS1.p1.7.m1.1.1.cmml"><mi id="S3.SS1.p1.7.m1.1.1.2" xref="S3.SS1.p1.7.m1.1.1.2.cmml">R</mi><mi id="S3.SS1.p1.7.m1.1.1.3" xref="S3.SS1.p1.7.m1.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m1.1b"><apply id="S3.SS1.p1.7.m1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m1.1.1.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2">𝑅</ci><ci id="S3.SS1.p1.7.m1.1.1.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m1.1c">R_{y}</annotation></semantics></math> and <math id="S3.SS1.p1.8.m2.1" class="ltx_Math" alttext="R_{z}" display="inline"><semantics id="S3.SS1.p1.8.m2.1a"><msub id="S3.SS1.p1.8.m2.1.1" xref="S3.SS1.p1.8.m2.1.1.cmml"><mi id="S3.SS1.p1.8.m2.1.1.2" xref="S3.SS1.p1.8.m2.1.1.2.cmml">R</mi><mi id="S3.SS1.p1.8.m2.1.1.3" xref="S3.SS1.p1.8.m2.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m2.1b"><apply id="S3.SS1.p1.8.m2.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m2.1.1.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2">𝑅</ci><ci id="S3.SS1.p1.8.m2.1.1.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m2.1c">R_{z}</annotation></semantics></math> and use <math id="S3.SS1.p1.9.m3.2" class="ltx_Math" alttext="\arctan(x_{i})" display="inline"><semantics id="S3.SS1.p1.9.m3.2a"><mrow id="S3.SS1.p1.9.m3.2.2.1" xref="S3.SS1.p1.9.m3.2.2.2.cmml"><mi id="S3.SS1.p1.9.m3.1.1" xref="S3.SS1.p1.9.m3.1.1.cmml">arctan</mi><mo id="S3.SS1.p1.9.m3.2.2.1a" xref="S3.SS1.p1.9.m3.2.2.2.cmml">⁡</mo><mrow id="S3.SS1.p1.9.m3.2.2.1.1" xref="S3.SS1.p1.9.m3.2.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.9.m3.2.2.1.1.2" xref="S3.SS1.p1.9.m3.2.2.2.cmml">(</mo><msub id="S3.SS1.p1.9.m3.2.2.1.1.1" xref="S3.SS1.p1.9.m3.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.9.m3.2.2.1.1.1.2" xref="S3.SS1.p1.9.m3.2.2.1.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.9.m3.2.2.1.1.1.3" xref="S3.SS1.p1.9.m3.2.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p1.9.m3.2.2.1.1.3" xref="S3.SS1.p1.9.m3.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m3.2b"><apply id="S3.SS1.p1.9.m3.2.2.2.cmml" xref="S3.SS1.p1.9.m3.2.2.1"><arctan id="S3.SS1.p1.9.m3.1.1.cmml" xref="S3.SS1.p1.9.m3.1.1"></arctan><apply id="S3.SS1.p1.9.m3.2.2.1.1.1.cmml" xref="S3.SS1.p1.9.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.9.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.9.m3.2.2.1.1.1.2">𝑥</ci><ci id="S3.SS1.p1.9.m3.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.9.m3.2.2.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m3.2c">\arctan(x_{i})</annotation></semantics></math> and <math id="S3.SS1.p1.10.m4.2" class="ltx_Math" alttext="\arctan(x_{i}^{2})" display="inline"><semantics id="S3.SS1.p1.10.m4.2a"><mrow id="S3.SS1.p1.10.m4.2.2.1" xref="S3.SS1.p1.10.m4.2.2.2.cmml"><mi id="S3.SS1.p1.10.m4.1.1" xref="S3.SS1.p1.10.m4.1.1.cmml">arctan</mi><mo id="S3.SS1.p1.10.m4.2.2.1a" xref="S3.SS1.p1.10.m4.2.2.2.cmml">⁡</mo><mrow id="S3.SS1.p1.10.m4.2.2.1.1" xref="S3.SS1.p1.10.m4.2.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.10.m4.2.2.1.1.2" xref="S3.SS1.p1.10.m4.2.2.2.cmml">(</mo><msubsup id="S3.SS1.p1.10.m4.2.2.1.1.1" xref="S3.SS1.p1.10.m4.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.10.m4.2.2.1.1.1.2.2" xref="S3.SS1.p1.10.m4.2.2.1.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p1.10.m4.2.2.1.1.1.2.3" xref="S3.SS1.p1.10.m4.2.2.1.1.1.2.3.cmml">i</mi><mn id="S3.SS1.p1.10.m4.2.2.1.1.1.3" xref="S3.SS1.p1.10.m4.2.2.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S3.SS1.p1.10.m4.2.2.1.1.3" xref="S3.SS1.p1.10.m4.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m4.2b"><apply id="S3.SS1.p1.10.m4.2.2.2.cmml" xref="S3.SS1.p1.10.m4.2.2.1"><arctan id="S3.SS1.p1.10.m4.1.1.cmml" xref="S3.SS1.p1.10.m4.1.1"></arctan><apply id="S3.SS1.p1.10.m4.2.2.1.1.1.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m4.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.10.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m4.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m4.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1.2.2">𝑥</ci><ci id="S3.SS1.p1.10.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS1.p1.10.m4.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.10.m4.2.2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m4.2c">\arctan(x_{i}^{2})</annotation></semantics></math> as the corresponding transformations.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">III.2 </span>Quantum Gradients</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The hybrid quantum-classical model can be trained in an end-to-end fashion, following the common backpropagation method used in training deep neural network. When it comes to the gradient calculation on quantum functions, <em id="S3.SS2.p1.1.1" class="ltx_emph ltx_font_italic">parameter-shift</em> method is employed. It can be used to derive the analytical gradient of the quantum circuits. The method is described in the reference <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib72" title="" class="ltx_ref">schuld2019evaluating </a>; <a href="#bib.bib73" title="" class="ltx_ref">bergholm2018pennylane </a></cite>. The idea behind the parameter-shift rule is that given the knowledge of calculating the expectation of certain observable of quantum functions, the quantum gradients can be calculated without the use of finite difference method.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span>Hybrid Quantum-Classical Transfer Learning</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">In the NISQ era, the quantum computers are not error-corrected and thus cannot perform calculations in a fault-tolerant manner. The circuit depth and number of qubits are therefore limited and it is non-trivial to design the model architectures which can potentially harness the capabilities provided by near-term quantum computers.
In this work, we employ the hybrid quantum-classical transfer learning scheme inspired by the work <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref">mari2019transfer </a></cite>. The idea is to use a pre-trained classical deep neural network, mostly convolutional neural networks (CNN) to extract the features from the images and compress the information into a latent vector <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">x</annotation></semantics></math> which is with much smaller dimension than the original image. Then the latent vector <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">x</annotation></semantics></math> is processed by the quantum circuit model to output the logits of each class. The scheme is presented in Figure <a href="#S4.F4" title="Figure 4 ‣ IV Hybrid Quantum-Classical Transfer Learning ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. In this work, we employ the VGG16 <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">simonyan2014very </a></cite> pre-trained model as the feature extractor.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2103.12010/assets/x2.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="103" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S4.F4.2.1" class="ltx_text ltx_font_bold">Hybrid Quantum-Classical Transfer Learning.</span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span>Experiments and Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this study we consider the following setting:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.4" class="ltx_p">Central node <math id="S5.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S5.I1.i1.p1.1.m1.1a"><mi id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><ci id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">C</annotation></semantics></math>: Receive the uploaded circuit parameters <math id="S5.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\theta_{i}" display="inline"><semantics id="S5.I1.i1.p1.2.m2.1a"><msub id="S5.I1.i1.p1.2.m2.1.1" xref="S5.I1.i1.p1.2.m2.1.1.cmml"><mi id="S5.I1.i1.p1.2.m2.1.1.2" xref="S5.I1.i1.p1.2.m2.1.1.2.cmml">θ</mi><mi id="S5.I1.i1.p1.2.m2.1.1.3" xref="S5.I1.i1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.2.m2.1b"><apply id="S5.I1.i1.p1.2.m2.1.1.cmml" xref="S5.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.I1.i1.p1.2.m2.1.1.1.cmml" xref="S5.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.I1.i1.p1.2.m2.1.1.2.cmml" xref="S5.I1.i1.p1.2.m2.1.1.2">𝜃</ci><ci id="S5.I1.i1.p1.2.m2.1.1.3.cmml" xref="S5.I1.i1.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.2.m2.1c">\theta_{i}</annotation></semantics></math> from each local machine <math id="S5.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S5.I1.i1.p1.3.m3.1a"><msub id="S5.I1.i1.p1.3.m3.1.1" xref="S5.I1.i1.p1.3.m3.1.1.cmml"><mi id="S5.I1.i1.p1.3.m3.1.1.2" xref="S5.I1.i1.p1.3.m3.1.1.2.cmml">N</mi><mi id="S5.I1.i1.p1.3.m3.1.1.3" xref="S5.I1.i1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.3.m3.1b"><apply id="S5.I1.i1.p1.3.m3.1.1.cmml" xref="S5.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.I1.i1.p1.3.m3.1.1.1.cmml" xref="S5.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.I1.i1.p1.3.m3.1.1.2.cmml" xref="S5.I1.i1.p1.3.m3.1.1.2">𝑁</ci><ci id="S5.I1.i1.p1.3.m3.1.1.3.cmml" xref="S5.I1.i1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.3.m3.1c">N_{i}</annotation></semantics></math> and aggregate them into a global parameter <math id="S5.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S5.I1.i1.p1.4.m4.1a"><mi mathvariant="normal" id="S5.I1.i1.p1.4.m4.1.1" xref="S5.I1.i1.p1.4.m4.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.4.m4.1b"><ci id="S5.I1.i1.p1.4.m4.1.1.cmml" xref="S5.I1.i1.p1.4.m4.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.4.m4.1c">\Theta</annotation></semantics></math> and distributes to all local machines.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">Training points are equally distributed to the local machines and the testing points are on the central node to evaluate the aggregated global model.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.3" class="ltx_p">Individual local machines <math id="S5.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S5.I1.i3.p1.1.m1.1a"><msub id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml"><mi id="S5.I1.i3.p1.1.m1.1.1.2" xref="S5.I1.i3.p1.1.m1.1.1.2.cmml">N</mi><mi id="S5.I1.i3.p1.1.m1.1.1.3" xref="S5.I1.i3.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b"><apply id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.I1.i3.p1.1.m1.1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.I1.i3.p1.1.m1.1.1.2.cmml" xref="S5.I1.i3.p1.1.m1.1.1.2">𝑁</ci><ci id="S5.I1.i3.p1.1.m1.1.1.3.cmml" xref="S5.I1.i3.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">N_{i}</annotation></semantics></math>: Each has a distinct part of the training data and will perform <math id="S5.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S5.I1.i3.p1.2.m2.1a"><mi id="S5.I1.i3.p1.2.m2.1.1" xref="S5.I1.i3.p1.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.2.m2.1b"><ci id="S5.I1.i3.p1.2.m2.1.1.cmml" xref="S5.I1.i3.p1.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.2.m2.1c">E</annotation></semantics></math> epochs of the training locally with the batch size <math id="S5.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S5.I1.i3.p1.3.m3.1a"><mi id="S5.I1.i3.p1.3.m3.1.1" xref="S5.I1.i3.p1.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.3.m3.1b"><ci id="S5.I1.i3.p1.3.m3.1.1.cmml" xref="S5.I1.i3.p1.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.3.m3.1c">B</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The software we use for this work are PyTorch <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib74" title="" class="ltx_ref">paszke2019pytorch </a></cite>, PennyLane <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib73" title="" class="ltx_ref">bergholm2018pennylane </a></cite> and Qulacs <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib75" title="" class="ltx_ref">suzuki2020qulacs </a></cite>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">V.1 </span>Cats vs Dogs</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.14" class="ltx_p">We perform the binary classification on the classic cats vs dogs dataset <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib76" title="" class="ltx_ref">asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization </a></cite>. Each image in this dataset has slightly different dimensions, therefore we preprocessed to make all of the training and testing samples in the dimension of <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><times id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">224</cn><cn type="integer" id="S5.SS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">224\times 224</annotation></semantics></math>. In Figure <a href="#S5.F5" title="Figure 5 ‣ V.1 Cats vs Dogs ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we show some of the examples from this dataset.
Here, we have in total 23,000 training data and 2,000 testing data. The testing data are on the central node which will be used to evaluate the aggregated model (global model) after each training round. The training data are equally distributed to the <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn type="integer" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">100</annotation></semantics></math> local machines <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><msub id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">N</mi><mi id="S5.SS1.p1.3.m3.1.1.3" xref="S5.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.p1.3.m3.1.1.2">𝑁</ci><ci id="S5.SS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">N_{i}</annotation></semantics></math> where <math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="i\in\{1\cdots 100\}" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mrow id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml"><mi id="S5.SS1.p1.4.m4.1.1.3" xref="S5.SS1.p1.4.m4.1.1.3.cmml">i</mi><mo id="S5.SS1.p1.4.m4.1.1.2" xref="S5.SS1.p1.4.m4.1.1.2.cmml">∈</mo><mrow id="S5.SS1.p1.4.m4.1.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS1.p1.4.m4.1.1.1.1.2" xref="S5.SS1.p1.4.m4.1.1.1.2.cmml">{</mo><mrow id="S5.SS1.p1.4.m4.1.1.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.1.1.cmml"><mn id="S5.SS1.p1.4.m4.1.1.1.1.1.2" xref="S5.SS1.p1.4.m4.1.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S5.SS1.p1.4.m4.1.1.1.1.1.1" xref="S5.SS1.p1.4.m4.1.1.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S5.SS1.p1.4.m4.1.1.1.1.1.3" xref="S5.SS1.p1.4.m4.1.1.1.1.1.3.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p1.4.m4.1.1.1.1.1.1a" xref="S5.SS1.p1.4.m4.1.1.1.1.1.1.cmml">​</mo><mn id="S5.SS1.p1.4.m4.1.1.1.1.1.4" xref="S5.SS1.p1.4.m4.1.1.1.1.1.4.cmml">100</mn></mrow><mo stretchy="false" id="S5.SS1.p1.4.m4.1.1.1.1.3" xref="S5.SS1.p1.4.m4.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><apply id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1"><in id="S5.SS1.p1.4.m4.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.2"></in><ci id="S5.SS1.p1.4.m4.1.1.3.cmml" xref="S5.SS1.p1.4.m4.1.1.3">𝑖</ci><set id="S5.SS1.p1.4.m4.1.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1"><apply id="S5.SS1.p1.4.m4.1.1.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1.1"><times id="S5.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1.1.1"></times><cn type="integer" id="S5.SS1.p1.4.m4.1.1.1.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1.1.2">1</cn><ci id="S5.SS1.p1.4.m4.1.1.1.1.1.3.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1.1.3">⋯</ci><cn type="integer" id="S5.SS1.p1.4.m4.1.1.1.1.1.4.cmml" xref="S5.SS1.p1.4.m4.1.1.1.1.1.4">100</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">i\in\{1\cdots 100\}</annotation></semantics></math>. Therefore in each local machine, there are <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="230" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mn id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml">230</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><cn type="integer" id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">230</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">230</annotation></semantics></math> training points. In each training round, <math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><mn id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><cn type="integer" id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">5</annotation></semantics></math> local machines will be randomly selected and each will perform <math id="S5.SS1.p1.7.m7.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p1.7.m7.1a"><mn id="S5.SS1.p1.7.m7.1.1" xref="S5.SS1.p1.7.m7.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.1b"><cn type="integer" id="S5.SS1.p1.7.m7.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.1c">1</annotation></semantics></math>, <math id="S5.SS1.p1.8.m8.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS1.p1.8.m8.1a"><mn id="S5.SS1.p1.8.m8.1.1" xref="S5.SS1.p1.8.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.8.m8.1b"><cn type="integer" id="S5.SS1.p1.8.m8.1.1.cmml" xref="S5.SS1.p1.8.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.8.m8.1c">2</annotation></semantics></math> or <math id="S5.SS1.p1.9.m9.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p1.9.m9.1a"><mn id="S5.SS1.p1.9.m9.1.1" xref="S5.SS1.p1.9.m9.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.9.m9.1b"><cn type="integer" id="S5.SS1.p1.9.m9.1.1.cmml" xref="S5.SS1.p1.9.m9.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.9.m9.1c">4</annotation></semantics></math> epochs of training with its own training points. The batch size is <math id="S5.SS1.p1.10.m10.1" class="ltx_Math" alttext="S=32" display="inline"><semantics id="S5.SS1.p1.10.m10.1a"><mrow id="S5.SS1.p1.10.m10.1.1" xref="S5.SS1.p1.10.m10.1.1.cmml"><mi id="S5.SS1.p1.10.m10.1.1.2" xref="S5.SS1.p1.10.m10.1.1.2.cmml">S</mi><mo id="S5.SS1.p1.10.m10.1.1.1" xref="S5.SS1.p1.10.m10.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.10.m10.1.1.3" xref="S5.SS1.p1.10.m10.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.10.m10.1b"><apply id="S5.SS1.p1.10.m10.1.1.cmml" xref="S5.SS1.p1.10.m10.1.1"><eq id="S5.SS1.p1.10.m10.1.1.1.cmml" xref="S5.SS1.p1.10.m10.1.1.1"></eq><ci id="S5.SS1.p1.10.m10.1.1.2.cmml" xref="S5.SS1.p1.10.m10.1.1.2">𝑆</ci><cn type="integer" id="S5.SS1.p1.10.m10.1.1.3.cmml" xref="S5.SS1.p1.10.m10.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.10.m10.1c">S=32</annotation></semantics></math>. The trained model will then be sent to the central node for the aggregation. The aggregation method we use in this experiment is the collected model average. The aggregated model (global model) will then be shared to all the local machines.
The hybrid model used in this experiment consists of pre-trained VGG16 model and a <math id="S5.SS1.p1.11.m11.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p1.11.m11.1a"><mn id="S5.SS1.p1.11.m11.1.1" xref="S5.SS1.p1.11.m11.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.11.m11.1b"><cn type="integer" id="S5.SS1.p1.11.m11.1.1.cmml" xref="S5.SS1.p1.11.m11.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.11.m11.1c">4</annotation></semantics></math>-qubit variational quantum circuit (VQC) as shown in Figure <a href="#S3.F3" title="Figure 3 ‣ III Variational Quantum Circuits ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The original classifier layer in the VGG16 model is replaced with the one shown in Table <a href="#S5.T1" title="Table 1 ‣ V.1 Cats vs Dogs ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in order to fit input dimension of the VQC layer. The dashed-box in the quantum circuit repeats twice, consisting of <math id="S5.SS1.p1.12.m12.1" class="ltx_Math" alttext="4\times 3\times 2=24" display="inline"><semantics id="S5.SS1.p1.12.m12.1a"><mrow id="S5.SS1.p1.12.m12.1.1" xref="S5.SS1.p1.12.m12.1.1.cmml"><mrow id="S5.SS1.p1.12.m12.1.1.2" xref="S5.SS1.p1.12.m12.1.1.2.cmml"><mn id="S5.SS1.p1.12.m12.1.1.2.2" xref="S5.SS1.p1.12.m12.1.1.2.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.12.m12.1.1.2.1" xref="S5.SS1.p1.12.m12.1.1.2.1.cmml">×</mo><mn id="S5.SS1.p1.12.m12.1.1.2.3" xref="S5.SS1.p1.12.m12.1.1.2.3.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p1.12.m12.1.1.2.1a" xref="S5.SS1.p1.12.m12.1.1.2.1.cmml">×</mo><mn id="S5.SS1.p1.12.m12.1.1.2.4" xref="S5.SS1.p1.12.m12.1.1.2.4.cmml">2</mn></mrow><mo id="S5.SS1.p1.12.m12.1.1.1" xref="S5.SS1.p1.12.m12.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.12.m12.1.1.3" xref="S5.SS1.p1.12.m12.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.12.m12.1b"><apply id="S5.SS1.p1.12.m12.1.1.cmml" xref="S5.SS1.p1.12.m12.1.1"><eq id="S5.SS1.p1.12.m12.1.1.1.cmml" xref="S5.SS1.p1.12.m12.1.1.1"></eq><apply id="S5.SS1.p1.12.m12.1.1.2.cmml" xref="S5.SS1.p1.12.m12.1.1.2"><times id="S5.SS1.p1.12.m12.1.1.2.1.cmml" xref="S5.SS1.p1.12.m12.1.1.2.1"></times><cn type="integer" id="S5.SS1.p1.12.m12.1.1.2.2.cmml" xref="S5.SS1.p1.12.m12.1.1.2.2">4</cn><cn type="integer" id="S5.SS1.p1.12.m12.1.1.2.3.cmml" xref="S5.SS1.p1.12.m12.1.1.2.3">3</cn><cn type="integer" id="S5.SS1.p1.12.m12.1.1.2.4.cmml" xref="S5.SS1.p1.12.m12.1.1.2.4">2</cn></apply><cn type="integer" id="S5.SS1.p1.12.m12.1.1.3.cmml" xref="S5.SS1.p1.12.m12.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.12.m12.1c">4\times 3\times 2=24</annotation></semantics></math> quantum circuit parameters. The VQC receives <math id="S5.SS1.p1.13.m13.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS1.p1.13.m13.1a"><mn id="S5.SS1.p1.13.m13.1.1" xref="S5.SS1.p1.13.m13.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.13.m13.1b"><cn type="integer" id="S5.SS1.p1.13.m13.1.1.cmml" xref="S5.SS1.p1.13.m13.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.13.m13.1c">4</annotation></semantics></math>-dimensional compressed vectors from the pre-trained VGG model to perform the classification task.
The non-federated training for the comparison with the same hybrid VGG-VQC architecture as the one used in the federated training.
We perform <math id="S5.SS1.p1.14.m14.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS1.p1.14.m14.1a"><mn id="S5.SS1.p1.14.m14.1.1" xref="S5.SS1.p1.14.m14.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.14.m14.1b"><cn type="integer" id="S5.SS1.p1.14.m14.1.1.cmml" xref="S5.SS1.p1.14.m14.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.14.m14.1c">100</annotation></semantics></math> training rounds and the results are presented in Figure <a href="#S5.F6" title="Figure 6 ‣ V.1 Cats vs Dogs ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We compare the performance of federated learning with non-federated learning with the same hybrid quantum-classical architecture and the same dataset.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.2.2" class="ltx_tr">
<th id="S5.T1.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S5.T1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Linear</th>
<th id="S5.T1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">ReLU</th>
<th id="S5.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Dropout(<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="p=0.5" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mrow id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.m1.1.1.2.cmml">p</mi><mo id="S5.T1.1.1.1.m1.1.1.1" xref="S5.T1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S5.T1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><eq id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1.1"></eq><ci id="S5.T1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.m1.1.1.2">𝑝</ci><cn type="float" id="S5.T1.1.1.1.m1.1.1.3.cmml" xref="S5.T1.1.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">p=0.5</annotation></semantics></math>)</th>
<th id="S5.T1.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Linear</th>
<th id="S5.T1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">ReLU</th>
<th id="S5.T1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Dropout(<math id="S5.T1.2.2.2.m1.1" class="ltx_Math" alttext="p=0.5" display="inline"><semantics id="S5.T1.2.2.2.m1.1a"><mrow id="S5.T1.2.2.2.m1.1.1" xref="S5.T1.2.2.2.m1.1.1.cmml"><mi id="S5.T1.2.2.2.m1.1.1.2" xref="S5.T1.2.2.2.m1.1.1.2.cmml">p</mi><mo id="S5.T1.2.2.2.m1.1.1.1" xref="S5.T1.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S5.T1.2.2.2.m1.1.1.3" xref="S5.T1.2.2.2.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.m1.1b"><apply id="S5.T1.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1"><eq id="S5.T1.2.2.2.m1.1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1.1"></eq><ci id="S5.T1.2.2.2.m1.1.1.2.cmml" xref="S5.T1.2.2.2.m1.1.1.2">𝑝</ci><cn type="float" id="S5.T1.2.2.2.m1.1.1.3.cmml" xref="S5.T1.2.2.2.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.m1.1c">p=0.5</annotation></semantics></math>)</th>
<th id="S5.T1.2.2.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Linear</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.2.3.1" class="ltx_tr">
<th id="S5.T1.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Input</th>
<th id="S5.T1.2.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">25088</th>
<td id="S5.T1.2.3.1.3" class="ltx_td ltx_border_b ltx_border_r ltx_border_t" colspan="2" rowspan="2"></td>
<td id="S5.T1.2.3.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4096</td>
<td id="S5.T1.2.3.1.5" class="ltx_td ltx_border_b ltx_border_r ltx_border_t" colspan="2" rowspan="2"></td>
<td id="S5.T1.2.3.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4096</td>
</tr>
<tr id="S5.T1.2.4.2" class="ltx_tr">
<th id="S5.T1.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Output</th>
<th id="S5.T1.2.4.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">4096</th>
<td id="S5.T1.2.4.2.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">4096</td>
<td id="S5.T1.2.4.2.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The trainable layer in our modified VGG model.</figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.5" class="ltx_p">In the left three panels of Figure <a href="#S5.F6" title="Figure 6 ‣ V.1 Cats vs Dogs ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we present the results of training the hybrid quantum model via federated setting with different number of local training epochs. Since the training data is distributed across different clients, we only consider the testing accuracies with the aggregated global model. In the considered Cats vs Dogs dataset, we observe that both the testing accuracies and testing loss reach the comparable level as the non-federated training. We also observe that the training loss, which is the average from clients, has fluctuations compared to non-federated training (shown in Table <a href="#S5.T2" title="Table 2 ‣ V.1 Cats vs Dogs ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The underlying reason might be that in each training round, different clients are selected, therefore the training data used to evaluate the training loss are different. Yet the training loss still converges after the <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mn id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><cn type="integer" id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">100</annotation></semantics></math> rounds of training.
In addition, the testing loss and accuracies converge to comparable levels to the non-federal training, regardless of the local training epochs. Notably, we observe that a single epoch in local training is pretty enough to train a well-performed model. In each round of the federated training, the model updates are based on the samplings from <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mn id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><cn type="integer" id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">5</annotation></semantics></math> clients, with <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mn id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><cn type="integer" id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">1</annotation></semantics></math> local training epoch. The computing resources used are linear with <math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="230\times 5\times 1=1150" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><mrow id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml"><mrow id="S5.SS1.p2.4.m4.1.1.2" xref="S5.SS1.p2.4.m4.1.1.2.cmml"><mn id="S5.SS1.p2.4.m4.1.1.2.2" xref="S5.SS1.p2.4.m4.1.1.2.2.cmml">230</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p2.4.m4.1.1.2.1" xref="S5.SS1.p2.4.m4.1.1.2.1.cmml">×</mo><mn id="S5.SS1.p2.4.m4.1.1.2.3" xref="S5.SS1.p2.4.m4.1.1.2.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p2.4.m4.1.1.2.1a" xref="S5.SS1.p2.4.m4.1.1.2.1.cmml">×</mo><mn id="S5.SS1.p2.4.m4.1.1.2.4" xref="S5.SS1.p2.4.m4.1.1.2.4.cmml">1</mn></mrow><mo id="S5.SS1.p2.4.m4.1.1.1" xref="S5.SS1.p2.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS1.p2.4.m4.1.1.3" xref="S5.SS1.p2.4.m4.1.1.3.cmml">1150</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><apply id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1"><eq id="S5.SS1.p2.4.m4.1.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1.1"></eq><apply id="S5.SS1.p2.4.m4.1.1.2.cmml" xref="S5.SS1.p2.4.m4.1.1.2"><times id="S5.SS1.p2.4.m4.1.1.2.1.cmml" xref="S5.SS1.p2.4.m4.1.1.2.1"></times><cn type="integer" id="S5.SS1.p2.4.m4.1.1.2.2.cmml" xref="S5.SS1.p2.4.m4.1.1.2.2">230</cn><cn type="integer" id="S5.SS1.p2.4.m4.1.1.2.3.cmml" xref="S5.SS1.p2.4.m4.1.1.2.3">5</cn><cn type="integer" id="S5.SS1.p2.4.m4.1.1.2.4.cmml" xref="S5.SS1.p2.4.m4.1.1.2.4">1</cn></apply><cn type="integer" id="S5.SS1.p2.4.m4.1.1.3.cmml" xref="S5.SS1.p2.4.m4.1.1.3">1150</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">230\times 5\times 1=1150</annotation></semantics></math> in total. While for a full epoch of training with non-federated setting, the computing resources used are linear with <math id="S5.SS1.p2.5.m5.1" class="ltx_Math" alttext="23000" display="inline"><semantics id="S5.SS1.p2.5.m5.1a"><mn id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml">23000</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><cn type="integer" id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">23000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">23000</annotation></semantics></math>. This results imply the potential of more efficient training on QML models with distributed schemes. This particularly benefits the training of quantum models when we are using high-performance simulation platform or an array of small NISQ devices, with the communication overhead is moderate.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2103.12010/assets/x3.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S5.F5.2.1" class="ltx_text ltx_font_bold">Cats vs Dogs Dataset.</span> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib76" title="" class="ltx_ref">asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization </a></cite></figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2103.12010/assets/x4.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="142" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S5.F6.2.1" class="ltx_text ltx_font_bold">Results: Cats vs Dogs.</span></figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.12.13.1" class="ltx_tr">
<th id="S5.T2.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S5.T2.12.13.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Training Loss</th>
<th id="S5.T2.12.13.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Testing Loss</th>
<th id="S5.T2.12.13.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Testing Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.3.3" class="ltx_tr">
<th id="S5.T2.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (1 local epoch)</th>
<td id="S5.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="0.3506" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><mn id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">0.3506</mn><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><cn type="float" id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">0.3506</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">0.3506</annotation></semantics></math></td>
<td id="S5.T2.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.2.2.2.m1.1" class="ltx_Math" alttext="0.3519" display="inline"><semantics id="S5.T2.2.2.2.m1.1a"><mn id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml">0.3519</mn><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><cn type="float" id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">0.3519</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">0.3519</annotation></semantics></math></td>
<td id="S5.T2.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.3.3.3.m1.1" class="ltx_Math" alttext="98.7\%" display="inline"><semantics id="S5.T2.3.3.3.m1.1a"><mrow id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml"><mn id="S5.T2.3.3.3.m1.1.1.2" xref="S5.T2.3.3.3.m1.1.1.2.cmml">98.7</mn><mo id="S5.T2.3.3.3.m1.1.1.1" xref="S5.T2.3.3.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.m1.1.1.2">98.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">98.7\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.6.6" class="ltx_tr">
<th id="S5.T2.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (2 local epochs)</th>
<td id="S5.T2.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.4.4.1.m1.1" class="ltx_Math" alttext="0.3405" display="inline"><semantics id="S5.T2.4.4.1.m1.1a"><mn id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml">0.3405</mn><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><cn type="float" id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">0.3405</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">0.3405</annotation></semantics></math></td>
<td id="S5.T2.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.5.5.2.m1.1" class="ltx_Math" alttext="0.3408" display="inline"><semantics id="S5.T2.5.5.2.m1.1a"><mn id="S5.T2.5.5.2.m1.1.1" xref="S5.T2.5.5.2.m1.1.1.cmml">0.3408</mn><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.2.m1.1b"><cn type="float" id="S5.T2.5.5.2.m1.1.1.cmml" xref="S5.T2.5.5.2.m1.1.1">0.3408</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.2.m1.1c">0.3408</annotation></semantics></math></td>
<td id="S5.T2.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.6.6.3.m1.1" class="ltx_Math" alttext="98.6\%" display="inline"><semantics id="S5.T2.6.6.3.m1.1a"><mrow id="S5.T2.6.6.3.m1.1.1" xref="S5.T2.6.6.3.m1.1.1.cmml"><mn id="S5.T2.6.6.3.m1.1.1.2" xref="S5.T2.6.6.3.m1.1.1.2.cmml">98.6</mn><mo id="S5.T2.6.6.3.m1.1.1.1" xref="S5.T2.6.6.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.3.m1.1b"><apply id="S5.T2.6.6.3.m1.1.1.cmml" xref="S5.T2.6.6.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.6.6.3.m1.1.1.1.cmml" xref="S5.T2.6.6.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.6.6.3.m1.1.1.2.cmml" xref="S5.T2.6.6.3.m1.1.1.2">98.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.3.m1.1c">98.6\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.9.9" class="ltx_tr">
<th id="S5.T2.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (4 local epochs)</th>
<td id="S5.T2.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.7.7.1.m1.1" class="ltx_Math" alttext="0.3304" display="inline"><semantics id="S5.T2.7.7.1.m1.1a"><mn id="S5.T2.7.7.1.m1.1.1" xref="S5.T2.7.7.1.m1.1.1.cmml">0.3304</mn><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.1.m1.1b"><cn type="float" id="S5.T2.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.1.m1.1.1">0.3304</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.1.m1.1c">0.3304</annotation></semantics></math></td>
<td id="S5.T2.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.8.8.2.m1.1" class="ltx_Math" alttext="0.3413" display="inline"><semantics id="S5.T2.8.8.2.m1.1a"><mn id="S5.T2.8.8.2.m1.1.1" xref="S5.T2.8.8.2.m1.1.1.cmml">0.3413</mn><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.2.m1.1b"><cn type="float" id="S5.T2.8.8.2.m1.1.1.cmml" xref="S5.T2.8.8.2.m1.1.1">0.3413</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.2.m1.1c">0.3413</annotation></semantics></math></td>
<td id="S5.T2.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T2.9.9.3.m1.1" class="ltx_Math" alttext="98.6\%" display="inline"><semantics id="S5.T2.9.9.3.m1.1a"><mrow id="S5.T2.9.9.3.m1.1.1" xref="S5.T2.9.9.3.m1.1.1.cmml"><mn id="S5.T2.9.9.3.m1.1.1.2" xref="S5.T2.9.9.3.m1.1.1.2.cmml">98.6</mn><mo id="S5.T2.9.9.3.m1.1.1.1" xref="S5.T2.9.9.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.3.m1.1b"><apply id="S5.T2.9.9.3.m1.1.1.cmml" xref="S5.T2.9.9.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.9.9.3.m1.1.1.1.cmml" xref="S5.T2.9.9.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.9.9.3.m1.1.1.2.cmml" xref="S5.T2.9.9.3.m1.1.1.2">98.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.3.m1.1c">98.6\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.12.12" class="ltx_tr">
<th id="S5.T2.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Non-Federated Training</th>
<td id="S5.T2.10.10.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T2.10.10.1.m1.1" class="ltx_Math" alttext="0.3360" display="inline"><semantics id="S5.T2.10.10.1.m1.1a"><mn id="S5.T2.10.10.1.m1.1.1" xref="S5.T2.10.10.1.m1.1.1.cmml">0.3360</mn><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.1.m1.1b"><cn type="float" id="S5.T2.10.10.1.m1.1.1.cmml" xref="S5.T2.10.10.1.m1.1.1">0.3360</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.1.m1.1c">0.3360</annotation></semantics></math></td>
<td id="S5.T2.11.11.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T2.11.11.2.m1.1" class="ltx_Math" alttext="0.3369" display="inline"><semantics id="S5.T2.11.11.2.m1.1a"><mn id="S5.T2.11.11.2.m1.1.1" xref="S5.T2.11.11.2.m1.1.1.cmml">0.3369</mn><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.2.m1.1b"><cn type="float" id="S5.T2.11.11.2.m1.1.1.cmml" xref="S5.T2.11.11.2.m1.1.1">0.3369</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.2.m1.1c">0.3369</annotation></semantics></math></td>
<td id="S5.T2.12.12.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T2.12.12.3.m1.1" class="ltx_Math" alttext="98.75\%" display="inline"><semantics id="S5.T2.12.12.3.m1.1a"><mrow id="S5.T2.12.12.3.m1.1.1" xref="S5.T2.12.12.3.m1.1.1.cmml"><mn id="S5.T2.12.12.3.m1.1.1.2" xref="S5.T2.12.12.3.m1.1.1.2.cmml">98.75</mn><mo id="S5.T2.12.12.3.m1.1.1.1" xref="S5.T2.12.12.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.3.m1.1b"><apply id="S5.T2.12.12.3.m1.1.1.cmml" xref="S5.T2.12.12.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.12.12.3.m1.1.1.1.cmml" xref="S5.T2.12.12.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.12.12.3.m1.1.1.2.cmml" xref="S5.T2.12.12.3.m1.1.1.2">98.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.3.m1.1c">98.75\%</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of performance in different training schemes with Cats vs Dogs dataset.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">V.2 </span>CIFAR (Planes vs Cars)</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.15" class="ltx_p">In this experiment, we use the data from the CIFAR-10 dataset <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib77" title="" class="ltx_ref">Krizhevsky09learningmultiple </a></cite>. The dimension of the images in this dataset is <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">32</cn><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">32\times 32</annotation></semantics></math>.
The hybrid quantum-classical models used in this experiment is the same as in the previous experiment.
Here we have in total <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mn id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><cn type="integer" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">10000</annotation></semantics></math> training points and <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><cn type="integer" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">2000</annotation></semantics></math> testing points. The testing points are on the central node (global model) which will be used to evaluate the aggregated model after each training round. The training points are equally distributed to the <math id="S5.SS2.p1.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.SS2.p1.4.m4.1a"><mn id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><cn type="integer" id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">100</annotation></semantics></math> local machines <math id="S5.SS2.p1.5.m5.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S5.SS2.p1.5.m5.1a"><msub id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml"><mi id="S5.SS2.p1.5.m5.1.1.2" xref="S5.SS2.p1.5.m5.1.1.2.cmml">N</mi><mi id="S5.SS2.p1.5.m5.1.1.3" xref="S5.SS2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.p1.5.m5.1.1.2">𝑁</ci><ci id="S5.SS2.p1.5.m5.1.1.3.cmml" xref="S5.SS2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">N_{i}</annotation></semantics></math> where <math id="S5.SS2.p1.6.m6.1" class="ltx_Math" alttext="i\in\{1\cdots 100\}" display="inline"><semantics id="S5.SS2.p1.6.m6.1a"><mrow id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mi id="S5.SS2.p1.6.m6.1.1.3" xref="S5.SS2.p1.6.m6.1.1.3.cmml">i</mi><mo id="S5.SS2.p1.6.m6.1.1.2" xref="S5.SS2.p1.6.m6.1.1.2.cmml">∈</mo><mrow id="S5.SS2.p1.6.m6.1.1.1.1" xref="S5.SS2.p1.6.m6.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS2.p1.6.m6.1.1.1.1.2" xref="S5.SS2.p1.6.m6.1.1.1.2.cmml">{</mo><mrow id="S5.SS2.p1.6.m6.1.1.1.1.1" xref="S5.SS2.p1.6.m6.1.1.1.1.1.cmml"><mn id="S5.SS2.p1.6.m6.1.1.1.1.1.2" xref="S5.SS2.p1.6.m6.1.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p1.6.m6.1.1.1.1.1.1" xref="S5.SS2.p1.6.m6.1.1.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S5.SS2.p1.6.m6.1.1.1.1.1.3" xref="S5.SS2.p1.6.m6.1.1.1.1.1.3.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.6.m6.1.1.1.1.1.1a" xref="S5.SS2.p1.6.m6.1.1.1.1.1.1.cmml">​</mo><mn id="S5.SS2.p1.6.m6.1.1.1.1.1.4" xref="S5.SS2.p1.6.m6.1.1.1.1.1.4.cmml">100</mn></mrow><mo stretchy="false" id="S5.SS2.p1.6.m6.1.1.1.1.3" xref="S5.SS2.p1.6.m6.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><in id="S5.SS2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.2"></in><ci id="S5.SS2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.p1.6.m6.1.1.3">𝑖</ci><set id="S5.SS2.p1.6.m6.1.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1"><apply id="S5.SS2.p1.6.m6.1.1.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1.1"><times id="S5.SS2.p1.6.m6.1.1.1.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1.1.1"></times><cn type="integer" id="S5.SS2.p1.6.m6.1.1.1.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1.1.2">1</cn><ci id="S5.SS2.p1.6.m6.1.1.1.1.1.3.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1.1.3">⋯</ci><cn type="integer" id="S5.SS2.p1.6.m6.1.1.1.1.1.4.cmml" xref="S5.SS2.p1.6.m6.1.1.1.1.1.4">100</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">i\in\{1\cdots 100\}</annotation></semantics></math>. In each training round, <math id="S5.SS2.p1.7.m7.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS2.p1.7.m7.1a"><mn id="S5.SS2.p1.7.m7.1.1" xref="S5.SS2.p1.7.m7.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.7.m7.1b"><cn type="integer" id="S5.SS2.p1.7.m7.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.7.m7.1c">5</annotation></semantics></math> local machines will be randomly selected and each will perform <math id="S5.SS2.p1.8.m8.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS2.p1.8.m8.1a"><mn id="S5.SS2.p1.8.m8.1.1" xref="S5.SS2.p1.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.8.m8.1b"><cn type="integer" id="S5.SS2.p1.8.m8.1.1.cmml" xref="S5.SS2.p1.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.8.m8.1c">1</annotation></semantics></math>, <math id="S5.SS2.p1.9.m9.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS2.p1.9.m9.1a"><mn id="S5.SS2.p1.9.m9.1.1" xref="S5.SS2.p1.9.m9.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.9.m9.1b"><cn type="integer" id="S5.SS2.p1.9.m9.1.1.cmml" xref="S5.SS2.p1.9.m9.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.9.m9.1c">2</annotation></semantics></math> or <math id="S5.SS2.p1.10.m10.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.SS2.p1.10.m10.1a"><mn id="S5.SS2.p1.10.m10.1.1" xref="S5.SS2.p1.10.m10.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.10.m10.1b"><cn type="integer" id="S5.SS2.p1.10.m10.1.1.cmml" xref="S5.SS2.p1.10.m10.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.10.m10.1c">4</annotation></semantics></math> epochs of training with its own training points. The batch size <math id="S5.SS2.p1.11.m11.1" class="ltx_Math" alttext="S=32" display="inline"><semantics id="S5.SS2.p1.11.m11.1a"><mrow id="S5.SS2.p1.11.m11.1.1" xref="S5.SS2.p1.11.m11.1.1.cmml"><mi id="S5.SS2.p1.11.m11.1.1.2" xref="S5.SS2.p1.11.m11.1.1.2.cmml">S</mi><mo id="S5.SS2.p1.11.m11.1.1.1" xref="S5.SS2.p1.11.m11.1.1.1.cmml">=</mo><mn id="S5.SS2.p1.11.m11.1.1.3" xref="S5.SS2.p1.11.m11.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.11.m11.1b"><apply id="S5.SS2.p1.11.m11.1.1.cmml" xref="S5.SS2.p1.11.m11.1.1"><eq id="S5.SS2.p1.11.m11.1.1.1.cmml" xref="S5.SS2.p1.11.m11.1.1.1"></eq><ci id="S5.SS2.p1.11.m11.1.1.2.cmml" xref="S5.SS2.p1.11.m11.1.1.2">𝑆</ci><cn type="integer" id="S5.SS2.p1.11.m11.1.1.3.cmml" xref="S5.SS2.p1.11.m11.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.11.m11.1c">S=32</annotation></semantics></math>. The trained model will then be sent to the central mode for aggregation.
In the left three panels of Figure <a href="#S5.F8" title="Figure 8 ‣ V.2 CIFAR (Planes vs Cars) ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we present the results of training the hybrid quantum model via federated setting with different number of local training epochs. Since the training data is distributed across different clients, we only consider the testing accuracies with the aggregated global model. In the considered Planes vs Cars dataset, we observe that both the testing accuracies and testing loss reach the comparable level as the non-federated training (shown in Table <a href="#S5.T3" title="Table 3 ‣ V.2 CIFAR (Planes vs Cars) ‣ V Experiments and Results ‣ Federated Quantum Machine Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). Similar to the previous Cats vs Dogs dataset, we observe that the training loss, which is the average from clients, has fluctuations compared to non-federated training.
In addition, the testing loss and accuracies converge to comparable levels to the non-federated training, regardless of the local training epochs.
Notably, we observe that a single epoch in local training is pretty enough to train a well-performed model. In each round of the federated training, the model updates are based on the samplings from <math id="S5.SS2.p1.12.m12.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS2.p1.12.m12.1a"><mn id="S5.SS2.p1.12.m12.1.1" xref="S5.SS2.p1.12.m12.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.12.m12.1b"><cn type="integer" id="S5.SS2.p1.12.m12.1.1.cmml" xref="S5.SS2.p1.12.m12.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.12.m12.1c">5</annotation></semantics></math> clients, with <math id="S5.SS2.p1.13.m13.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS2.p1.13.m13.1a"><mn id="S5.SS2.p1.13.m13.1.1" xref="S5.SS2.p1.13.m13.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.13.m13.1b"><cn type="integer" id="S5.SS2.p1.13.m13.1.1.cmml" xref="S5.SS2.p1.13.m13.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.13.m13.1c">1</annotation></semantics></math> local training epoch. The computing resources used are linear with <math id="S5.SS2.p1.14.m14.1" class="ltx_Math" alttext="100\times 5\times 1=500" display="inline"><semantics id="S5.SS2.p1.14.m14.1a"><mrow id="S5.SS2.p1.14.m14.1.1" xref="S5.SS2.p1.14.m14.1.1.cmml"><mrow id="S5.SS2.p1.14.m14.1.1.2" xref="S5.SS2.p1.14.m14.1.1.2.cmml"><mn id="S5.SS2.p1.14.m14.1.1.2.2" xref="S5.SS2.p1.14.m14.1.1.2.2.cmml">100</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.14.m14.1.1.2.1" xref="S5.SS2.p1.14.m14.1.1.2.1.cmml">×</mo><mn id="S5.SS2.p1.14.m14.1.1.2.3" xref="S5.SS2.p1.14.m14.1.1.2.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.14.m14.1.1.2.1a" xref="S5.SS2.p1.14.m14.1.1.2.1.cmml">×</mo><mn id="S5.SS2.p1.14.m14.1.1.2.4" xref="S5.SS2.p1.14.m14.1.1.2.4.cmml">1</mn></mrow><mo id="S5.SS2.p1.14.m14.1.1.1" xref="S5.SS2.p1.14.m14.1.1.1.cmml">=</mo><mn id="S5.SS2.p1.14.m14.1.1.3" xref="S5.SS2.p1.14.m14.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.14.m14.1b"><apply id="S5.SS2.p1.14.m14.1.1.cmml" xref="S5.SS2.p1.14.m14.1.1"><eq id="S5.SS2.p1.14.m14.1.1.1.cmml" xref="S5.SS2.p1.14.m14.1.1.1"></eq><apply id="S5.SS2.p1.14.m14.1.1.2.cmml" xref="S5.SS2.p1.14.m14.1.1.2"><times id="S5.SS2.p1.14.m14.1.1.2.1.cmml" xref="S5.SS2.p1.14.m14.1.1.2.1"></times><cn type="integer" id="S5.SS2.p1.14.m14.1.1.2.2.cmml" xref="S5.SS2.p1.14.m14.1.1.2.2">100</cn><cn type="integer" id="S5.SS2.p1.14.m14.1.1.2.3.cmml" xref="S5.SS2.p1.14.m14.1.1.2.3">5</cn><cn type="integer" id="S5.SS2.p1.14.m14.1.1.2.4.cmml" xref="S5.SS2.p1.14.m14.1.1.2.4">1</cn></apply><cn type="integer" id="S5.SS2.p1.14.m14.1.1.3.cmml" xref="S5.SS2.p1.14.m14.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.14.m14.1c">100\times 5\times 1=500</annotation></semantics></math> in total. While for a full epoch of training with non-federated setting, the computing resources used are linear with <math id="S5.SS2.p1.15.m15.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S5.SS2.p1.15.m15.1a"><mn id="S5.SS2.p1.15.m15.1.1" xref="S5.SS2.p1.15.m15.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.15.m15.1b"><cn type="integer" id="S5.SS2.p1.15.m15.1.1.cmml" xref="S5.SS2.p1.15.m15.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.15.m15.1c">10000</annotation></semantics></math>. This results again imply the potential of more efficient training on QML models with distributed schemes. This particularly benefits the training of quantum models when we are using high-performance simulation platform or an array of small NISQ devices, with the communication overhead is moderate.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2103.12010/assets/x5.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="241" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S5.F7.2.1" class="ltx_text ltx_font_bold">Planes vs Cars from CIFAR-10 Dataset.</span> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib77" title="" class="ltx_ref">Krizhevsky09learningmultiple </a></cite></figcaption>
</figure>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2103.12010/assets/x6.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S5.F8.2.1" class="ltx_text ltx_font_bold">Results: Planes vs Cars.</span> </figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.12.13.1" class="ltx_tr">
<th id="S5.T3.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S5.T3.12.13.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Training Loss</th>
<th id="S5.T3.12.13.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Testing Loss</th>
<th id="S5.T3.12.13.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Testing Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.3.3" class="ltx_tr">
<th id="S5.T3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (1 local epoch)</th>
<td id="S5.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.1.1.1.m1.1" class="ltx_Math" alttext="0.4029" display="inline"><semantics id="S5.T3.1.1.1.m1.1a"><mn id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">0.4029</mn><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><cn type="float" id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">0.4029</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">0.4029</annotation></semantics></math></td>
<td id="S5.T3.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.2.2.2.m1.1" class="ltx_Math" alttext="0.4133" display="inline"><semantics id="S5.T3.2.2.2.m1.1a"><mn id="S5.T3.2.2.2.m1.1.1" xref="S5.T3.2.2.2.m1.1.1.cmml">0.4133</mn><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><cn type="float" id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1">0.4133</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">0.4133</annotation></semantics></math></td>
<td id="S5.T3.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.3.3.3.m1.1" class="ltx_Math" alttext="93.4\%" display="inline"><semantics id="S5.T3.3.3.3.m1.1a"><mrow id="S5.T3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.m1.1.1.cmml"><mn id="S5.T3.3.3.3.m1.1.1.2" xref="S5.T3.3.3.3.m1.1.1.2.cmml">93.4</mn><mo id="S5.T3.3.3.3.m1.1.1.1" xref="S5.T3.3.3.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.m1.1b"><apply id="S5.T3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1"><csymbol cd="latexml" id="S5.T3.3.3.3.m1.1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T3.3.3.3.m1.1.1.2.cmml" xref="S5.T3.3.3.3.m1.1.1.2">93.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.m1.1c">93.4\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.6.6" class="ltx_tr">
<th id="S5.T3.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (2 local epochs)</th>
<td id="S5.T3.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.4.4.1.m1.1" class="ltx_Math" alttext="0.4760" display="inline"><semantics id="S5.T3.4.4.1.m1.1a"><mn id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml">0.4760</mn><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><cn type="float" id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1">0.4760</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">0.4760</annotation></semantics></math></td>
<td id="S5.T3.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.5.5.2.m1.1" class="ltx_Math" alttext="0.4056" display="inline"><semantics id="S5.T3.5.5.2.m1.1a"><mn id="S5.T3.5.5.2.m1.1.1" xref="S5.T3.5.5.2.m1.1.1.cmml">0.4056</mn><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.2.m1.1b"><cn type="float" id="S5.T3.5.5.2.m1.1.1.cmml" xref="S5.T3.5.5.2.m1.1.1">0.4056</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.2.m1.1c">0.4056</annotation></semantics></math></td>
<td id="S5.T3.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.6.6.3.m1.1" class="ltx_Math" alttext="94.05\%" display="inline"><semantics id="S5.T3.6.6.3.m1.1a"><mrow id="S5.T3.6.6.3.m1.1.1" xref="S5.T3.6.6.3.m1.1.1.cmml"><mn id="S5.T3.6.6.3.m1.1.1.2" xref="S5.T3.6.6.3.m1.1.1.2.cmml">94.05</mn><mo id="S5.T3.6.6.3.m1.1.1.1" xref="S5.T3.6.6.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.3.m1.1b"><apply id="S5.T3.6.6.3.m1.1.1.cmml" xref="S5.T3.6.6.3.m1.1.1"><csymbol cd="latexml" id="S5.T3.6.6.3.m1.1.1.1.cmml" xref="S5.T3.6.6.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T3.6.6.3.m1.1.1.2.cmml" xref="S5.T3.6.6.3.m1.1.1.2">94.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.3.m1.1c">94.05\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.9.9" class="ltx_tr">
<th id="S5.T3.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Federated Training (4 local epochs)</th>
<td id="S5.T3.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.7.7.1.m1.1" class="ltx_Math" alttext="0.4090" display="inline"><semantics id="S5.T3.7.7.1.m1.1a"><mn id="S5.T3.7.7.1.m1.1.1" xref="S5.T3.7.7.1.m1.1.1.cmml">0.4090</mn><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.1.m1.1b"><cn type="float" id="S5.T3.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1">0.4090</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.1.m1.1c">0.4090</annotation></semantics></math></td>
<td id="S5.T3.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.8.8.2.m1.1" class="ltx_Math" alttext="0.3934" display="inline"><semantics id="S5.T3.8.8.2.m1.1a"><mn id="S5.T3.8.8.2.m1.1.1" xref="S5.T3.8.8.2.m1.1.1.cmml">0.3934</mn><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.2.m1.1b"><cn type="float" id="S5.T3.8.8.2.m1.1.1.cmml" xref="S5.T3.8.8.2.m1.1.1">0.3934</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.2.m1.1c">0.3934</annotation></semantics></math></td>
<td id="S5.T3.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S5.T3.9.9.3.m1.1" class="ltx_Math" alttext="93.45\%" display="inline"><semantics id="S5.T3.9.9.3.m1.1a"><mrow id="S5.T3.9.9.3.m1.1.1" xref="S5.T3.9.9.3.m1.1.1.cmml"><mn id="S5.T3.9.9.3.m1.1.1.2" xref="S5.T3.9.9.3.m1.1.1.2.cmml">93.45</mn><mo id="S5.T3.9.9.3.m1.1.1.1" xref="S5.T3.9.9.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.3.m1.1b"><apply id="S5.T3.9.9.3.m1.1.1.cmml" xref="S5.T3.9.9.3.m1.1.1"><csymbol cd="latexml" id="S5.T3.9.9.3.m1.1.1.1.cmml" xref="S5.T3.9.9.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T3.9.9.3.m1.1.1.2.cmml" xref="S5.T3.9.9.3.m1.1.1.2">93.45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.3.m1.1c">93.45\%</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.12.12" class="ltx_tr">
<th id="S5.T3.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Non-Federated Training</th>
<td id="S5.T3.10.10.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.10.10.1.m1.1" class="ltx_Math" alttext="0.4190" display="inline"><semantics id="S5.T3.10.10.1.m1.1a"><mn id="S5.T3.10.10.1.m1.1.1" xref="S5.T3.10.10.1.m1.1.1.cmml">0.4190</mn><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.1.m1.1b"><cn type="float" id="S5.T3.10.10.1.m1.1.1.cmml" xref="S5.T3.10.10.1.m1.1.1">0.4190</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.1.m1.1c">0.4190</annotation></semantics></math></td>
<td id="S5.T3.11.11.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.11.11.2.m1.1" class="ltx_Math" alttext="0.4016" display="inline"><semantics id="S5.T3.11.11.2.m1.1a"><mn id="S5.T3.11.11.2.m1.1.1" xref="S5.T3.11.11.2.m1.1.1.cmml">0.4016</mn><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.2.m1.1b"><cn type="float" id="S5.T3.11.11.2.m1.1.1.cmml" xref="S5.T3.11.11.2.m1.1.1">0.4016</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.2.m1.1c">0.4016</annotation></semantics></math></td>
<td id="S5.T3.12.12.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.12.12.3.m1.1" class="ltx_Math" alttext="93.65\%" display="inline"><semantics id="S5.T3.12.12.3.m1.1a"><mrow id="S5.T3.12.12.3.m1.1.1" xref="S5.T3.12.12.3.m1.1.1.cmml"><mn id="S5.T3.12.12.3.m1.1.1.2" xref="S5.T3.12.12.3.m1.1.1.2.cmml">93.65</mn><mo id="S5.T3.12.12.3.m1.1.1.1" xref="S5.T3.12.12.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.12.12.3.m1.1b"><apply id="S5.T3.12.12.3.m1.1.1.cmml" xref="S5.T3.12.12.3.m1.1.1"><csymbol cd="latexml" id="S5.T3.12.12.3.m1.1.1.1.cmml" xref="S5.T3.12.12.3.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T3.12.12.3.m1.1.1.2.cmml" xref="S5.T3.12.12.3.m1.1.1.2">93.65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.12.3.m1.1c">93.65\%</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of performance in different training schemes with CIFAR (Planes vs Cars) dataset.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span>Discussion</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">VI.1 </span>Integration with Other Private-Preserving Protocols</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In this study we consider the federated quantum learning framework. One of the limitation is that the process of exchanging model parameters can potentially be attacked. Moreover, we can not exclude the possibilities that malicious parties are joining the network, which will get the aggregated global model. The leaked model parameters can be used to deduce the training data of the model <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib78" title="" class="ltx_ref">dwork2014algorithmic </a></cite>.
There are other protocols which can further boost the security. For example, it has been shown that trained models can be used to recover training entries <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib79" title="" class="ltx_ref">fredrikson2015model </a></cite>. In addition, it is also possible for adversaries to find out whether a specific entry is used in training process <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib80" title="" class="ltx_ref">shokri2017membership </a></cite>. These possibilities raise serious concerns when the QML models are used to process private and sensitive data. One of the potential solution is to train the model with <em id="S6.SS1.p1.1.1" class="ltx_emph ltx_font_italic">differential privacy</em> (DP) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib81" title="" class="ltx_ref">abadi2016deep </a></cite>. With DP, it is possible to share the trained model and still keep the private information of the training data. Another direction if to incorporate the secure multi-party computation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib82" title="" class="ltx_ref">goryczka2013secure </a></cite> which can further increase the security in decentralization computing.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">VI.2 </span>Different Aggregation Method</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In this work, we use the simplest aggregation method which is simply calculating the average of parameters from each local machine (model). In a more realistic application scenario, clients may upload a corrupt trained model, or the communication channel may be interfered by noise, which can potentially compromise the global model if there is no other countermeasures. Several recent works present advanced aggregation schemes to address this issue <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib83" title="" class="ltx_ref">pillutla2019robust </a>; <a href="#bib.bib84" title="" class="ltx_ref">ang2020robust </a></cite>. The implementation of these advanced protocols with quantum machine learning is an interesting direction for future work.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">VI.3 </span>Decentralization</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">This research presents a proof-of-concept federated training on quantum machine learning models. The scheme includes a <em id="S6.SS3.p1.1.1" class="ltx_emph ltx_font_italic">central node</em> to receive the trained models from clients, to aggregate them and to distribute the aggregated model to clients. This <em id="S6.SS3.p1.1.2" class="ltx_emph ltx_font_italic">central node</em> can be vulnerable to malicious attacks and the adversaries can compromise the whole network. Moreover, the communication bandwidth between clients and the central node may vary, leading some undesired effects in the synchronization process. To address these issues, recent studies propose various <em id="S6.SS3.p1.1.3" class="ltx_emph ltx_font_italic">decentralized</em> federated learning schemes <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib85" title="" class="ltx_ref">savazzi2020federated </a>; <a href="#bib.bib86" title="" class="ltx_ref">wittkopp2021decentralized </a>; <a href="#bib.bib87" title="" class="ltx_ref">pokhrel2020decentralized </a>; <a href="#bib.bib88" title="" class="ltx_ref">bonawitz2019towards </a>; <a href="#bib.bib89" title="" class="ltx_ref">xiao2020fully </a>; <a href="#bib.bib90" title="" class="ltx_ref">lalitha2018fully </a>; <a href="#bib.bib91" title="" class="ltx_ref">lu2020decentralized </a></cite>.
For example, the <em id="S6.SS3.p1.1.4" class="ltx_emph ltx_font_italic">distributed ledger technologies</em> (DLT) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib92" title="" class="ltx_ref">nakamoto2008bitcoin </a>; <a href="#bib.bib93" title="" class="ltx_ref">zyskind2015decentralizing </a>; <a href="#bib.bib94" title="" class="ltx_ref">cai2018decentralized </a>; <a href="#bib.bib95" title="" class="ltx_ref">pandl2020convergence </a></cite> which power the development of blockchain have been applied in the decentralized FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib96" title="" class="ltx_ref">qu2020decentralized </a>; <a href="#bib.bib97" title="" class="ltx_ref">ramanan2020baffle </a>; <a href="#bib.bib98" title="" class="ltx_ref">awan2019poster </a>; <a href="#bib.bib99" title="" class="ltx_ref">qu2020blockchained </a>; <a href="#bib.bib100" title="" class="ltx_ref">zhao2020privacy </a>; <a href="#bib.bib101" title="" class="ltx_ref">bao2019flchain </a>; <a href="#bib.bib102" title="" class="ltx_ref">kim2019blockchained </a></cite>. The blockchain technologies are used to ensure the robustness and integrity of the shared information while remove the requirement of a central node. Blockchain-enabled FL can also be designed to encourage the data-owner participating in the model training process <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib103" title="" class="ltx_ref">liu2020fedcoin </a></cite>.
In addition, <em id="S6.SS3.p1.1.5" class="ltx_emph ltx_font_italic">peer-to-peer</em> protocols are also employed in FL to remove the need of a central node <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib104" title="" class="ltx_ref">roy2019braintorrent </a>; <a href="#bib.bib105" title="" class="ltx_ref">lalitha2019peer </a></cite>. <em id="S6.SS3.p1.1.6" class="ltx_emph ltx_font_italic">Gossip learning</em> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib106" title="" class="ltx_ref">hegedHus2016robust </a>; <a href="#bib.bib107" title="" class="ltx_ref">ormandi2013gossip </a></cite> is an alternative learning framework to FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib108" title="" class="ltx_ref">hegedHus2019gossip </a>; <a href="#bib.bib109" title="" class="ltx_ref">hegedHus2019decentralized </a>; <a href="#bib.bib110" title="" class="ltx_ref">hegedHus2021decentralized </a>; <a href="#bib.bib111" title="" class="ltx_ref">hu2019decentralized </a></cite>. Under gossip learning framework, no central node is required, nodes on the network exchange and aggregate models directly.
The efficiencies and capabilities of these decentralized schemes such as blockchained FL and gossip learning in the quantum regime are left for future work.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">In classical machine learning, distributed training frameworks are designed to scale up the model training to computing clusters <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib112" title="" class="ltx_ref">sergeev2018horovod </a></cite>, making the training on large-scale dataset and complex models possible.
Potential direction is to apply the federated quantum learning to the high-performance quantum simulation.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">VI.4 </span>Other Quantum Machine Learning Models</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">In this work we consider the hybrid quantum-classical transfer learning architecture which includes a pre-trained classical model as the feature extractor. Currently the available quantum computers and simulation software are rather limited and do not posses large number of qubits. However, the proposed framework can be extended well beyond the transfer learning structure. Recently, a hybrid architecture combining tensor network and quantum circuit is proposed <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib113" title="" class="ltx_ref">chen2021end </a></cite>. Such hybrid architecture is more generic than the pre-trained network used in this work. It is interesting to investigate the potential of decentralizing such kind of architectures. Moreover, it is possible to study the federated learning on quantum convolutional neural networks (QCNN) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib65" title="" class="ltx_ref">chen2020qcnn </a>; <a href="#bib.bib114" title="" class="ltx_ref">cong2019quantum </a>; <a href="#bib.bib115" title="" class="ltx_ref">li2020quantum </a>; <a href="#bib.bib116" title="" class="ltx_ref">oh2020tutorial </a>; <a href="#bib.bib117" title="" class="ltx_ref">kerenidis2019quantum </a>; <a href="#bib.bib118" title="" class="ltx_ref">liu2019hybrid </a>; <a href="#bib.bib66" title="" class="ltx_ref">chen2021hybrid </a></cite> when larger-scale quantum simulators or real quantum computers are available.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">VI.5 </span>Potential Applications</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">This work can potentially be integrated with the work <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">yang2020decentralizing </a>; <a href="#bib.bib119" title="" class="ltx_ref">qi2020submodular </a></cite> for decentralizing the quantum-enhanced speech recognition. Another potential direction is in the use in healthcare in which a tremendous amount of sensitive personal data need to be processed to train a reliable model. For example, the work <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib67" title="" class="ltx_ref">sierra2020dementia </a></cite> studied the application of VQC in dementia prediction which would benefit from the federated training to preserve the users’ privacy. Recently, the application of quantum computing in financial industries have drawn a lot of attention <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib120" title="" class="ltx_ref">egger2020quantum </a></cite>. It is expected that federated QML would play an important role in finance as well.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work we provide the framework to train hybrid quantum-classical classifiers in a federated manner which can help in preserving the privacy and distributing computational loads to an array of NISQ computers. We also show that the federated training in our setting does not sacrifice the performance in terms of the testing accuracy. This work should benefit the research in both the privacy-preserving AI and the quantum computing and pave new direction on building secure, reliable and scalable distributed quantum machine learning architecture.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work is supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research under Award Number DE-SC-0012704 and the Brookhaven National Laboratory LDRD #20-024.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1409.1556</span>, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern
recognition</span>, pp. 1–9, 2015.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
A. Voulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis, “Deep
Learning for Computer Vision: A Brief Review,” <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Computational
Intelligence and Neuroscience</span>, vol. 2018, pp. 1–13, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning with
neural networks,” in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing
systems</span>, pp. 3104–3112, 2014.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche,
J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman,
D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach,
K. Kavukcuoglu, T. Graepel, and D. Hassabis, “Mastering the game of Go with
deep neural networks and tree search,” <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Nature</span>, vol. 529,
pp. 484–489, 1 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
A. Cross, “The ibm q experience and qiskit open-source quantum computing
software,” in <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">APS Meeting Abstracts</span>, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
F. Arute, K. Arya, R. Babbush, D. Bacon, J. C. Bardin, R. Barends, R. Biswas,
S. Boixo, F. G. Brandao, D. A. Buell, <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Quantum supremacy using
a programmable superconducting processor,” <span id="bib.bib7.2.2" class="ltx_text ltx_font_italic">Nature</span>, vol. 574, no. 7779,
pp. 505–510, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
N. Grzesiak, R. Blümel, K. Wright, K. M. Beck, N. C. Pisenti, M. Li,
V. Chaplin, J. M. Amini, S. Debnath, J.-S. Chen, <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Efficient
arbitrary simultaneously entangling gates on a trapped-ion quantum
computer,” <span id="bib.bib8.2.2" class="ltx_text ltx_font_italic">Nature Communications</span>, vol. 11, no. 1, pp. 1–6, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
T. Lanting, A. J. Przybysz, A. Y. Smirnov, F. M. Spedalieri, M. H. Amin, A. J.
Berkley, R. Harris, F. Altomare, S. Boixo, P. Bunyk, <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">et al.</span>,
“Entanglement in a quantum annealing processor,” <span id="bib.bib9.2.2" class="ltx_text ltx_font_italic">Physical Review X</span>,
vol. 4, no. 2, p. 021041, 2014.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
A. W. Harrow and A. Montanaro, “Quantum computational supremacy,” <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Nature</span>, vol. 549, no. 7671, pp. 203–209, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
M. A. Nielsen and I. Chuang, “Quantum computation and quantum information,”
2002.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
P. W. Shor, “Polynomial-time algorithms for prime factorization and discrete
logarithms on a quantum computer,” <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">SIAM review</span>, vol. 41, no. 2,
pp. 303–332, 1999.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
L. K. Grover, “Quantum mechanics helps in searching for a needle in a
haystack,” <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Physical review letters</span>, vol. 79, no. 2, p. 325, 1997.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
D. Gottesman, “Stabilizer codes and quantum error correction,” <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv
preprint quant-ph/9705052</span>, 1997.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
D. Gottesman, “Theory of fault-tolerant quantum computation,” <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Physical
Review A</span>, vol. 57, no. 1, p. 127, 1998.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
J. Preskill, “Quantum computing in the nisq era and beyond,” <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Quantum</span>,
vol. 2, p. 79, 2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love,
A. Aspuru-Guzik, and J. L. O’brien, “A variational eigenvalue solver on a
photonic quantum processor,” <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Nature communications</span>, vol. 5, p. 4213,
2014.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii, J. R.
McClean, K. Mitarai, X. Yuan, L. Cincio, <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Variational quantum
algorithms,” <span id="bib.bib18.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.09265</span>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
K. Bharti, A. Cervera-Lierta, T. H. Kyaw, T. Haug, S. Alperin-Lea, A. Anand,
M. Degroote, H. Heimonen, J. S. Kottmann, T. Menke, <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Noisy
intermediate-scale quantum (nisq) algorithms,” <span id="bib.bib19.2.2" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2101.08448</span>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, “Quantum circuit learning,”
<span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Physical Review A</span>, vol. 98, no. 3, p. 032309, 2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
M. Schuld, A. Bocharov, K. Svore, and N. Wiebe, “Circuit-centric quantum
classifiers,” <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1804.00633</span>, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
E. Farhi and H. Neven, “Classification with quantum neural networks on near
term processors,” <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1802.06002</span>, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, “Parameterized quantum
circuits as machine learning models,” <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Quantum Science and Technology</span>,
vol. 4, no. 4, p. 043001, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
A. Mari, T. R. Bromley, J. Izaac, M. Schuld, and N. Killoran, “Transfer
learning in hybrid classical-quantum neural networks,” <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1912.08278</span>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
Z. Abohashima, M. Elhosen, E. H. Houssein, and W. M. Mohamed, “Classification
with quantum machine learning: A survey,” <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2006.12270</span>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
P. Easom-McCaldin, A. Bouridane, A. Belatreche, and R. Jiang, “Towards
building a facial identification system using quantum machine learning
techniques,” <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.12616</span>, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(27)</span>
<span class="ltx_bibblock">
A. Sarma, R. Chatterjee, K. Gili, and T. Yu, “Quantum unsupervised and
supervised learning on superconducting processors,” <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1909.04226</span>, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(28)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, C.-M. Huang, C.-W. Hsing, and Y.-J. Kao, “Hybrid
quantum-classical classifier based on tensor network and variational quantum
circuit,” <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.14651</span>, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(29)</span>
<span class="ltx_bibblock">
S. A. Stein, B. Baheri, R. M. Tischio, Y. Chen, Y. Mao, Q. Guan, A. Li, and
B. Fang, “A hybrid system for learning classical data in quantum states,”
<span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.00256</span>, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(30)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, S. Yoo, and Y.-L. L. Fang, “Quantum long short-term memory,”
<span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.01783</span>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(31)</span>
<span class="ltx_bibblock">
O. Kyriienko, A. E. Paine, and V. E. Elfving, “Solving nonlinear differential
equations with differentiable quantum circuits,” <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2011.10395</span>, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(32)</span>
<span class="ltx_bibblock">
P.-L. Dallaire-Demers and N. Killoran, “Quantum generative adversarial
networks,” <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Physical Review A</span>, vol. 98, no. 1, p. 012324, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(33)</span>
<span class="ltx_bibblock">
J. Li, R. Topaloglu, and S. Ghosh, “Quantum generative models for small
molecule drug discovery,” <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2101.03438</span>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
S. A. Stein, B. Baheri, R. M. Tischio, Y. Mao, Q. Guan, A. Li, B. Fang, and
S. Xu, “Qugan: A generative adversarial network through quantum states,”
<span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.09036</span>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(35)</span>
<span class="ltx_bibblock">
C. Zoufal, A. Lucchi, and S. Woerner, “Quantum generative adversarial networks
for learning and loading random distributions,” <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">npj Quantum
Information</span>, vol. 5, no. 1, pp. 1–9, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(36)</span>
<span class="ltx_bibblock">
H. Situ, Z. He, L. Li, and S. Zheng, “Quantum generative adversarial network
for generating discrete data,” <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1807.01235</span>, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(37)</span>
<span class="ltx_bibblock">
K. Nakaji and N. Yamamoto, “Quantum semi-supervised generative adversarial
network for enhanced data classification,” <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2010.13727</span>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
S. Lloyd, M. Schuld, A. Ijaz, J. Izaac, and N. Killoran, “Quantum embeddings
for machine learning,” <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2001.03622</span>, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(39)</span>
<span class="ltx_bibblock">
N. A. Nghiem, S. Y.-C. Chen, and T.-C. Wei, “A unified classification
framework with quantum metric learning,” <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2010.13186</span>, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(40)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, C.-H. H. Yang, J. Qi, P.-Y. Chen, X. Ma, and H.-S. Goan,
“Variational quantum circuits for deep reinforcement learning,” <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">IEEE
Access</span>, vol. 8, pp. 141007–141024, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(41)</span>
<span class="ltx_bibblock">
O. Lockwood and M. Si, “Reinforcement learning with quantum variational
circuit,” in <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence and Interactive Digital Entertainment</span>, vol. 16, pp. 245–251,
2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(42)</span>
<span class="ltx_bibblock">
S. Wu, S. Jin, D. Wen, and X. Wang, “Quantum reinforcement learning in
continuous action space,” <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.10711</span>, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(43)</span>
<span class="ltx_bibblock">
S. Jerbi, L. M. Trenkwalder, H. P. Nautrup, H. J. Briegel, and V. Dunjko,
“Quantum enhancements for deep reinforcement learning in large spaces,”
<span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.12760</span>, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
C.-C. CHEN, K. SHIBA, M. SOGABE, K. SAKAMOTO, and T. SOGABE, “Hybrid
quantum-classical ulam-von neumann linear solver-based quantum dynamic
programing algorithm,” <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Proceedings of the Annual Conference of JSAI</span>,
vol. JSAI2020, pp. 2K6ES203–2K6ES203, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(45)</span>
<span class="ltx_bibblock">
J. Bausch, “Recurrent quantum neural networks,” <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2006.14619</span>, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(46)</span>
<span class="ltx_bibblock">
C.-H. H. Yang, J. Qi, S. Y.-C. Chen, P.-Y. Chen, S. M. Siniscalchi, X. Ma, and
C.-H. Lee, “Decentralizing feature extraction with quantum convolutional
neural network for automatic speech recognition,” <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2010.13309</span>, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(47)</span>
<span class="ltx_bibblock">
K. Suzuki, “Overview of deep learning in medical imaging,” <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Radiological
physics and technology</span>, vol. 10, no. 3, pp. 257–273, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(48)</span>
<span class="ltx_bibblock">
A. S. Lundervold and A. Lundervold, “An overview of deep learning in medical
imaging focusing on mri,” <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Zeitschrift für Medizinische Physik</span>,
vol. 29, no. 2, pp. 102–127, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(49)</span>
<span class="ltx_bibblock">
L. Deng, G. Hinton, and B. Kingsbury, “New types of deep neural network
learning for speech recognition and related applications: An overview,” in
<span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">2013 IEEE international conference on acoustics, speech and signal
processing</span>, pp. 8599–8603, IEEE, 2013.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(50)</span>
<span class="ltx_bibblock">
D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case,
J. Casper, B. Catanzaro, Q. Cheng, G. Chen, <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Deep speech 2:
End-to-end speech recognition in english and mandarin,” in <span id="bib.bib50.2.2" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pp. 173–182, 2016.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(51)</span>
<span class="ltx_bibblock">
A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger,
S. Satheesh, S. Sengupta, A. Coates, <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Deep speech: Scaling up
end-to-end speech recognition,” <span id="bib.bib51.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.5567</span>, 2014.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(52)</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence and Statistics</span>, pp. 1273–1282,
PMLR, 2017.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(53)</span>
<span class="ltx_bibblock">
R. Shokri and V. Shmatikov, “Privacy-preserving deep learning,” in <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22nd ACM SIGSAC conference on computer and communications
security</span>, pp. 1310–1321, 2015.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(54)</span>
<span class="ltx_bibblock">
V. Kulkarni, M. Kulkarni, and A. Pant, “Survey of personalization techniques
for federated learning,” <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.08673</span>, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(55)</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Advances
and open problems in federated learning,” <span id="bib.bib55.2.2" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1912.04977</span>, 2019.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(56)</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</span>, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(57)</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology (TIST)</span>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(58)</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing
Magazine</span>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(59)</span>
<span class="ltx_bibblock">
Q. Li, Z. Wen, and B. He, “Federated learning systems: Vision, hype and
reality for data privacy and protection,” <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1907.09693</span>, 2019.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(60)</span>
<span class="ltx_bibblock">
X. Wang, Y. Han, V. C. Leung, D. Niyato, X. Yan, and X. Chen, “Convergence of
edge computing and deep learning: A comprehensive survey,” <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">IEEE
Communications Surveys &amp; Tutorials</span>, vol. 22, no. 2, pp. 869–904, 2020.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(61)</span>
<span class="ltx_bibblock">
T. Semwal, A. Mulay, and A. M. Agrawal, “Fedperf: A practitioners’ guide to
performance of federated learning algorithms,” <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">OSF Preprints</span>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(62)</span>
<span class="ltx_bibblock">
S. Sim, P. D. Johnson, and A. Aspuru-Guzik, “Expressibility and entangling
capability of parameterized quantum circuits for hybrid quantum-classical
algorithms,” <span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Advanced Quantum Technologies</span>, vol. 2, no. 12,
p. 1900070, 2019.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(63)</span>
<span class="ltx_bibblock">
Y. Du, M.-H. Hsieh, T. Liu, and D. Tao, “The expressive power of parameterized
quantum circuits,” <span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.11922</span>, 2018.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(64)</span>
<span class="ltx_bibblock">
A. Abbas, D. Sutter, C. Zoufal, A. Lucchi, A. Figalli, and S. Woerner, “The
power of quantum neural networks,” <span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.00027</span>,
2020.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(65)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, T.-C. Wei, C. Zhang, H. Yu, and S. Yoo, “Quantum convolutional
neural networks for high energy physics data analysis,” <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2012.12177</span>, 2020.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(66)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, T.-C. Wei, C. Zhang, H. Yu, and S. Yoo, “Hybrid
quantum-classical graph convolutional network,” <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2101.06189</span>, 2021.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(67)</span>
<span class="ltx_bibblock">
D. Sierra-Sosa, J. Arcila-Moreno, B. Garcia-Zapirain, C. Castillo-Olea, and
A. Elmaghraby, “Dementia prediction applying variational quantum
classifier,” <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.08653</span>, 2020.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(68)</span>
<span class="ltx_bibblock">
S. L. Wu, J. Chan, W. Guan, S. Sun, A. Wang, C. Zhou, M. Livny, F. Carminati,
A. Di Meglio, A. C. Li, <span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Application of quantum machine
learning using the quantum variational classifier method to high energy
physics analysis at the lhc on ibm quantum computer simulator and hardware
with 10 qubits,” <span id="bib.bib68.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.11560</span>, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(69)</span>
<span class="ltx_bibblock">
S. Jerbi, C. Gyurik, S. Marshall, H. J. Briegel, and V. Dunjko, “Variational
quantum policies for reinforcement learning,” <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2103.05577</span>, 2021.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(70)</span>
<span class="ltx_bibblock">
Y. Takaki, K. Mitarai, M. Negoro, K. Fujii, and M. Kitagawa, “Learning
temporal data with variational quantum recurrent neural network,” <span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">arXiv
preprint arXiv:2012.11242</span>, 2020.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(71)</span>
<span class="ltx_bibblock">
M. Schuld and F. Petruccione, “Information encoding,” in <span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">Supervised
Learning with Quantum Computers</span>, pp. 139–171, Cham: Springer International
Publishing, 2018.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(72)</span>
<span class="ltx_bibblock">
M. Schuld, V. Bergholm, C. Gogolin, J. Izaac, and N. Killoran, “Evaluating
analytic gradients on quantum hardware,” <span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Physical Review A</span>, vol. 99,
no. 3, p. 032331, 2019.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(73)</span>
<span class="ltx_bibblock">
V. Bergholm, J. Izaac, M. Schuld, C. Gogolin, C. Blank, K. McKiernan, and
N. Killoran, “Pennylane: Automatic differentiation of hybrid
quantum-classical computations,” <span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1811.04968</span>,
2018.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(74)</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga, <span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Pytorch: An imperative
style, high-performance deep learning library,” in <span id="bib.bib74.2.2" class="ltx_text ltx_font_italic">Advances in neural
information processing systems</span>, pp. 8026–8037, 2019.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(75)</span>
<span class="ltx_bibblock">
Y. Suzuki, Y. Kawase, Y. Masumura, Y. Hiraga, M. Nakadai, J. Chen, K. M.
Nakanishi, K. Mitarai, R. Imai, S. Tamiya, <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Qulacs: a fast and
versatile quantum circuit simulator for research purpose,” <span id="bib.bib75.2.2" class="ltx_text ltx_font_italic">arXiv
preprint arXiv:2011.13524</span>, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(76)</span>
<span class="ltx_bibblock">
J. Elson, J. J. Douceur, J. Howell, and J. Saul, “Asirra: A captcha that
exploits interest-aligned manual image categorization,” in <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">Proceedings
of 14th ACM Conference on Computer and Communications Security (CCS)</span>,
Association for Computing Machinery, Inc., October 2007.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(77)</span>
<span class="ltx_bibblock">
A. Krizhevsky, “Learning multiple layers of features from tiny images,” tech.
rep., 2009.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(78)</span>
<span class="ltx_bibblock">
C. Dwork, A. Roth, <span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The algorithmic foundations of differential
privacy.,” <span id="bib.bib78.2.2" class="ltx_text ltx_font_italic">Foundations and Trends in Theoretical Computer Science</span>,
vol. 9, no. 3-4, pp. 211–407, 2014.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(79)</span>
<span class="ltx_bibblock">
M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that
exploit confidence information and basic countermeasures,” in <span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications
Security</span>, pp. 1322–1333, 2015.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(80)</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference
attacks against machine learning models,” in <span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">2017 IEEE Symposium on
Security and Privacy (SP)</span>, pp. 3–18, IEEE, 2017.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(81)</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang, “Deep learning with differential privacy,” in <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">Proceedings of
the 2016 ACM SIGSAC conference on computer and communications security</span>,
pp. 308–318, 2016.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(82)</span>
<span class="ltx_bibblock">
S. Goryczka, L. Xiong, and V. Sunderam, “Secure multiparty aggregation with
differential privacy: A comparative study,” in <span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">Proceedings of the Joint
EDBT/ICDT 2013 Workshops</span>, pp. 155–163, 2013.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(83)</span>
<span class="ltx_bibblock">
K. Pillutla, S. M. Kakade, and Z. Harchaoui, “Robust aggregation for federated
learning,” <span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.13445</span>, 2019.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(84)</span>
<span class="ltx_bibblock">
F. Ang, L. Chen, N. Zhao, Y. Chen, W. Wang, and F. R. Yu, “Robust federated
learning with noisy communication,” <span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on
Communications</span>, vol. 68, no. 6, pp. 3452–3464, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(85)</span>
<span class="ltx_bibblock">
S. Savazzi, M. Nicoli, and V. Rampa, “Federated learning with cooperating
devices: A consensus approach for massive iot networks,” <span id="bib.bib85.1.1" class="ltx_text ltx_font_italic">IEEE Internet
of Things Journal</span>, vol. 7, no. 5, pp. 4641–4654, 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(86)</span>
<span class="ltx_bibblock">
T. Wittkopp and A. Acker, “Decentralized federated learning preserves model
and data privacy,” <span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.00880</span>, 2021.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(87)</span>
<span class="ltx_bibblock">
S. R. Pokhrel and J. Choi, “A decentralized federated learning approach for
connected autonomous vehicles,” in <span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">2020 IEEE Wireless Communications
and Networking Conference Workshops (WCNCW)</span>, pp. 1–6, IEEE, 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(88)</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konečnỳ, S. Mazzocchi, H. B. McMahan, <span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">et al.</span>,
“Towards federated learning at scale: System design,” <span id="bib.bib88.2.2" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1902.01046</span>, 2019.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(89)</span>
<span class="ltx_bibblock">
Y. Xiao, Y. Ye, S. Huang, L. Hao, Z. Ma, M. Xiao, and S. Mumtaz, “Fully
decentralized federated learning based beamforming design for uav
communications,” <span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.13614</span>, 2020.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(90)</span>
<span class="ltx_bibblock">
A. Lalitha, S. Shekhar, T. Javidi, and F. Koushanfar, “Fully decentralized
federated learning,” in <span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">Third workshop on Bayesian Deep Learning
(NeurIPS)</span>, 2018.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(91)</span>
<span class="ltx_bibblock">
S. Lu, Y. Zhang, and Y. Wang, “Decentralized federated learning for electronic
health records,” in <span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">2020 54th Annual Conference on Information Sciences
and Systems (CISS)</span>, pp. 1–5, IEEE, 2020.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(92)</span>
<span class="ltx_bibblock">
S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” <span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">bitcoin.org</span>, 2008.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(93)</span>
<span class="ltx_bibblock">
G. Zyskind, O. Nathan, <span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Decentralizing privacy: Using blockchain
to protect personal data,” in <span id="bib.bib93.2.2" class="ltx_text ltx_font_italic">2015 IEEE Security and Privacy
Workshops</span>, pp. 180–184, IEEE, 2015.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(94)</span>
<span class="ltx_bibblock">
W. Cai, Z. Wang, J. B. Ernst, Z. Hong, C. Feng, and V. C. Leung,
“Decentralized applications: The blockchain-empowered software system,”
<span id="bib.bib94.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, vol. 6, pp. 53019–53033, 2018.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(95)</span>
<span class="ltx_bibblock">
K. D. Pandl, S. Thiebes, M. Schmidt-Kraepelin, and A. Sunyaev, “On the
convergence of artificial intelligence and distributed ledger technology: A
scoping review and future research agenda,” <span id="bib.bib95.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, vol. 8,
pp. 57075–57095, 2020.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(96)</span>
<span class="ltx_bibblock">
Y. Qu, L. Gao, T. H. Luan, Y. Xiang, S. Yu, B. Li, and G. Zheng,
“Decentralized privacy using blockchain-enabled federated learning in fog
computing,” <span id="bib.bib96.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, vol. 7, no. 6,
pp. 5171–5183, 2020.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(97)</span>
<span class="ltx_bibblock">
P. Ramanan and K. Nakayama, “Baffle: Blockchain based aggregator free
federated learning,” in <span id="bib.bib97.1.1" class="ltx_text ltx_font_italic">2020 IEEE International Conference on
Blockchain (Blockchain)</span>, pp. 72–81, IEEE, 2020.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(98)</span>
<span class="ltx_bibblock">
S. Awan, F. Li, B. Luo, and M. Liu, “Poster: A reliable and accountable
privacy-preserving federated learning framework using the blockchain,” in
<span id="bib.bib98.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security</span>, pp. 2561–2563, 2019.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(99)</span>
<span class="ltx_bibblock">
Y. Qu, S. R. Pokhrel, S. Garg, L. Gao, and Y. Xiang, “A blockchained federated
learning framework for cognitive computing in industry 4.0 networks,” <span id="bib.bib99.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 2020.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(100)</span>
<span class="ltx_bibblock">
Y. Zhao, J. Zhao, L. Jiang, R. Tan, D. Niyato, Z. Li, L. Lyu, and Y. Liu,
“Privacy-preserving blockchain-based federated learning for iot devices,”
<span id="bib.bib100.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2020.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(101)</span>
<span class="ltx_bibblock">
X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu, “Flchain: A blockchain for
auditable federated learning with trust and incentive,” in <span id="bib.bib101.1.1" class="ltx_text ltx_font_italic">2019 5th
International Conference on Big Data Computing and Communications (BIGCOM)</span>,
pp. 151–159, IEEE, 2019.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(102)</span>
<span class="ltx_bibblock">
H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained on-device federated
learning,” <span id="bib.bib102.1.1" class="ltx_text ltx_font_italic">IEEE Communications Letters</span>, vol. 24, no. 6,
pp. 1279–1283, 2019.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(103)</span>
<span class="ltx_bibblock">
Y. Liu, Z. Ai, S. Sun, S. Zhang, Z. Liu, and H. Yu, “Fedcoin: A peer-to-peer
payment system for federated learning,” in <span id="bib.bib103.1.1" class="ltx_text ltx_font_italic">Federated Learning</span>,
pp. 125–138, Springer, 2020.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(104)</span>
<span class="ltx_bibblock">
A. G. Roy, S. Siddiqui, S. Pölsterl, N. Navab, and C. Wachinger,
“Braintorrent: A peer-to-peer environment for decentralized federated
learning,” <span id="bib.bib104.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1905.06731</span>, 2019.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(105)</span>
<span class="ltx_bibblock">
A. Lalitha, O. C. Kilinc, T. Javidi, and F. Koushanfar, “Peer-to-peer
federated learning on graphs,” <span id="bib.bib105.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1901.11173</span>, 2019.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(106)</span>
<span class="ltx_bibblock">
I. Hegedűs, Á. Berta, L. Kocsis, A. A. Benczúr, and M. Jelasity,
“Robust decentralized low-rank matrix decomposition,” <span id="bib.bib106.1.1" class="ltx_text ltx_font_italic">ACM Transactions
on Intelligent Systems and Technology (TIST)</span>, vol. 7, no. 4, pp. 1–24,
2016.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(107)</span>
<span class="ltx_bibblock">
R. Ormándi, I. Hegedűs, and M. Jelasity, “Gossip learning with
linear models on fully distributed data,” <span id="bib.bib107.1.1" class="ltx_text ltx_font_italic">Concurrency and Computation:
Practice and Experience</span>, vol. 25, no. 4, pp. 556–571, 2013.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(108)</span>
<span class="ltx_bibblock">
I. Hegedűs, G. Danner, and M. Jelasity, “Gossip learning as a
decentralized alternative to federated learning,” in <span id="bib.bib108.1.1" class="ltx_text ltx_font_italic">IFIP International
Conference on Distributed Applications and Interoperable Systems</span>,
pp. 74–90, Springer, 2019.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(109)</span>
<span class="ltx_bibblock">
I. Hegedűs, G. Danner, and M. Jelasity, “Decentralized recommendation
based on matrix factorization: a comparison of gossip and federated
learning,” in <span id="bib.bib109.1.1" class="ltx_text ltx_font_italic">Joint European Conference on Machine Learning and
Knowledge Discovery in Databases</span>, pp. 317–332, Springer, 2019.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(110)</span>
<span class="ltx_bibblock">
I. Hegedűs, G. Danner, and M. Jelasity, “Decentralized learning works:
An empirical comparison of gossip learning and federated learning,” <span id="bib.bib110.1.1" class="ltx_text ltx_font_italic">Journal of Parallel and Distributed Computing</span>, vol. 148, pp. 109–124, 2021.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(111)</span>
<span class="ltx_bibblock">
C. Hu, J. Jiang, and Z. Wang, “Decentralized federated learning: a segmented
gossip approach,” <span id="bib.bib111.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1908.07782</span>, 2019.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(112)</span>
<span class="ltx_bibblock">
A. Sergeev and M. D. Balso, “Horovod: fast and easy distributed deep learning
in TensorFlow,” <span id="bib.bib112.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1802.05799</span>, 2018.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(113)</span>
<span class="ltx_bibblock">
S. Y.-C. Chen, C.-M. Huang, C.-W. Hsing, and Y.-J. Kao, “An end-to-end
trainable hybrid classical-quantum classifier,” <span id="bib.bib113.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:2102.02416</span>, 2021.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(114)</span>
<span class="ltx_bibblock">
I. Cong, S. Choi, and M. D. Lukin, “Quantum convolutional neural networks,”
<span id="bib.bib114.1.1" class="ltx_text ltx_font_italic">Nature Physics</span>, vol. 15, no. 12, pp. 1273–1278, 2019.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(115)</span>
<span class="ltx_bibblock">
Y. Li, R.-G. Zhou, R. Xu, J. Luo, and W. Hu, “A quantum deep convolutional
neural network for image recognition,” <span id="bib.bib115.1.1" class="ltx_text ltx_font_italic">Quantum Science and Technology</span>,
vol. 5, no. 4, p. 044003, 2020.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(116)</span>
<span class="ltx_bibblock">
S. Oh, J. Choi, and J. Kim, “A tutorial on quantum convolutional neural
networks (qcnn),” <span id="bib.bib116.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.09423</span>, 2020.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(117)</span>
<span class="ltx_bibblock">
I. Kerenidis, J. Landman, and A. Prakash, “Quantum algorithms for deep
convolutional neural networks,” <span id="bib.bib117.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.01117</span>, 2019.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(118)</span>
<span class="ltx_bibblock">
J. Liu, K. H. Lim, K. L. Wood, W. Huang, C. Guo, and H.-L. Huang, “Hybrid
quantum-classical convolutional neural networks,” <span id="bib.bib118.1.1" class="ltx_text ltx_font_italic">arXiv preprint
arXiv:1911.02998</span>, 2019.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(119)</span>
<span class="ltx_bibblock">
J. Qi, C.-H. H. Yang, and J. Tejedor, “Submodular rank aggregation on
score-based permutations for distributed automatic speech recognition,” in
<span id="bib.bib119.1.1" class="ltx_text ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</span>, pp. 3517–3521, IEEE, 2020.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(120)</span>
<span class="ltx_bibblock">
D. J. Egger, C. Gambella, J. Marecek, S. McFaddin, M. Mevissen, R. Raymond,
A. Simonetto, S. Woerner, and E. Yndurain, “Quantum computing for finance:
state of the art and future prospects,” <span id="bib.bib120.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Quantum
Engineering</span>, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2103.12009" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2103.12010" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2103.12010">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2103.12010" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2103.12011" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 12 15:18:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
