<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification</title>
<!--Generated on Fri May 17 06:28:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="E-commerce Search, 
Attribute Tagging, 
Named Entity Recognition, 
Partially-labeled Data, 
Seq2Seq models, 
Token Classification models
" lang="en" name="keywords"/>
<base href="/html/2405.10918v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S1" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S2" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S3" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S4" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S4.SS1" title="In 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Generative Attribute-Value Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S4.SS2" title="In 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Token Classification Attribute-Value Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S4.SS3" title="In 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span><span class="ltx_text ltx_font_smallcaps">GenToC</span>: Generative Attribute Extraction + Token Classification Value Extraction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.SS1" title="In 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Dataset and Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.SS2" title="In 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Implementation and Systems Compared</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Experiments and Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS1" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Comparison with Other Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS2" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS3" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Bootstrapping Training Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS4" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Precision-Recall Trade-off</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS5" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Performance on Long Product Names</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S7" title="In GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id1.id1">GenToC</span>: Leveraging Partially-Labeled Data for Product Attribute-Value Identification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">D. Subhalingam
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:subhalingam.d@knowdis.ai">subhalingam.d@knowdis.ai</a>
</span></span></span>
<span class="ltx_author_before">,¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Keshav Kolluru
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:keshav.kolluru@knowdis.ai">keshav.kolluru@knowdis.ai</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">KnowDis AI</span><span class="ltx_text ltx_affiliation_state" id="id3.2.id2">Delhi</span><span class="ltx_text ltx_affiliation_country" id="id4.3.id3">India</span>
</span></span></span>
<span class="ltx_author_before">,¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mausam
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mausam@cse.iitd.ac.in">mausam@cse.iitd.ac.in</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Indian Institute of Technology, Delhi</span><span class="ltx_text ltx_affiliation_state" id="id6.2.id2">Delhi</span><span class="ltx_text ltx_affiliation_country" id="id7.3.id3">India</span>
</span></span></span>
<span class="ltx_author_before">¬†and¬†</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Saurabh Singal
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:saurabh@knowdis.ai">saurabh@knowdis.ai</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">KnowDis AI</span><span class="ltx_text ltx_affiliation_state" id="id9.2.id2">Delhi</span><span class="ltx_text ltx_affiliation_country" id="id10.3.id3">India</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id11.id1">In the e-commerce domain, the accurate extraction of attribute-value pairs from product listings (e.g., <span class="ltx_text ltx_font_smallcaps" id="id11.id1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="id11.id1.2">Apple</span>) is crucial for enhancing search and recommendation systems.
The automation of this extraction process is challenging due to the vast diversity of product categories and their respective attributes, compounded by the lack of extensive, accurately annotated training datasets and the demand for low latency to meet the real-time needs of e-commerce platforms.
To address these challenges, we introduce <span class="ltx_text ltx_font_smallcaps" id="id11.id1.3">GenToC</span>, a novel two-stage model for extracting attribute-value pairs from product titles.
<span class="ltx_text ltx_font_smallcaps" id="id11.id1.4">GenToC</span> is designed to train with partially-labeled data, leveraging incomplete attribute-value pairs and obviating the need for a fully annotated dataset.
The first stage uses a marker-augmented generative model to propose potential attributes, followed by a token classification model that determines the associated values for each attribute.
<span class="ltx_text ltx_font_smallcaps" id="id11.id1.5">GenToC</span> outperforms existing state-of-the-art models, exhibiting upto 56.3% increase in the number of accurate extractions.</p>
<p class="ltx_p" id="id12.id2">Moreover, we introduce a bootstrapping method that enables <span class="ltx_text ltx_font_smallcaps" id="id12.id2.1">GenToC</span> to progressively refine and expand its training dataset.
This enhancement substantially improves the quality of data available for training other neural network models that are typically faster but are inherently less capable than <span class="ltx_text ltx_font_smallcaps" id="id12.id2.2">GenToC</span> in terms of their capacity to handle partially-labeled data.
By supplying an enriched dataset for training, <span class="ltx_text ltx_font_smallcaps" id="id12.id2.3">GenToC</span> significantly advances the performance of these alternative models, making them more suitable for real-time deployment.
Our results highlight the unique capability of <span class="ltx_text ltx_font_smallcaps" id="id12.id2.4">GenToC</span> to learn from a limited set of labeled data and to contribute to the training of more efficient models, marking a significant leap forward in the automated extraction of attribute-value pairs from product titles.
<span class="ltx_text ltx_font_smallcaps" id="id12.id2.5">GenToC</span> has been successfully integrated into India‚Äôs largest B2B e-commerce platform, <a class="ltx_ref ltx_href" href="http://www.indiamart.com" title="">IndiaMART.com</a>, achieving a significant increase of 21.1% in the number of correctly identified attribute-value pairs over the existing deployed system while achieving a high precision of 89.5%.</p>
</div>
<div class="ltx_keywords">E-commerce Search,
Attribute Tagging,
Named Entity Recognition,
Partially-labeled Data,
Seq2Seq models,
Token Classification models

</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03‚Äì05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_price" id="id5"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The rapid expansion of E-Commerce has led to a significant increase in the variety and complexity of products available online.
Every product usually comes with a variety of attributes like <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.1">Brand</span>, <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.2">Color</span>, <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.3">Model</span> and so on, each having specific values, for example, <span class="ltx_text ltx_font_italic" id="S1.p1.1.4">Samsung</span>, <span class="ltx_text ltx_font_italic" id="S1.p1.1.5">Phantom Gray</span>, <span class="ltx_text ltx_font_italic" id="S1.p1.1.6">Galaxy S21</span>, etc. (as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S1.T1" title="In 1. Introduction ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>).
These attributes and values help consumers locate and select their desired products.
Nonetheless, the attribute-value pairs provided in product listings by sellers are often incomplete and can be enhanced using the information contained within the product title.
This problem of automatic attribute-value identification for E-Commerce products is a well-established topic in literature <cite class="ltx_cite ltx_citemacro_citep">(Bing et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib2" title="">2012</a>; Putthividhya and Hu, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib12" title="">2011</a>; Probst et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib11" title="">2007</a>; Shinzato and Sekine, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib17" title="">2013</a>; Roy et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib15" title="">2021</a>; Wang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib22" title="">2020</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>; Zheng et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>)</cite>. It has been investigated in various contexts that sometimes include additional metadata such as product descriptions <cite class="ltx_cite ltx_citemacro_citep">(Yang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib25" title="">2021</a>; Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite>, knowledge graphs <cite class="ltx_cite ltx_citemacro_citep">(Ricatte and Crisostomi, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib14" title="">2023</a>)</cite> or images <cite class="ltx_cite ltx_citemacro_citep">(Zhu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib28" title="">2020</a>; Khandelwal et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib8" title="">2023</a>)</cite>.
In this study, we focus on automated extraction from product titles.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S1.T1.1">
<tr class="ltx_tr" id="S1.T1.1.1">
<td class="ltx_td ltx_align_center" colspan="2" id="S1.T1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1">Product Name</span>: <span class="ltx_text" id="S1.T1.1.1.1.2" style="color:#0000FF;">Boat</span> <span class="ltx_text" id="S1.T1.1.1.1.3" style="color:#808000;">Rockerz 255 Pro</span>
</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.2">
<td class="ltx_td ltx_align_center" colspan="2" id="S1.T1.1.2.1">
<span class="ltx_text" id="S1.T1.1.2.1.1" style="color:#FF0000;">Raging Red</span> <span class="ltx_text" id="S1.T1.1.2.1.2" style="color:#00FFFF;">Bluetooth</span> <span class="ltx_text" id="S1.T1.1.2.1.3" style="color:#BF8040;">Neckband</span>
</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.T1.1.3.1"><span class="ltx_text ltx_font_bold" id="S1.T1.1.3.1.1">Attribute</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.T1.1.3.2"><span class="ltx_text ltx_font_bold" id="S1.T1.1.3.2.1">Value</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.4.1">
<span class="ltx_text ltx_font_smallcaps" id="S1.T1.1.4.1.1">Brand</span>*</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.4.2"><span class="ltx_text ltx_font_italic" id="S1.T1.1.4.2.1" style="color:#0000FF;">Boat</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.5">
<td class="ltx_td ltx_align_left" id="S1.T1.1.5.1">
<span class="ltx_text ltx_font_smallcaps" id="S1.T1.1.5.1.1">Model Name</span>*</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.5.2"><span class="ltx_text ltx_font_italic" id="S1.T1.1.5.2.1" style="color:#808000;">Rockerz 255 Pro</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.6">
<td class="ltx_td ltx_align_left" id="S1.T1.1.6.1">
<span class="ltx_text ltx_font_smallcaps" id="S1.T1.1.6.1.1">Color</span>*</td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.6.2"><span class="ltx_text ltx_font_italic" id="S1.T1.1.6.2.1" style="color:#FF0000;">Raging Red</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.7">
<td class="ltx_td ltx_align_left" id="S1.T1.1.7.1"><span class="ltx_text ltx_font_smallcaps" id="S1.T1.1.7.1.1">Connectivity</span></td>
<td class="ltx_td ltx_align_left" id="S1.T1.1.7.2"><span class="ltx_text ltx_font_italic" id="S1.T1.1.7.2.1" style="color:#00FFFF;">Bluetooth</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S1.T1.1.8.1"><span class="ltx_text ltx_font_smallcaps" id="S1.T1.1.8.1.1">Headphone Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S1.T1.1.8.2"><span class="ltx_text ltx_font_italic" id="S1.T1.1.8.2.1" style="color:#BF8040;">Neckband</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Complete collection of attribute-value pairs covering all words in the specified product name, with only the attributes <span class="ltx_text ltx_font_smallcaps" id="S1.T1.6.1">Brand</span>, <span class="ltx_text ltx_font_smallcaps" id="S1.T1.7.2">Model Name</span> and <span class="ltx_text ltx_font_smallcaps" id="S1.T1.8.3">Color</span> (marked with *) are included in the training data and the remaining attributes are extracted by the <span class="ltx_text ltx_font_smallcaps" id="S1.T1.9.4">GenToC</span> model.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The predominant approach for acquiring training datasets for attribute-value extraction tasks typically relies on leveraging product listings and associated attribute-value pairs as furnished by vendors on E-Commerce platforms.
This method is directly dependent on the comprehensiveness and accuracy of the data that vendors provide.
However, it is common practice for vendors to list these details in an incomplete or inconsistent manner.
Such gaps and irregularities in the data present a substantial obstacle, as the development of effective deep learning models for attribute-value extraction is contingent upon the availability of large-scale, high-quality training data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The complexity of the task is further amplified by the multitude of attributes involved, potentially running into tens of thousands of attributes (24.7K in our case).
At this scale, some attributes end up being redundant, noisy or rarely used which leads to an extremely long-tailed distribution <cite class="ltx_cite ltx_citemacro_citep">(Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>)</cite>.
This redundancy is evident when attributes that fundamentally represent the same product feature ‚Äì <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1">Color</span> and <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.2">Shade</span> or <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.3">Size</span> and <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.4">Dimensions</span> ‚Äì are utilized interchangeably.
Additionally, attribute representation may vary, with instances such as <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.5">Model No.</span> and <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.6">Model Number</span> being treated as distinct attributes despite their equivalence.
This adds complexity to the process of training and evaluating neural models for extracting attribute-value pairs, as these overlapping attributes may differ across various products and categories.
Finally, attribute-value extraction systems are also often used on user query traffic to enable capturing user search intentions effectively <cite class="ltx_cite ltx_citemacro_citep">(Ricatte and Crisostomi, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib14" title="">2023</a>)</cite>.
Therefore, developing systems that deliver responses in real-time is crucial.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address the three challenges outlined, we propose a novel two-stage model, <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">GenToC</span>, which decomposes the task into two distinct phases: initially, it identifies all attributes within a product name, and subsequently, it extracts the corresponding values for each attribute.
Specifically, <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">GenToC</span> employs a <span class="ltx_text ltx_font_bold" id="S1.p4.1.3">Gen</span>erative Seq2Seq model in the initial stage and a <span class="ltx_text ltx_font_bold" id="S1.p4.1.4">To</span>ken <span class="ltx_text ltx_font_bold" id="S1.p4.1.5">C</span>lassification model in the subsequent stage to accurately extract attribute-value pairs from product names.
The first-stage generative model is designed to output all relevant attributes concatenated with each other using a delimiter.
The second-stage token classification model takes as input, each attribute name and the product name and classifies the words in the product name that denote the attribute value.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To foster the model‚Äôs learning capacity using partially-labeled data, we incorporate special <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">markers</span> during the training phase of the first-stage Generative model, which generates all the attributes potentially present in the product name.
These markers are used to highlight the words in the product name that are present as attribute values in training data.
For instance, in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S1.T1" title="In 1. Introduction ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>, markers will be added to the words <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">Boat</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.3">Rockerz</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">255</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.5">Pro</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.6">Raging</span>, <span class="ltx_text ltx_font_italic" id="S1.p5.1.7">Red</span> (at token level) because these are identified as attribute values in the training data.
The markers serve as cues, directing the model to assimilate information from these specified words into the attribute generation process while still taking into account the full context of the product name.
Through the strategic use of these markers, the model is trained to form associations between attributes and the highlighted words, while also understanding that words without markers do not have any attributes associated with them at training.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Through this training methodology, the model becomes adept at generalization during inference, where we apply a marker to every token in the input.
Marking each token prompts the model to treat every word as a potential source of attribute information.
This practice significantly refines the model‚Äôs predictive strategy, as it becomes more attentive to the potential that any word in a product name might be linked to an attribute.
Consequently, the model is not limited to merely mimicking the patterns observed in training but is also capable of anticipating attributes for every word in the product name.
Such a strategy is particularly effective when the model is trained on data that is only partially labeled, enabling it to reliably extract attribute information.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The second-stage token classification model accepts both the attribute name and the product name as input, concatenating them with a special delimiter (<span class="ltx_text ltx_font_italic" id="S1.p7.1.1">¬°sep¬ø</span>).
It is tasked with classifying each word within the product name to ascertain whether it signifies a value for the given input attribute.
In the training phase, we use the attributes that are already known, whereas during inference, we rely on the attributes predicted by the first-stage model.
By using the attribute name directly, we enable synonymous attributes to be embedded closely in the vector space.
This method effectively addresses the second challenge of the model learning independently from each of the closely associated attributes.
So, the training examples for <span class="ltx_text ltx_font_smallcaps" id="S1.p7.1.2">Model No.</span> will influence those for <span class="ltx_text ltx_font_smallcaps" id="S1.p7.1.3">Model Number</span> owing to the similarity in both their semantic representation.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Due to the cascading design of <span class="ltx_text ltx_font_smallcaps" id="S1.p8.1.1">GenToC</span>, errors from the first-stage model can potentially escalate, adversely affecting the second-stage model‚Äôs performance. To fortify the second-stage model against such compounded inaccuracies, we implement a ‚ÄòValue Pruning‚Äô method. This technique equips the value-extraction model with the ability to generate null outputs for any incorrect attributes that might be output by the attribute-extraction model.
Compared to existing state-of-the-art NER models <cite class="ltx_cite ltx_citemacro_citep">(Zheng et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>)</cite> and Generative models <cite class="ltx_cite ltx_citemacro_citep">(Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite> used for attribute-value extraction, <span class="ltx_text ltx_font_smallcaps" id="S1.p8.1.2">GenToC</span> achieves an increase of 16.2% and 18.2% in F1, respectively.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">Motivated by the objective of creating a faster model, we employ <span class="ltx_text ltx_font_smallcaps" id="S1.p9.1.1">GenToC</span> to refine the training dataset by predicting the attribute-value pairs from product names within the training data. This bootstrapping process yields a more exhaustive training set.
Utilizing this augmented dataset to train the faster NER model results in a rise of 20.2% in F1, compared to training on the original dataset, while giving a real-time speed of 8.8 ms per query during inference.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">To summarize, the major contributions of our work include</p>
</div>
<div class="ltx_para" id="S1.p11">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Introduction of <span class="ltx_text ltx_font_smallcaps" id="S1.I1.i1.p1.1.1">GenToC</span>, a novel two-stage architecture integrating a Generative Seq2Seq with a Token Classification model, leading to an F1 score improvement of 15.5% to 19.7% over existing attribute-value extraction techniques.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Implementation of <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">markers</span> in the initial generative model stage to effectively handle the challenge of incomplete attribute-value pair data, a common issue in E-Commerce product listings used to create training data.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Usage of attribute names in second-stage token classification model that allows to mitigate issues of redundancy and noise across thousands of attributes.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">Adoption of bootstrapping to refine training datasets, which leads to strong performance of real-time systems.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Attribute value extraction <cite class="ltx_cite ltx_citemacro_citep">(Nadeau and Sekine, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib10" title="">2007</a>; Bing et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib2" title="">2012</a>; Putthividhya and Hu, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib12" title="">2011</a>; Probst et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib11" title="">2007</a>; Shinzato and Sekine, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib17" title="">2013</a>; Roy et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib15" title="">2021</a>; Wang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib22" title="">2020</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>; Zheng et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>)</cite>
has been a significant topic of study in the realm of E-Commerce, with a wealth of research targeting the extraction of product details from various modalities, including purely text-based methods <cite class="ltx_cite ltx_citemacro_citep">(Wang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib22" title="">2020</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>)</cite> as well as those that incorporate images <cite class="ltx_cite ltx_citemacro_citep">(Zhu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib28" title="">2020</a>; Khandelwal et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib8" title="">2023</a>; Wang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib21" title="">2023</a>)</cite>.
A common limitation of these methods is their assumption of high-quality training data, which fails in many real-world scenarios where the training data is created using distant supervision and hence potentially incomplete <cite class="ltx_cite ltx_citemacro_citep">(Shrimal et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib20" title="">2022</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>)</cite>.
Some publicly available datasets like MAVE <cite class="ltx_cite ltx_citemacro_citep">(Yang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib25" title="">2021</a>)</cite> offer high-quality data (achieving over 98% F1 score), but our work specifically addresses the more challenging case of partially-labeled settings, and therefore, we do not compare with them.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Few works, such as <cite class="ltx_cite ltx_citemacro_citet">Zhang et¬†al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib26" title="">2021</a>); Zheng et¬†al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>)</cite> focus on improving the training data quality in attribute-value extraction task but are severely limited to operating on a small number of attributes only.
For instance, <cite class="ltx_cite ltx_citemacro_citet">Zhang et¬†al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib26" title="">2021</a>)</cite> rely on a subset of strongly-labeled data to train a teacher network which in turn creates training data for a student network.
The requirement of having a strongly-labeled subset limits them to operate on 13 attributes.
<cite class="ltx_cite ltx_citemacro_citet">Zheng et¬†al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>)</cite> also relies on a small set of labeled instances to be used in an active learning setting to collect good examples for manual annotation.
They apply the technique to only one attribute per dataset.
In contrast, <span class="ltx_text ltx_font_smallcaps" id="S2.p2.1.1">GenToC</span> introduces a fundamentally new model design that can handle incomplete training data without requiring any completely labeled subsets.
This allows the model to scale to tens of thousands of attributes.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In terms of modelling, some of the earliest works on attribute value extraction primarily employed rule-based extraction methods.
They utilized a specialized seed dictionary or vocabulary to identify key phrases and attributes <cite class="ltx_cite ltx_citemacro_citep">(Ghani et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib5" title="">2006</a>; Wong et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib23" title="">2009</a>; Gopalakrishnan et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib6" title="">2012</a>)</cite>.
Moving beyond rule-based systems, several neural models have also been proposed for this task in the recent past <cite class="ltx_cite ltx_citemacro_citep">(Roy et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib15" title="">2021</a>)</cite>.
Architectures for this task can be broadly divided into two categories ‚Äì token classification <cite class="ltx_cite ltx_citemacro_citep">(Yang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib25" title="">2021</a>; Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>; Shrimal et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib20" title="">2022</a>)</cite> or generative <cite class="ltx_cite ltx_citemacro_citep">(Roy et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib16" title="">2022</a>; Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite> models.
Token classification models typically identify the spans in the input text corresponding to an attribute.
On the other hand, generative models utilize Seq2Seq models to produce relevant attribute-value pairs from a specified input.
Our <span class="ltx_text ltx_font_smallcaps" id="S2.p3.1.1">GenToC</span> model makes clever use of both the types of architecture, using a generative model for attribute extraction and a token-classification model for value extraction.
We compare extensively with both types of architectures and show significant gains achieved by <span class="ltx_text ltx_font_smallcaps" id="S2.p3.1.2">GenToC</span>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Token classification systems that rely on NER are often limited to the attributes seen in training time <cite class="ltx_cite ltx_citemacro_citep">(Zhang et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib26" title="">2021</a>)</cite>.
Other token-classification systems utilize a BERT+LSTM model to embed each attribute separately <cite class="ltx_cite ltx_citemacro_citep">(Xu et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib24" title="">2019</a>)</cite>.
The embedded representation attends over the product name and identifies the corresponding value.
This allows the inclusion of new attributes at the inference stage.
However, this approach encounters scalability issues as the model must check for values using every possible attribute.
Some generative models <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib8" title="">2023</a>)</cite> are limited in their operation to a relatively small set of attributes (in their case, 38).
This is because they use a seq2seq model pass for every attribute to identify the relevant values.
Other generative models <cite class="ltx_cite ltx_citemacro_citep">(Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite>, are applicable to larger attribute sets as they generate the attribute name as well.
Similarly, <span class="ltx_text ltx_font_smallcaps" id="S2.p4.1.1">GenToC</span> can handle large attribute sets due to a dedicated module that generates all the relevant attributes.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="S2.F1.g1" src="extracted/5602134/assets/GenToC.drawio.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Model architectures.
(a) Gen-AVE ingests the product name and outputs a string that concatenates all attribute-value pairs.
(b) ToC-AVE classifies each word in the product name, tagging it with the relevant attribute.
(c) <span class="ltx_text ltx_font_smallcaps" id="S2.F1.2.1">GenToC</span> employs Gen-AE to yield a concatenated list of attributes and ToC-VE to annotate the values linked to every recognized attribute. The Gen-AE model incorporates markers (‚ÄòM‚Äô) during the training process for the words which are covered. During inference, these markers are applied to all the words in the product name.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Problem Statement</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.10">Given a product name <math alttext="p" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_p</annotation></semantics></math> with <math alttext="k" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_k</annotation></semantics></math> words, <math alttext="p=w_{1}w_{2}\cdots w_{k}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">p</mi><mo id="S3.p1.3.m3.1.1.1" xref="S3.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml"><msub id="S3.p1.3.m3.1.1.3.2" xref="S3.p1.3.m3.1.1.3.2.cmml"><mi id="S3.p1.3.m3.1.1.3.2.2" xref="S3.p1.3.m3.1.1.3.2.2.cmml">w</mi><mn id="S3.p1.3.m3.1.1.3.2.3" xref="S3.p1.3.m3.1.1.3.2.3.cmml">1</mn></msub><mo id="S3.p1.3.m3.1.1.3.1" xref="S3.p1.3.m3.1.1.3.1.cmml">‚Å¢</mo><msub id="S3.p1.3.m3.1.1.3.3" xref="S3.p1.3.m3.1.1.3.3.cmml"><mi id="S3.p1.3.m3.1.1.3.3.2" xref="S3.p1.3.m3.1.1.3.3.2.cmml">w</mi><mn id="S3.p1.3.m3.1.1.3.3.3" xref="S3.p1.3.m3.1.1.3.3.3.cmml">2</mn></msub><mo id="S3.p1.3.m3.1.1.3.1a" xref="S3.p1.3.m3.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.p1.3.m3.1.1.3.4" mathvariant="normal" xref="S3.p1.3.m3.1.1.3.4.cmml">‚ãØ</mi><mo id="S3.p1.3.m3.1.1.3.1b" xref="S3.p1.3.m3.1.1.3.1.cmml">‚Å¢</mo><msub id="S3.p1.3.m3.1.1.3.5" xref="S3.p1.3.m3.1.1.3.5.cmml"><mi id="S3.p1.3.m3.1.1.3.5.2" xref="S3.p1.3.m3.1.1.3.5.2.cmml">w</mi><mi id="S3.p1.3.m3.1.1.3.5.3" xref="S3.p1.3.m3.1.1.3.5.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><eq id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1"></eq><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">ùëù</ci><apply id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3"><times id="S3.p1.3.m3.1.1.3.1.cmml" xref="S3.p1.3.m3.1.1.3.1"></times><apply id="S3.p1.3.m3.1.1.3.2.cmml" xref="S3.p1.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.3.2.1.cmml" xref="S3.p1.3.m3.1.1.3.2">subscript</csymbol><ci id="S3.p1.3.m3.1.1.3.2.2.cmml" xref="S3.p1.3.m3.1.1.3.2.2">ùë§</ci><cn id="S3.p1.3.m3.1.1.3.2.3.cmml" type="integer" xref="S3.p1.3.m3.1.1.3.2.3">1</cn></apply><apply id="S3.p1.3.m3.1.1.3.3.cmml" xref="S3.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.3.3.1.cmml" xref="S3.p1.3.m3.1.1.3.3">subscript</csymbol><ci id="S3.p1.3.m3.1.1.3.3.2.cmml" xref="S3.p1.3.m3.1.1.3.3.2">ùë§</ci><cn id="S3.p1.3.m3.1.1.3.3.3.cmml" type="integer" xref="S3.p1.3.m3.1.1.3.3.3">2</cn></apply><ci id="S3.p1.3.m3.1.1.3.4.cmml" xref="S3.p1.3.m3.1.1.3.4">‚ãØ</ci><apply id="S3.p1.3.m3.1.1.3.5.cmml" xref="S3.p1.3.m3.1.1.3.5"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.3.5.1.cmml" xref="S3.p1.3.m3.1.1.3.5">subscript</csymbol><ci id="S3.p1.3.m3.1.1.3.5.2.cmml" xref="S3.p1.3.m3.1.1.3.5.2">ùë§</ci><ci id="S3.p1.3.m3.1.1.3.5.3.cmml" xref="S3.p1.3.m3.1.1.3.5.3">ùëò</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">p=w_{1}w_{2}\cdots w_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_p = italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ‚ãØ italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and the set of all potential attributes, <math alttext="\mathbb{A}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">ùî∏</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ùî∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathbb{A}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">blackboard_A</annotation></semantics></math>, the objective of attribute-value extraction is to list all possible attribute-value pairings, which can be denoted as <math alttext="\{(a_{1},v_{1}),(a_{2},v_{2}),\cdots,(a_{n},v_{n})\}" class="ltx_Math" display="inline" id="S3.p1.5.m5.4"><semantics id="S3.p1.5.m5.4a"><mrow id="S3.p1.5.m5.4.4.3" xref="S3.p1.5.m5.4.4.4.cmml"><mo id="S3.p1.5.m5.4.4.3.4" stretchy="false" xref="S3.p1.5.m5.4.4.4.cmml">{</mo><mrow id="S3.p1.5.m5.2.2.1.1.2" xref="S3.p1.5.m5.2.2.1.1.3.cmml"><mo id="S3.p1.5.m5.2.2.1.1.2.3" stretchy="false" xref="S3.p1.5.m5.2.2.1.1.3.cmml">(</mo><msub id="S3.p1.5.m5.2.2.1.1.1.1" xref="S3.p1.5.m5.2.2.1.1.1.1.cmml"><mi id="S3.p1.5.m5.2.2.1.1.1.1.2" xref="S3.p1.5.m5.2.2.1.1.1.1.2.cmml">a</mi><mn id="S3.p1.5.m5.2.2.1.1.1.1.3" xref="S3.p1.5.m5.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.5.m5.2.2.1.1.2.4" xref="S3.p1.5.m5.2.2.1.1.3.cmml">,</mo><msub id="S3.p1.5.m5.2.2.1.1.2.2" xref="S3.p1.5.m5.2.2.1.1.2.2.cmml"><mi id="S3.p1.5.m5.2.2.1.1.2.2.2" xref="S3.p1.5.m5.2.2.1.1.2.2.2.cmml">v</mi><mn id="S3.p1.5.m5.2.2.1.1.2.2.3" xref="S3.p1.5.m5.2.2.1.1.2.2.3.cmml">1</mn></msub><mo id="S3.p1.5.m5.2.2.1.1.2.5" stretchy="false" xref="S3.p1.5.m5.2.2.1.1.3.cmml">)</mo></mrow><mo id="S3.p1.5.m5.4.4.3.5" xref="S3.p1.5.m5.4.4.4.cmml">,</mo><mrow id="S3.p1.5.m5.3.3.2.2.2" xref="S3.p1.5.m5.3.3.2.2.3.cmml"><mo id="S3.p1.5.m5.3.3.2.2.2.3" stretchy="false" xref="S3.p1.5.m5.3.3.2.2.3.cmml">(</mo><msub id="S3.p1.5.m5.3.3.2.2.1.1" xref="S3.p1.5.m5.3.3.2.2.1.1.cmml"><mi id="S3.p1.5.m5.3.3.2.2.1.1.2" xref="S3.p1.5.m5.3.3.2.2.1.1.2.cmml">a</mi><mn id="S3.p1.5.m5.3.3.2.2.1.1.3" xref="S3.p1.5.m5.3.3.2.2.1.1.3.cmml">2</mn></msub><mo id="S3.p1.5.m5.3.3.2.2.2.4" xref="S3.p1.5.m5.3.3.2.2.3.cmml">,</mo><msub id="S3.p1.5.m5.3.3.2.2.2.2" xref="S3.p1.5.m5.3.3.2.2.2.2.cmml"><mi id="S3.p1.5.m5.3.3.2.2.2.2.2" xref="S3.p1.5.m5.3.3.2.2.2.2.2.cmml">v</mi><mn id="S3.p1.5.m5.3.3.2.2.2.2.3" xref="S3.p1.5.m5.3.3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.p1.5.m5.3.3.2.2.2.5" stretchy="false" xref="S3.p1.5.m5.3.3.2.2.3.cmml">)</mo></mrow><mo id="S3.p1.5.m5.4.4.3.6" xref="S3.p1.5.m5.4.4.4.cmml">,</mo><mi id="S3.p1.5.m5.1.1" mathvariant="normal" xref="S3.p1.5.m5.1.1.cmml">‚ãØ</mi><mo id="S3.p1.5.m5.4.4.3.7" xref="S3.p1.5.m5.4.4.4.cmml">,</mo><mrow id="S3.p1.5.m5.4.4.3.3.2" xref="S3.p1.5.m5.4.4.3.3.3.cmml"><mo id="S3.p1.5.m5.4.4.3.3.2.3" stretchy="false" xref="S3.p1.5.m5.4.4.3.3.3.cmml">(</mo><msub id="S3.p1.5.m5.4.4.3.3.1.1" xref="S3.p1.5.m5.4.4.3.3.1.1.cmml"><mi id="S3.p1.5.m5.4.4.3.3.1.1.2" xref="S3.p1.5.m5.4.4.3.3.1.1.2.cmml">a</mi><mi id="S3.p1.5.m5.4.4.3.3.1.1.3" xref="S3.p1.5.m5.4.4.3.3.1.1.3.cmml">n</mi></msub><mo id="S3.p1.5.m5.4.4.3.3.2.4" xref="S3.p1.5.m5.4.4.3.3.3.cmml">,</mo><msub id="S3.p1.5.m5.4.4.3.3.2.2" xref="S3.p1.5.m5.4.4.3.3.2.2.cmml"><mi id="S3.p1.5.m5.4.4.3.3.2.2.2" xref="S3.p1.5.m5.4.4.3.3.2.2.2.cmml">v</mi><mi id="S3.p1.5.m5.4.4.3.3.2.2.3" xref="S3.p1.5.m5.4.4.3.3.2.2.3.cmml">n</mi></msub><mo id="S3.p1.5.m5.4.4.3.3.2.5" stretchy="false" xref="S3.p1.5.m5.4.4.3.3.3.cmml">)</mo></mrow><mo id="S3.p1.5.m5.4.4.3.8" stretchy="false" xref="S3.p1.5.m5.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.4b"><set id="S3.p1.5.m5.4.4.4.cmml" xref="S3.p1.5.m5.4.4.3"><interval closure="open" id="S3.p1.5.m5.2.2.1.1.3.cmml" xref="S3.p1.5.m5.2.2.1.1.2"><apply id="S3.p1.5.m5.2.2.1.1.1.1.cmml" xref="S3.p1.5.m5.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.5.m5.2.2.1.1.1.1.1.cmml" xref="S3.p1.5.m5.2.2.1.1.1.1">subscript</csymbol><ci id="S3.p1.5.m5.2.2.1.1.1.1.2.cmml" xref="S3.p1.5.m5.2.2.1.1.1.1.2">ùëé</ci><cn id="S3.p1.5.m5.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.p1.5.m5.2.2.1.1.1.1.3">1</cn></apply><apply id="S3.p1.5.m5.2.2.1.1.2.2.cmml" xref="S3.p1.5.m5.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.5.m5.2.2.1.1.2.2.1.cmml" xref="S3.p1.5.m5.2.2.1.1.2.2">subscript</csymbol><ci id="S3.p1.5.m5.2.2.1.1.2.2.2.cmml" xref="S3.p1.5.m5.2.2.1.1.2.2.2">ùë£</ci><cn id="S3.p1.5.m5.2.2.1.1.2.2.3.cmml" type="integer" xref="S3.p1.5.m5.2.2.1.1.2.2.3">1</cn></apply></interval><interval closure="open" id="S3.p1.5.m5.3.3.2.2.3.cmml" xref="S3.p1.5.m5.3.3.2.2.2"><apply id="S3.p1.5.m5.3.3.2.2.1.1.cmml" xref="S3.p1.5.m5.3.3.2.2.1.1"><csymbol cd="ambiguous" id="S3.p1.5.m5.3.3.2.2.1.1.1.cmml" xref="S3.p1.5.m5.3.3.2.2.1.1">subscript</csymbol><ci id="S3.p1.5.m5.3.3.2.2.1.1.2.cmml" xref="S3.p1.5.m5.3.3.2.2.1.1.2">ùëé</ci><cn id="S3.p1.5.m5.3.3.2.2.1.1.3.cmml" type="integer" xref="S3.p1.5.m5.3.3.2.2.1.1.3">2</cn></apply><apply id="S3.p1.5.m5.3.3.2.2.2.2.cmml" xref="S3.p1.5.m5.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.5.m5.3.3.2.2.2.2.1.cmml" xref="S3.p1.5.m5.3.3.2.2.2.2">subscript</csymbol><ci id="S3.p1.5.m5.3.3.2.2.2.2.2.cmml" xref="S3.p1.5.m5.3.3.2.2.2.2.2">ùë£</ci><cn id="S3.p1.5.m5.3.3.2.2.2.2.3.cmml" type="integer" xref="S3.p1.5.m5.3.3.2.2.2.2.3">2</cn></apply></interval><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">‚ãØ</ci><interval closure="open" id="S3.p1.5.m5.4.4.3.3.3.cmml" xref="S3.p1.5.m5.4.4.3.3.2"><apply id="S3.p1.5.m5.4.4.3.3.1.1.cmml" xref="S3.p1.5.m5.4.4.3.3.1.1"><csymbol cd="ambiguous" id="S3.p1.5.m5.4.4.3.3.1.1.1.cmml" xref="S3.p1.5.m5.4.4.3.3.1.1">subscript</csymbol><ci id="S3.p1.5.m5.4.4.3.3.1.1.2.cmml" xref="S3.p1.5.m5.4.4.3.3.1.1.2">ùëé</ci><ci id="S3.p1.5.m5.4.4.3.3.1.1.3.cmml" xref="S3.p1.5.m5.4.4.3.3.1.1.3">ùëõ</ci></apply><apply id="S3.p1.5.m5.4.4.3.3.2.2.cmml" xref="S3.p1.5.m5.4.4.3.3.2.2"><csymbol cd="ambiguous" id="S3.p1.5.m5.4.4.3.3.2.2.1.cmml" xref="S3.p1.5.m5.4.4.3.3.2.2">subscript</csymbol><ci id="S3.p1.5.m5.4.4.3.3.2.2.2.cmml" xref="S3.p1.5.m5.4.4.3.3.2.2.2">ùë£</ci><ci id="S3.p1.5.m5.4.4.3.3.2.2.3.cmml" xref="S3.p1.5.m5.4.4.3.3.2.2.3">ùëõ</ci></apply></interval></set></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.4c">\{(a_{1},v_{1}),(a_{2},v_{2}),\cdots,(a_{n},v_{n})\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.4d">{ ( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ( italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , ‚ãØ , ( italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) }</annotation></semantics></math>, where <math alttext="a_{i}\in\mathbb{A}" class="ltx_Math" display="inline" id="S3.p1.6.m6.1"><semantics id="S3.p1.6.m6.1a"><mrow id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml"><msub id="S3.p1.6.m6.1.1.2" xref="S3.p1.6.m6.1.1.2.cmml"><mi id="S3.p1.6.m6.1.1.2.2" xref="S3.p1.6.m6.1.1.2.2.cmml">a</mi><mi id="S3.p1.6.m6.1.1.2.3" xref="S3.p1.6.m6.1.1.2.3.cmml">i</mi></msub><mo id="S3.p1.6.m6.1.1.1" xref="S3.p1.6.m6.1.1.1.cmml">‚àà</mo><mi id="S3.p1.6.m6.1.1.3" xref="S3.p1.6.m6.1.1.3.cmml">ùî∏</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><apply id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1"><in id="S3.p1.6.m6.1.1.1.cmml" xref="S3.p1.6.m6.1.1.1"></in><apply id="S3.p1.6.m6.1.1.2.cmml" xref="S3.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.2.1.cmml" xref="S3.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.p1.6.m6.1.1.2.2.cmml" xref="S3.p1.6.m6.1.1.2.2">ùëé</ci><ci id="S3.p1.6.m6.1.1.2.3.cmml" xref="S3.p1.6.m6.1.1.2.3">ùëñ</ci></apply><ci id="S3.p1.6.m6.1.1.3.cmml" xref="S3.p1.6.m6.1.1.3">ùî∏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">a_{i}\in\mathbb{A}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà blackboard_A</annotation></semantics></math> and <math alttext="v_{i}" class="ltx_Math" display="inline" id="S3.p1.7.m7.1"><semantics id="S3.p1.7.m7.1a"><msub id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml"><mi id="S3.p1.7.m7.1.1.2" xref="S3.p1.7.m7.1.1.2.cmml">v</mi><mi id="S3.p1.7.m7.1.1.3" xref="S3.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><apply id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p1.7.m7.1.1.1.cmml" xref="S3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.p1.7.m7.1.1.2.cmml" xref="S3.p1.7.m7.1.1.2">ùë£</ci><ci id="S3.p1.7.m7.1.1.3.cmml" xref="S3.p1.7.m7.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">v_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.1d">italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a subset of words in <math alttext="p" class="ltx_Math" display="inline" id="S3.p1.8.m8.1"><semantics id="S3.p1.8.m8.1a"><mi id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.p1.8.m8.1d">italic_p</annotation></semantics></math>.
In our setup, we assume that each word <math alttext="w" class="ltx_Math" display="inline" id="S3.p1.9.m9.1"><semantics id="S3.p1.9.m9.1a"><mi id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">ùë§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.p1.9.m9.1d">italic_w</annotation></semantics></math> in <math alttext="p" class="ltx_Math" display="inline" id="S3.p1.10.m10.1"><semantics id="S3.p1.10.m10.1a"><mi id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><ci id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.p1.10.m10.1d">italic_p</annotation></semantics></math> is linked to a maximum of one attribute.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Models</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we first describe how existing State-of-the-art models use Generative models (Gen-AVE) and Token Classification (ToC-AVE) for attribute-value extraction.
We then proceed with introducing <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">GenToC</span> that combines both generative and token classification in the two stages of the model.
The three models are visually represented in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S2.F1" title="In 2. Related Work ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>, and comparative analysis is presented in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S4.T2" title="In 4.3. GenToC: Generative Attribute Extraction + Token Classification Value Extraction ‚Ä£ 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Generative Attribute-Value Extraction</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.8">Following the architecture proposed in <cite class="ltx_cite ltx_citemacro_citet">Shinzato et¬†al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite>, we design the Gen-AVE model to employ a Seq2Seq model that inputs the product name and yields a concatenated string incorporating the respective attribute-value pairs.
For instance, the encoder takes an input <math alttext="p" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_p</annotation></semantics></math>, and the decoder generates the output string ‚Äò<math alttext="a_{1}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">a</mi><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ùëé</ci><cn id="S4.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">a_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>:<math alttext="v_{1}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">v</mi><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">ùë£</ci><cn id="S4.SS1.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">v_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>,<math alttext="a_{2}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">a</mi><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">ùëé</ci><cn id="S4.SS1.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">a_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>:<math alttext="v_{2}" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><msub id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">v</mi><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">ùë£</ci><cn id="S4.SS1.p1.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">v_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>,<math alttext="\cdots" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mi id="S4.SS1.p1.6.m6.1.1" mathvariant="normal" xref="S4.SS1.p1.6.m6.1.1.cmml">‚ãØ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><ci id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">‚ãØ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">‚ãØ</annotation></semantics></math>, <math alttext="a_{n}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><msub id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml">a</mi><mi id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">ùëé</ci><ci id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">a_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>:<math alttext="v_{n}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1"><semantics id="S4.SS1.p1.8.m8.1a"><msub id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml"><mi id="S4.SS1.p1.8.m8.1.1.2" xref="S4.SS1.p1.8.m8.1.1.2.cmml">v</mi><mi id="S4.SS1.p1.8.m8.1.1.3" xref="S4.SS1.p1.8.m8.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><apply id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S4.SS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.p1.8.m8.1.1.2">ùë£</ci><ci id="S4.SS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.p1.8.m8.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">v_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.1d">italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>‚Äô.
Its challenges are slow inference speed and limited learning ability from partially labeled data.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Token Classification Attribute-Value Extraction</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Following NER models used for the task <cite class="ltx_cite ltx_citemacro_citep">(Rezk et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib13" title="">2019</a>; Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib18" title="">2022</a>)</cite>, ToC-AVE is designed as an encoder-only model that operates by classifying tokens in the product name, where each token in the query is assigned a label corresponding to the relevant attribute.
As a NER model, it treats every attribute as a unique label and is limited to the attributes it has seen during training.
However, its major strength lies in its speed due to the simple encoder-only architecture.
Although it is not capable of effectively learning from partially labeled data, we find that training it with better quality data generated by <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p1.1.1">GenToC</span>, results in a fast and powerful attribute-value extraction system.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span><span class="ltx_text ltx_font_smallcaps" id="S4.SS3.1.1">GenToC</span>: Generative Attribute Extraction + Token Classification Value Extraction</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Our proposed model, <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p1.1.1">GenToC</span>, operates as a two-step pipeline.
The initial step employs a Generative Attribute Extraction (Gen-AE) model, which takes the product name as input and subsequently generates a concatenated list of predicted attributes.
The model is trained to generate attributes in the order their values occur in the product name.
Given the model‚Äôs generative ability, it might generate attributes outside the initial set. However, these are often relevant, so we forgo constrained generation <cite class="ltx_cite ltx_citemacro_citep">(De Cao et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib3" title="">2021</a>)</cite>, avoiding any restrictions forcing the attributes to belong solely to the original set of attributes, <math alttext="\mathbb{A}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">ùî∏</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ùî∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathbb{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">blackboard_A</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Markers: </span>
To deal with partially-labeled training data, we initially identify the words within the product name that correspond to values of any attribute. We refer to these identified words as <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.2">marked words</span>.
For the example in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S1.T1" title="In 1. Introduction ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>, [<span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.3">boat</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.4">rockerz</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.5">255</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.6">pro</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.7">raging</span>, <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.8">red</span>] are treated as marked words during training, as they have been labeled with some attribute.
A special learnable embedding, termed as ‚Äú<span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.9">marker embedding</span>‚Äù, is added to the encoder‚Äôs final hidden states of every token of the marked words before being passed to the decoder.
The same learnable embedding is shared across all tokens everywhere.
The model is then able to learn that the output attributes, as observed in the training data, are a result of considering only the limited set of words in the input that have been marked.
Consequently, the marker embeddings act as signals that instruct the model to focus on and incorporate the information from these marked words into its attribute generation process, while preserving the broader context of the product name.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">When it comes to inference, the marker embedding is applied to all words within the product name, nudging the model to generalize and output attributes that are relevant to any word present in the product name.
This enhances the model‚Äôs capability to recognize and associate attributes with words like <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">bluetooth</span> and <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.2">neckband</span>, which did not have valid attribute-value pairs annotated and hence were not marked at training time.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">In the next stage, a Token Classification Value Extraction (ToC-VE) model takes each of the attribute names from the first stage along with the original product name, separated by a special delimiter, <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.1">¬°sep¬ø</span>.
It then labels each token with a binary value, for <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.2">yes</span> or <span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.3">no</span>, to denote whether it corresponds to a value or not for the chosen attribute.
This model is trained independently of the first-stage model.
Since attribute names are used in the training process, it allows the model to learn from closely related attributes which share similarities in the attribute names.
This becomes particularly crucial when dealing with a noisy attribute name ontology, which may include different attribute names conveying the same property, such as <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p4.1.4">Model Number</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p4.1.5">Model No</span>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1">Value Pruning:</span>
When training the ToC-VE model with a set of attribute-value pairs, it always contains a value for every attribute.
However, during the inference phase, it depends on attributes produced by the Gen-AE model.
As a consequence, even when the Gen-AE model generates incorrect attributes, the ToC-VE model tends to assign some value to them.
To counteract this, we supplement the ToC-VE training with additional data to identify instances where no correct value is present for a given attribute.
We accomplish this by taking an existing attribute-value pair and deleting the value from the product name.
Consequently, we ensure that the chosen attribute no longer appears in the product name, training the model to label all tokens as ‚ÄòNO‚Äô values for the attribute.
For example, if we remove the brand, ‚Äòboat‚Äô, the example, ‚Äòbrand <span class="ltx_text ltx_font_italic" id="S4.SS3.p5.1.2">¬°sep¬ø</span> rockerz 255 pro raging red bluetooth neckband‚Äô, will have no value for the attribute <span class="ltx_text ltx_font_italic" id="S4.SS3.p5.1.3">brand</span>.
We term the generation of this kind of synthetic training data as Value Pruning.
For the final set of attribute-value pairs yielded by the model, we exclude those attributes that do not have any associated values.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tr class="ltx_tr" id="S4.T2.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1">Architecture</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2">
<span class="ltx_text" id="S4.T2.1.1.2.1"></span> <span class="ltx_text" id="S4.T2.1.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.2.2.1">
<span class="ltx_tr" id="S4.T2.1.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.2.1.1.1">Partially</span></span>
<span class="ltx_tr" id="S4.T2.1.1.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.2.1.2.1">labeled</span></span>
</span></span><span class="ltx_text" id="S4.T2.1.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3">
<span class="ltx_text" id="S4.T2.1.1.3.1"></span> <span class="ltx_text" id="S4.T2.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.3.2.1">
<span class="ltx_tr" id="S4.T2.1.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.3.2.1.1.1">Redundant</span></span>
<span class="ltx_tr" id="S4.T2.1.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.3.2.1.2.1">attributes</span></span>
</span></span><span class="ltx_text" id="S4.T2.1.1.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4">
<span class="ltx_text" id="S4.T2.1.1.4.1"></span> <span class="ltx_text" id="S4.T2.1.1.4.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.4.2.1">
<span class="ltx_tr" id="S4.T2.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.4.2.1.1.1">Response</span></span>
<span class="ltx_tr" id="S4.T2.1.1.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.4.2.1.2.1">time</span></span>
</span></span><span class="ltx_text" id="S4.T2.1.1.4.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.2.1">ToC-AVE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2">‚úó</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.3">‚úó</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.4">fastest</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3">
<td class="ltx_td ltx_align_left" id="S4.T2.1.3.1">Gen-AVE</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2">‚úó</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.3">‚úì</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.4">slow</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T2.1.4.1">GenToC</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.4.2">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.4.3">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.4.4">slow</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparison of different architectures.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">Therefore, the architecture of <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p6.1.1">GenToC</span> ensures effective attribute-value pair extraction, preventing error build-up in the pipeline, even in the face of partially labeled data and vast attribute sets that contain redundancies.
The complete algorithm for training and inference are described in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#alg1" title="In 4.3. GenToC: Generative Attribute Extraction + Token Classification Value Extraction ‚Ä£ 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Algorithm</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#alg2" title="In 4.3. GenToC: Generative Attribute Extraction + Token Classification Value Extraction ‚Ä£ 4. Models ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Algorithm</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>, respectively.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> Training algorithm for <span class="ltx_text ltx_font_smallcaps" id="alg1.4.2">GenToC</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg1.5">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_text ltx_markedasmath ltx_font_bold" id="alg1.l1.1">Input:</span> Set of ¬°Product name, Incomplete attribute-value pairs¬ø

</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_text ltx_markedasmath ltx_font_bold" id="alg1.l2.1">Output:</span> Gen-AE and ToC-VE models

</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_text ltx_font_bold" id="alg1.l3.1">Training Gen-AE Model:</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_text ltx_font_bold" id="alg1.l4.1">for</span>¬†¬°product name, attribute-value pairs¬ø in training set¬†<span class="ltx_text ltx_font_bold" id="alg1.l4.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l5">¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l5.1">Step-1:</span> Tag the words as <span class="ltx_text ltx_font_italic" id="alg1.l5.2">marked</span> in the product name if they are present in any of the attribute values.

</div>
<div class="ltx_listingline" id="alg1.l6">¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l6.1">Step-2:</span> Train Gen-AE with marker embeddings added to the encoder‚Äôs hidden states of the marked words.

</div>
<div class="ltx_listingline" id="alg1.l7">¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l7.1">Step-3:</span> Gen-AE generates is trained to generate the attribute list in order of occurrence in their product name.

</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_text ltx_font_bold" id="alg1.l8.1">end</span>¬†<span class="ltx_text ltx_font_bold" id="alg1.l8.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_text ltx_font_bold" id="alg1.l10.1">Training ToC-VE Model:</span>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_text ltx_font_bold" id="alg1.l11.1">for</span>¬†each product name in training set¬†<span class="ltx_text ltx_font_bold" id="alg1.l11.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l12">¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_bold" id="alg1.l12.1">for</span>¬†each attribute-value pair associated with the product name¬†<span class="ltx_text ltx_font_bold" id="alg1.l12.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l13">¬†¬†¬†¬†¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l13.1">Step 1:</span> Concatenate both the attribute name and product name with <span class="ltx_text ltx_font_italic" id="alg1.l13.2">¬°sep¬ø</span> delimiter.

</div>
<div class="ltx_listingline" id="alg1.l14">¬†¬†¬†¬†¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l14.1">Step 2:</span> Label tokens as ‚ÄòYES‚Äô if they are present in the value for the attribute; otherwise ‚ÄòNO‚Äô.

</div>
<div class="ltx_listingline" id="alg1.l15">¬†¬†¬†¬†¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l15.1">Step 3:</span> Apply Value Pruning to create examples with no values for a particular attribute.

</div>
<div class="ltx_listingline" id="alg1.l16">¬†¬†¬†¬†¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_italic" id="alg1.l16.1">Step 4:</span> Train ToC-VE model for binary classification of token values (‚ÄòYES‚Äô/‚ÄòNO‚Äô).

</div>
<div class="ltx_listingline" id="alg1.l17">¬†¬†¬†¬†¬†<span class="ltx_text ltx_font_bold" id="alg1.l17.1">end</span>¬†<span class="ltx_text ltx_font_bold" id="alg1.l17.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l18">
<span class="ltx_text ltx_font_bold" id="alg1.l18.1">end</span>¬†<span class="ltx_text ltx_font_bold" id="alg1.l18.2">for</span>
</div>
</div>
</figure>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.3.1.1">Algorithm 2</span> </span> Inference algorithm for <span class="ltx_text ltx_font_smallcaps" id="alg2.4.2">GenToC</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg2.5">
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_text ltx_font_bold" id="alg2.l1.1">Input:</span> Product name

</div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_text ltx_font_bold" id="alg2.l2.1">Output:</span> List of attribute-value pairs

</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_text ltx_font_italic" id="alg2.l3.1">Step 1:</span> Tag all words in the product name as <span class="ltx_text ltx_font_italic" id="alg2.l3.2">marked</span>.

</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_text ltx_font_italic" id="alg2.l4.1">Step 2:</span> Use the trained Gen-AE model to predict attributes for the product name with marker embeddings added to encoder hidden states of the marked words.

</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_text ltx_font_italic" id="alg2.l5.1">Step 3:</span> For each predicted attribute from Gen-AE:

</div>
<div class="ltx_listingline" id="alg2.l6">‚ÄÉ<span class="ltx_text ltx_font_italic" id="alg2.l6.1">Step 3.1:</span> Concatenate the predicted attribute and product name with <span class="ltx_text ltx_font_italic" id="alg2.l6.2">¬°sep¬ø</span> delimiter.

</div>
<div class="ltx_listingline" id="alg2.l7">‚ÄÉ<span class="ltx_text ltx_font_italic" id="alg2.l7.1">Step 3.2:</span> Use the trained ToC-VE model to classify each token as a value (‚ÄôYES‚Äô) or not (‚ÄôNO‚Äô).

</div>
<div class="ltx_listingline" id="alg2.l8">‚ÄÉ<span class="ltx_text ltx_font_italic" id="alg2.l8.1">Step 3.3:</span> Extract values for each attribute, excluding attributes with no associated values.

</div>
</div>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experimental Setup</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Dataset and Metrics</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">To curate data for the attribute-value extraction task, we make use of the product specifications that are provided by the sellers for product listings on IndiaMART<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.indiamart.com" title="">https://www.indiamart.com</a></span></span></span>.
IndiaMART is India‚Äôs largest online B2B marketplace, connecting 182M buyers with 7.7M suppliers and featuring over 102M different products and services.
We use a set of 2M examples for training models in this work.
It comprises 715K unique attribute-value pairs covering 24.7K attributes.
The category-wise distribution of products is presented in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.F2" title="In 5.1. Dataset and Metrics ‚Ä£ 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>.
<a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.T3" title="In 5.1. Dataset and Metrics ‚Ä£ 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">3</span></a> lists the top-five attributes and provides a set of example values for each.
Despite the large scale of attributes, only 40.7% of the words of a product name are tagged on average with an attribute.
This motivates us to build models designed for partially labeled data, where the present attribute-value pairs are reliable and of high quality but might lack the complete set of attribute-values.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="770" id="S5.F2.g1" src="extracted/5602134/assets/Chart.png" width="820"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>
Distribution of product categories within training dataset.
Specific percentage values are omitted to preserve data confidentiality.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
<tr class="ltx_tr" id="S5.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1" style="font-size:90%;">Attribute</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S5.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.1" style="font-size:90%;">Values</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.2.1.1" style="font-size:90%;">Brand</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S5.T3.1.2.2">
<span class="ltx_text ltx_font_italic" id="S5.T3.1.2.2.1" style="font-size:90%;">hp</span><span class="ltx_text" id="S5.T3.1.2.2.2" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.2.2.3" style="font-size:90%;">samsung</span><span class="ltx_text" id="S5.T3.1.2.2.4" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.2.2.5" style="font-size:90%;">dell</span><span class="ltx_text" id="S5.T3.1.2.2.6" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.2.2.7" style="font-size:90%;">siemens</span><span class="ltx_text" id="S5.T3.1.2.2.8" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.2.2.9" style="font-size:90%;">bosch</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3">
<td class="ltx_td ltx_align_left" id="S5.T3.1.3.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.3.1.1" style="font-size:90%;">Material</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T3.1.3.2">
<span class="ltx_text ltx_font_italic" id="S5.T3.1.3.2.1" style="font-size:90%;">stainless steel</span><span class="ltx_text" id="S5.T3.1.3.2.2" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.3.2.3" style="font-size:90%;">plastic</span><span class="ltx_text" id="S5.T3.1.3.2.4" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.3.2.5" style="font-size:90%;">brass</span><span class="ltx_text" id="S5.T3.1.3.2.6" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.3.2.7" style="font-size:90%;">wooden</span><span class="ltx_text" id="S5.T3.1.3.2.8" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.3.2.9" style="font-size:90%;">cotton</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4">
<td class="ltx_td ltx_align_left" id="S5.T3.1.4.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.4.1.1" style="font-size:90%;">Color</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T3.1.4.2">
<span class="ltx_text ltx_font_italic" id="S5.T3.1.4.2.1" style="font-size:90%;">black</span><span class="ltx_text" id="S5.T3.1.4.2.2" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.4.2.3" style="font-size:90%;">white</span><span class="ltx_text" id="S5.T3.1.4.2.4" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.4.2.5" style="font-size:90%;">blue</span><span class="ltx_text" id="S5.T3.1.4.2.6" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.4.2.7" style="font-size:90%;">red</span><span class="ltx_text" id="S5.T3.1.4.2.8" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.4.2.9" style="font-size:90%;">brown</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5">
<td class="ltx_td ltx_align_left" id="S5.T3.1.5.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.5.1.1" style="font-size:90%;">Model name/number</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T3.1.5.2">
<span class="ltx_text ltx_font_italic" id="S5.T3.1.5.2.1" style="font-size:90%;">n95</span><span class="ltx_text" id="S5.T3.1.5.2.2" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.5.2.3" style="font-size:90%;">classic</span><span class="ltx_text" id="S5.T3.1.5.2.4" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.5.2.5" style="font-size:90%;">12a</span><span class="ltx_text" id="S5.T3.1.5.2.6" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.5.2.7" style="font-size:90%;">kn95</span><span class="ltx_text" id="S5.T3.1.5.2.8" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.5.2.9" style="font-size:90%;">eco</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.1.6.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.6.1.1" style="font-size:90%;">Usage</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S5.T3.1.6.2">
<span class="ltx_text ltx_font_italic" id="S5.T3.1.6.2.1" style="font-size:90%;">industrial</span><span class="ltx_text" id="S5.T3.1.6.2.2" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.6.2.3" style="font-size:90%;">office</span><span class="ltx_text" id="S5.T3.1.6.2.4" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.6.2.5" style="font-size:90%;">kitchen</span><span class="ltx_text" id="S5.T3.1.6.2.6" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.6.2.7" style="font-size:90%;">packaging</span><span class="ltx_text" id="S5.T3.1.6.2.8" style="font-size:90%;">, </span><span class="ltx_text ltx_font_italic" id="S5.T3.1.6.2.9" style="font-size:90%;">home</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3. </span>Top-5 attributes in the dataset (based on frequency), along with a set of example values for each.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">We evaluate the systems on 39,671 samples (<span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">39K</span>) based on the ground truth values available.
We compute the precision, recall and F1-score by comparing the set of attribute-value pairs generated for each input with the ground truth set of attribute-value pairs.
We then report their averages taken across all examples.
However, we find that automatic evaluation is challenging and often unreliable due to the lack of normalization in the attribute names, as the ground truth set can use different attributes to express the same characteristic.
So we randomly sample 2,000 examples (<span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.2">2K</span>) and get every output checked using 3 data annotators (DAs). These annotators are skilled professionals who perform various annotation tasks within our organization.
We consider the majority class assigned by the DAs to determine if a given attribute-value pair is correct/incorrect.
We find that
the inter-annotator agreement, computed using Fleiss‚Äô kappa <cite class="ltx_cite ltx_citemacro_citep">(Fleiss, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib4" title="">1971</a>)</cite>, is <math alttext="\kappa=0.73{}" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">Œ∫</mi><mo id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">0.73</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><eq id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1"></eq><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">ùúÖ</ci><cn id="S5.SS1.p2.1.m1.1.1.3.cmml" type="float" xref="S5.SS1.p2.1.m1.1.1.3">0.73</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\kappa=0.73{}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">italic_Œ∫ = 0.73</annotation></semantics></math>.
Response time is measured by taking the average on the same 2K queries using NVIDIA GeForce RTX 3090 GPU (with batch size of one).</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Implementation and Systems Compared</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To compare <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.1.1">GenToC</span> with the two classes of state-of-art models, we use ToC-AVE as a representative of the available NER-style models <cite class="ltx_cite ltx_citemacro_citep">(Zheng et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib27" title="">2018</a>; Rezk et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib13" title="">2019</a>; Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib18" title="">2022</a>)</cite> and Gen-AVE as a representative of the published generative models <cite class="ltx_cite ltx_citemacro_citep">(Roy et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib16" title="">2022</a>; Shinzato et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib19" title="">2023</a>)</cite>.
We use our own implementations due to lack of availability of standard open-source implementations for the above works.
We use the DeBERTa-V3-Small<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/microsoft/deberta-v3-small" title="">https://hf.co/microsoft/deberta-v3-small</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(He et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib7" title="">2021</a>)</cite> for all the classification tasks and BART-Base<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/facebook/bart-base" title="">https://hf.co/facebook/bart-base</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Lewis et¬†al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#bib.bib9" title="">2019</a>)</cite> for all generation tasks. Both architectures consist of 6 encoder layers, and BART has 6 additional decoder layers.
Due to the need for industry-scale systems to be used by millions of users, we don‚Äôt experiment with LLMs, which are highly resource intensive.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
<tr class="ltx_tr" id="S5.T4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T4.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.1">Architecture</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T4.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.2.1">Automatic Evaluation (39K)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T4.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.1">Manual Evaluation (2K)</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" id="S5.T4.1.1.4" rowspan="2"><span class="ltx_text" id="S5.T4.1.1.4.1">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.1.4.1.1">
<span class="ltx_tr" id="S5.T4.1.1.4.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.1.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.4.1.1.1.1.1">Response Time</span></span></span>
<span class="ltx_tr" id="S5.T4.1.1.4.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.1.4.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.4.1.1.2.1.1">(in ms/query)</span></span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.1.1">Precision</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.2.1">Recall</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.3.1">F1-score</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.4.1">Precision</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.5.1">Recall</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.2.6"><span class="ltx_text ltx_font_bold" id="S5.T4.1.2.6.1">F1-score</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.3.1">ToC-AVE</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.2">80.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.3">60.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.4">68.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.5">90.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.6">52.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.3.7">66.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S5.T4.1.3.8"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.8.1">8.8 <span class="ltx_text" id="S5.T4.1.3.8.1.1" style="font-size:50%;">¬± 1.1</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4">
<td class="ltx_td ltx_align_left" id="S5.T4.1.4.1">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†with Marker</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.2">58.6</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.3">71.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.4">64.3</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.5">66.5</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.6"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.6.1">87.5</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.7">75.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.4.8"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.8.1">8.9 <span class="ltx_text" id="S5.T4.1.4.8.1.1" style="font-size:50%;">¬± 1.1</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.5.1">Gen-AVE</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.2">80.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.3">52.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.4">63.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.5">89.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.6">50.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.5.7">64.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S5.T4.1.5.8">91.9 <span class="ltx_text" id="S5.T4.1.5.8.1" style="font-size:50%;">¬± 23.8</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6">
<td class="ltx_td ltx_align_left" id="S5.T4.1.6.1">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†with Marker</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.2">60.0</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.3">67.9</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.4">63.7</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.5">65.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.6">69.9</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.6.7">67.5</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.6.8">149.4 <span class="ltx_text" id="S5.T4.1.6.8.1" style="font-size:50%;">¬± 43.5</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.7.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T4.1.7.1.1">GenToC</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.2">70.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.3">71.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.7.4.1">71.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.5">86.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.6">80.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.7.7"><span class="ltx_text ltx_font_bold" id="S5.T4.1.7.7.1">83.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S5.T4.1.7.8">90.1 <span class="ltx_text" id="S5.T4.1.7.8.1" style="font-size:50%;">¬± 19.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8">
<td class="ltx_td ltx_align_left" id="S5.T4.1.8.1">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without Marker</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.2.1">80.8</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.3">54.7</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.4">65.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.5.1">92.7</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.6">51.0</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.8.7">65.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.8.8">66.1 <span class="ltx_text" id="S5.T4.1.8.8.1" style="font-size:50%;">¬± 12.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.9">
<td class="ltx_td ltx_align_left" id="S5.T4.1.9.1">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without VP</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.2">66.3</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.3.1">74.3</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.4">70.1</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.5">78.9</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.6">85.4</td>
<td class="ltx_td ltx_align_right" id="S5.T4.1.9.7">82.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S5.T4.1.9.8">86.3 <span class="ltx_text" id="S5.T4.1.9.8.1" style="font-size:50%;">¬± 18.8</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.10">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.1.10.1">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without Marker &amp; VP</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.2">79.7</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.3">55.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.4">65.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.5">90.7</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.6">52.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.10.7">66.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S5.T4.1.10.8">66.5 <span class="ltx_text" id="S5.T4.1.10.8.1" style="font-size:50%;">¬± 12.2</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Model Performance. A comparison of ToC-AVE, Gen-AVE and <span class="ltx_text ltx_font_smallcaps" id="S5.T4.4.1">GenToC</span> models reveals the superior performance of <span class="ltx_text ltx_font_smallcaps" id="S5.T4.5.2">GenToC</span> in both automated and manual evaluation.
However, it comes at the cost of increased response time with respect to ToC-AVE and thus motivates our bootstrapping experiments.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Experiments and Results</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we answer the following questions:</p>
</div>
<div class="ltx_para" id="S6.p2">
<ol class="ltx_enumerate" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1">How does <span class="ltx_text ltx_font_smallcaps" id="S6.I1.i1.p1.1.1">GenToC</span> compare to other models using both automated and manual evaluation?</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1">What is the significance of Markers and Value Pruning in the <span class="ltx_text ltx_font_smallcaps" id="S6.I1.i2.p1.1.1">GenToC</span> system?</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S6.I1.i3.p1">
<p class="ltx_p" id="S6.I1.i3.p1.1">Can <span class="ltx_text ltx_font_smallcaps" id="S6.I1.i3.p1.1.1">GenToC</span> improve training data tagging and thus be used to train faster models?</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S6.I1.i4.p1">
<p class="ltx_p" id="S6.I1.i4.p1.1">Which system is better when considering the trade-off between precision and recall?</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span>
<div class="ltx_para" id="S6.I1.i5.p1">
<p class="ltx_p" id="S6.I1.i5.p1.1">How do the models perform when dealing with long product names?</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_table" id="S6.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T5.1">
<tr class="ltx_tr" id="S6.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T5.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1">Architecture</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T5.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.2.1">Data Source</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S6.T5.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.3.1">Automatic Evaluation (39K)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S6.T5.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.4.1">Manual Evaluation (2K)</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.1.1">Precision</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.2.1">Recall</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.3.1">F1-score</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.4.1">Precision</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.5"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.5.1">Recall</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T5.1.2.6"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.6.1">F1-score</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.3.1">ToC-AVE</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.3.2">ToC-AVE</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.3.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.3.3.1">80.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.3.4">61.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.3.5">69.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.3.6"><span class="ltx_text ltx_font_bold" id="S6.T5.1.3.6.1">90.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.3.7">55.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T5.1.3.8">68.5</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.4">
<td class="ltx_td ltx_align_left" id="S6.T5.1.4.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T5.1.4.1.1">GenToC</span></td>
<td class="ltx_td" id="S6.T5.1.4.2"></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.3">70.7</td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.4">68.8</td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.5">69.7</td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.6">86.8</td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.7">76.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T5.1.4.8">81.5</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.5.1">ToC-AVE</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.5.2"><span class="ltx_text ltx_font_smallcaps" id="S6.T5.1.5.2.1">GenToC</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.5.3">70.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.5.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.5.4.1">72.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.5.5"><span class="ltx_text ltx_font_bold" id="S6.T5.1.5.5.1">71.6</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.5.6">85.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.5.7">81.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T5.1.5.8">83.6</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T5.1.6.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T5.1.6.1.1">GenToC</span></td>
<td class="ltx_td ltx_border_bb" id="S6.T5.1.6.2"></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.6.3">64.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.6.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.6.4.1">72.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.6.5">68.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.6.6">83.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.6.7"><span class="ltx_text ltx_font_bold" id="S6.T5.1.6.7.1">91.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S6.T5.1.6.8"><span class="ltx_text ltx_font_bold" id="S6.T5.1.6.8.1">87.0</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Bootstrapping performance. <span class="ltx_text ltx_font_smallcaps" id="S6.T5.4.1">GenToC</span> and ToC-AVE are re-trained with data bootstrapped from the two models. ToC-AVE with <span class="ltx_text ltx_font_smallcaps" id="S6.T5.5.2">GenToC</span> gives us the best trade-off between performance and speed for deployability.</figcaption>
</figure>
<figure class="ltx_table" id="S6.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T6.1">
<tr class="ltx_tr" id="S6.T6.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1">Product Name</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.2.1">ToC-AVE</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.3.1">Gen-AVE</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.4.1">GenToC</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.2.1">
<span class="ltx_text" id="S6.T6.1.2.1.1"></span> <span class="ltx_text" id="S6.T6.1.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.2.1.2.1">
<span class="ltx_tr" id="S6.T6.1.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.1.2.1.1.1">Casual Juliet Sleeve Solid</span></span>
<span class="ltx_tr" id="S6.T6.1.2.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.1.2.1.2.1">Women Maroon Top</span></span>
</span></span><span class="ltx_text" id="S6.T6.1.2.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.2.2">
<span class="ltx_text" id="S6.T6.1.2.2.1"></span> <span class="ltx_text" id="S6.T6.1.2.2.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.2.2.2.1">
<span class="ltx_tr" id="S6.T6.1.2.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.2.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.2.2.1.1.1.1">Color</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.2.2.1.1.1.2">Maroon</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.2.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.2.3">
<span class="ltx_text" id="S6.T6.1.2.3.1"></span> <span class="ltx_text" id="S6.T6.1.2.3.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.2.3.2.1">
<span class="ltx_tr" id="S6.T6.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.3.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.3.2.1.1.1.1">Color</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.3.2.1.1.1.2">Maroon</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.2.4">
<span class="ltx_text" id="S6.T6.1.2.4.1"></span> <span class="ltx_text" id="S6.T6.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.2.4.2.1">
<span class="ltx_tr" id="S6.T6.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.4.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.4.2.1.1.1.1">Occasion</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.4.2.1.1.1.2">Casual</span></span></span>
<span class="ltx_tr" id="S6.T6.1.2.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.4.2.1.2.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.4.2.1.2.1.1">Sleeves Type</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.4.2.1.2.1.2">Juliet Sleeve</span></span></span>
<span class="ltx_tr" id="S6.T6.1.2.4.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.4.2.1.3.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.4.2.1.3.1.1">Pattern</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.4.2.1.3.1.2">Solid</span></span></span>
<span class="ltx_tr" id="S6.T6.1.2.4.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.4.2.1.4.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.4.2.1.4.1.1">Gender</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.4.2.1.4.1.2">Women</span></span></span>
<span class="ltx_tr" id="S6.T6.1.2.4.2.1.5">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.2.4.2.1.5.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.2.4.2.1.5.1.1">Color</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.2.4.2.1.5.1.2">Maroon</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.2.4.3"></span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.3.1">
<span class="ltx_text" id="S6.T6.1.3.1.1"></span> <span class="ltx_text" id="S6.T6.1.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.3.1.2.1">
<span class="ltx_tr" id="S6.T6.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.1.2.1.1.1">Sofar Ongrid Inverter</span></span>
<span class="ltx_tr" id="S6.T6.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.1.2.1.2.1">5.5KTL-X 5.5KW Three Phase</span></span>
</span></span><span class="ltx_text" id="S6.T6.1.3.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.3.2">
<span class="ltx_text" id="S6.T6.1.3.2.1"></span> <span class="ltx_text" id="S6.T6.1.3.2.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.3.2.2.1">
<span class="ltx_tr" id="S6.T6.1.3.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.2.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.2.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.2.2.1.1.1.2">Sofar</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.3.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.3.3">
<span class="ltx_text" id="S6.T6.1.3.3.1"></span> <span class="ltx_text" id="S6.T6.1.3.3.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.3.3.2.1">
<span class="ltx_tr" id="S6.T6.1.3.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.3.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.3.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.3.2.1.1.1.2">Sofar</span></span></span>
<span class="ltx_tr" id="S6.T6.1.3.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.3.2.1.2.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.3.2.1.2.1.1">Model</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.3.2.1.2.1.2">5.5KTL-X</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.3.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.3.4">
<span class="ltx_text" id="S6.T6.1.3.4.1"></span> <span class="ltx_text" id="S6.T6.1.3.4.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.3.4.2.1">
<span class="ltx_tr" id="S6.T6.1.3.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.4.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.4.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.4.2.1.1.1.2">Sofar</span></span></span>
<span class="ltx_tr" id="S6.T6.1.3.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.4.2.1.2.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.4.2.1.2.1.1">Grid Type</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.4.2.1.2.1.2">Ongrid</span></span></span>
<span class="ltx_tr" id="S6.T6.1.3.4.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.4.2.1.3.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.4.2.1.3.1.1">Model</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.4.2.1.3.1.2">5.5KTL-X</span></span></span>
<span class="ltx_tr" id="S6.T6.1.3.4.2.1.4">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.4.2.1.4.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.4.2.1.4.1.1">Capacity</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.4.2.1.4.1.2">5.5KW</span></span></span>
<span class="ltx_tr" id="S6.T6.1.3.4.2.1.5">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.3.4.2.1.5.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.3.4.2.1.5.1.1">Phase</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.3.4.2.1.5.1.2">Three Phase</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.3.4.3"></span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.4.1">
<span class="ltx_text" id="S6.T6.1.4.1.1"></span> <span class="ltx_text" id="S6.T6.1.4.1.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.4.1.2.1">
<span class="ltx_tr" id="S6.T6.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.1.2.1.1.1">Globe SS Induction</span></span>
<span class="ltx_tr" id="S6.T6.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.1.2.1.2.1">Pressure Cooker</span></span>
</span></span><span class="ltx_text" id="S6.T6.1.4.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.4.2">
<span class="ltx_text" id="S6.T6.1.4.2.1"></span> <span class="ltx_text" id="S6.T6.1.4.2.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.4.2.2.1">
<span class="ltx_tr" id="S6.T6.1.4.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.2.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.4.2.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.4.2.2.1.1.1.2">Globe</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.4.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.4.3">
<span class="ltx_text" id="S6.T6.1.4.3.1"></span> <span class="ltx_text" id="S6.T6.1.4.3.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.4.3.2.1">
<span class="ltx_tr" id="S6.T6.1.4.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.3.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.4.3.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.4.3.2.1.1.1.2">Globe</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.4.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.4.4">
<span class="ltx_text" id="S6.T6.1.4.4.1"></span> <span class="ltx_text" id="S6.T6.1.4.4.2">
<span class="ltx_tabular ltx_align_middle" id="S6.T6.1.4.4.2.1">
<span class="ltx_tr" id="S6.T6.1.4.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.4.2.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.4.4.2.1.1.1.1">Brand</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.4.4.2.1.1.1.2">Globe</span></span></span>
<span class="ltx_tr" id="S6.T6.1.4.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.4.2.1.2.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.4.4.2.1.2.1.1">Material</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.4.4.2.1.2.1.2">SS</span></span></span>
<span class="ltx_tr" id="S6.T6.1.4.4.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T6.1.4.4.2.1.3.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T6.1.4.4.2.1.3.1.1">Type of Pressure Cookers</span>: <span class="ltx_text ltx_font_italic" id="S6.T6.1.4.4.2.1.3.1.2">Induction</span></span></span>
</span></span><span class="ltx_text" id="S6.T6.1.4.4.3"></span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>Predictions made by the ToC-AVE, Gen-AVE, and <span class="ltx_text ltx_font_smallcaps" id="S6.T6.6.1">GenToC</span> models for three test set examples. It‚Äôs evident that <span class="ltx_text ltx_font_smallcaps" id="S6.T6.7.2">GenToC</span> outperforms the other two models by identifying a greater number of attribute-value pairs. (<span class="ltx_text ltx_font_italic" id="S6.T6.8.3">SS</span> stands for <span class="ltx_text ltx_font_italic" id="S6.T6.9.4">stainless steel</span>)</figcaption>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Comparison with Other Models</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">In <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.T4" title="In 5.2. Implementation and Systems Compared ‚Ä£ 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>, we present a comparison of three systems ‚Äì ToC-AVE, Gen-AVE and <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p1.1.1">GenToC</span>.
<span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p1.1.2">GenToC</span> model outperforms its counterparts in recall, achieving 71.8% in automatic and 80.1% in manual evaluations, which are the highest among the three models.
These scores are notably higher (by 11.7% and 27.3% in automatic and manual evaluations) than those of the next best-performing model, ToC-AVE.
Such a significant gap in recall proves that <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p1.1.3">GenToC</span> effectively leverages the partially labeled nature of the training data, resulting in more extractions.
Indeed, the total number of correct attribute-value extractions rose from 2,636 to 4,121 (a 56.3% increase) on the 2K test set.
In terms of precision, both the ToC-AVE and Gen-AVE models exhibit higher precision than the <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p1.1.4">GenToC</span> model in both automatic and manual evaluations, with approximately 9-10% and 4-5% higher precision, respectively.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">Overall, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p2.1.1">GenToC</span> maintains its superiority in F1-score, recording the highest at 71.3% in automatic evaluations and 83.0% in manual evaluations, indicating a more balanced and consistent performance.
However, a drawback of <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p2.1.2">GenToC</span> is its slower response time compared to the ToC-AVE model. We address a potential solution to this performance-speed trade-off in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.SS3" title="6.3. Bootstrapping Training Data ‚Ä£ 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Section</span>¬†<span class="ltx_text ltx_ref_tag">6.3</span></a>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">In <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.T6" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">6</span></a>, we present example cases showcasing <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.1">GenToC</span>‚Äôs superior performance in comparison to both ToC-AVE and Gen-AVE models, in terms of the number of attribute-value pairs extracted. For instance, in the first example, the <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.2">GenToC</span> model surpasses the other models by identifying four additional attributes ‚Äì <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.3">Occasion</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.4">Sleeves Type</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.5">Pattern</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.p3.1.6">Gender</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Ablation Study</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">Our initial hypothesis posited that incorporating Markers would enhance recall by identifying more attributes (critical in dealing with partially-labeled data), while Value Pruning (VP) would boost precision by eliminating inaccurately generated attributes.
To validate this, we evaluated variations of the <span class="ltx_text ltx_font_smallcaps" id="S6.SS2.p1.1.1">GenToC</span> model, specifically configurations excluding either Markers, VP, or both.
The outcomes, as presented in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.T4" title="In 5.2. Implementation and Systems Compared ‚Ä£ 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>, align with our expectations.
Notably, in the 2K test set, the absence of Markers in the <span class="ltx_text ltx_font_smallcaps" id="S6.SS2.p1.1.2">GenToC</span> model resulted in a 29.1% decrease in recall, while omitting VP led to a 7.2% reduction in precision. This pattern was also evident in the larger 39K test set.
The findings clearly demonstrate the critical roles of both Markers and VP in balancing recall and precision.
The <span class="ltx_text ltx_font_smallcaps" id="S6.SS2.p1.1.3">GenToC</span> model, when devoid of either component, shows a diminished F1-score compared to its complete configuration.
These results substantiate our choice to incorporate both these strategies in the final formulation of the <span class="ltx_text ltx_font_smallcaps" id="S6.SS2.p1.1.4">GenToC</span> model, for its superior overall performance.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">We also experiment with adding Markers to ToC-AVE and Gen-AVE.
During training, we incorporate marker embeddings to those words which have been covered by the available attributes, and at inference, we incorporate the marker embeddings to all words. Consistent with earlier practices, these embeddings are added into the final hidden states of the encoder.
In the 2K test set, this modification results in considerable reductions in precision scores, plummeting to 66.5% from 90.8% in ToC-AVE and to 65.2% from 89.6% in Gen-AVE. A similar pattern can be observed in case of the 39K test set as well.
This outcome underscores the importance of two-stage model for using markers effectively.
The bifurcated structure of the two-stage model ensures that markers are exclusively utilized in the first stage.
This design circumvents the problem in single-stage models, where markers can force the assignment of outputs to every word, often resulting in suboptimal performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Bootstrapping Training Data</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">From <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S5.T4" title="In 5.2. Implementation and Systems Compared ‚Ä£ 5. Experimental Setup ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>, we find that ToC-AVE has the fastest response time.
Gen-AVE is the slowest, as it has to generate a long string containing all attributes and values.
The high performance of <span class="ltx_text ltx_font_smallcaps" id="S6.SS3.p1.1.1">GenToC</span> comes at the cost of speed, as its response time is 10x greater than ToC-AVE‚Äôs.
With the motivation to build a deployable system that can handle real-world traffic, we experiment with cleaning the training data by regenerating it using the trained <span class="ltx_text ltx_font_smallcaps" id="S6.SS3.p1.1.2">GenToC</span> model.
It increases the average number of words tagged in any attribute-value pair from 0.41 to 0.65 while increasing the total number of attribute-value pairs from 3M to 4.7M on the full training data.
Furthermore, it also brings down the number of attributes from 24.7K to 7.2K, potentially minimizing the presence of redundant and un-canonicalized attributes.
In <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.T5" title="In 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">5</span></a>, we find that the ToC-AVE model trained with this <span class="ltx_text ltx_font_smallcaps" id="S6.SS3.p1.1.3">GenToC</span>-bootstrapped training data significantly improves the performance.
In fact, its performance is comparable to the <span class="ltx_text ltx_font_smallcaps" id="S6.SS3.p1.1.4">GenToC</span> model in both automatic and manual evaluations.
This makes it a strong alternative to the <span class="ltx_text ltx_font_smallcaps" id="S6.SS3.p1.1.5">GenToC</span> model for production environments, where rapid response times are crucial.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Precision-Recall Trade-off</h3>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S6.F3.g1" src="extracted/5602134/assets/pr_curve_v3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Precision-Recall curves show that <span class="ltx_text ltx_font_smallcaps" id="S6.F3.3.1">GenToC</span> and ToC-AVE (<span class="ltx_text ltx_font_smallcaps" id="S6.F3.4.2">GenToC</span> bootstrapping) significantly outperform remaining models, ToC-AVE and Gen-AVE.</figcaption>
</figure>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">To understand the trade-off between precision and recall across different systems, we evaluate the systems using a precision-recall curve.
We employ a common re-scoring model to compute the confidence level for all system extractions in this process.
The model used for re-scoring is an independent Seq2Seq model, trained by using the ‚Äò<span class="ltx_text ltx_font_italic" id="S6.SS4.p1.1.1">product name</span>‚Äô as the input and the ‚Äò<span class="ltx_text ltx_font_italic" id="S6.SS4.p1.1.2">attribute: value</span>‚Äô string as the output, utilizing the same training data.
The model computes the confidence level associated with any given attribute-value pair by accumulating the log probabilities for every token present within the output string.
We found that the model provides us with better-calibrated scores for an attribute-value pair generated by any of the systems.
By applying uniformly spaced thresholds between 0 and 1 for the confidence values, we created the Precision-Recall curve shown in <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.F3" title="In 6.4. Precision-Recall Trade-off ‚Ä£ 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">3</span></a>.
Upon inspection, it was clear that <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.1.3">GenToC</span>‚Äôs performance significantly eclipsed that of other models.
Across most of the curve, <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.1.4">GenToC</span> achieves a higher precision for a given recall, demonstrating its power.
This substantiates the superior quality and efficacy of the <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.1.5">GenToC</span> system.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5. </span>Performance on Long Product Names</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">To assess how well the models handle intricate scenarios, we evaluate their performance on unusually long product names. Product names consist of five words on average, with a standard deviation of two. Thus, we create a test set comprising 500 examples, each containing at least seven words, for the evaluation process.
In <a class="ltx_ref" href="https://arxiv.org/html/2405.10918v1#S6.T7" title="In 6.5. Performance on Long Product Names ‚Ä£ 6. Experiments and Results ‚Ä£ GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">7</span></a>, we tabulate the scores obtained from manual evaluation, together with the <span class="ltx_text ltx_font_italic" id="S6.SS5.p1.1.1">tagged ratio</span> ‚Äî that is, the proportion of words in the product name that have been marked with an attribute ‚Äî for various models.</p>
</div>
<div class="ltx_para" id="S6.SS5.p2">
<p class="ltx_p" id="S6.SS5.p2.1">While Gen-AVE exhibits the highest precision at 95.3%, and <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.1">GenToC</span> without VP shows a notable recall of 90.3%, <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.2">GenToC</span>, stands out with the highest F1-score of 90.7%. This underscores <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.3">GenToC</span>‚Äôs superior balance in the precision-recall trade-off, even in cases where the product names are long.
It‚Äôs noteworthy that when Markers are incorporated into the ToC-AVE and Gen-AVE models, over 99% of the words in product names are linked to an attribute.
However, this high tagging ratio might not be ideal, particularly for lengthy queries, as not every word necessarily possesses a relevant attribute.
This is also reflected in the significant decrease in precision values for these models when Markers are used ‚Äî a drop of over 22% compared to their counterparts without Markers.
Single-stage models, which have to perform value labeling alongside attribute extraction, face this issue when Markers are employed, as they attempt to arbitrarily assign an attribute to every word.
However, since we apply markers only to the first stage of the <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.4">GenToC</span> model, it does not face this problem as there is no direct one-to-one mapping between the predicted attributes and input words.
Finally, even the ToC-AVE model trained with <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.5">GenToC</span> bootstrapping attains an F1-score that‚Äôs comparable with <span class="ltx_text ltx_font_smallcaps" id="S6.SS5.p2.1.6">GenToC</span>, while having a faster response time.
This shows that the full potential of ToC-AVE model is realized only with high-quality training data.</p>
</div>
<figure class="ltx_table" id="S6.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T7.1">
<tr class="ltx_tr" id="S6.T7.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T7.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.1.1" style="font-size:90%;">Architecture</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T7.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.2.1" style="font-size:90%;">Precision</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T7.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.3.1" style="font-size:90%;">Recall</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T7.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.4.1" style="font-size:90%;">F1-score</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" id="S6.T7.1.1.5">
<table class="ltx_tabular ltx_align_middle" id="S6.T7.1.1.5.1">
<tr class="ltx_tr" id="S6.T7.1.1.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.1.5.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.5.1.1.1.1" style="font-size:90%;">Tagged</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.1.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.1.5.1.2.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.5.1.2.1.1" style="font-size:90%;">Ratio</span></td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.2.1"><span class="ltx_text" id="S6.T7.1.2.1.1" style="font-size:90%;">ToC-AVE</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.2.2"><span class="ltx_text" id="S6.T7.1.2.2.1" style="font-size:90%;">94.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.2.3"><span class="ltx_text" id="S6.T7.1.2.3.1" style="font-size:90%;">65.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.2.4"><span class="ltx_text" id="S6.T7.1.2.4.1" style="font-size:90%;">77.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T7.1.2.5"><span class="ltx_text" id="S6.T7.1.2.5.1" style="font-size:90%;">0.464</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.3">
<td class="ltx_td ltx_align_left" id="S6.T7.1.3.1"><span class="ltx_text" id="S6.T7.1.3.1.1" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†with Marker</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.3.2"><span class="ltx_text" id="S6.T7.1.3.2.1" style="font-size:90%;">72.4</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.3.3"><span class="ltx_text" id="S6.T7.1.3.3.1" style="font-size:90%;">90.3</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.3.4"><span class="ltx_text" id="S6.T7.1.3.4.1" style="font-size:90%;">80.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.3.5"><span class="ltx_text ltx_font_bold" id="S6.T7.1.3.5.1" style="font-size:90%;">0.999</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.4.1"><span class="ltx_text" id="S6.T7.1.4.1.1" style="font-size:90%;">Gen-AVE</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.4.2"><span class="ltx_text ltx_font_bold" id="S6.T7.1.4.2.1" style="font-size:90%;">95.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.4.3"><span class="ltx_text" id="S6.T7.1.4.3.1" style="font-size:90%;">58.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.4.4"><span class="ltx_text" id="S6.T7.1.4.4.1" style="font-size:90%;">72.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T7.1.4.5"><span class="ltx_text" id="S6.T7.1.4.5.1" style="font-size:90%;">0.403</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.5">
<td class="ltx_td ltx_align_left" id="S6.T7.1.5.1"><span class="ltx_text" id="S6.T7.1.5.1.1" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†with Marker</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.5.2"><span class="ltx_text" id="S6.T7.1.5.2.1" style="font-size:90%;">71.7</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.5.3"><span class="ltx_text" id="S6.T7.1.5.3.1" style="font-size:90%;">71.6</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.5.4"><span class="ltx_text" id="S6.T7.1.5.4.1" style="font-size:90%;">71.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.5.5"><span class="ltx_text" id="S6.T7.1.5.5.1" style="font-size:90%;">0.993</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.6.1"><span class="ltx_text ltx_font_smallcaps" id="S6.T7.1.6.1.1" style="font-size:90%;">GenToC</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.6.2"><span class="ltx_text" id="S6.T7.1.6.2.1" style="font-size:90%;">90.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.6.3"><span class="ltx_text" id="S6.T7.1.6.3.1" style="font-size:90%;">90.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T7.1.6.4"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.4.1" style="font-size:90%;">90.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S6.T7.1.6.5"><span class="ltx_text" id="S6.T7.1.6.5.1" style="font-size:90%;">0.662</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.7">
<td class="ltx_td ltx_align_left" id="S6.T7.1.7.1"><span class="ltx_text" id="S6.T7.1.7.1.1" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without Marker</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.7.2"><span class="ltx_text" id="S6.T7.1.7.2.1" style="font-size:90%;">94.5</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.7.3"><span class="ltx_text" id="S6.T7.1.7.3.1" style="font-size:90%;">58.7</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.7.4"><span class="ltx_text" id="S6.T7.1.7.4.1" style="font-size:90%;">72.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.7.5"><span class="ltx_text" id="S6.T7.1.7.5.1" style="font-size:90%;">0.405</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.8">
<td class="ltx_td ltx_align_left" id="S6.T7.1.8.1"><span class="ltx_text" id="S6.T7.1.8.1.1" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without VP</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.8.2"><span class="ltx_text" id="S6.T7.1.8.2.1" style="font-size:90%;">87.1</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.8.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.8.3.1" style="font-size:90%;">93.0</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.8.4"><span class="ltx_text" id="S6.T7.1.8.4.1" style="font-size:90%;">89.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.8.5"><span class="ltx_text" id="S6.T7.1.8.5.1" style="font-size:90%;">0.697</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.9">
<td class="ltx_td ltx_align_left" id="S6.T7.1.9.1"><span class="ltx_text" id="S6.T7.1.9.1.1" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†without Marker &amp; VP</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.9.2"><span class="ltx_text" id="S6.T7.1.9.2.1" style="font-size:90%;">94.2</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.9.3"><span class="ltx_text" id="S6.T7.1.9.3.1" style="font-size:90%;">59.0</span></td>
<td class="ltx_td ltx_align_right" id="S6.T7.1.9.4"><span class="ltx_text" id="S6.T7.1.9.4.1" style="font-size:90%;">72.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S6.T7.1.9.5"><span class="ltx_text" id="S6.T7.1.9.5.1" style="font-size:90%;">0.406</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.10">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S6.T7.1.10.1">
<table class="ltx_tabular ltx_align_middle" id="S6.T7.1.10.1.1">
<tr class="ltx_tr" id="S6.T7.1.10.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S6.T7.1.10.1.1.1.1"><span class="ltx_text" id="S6.T7.1.10.1.1.1.1.1" style="font-size:90%;">ToC-AVE</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.10.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S6.T7.1.10.1.1.2.1">
<span class="ltx_text" id="S6.T7.1.10.1.1.2.1.1" style="font-size:90%;">(</span><span class="ltx_text ltx_font_smallcaps" id="S6.T7.1.10.1.1.2.1.2" style="font-size:90%;">GenToC</span><span class="ltx_text" id="S6.T7.1.10.1.1.2.1.3" style="font-size:90%;"> bootstrapping)</span>
</td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S6.T7.1.10.2"><span class="ltx_text" id="S6.T7.1.10.2.1" style="font-size:90%;">90.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S6.T7.1.10.3"><span class="ltx_text" id="S6.T7.1.10.3.1" style="font-size:90%;">88.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S6.T7.1.10.4"><span class="ltx_text" id="S6.T7.1.10.4.1" style="font-size:90%;">89.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t" id="S6.T7.1.10.5"><span class="ltx_text" id="S6.T7.1.10.5.1" style="font-size:90%;">0.689</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7. </span>Results of manual evaluation for various models on a test set of 500 long product names.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The <span class="ltx_text ltx_font_smallcaps" id="S7.p1.1.1">GenToC</span> model for attribute-value extraction excels in handling partially labeled data and scaling effectively to large, possibly redundant attribute sets.
Its unique use of Marker embeddings and Value Pruning allows it to deal effectively with incomplete data and avoid incorrect attributes, respectively.
Furthermore, by harnessing <span class="ltx_text ltx_font_smallcaps" id="S7.p1.1.2">GenToC</span>‚Äôs strengths to enhance training data, it paves the way for training more efficient models, thereby bridging the gap between research and actual deployment.
Future work could include performing multiple stages of bootstrapping to realize the benefits of potentially higher-quality training data.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We would like to thank IndiaMART for providing us with the data for our research and helping us integrate with their current systems. We would like to thank KnowDis Data Annotator team for their timely help with the annotations required for this project and KnowDis Data Science members for giving valuable suggestions.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bing et¬†al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Lidong Bing, Tak-Lam Wong, and Wai Lam. 2012.

</span>
<span class="ltx_bibblock">Unsupervised extraction of popular product attributes from web sites. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Information Retrieval Technology</em>. Springer Berlin Heidelberg, 437‚Äì446.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Cao et¬†al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Nicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. 2021.

</span>
<span class="ltx_bibblock">Autoregressive Entity Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=5k8F6UU39V" title="">https://openreview.net/forum?id=5k8F6UU39V</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fleiss (1971)</span>
<span class="ltx_bibblock">
Joseph¬†L. Fleiss. 1971.

</span>
<span class="ltx_bibblock">Measuring nominal scale agreement among many raters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Psychological Bulletin</em> 76 (1971), 378‚Äì382.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:143544759" title="">https://api.semanticscholar.org/CorpusID:143544759</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghani et¬†al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Rayid Ghani, Katharina Probst, Yan Liu, Marko Krema, and Andrew¬†E. Fano. 2006.

</span>
<span class="ltx_bibblock">Text mining for product attribute extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">SIGKDD Explor.</em> 8 (2006), 41‚Äì48.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gopalakrishnan et¬†al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Vishrawas Gopalakrishnan, Suresh Iyengar, Amit Madaan, Rajeev Rastogi, and Srinivasan¬†H. Sengamedu. 2012.

</span>
<span class="ltx_bibblock">Matching product titles using web-based enrichment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the 21st ACM international conference on Information and knowledge management</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et¬†al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=XPZIaotutsD" title="">https://openreview.net/forum?id=XPZIaotutsD</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khandelwal et¬†al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Anant Khandelwal, Happy Mittal, Shreyas¬†Sunil Kulkarni, and Deepak¬†Kumar Gupta. 2023.

</span>
<span class="ltx_bibblock">Large Scale Generative Multimodal Attribute Extraction for E-commerce Attributes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">ArXiv</em> abs/2306.00379 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et¬†al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2019.

</span>
<span class="ltx_bibblock">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">CoRR</em> abs/1910.13461 (2019).

</span>
<span class="ltx_bibblock">arXiv:1910.13461

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.13461" title="">http://arxiv.org/abs/1910.13461</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nadeau and Sekine (2007)</span>
<span class="ltx_bibblock">
David Nadeau and Satoshi Sekine. 2007.

</span>
<span class="ltx_bibblock">A survey of named entity recognition and classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Lingvisticae Investigationes</em> 30 (2007), 3‚Äì26.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Probst et¬†al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2007)</span>
<span class="ltx_bibblock">
Katharina Probst, Rayid Ghani, Marko Krema, Andrew¬†E Fano, and Yan Liu. 2007.

</span>
<span class="ltx_bibblock">Semi-supervised learning of attribute-value pairs from product descriptions. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 20th International Joint Conference on Artificial Intelligence</em>. Morgan Kaufmann Publishers Inc., 2838‚Äì2843.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Putthividhya and Hu (2011)</span>
<span class="ltx_bibblock">
Duangmanee Putthividhya and Junling Hu. 2011.

</span>
<span class="ltx_bibblock">Bootstrapped named entity recognition for product attribute extraction. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics, 1557‚Äì1567.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rezk et¬†al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mart√≠n Rezk, Laura¬†Alonso Alemany, Lasguido Nio, and Ted Zhang. 2019.

</span>
<span class="ltx_bibblock">Accurate Product Attribute Extraction on the Field.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">2019 IEEE 35th International Conference on Data Engineering (ICDE)</em> (2019), 1862‚Äì1873.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ricatte and Crisostomi (2023)</span>
<span class="ltx_bibblock">
Thomas Ricatte and Donato Crisostomi. 2023.

</span>
<span class="ltx_bibblock">AVEN-GR: Attribute Value Extraction and Normalization using product GRaphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)</em>, Sunayana Sitaram, Beata Beigman¬†Klebanov, and Jason¬†D Williams (Eds.). Association for Computational Linguistics, Toronto, Canada.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et¬†al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Kalyani Roy, Pawan Goyal, and Manish Pandey. 2021.

</span>
<span class="ltx_bibblock">Attribute Value Generation from Product Title using Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of The 4th Workshop on e-Commerce and NLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et¬†al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Kalyani Roy, Tapas Nayak, and Pawan Goyal. 2022.

</span>
<span class="ltx_bibblock">Exploring Generative Models for Joint Attribute Value Extraction from Product Titles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">ArXiv</em> abs/2208.07130 (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinzato and Sekine (2013)</span>
<span class="ltx_bibblock">
Keiji Shinzato and Satoshi Sekine. 2013.

</span>
<span class="ltx_bibblock">Unsupervised extraction of attributes and their values from product description. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the Sixth International Joint Conference on Natural Language Processing</em>. Asian Federation of Natural Language Processing, 1339‚Äì1347.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinzato et¬†al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Keiji Shinzato, Naoki Yoshinaga, Yandi Xia, and Wei-Te Chen. 2022.

</span>
<span class="ltx_bibblock">Simple and Effective Knowledge-Driven Query Expansion for QA-Based Product Attribute Extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">ArXiv</em> abs/2206.14264 (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinzato et¬†al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Keiji Shinzato, Naoki Yoshinaga, Yandi Xia, and Wei-Te Chen. 2023.

</span>
<span class="ltx_bibblock">A Unified Generative Approach to Product Attribute-Value Identification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">ArXiv</em> abs/2306.05605 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shrimal et¬†al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Anubhav Shrimal, Avi¬†Rajesh Jain, Kartik Mehta, and Promod Yenigalla. 2022.

</span>
<span class="ltx_bibblock">NER-MQMRC: Formulating Named Entity Recognition as Multi Question Machine Reading Comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">ArXiv</em> abs/2205.05904 (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et¬†al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
K. Wang, Jianzhi Shao, T. Zhang, Qijin Chen, and Chengfu Huo. 2023.

</span>
<span class="ltx_bibblock">MPKGAC: Multimodal Product Attribute Completion in E-commerce.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Companion Proceedings of the ACM Web Conference 2023</em> (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:258377639" title="">https://api.semanticscholar.org/CorpusID:258377639</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et¬†al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Qifan Wang, Li Yang, Bhargav Kanagal, Sumit¬†K. Sanghai, D. Sivakumar, Bin Shu, Zac Yu, and Jonathan¬†L. Elsas. 2020.

</span>
<span class="ltx_bibblock">Learning to Extract Attribute Value from Product via Question Answering: A Multi-task Approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wong et¬†al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Yuk¬†Wah Wong, Dominic Widdows, Tom Lokovic, and Kamal Nigam. 2009.

</span>
<span class="ltx_bibblock">Scalable Attribute-Value Extraction from Semi-structured Text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">2009 IEEE International Conference on Data Mining Workshops</em> (2009), 302‚Äì307.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et¬†al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Huimin Xu, Wenting Wang, Xin Mao, Xinyue Jiang, and Man Lan. 2019.

</span>
<span class="ltx_bibblock">Scaling up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">ACL</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et¬†al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Li Yang, Qifan Wang, Zac Yu, Anand Kulkarni, Sumit¬†K. Sanghai, Bin Shu, Jonathan¬†L. Elsas, and Bhargav Kanagal. 2021.

</span>
<span class="ltx_bibblock">MAVE: A Product Dataset for Multi-source Attribute Value Extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Danqing Zhang, Zheng Li, Tianyu Cao, Chen Luo, Tony Wu, Hanqing Lu, Yiwei Song, Bing Yin, Tuo Zhao, and Qiang Yang. 2021.

</span>
<span class="ltx_bibblock">QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em> (2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:237213565" title="">https://api.semanticscholar.org/CorpusID:237213565</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et¬†al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Guineng Zheng, Subhabrata Mukherjee, Xin Dong, and Feifei Li. 2018.

</span>
<span class="ltx_bibblock">OpenTag: Open Attribute Value Extraction from Product Profiles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et¬†al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tiangang Zhu, Yue Wang, Haoran Li, Youzheng Wu, Xiaodong He, and Bowen Zhou. 2020.

</span>
<span class="ltx_bibblock">Multimodal Joint Attribute Prediction and Value Extraction for E-commerce Product. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri May 17 06:28:48 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
