<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?</title>
<!--Generated on Tue Oct  8 20:15:30 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.06338v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S1" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S2" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3.SS1" title="In 3 Data ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Emotion-related QE Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3.SS2" title="In 3 Data ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Calculation of MQM Scores</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS1" title="In 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>In-context Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS2" title="In 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>PEFT of LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS3" title="In 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS3.SSS0.Px1" title="In 4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS4" title="In 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Experimental Setup</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results and Manual Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS1" title="In 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS2" title="In 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>In-context Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS3" title="In 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>PEFT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS4" title="In 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Manual Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS4.SSS1" title="In 5.4 Manual Analysis ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.1 </span>Refusal to Reply</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS4.SSS2" title="In 5.4 Manual Analysis ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.2 </span>Unstable Output</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S6" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S7" title="In Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shenbin Qian<span class="ltx_text" id="id1.1.1" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="id1.1.1.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>, Constantin Orăsan<span class="ltx_text" id="id2.2.2" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="id2.2.2.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>, Diptesh Kanojia<span class="ltx_text" id="id3.3.3" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="14" id="id3.3.3.g1" src="extracted/5910816/latex/pai-icon.png" width="14"/></span>and Félix do Carmo<span class="ltx_text" id="id4.4.4" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="id4.4.4.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>
<br class="ltx_break"/><span class="ltx_text" id="id5.5.5" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="id5.5.5.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>Centre for Translation Studies and
<span class="ltx_text" id="id6.6.6" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="14" id="id6.6.6.g1" src="extracted/5910816/latex/pai-icon.png" width="14"/></span>Institute for People-Centred AI, 
<br class="ltx_break"/>
University of Surrey, United Kingdom 
<br class="ltx_break"/>
{s.qian, c.orasan, d.kanojia, f.docarmo}@surrey.ac.uk
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.id1">This paper investigates whether large language models (LLMs) are state-of-the-art quality estimators for machine translation of user-generated content (UGC) that contains emotional expressions, without the use of reference translations. To achieve this, we employ an existing emotion-related dataset with human-annotated errors and calculate quality evaluation scores based on the Multi-dimensional Quality Metrics. We compare the accuracy of several LLMs with that of our fine-tuned baseline models, under in-context learning and parameter-efficient fine-tuning (PEFT) scenarios. We find that PEFT of LLMs leads to better performance in score prediction with human interpretable explanations than fine-tuned models. However, a manual analysis of LLM outputs reveals that they still have problems such as refusal to reply to a prompt and unstable output while evaluating machine translation of UGC.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.6">
<p class="ltx_p" id="p1.6.7"><span class="ltx_text ltx_font_bold" id="p1.6.7.1">Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.6.6" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.6.6.6" style="width:0.0pt;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_top" id="p1.6.6.6.6">
<span class="ltx_thead">
<span class="ltx_tr" id="p1.4.4.4.4.4">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="p1.4.4.4.4.4.4.4">Shenbin Qian<span class="ltx_text" id="p1.1.1.1.1.1.1.1.1" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="p1.1.1.1.1.1.1.1.1.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>, Constantin Orăsan<span class="ltx_text" id="p1.2.2.2.2.2.2.2.2" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="p1.2.2.2.2.2.2.2.2.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>, Diptesh Kanojia<span class="ltx_text" id="p1.3.3.3.3.3.3.3.3" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="14" id="p1.3.3.3.3.3.3.3.3.g1" src="extracted/5910816/latex/pai-icon.png" width="14"/></span>and Félix do Carmo<span class="ltx_text" id="p1.4.4.4.4.4.4.4.4" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="p1.4.4.4.4.4.4.4.4.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span></span></span></span>
<span class="ltx_tr" id="p1.6.6.6.6.6">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.6.6.6.6.6.2" style="padding-bottom:1.99997pt;"><span class="ltx_text" id="p1.5.5.5.5.5.1.1" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="16" id="p1.5.5.5.5.5.1.1.g1" src="extracted/5910816/latex/ctsicon.png" width="16"/></span>Centre for Translation Studies and
<span class="ltx_text" id="p1.6.6.6.6.6.2.2" style="position:relative; bottom:3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="14" id="p1.6.6.6.6.6.2.2.g1" src="extracted/5910816/latex/pai-icon.png" width="14"/></span>Institute for People-Centred AI,</span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.6.6.6.6.7.1">
<span class="ltx_td ltx_align_center" id="p1.6.6.6.6.7.1.1" style="padding-bottom:1.30005pt;">University of Surrey, United Kingdom</span></span>
<span class="ltx_tr" id="p1.6.6.6.6.8.2">
<span class="ltx_td ltx_align_center" id="p1.6.6.6.6.8.2.1">{s.qian, c.orasan, d.kanojia, f.docarmo}@surrey.ac.uk</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advancements in machine translation (MT) technology, particularly in Chinese-English news translation, have led to claims of achieving human parity <cite class="ltx_cite ltx_citemacro_citep">(Hassan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib13" title="">2018</a>)</cite>. These claims have gained traction, particularly with the emergence of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib35" title="">2021</a>)</cite>, and their reported zero-shot state-of-the-art (SoTA) performance across various downstream tasks <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib21" title="">2023</a>)</cite>. However, translating user-generated content (UGC) containing emotional expressions, such as tweets, poses additional challenges for MT systems <cite class="ltx_cite ltx_citemacro_citep">(Saadany et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib27" title="">2023</a>)</cite>. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">1</span></a>, testing Google Translate (GT) and ChatGPT<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>GPT-3.5 at “https://chat.openai.com/” in Mar., 2024</span></span></span> using Chinese UGC with emotional slang revealed that the output of these systems requires significant improvement to be considered usable. This highlights the importance of evaluating MT quality using metrics that account for emotion preservation in translation.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="273" id="S1.F1.g1" src="extracted/5910816/example1.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of translations from Google Translate and ChatGPT</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Relying on human evaluation to assess the quality of machine translation is costly in terms of both time and money <cite class="ltx_cite ltx_citemacro_citep">(Dorr et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib4" title="">2011</a>; Lai et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib18" title="">2020</a>)</cite>. Quality estimation (QE), which predicts MT quality in the absence of human references, can serve as a cost-effective alternative to approximate human evaluation <cite class="ltx_cite ltx_citemacro_citep">(Specia et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib32" title="">2018</a>)</cite>. A commonly adopted QE method involves fine-tuning multilingual pre-trained language models (PTLMs) on human evaluation data using frameworks like Multi-dimensional Quality Metrics (MQM), an error-based evaluation scheme for MT quality <cite class="ltx_cite ltx_citemacro_citep">(Lommel et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib19" title="">2014</a>)</cite>. These fine-tuned models can provide a score for MT outputs, indicating translation quality. However, this approach has faced criticism for its lack of explainability <cite class="ltx_cite ltx_citemacro_citep">(Guerreiro et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib11" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The inherent generative capability of LLMs allows for the provision of QE scores along with natural language explanations, rendering them comprehensible to humans. Some research claims that LLMs excel as quality evaluators in score prediction, in addition to their explainability <cite class="ltx_cite ltx_citemacro_citep">(Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib17" title="">2023b</a>)</cite>. Our paper delves into the question, <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">“Are LLMs SoTA quality estimators for the translation of Chinese emotion-loaded UGC, through in-context learning (ICL)<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><span class="ltx_text ltx_font_upright" id="footnote2.5">We refer to ICL as the ability of a LLM to adapt to new tasks by examples or instructions, without parameter updates or explicit training. It includes zero- and few-shot learning.</span></span></span></span></span> <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">and parameter-efficient fine-tuning (PEFT)?”</span>. To answer this question, we utilize an existing dataset that was collected for the study of emotion translation in social media texts, and enhance it by adding segment-level QE scores based on MQM. This augmentation allows for the evaluation of LLMs’ performance in predicting a QE score that reflects the overall translation quality of the MT segment. Our findings are contrasted with those of the conventional supervised fine-tuning approach. Our method achieves better results than fine-tuning on the emotion-related UGC dataset. Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p4">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Computing QE score based on MQM for each data instance.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Novel prompt templates for ICL and PEFT using multiple LLMs to evaluate MT quality of emotion-loaded UGC, achieving improved performance over the baseline with PEFT<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/surrey-nlp/LLMs4MTQE-UGC" title="">https://github.com/surrey-nlp/LLMs4MTQE-UGC</a>.</span></span></span>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Manually analyzing LLM outputs, and revealing problems such as <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">refusal to reply</span> and <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.2">unstable output</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Current state-of-the-art QE models are obtained by fine-tuning multilingual PTLMs on human evaluation data based on metrics such as translation edit rate (TER) <cite class="ltx_cite ltx_citemacro_citep">(Snover et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib28" title="">2006</a>)</cite>, direct assessment (DA) <cite class="ltx_cite ltx_citemacro_citep">(Graham et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib10" title="">2013</a>)</cite>, MQM and <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">etc</span>. For instance, TransQuest <cite class="ltx_cite ltx_citemacro_citep">(Ranasinghe et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib23" title="">2020</a>)</cite> employs the pre-trained XLM-RoBERTa <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib2" title="">2020</a>)</cite> model as the encoder, concatenating the source and target sentences as its input for TER/DA score prediction. Both its MonoTransQuest and SiameseTransQuest architectures can achieve good results for sentence-level QE after fine-tuning. Another popular framework, COMET <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib24" title="">2020</a>; Stewart et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib33" title="">2020</a>)</cite> initially relied on reference translation for evaluation, until 2022 when COMETKIWI <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib25" title="">2022</a>)</cite> was introduced to support reference-less evaluation. Similar to MonoTransQuest, it concatenates the source and target, and inputs them into the encoder to get predictions for sentence-level QE scores.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Given their success in the QE shared tasks in the Conference on Machine Translation (WMT) recently <cite class="ltx_cite ltx_citemacro_citep">(Specia et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib30" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib31" title="">2021</a>; Zerva et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib37" title="">2022</a>)</cite>, TransQuest and COMET are used for fine-tuning to get our baseline models.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.2">The success of LLMs in various natural language processing tasks <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib36" title="">2024</a>)</cite> brings new trends and methods in QE research. <cite class="ltx_cite ltx_citemacro_citet">Kocmi and Federmann (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib17" title="">2023b</a>)</cite> proposed a zero-shot prompting technique (called GEMBA) for direct assessment (score from <math alttext="0" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn id="S2.p3.1.m1.1.1.cmml" type="integer" xref="S2.p3.1.m1.1.1">0</cn></annotation-xml></semantics></math> to <math alttext="100" class="ltx_Math" display="inline" id="S2.p3.2.m2.1"><semantics id="S2.p3.2.m2.1a"><mn id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><cn id="S2.p3.2.m2.1.1.cmml" type="integer" xref="S2.p3.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">100</annotation><annotation encoding="application/x-llamapun" id="S2.p3.2.m2.1d">100</annotation></semantics></math>) using GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib21" title="">2023</a>)</cite>. They claimed that LLMs without fine-tuning can achieve results comparable to SoTA QE models in score prediction. They further explored the explainability of LLMs in error span detection, and achieved state-of-the-art accuracy for QE system ranking using GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(Kocmi and Federmann, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib16" title="">2023a</a>)</cite>. Based on the GEMBA prompt, <cite class="ltx_cite ltx_citemacro_citet">Fernandes et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib5" title="">2023</a>)</cite> proposed to use LLMs for both score prediction and error categorization. They employed ICL and fine-tuning of LLMs and achieved better results than fine-tuning (encoder-based) multilingual PTLMs. However, fine-tuning LLMs is not cost-effective and energy-efficient. In addition, it might have <span class="ltx_text ltx_font_italic" id="S2.p3.2.1">catastrophic forgetting</span>, where a language model <span class="ltx_text ltx_font_italic" id="S2.p3.2.2">forgets</span> the knowledge learned during pre-training as it adapts to task-specific data <cite class="ltx_cite ltx_citemacro_citep">(McCloskey and Cohen, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib20" title="">1989</a>; Ruiz-Garcia, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib26" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Therefore, in this paper, we explore whether PEFT and ICL yield superior performance compared to fine-tuning multilingual PTLMs on the evaluation of machine translation of emotion-loaded UGC.</p>
</div>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S2.F2.3" style="width:426.8pt;">
<p class="ltx_p" id="S2.F2.3.3">Score the following translation from Chinese to English with respect to the preservation of emotion on a continuous scale from <math alttext="0" class="ltx_Math" display="inline" id="S2.F2.1.1.m1.1"><semantics id="S2.F2.1.1.m1.1a"><mn id="S2.F2.1.1.m1.1.1" xref="S2.F2.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.F2.1.1.m1.1b"><cn id="S2.F2.1.1.m1.1.1.cmml" type="integer" xref="S2.F2.1.1.m1.1.1">0</cn></annotation-xml></semantics></math> to <math alttext="-100" class="ltx_Math" display="inline" id="S2.F2.2.2.m2.1"><semantics id="S2.F2.2.2.m2.1a"><mrow id="S2.F2.2.2.m2.1.1" xref="S2.F2.2.2.m2.1.1.cmml"><mo id="S2.F2.2.2.m2.1.1a" xref="S2.F2.2.2.m2.1.1.cmml">−</mo><mn id="S2.F2.2.2.m2.1.1.2" xref="S2.F2.2.2.m2.1.1.2.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.2.2.m2.1b"><apply id="S2.F2.2.2.m2.1.1.cmml" xref="S2.F2.2.2.m2.1.1"><minus id="S2.F2.2.2.m2.1.1.1.cmml" xref="S2.F2.2.2.m2.1.1"></minus><cn id="S2.F2.2.2.m2.1.1.2.cmml" type="integer" xref="S2.F2.2.2.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.2.m2.1c">-100</annotation><annotation encoding="application/x-llamapun" id="S2.F2.2.2.m2.1d">- 100</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="S2.F2.3.3.1">where a score of minus one hundred means “emotions are critically damaged in multiple places in the text” and score of zero means “perfect emotion preservation”. A score of <math alttext="-1" class="ltx_Math" display="inline" id="S2.F2.3.3.1.m1.1"><semantics id="S2.F2.3.3.1.m1.1a"><mrow id="S2.F2.3.3.1.m1.1.1" xref="S2.F2.3.3.1.m1.1.1.cmml"><mo id="S2.F2.3.3.1.m1.1.1a" xref="S2.F2.3.3.1.m1.1.1.cmml">−</mo><mn id="S2.F2.3.3.1.m1.1.1.2" xref="S2.F2.3.3.1.m1.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.3.3.1.m1.1b"><apply id="S2.F2.3.3.1.m1.1.1.cmml" xref="S2.F2.3.3.1.m1.1.1"><minus id="S2.F2.3.3.1.m1.1.1.1.cmml" xref="S2.F2.3.3.1.m1.1.1"></minus><cn id="S2.F2.3.3.1.m1.1.1.2.cmml" type="integer" xref="S2.F2.3.3.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.3.3.1.m1.1c">-1</annotation><annotation encoding="application/x-llamapun" id="S2.F2.3.3.1.m1.1d">- 1</annotation></semantics></math> means “very subtle difference in emotion between the source and the target”.</span> If the score is not zero (not perfect translation), please list keywords or parts of sentences in both source and target where translation is incorrect.</p>
<p class="ltx_p" id="S2.F2.3.4">Chinese source: {Source_text}</p>
<p class="ltx_p" id="S2.F2.3.5">English translation: {Machine_translation}</p>
<p class="ltx_p" id="S2.F2.3.6">The score in terms of emotion preservation for the translation is: {MQM_score}</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Prompt Template 1</figcaption>
</figure>
<figure class="ltx_figure" id="S2.F3">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S2.F3.5" style="width:426.8pt;">
<p class="ltx_p" id="S2.F3.5.5">Score the following translation from Chinese to English with respect to errors in the preservation of emotion. <span class="ltx_text ltx_font_italic" id="S2.F3.3.3.3">The score is calculated based on the number of errors and the level of error severity and weights assigned to each severity level, that is, minor, major and critical. One minor error in emotion preservation, leading to the slight change of emotion after translation, gets a score of <math alttext="-1" class="ltx_Math" display="inline" id="S2.F3.1.1.1.m1.1"><semantics id="S2.F3.1.1.1.m1.1a"><mrow id="S2.F3.1.1.1.m1.1.1" xref="S2.F3.1.1.1.m1.1.1.cmml"><mo id="S2.F3.1.1.1.m1.1.1a" xref="S2.F3.1.1.1.m1.1.1.cmml">−</mo><mn id="S2.F3.1.1.1.m1.1.1.2" xref="S2.F3.1.1.1.m1.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.1.1.1.m1.1b"><apply id="S2.F3.1.1.1.m1.1.1.cmml" xref="S2.F3.1.1.1.m1.1.1"><minus id="S2.F3.1.1.1.m1.1.1.1.cmml" xref="S2.F3.1.1.1.m1.1.1"></minus><cn id="S2.F3.1.1.1.m1.1.1.2.cmml" type="integer" xref="S2.F3.1.1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.1.1.1.m1.1c">-1</annotation><annotation encoding="application/x-llamapun" id="S2.F3.1.1.1.m1.1d">- 1</annotation></semantics></math>; one major error, pertaining to the change of emotion into a different category after translation, gets a score of <math alttext="-5" class="ltx_Math" display="inline" id="S2.F3.2.2.2.m2.1"><semantics id="S2.F3.2.2.2.m2.1a"><mrow id="S2.F3.2.2.2.m2.1.1" xref="S2.F3.2.2.2.m2.1.1.cmml"><mo id="S2.F3.2.2.2.m2.1.1a" xref="S2.F3.2.2.2.m2.1.1.cmml">−</mo><mn id="S2.F3.2.2.2.m2.1.1.2" xref="S2.F3.2.2.2.m2.1.1.2.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.2.2.2.m2.1b"><apply id="S2.F3.2.2.2.m2.1.1.cmml" xref="S2.F3.2.2.2.m2.1.1"><minus id="S2.F3.2.2.2.m2.1.1.1.cmml" xref="S2.F3.2.2.2.m2.1.1"></minus><cn id="S2.F3.2.2.2.m2.1.1.2.cmml" type="integer" xref="S2.F3.2.2.2.m2.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.2.2.2.m2.1c">-5</annotation><annotation encoding="application/x-llamapun" id="S2.F3.2.2.2.m2.1d">- 5</annotation></semantics></math>; and one critical error, resulting in the change of emotion into an extremely different or even opposite category after translation, gets a score of <math alttext="-10" class="ltx_Math" display="inline" id="S2.F3.3.3.3.m3.1"><semantics id="S2.F3.3.3.3.m3.1a"><mrow id="S2.F3.3.3.3.m3.1.1" xref="S2.F3.3.3.3.m3.1.1.cmml"><mo id="S2.F3.3.3.3.m3.1.1a" xref="S2.F3.3.3.3.m3.1.1.cmml">−</mo><mn id="S2.F3.3.3.3.m3.1.1.2" xref="S2.F3.3.3.3.m3.1.1.2.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.3.3.3.m3.1b"><apply id="S2.F3.3.3.3.m3.1.1.cmml" xref="S2.F3.3.3.3.m3.1.1"><minus id="S2.F3.3.3.3.m3.1.1.1.cmml" xref="S2.F3.3.3.3.m3.1.1"></minus><cn id="S2.F3.3.3.3.m3.1.1.2.cmml" type="integer" xref="S2.F3.3.3.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.3.3.3.m3.1c">-10</annotation><annotation encoding="application/x-llamapun" id="S2.F3.3.3.3.m3.1d">- 10</annotation></semantics></math>. If there is no error in terms of emotion preservation, the score is 0, which means “perfect emotion preservation”.</span> We set a score of <math alttext="-100" class="ltx_Math" display="inline" id="S2.F3.4.4.m1.1"><semantics id="S2.F3.4.4.m1.1a"><mrow id="S2.F3.4.4.m1.1.1" xref="S2.F3.4.4.m1.1.1.cmml"><mo id="S2.F3.4.4.m1.1.1a" xref="S2.F3.4.4.m1.1.1.cmml">−</mo><mn id="S2.F3.4.4.m1.1.1.2" xref="S2.F3.4.4.m1.1.1.2.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.4.4.m1.1b"><apply id="S2.F3.4.4.m1.1.1.cmml" xref="S2.F3.4.4.m1.1.1"><minus id="S2.F3.4.4.m1.1.1.1.cmml" xref="S2.F3.4.4.m1.1.1"></minus><cn id="S2.F3.4.4.m1.1.1.2.cmml" type="integer" xref="S2.F3.4.4.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.4.4.m1.1c">-100</annotation><annotation encoding="application/x-llamapun" id="S2.F3.4.4.m1.1d">- 100</annotation></semantics></math> as the worst score, which means “there are more than 10 critical errors in emotion preservation”. If the score is not <math alttext="0" class="ltx_Math" display="inline" id="S2.F3.5.5.m2.1"><semantics id="S2.F3.5.5.m2.1a"><mn id="S2.F3.5.5.m2.1.1" xref="S2.F3.5.5.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.F3.5.5.m2.1b"><cn id="S2.F3.5.5.m2.1.1.cmml" type="integer" xref="S2.F3.5.5.m2.1.1">0</cn></annotation-xml></semantics></math> (imperfect translation), please list keywords or parts of sentences in both source and target where error occurs.</p>
<p class="ltx_p" id="S2.F3.5.6">Chinese source: {Source_text}</p>
<p class="ltx_p" id="S2.F3.5.7">English translation: {Machine_translation}</p>
<p class="ltx_p" id="S2.F3.5.8">The score in terms of emotion preservation for the translation is: {MQM_score}</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Prompt Template 2</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section introduces the emotion-related dataset and our extension of QE scores based on MQM.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Emotion-related QE Dataset</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this paper, we utilize the Human Annotated Dataset for Quality Assessment of Emotion Translation (HADQAET)<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/surrey-nlp/HADQAET" title="">https://github.com/surrey-nlp/HADQAET</a></span></span></span> as the main resource <cite class="ltx_cite ltx_citemacro_citep">(Qian et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib22" title="">2023</a>)</cite>. Its source text originates from the dataset released by the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Evaluation of Weibo Emotion Classification Technology on the Ninth China National Conference on Social Media Processing</span> (SMP2020-EWECT) and contains 34,768 instances. Each instance is a tweet-like text segment<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Like most NLP tasks, we treat tweet-like text segments as sentence-level data. However, in contrast to tweets, our instances are longer with an average of <math alttext="40" class="ltx_Math" display="inline" id="footnote5.m1.1"><semantics id="footnote5.m1.1b"><mn id="footnote5.m1.1.1" xref="footnote5.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="footnote5.m1.1c"><cn id="footnote5.m1.1.1.cmml" type="integer" xref="footnote5.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="footnote5.m1.1d">40</annotation><annotation encoding="application/x-llamapun" id="footnote5.m1.1e">40</annotation></semantics></math> Chinese characters.</span></span></span>, which was manually annotated with one of the six emotion labels, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">i.e.</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">anger</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.4">joy</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.5">sadness</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.6">surprise</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.7">fear</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.8">neutral</span> <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib12" title="">2021</a>)</cite>. We randomly selected <math alttext="5,538" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.2"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">5</mn><mo id="S3.SS1.p1.1.m1.2.3.2.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">538</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><list id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.2"><cn id="S3.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1">5</cn><cn id="S3.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2">538</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">5,538</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.2d">5 , 538</annotation></semantics></math> instances with <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.9">non-neutral</span> emotion labels and used Google Translate for English translation. We proposed an emotion-related MQM framework and recruited two professional translators to annotate errors and their corresponding severity in terms of emotion preservation. Details of our framework, error definition<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>The error definition in our prompt templates in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS1" title="4.1 In-context Learning ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4.1</span></a> mainly derives from from <cite class="ltx_cite ltx_citemacro_citet">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib22" title="">2023</a>)</cite>.</span></span></span>, error annotation (including inter-annotator agreement), error analysis and data distribution can be seen in <cite class="ltx_cite ltx_citemacro_citet">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib22" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Calculation of MQM Scores</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">Since <cite class="ltx_cite ltx_citemacro_citet">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib22" title="">2023</a>)</cite> only annotated and analyzed the translation errors (and error severity levels) according to the MQM framework, no evaluation score was calculated and proposed. We followed <cite class="ltx_cite ltx_citemacro_citet">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib6" title="">2021a</a>)</cite> to sum up all weighted errors based on their corresponding severity. The weights for severity levels, as suggested by MQM, are <math alttext="1" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn id="S3.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">1</annotation></semantics></math> for <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.4.1">minor error</span>, <math alttext="5" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn id="S3.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">5</annotation></semantics></math> for <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.4.2">major</span> and <math alttext="10" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mn id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><cn id="S3.SS2.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS2.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">10</annotation></semantics></math> for <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.4.3">critical</span>. To test the sensitivity of these weights to the overall quality evaluation score, we selected three sets of weights (as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3.T1" title="Table 1 ‣ 3.2 Calculation of MQM Scores ‣ 3 Data ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">1</span></a>) to check the ranking stability compared with the MQM suggestion. We generated two subsets of <math alttext="5,000" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.2"><semantics id="S3.SS2.p1.4.m4.2a"><mrow id="S3.SS2.p1.4.m4.2.3.2" xref="S3.SS2.p1.4.m4.2.3.1.cmml"><mn id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">5</mn><mo id="S3.SS2.p1.4.m4.2.3.2.1" xref="S3.SS2.p1.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.4.m4.2.2" xref="S3.SS2.p1.4.m4.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.2b"><list id="S3.SS2.p1.4.m4.2.3.1.cmml" xref="S3.SS2.p1.4.m4.2.3.2"><cn id="S3.SS2.p1.4.m4.1.1.cmml" type="integer" xref="S3.SS2.p1.4.m4.1.1">5</cn><cn id="S3.SS2.p1.4.m4.2.2.cmml" type="integer" xref="S3.SS2.p1.4.m4.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.2c">5,000</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.2d">5 , 000</annotation></semantics></math> instances by sampling with replacement. Then, we calculated the MQM scores using the listed sets of weights. Next, we ranked the scores in ascending order and assessed the similarity of the rankings using the Spearman correlation score <cite class="ltx_cite ltx_citemacro_citep">(Spearman, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib29" title="">1904</a>)</cite>. We did this for 1000 times and averaged the ranking similarity. Results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3.T1" title="Table 1 ‣ 3.2 Calculation of MQM Scores ‣ 3 Data ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.16" style="width:199.2pt;height:71.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-26.5pt,9.4pt) scale(0.790091501107862,0.790091501107862) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.16.16">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.16.16.17.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T1.16.16.17.1.1">Sets of Weights</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.16.16.17.1.2">Ranking Similarities</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.3.3.3">Minor: <math alttext="1" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><cn id="S3.T1.1.1.1.1.m1.1.1.cmml" type="integer" xref="S3.T1.1.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">1</annotation></semantics></math>, Major: <math alttext="5" class="ltx_Math" display="inline" id="S3.T1.2.2.2.2.m2.1"><semantics id="S3.T1.2.2.2.2.m2.1a"><mn id="S3.T1.2.2.2.2.m2.1.1" xref="S3.T1.2.2.2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m2.1b"><cn id="S3.T1.2.2.2.2.m2.1.1.cmml" type="integer" xref="S3.T1.2.2.2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.2.m2.1d">5</annotation></semantics></math>, Critical: <math alttext="10" class="ltx_Math" display="inline" id="S3.T1.3.3.3.3.m3.1"><semantics id="S3.T1.3.3.3.3.m3.1a"><mn id="S3.T1.3.3.3.3.m3.1.1" xref="S3.T1.3.3.3.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m3.1b"><cn id="S3.T1.3.3.3.3.m3.1.1.cmml" type="integer" xref="S3.T1.3.3.3.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m3.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.3.m3.1d">10</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.4.4.4"><math alttext="0.2711" class="ltx_Math" display="inline" id="S3.T1.4.4.4.4.m1.1"><semantics id="S3.T1.4.4.4.4.m1.1a"><mn id="S3.T1.4.4.4.4.m1.1.1" xref="S3.T1.4.4.4.4.m1.1.1.cmml">0.2711</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.4.m1.1b"><cn id="S3.T1.4.4.4.4.m1.1.1.cmml" type="float" xref="S3.T1.4.4.4.4.m1.1.1">0.2711</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.4.m1.1c">0.2711</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.4.m1.1d">0.2711</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.7.7.7.3">Minor: <math alttext="1" class="ltx_Math" display="inline" id="S3.T1.5.5.5.1.m1.1"><semantics id="S3.T1.5.5.5.1.m1.1a"><mn id="S3.T1.5.5.5.1.m1.1.1" xref="S3.T1.5.5.5.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.1b"><cn id="S3.T1.5.5.5.1.m1.1.1.cmml" type="integer" xref="S3.T1.5.5.5.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.1.m1.1d">1</annotation></semantics></math>, Major: <math alttext="3" class="ltx_Math" display="inline" id="S3.T1.6.6.6.2.m2.1"><semantics id="S3.T1.6.6.6.2.m2.1a"><mn id="S3.T1.6.6.6.2.m2.1.1" xref="S3.T1.6.6.6.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.2.m2.1b"><cn id="S3.T1.6.6.6.2.m2.1.1.cmml" type="integer" xref="S3.T1.6.6.6.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.2.m2.1c">3</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.2.m2.1d">3</annotation></semantics></math>, Critical: <math alttext="9" class="ltx_Math" display="inline" id="S3.T1.7.7.7.3.m3.1"><semantics id="S3.T1.7.7.7.3.m3.1a"><mn id="S3.T1.7.7.7.3.m3.1.1" xref="S3.T1.7.7.7.3.m3.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.3.m3.1b"><cn id="S3.T1.7.7.7.3.m3.1.1.cmml" type="integer" xref="S3.T1.7.7.7.3.m3.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.3.m3.1c">9</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.7.3.m3.1d">9</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.8.4"><math alttext="0.0527" class="ltx_Math" display="inline" id="S3.T1.8.8.8.4.m1.1"><semantics id="S3.T1.8.8.8.4.m1.1a"><mn id="S3.T1.8.8.8.4.m1.1.1" xref="S3.T1.8.8.8.4.m1.1.1.cmml">0.0527</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.4.m1.1b"><cn id="S3.T1.8.8.8.4.m1.1.1.cmml" type="float" xref="S3.T1.8.8.8.4.m1.1.1">0.0527</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.4.m1.1c">0.0527</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.8.4.m1.1d">0.0527</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.12.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.11.11.11.3">Minor: <math alttext="1" class="ltx_Math" display="inline" id="S3.T1.9.9.9.1.m1.1"><semantics id="S3.T1.9.9.9.1.m1.1a"><mn id="S3.T1.9.9.9.1.m1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.1b"><cn id="S3.T1.9.9.9.1.m1.1.1.cmml" type="integer" xref="S3.T1.9.9.9.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.9.1.m1.1d">1</annotation></semantics></math>, Major: <math alttext="5" class="ltx_Math" display="inline" id="S3.T1.10.10.10.2.m2.1"><semantics id="S3.T1.10.10.10.2.m2.1a"><mn id="S3.T1.10.10.10.2.m2.1.1" xref="S3.T1.10.10.10.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.2.m2.1b"><cn id="S3.T1.10.10.10.2.m2.1.1.cmml" type="integer" xref="S3.T1.10.10.10.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.10.2.m2.1d">5</annotation></semantics></math>, Critical: <math alttext="15" class="ltx_Math" display="inline" id="S3.T1.11.11.11.3.m3.1"><semantics id="S3.T1.11.11.11.3.m3.1a"><mn id="S3.T1.11.11.11.3.m3.1.1" xref="S3.T1.11.11.11.3.m3.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.3.m3.1b"><cn id="S3.T1.11.11.11.3.m3.1.1.cmml" type="integer" xref="S3.T1.11.11.11.3.m3.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.3.m3.1c">15</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.11.3.m3.1d">15</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.12.12.12.4"><math alttext="0.0486" class="ltx_Math" display="inline" id="S3.T1.12.12.12.4.m1.1"><semantics id="S3.T1.12.12.12.4.m1.1a"><mn id="S3.T1.12.12.12.4.m1.1.1" xref="S3.T1.12.12.12.4.m1.1.1.cmml">0.0486</mn><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.4.m1.1b"><cn id="S3.T1.12.12.12.4.m1.1.1.cmml" type="float" xref="S3.T1.12.12.12.4.m1.1.1">0.0486</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.4.m1.1c">0.0486</annotation><annotation encoding="application/x-llamapun" id="S3.T1.12.12.12.4.m1.1d">0.0486</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.16.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S3.T1.15.15.15.3">Minor: <math alttext="1" class="ltx_Math" display="inline" id="S3.T1.13.13.13.1.m1.1"><semantics id="S3.T1.13.13.13.1.m1.1a"><mn id="S3.T1.13.13.13.1.m1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.1b"><cn id="S3.T1.13.13.13.1.m1.1.1.cmml" type="integer" xref="S3.T1.13.13.13.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.T1.13.13.13.1.m1.1d">1</annotation></semantics></math>, Major: <math alttext="5" class="ltx_Math" display="inline" id="S3.T1.14.14.14.2.m2.1"><semantics id="S3.T1.14.14.14.2.m2.1a"><mn id="S3.T1.14.14.14.2.m2.1.1" xref="S3.T1.14.14.14.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m2.1b"><cn id="S3.T1.14.14.14.2.m2.1.1.cmml" type="integer" xref="S3.T1.14.14.14.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S3.T1.14.14.14.2.m2.1d">5</annotation></semantics></math>, Critical: <math alttext="25" class="ltx_Math" display="inline" id="S3.T1.15.15.15.3.m3.1"><semantics id="S3.T1.15.15.15.3.m3.1a"><mn id="S3.T1.15.15.15.3.m3.1.1" xref="S3.T1.15.15.15.3.m3.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.3.m3.1b"><cn id="S3.T1.15.15.15.3.m3.1.1.cmml" type="integer" xref="S3.T1.15.15.15.3.m3.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.3.m3.1c">25</annotation><annotation encoding="application/x-llamapun" id="S3.T1.15.15.15.3.m3.1d">25</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.16.16.16.4"><math alttext="0.0515" class="ltx_Math" display="inline" id="S3.T1.16.16.16.4.m1.1"><semantics id="S3.T1.16.16.16.4.m1.1a"><mn id="S3.T1.16.16.16.4.m1.1.1" xref="S3.T1.16.16.16.4.m1.1.1.cmml">0.0515</mn><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.4.m1.1b"><cn id="S3.T1.16.16.16.4.m1.1.1.cmml" type="float" xref="S3.T1.16.16.16.4.m1.1.1">0.0515</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.4.m1.1c">0.0515</annotation><annotation encoding="application/x-llamapun" id="S3.T1.16.16.16.4.m1.1d">0.0515</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Ranking stability of severity weights</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.4">From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S3.T1" title="Table 1 ‣ 3.2 Calculation of MQM Scores ‣ 3 Data ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">1</span></a>, we see that the weights suggested by MQM have the highest Spearman correlation score. That means the MQM scores calculated by these weights are most stable. Meanwhile, this set of weights results in a range of scores between <math alttext="-100" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mo id="S3.SS2.p2.1.m1.1.1a" xref="S3.SS2.p2.1.m1.1.1.cmml">−</mo><mn id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><minus id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"></minus><cn id="S3.SS2.p2.1.m1.1.1.2.cmml" type="integer" xref="S3.SS2.p2.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">-100</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">- 100</annotation></semantics></math> to <math alttext="0" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mn id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><cn id="S3.SS2.p2.2.m2.1.1.cmml" type="integer" xref="S3.SS2.p2.2.m2.1.1">0</cn></annotation-xml></semantics></math>, where <math alttext="-100" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mo id="S3.SS2.p2.3.m3.1.1a" xref="S3.SS2.p2.3.m3.1.1.cmml">−</mo><mn id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><minus id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"></minus><cn id="S3.SS2.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS2.p2.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">-100</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">- 100</annotation></semantics></math> stands for the worst emotion preservation and <math alttext="0" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><mn id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><cn id="S3.SS2.p2.4.m4.1.1.cmml" type="integer" xref="S3.SS2.p2.4.m4.1.1">0</cn></annotation-xml></semantics></math> for the perfect emotion preservation. The nice range of scores enables us to use prompts designed for DA score prediction such as the GEMBA prompt.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The calculated MQM scores serve as the true labels for comparison against the predicted scores extracted from the LLM output in both ICL and PEFT scenarios. The source texts and GT translations are utilized to create prompts for the LLM input, as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS1" title="4.1 In-context Learning ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This section explains the methods we used, <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">i.e.</span>, ICL and PEFT, with the experimental setup. Selected LLMs and baseline models are listed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS3" title="4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>In-context Learning</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We devised two prompt templates that include instructions, source text, machine translation and prompt for scores, to ask LLMs to give a score prediction with error explanations. The main difference between our Template 1 (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">2</span></a>) and Template 2 (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S2.F3" title="Figure 3 ‣ 2 Related Work ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">3</span></a>) is the (italic) instruction. Template 1 instructs LLMs to score the machine translation between -100 to 0 and list erroneous words based on emotion preservation. In addition to the basic instruction, Template 2 also includes information about the definition of errors and how the score is calculated based on error severity.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Apart from zero-shot learning, we employed few-shot learning, where 4 examples<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Due to the input length limit of selected LLMs and the long explanations in the examples, we cannot give more examples than 4.</span></span></span> with different MQM score ranges and errors were inserted into both templates for quality estimation.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>PEFT of LLMs</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To maintain model effectiveness while reducing computational costs, we utilized Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib14" title="">2022</a>)</cite> for parameter efficient fine-tuning of <math alttext="4" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">4</annotation></semantics></math>-bit quantized LLMs <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib3" title="">2023</a>)</cite> instead of full fine-tuning. Both zero-shot and few-shot learning were applied to the fine-tuned LLMs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Models</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We selected a wide range of LLMs, mainly open-source models for both ICL and PEFT. Our models include one of the most influential open-source LLMs—Llama-2-13B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib34" title="">2023</a>)</cite>, models that are claimed to be SoTA Chinese-English LLMs, <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">i.e.</span>, Yi-34B<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.01.ai/" title="">https://www.01.ai/</a></span></span></span> and DeepSeek-67B<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.deepseek.com/" title="">https://www.deepseek.com/</a></span></span></span>, and the Mixture-of-Expert (MoE) model, Mixtral-8x7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib15" title="">2024</a>)</cite>. Gemini Pro<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://gemini.google.com/app" title="">https://gemini.google.com/app</a> at April, 2024</span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib9" title="">2024</a>)</cite> was included in the ICL scenario, to test how proprietary LLMs perform in quality estimation of machine translation of UGC. For PEFT, we tested both the base and the instruction-tuned (chat) models in our experiments.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.42" style="width:298.8pt;height:201.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.8pt,7.3pt) scale(0.932633195696399,0.932633195696399) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.42.42">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.42.42.43.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="2" id="S4.T2.42.42.43.1.1">Methods</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.42.42.43.1.2">Zero-shot Learning</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.42.42.43.1.3">Few-shot Learning</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.2.2.2.3">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.2.2.2.4">Template</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1"><math alttext="\rho" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">italic_ρ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.2.5"><span class="ltx_text ltx_font_italic" id="S4.T2.2.2.2.5.1">r</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.2.2"><math alttext="\rho" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.2.m1.1a"><mi id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.m1.1d">italic_ρ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.2.6"><span class="ltx_text ltx_font_italic" id="S4.T2.2.2.2.6.1">r</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.6.6.6.5" rowspan="2"><span class="ltx_text" id="S4.T2.6.6.6.5.1">Llama-2-13B</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.6.6.6.6">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.3.1"><math alttext="0.2143" class="ltx_Math" display="inline" id="S4.T2.3.3.3.1.m1.1"><semantics id="S4.T2.3.3.3.1.m1.1a"><mn id="S4.T2.3.3.3.1.m1.1.1" xref="S4.T2.3.3.3.1.m1.1.1.cmml">0.2143</mn><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.1.m1.1b"><cn id="S4.T2.3.3.3.1.m1.1.1.cmml" type="float" xref="S4.T2.3.3.3.1.m1.1.1">0.2143</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.1.m1.1c">0.2143</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.1.m1.1d">0.2143</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.4.4.2"><math alttext="0.1782" class="ltx_Math" display="inline" id="S4.T2.4.4.4.2.m1.1"><semantics id="S4.T2.4.4.4.2.m1.1a"><mn id="S4.T2.4.4.4.2.m1.1.1" xref="S4.T2.4.4.4.2.m1.1.1.cmml">0.1782</mn><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.2.m1.1b"><cn id="S4.T2.4.4.4.2.m1.1.1.cmml" type="float" xref="S4.T2.4.4.4.2.m1.1.1">0.1782</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.2.m1.1c">0.1782</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.2.m1.1d">0.1782</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.5.3"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.5.5.5.3.1">-0.025</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.6.4"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.6.6.6.4.1">-0.0194</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.10.10.10.5">2</th>
<td class="ltx_td ltx_align_center" id="S4.T2.7.7.7.1"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.7.7.7.1.1">-0.0310</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.8.8.8.2"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.8.8.8.2.1">0.0260</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.9.9.3"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.9.9.9.3.1">0.0480</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.10.10.4"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S4.T2.10.10.10.4.1">0.0518</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.14.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.14.14.14.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T2.14.14.14.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T2.14.14.14.5.2">Yi-34B</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.14.14.14.6">1</th>
<td class="ltx_td ltx_align_center" id="S4.T2.11.11.11.1"><math alttext="0.2195" class="ltx_Math" display="inline" id="S4.T2.11.11.11.1.m1.1"><semantics id="S4.T2.11.11.11.1.m1.1a"><mn id="S4.T2.11.11.11.1.m1.1.1" xref="S4.T2.11.11.11.1.m1.1.1.cmml">0.2195</mn><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.1.m1.1b"><cn id="S4.T2.11.11.11.1.m1.1.1.cmml" type="float" xref="S4.T2.11.11.11.1.m1.1.1">0.2195</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.1.m1.1c">0.2195</annotation><annotation encoding="application/x-llamapun" id="S4.T2.11.11.11.1.m1.1d">0.2195</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.12.12.12.2"><math alttext="0.1851" class="ltx_Math" display="inline" id="S4.T2.12.12.12.2.m1.1"><semantics id="S4.T2.12.12.12.2.m1.1a"><mn id="S4.T2.12.12.12.2.m1.1.1" xref="S4.T2.12.12.12.2.m1.1.1.cmml">0.1851</mn><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.2.m1.1b"><cn id="S4.T2.12.12.12.2.m1.1.1.cmml" type="float" xref="S4.T2.12.12.12.2.m1.1.1">0.1851</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.2.m1.1c">0.1851</annotation><annotation encoding="application/x-llamapun" id="S4.T2.12.12.12.2.m1.1d">0.1851</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.13.13.13.3"><math alttext="0.3470" class="ltx_Math" display="inline" id="S4.T2.13.13.13.3.m1.1"><semantics id="S4.T2.13.13.13.3.m1.1a"><mn id="S4.T2.13.13.13.3.m1.1.1" xref="S4.T2.13.13.13.3.m1.1.1.cmml">0.3470</mn><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.13.3.m1.1b"><cn id="S4.T2.13.13.13.3.m1.1.1.cmml" type="float" xref="S4.T2.13.13.13.3.m1.1.1">0.3470</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.13.3.m1.1c">0.3470</annotation><annotation encoding="application/x-llamapun" id="S4.T2.13.13.13.3.m1.1d">0.3470</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.14.14.14.4"><math alttext="0.0248" class="ltx_Math" display="inline" id="S4.T2.14.14.14.4.m1.1"><semantics id="S4.T2.14.14.14.4.m1.1a"><mn id="S4.T2.14.14.14.4.m1.1.1" xref="S4.T2.14.14.14.4.m1.1.1.cmml">0.0248</mn><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.4.m1.1b"><cn id="S4.T2.14.14.14.4.m1.1.1.cmml" type="float" xref="S4.T2.14.14.14.4.m1.1.1">0.0248</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.4.m1.1c">0.0248</annotation><annotation encoding="application/x-llamapun" id="S4.T2.14.14.14.4.m1.1d">0.0248</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.18.18.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.18.18.18.5">2</th>
<td class="ltx_td ltx_align_center" id="S4.T2.15.15.15.1"><math alttext="0.2060" class="ltx_Math" display="inline" id="S4.T2.15.15.15.1.m1.1"><semantics id="S4.T2.15.15.15.1.m1.1a"><mn id="S4.T2.15.15.15.1.m1.1.1" xref="S4.T2.15.15.15.1.m1.1.1.cmml">0.2060</mn><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.1.m1.1b"><cn id="S4.T2.15.15.15.1.m1.1.1.cmml" type="float" xref="S4.T2.15.15.15.1.m1.1.1">0.2060</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.1.m1.1c">0.2060</annotation><annotation encoding="application/x-llamapun" id="S4.T2.15.15.15.1.m1.1d">0.2060</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.16.16.16.2"><math alttext="0.0287" class="ltx_Math" display="inline" id="S4.T2.16.16.16.2.m1.1"><semantics id="S4.T2.16.16.16.2.m1.1a"><mn id="S4.T2.16.16.16.2.m1.1.1" xref="S4.T2.16.16.16.2.m1.1.1.cmml">0.0287</mn><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.16.2.m1.1b"><cn id="S4.T2.16.16.16.2.m1.1.1.cmml" type="float" xref="S4.T2.16.16.16.2.m1.1.1">0.0287</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.16.2.m1.1c">0.0287</annotation><annotation encoding="application/x-llamapun" id="S4.T2.16.16.16.2.m1.1d">0.0287</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.17.17.17.3"><math alttext="0.3127" class="ltx_Math" display="inline" id="S4.T2.17.17.17.3.m1.1"><semantics id="S4.T2.17.17.17.3.m1.1a"><mn id="S4.T2.17.17.17.3.m1.1.1" xref="S4.T2.17.17.17.3.m1.1.1.cmml">0.3127</mn><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.17.3.m1.1b"><cn id="S4.T2.17.17.17.3.m1.1.1.cmml" type="float" xref="S4.T2.17.17.17.3.m1.1.1">0.3127</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.17.3.m1.1c">0.3127</annotation><annotation encoding="application/x-llamapun" id="S4.T2.17.17.17.3.m1.1d">0.3127</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.18.18.18.4"><math alttext="0.0236" class="ltx_Math" display="inline" id="S4.T2.18.18.18.4.m1.1"><semantics id="S4.T2.18.18.18.4.m1.1a"><mn id="S4.T2.18.18.18.4.m1.1.1" xref="S4.T2.18.18.18.4.m1.1.1.cmml">0.0236</mn><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.18.4.m1.1b"><cn id="S4.T2.18.18.18.4.m1.1.1.cmml" type="float" xref="S4.T2.18.18.18.4.m1.1.1">0.0236</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.18.4.m1.1c">0.0236</annotation><annotation encoding="application/x-llamapun" id="S4.T2.18.18.18.4.m1.1d">0.0236</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.22.22.22">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.22.22.22.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T2.22.22.22.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T2.22.22.22.5.2">DeepSeek-67B</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.22.22.22.6">1</th>
<td class="ltx_td ltx_align_center" id="S4.T2.19.19.19.1"><math alttext="0.3196" class="ltx_Math" display="inline" id="S4.T2.19.19.19.1.m1.1"><semantics id="S4.T2.19.19.19.1.m1.1a"><mn id="S4.T2.19.19.19.1.m1.1.1" xref="S4.T2.19.19.19.1.m1.1.1.cmml">0.3196</mn><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.19.1.m1.1b"><cn id="S4.T2.19.19.19.1.m1.1.1.cmml" type="float" xref="S4.T2.19.19.19.1.m1.1.1">0.3196</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.19.1.m1.1c">0.3196</annotation><annotation encoding="application/x-llamapun" id="S4.T2.19.19.19.1.m1.1d">0.3196</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.20.20.20.2"><math alttext="0.1821" class="ltx_Math" display="inline" id="S4.T2.20.20.20.2.m1.1"><semantics id="S4.T2.20.20.20.2.m1.1a"><mn id="S4.T2.20.20.20.2.m1.1.1" xref="S4.T2.20.20.20.2.m1.1.1.cmml">0.1821</mn><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.20.2.m1.1b"><cn id="S4.T2.20.20.20.2.m1.1.1.cmml" type="float" xref="S4.T2.20.20.20.2.m1.1.1">0.1821</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.20.2.m1.1c">0.1821</annotation><annotation encoding="application/x-llamapun" id="S4.T2.20.20.20.2.m1.1d">0.1821</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.21.21.21.3"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.21.21.21.3.1">0.4165</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.22.22.22.4"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.22.22.22.4.1">0.2959</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.26.26.26">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.26.26.26.5">2</th>
<td class="ltx_td ltx_align_center" id="S4.T2.23.23.23.1"><math alttext="0.1956" class="ltx_Math" display="inline" id="S4.T2.23.23.23.1.m1.1"><semantics id="S4.T2.23.23.23.1.m1.1a"><mn id="S4.T2.23.23.23.1.m1.1.1" xref="S4.T2.23.23.23.1.m1.1.1.cmml">0.1956</mn><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.23.1.m1.1b"><cn id="S4.T2.23.23.23.1.m1.1.1.cmml" type="float" xref="S4.T2.23.23.23.1.m1.1.1">0.1956</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.23.1.m1.1c">0.1956</annotation><annotation encoding="application/x-llamapun" id="S4.T2.23.23.23.1.m1.1d">0.1956</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.24.24.24.2"><math alttext="0.0260" class="ltx_Math" display="inline" id="S4.T2.24.24.24.2.m1.1"><semantics id="S4.T2.24.24.24.2.m1.1a"><mn id="S4.T2.24.24.24.2.m1.1.1" xref="S4.T2.24.24.24.2.m1.1.1.cmml">0.0260</mn><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.24.2.m1.1b"><cn id="S4.T2.24.24.24.2.m1.1.1.cmml" type="float" xref="S4.T2.24.24.24.2.m1.1.1">0.0260</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.24.2.m1.1c">0.0260</annotation><annotation encoding="application/x-llamapun" id="S4.T2.24.24.24.2.m1.1d">0.0260</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.25.25.25.3"><math alttext="0.3673" class="ltx_Math" display="inline" id="S4.T2.25.25.25.3.m1.1"><semantics id="S4.T2.25.25.25.3.m1.1a"><mn id="S4.T2.25.25.25.3.m1.1.1" xref="S4.T2.25.25.25.3.m1.1.1.cmml">0.3673</mn><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.25.3.m1.1b"><cn id="S4.T2.25.25.25.3.m1.1.1.cmml" type="float" xref="S4.T2.25.25.25.3.m1.1.1">0.3673</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.25.3.m1.1c">0.3673</annotation><annotation encoding="application/x-llamapun" id="S4.T2.25.25.25.3.m1.1d">0.3673</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.26.26.26.4"><math alttext="0.0294" class="ltx_Math" display="inline" id="S4.T2.26.26.26.4.m1.1"><semantics id="S4.T2.26.26.26.4.m1.1a"><mn id="S4.T2.26.26.26.4.m1.1.1" xref="S4.T2.26.26.26.4.m1.1.1.cmml">0.0294</mn><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.26.4.m1.1b"><cn id="S4.T2.26.26.26.4.m1.1.1.cmml" type="float" xref="S4.T2.26.26.26.4.m1.1.1">0.0294</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.26.4.m1.1c">0.0294</annotation><annotation encoding="application/x-llamapun" id="S4.T2.26.26.26.4.m1.1d">0.0294</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.30.30.30">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.30.30.30.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T2.30.30.30.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T2.30.30.30.5.2">Mixtral-8x7B</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.30.30.30.6">1</th>
<td class="ltx_td ltx_align_center" id="S4.T2.27.27.27.1"><math alttext="0.3154" class="ltx_Math" display="inline" id="S4.T2.27.27.27.1.m1.1"><semantics id="S4.T2.27.27.27.1.m1.1a"><mn id="S4.T2.27.27.27.1.m1.1.1" xref="S4.T2.27.27.27.1.m1.1.1.cmml">0.3154</mn><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.27.1.m1.1b"><cn id="S4.T2.27.27.27.1.m1.1.1.cmml" type="float" xref="S4.T2.27.27.27.1.m1.1.1">0.3154</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.27.1.m1.1c">0.3154</annotation><annotation encoding="application/x-llamapun" id="S4.T2.27.27.27.1.m1.1d">0.3154</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.28.28.28.2"><math alttext="0.2633" class="ltx_Math" display="inline" id="S4.T2.28.28.28.2.m1.1"><semantics id="S4.T2.28.28.28.2.m1.1a"><mn id="S4.T2.28.28.28.2.m1.1.1" xref="S4.T2.28.28.28.2.m1.1.1.cmml">0.2633</mn><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.28.2.m1.1b"><cn id="S4.T2.28.28.28.2.m1.1.1.cmml" type="float" xref="S4.T2.28.28.28.2.m1.1.1">0.2633</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.28.2.m1.1c">0.2633</annotation><annotation encoding="application/x-llamapun" id="S4.T2.28.28.28.2.m1.1d">0.2633</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.29.29.29.3"><math alttext="0.3670" class="ltx_Math" display="inline" id="S4.T2.29.29.29.3.m1.1"><semantics id="S4.T2.29.29.29.3.m1.1a"><mn id="S4.T2.29.29.29.3.m1.1.1" xref="S4.T2.29.29.29.3.m1.1.1.cmml">0.3670</mn><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.29.3.m1.1b"><cn id="S4.T2.29.29.29.3.m1.1.1.cmml" type="float" xref="S4.T2.29.29.29.3.m1.1.1">0.3670</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.29.3.m1.1c">0.3670</annotation><annotation encoding="application/x-llamapun" id="S4.T2.29.29.29.3.m1.1d">0.3670</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.30.30.30.4"><math alttext="0.2870" class="ltx_Math" display="inline" id="S4.T2.30.30.30.4.m1.1"><semantics id="S4.T2.30.30.30.4.m1.1a"><mn id="S4.T2.30.30.30.4.m1.1.1" xref="S4.T2.30.30.30.4.m1.1.1.cmml">0.2870</mn><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.30.4.m1.1b"><cn id="S4.T2.30.30.30.4.m1.1.1.cmml" type="float" xref="S4.T2.30.30.30.4.m1.1.1">0.2870</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.30.4.m1.1c">0.2870</annotation><annotation encoding="application/x-llamapun" id="S4.T2.30.30.30.4.m1.1d">0.2870</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.34.34.34">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.34.34.34.5">2</th>
<td class="ltx_td ltx_align_center" id="S4.T2.31.31.31.1"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.31.31.31.1.1">0.3484</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.32.32.32.2"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.32.32.32.2.1">0.3064</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.33.33.33.3"><math alttext="0.2536" class="ltx_Math" display="inline" id="S4.T2.33.33.33.3.m1.1"><semantics id="S4.T2.33.33.33.3.m1.1a"><mn id="S4.T2.33.33.33.3.m1.1.1" xref="S4.T2.33.33.33.3.m1.1.1.cmml">0.2536</mn><annotation-xml encoding="MathML-Content" id="S4.T2.33.33.33.3.m1.1b"><cn id="S4.T2.33.33.33.3.m1.1.1.cmml" type="float" xref="S4.T2.33.33.33.3.m1.1.1">0.2536</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.33.33.33.3.m1.1c">0.2536</annotation><annotation encoding="application/x-llamapun" id="S4.T2.33.33.33.3.m1.1d">0.2536</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.34.34.34.4"><math alttext="0.0405" class="ltx_Math" display="inline" id="S4.T2.34.34.34.4.m1.1"><semantics id="S4.T2.34.34.34.4.m1.1a"><mn id="S4.T2.34.34.34.4.m1.1.1" xref="S4.T2.34.34.34.4.m1.1.1.cmml">0.0405</mn><annotation-xml encoding="MathML-Content" id="S4.T2.34.34.34.4.m1.1b"><cn id="S4.T2.34.34.34.4.m1.1.1.cmml" type="float" xref="S4.T2.34.34.34.4.m1.1.1">0.0405</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.34.34.4.m1.1c">0.0405</annotation><annotation encoding="application/x-llamapun" id="S4.T2.34.34.34.4.m1.1d">0.0405</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.38.38.38">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T2.38.38.38.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T2.38.38.38.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T2.38.38.38.5.2">Gemini Pro</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.38.38.38.6">1</th>
<td class="ltx_td ltx_align_center" id="S4.T2.35.35.35.1"><math alttext="0.2232" class="ltx_Math" display="inline" id="S4.T2.35.35.35.1.m1.1"><semantics id="S4.T2.35.35.35.1.m1.1a"><mn id="S4.T2.35.35.35.1.m1.1.1" xref="S4.T2.35.35.35.1.m1.1.1.cmml">0.2232</mn><annotation-xml encoding="MathML-Content" id="S4.T2.35.35.35.1.m1.1b"><cn id="S4.T2.35.35.35.1.m1.1.1.cmml" type="float" xref="S4.T2.35.35.35.1.m1.1.1">0.2232</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.35.35.35.1.m1.1c">0.2232</annotation><annotation encoding="application/x-llamapun" id="S4.T2.35.35.35.1.m1.1d">0.2232</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.36.36.36.2"><math alttext="0.2416" class="ltx_Math" display="inline" id="S4.T2.36.36.36.2.m1.1"><semantics id="S4.T2.36.36.36.2.m1.1a"><mn id="S4.T2.36.36.36.2.m1.1.1" xref="S4.T2.36.36.36.2.m1.1.1.cmml">0.2416</mn><annotation-xml encoding="MathML-Content" id="S4.T2.36.36.36.2.m1.1b"><cn id="S4.T2.36.36.36.2.m1.1.1.cmml" type="float" xref="S4.T2.36.36.36.2.m1.1.1">0.2416</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.36.36.36.2.m1.1c">0.2416</annotation><annotation encoding="application/x-llamapun" id="S4.T2.36.36.36.2.m1.1d">0.2416</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.37.37.37.3"><math alttext="0.3089" class="ltx_Math" display="inline" id="S4.T2.37.37.37.3.m1.1"><semantics id="S4.T2.37.37.37.3.m1.1a"><mn id="S4.T2.37.37.37.3.m1.1.1" xref="S4.T2.37.37.37.3.m1.1.1.cmml">0.3089</mn><annotation-xml encoding="MathML-Content" id="S4.T2.37.37.37.3.m1.1b"><cn id="S4.T2.37.37.37.3.m1.1.1.cmml" type="float" xref="S4.T2.37.37.37.3.m1.1.1">0.3089</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.37.37.37.3.m1.1c">0.3089</annotation><annotation encoding="application/x-llamapun" id="S4.T2.37.37.37.3.m1.1d">0.3089</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T2.38.38.38.4"><math alttext="0.1830" class="ltx_Math" display="inline" id="S4.T2.38.38.38.4.m1.1"><semantics id="S4.T2.38.38.38.4.m1.1a"><mn id="S4.T2.38.38.38.4.m1.1.1" xref="S4.T2.38.38.38.4.m1.1.1.cmml">0.1830</mn><annotation-xml encoding="MathML-Content" id="S4.T2.38.38.38.4.m1.1b"><cn id="S4.T2.38.38.38.4.m1.1.1.cmml" type="float" xref="S4.T2.38.38.38.4.m1.1.1">0.1830</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.38.38.38.4.m1.1c">0.1830</annotation><annotation encoding="application/x-llamapun" id="S4.T2.38.38.38.4.m1.1d">0.1830</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.42.42.42">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T2.42.42.42.5">2</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.39.39.39.1"><math alttext="0.2554" class="ltx_Math" display="inline" id="S4.T2.39.39.39.1.m1.1"><semantics id="S4.T2.39.39.39.1.m1.1a"><mn id="S4.T2.39.39.39.1.m1.1.1" xref="S4.T2.39.39.39.1.m1.1.1.cmml">0.2554</mn><annotation-xml encoding="MathML-Content" id="S4.T2.39.39.39.1.m1.1b"><cn id="S4.T2.39.39.39.1.m1.1.1.cmml" type="float" xref="S4.T2.39.39.39.1.m1.1.1">0.2554</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.39.39.39.1.m1.1c">0.2554</annotation><annotation encoding="application/x-llamapun" id="S4.T2.39.39.39.1.m1.1d">0.2554</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.40.40.40.2"><math alttext="0.1833" class="ltx_Math" display="inline" id="S4.T2.40.40.40.2.m1.1"><semantics id="S4.T2.40.40.40.2.m1.1a"><mn id="S4.T2.40.40.40.2.m1.1.1" xref="S4.T2.40.40.40.2.m1.1.1.cmml">0.1833</mn><annotation-xml encoding="MathML-Content" id="S4.T2.40.40.40.2.m1.1b"><cn id="S4.T2.40.40.40.2.m1.1.1.cmml" type="float" xref="S4.T2.40.40.40.2.m1.1.1">0.1833</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.40.40.40.2.m1.1c">0.1833</annotation><annotation encoding="application/x-llamapun" id="S4.T2.40.40.40.2.m1.1d">0.1833</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.41.41.41.3"><math alttext="0.3498" class="ltx_Math" display="inline" id="S4.T2.41.41.41.3.m1.1"><semantics id="S4.T2.41.41.41.3.m1.1a"><mn id="S4.T2.41.41.41.3.m1.1.1" xref="S4.T2.41.41.41.3.m1.1.1.cmml">0.3498</mn><annotation-xml encoding="MathML-Content" id="S4.T2.41.41.41.3.m1.1b"><cn id="S4.T2.41.41.41.3.m1.1.1.cmml" type="float" xref="S4.T2.41.41.41.3.m1.1.1">0.3498</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.41.41.41.3.m1.1c">0.3498</annotation><annotation encoding="application/x-llamapun" id="S4.T2.41.41.41.3.m1.1d">0.3498</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.42.42.42.4"><math alttext="0.2441" class="ltx_Math" display="inline" id="S4.T2.42.42.42.4.m1.1"><semantics id="S4.T2.42.42.42.4.m1.1a"><mn id="S4.T2.42.42.42.4.m1.1.1" xref="S4.T2.42.42.42.4.m1.1.1.cmml">0.2441</mn><annotation-xml encoding="MathML-Content" id="S4.T2.42.42.42.4.m1.1b"><cn id="S4.T2.42.42.42.4.m1.1.1.cmml" type="float" xref="S4.T2.42.42.42.4.m1.1.1">0.2441</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.42.42.42.4.m1.1c">0.2441</annotation><annotation encoding="application/x-llamapun" id="S4.T2.42.42.42.4.m1.1d">0.2441</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Spearman <math alttext="\rho" class="ltx_Math" display="inline" id="S4.T2.44.m1.1"><semantics id="S4.T2.44.m1.1b"><mi id="S4.T2.44.m1.1.1" xref="S4.T2.44.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.44.m1.1c"><ci id="S4.T2.44.m1.1.1.cmml" xref="S4.T2.44.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.44.m1.1d">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T2.44.m1.1e">italic_ρ</annotation></semantics></math> and Pearson’s <span class="ltx_text ltx_font_italic" id="S4.T2.47.1">r</span> correlation scores for score prediction in <span class="ltx_text ltx_font_bold" id="S4.T2.48.2">ICL</span> scenario</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.66" style="width:313.0pt;height:278pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.9pt,23.0pt) scale(0.858066845580174,0.858066845580174) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.66.66">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.66.66.67.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2" id="S4.T3.66.66.67.1.1">Methods</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T3.66.66.67.1.2">Zero-shot Learning</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T3.66.66.67.1.3">Few-shot Learning</th>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T3.2.2.2.3">Models</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.2.4">Template</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.1.1.1"><math alttext="\rho" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">italic_ρ</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.2.5"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.5.1">r</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.2.2"><math alttext="\rho" class="ltx_Math" display="inline" id="S4.T3.2.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.2.m1.1a"><mi id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.2.m1.1d">italic_ρ</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.2.2.2.6"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.6.1">r</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T3.6.6.6.5" rowspan="2"><span class="ltx_text" id="S4.T3.6.6.6.5.1">Llama-2-13B Chat</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.6.6">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.3.1"><math alttext="0.3114" class="ltx_Math" display="inline" id="S4.T3.3.3.3.1.m1.1"><semantics id="S4.T3.3.3.3.1.m1.1a"><mn id="S4.T3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.1.m1.1.1.cmml">0.3114</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.m1.1b"><cn id="S4.T3.3.3.3.1.m1.1.1.cmml" type="float" xref="S4.T3.3.3.3.1.m1.1.1">0.3114</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.1.m1.1c">0.3114</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.1.m1.1d">0.3114</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.4.4.2"><math alttext="0.2511" class="ltx_Math" display="inline" id="S4.T3.4.4.4.2.m1.1"><semantics id="S4.T3.4.4.4.2.m1.1a"><mn id="S4.T3.4.4.4.2.m1.1.1" xref="S4.T3.4.4.4.2.m1.1.1.cmml">0.2511</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.2.m1.1b"><cn id="S4.T3.4.4.4.2.m1.1.1.cmml" type="float" xref="S4.T3.4.4.4.2.m1.1.1">0.2511</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.2.m1.1c">0.2511</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.2.m1.1d">0.2511</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.5.3"><math alttext="0.1028" class="ltx_Math" display="inline" id="S4.T3.5.5.5.3.m1.1"><semantics id="S4.T3.5.5.5.3.m1.1a"><mn id="S4.T3.5.5.5.3.m1.1.1" xref="S4.T3.5.5.5.3.m1.1.1.cmml">0.1028</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.3.m1.1b"><cn id="S4.T3.5.5.5.3.m1.1.1.cmml" type="float" xref="S4.T3.5.5.5.3.m1.1.1">0.1028</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.3.m1.1c">0.1028</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.3.m1.1d">0.1028</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.6.4"><math alttext="0.0061" class="ltx_Math" display="inline" id="S4.T3.6.6.6.4.m1.1"><semantics id="S4.T3.6.6.6.4.m1.1a"><mn id="S4.T3.6.6.6.4.m1.1.1" xref="S4.T3.6.6.6.4.m1.1.1.cmml">0.0061</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.4.m1.1b"><cn id="S4.T3.6.6.6.4.m1.1.1.cmml" type="float" xref="S4.T3.6.6.6.4.m1.1.1">0.0061</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.4.m1.1c">0.0061</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.4.m1.1d">0.0061</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.10.10.10">
<td class="ltx_td ltx_align_center" id="S4.T3.10.10.10.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.7.7.7.1"><math alttext="0.3362" class="ltx_Math" display="inline" id="S4.T3.7.7.7.1.m1.1"><semantics id="S4.T3.7.7.7.1.m1.1a"><mn id="S4.T3.7.7.7.1.m1.1.1" xref="S4.T3.7.7.7.1.m1.1.1.cmml">0.3362</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.1.m1.1b"><cn id="S4.T3.7.7.7.1.m1.1.1.cmml" type="float" xref="S4.T3.7.7.7.1.m1.1.1">0.3362</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.1.m1.1c">0.3362</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.7.1.m1.1d">0.3362</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.8.8.2"><math alttext="0.2782" class="ltx_Math" display="inline" id="S4.T3.8.8.8.2.m1.1"><semantics id="S4.T3.8.8.8.2.m1.1a"><mn id="S4.T3.8.8.8.2.m1.1.1" xref="S4.T3.8.8.8.2.m1.1.1.cmml">0.2782</mn><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.2.m1.1b"><cn id="S4.T3.8.8.8.2.m1.1.1.cmml" type="float" xref="S4.T3.8.8.8.2.m1.1.1">0.2782</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.2.m1.1c">0.2782</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.8.2.m1.1d">0.2782</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.9.9.9.3"><math alttext="0.1713" class="ltx_Math" display="inline" id="S4.T3.9.9.9.3.m1.1"><semantics id="S4.T3.9.9.9.3.m1.1a"><mn id="S4.T3.9.9.9.3.m1.1.1" xref="S4.T3.9.9.9.3.m1.1.1.cmml">0.1713</mn><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.3.m1.1b"><cn id="S4.T3.9.9.9.3.m1.1.1.cmml" type="float" xref="S4.T3.9.9.9.3.m1.1.1">0.1713</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.3.m1.1c">0.1713</annotation><annotation encoding="application/x-llamapun" id="S4.T3.9.9.9.3.m1.1d">0.1713</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.10.10.10.4"><math alttext="0.1538" class="ltx_Math" display="inline" id="S4.T3.10.10.10.4.m1.1"><semantics id="S4.T3.10.10.10.4.m1.1a"><mn id="S4.T3.10.10.10.4.m1.1.1" xref="S4.T3.10.10.10.4.m1.1.1.cmml">0.1538</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.10.4.m1.1b"><cn id="S4.T3.10.10.10.4.m1.1.1.cmml" type="float" xref="S4.T3.10.10.10.4.m1.1.1">0.1538</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.10.4.m1.1c">0.1538</annotation><annotation encoding="application/x-llamapun" id="S4.T3.10.10.10.4.m1.1d">0.1538</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.14.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.14.14.14.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.14.14.14.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.14.14.14.5.2">Yi-34B Chat</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.14.14.14.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.11.11.11.1"><math alttext="0.5880" class="ltx_Math" display="inline" id="S4.T3.11.11.11.1.m1.1"><semantics id="S4.T3.11.11.11.1.m1.1a"><mn id="S4.T3.11.11.11.1.m1.1.1" xref="S4.T3.11.11.11.1.m1.1.1.cmml">0.5880</mn><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.11.1.m1.1b"><cn id="S4.T3.11.11.11.1.m1.1.1.cmml" type="float" xref="S4.T3.11.11.11.1.m1.1.1">0.5880</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.11.1.m1.1c">0.5880</annotation><annotation encoding="application/x-llamapun" id="S4.T3.11.11.11.1.m1.1d">0.5880</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.12.2"><math alttext="0.5902" class="ltx_Math" display="inline" id="S4.T3.12.12.12.2.m1.1"><semantics id="S4.T3.12.12.12.2.m1.1a"><mn id="S4.T3.12.12.12.2.m1.1.1" xref="S4.T3.12.12.12.2.m1.1.1.cmml">0.5902</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.2.m1.1b"><cn id="S4.T3.12.12.12.2.m1.1.1.cmml" type="float" xref="S4.T3.12.12.12.2.m1.1.1">0.5902</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.2.m1.1c">0.5902</annotation><annotation encoding="application/x-llamapun" id="S4.T3.12.12.12.2.m1.1d">0.5902</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.13.13.13.3"><math alttext="0.4950" class="ltx_Math" display="inline" id="S4.T3.13.13.13.3.m1.1"><semantics id="S4.T3.13.13.13.3.m1.1a"><mn id="S4.T3.13.13.13.3.m1.1.1" xref="S4.T3.13.13.13.3.m1.1.1.cmml">0.4950</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.13.3.m1.1b"><cn id="S4.T3.13.13.13.3.m1.1.1.cmml" type="float" xref="S4.T3.13.13.13.3.m1.1.1">0.4950</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.13.3.m1.1c">0.4950</annotation><annotation encoding="application/x-llamapun" id="S4.T3.13.13.13.3.m1.1d">0.4950</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.14.14.14.4"><math alttext="0.3685" class="ltx_Math" display="inline" id="S4.T3.14.14.14.4.m1.1"><semantics id="S4.T3.14.14.14.4.m1.1a"><mn id="S4.T3.14.14.14.4.m1.1.1" xref="S4.T3.14.14.14.4.m1.1.1.cmml">0.3685</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.14.4.m1.1b"><cn id="S4.T3.14.14.14.4.m1.1.1.cmml" type="float" xref="S4.T3.14.14.14.4.m1.1.1">0.3685</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.14.4.m1.1c">0.3685</annotation><annotation encoding="application/x-llamapun" id="S4.T3.14.14.14.4.m1.1d">0.3685</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.18.18.18">
<td class="ltx_td ltx_align_center" id="S4.T3.18.18.18.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.15.15.15.1"><math alttext="0.5934" class="ltx_Math" display="inline" id="S4.T3.15.15.15.1.m1.1"><semantics id="S4.T3.15.15.15.1.m1.1a"><mn id="S4.T3.15.15.15.1.m1.1.1" xref="S4.T3.15.15.15.1.m1.1.1.cmml">0.5934</mn><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.15.1.m1.1b"><cn id="S4.T3.15.15.15.1.m1.1.1.cmml" type="float" xref="S4.T3.15.15.15.1.m1.1.1">0.5934</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.15.1.m1.1c">0.5934</annotation><annotation encoding="application/x-llamapun" id="S4.T3.15.15.15.1.m1.1d">0.5934</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.16.16.16.2"><math alttext="0.5490" class="ltx_Math" display="inline" id="S4.T3.16.16.16.2.m1.1"><semantics id="S4.T3.16.16.16.2.m1.1a"><mn id="S4.T3.16.16.16.2.m1.1.1" xref="S4.T3.16.16.16.2.m1.1.1.cmml">0.5490</mn><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.16.2.m1.1b"><cn id="S4.T3.16.16.16.2.m1.1.1.cmml" type="float" xref="S4.T3.16.16.16.2.m1.1.1">0.5490</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.16.2.m1.1c">0.5490</annotation><annotation encoding="application/x-llamapun" id="S4.T3.16.16.16.2.m1.1d">0.5490</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.17.17.17.3"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.17.17.17.3.1">0.5779</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.18.18.18.4"><math alttext="0.4663" class="ltx_Math" display="inline" id="S4.T3.18.18.18.4.m1.1"><semantics id="S4.T3.18.18.18.4.m1.1a"><mn id="S4.T3.18.18.18.4.m1.1.1" xref="S4.T3.18.18.18.4.m1.1.1.cmml">0.4663</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.18.4.m1.1b"><cn id="S4.T3.18.18.18.4.m1.1.1.cmml" type="float" xref="S4.T3.18.18.18.4.m1.1.1">0.4663</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.18.4.m1.1c">0.4663</annotation><annotation encoding="application/x-llamapun" id="S4.T3.18.18.18.4.m1.1d">0.4663</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.22.22.22">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.22.22.22.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.22.22.22.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.22.22.22.5.2">DeepSeek-67B Chat</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.22.22.22.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.19.19.19.1"><math alttext="0.5741" class="ltx_Math" display="inline" id="S4.T3.19.19.19.1.m1.1"><semantics id="S4.T3.19.19.19.1.m1.1a"><mn id="S4.T3.19.19.19.1.m1.1.1" xref="S4.T3.19.19.19.1.m1.1.1.cmml">0.5741</mn><annotation-xml encoding="MathML-Content" id="S4.T3.19.19.19.1.m1.1b"><cn id="S4.T3.19.19.19.1.m1.1.1.cmml" type="float" xref="S4.T3.19.19.19.1.m1.1.1">0.5741</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.19.19.1.m1.1c">0.5741</annotation><annotation encoding="application/x-llamapun" id="S4.T3.19.19.19.1.m1.1d">0.5741</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.20.20.20.2"><math alttext="0.5325" class="ltx_Math" display="inline" id="S4.T3.20.20.20.2.m1.1"><semantics id="S4.T3.20.20.20.2.m1.1a"><mn id="S4.T3.20.20.20.2.m1.1.1" xref="S4.T3.20.20.20.2.m1.1.1.cmml">0.5325</mn><annotation-xml encoding="MathML-Content" id="S4.T3.20.20.20.2.m1.1b"><cn id="S4.T3.20.20.20.2.m1.1.1.cmml" type="float" xref="S4.T3.20.20.20.2.m1.1.1">0.5325</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.20.20.2.m1.1c">0.5325</annotation><annotation encoding="application/x-llamapun" id="S4.T3.20.20.20.2.m1.1d">0.5325</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.21.21.21.3"><math alttext="0.5601" class="ltx_Math" display="inline" id="S4.T3.21.21.21.3.m1.1"><semantics id="S4.T3.21.21.21.3.m1.1a"><mn id="S4.T3.21.21.21.3.m1.1.1" xref="S4.T3.21.21.21.3.m1.1.1.cmml">0.5601</mn><annotation-xml encoding="MathML-Content" id="S4.T3.21.21.21.3.m1.1b"><cn id="S4.T3.21.21.21.3.m1.1.1.cmml" type="float" xref="S4.T3.21.21.21.3.m1.1.1">0.5601</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.21.21.3.m1.1c">0.5601</annotation><annotation encoding="application/x-llamapun" id="S4.T3.21.21.21.3.m1.1d">0.5601</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.22.22.22.4"><math alttext="0.5261" class="ltx_Math" display="inline" id="S4.T3.22.22.22.4.m1.1"><semantics id="S4.T3.22.22.22.4.m1.1a"><mn id="S4.T3.22.22.22.4.m1.1.1" xref="S4.T3.22.22.22.4.m1.1.1.cmml">0.5261</mn><annotation-xml encoding="MathML-Content" id="S4.T3.22.22.22.4.m1.1b"><cn id="S4.T3.22.22.22.4.m1.1.1.cmml" type="float" xref="S4.T3.22.22.22.4.m1.1.1">0.5261</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.22.22.4.m1.1c">0.5261</annotation><annotation encoding="application/x-llamapun" id="S4.T3.22.22.22.4.m1.1d">0.5261</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.26.26.26">
<td class="ltx_td ltx_align_center" id="S4.T3.26.26.26.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.23.23.23.1"><math alttext="0.6192" class="ltx_Math" display="inline" id="S4.T3.23.23.23.1.m1.1"><semantics id="S4.T3.23.23.23.1.m1.1a"><mn id="S4.T3.23.23.23.1.m1.1.1" xref="S4.T3.23.23.23.1.m1.1.1.cmml">0.6192</mn><annotation-xml encoding="MathML-Content" id="S4.T3.23.23.23.1.m1.1b"><cn id="S4.T3.23.23.23.1.m1.1.1.cmml" type="float" xref="S4.T3.23.23.23.1.m1.1.1">0.6192</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.23.23.1.m1.1c">0.6192</annotation><annotation encoding="application/x-llamapun" id="S4.T3.23.23.23.1.m1.1d">0.6192</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.24.24.24.2"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.24.24.24.2.1">0.5983</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.25.25.25.3"><math alttext="0.5567" class="ltx_Math" display="inline" id="S4.T3.25.25.25.3.m1.1"><semantics id="S4.T3.25.25.25.3.m1.1a"><mn id="S4.T3.25.25.25.3.m1.1.1" xref="S4.T3.25.25.25.3.m1.1.1.cmml">0.5567</mn><annotation-xml encoding="MathML-Content" id="S4.T3.25.25.25.3.m1.1b"><cn id="S4.T3.25.25.25.3.m1.1.1.cmml" type="float" xref="S4.T3.25.25.25.3.m1.1.1">0.5567</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.25.25.3.m1.1c">0.5567</annotation><annotation encoding="application/x-llamapun" id="S4.T3.25.25.25.3.m1.1d">0.5567</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.26.26.26.4"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.26.26.26.4.1">0.5321</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.30.30.30">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.30.30.30.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.30.30.30.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.30.30.30.5.2">Mixtral-8x7B Instruct</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.30.30.30.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.27.27.27.1"><math alttext="0.4577" class="ltx_Math" display="inline" id="S4.T3.27.27.27.1.m1.1"><semantics id="S4.T3.27.27.27.1.m1.1a"><mn id="S4.T3.27.27.27.1.m1.1.1" xref="S4.T3.27.27.27.1.m1.1.1.cmml">0.4577</mn><annotation-xml encoding="MathML-Content" id="S4.T3.27.27.27.1.m1.1b"><cn id="S4.T3.27.27.27.1.m1.1.1.cmml" type="float" xref="S4.T3.27.27.27.1.m1.1.1">0.4577</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.27.27.1.m1.1c">0.4577</annotation><annotation encoding="application/x-llamapun" id="S4.T3.27.27.27.1.m1.1d">0.4577</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.28.28.28.2"><math alttext="0.4717" class="ltx_Math" display="inline" id="S4.T3.28.28.28.2.m1.1"><semantics id="S4.T3.28.28.28.2.m1.1a"><mn id="S4.T3.28.28.28.2.m1.1.1" xref="S4.T3.28.28.28.2.m1.1.1.cmml">0.4717</mn><annotation-xml encoding="MathML-Content" id="S4.T3.28.28.28.2.m1.1b"><cn id="S4.T3.28.28.28.2.m1.1.1.cmml" type="float" xref="S4.T3.28.28.28.2.m1.1.1">0.4717</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.28.28.2.m1.1c">0.4717</annotation><annotation encoding="application/x-llamapun" id="S4.T3.28.28.28.2.m1.1d">0.4717</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.29.29.29.3"><math alttext="0.4477" class="ltx_Math" display="inline" id="S4.T3.29.29.29.3.m1.1"><semantics id="S4.T3.29.29.29.3.m1.1a"><mn id="S4.T3.29.29.29.3.m1.1.1" xref="S4.T3.29.29.29.3.m1.1.1.cmml">0.4477</mn><annotation-xml encoding="MathML-Content" id="S4.T3.29.29.29.3.m1.1b"><cn id="S4.T3.29.29.29.3.m1.1.1.cmml" type="float" xref="S4.T3.29.29.29.3.m1.1.1">0.4477</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.29.29.3.m1.1c">0.4477</annotation><annotation encoding="application/x-llamapun" id="S4.T3.29.29.29.3.m1.1d">0.4477</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.30.30.30.4"><math alttext="0.3444" class="ltx_Math" display="inline" id="S4.T3.30.30.30.4.m1.1"><semantics id="S4.T3.30.30.30.4.m1.1a"><mn id="S4.T3.30.30.30.4.m1.1.1" xref="S4.T3.30.30.30.4.m1.1.1.cmml">0.3444</mn><annotation-xml encoding="MathML-Content" id="S4.T3.30.30.30.4.m1.1b"><cn id="S4.T3.30.30.30.4.m1.1.1.cmml" type="float" xref="S4.T3.30.30.30.4.m1.1.1">0.3444</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.30.30.4.m1.1c">0.3444</annotation><annotation encoding="application/x-llamapun" id="S4.T3.30.30.30.4.m1.1d">0.3444</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.34.34.34">
<td class="ltx_td ltx_align_center" id="S4.T3.34.34.34.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.31.31.31.1"><math alttext="0.4256" class="ltx_Math" display="inline" id="S4.T3.31.31.31.1.m1.1"><semantics id="S4.T3.31.31.31.1.m1.1a"><mn id="S4.T3.31.31.31.1.m1.1.1" xref="S4.T3.31.31.31.1.m1.1.1.cmml">0.4256</mn><annotation-xml encoding="MathML-Content" id="S4.T3.31.31.31.1.m1.1b"><cn id="S4.T3.31.31.31.1.m1.1.1.cmml" type="float" xref="S4.T3.31.31.31.1.m1.1.1">0.4256</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.31.31.31.1.m1.1c">0.4256</annotation><annotation encoding="application/x-llamapun" id="S4.T3.31.31.31.1.m1.1d">0.4256</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.32.32.32.2"><math alttext="0.3542" class="ltx_Math" display="inline" id="S4.T3.32.32.32.2.m1.1"><semantics id="S4.T3.32.32.32.2.m1.1a"><mn id="S4.T3.32.32.32.2.m1.1.1" xref="S4.T3.32.32.32.2.m1.1.1.cmml">0.3542</mn><annotation-xml encoding="MathML-Content" id="S4.T3.32.32.32.2.m1.1b"><cn id="S4.T3.32.32.32.2.m1.1.1.cmml" type="float" xref="S4.T3.32.32.32.2.m1.1.1">0.3542</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.32.32.32.2.m1.1c">0.3542</annotation><annotation encoding="application/x-llamapun" id="S4.T3.32.32.32.2.m1.1d">0.3542</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.33.33.33.3"><math alttext="0.3712" class="ltx_Math" display="inline" id="S4.T3.33.33.33.3.m1.1"><semantics id="S4.T3.33.33.33.3.m1.1a"><mn id="S4.T3.33.33.33.3.m1.1.1" xref="S4.T3.33.33.33.3.m1.1.1.cmml">0.3712</mn><annotation-xml encoding="MathML-Content" id="S4.T3.33.33.33.3.m1.1b"><cn id="S4.T3.33.33.33.3.m1.1.1.cmml" type="float" xref="S4.T3.33.33.33.3.m1.1.1">0.3712</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.33.33.33.3.m1.1c">0.3712</annotation><annotation encoding="application/x-llamapun" id="S4.T3.33.33.33.3.m1.1d">0.3712</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.34.34.34.4"><math alttext="0.2709" class="ltx_Math" display="inline" id="S4.T3.34.34.34.4.m1.1"><semantics id="S4.T3.34.34.34.4.m1.1a"><mn id="S4.T3.34.34.34.4.m1.1.1" xref="S4.T3.34.34.34.4.m1.1.1.cmml">0.2709</mn><annotation-xml encoding="MathML-Content" id="S4.T3.34.34.34.4.m1.1b"><cn id="S4.T3.34.34.34.4.m1.1.1.cmml" type="float" xref="S4.T3.34.34.34.4.m1.1.1">0.2709</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.34.34.34.4.m1.1c">0.2709</annotation><annotation encoding="application/x-llamapun" id="S4.T3.34.34.34.4.m1.1d">0.2709</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.38.38.38">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T3.38.38.38.5" rowspan="2"><span class="ltx_text" id="S4.T3.38.38.38.5.1">Llama-2-13B Base</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.38.38.38.6">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.35.35.35.1"><math alttext="0.2468" class="ltx_Math" display="inline" id="S4.T3.35.35.35.1.m1.1"><semantics id="S4.T3.35.35.35.1.m1.1a"><mn id="S4.T3.35.35.35.1.m1.1.1" xref="S4.T3.35.35.35.1.m1.1.1.cmml">0.2468</mn><annotation-xml encoding="MathML-Content" id="S4.T3.35.35.35.1.m1.1b"><cn id="S4.T3.35.35.35.1.m1.1.1.cmml" type="float" xref="S4.T3.35.35.35.1.m1.1.1">0.2468</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.35.35.35.1.m1.1c">0.2468</annotation><annotation encoding="application/x-llamapun" id="S4.T3.35.35.35.1.m1.1d">0.2468</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.36.36.36.2"><math alttext="0.3197" class="ltx_Math" display="inline" id="S4.T3.36.36.36.2.m1.1"><semantics id="S4.T3.36.36.36.2.m1.1a"><mn id="S4.T3.36.36.36.2.m1.1.1" xref="S4.T3.36.36.36.2.m1.1.1.cmml">0.3197</mn><annotation-xml encoding="MathML-Content" id="S4.T3.36.36.36.2.m1.1b"><cn id="S4.T3.36.36.36.2.m1.1.1.cmml" type="float" xref="S4.T3.36.36.36.2.m1.1.1">0.3197</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.36.36.36.2.m1.1c">0.3197</annotation><annotation encoding="application/x-llamapun" id="S4.T3.36.36.36.2.m1.1d">0.3197</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.37.37.37.3"><math alttext="0.1371" class="ltx_Math" display="inline" id="S4.T3.37.37.37.3.m1.1"><semantics id="S4.T3.37.37.37.3.m1.1a"><mn id="S4.T3.37.37.37.3.m1.1.1" xref="S4.T3.37.37.37.3.m1.1.1.cmml">0.1371</mn><annotation-xml encoding="MathML-Content" id="S4.T3.37.37.37.3.m1.1b"><cn id="S4.T3.37.37.37.3.m1.1.1.cmml" type="float" xref="S4.T3.37.37.37.3.m1.1.1">0.1371</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.37.37.37.3.m1.1c">0.1371</annotation><annotation encoding="application/x-llamapun" id="S4.T3.37.37.37.3.m1.1d">0.1371</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.38.38.38.4"><math alttext="0.0989" class="ltx_Math" display="inline" id="S4.T3.38.38.38.4.m1.1"><semantics id="S4.T3.38.38.38.4.m1.1a"><mn id="S4.T3.38.38.38.4.m1.1.1" xref="S4.T3.38.38.38.4.m1.1.1.cmml">0.0989</mn><annotation-xml encoding="MathML-Content" id="S4.T3.38.38.38.4.m1.1b"><cn id="S4.T3.38.38.38.4.m1.1.1.cmml" type="float" xref="S4.T3.38.38.38.4.m1.1.1">0.0989</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.38.38.38.4.m1.1c">0.0989</annotation><annotation encoding="application/x-llamapun" id="S4.T3.38.38.38.4.m1.1d">0.0989</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.42.42.42">
<td class="ltx_td ltx_align_center" id="S4.T3.42.42.42.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.39.39.39.1"><math alttext="0.2848" class="ltx_Math" display="inline" id="S4.T3.39.39.39.1.m1.1"><semantics id="S4.T3.39.39.39.1.m1.1a"><mn id="S4.T3.39.39.39.1.m1.1.1" xref="S4.T3.39.39.39.1.m1.1.1.cmml">0.2848</mn><annotation-xml encoding="MathML-Content" id="S4.T3.39.39.39.1.m1.1b"><cn id="S4.T3.39.39.39.1.m1.1.1.cmml" type="float" xref="S4.T3.39.39.39.1.m1.1.1">0.2848</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.39.39.39.1.m1.1c">0.2848</annotation><annotation encoding="application/x-llamapun" id="S4.T3.39.39.39.1.m1.1d">0.2848</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.40.40.40.2"><math alttext="0.3391" class="ltx_Math" display="inline" id="S4.T3.40.40.40.2.m1.1"><semantics id="S4.T3.40.40.40.2.m1.1a"><mn id="S4.T3.40.40.40.2.m1.1.1" xref="S4.T3.40.40.40.2.m1.1.1.cmml">0.3391</mn><annotation-xml encoding="MathML-Content" id="S4.T3.40.40.40.2.m1.1b"><cn id="S4.T3.40.40.40.2.m1.1.1.cmml" type="float" xref="S4.T3.40.40.40.2.m1.1.1">0.3391</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.40.40.40.2.m1.1c">0.3391</annotation><annotation encoding="application/x-llamapun" id="S4.T3.40.40.40.2.m1.1d">0.3391</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.41.41.41.3"><math alttext="0.0085" class="ltx_Math" display="inline" id="S4.T3.41.41.41.3.m1.1"><semantics id="S4.T3.41.41.41.3.m1.1a"><mn id="S4.T3.41.41.41.3.m1.1.1" xref="S4.T3.41.41.41.3.m1.1.1.cmml">0.0085</mn><annotation-xml encoding="MathML-Content" id="S4.T3.41.41.41.3.m1.1b"><cn id="S4.T3.41.41.41.3.m1.1.1.cmml" type="float" xref="S4.T3.41.41.41.3.m1.1.1">0.0085</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.41.41.41.3.m1.1c">0.0085</annotation><annotation encoding="application/x-llamapun" id="S4.T3.41.41.41.3.m1.1d">0.0085</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.42.42.42.4"><math alttext="0.0226" class="ltx_Math" display="inline" id="S4.T3.42.42.42.4.m1.1"><semantics id="S4.T3.42.42.42.4.m1.1a"><mn id="S4.T3.42.42.42.4.m1.1.1" xref="S4.T3.42.42.42.4.m1.1.1.cmml">0.0226</mn><annotation-xml encoding="MathML-Content" id="S4.T3.42.42.42.4.m1.1b"><cn id="S4.T3.42.42.42.4.m1.1.1.cmml" type="float" xref="S4.T3.42.42.42.4.m1.1.1">0.0226</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.42.42.42.4.m1.1c">0.0226</annotation><annotation encoding="application/x-llamapun" id="S4.T3.42.42.42.4.m1.1d">0.0226</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.46.46.46">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.46.46.46.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.46.46.46.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.46.46.46.5.2">Yi-34B Base</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.46.46.46.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.43.43.43.1"><math alttext="0.5694" class="ltx_Math" display="inline" id="S4.T3.43.43.43.1.m1.1"><semantics id="S4.T3.43.43.43.1.m1.1a"><mn id="S4.T3.43.43.43.1.m1.1.1" xref="S4.T3.43.43.43.1.m1.1.1.cmml">0.5694</mn><annotation-xml encoding="MathML-Content" id="S4.T3.43.43.43.1.m1.1b"><cn id="S4.T3.43.43.43.1.m1.1.1.cmml" type="float" xref="S4.T3.43.43.43.1.m1.1.1">0.5694</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.43.43.43.1.m1.1c">0.5694</annotation><annotation encoding="application/x-llamapun" id="S4.T3.43.43.43.1.m1.1d">0.5694</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.44.44.44.2"><math alttext="0.4881" class="ltx_Math" display="inline" id="S4.T3.44.44.44.2.m1.1"><semantics id="S4.T3.44.44.44.2.m1.1a"><mn id="S4.T3.44.44.44.2.m1.1.1" xref="S4.T3.44.44.44.2.m1.1.1.cmml">0.4881</mn><annotation-xml encoding="MathML-Content" id="S4.T3.44.44.44.2.m1.1b"><cn id="S4.T3.44.44.44.2.m1.1.1.cmml" type="float" xref="S4.T3.44.44.44.2.m1.1.1">0.4881</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.44.44.44.2.m1.1c">0.4881</annotation><annotation encoding="application/x-llamapun" id="S4.T3.44.44.44.2.m1.1d">0.4881</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.45.45.45.3"><math alttext="0.3589" class="ltx_Math" display="inline" id="S4.T3.45.45.45.3.m1.1"><semantics id="S4.T3.45.45.45.3.m1.1a"><mn id="S4.T3.45.45.45.3.m1.1.1" xref="S4.T3.45.45.45.3.m1.1.1.cmml">0.3589</mn><annotation-xml encoding="MathML-Content" id="S4.T3.45.45.45.3.m1.1b"><cn id="S4.T3.45.45.45.3.m1.1.1.cmml" type="float" xref="S4.T3.45.45.45.3.m1.1.1">0.3589</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.45.45.45.3.m1.1c">0.3589</annotation><annotation encoding="application/x-llamapun" id="S4.T3.45.45.45.3.m1.1d">0.3589</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.46.46.46.4"><math alttext="0.3370" class="ltx_Math" display="inline" id="S4.T3.46.46.46.4.m1.1"><semantics id="S4.T3.46.46.46.4.m1.1a"><mn id="S4.T3.46.46.46.4.m1.1.1" xref="S4.T3.46.46.46.4.m1.1.1.cmml">0.3370</mn><annotation-xml encoding="MathML-Content" id="S4.T3.46.46.46.4.m1.1b"><cn id="S4.T3.46.46.46.4.m1.1.1.cmml" type="float" xref="S4.T3.46.46.46.4.m1.1.1">0.3370</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.46.46.46.4.m1.1c">0.3370</annotation><annotation encoding="application/x-llamapun" id="S4.T3.46.46.46.4.m1.1d">0.3370</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.50.50.50">
<td class="ltx_td ltx_align_center" id="S4.T3.50.50.50.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.47.47.47.1"><math alttext="0.4883" class="ltx_Math" display="inline" id="S4.T3.47.47.47.1.m1.1"><semantics id="S4.T3.47.47.47.1.m1.1a"><mn id="S4.T3.47.47.47.1.m1.1.1" xref="S4.T3.47.47.47.1.m1.1.1.cmml">0.4883</mn><annotation-xml encoding="MathML-Content" id="S4.T3.47.47.47.1.m1.1b"><cn id="S4.T3.47.47.47.1.m1.1.1.cmml" type="float" xref="S4.T3.47.47.47.1.m1.1.1">0.4883</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.47.47.47.1.m1.1c">0.4883</annotation><annotation encoding="application/x-llamapun" id="S4.T3.47.47.47.1.m1.1d">0.4883</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.48.48.48.2"><math alttext="0.4953" class="ltx_Math" display="inline" id="S4.T3.48.48.48.2.m1.1"><semantics id="S4.T3.48.48.48.2.m1.1a"><mn id="S4.T3.48.48.48.2.m1.1.1" xref="S4.T3.48.48.48.2.m1.1.1.cmml">0.4953</mn><annotation-xml encoding="MathML-Content" id="S4.T3.48.48.48.2.m1.1b"><cn id="S4.T3.48.48.48.2.m1.1.1.cmml" type="float" xref="S4.T3.48.48.48.2.m1.1.1">0.4953</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.48.48.48.2.m1.1c">0.4953</annotation><annotation encoding="application/x-llamapun" id="S4.T3.48.48.48.2.m1.1d">0.4953</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.49.49.49.3"><math alttext="0.2229" class="ltx_Math" display="inline" id="S4.T3.49.49.49.3.m1.1"><semantics id="S4.T3.49.49.49.3.m1.1a"><mn id="S4.T3.49.49.49.3.m1.1.1" xref="S4.T3.49.49.49.3.m1.1.1.cmml">0.2229</mn><annotation-xml encoding="MathML-Content" id="S4.T3.49.49.49.3.m1.1b"><cn id="S4.T3.49.49.49.3.m1.1.1.cmml" type="float" xref="S4.T3.49.49.49.3.m1.1.1">0.2229</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.49.49.49.3.m1.1c">0.2229</annotation><annotation encoding="application/x-llamapun" id="S4.T3.49.49.49.3.m1.1d">0.2229</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.50.50.50.4"><math alttext="0.2286" class="ltx_Math" display="inline" id="S4.T3.50.50.50.4.m1.1"><semantics id="S4.T3.50.50.50.4.m1.1a"><mn id="S4.T3.50.50.50.4.m1.1.1" xref="S4.T3.50.50.50.4.m1.1.1.cmml">0.2286</mn><annotation-xml encoding="MathML-Content" id="S4.T3.50.50.50.4.m1.1b"><cn id="S4.T3.50.50.50.4.m1.1.1.cmml" type="float" xref="S4.T3.50.50.50.4.m1.1.1">0.2286</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.50.50.50.4.m1.1c">0.2286</annotation><annotation encoding="application/x-llamapun" id="S4.T3.50.50.50.4.m1.1d">0.2286</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.54.54.54">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.54.54.54.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.54.54.54.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.54.54.54.5.2">DeepSeek-67B Base</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.54.54.54.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.51.51.51.1"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.51.51.51.1.1">0.6498</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.52.52.52.2"><math alttext="0.5433" class="ltx_Math" display="inline" id="S4.T3.52.52.52.2.m1.1"><semantics id="S4.T3.52.52.52.2.m1.1a"><mn id="S4.T3.52.52.52.2.m1.1.1" xref="S4.T3.52.52.52.2.m1.1.1.cmml">0.5433</mn><annotation-xml encoding="MathML-Content" id="S4.T3.52.52.52.2.m1.1b"><cn id="S4.T3.52.52.52.2.m1.1.1.cmml" type="float" xref="S4.T3.52.52.52.2.m1.1.1">0.5433</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.52.52.52.2.m1.1c">0.5433</annotation><annotation encoding="application/x-llamapun" id="S4.T3.52.52.52.2.m1.1d">0.5433</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.53.53.53.3"><math alttext="0.4888" class="ltx_Math" display="inline" id="S4.T3.53.53.53.3.m1.1"><semantics id="S4.T3.53.53.53.3.m1.1a"><mn id="S4.T3.53.53.53.3.m1.1.1" xref="S4.T3.53.53.53.3.m1.1.1.cmml">0.4888</mn><annotation-xml encoding="MathML-Content" id="S4.T3.53.53.53.3.m1.1b"><cn id="S4.T3.53.53.53.3.m1.1.1.cmml" type="float" xref="S4.T3.53.53.53.3.m1.1.1">0.4888</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.53.53.53.3.m1.1c">0.4888</annotation><annotation encoding="application/x-llamapun" id="S4.T3.53.53.53.3.m1.1d">0.4888</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.54.54.54.4"><math alttext="0.4012" class="ltx_Math" display="inline" id="S4.T3.54.54.54.4.m1.1"><semantics id="S4.T3.54.54.54.4.m1.1a"><mn id="S4.T3.54.54.54.4.m1.1.1" xref="S4.T3.54.54.54.4.m1.1.1.cmml">0.4012</mn><annotation-xml encoding="MathML-Content" id="S4.T3.54.54.54.4.m1.1b"><cn id="S4.T3.54.54.54.4.m1.1.1.cmml" type="float" xref="S4.T3.54.54.54.4.m1.1.1">0.4012</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.54.54.54.4.m1.1c">0.4012</annotation><annotation encoding="application/x-llamapun" id="S4.T3.54.54.54.4.m1.1d">0.4012</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.58.58.58">
<td class="ltx_td ltx_align_center" id="S4.T3.58.58.58.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.55.55.55.1"><math alttext="0.6034" class="ltx_Math" display="inline" id="S4.T3.55.55.55.1.m1.1"><semantics id="S4.T3.55.55.55.1.m1.1a"><mn id="S4.T3.55.55.55.1.m1.1.1" xref="S4.T3.55.55.55.1.m1.1.1.cmml">0.6034</mn><annotation-xml encoding="MathML-Content" id="S4.T3.55.55.55.1.m1.1b"><cn id="S4.T3.55.55.55.1.m1.1.1.cmml" type="float" xref="S4.T3.55.55.55.1.m1.1.1">0.6034</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.55.55.55.1.m1.1c">0.6034</annotation><annotation encoding="application/x-llamapun" id="S4.T3.55.55.55.1.m1.1d">0.6034</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.56.56.56.2"><math alttext="0.5494" class="ltx_Math" display="inline" id="S4.T3.56.56.56.2.m1.1"><semantics id="S4.T3.56.56.56.2.m1.1a"><mn id="S4.T3.56.56.56.2.m1.1.1" xref="S4.T3.56.56.56.2.m1.1.1.cmml">0.5494</mn><annotation-xml encoding="MathML-Content" id="S4.T3.56.56.56.2.m1.1b"><cn id="S4.T3.56.56.56.2.m1.1.1.cmml" type="float" xref="S4.T3.56.56.56.2.m1.1.1">0.5494</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.56.56.56.2.m1.1c">0.5494</annotation><annotation encoding="application/x-llamapun" id="S4.T3.56.56.56.2.m1.1d">0.5494</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.57.57.57.3"><math alttext="0.4350" class="ltx_Math" display="inline" id="S4.T3.57.57.57.3.m1.1"><semantics id="S4.T3.57.57.57.3.m1.1a"><mn id="S4.T3.57.57.57.3.m1.1.1" xref="S4.T3.57.57.57.3.m1.1.1.cmml">0.4350</mn><annotation-xml encoding="MathML-Content" id="S4.T3.57.57.57.3.m1.1b"><cn id="S4.T3.57.57.57.3.m1.1.1.cmml" type="float" xref="S4.T3.57.57.57.3.m1.1.1">0.4350</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.57.57.57.3.m1.1c">0.4350</annotation><annotation encoding="application/x-llamapun" id="S4.T3.57.57.57.3.m1.1d">0.4350</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.58.58.58.4"><math alttext="0.3574" class="ltx_Math" display="inline" id="S4.T3.58.58.58.4.m1.1"><semantics id="S4.T3.58.58.58.4.m1.1a"><mn id="S4.T3.58.58.58.4.m1.1.1" xref="S4.T3.58.58.58.4.m1.1.1.cmml">0.3574</mn><annotation-xml encoding="MathML-Content" id="S4.T3.58.58.58.4.m1.1b"><cn id="S4.T3.58.58.58.4.m1.1.1.cmml" type="float" xref="S4.T3.58.58.58.4.m1.1.1">0.3574</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.58.58.58.4.m1.1c">0.3574</annotation><annotation encoding="application/x-llamapun" id="S4.T3.58.58.58.4.m1.1d">0.3574</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.62.62.62">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T3.62.62.62.5" rowspan="2">
<span class="ltx_ERROR undefined" id="S4.T3.62.62.62.5.1">\cdashline</span>2-6
<span class="ltx_text" id="S4.T3.62.62.62.5.2">Mixtral-8x7B Base</span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.62.62.62.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.59.59.59.1"><math alttext="0.4969" class="ltx_Math" display="inline" id="S4.T3.59.59.59.1.m1.1"><semantics id="S4.T3.59.59.59.1.m1.1a"><mn id="S4.T3.59.59.59.1.m1.1.1" xref="S4.T3.59.59.59.1.m1.1.1.cmml">0.4969</mn><annotation-xml encoding="MathML-Content" id="S4.T3.59.59.59.1.m1.1b"><cn id="S4.T3.59.59.59.1.m1.1.1.cmml" type="float" xref="S4.T3.59.59.59.1.m1.1.1">0.4969</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.59.59.59.1.m1.1c">0.4969</annotation><annotation encoding="application/x-llamapun" id="S4.T3.59.59.59.1.m1.1d">0.4969</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.60.60.60.2"><math alttext="0.3125" class="ltx_Math" display="inline" id="S4.T3.60.60.60.2.m1.1"><semantics id="S4.T3.60.60.60.2.m1.1a"><mn id="S4.T3.60.60.60.2.m1.1.1" xref="S4.T3.60.60.60.2.m1.1.1.cmml">0.3125</mn><annotation-xml encoding="MathML-Content" id="S4.T3.60.60.60.2.m1.1b"><cn id="S4.T3.60.60.60.2.m1.1.1.cmml" type="float" xref="S4.T3.60.60.60.2.m1.1.1">0.3125</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.60.60.60.2.m1.1c">0.3125</annotation><annotation encoding="application/x-llamapun" id="S4.T3.60.60.60.2.m1.1d">0.3125</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.61.61.61.3"><math alttext="0.4958" class="ltx_Math" display="inline" id="S4.T3.61.61.61.3.m1.1"><semantics id="S4.T3.61.61.61.3.m1.1a"><mn id="S4.T3.61.61.61.3.m1.1.1" xref="S4.T3.61.61.61.3.m1.1.1.cmml">0.4958</mn><annotation-xml encoding="MathML-Content" id="S4.T3.61.61.61.3.m1.1b"><cn id="S4.T3.61.61.61.3.m1.1.1.cmml" type="float" xref="S4.T3.61.61.61.3.m1.1.1">0.4958</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.61.61.61.3.m1.1c">0.4958</annotation><annotation encoding="application/x-llamapun" id="S4.T3.61.61.61.3.m1.1d">0.4958</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T3.62.62.62.4"><math alttext="0.4694" class="ltx_Math" display="inline" id="S4.T3.62.62.62.4.m1.1"><semantics id="S4.T3.62.62.62.4.m1.1a"><mn id="S4.T3.62.62.62.4.m1.1.1" xref="S4.T3.62.62.62.4.m1.1.1.cmml">0.4694</mn><annotation-xml encoding="MathML-Content" id="S4.T3.62.62.62.4.m1.1b"><cn id="S4.T3.62.62.62.4.m1.1.1.cmml" type="float" xref="S4.T3.62.62.62.4.m1.1.1">0.4694</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.62.62.62.4.m1.1c">0.4694</annotation><annotation encoding="application/x-llamapun" id="S4.T3.62.62.62.4.m1.1d">0.4694</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.66.66.66">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.66.66.66.5">2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.63.63.63.1"><math alttext="0.4216" class="ltx_Math" display="inline" id="S4.T3.63.63.63.1.m1.1"><semantics id="S4.T3.63.63.63.1.m1.1a"><mn id="S4.T3.63.63.63.1.m1.1.1" xref="S4.T3.63.63.63.1.m1.1.1.cmml">0.4216</mn><annotation-xml encoding="MathML-Content" id="S4.T3.63.63.63.1.m1.1b"><cn id="S4.T3.63.63.63.1.m1.1.1.cmml" type="float" xref="S4.T3.63.63.63.1.m1.1.1">0.4216</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.63.63.63.1.m1.1c">0.4216</annotation><annotation encoding="application/x-llamapun" id="S4.T3.63.63.63.1.m1.1d">0.4216</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.64.64.64.2"><math alttext="0.3210" class="ltx_Math" display="inline" id="S4.T3.64.64.64.2.m1.1"><semantics id="S4.T3.64.64.64.2.m1.1a"><mn id="S4.T3.64.64.64.2.m1.1.1" xref="S4.T3.64.64.64.2.m1.1.1.cmml">0.3210</mn><annotation-xml encoding="MathML-Content" id="S4.T3.64.64.64.2.m1.1b"><cn id="S4.T3.64.64.64.2.m1.1.1.cmml" type="float" xref="S4.T3.64.64.64.2.m1.1.1">0.3210</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.64.64.64.2.m1.1c">0.3210</annotation><annotation encoding="application/x-llamapun" id="S4.T3.64.64.64.2.m1.1d">0.3210</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.65.65.65.3"><math alttext="0.4530" class="ltx_Math" display="inline" id="S4.T3.65.65.65.3.m1.1"><semantics id="S4.T3.65.65.65.3.m1.1a"><mn id="S4.T3.65.65.65.3.m1.1.1" xref="S4.T3.65.65.65.3.m1.1.1.cmml">0.4530</mn><annotation-xml encoding="MathML-Content" id="S4.T3.65.65.65.3.m1.1b"><cn id="S4.T3.65.65.65.3.m1.1.1.cmml" type="float" xref="S4.T3.65.65.65.3.m1.1.1">0.4530</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.65.65.65.3.m1.1c">0.4530</annotation><annotation encoding="application/x-llamapun" id="S4.T3.65.65.65.3.m1.1d">0.4530</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.66.66.66.4"><math alttext="0.3172" class="ltx_Math" display="inline" id="S4.T3.66.66.66.4.m1.1"><semantics id="S4.T3.66.66.66.4.m1.1a"><mn id="S4.T3.66.66.66.4.m1.1.1" xref="S4.T3.66.66.66.4.m1.1.1.cmml">0.3172</mn><annotation-xml encoding="MathML-Content" id="S4.T3.66.66.66.4.m1.1b"><cn id="S4.T3.66.66.66.4.m1.1.1.cmml" type="float" xref="S4.T3.66.66.66.4.m1.1.1">0.3172</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.66.66.66.4.m1.1c">0.3172</annotation><annotation encoding="application/x-llamapun" id="S4.T3.66.66.66.4.m1.1d">0.3172</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Spearman <math alttext="\rho" class="ltx_Math" display="inline" id="S4.T3.68.m1.1"><semantics id="S4.T3.68.m1.1b"><mi id="S4.T3.68.m1.1.1" xref="S4.T3.68.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.68.m1.1c"><ci id="S4.T3.68.m1.1.1.cmml" xref="S4.T3.68.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.68.m1.1d">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T3.68.m1.1e">italic_ρ</annotation></semantics></math> and Pearson’s <span class="ltx_text ltx_font_italic" id="S4.T3.71.1">r</span> correlation scores for score prediction in <span class="ltx_text ltx_font_bold" id="S4.T3.72.2">PEFT</span> scenario</figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">We utilized TransQuest (including MonoTransQuest and SiameseTransQuest) and COMET to fine-tune multilingual PTLMs like XLM-RoBERTa as our baselines. We also continued fine-tuning on HADQAET after we fine-tuned XLM-RoBERTa<sub class="ltx_sub" id="S4.SS3.SSS0.Px1.p1.1.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px1.p1.1.1.1">large</span></sub> on the Chinese-English sentence-level MQM dataset from WMT20-22 <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib6" title="">2021a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib8" title="">b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib7" title="">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Experimental Setup</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We evaluated the two prompt templates on the models listed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS3" title="4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4.3</span></a>, focusing on score prediction with error explanations. The evaluation was conducted under both ICL and PEFT scenarios, using zero-shot and few-shot learning approaches. The predicted scores were extracted from the LLM-generated texts using regular expression. They were evaluated using Spearman <math alttext="\rho" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">italic_ρ</annotation></semantics></math> and Pearson’s  <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.1">r</span> correlation scores.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.14">We divided the data into training, validation, and test sets in proportions of <math alttext="80\%" class="ltx_Math" display="inline" id="S4.SS4.p2.1.m1.1"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mn id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">80</mn><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1">percent</csymbol><cn id="S4.SS4.p2.1.m1.1.1.2.cmml" type="integer" xref="S4.SS4.p2.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">80\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.1.m1.1d">80 %</annotation></semantics></math>, <math alttext="10\%" class="ltx_Math" display="inline" id="S4.SS4.p2.2.m2.1"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><mn id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml">10</mn><mo id="S4.SS4.p2.2.m2.1.1.1" xref="S4.SS4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p2.2.m2.1.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1.1">percent</csymbol><cn id="S4.SS4.p2.2.m2.1.1.2.cmml" type="integer" xref="S4.SS4.p2.2.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">10\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.2.m2.1d">10 %</annotation></semantics></math>, and <math alttext="10\%" class="ltx_Math" display="inline" id="S4.SS4.p2.3.m3.1"><semantics id="S4.SS4.p2.3.m3.1a"><mrow id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml"><mn id="S4.SS4.p2.3.m3.1.1.2" xref="S4.SS4.p2.3.m3.1.1.2.cmml">10</mn><mo id="S4.SS4.p2.3.m3.1.1.1" xref="S4.SS4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><apply id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.p2.3.m3.1.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1.1">percent</csymbol><cn id="S4.SS4.p2.3.m3.1.1.2.cmml" type="integer" xref="S4.SS4.p2.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">10\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.3.m3.1d">10 %</annotation></semantics></math>. Baseline models were fine-tuned for <math alttext="2" class="ltx_Math" display="inline" id="S4.SS4.p2.4.m4.1"><semantics id="S4.SS4.p2.4.m4.1a"><mn id="S4.SS4.p2.4.m4.1.1" xref="S4.SS4.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.4.m4.1b"><cn id="S4.SS4.p2.4.m4.1.1.cmml" type="integer" xref="S4.SS4.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.4.m4.1c">2</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.4.m4.1d">2</annotation></semantics></math> epochs with a learning rate of <math alttext="2e-5" class="ltx_Math" display="inline" id="S4.SS4.p2.5.m5.1"><semantics id="S4.SS4.p2.5.m5.1a"><mrow id="S4.SS4.p2.5.m5.1.1" xref="S4.SS4.p2.5.m5.1.1.cmml"><mrow id="S4.SS4.p2.5.m5.1.1.2" xref="S4.SS4.p2.5.m5.1.1.2.cmml"><mn id="S4.SS4.p2.5.m5.1.1.2.2" xref="S4.SS4.p2.5.m5.1.1.2.2.cmml">2</mn><mo id="S4.SS4.p2.5.m5.1.1.2.1" xref="S4.SS4.p2.5.m5.1.1.2.1.cmml">⁢</mo><mi id="S4.SS4.p2.5.m5.1.1.2.3" xref="S4.SS4.p2.5.m5.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS4.p2.5.m5.1.1.1" xref="S4.SS4.p2.5.m5.1.1.1.cmml">−</mo><mn id="S4.SS4.p2.5.m5.1.1.3" xref="S4.SS4.p2.5.m5.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.5.m5.1b"><apply id="S4.SS4.p2.5.m5.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1"><minus id="S4.SS4.p2.5.m5.1.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1.1"></minus><apply id="S4.SS4.p2.5.m5.1.1.2.cmml" xref="S4.SS4.p2.5.m5.1.1.2"><times id="S4.SS4.p2.5.m5.1.1.2.1.cmml" xref="S4.SS4.p2.5.m5.1.1.2.1"></times><cn id="S4.SS4.p2.5.m5.1.1.2.2.cmml" type="integer" xref="S4.SS4.p2.5.m5.1.1.2.2">2</cn><ci id="S4.SS4.p2.5.m5.1.1.2.3.cmml" xref="S4.SS4.p2.5.m5.1.1.2.3">𝑒</ci></apply><cn id="S4.SS4.p2.5.m5.1.1.3.cmml" type="integer" xref="S4.SS4.p2.5.m5.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.5.m5.1c">2e-5</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.5.m5.1d">2 italic_e - 5</annotation></semantics></math>, batch size of <math alttext="8" class="ltx_Math" display="inline" id="S4.SS4.p2.6.m6.1"><semantics id="S4.SS4.p2.6.m6.1a"><mn id="S4.SS4.p2.6.m6.1.1" xref="S4.SS4.p2.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.6.m6.1b"><cn id="S4.SS4.p2.6.m6.1.1.cmml" type="integer" xref="S4.SS4.p2.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.6.m6.1c">8</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.6.m6.1d">8</annotation></semantics></math> and sequence length of <math alttext="200" class="ltx_Math" display="inline" id="S4.SS4.p2.7.m7.1"><semantics id="S4.SS4.p2.7.m7.1a"><mn id="S4.SS4.p2.7.m7.1.1" xref="S4.SS4.p2.7.m7.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.7.m7.1b"><cn id="S4.SS4.p2.7.m7.1.1.cmml" type="integer" xref="S4.SS4.p2.7.m7.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.7.m7.1c">200</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.7.m7.1d">200</annotation></semantics></math> on an NVIDIA Quadro RTX 5000 GPU. For LLM inference, the temperature hyperparameter was set as <math alttext="0.95" class="ltx_Math" display="inline" id="S4.SS4.p2.8.m8.1"><semantics id="S4.SS4.p2.8.m8.1a"><mn id="S4.SS4.p2.8.m8.1.1" xref="S4.SS4.p2.8.m8.1.1.cmml">0.95</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.8.m8.1b"><cn id="S4.SS4.p2.8.m8.1.1.cmml" type="float" xref="S4.SS4.p2.8.m8.1.1">0.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.8.m8.1c">0.95</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.8.m8.1d">0.95</annotation></semantics></math> and top_p as <math alttext="0.7" class="ltx_Math" display="inline" id="S4.SS4.p2.9.m9.1"><semantics id="S4.SS4.p2.9.m9.1a"><mn id="S4.SS4.p2.9.m9.1.1" xref="S4.SS4.p2.9.m9.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.9.m9.1b"><cn id="S4.SS4.p2.9.m9.1.1.cmml" type="float" xref="S4.SS4.p2.9.m9.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.9.m9.1c">0.7</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.9.m9.1d">0.7</annotation></semantics></math>. All LLMs were loaded in 4-bits using LLaMA-Factory <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib38" title="">2024</a>)</cite> for both inference and PEFT. For PEFT, we chose the rank to be <math alttext="8" class="ltx_Math" display="inline" id="S4.SS4.p2.10.m10.1"><semantics id="S4.SS4.p2.10.m10.1a"><mn id="S4.SS4.p2.10.m10.1.1" xref="S4.SS4.p2.10.m10.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.10.m10.1b"><cn id="S4.SS4.p2.10.m10.1.1.cmml" type="integer" xref="S4.SS4.p2.10.m10.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.10.m10.1c">8</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.10.m10.1d">8</annotation></semantics></math>, alpha to be <math alttext="64" class="ltx_Math" display="inline" id="S4.SS4.p2.11.m11.1"><semantics id="S4.SS4.p2.11.m11.1a"><mn id="S4.SS4.p2.11.m11.1.1" xref="S4.SS4.p2.11.m11.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.11.m11.1b"><cn id="S4.SS4.p2.11.m11.1.1.cmml" type="integer" xref="S4.SS4.p2.11.m11.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.11.m11.1c">64</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.11.m11.1d">64</annotation></semantics></math>, and the target layers to be the attention layers based on experimentation. All LLMs were trained for <math alttext="3" class="ltx_Math" display="inline" id="S4.SS4.p2.12.m12.1"><semantics id="S4.SS4.p2.12.m12.1a"><mn id="S4.SS4.p2.12.m12.1.1" xref="S4.SS4.p2.12.m12.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.12.m12.1b"><cn id="S4.SS4.p2.12.m12.1.1.cmml" type="integer" xref="S4.SS4.p2.12.m12.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.12.m12.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.12.m12.1d">3</annotation></semantics></math> epochs with a learning rate of <math alttext="5e-5" class="ltx_Math" display="inline" id="S4.SS4.p2.13.m13.1"><semantics id="S4.SS4.p2.13.m13.1a"><mrow id="S4.SS4.p2.13.m13.1.1" xref="S4.SS4.p2.13.m13.1.1.cmml"><mrow id="S4.SS4.p2.13.m13.1.1.2" xref="S4.SS4.p2.13.m13.1.1.2.cmml"><mn id="S4.SS4.p2.13.m13.1.1.2.2" xref="S4.SS4.p2.13.m13.1.1.2.2.cmml">5</mn><mo id="S4.SS4.p2.13.m13.1.1.2.1" xref="S4.SS4.p2.13.m13.1.1.2.1.cmml">⁢</mo><mi id="S4.SS4.p2.13.m13.1.1.2.3" xref="S4.SS4.p2.13.m13.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS4.p2.13.m13.1.1.1" xref="S4.SS4.p2.13.m13.1.1.1.cmml">−</mo><mn id="S4.SS4.p2.13.m13.1.1.3" xref="S4.SS4.p2.13.m13.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.13.m13.1b"><apply id="S4.SS4.p2.13.m13.1.1.cmml" xref="S4.SS4.p2.13.m13.1.1"><minus id="S4.SS4.p2.13.m13.1.1.1.cmml" xref="S4.SS4.p2.13.m13.1.1.1"></minus><apply id="S4.SS4.p2.13.m13.1.1.2.cmml" xref="S4.SS4.p2.13.m13.1.1.2"><times id="S4.SS4.p2.13.m13.1.1.2.1.cmml" xref="S4.SS4.p2.13.m13.1.1.2.1"></times><cn id="S4.SS4.p2.13.m13.1.1.2.2.cmml" type="integer" xref="S4.SS4.p2.13.m13.1.1.2.2">5</cn><ci id="S4.SS4.p2.13.m13.1.1.2.3.cmml" xref="S4.SS4.p2.13.m13.1.1.2.3">𝑒</ci></apply><cn id="S4.SS4.p2.13.m13.1.1.3.cmml" type="integer" xref="S4.SS4.p2.13.m13.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.13.m13.1c">5e-5</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.13.m13.1d">5 italic_e - 5</annotation></semantics></math> and a batch size of <math alttext="4" class="ltx_Math" display="inline" id="S4.SS4.p2.14.m14.1"><semantics id="S4.SS4.p2.14.m14.1a"><mn id="S4.SS4.p2.14.m14.1.1" xref="S4.SS4.p2.14.m14.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.14.m14.1b"><cn id="S4.SS4.p2.14.m14.1.1.cmml" type="integer" xref="S4.SS4.p2.14.m14.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.14.m14.1c">4</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.14.m14.1d">4</annotation></semantics></math> using an NVIDIA A40 GPU.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.11" style="width:199.2pt;height:101.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-6.4pt,3.2pt) scale(0.939969116476741,0.939969116476741) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.11.11">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S4.T4.1.1.1.2">Methods</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.1.1.1.1"><math alttext="\rho" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.m1.1a"><mi id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.m1.1d">italic_ρ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.1.1.1.3"><span class="ltx_text ltx_font_italic" id="S4.T4.1.1.1.3.1">r</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T4.3.3.3.3">MonoTransQuest (FT)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.2.1"><math alttext="0.4355" class="ltx_Math" display="inline" id="S4.T4.2.2.2.1.m1.1"><semantics id="S4.T4.2.2.2.1.m1.1a"><mn id="S4.T4.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.1.m1.1.1.cmml">0.4355</mn><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.1.m1.1b"><cn id="S4.T4.2.2.2.1.m1.1.1.cmml" type="float" xref="S4.T4.2.2.2.1.m1.1.1">0.4355</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.1.m1.1c">0.4355</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.1.m1.1d">0.4355</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.3.3.2"><math alttext="0.3984" class="ltx_Math" display="inline" id="S4.T4.3.3.3.2.m1.1"><semantics id="S4.T4.3.3.3.2.m1.1a"><mn id="S4.T4.3.3.3.2.m1.1.1" xref="S4.T4.3.3.3.2.m1.1.1.cmml">0.3984</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.2.m1.1b"><cn id="S4.T4.3.3.3.2.m1.1.1.cmml" type="float" xref="S4.T4.3.3.3.2.m1.1.1">0.3984</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.2.m1.1c">0.3984</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.2.m1.1d">0.3984</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.5.5.5.3">SiameseTransQuest (FT)</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.4.1"><math alttext="0.4151" class="ltx_Math" display="inline" id="S4.T4.4.4.4.1.m1.1"><semantics id="S4.T4.4.4.4.1.m1.1a"><mn id="S4.T4.4.4.4.1.m1.1.1" xref="S4.T4.4.4.4.1.m1.1.1.cmml">0.4151</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.m1.1b"><cn id="S4.T4.4.4.4.1.m1.1.1.cmml" type="float" xref="S4.T4.4.4.4.1.m1.1.1">0.4151</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.m1.1c">0.4151</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.1.m1.1d">0.4151</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.5.2"><math alttext="0.4502" class="ltx_Math" display="inline" id="S4.T4.5.5.5.2.m1.1"><semantics id="S4.T4.5.5.5.2.m1.1a"><mn id="S4.T4.5.5.5.2.m1.1.1" xref="S4.T4.5.5.5.2.m1.1.1.cmml">0.4502</mn><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.2.m1.1b"><cn id="S4.T4.5.5.5.2.m1.1.1.cmml" type="float" xref="S4.T4.5.5.5.2.m1.1.1">0.4502</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.2.m1.1c">0.4502</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.5.2.m1.1d">0.4502</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.7.7.7.3">COMET (FT)</th>
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.6.1"><math alttext="0.4083" class="ltx_Math" display="inline" id="S4.T4.6.6.6.1.m1.1"><semantics id="S4.T4.6.6.6.1.m1.1a"><mn id="S4.T4.6.6.6.1.m1.1.1" xref="S4.T4.6.6.6.1.m1.1.1.cmml">0.4083</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.1.m1.1b"><cn id="S4.T4.6.6.6.1.m1.1.1.cmml" type="float" xref="S4.T4.6.6.6.1.m1.1.1">0.4083</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.1.m1.1c">0.4083</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.1.m1.1d">0.4083</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.7.2"><math alttext="0.3699" class="ltx_Math" display="inline" id="S4.T4.7.7.7.2.m1.1"><semantics id="S4.T4.7.7.7.2.m1.1a"><mn id="S4.T4.7.7.7.2.m1.1.1" xref="S4.T4.7.7.7.2.m1.1.1.cmml">0.3699</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.2.m1.1b"><cn id="S4.T4.7.7.7.2.m1.1.1.cmml" type="float" xref="S4.T4.7.7.7.2.m1.1.1">0.3699</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.2.m1.1c">0.3699</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.7.2.m1.1d">0.3699</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.9.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.9.9.9.3">MonoTransQuest (CFT)</th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.8.1"><math alttext="0.4527" class="ltx_Math" display="inline" id="S4.T4.8.8.8.1.m1.1"><semantics id="S4.T4.8.8.8.1.m1.1a"><mn id="S4.T4.8.8.8.1.m1.1.1" xref="S4.T4.8.8.8.1.m1.1.1.cmml">0.4527</mn><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.1.m1.1b"><cn id="S4.T4.8.8.8.1.m1.1.1.cmml" type="float" xref="S4.T4.8.8.8.1.m1.1.1">0.4527</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.1.m1.1c">0.4527</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.8.8.1.m1.1d">0.4527</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.9.9.9.2"><math alttext="0.4050" class="ltx_Math" display="inline" id="S4.T4.9.9.9.2.m1.1"><semantics id="S4.T4.9.9.9.2.m1.1a"><mn id="S4.T4.9.9.9.2.m1.1.1" xref="S4.T4.9.9.9.2.m1.1.1.cmml">0.4050</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.9.2.m1.1b"><cn id="S4.T4.9.9.9.2.m1.1.1.cmml" type="float" xref="S4.T4.9.9.9.2.m1.1.1">0.4050</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.9.2.m1.1c">0.4050</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.9.9.2.m1.1d">0.4050</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.11.11.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T4.11.11.11.3">SiameseTransQuest (CFT)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.10.10.10.1"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T4.10.10.10.1.1">0.5118</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.11.11.11.2"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T4.11.11.11.2.1">0.4934</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Spearman <math alttext="\rho" class="ltx_Math" display="inline" id="S4.T4.13.m1.1"><semantics id="S4.T4.13.m1.1b"><mi id="S4.T4.13.m1.1.1" xref="S4.T4.13.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.T4.13.m1.1c"><ci id="S4.T4.13.m1.1.1.cmml" xref="S4.T4.13.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.m1.1d">\rho</annotation><annotation encoding="application/x-llamapun" id="S4.T4.13.m1.1e">italic_ρ</annotation></semantics></math> and Pearson’s <span class="ltx_text ltx_font_italic" id="S4.T4.15.1">r</span> correlation scores of baseline models fine-tuned (FT) and continued fine-tuned (CFT) using TransQuest and COMET. CFT models are obtained by fine-tuning on WMT MQM data first and then continued fine-tuning on HADQAET and results are evaluated on HADQAET.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p3">
<span class="ltx_ERROR undefined" id="S4.SS4.p3.1">{CJK*}</span>
<p class="ltx_p" id="S4.SS4.p3.2">UTF8gbsn</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.1" style="width:426.8pt;">
<p class="ltx_p" id="S4.F4.1.1">Source: 我下次洗衣服的时候如果再放很多洗衣液进去我就是狗，怎么洗都还是很多泡沫。FUCK!</p>
<p class="ltx_p" id="S4.F4.1.2">GT output: If I put a lot of laundry detergent in the next time I do laundry, I will be a dog, and I will still have a lot of foam no matter how I wash it. FUCK!</p>
<p class="ltx_p" id="S4.F4.1.3">Human translation: If I still use a lot of laundry detergent in the next time I do laundry, I will be a dog. No matter how I wash it, there is still lots of foam. FUCK!</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An example of refusal to reply because of interjections</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p4">
<span class="ltx_ERROR undefined" id="S4.SS4.p4.1">{CJK*}</span>
<p class="ltx_p" id="S4.SS4.p4.2">UTF8gbsn</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.1" style="width:426.8pt;">
<p class="ltx_p" id="S4.F5.1.1">Source: 踢个香港，裁判黑成这样…不知道该说什么了</p>
<p class="ltx_p" id="S4.F5.1.2">GT output: Kick Hong Kong, the referee is so black… I don’t know what to say</p>
<p class="ltx_p" id="S4.F5.1.3">Human translation: In the (football) game against Hong Kong, the referee was so biased!!! Don’t know what to say.</p>
<p class="ltx_p" id="S4.F5.1.4">LLM output: I apologize, but I cannot provide a score for the translation as it is not appropriate to use language that is derogatory or offensive. The phrase <span class="ltx_text ltx_font_bold" id="S4.F5.1.4.1">“裁判黑” (referee is black) is not a neutral or factual statement, and it could be perceived as racist or discriminatory</span>. Additionally, the phrase <span class="ltx_text ltx_font_bold" id="S4.F5.1.4.2">“踢个香港” (kick Hong Kong) is also not appropriate, as it could be interpreted as advocating for violence or aggression towards a specific group of people</span>. Instead, I would suggest using more neutral and respectful language to convey the intended meaning. For example, the phrase “裁判是黑的” (the referee is black) could be used to describe the physical appearance of the referee, without any negative or derogatory connotations. Similarly, the phrase “踢个球” (kick the ball) could be used to describe the action of kicking a ball, without any reference to a specific location or group of people. It’s important to be mindful of the language we use and the impact it can have on others. Using respectful and inclusive language is essential for maintaining a positive and welcoming environment for everyone.</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example of refusal to reply because of “sensitive” words</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Manual Analysis</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This section shows the results under our ICL and PEFT scenarios in Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T2" title="Table 2 ‣ 4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T3" title="Table 3 ‣ 4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">3</span></a> in comparison with the baselines in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T4" title="Table 4 ‣ 4.4 Experimental Setup ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4</span></a>. A manual analysis of some LLM outputs is presented in <math alttext="\S" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" mathvariant="normal" xref="S5.p1.1.m1.1.1.cmml">§</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">§</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\S</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">§</annotation></semantics></math> <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS4" title="5.4 Manual Analysis ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">5.4</span></a>.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Baselines</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T4" title="Table 4 ‣ 4.4 Experimental Setup ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4</span></a> shows results of simple and continued fine-tuning on HADQAET and the Chinese-English MQM dataset from WMT20-22 using TransQuest and COMET. We observe that TransQuest achieved higher correlation scores than COMET when fine-tuned on HADQAET. Therefore, only TransQuest was used for continued fine-tuning. The highest Spearman and Pearson correlation scores <math alttext="0.5118" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">0.5118</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn id="S5.SS1.p1.1.m1.1.1.cmml" type="float" xref="S5.SS1.p1.1.m1.1.1">0.5118</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">0.5118</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">0.5118</annotation></semantics></math> and <math alttext="0.4934" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">0.4934</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn id="S5.SS1.p1.2.m2.1.1.cmml" type="float" xref="S5.SS1.p1.2.m2.1.1">0.4934</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">0.4934</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">0.4934</annotation></semantics></math> were achieved by continued fine-tuning of models that had been fine-tuned on the MQM dataset using SiameseTransQuest.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>In-context Learning</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T2" title="Table 2 ‣ 4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">2</span></a> shows ICL results using the two prompt templates. We cannot see a clear performance boost using Template 2 where error severities are clearly defined and described. In contrast, we see an obvious drop in correlation scores using Template 2 for Llama-2-13B (see Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.SS4" title="5.4 Manual Analysis ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">5.4</span></a> for our investigation). Few-shot learning improves model performance<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Few-shot results are bad for Llama-2-13B, because it cuts off the prompt while reaching the input length limit.</span></span></span> like the cases for Yi-34B, DeepSeek-67B and Gemini Pro.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The MoE model, Mixtral-8x7B achieves the highest correlation scores in zero-shot setting, while DeepSeek-67B is the best at few-shot learning, obtaining a Spearman correlation score of 0.4165, very close to the fine-tuned models using TransQuest and COMET. Gemini Pro, the proprietary LLM, failed to achieve higher correlation scores than the open-source ones in this task. ICL results of all above models are no better than our continued fine-tuning baselines.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<span class="ltx_ERROR undefined" id="S5.SS2.p3.1">{CJK*}</span>
<p class="ltx_p" id="S5.SS2.p3.2">UTF8gbsn</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S5.F6.1" style="width:426.8pt;">
<p class="ltx_p" id="S5.F6.1.1"><span class="ltx_text ltx_font_bold" id="S5.F6.1.1.1">Case 1</span></p>
<p class="ltx_p" id="S5.F6.1.2">I would score this translation as follows:</p>
<p class="ltx_p" id="S5.F6.1.3">Minor errors: 1; Major errors: 1; Critical errors: 0; Total score: -2</p>
<p class="ltx_p" id="S5.F6.1.4">Here’s a breakdown of the errors and their severity levels:</p>
<p class="ltx_p" id="S5.F6.1.5">1. Minor error: The word “满满” (full of) in the source text is not accurately conveyed in the target text as “full of love”. A more accurate translation would be “very full” or “overwhelmingly full”. (Score: -1)</p>
<p class="ltx_p" id="S5.F6.1.6">2. Major error: The word “爱” (love) in the target text is not present in the source text. This is a significant deviation from the original meaning, as the source text does not mention love. (Score: -5) Therefore, the total score for this translation is -2.</p>
<p class="ltx_p" id="S5.F6.1.7">In terms of error locations, the minor error occurs in the word “满满” not being accurately conveyed, and the major error occurs in the word “爱” being added to the target text despite not being present in the source text.</p>
<p class="ltx_p" id="S5.F6.1.8"><span class="ltx_text ltx_font_bold" id="S5.F6.1.8.1">Case 2</span></p>
<p class="ltx_p" id="S5.F6.1.9">I’d be happy to help! Here’s the translation of the Chinese sentence into English, with an error analysis based on the criteria you provided:</p>
<p class="ltx_p" id="S5.F6.1.10">Chinese source: 遇到你和你在一起是我最大最大的荣幸</p>
<p class="ltx_p" id="S5.F6.1.11">English translation: It is my greatest honor to meet you and be with you</p>
<p class="ltx_p" id="S5.F6.1.12">Error analysis: Minor error in emotion preservation: The word “荣幸” (rangxing) in the Chinese source is not perfectly preserved in the English translation as “honor”. While “honor” does convey a sense of pride and respect, it does not fully capture the nuance of “荣幸”, which carries a stronger connotation of joy and happiness. Therefore, the score for this translation is -1.</p>
<p class="ltx_p" id="S5.F6.1.13">Keywords or parts of sentences where error occurs: Chinese: 遇到你和你在一起 English: It is my greatest honor to meet you and be with you</p>
<p class="ltx_p" id="S5.F6.1.14">Note: The word “和” (he) in the Chinese source is not translated in the English translation, which could potentially result in a loss of information and context. However, this omission does not significantly affect the overall meaning of the sentence, so it is not counted as an error in this case.</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>An example of unstable output</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F7">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S5.F7.4" style="width:426.8pt;">
<p class="ltx_p" id="S5.F7.4.5"><span class="ltx_text ltx_font_bold" id="S5.F7.4.5.1">Output 1</span></p>
<p class="ltx_p" id="S5.F7.1.1">I’d be happy to help you with that! …… The score is based on the severity level of the errors and the number of errors. In this case, there is only one minor error, so the score is <math alttext="-1" class="ltx_Math" display="inline" id="S5.F7.1.1.m1.1"><semantics id="S5.F7.1.1.m1.1a"><mrow id="S5.F7.1.1.m1.1.1" xref="S5.F7.1.1.m1.1.1.cmml"><mo id="S5.F7.1.1.m1.1.1a" xref="S5.F7.1.1.m1.1.1.cmml">−</mo><mn id="S5.F7.1.1.m1.1.1.2" xref="S5.F7.1.1.m1.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.1.1.m1.1b"><apply id="S5.F7.1.1.m1.1.1.cmml" xref="S5.F7.1.1.m1.1.1"><minus id="S5.F7.1.1.m1.1.1.1.cmml" xref="S5.F7.1.1.m1.1.1"></minus><cn id="S5.F7.1.1.m1.1.1.2.cmml" type="integer" xref="S5.F7.1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.1.1.m1.1c">-1</annotation><annotation encoding="application/x-llamapun" id="S5.F7.1.1.m1.1d">- 1</annotation></semantics></math>.</p>
<p class="ltx_p" id="S5.F7.4.6"><span class="ltx_text ltx_font_bold" id="S5.F7.4.6.1">Output 2</span></p>
<p class="ltx_p" id="S5.F7.4.4">I’d be happy to help you with that! …… The score is based on the severity of the errors and the level of emotion preservation. A score of <math alttext="-10" class="ltx_Math" display="inline" id="S5.F7.2.2.m1.1"><semantics id="S5.F7.2.2.m1.1a"><mrow id="S5.F7.2.2.m1.1.1" xref="S5.F7.2.2.m1.1.1.cmml"><mo id="S5.F7.2.2.m1.1.1a" xref="S5.F7.2.2.m1.1.1.cmml">−</mo><mn id="S5.F7.2.2.m1.1.1.2" xref="S5.F7.2.2.m1.1.1.2.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.2.2.m1.1b"><apply id="S5.F7.2.2.m1.1.1.cmml" xref="S5.F7.2.2.m1.1.1"><minus id="S5.F7.2.2.m1.1.1.1.cmml" xref="S5.F7.2.2.m1.1.1"></minus><cn id="S5.F7.2.2.m1.1.1.2.cmml" type="integer" xref="S5.F7.2.2.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.2.2.m1.1c">-10</annotation><annotation encoding="application/x-llamapun" id="S5.F7.2.2.m1.1d">- 10</annotation></semantics></math> indicates a critical error in emotion preservation, while a score of <math alttext="-1" class="ltx_Math" display="inline" id="S5.F7.3.3.m2.1"><semantics id="S5.F7.3.3.m2.1a"><mrow id="S5.F7.3.3.m2.1.1" xref="S5.F7.3.3.m2.1.1.cmml"><mo id="S5.F7.3.3.m2.1.1a" xref="S5.F7.3.3.m2.1.1.cmml">−</mo><mn id="S5.F7.3.3.m2.1.1.2" xref="S5.F7.3.3.m2.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.3.3.m2.1b"><apply id="S5.F7.3.3.m2.1.1.cmml" xref="S5.F7.3.3.m2.1.1"><minus id="S5.F7.3.3.m2.1.1.1.cmml" xref="S5.F7.3.3.m2.1.1"></minus><cn id="S5.F7.3.3.m2.1.1.2.cmml" type="integer" xref="S5.F7.3.3.m2.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.3.3.m2.1c">-1</annotation><annotation encoding="application/x-llamapun" id="S5.F7.3.3.m2.1d">- 1</annotation></semantics></math> indicates a minor error. A score of <math alttext="0" class="ltx_Math" display="inline" id="S5.F7.4.4.m3.1"><semantics id="S5.F7.4.4.m3.1a"><mn id="S5.F7.4.4.m3.1.1" xref="S5.F7.4.4.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.F7.4.4.m3.1b"><cn id="S5.F7.4.4.m3.1.1.cmml" type="integer" xref="S5.F7.4.4.m3.1.1">0</cn></annotation-xml></semantics></math> indicates perfect emotion preservation.</p>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Different outputs using the exact same prompt and hyperparameters (temperature as <math alttext="0" class="ltx_Math" display="inline" id="S5.F7.6.m1.1"><semantics id="S5.F7.6.m1.1b"><mn id="S5.F7.6.m1.1.1" xref="S5.F7.6.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.F7.6.m1.1c"><cn id="S5.F7.6.m1.1.1.cmml" type="integer" xref="S5.F7.6.m1.1.1">0</cn></annotation-xml></semantics></math>) from Llama-2-13B, where the same repetitive text in both outputs is omitted and denoted as “……”.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>PEFT</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.T3" title="Table 3 ‣ 4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">3</span></a> presents results for score prediction in the PEFT scenario. We observe that while few-shot learning usually results in better performance in ICL scenario, its performance is worse than zero-shot post-PEFT, especially for base models. We observe that the performance drop for base models after fine-tuning is more obvious than instruction-tuned models in the few-shot setting, with the exception of Mixtral-8x7B. The findings in ICL indicate that the MoE model outperforms regular dense models of similar size. We anticipated that the Mixtral-8x7B model would yield significantly improved results after PEFT, but the observed enhancement was not as substantial as expected. We attained our highest correlation scores of <math alttext="0.6498" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mn id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">0.6498</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><cn id="S5.SS3.p1.1.m1.1.1.cmml" type="float" xref="S5.SS3.p1.1.m1.1.1">0.6498</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">0.6498</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">0.6498</annotation></semantics></math> and <math alttext="0.5983" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><mn id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml">0.5983</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><cn id="S5.SS3.p1.2.m2.1.1.cmml" type="float" xref="S5.SS3.p1.2.m2.1.1">0.5983</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">0.5983</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">0.5983</annotation></semantics></math> by fine-tuning the DeepSeek models, with both Spearman and Pearson correlation scores surpassing the baselines. These results underscore the effectiveness of PEFT for LLMs towards achieving state-of-the-art performance in quality estimation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Manual Analysis</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.2">While most Spearman correlation scores are positive and larger than <math alttext="0.1" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><mn id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><cn id="S5.SS4.p1.1.m1.1.1.cmml" type="float" xref="S5.SS4.p1.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">0.1</annotation></semantics></math>, it is noteworthy that Llama-2-13B outputs QE scores that exhibit a negative correlation (<math alttext="-0.0310" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.1"><semantics id="S5.SS4.p1.2.m2.1a"><mrow id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml"><mo id="S5.SS4.p1.2.m2.1.1a" xref="S5.SS4.p1.2.m2.1.1.cmml">−</mo><mn id="S5.SS4.p1.2.m2.1.1.2" xref="S5.SS4.p1.2.m2.1.1.2.cmml">0.0310</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><apply id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"><minus id="S5.SS4.p1.2.m2.1.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"></minus><cn id="S5.SS4.p1.2.m2.1.1.2.cmml" type="float" xref="S5.SS4.p1.2.m2.1.1.2">0.0310</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">-0.0310</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.1d">- 0.0310</annotation></semantics></math>) with the true scores using Template 2. For further investigation, we did a manual analysis of the model output with the help of a Chinese-English translator. We observe two phenomena that might pose challenges for using LLMs to evaluate translation quality: <span class="ltx_text ltx_font_italic" id="S5.SS4.p1.2.1">1) refusal to reply</span> because of “inappropriate language”, and <span class="ltx_text ltx_font_italic" id="S5.SS4.p1.2.2">2) unstable output</span> patterns.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Refusal to Reply</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">We find Llama-2-13B <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p1.1.1">refused to evaluate</span> <math alttext="4.97\%" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p1.1.m1.1"><semantics id="S5.SS4.SSS1.p1.1.m1.1a"><mrow id="S5.SS4.SSS1.p1.1.m1.1.1" xref="S5.SS4.SSS1.p1.1.m1.1.1.cmml"><mn id="S5.SS4.SSS1.p1.1.m1.1.1.2" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.cmml">4.97</mn><mo id="S5.SS4.SSS1.p1.1.m1.1.1.1" xref="S5.SS4.SSS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p1.1.m1.1b"><apply id="S5.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS4.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS4.SSS1.p1.1.m1.1.1.2.cmml" type="float" xref="S5.SS4.SSS1.p1.1.m1.1.1.2">4.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p1.1.m1.1c">4.97\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.SSS1.p1.1.m1.1d">4.97 %</annotation></semantics></math> of the instances<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>They were excluded for correlation score computation.</span></span></span> in the test set, because the source texts contain swear words from social media. However, most of these words are used as interjections to express the <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p1.1.2">angry</span> emotion of the blogger towards a certain event as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.F4" title="Figure 4 ‣ 4.4 Experimental Setup ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4</span></a>, not aggression towards someone. Llama-2-13B seems to refuse to answer any questions containing these words.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS1.p2">
<span class="ltx_ERROR undefined" id="S5.SS4.SSS1.p2.1">{CJK*}</span>
<p class="ltx_p" id="S5.SS4.SSS1.p2.2">UTF8gbsn
Of particular interest, Llama-2-13B demonstrates heightened sensitivity to language associated with discrimination and aggression. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.F5" title="Figure 5 ‣ 4.4 Experimental Setup ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">5</span></a>, the Chinese source text complains about a football game against Hong Kong. It mentions “踢” <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p2.2.1">kick (ball)</span> and “香港” <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS1.p2.2.2">Hong Kong</span>, which Llama-2-13B believes it could be interpreted as “advocating for violence or aggression towards a specific group of people”. “裁判黑” in the source means the referee manipulates the game, as the character “黑”, which has the meaning of “black”, means doing something behind the scenes in this context. Llama-2-13B is over-sensitive about using the character “黑” to describe a person. This may become a problem for evaluating translation quality, especially emotion-load UGC.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>Unstable Output</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">We expect LLMs to output texts with similar structures or patterns when the same prompt template is used. However, responses from Llama-2-13B sometimes varied. Some answers indicate a misunderstanding of the instruction in the prompt, whereas others seem to follow the instruction and perform the quality evaluation task.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS2.p2">
<p class="ltx_p" id="S5.SS4.SSS2.p2.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.F6" title="Figure 6 ‣ 5.2 In-context Learning ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">6</span></a>, the output structure of Case 1 and Case 2 are very different even when using the same prompt template. In Case 1, Llama-2-13B lists the number of errors based on severity levels and generates a total score, which is inconsistent with its following analysis. The analysis thereafter breaks down the errors and provides a score to each error, but the total score is calculated <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS2.p2.1.1">incorrectly</span> due to its poor reasoning ability  <cite class="ltx_cite ltx_citemacro_citep">(Arkoudas, <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#bib.bib1" title="">2023</a>)</cite>. In Case 2, Llama-2-13B starts with error analysis and then produces a total score without mentioning scores for each error.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS2.p3">
<p class="ltx_p" id="S5.SS4.SSS2.p3.1">We observe unstable output even when the temperature hyperparameter is set to zero, which essentially eliminates the sampling process and is supposed to produce the exact same consistent output. However, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S5.F7" title="Figure 7 ‣ 5.2 In-context Learning ‣ 5 Results and Manual Analysis ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">7</span></a>, we observe variance in outputs from Llama-2-13B after prompting with the same text several times, using identical hyperparameters (<math alttext="0" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p3.1.m1.1"><semantics id="S5.SS4.SSS2.p3.1.m1.1a"><mn id="S5.SS4.SSS2.p3.1.m1.1.1" xref="S5.SS4.SSS2.p3.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p3.1.m1.1b"><cn id="S5.SS4.SSS2.p3.1.m1.1.1.cmml" type="integer" xref="S5.SS4.SSS2.p3.1.m1.1.1">0</cn></annotation-xml></semantics></math> temperature). Inconsistent output structures might cause problems for extracting the QE scores for the computation of the overall correlation, and more importantly, confuse users in understanding the real translation quality.</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS2.p4">
<p class="ltx_p" id="S5.SS4.SSS2.p4.1">The phenomena of refusal to reply and unstable output were not observed only in the Llama-2-13B model. Other LLMs might also refuse to reply to questions containing swear words and output inconsistent text structures. Interestingly, we find that models proposed by Chinese companies such as Yi and DeepSeek are less sensitive to words related to discrimination and aggression, unlike Llama and ChatGPT, as they usually provide a QE score to such examples. However, this needs to be verified by further experiments using more LLMs.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In order to understand whether LLMs are state-of-the-art quality estimators for machine translation of emotion-loaded UGC, our paper utilized an existing emotion-related dataset with human-annotated errors. We computed the MQM scores based on the translation errors, and devised two prompt templates to allow LLMs to perform score prediction with error explanations. Different types and sizes of LLMs were employed to compare with fine-tuning of multilingual PTLMs, under ICL and PEFT scenarios. We find that while LLMs can obtain good correlation scores in zero-shot setting, PEFT of LLMs leads to state-of-the-art performance in score prediction with error explanations, which resolves the <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">opacity issue</span> of current QE models. However, a manual analysis reveals that LLMs still have problems such as refusal to reply and unstable output while performing the QE task. Users need to be mindful when using LLMs for quality evaluation. For future work, we will investigate how LLMs perform on the evaluation of general MT quality under ICL and PEFT scenarios.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Our experimentation is limited to a small number of LLMs listed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.06338v1#S4.SS3" title="4.3 Models ‣ 4 Methodology ‣ Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?"><span class="ltx_text ltx_ref_tag">4.3</span></a>, due to the economic, time and energy cost in LLM training and inferencing. Results might be different on other LLMs. Meanwhile, although LLM-based evaluation is more interpretable and accurate, it is much more time- and energy-consuming than using regular QE models.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arkoudas (2023)</span>
<span class="ltx_bibblock">
Konstantine Arkoudas. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.03762" title="">GPT-4 can’t reason</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint</em>, arXiv:2308.03762.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2020)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.747" title="">Unsupervised cross-lingual representation learning at scale</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 8440–8451, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/1feb87871436031bdc0f2beaa62a049b-Paper-Conference.pdf" title="">QLoRA: Efficient Finetuning of Quantized LLMs</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Advances in Neural Information Processing Systems</em>, volume 36, pages 10088–10115. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dorr et al. (2011)</span>
<span class="ltx_bibblock">
Bonnie Dorr, Joseph Olive, John McCary, and Caitlin Christianson. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-1-4419-7713-7_5" title="">Machine Translation Evaluation and Optimization</a>.

</span>
<span class="ltx_bibblock">In J. Olive, C. Christianson, and J. McCary, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Handbook of Natural Language Processing and Machine Translation</em>, pages 745–843. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernandes et al. (2023)</span>
<span class="ltx_bibblock">
Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, André Martins, Graham Neubig, Ankush Garg, Jonathan Clark, Markus Freitag, and Orhan Firat. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.100" title="">The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 1066–1083, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2021a)</span>
<span class="ltx_bibblock">
Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00437" title="">Experts, errors, and context: A large-scale study of human evaluation for machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Transactions of the Association for Computational Linguistics</em>, volume 9, pages 1460–1474, Cambridge, MA. MIT Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2021b)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, George Foster, Alon Lavie, and Ondřej Bojar. 2021b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.73" title="">Results of the WMT21 metrics shared task: Evaluating metrics with expert-based human evaluations on TED and news domain</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the Sixth Conference on Machine Translation</em>, pages 733–774, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team (2024)</span>
<span class="ltx_bibblock">
Gemini Team. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.05530" title="">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint</em>, arXiv:2403.05530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graham et al. (2013)</span>
<span class="ltx_bibblock">
Yvette Graham, Timothy Baldwin, Alistair Moffat, and Justin Zobel. 2013.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W13-2305" title="">Continuous measurement scales in human evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</em>, pages 33–41, Sofia, Bulgaria. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guerreiro et al. (2024)</span>
<span class="ltx_bibblock">
Nuno M. Guerreiro, Ricardo Rei, Daan van Stigt, Luisa Coheur, Pierre Colombo, and André F. T. Martins. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00683" title="">xcomet: Transparent Machine Translation Evaluation through Fine-grained Error Detection</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Transactions of the Association for Computational Linguistics</em>, 12:979–995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2021)</span>
<span class="ltx_bibblock">
Xianwei Guo, Hua Lai, Yan Xiang, Zhengtao Yu, and Yuxin Huang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.ccl-1.82" title="">Emotion Classification of COVID-19 Chinese Microblogs based on the Emotion Category Description</a>.

</span>
<span class="ltx_bibblock">pages 916–927. Chinese Information Processing Society of China.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hassan et al. (2018)</span>
<span class="ltx_bibblock">
Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan Clark, Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William Lewis, Mu Li, Shujie Liu, Tie-Yan Liu, Renqian Luo, Arul Menezes, Tao Qin, Frank Seide, Xu Tan, Fei Tian, Lijun Wu, Shuangzhi Wu, Yingce Xia, Dongdong Zhang, Zhirui Zhang, and Ming Zhou. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:1803.05567" title="">Achieving Human Parity on Automatic Chinese to English News Translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXive preprint</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">LoRA: Low-Rank Adaptation of Large Language Models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.04088" title="">Mixtral of Experts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:2401.04088.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi and Federmann (2023a)</span>
<span class="ltx_bibblock">
Tom Kocmi and Christian Federmann. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.wmt-1.64" title="">GEMBA-MQM: Detecting translation quality error spans with GPT-4</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the Eighth Conference on Machine Translation</em>, pages 768–775, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocmi and Federmann (2023b)</span>
<span class="ltx_bibblock">
Tom Kocmi and Christian Federmann. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.19" title="">Large language models are state-of-the-art evaluators of translation quality</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, pages 193–203, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al. (2020)</span>
<span class="ltx_bibblock">
Guokun Lai, Zihang Dai, and Yiming Yang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2009.08595" title="">Unsupervised Parallel Corpus Mining on Web Data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lommel et al. (2014)</span>
<span class="ltx_bibblock">
Arle Richard Lommel, Aljoscha Burchardt, and Hans Uszkoreit. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.5565/rev/tradumatica.77" title="">Multidimensional Quality Metrics: A Flexible System for Assessing Translation Quality</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Tradumàtica: tecnologies de la traducció</em>, 0:455–463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)</span>
<span class="ltx_bibblock">
Michael McCloskey and Neal J. Cohen. 1989.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1016/S0079-7421(08)60536-8" title="">Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</a>.

</span>
<span class="ltx_bibblock">volume 24, pages 109–165. Academic Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2303.08774" title="">GPT-4 Technical Report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXive preprint</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian et al. (2023)</span>
<span class="ltx_bibblock">
Shenbin Qian, Constantin Orasan, Felix Do Carmo, Qiuliang Li, and Diptesh Kanojia. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.13" title="">Evaluation of Chinese-English machine translation of emotion-loaded microblog texts: A human annotated dataset for the quality assessment of emotion translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, pages 125–135, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranasinghe et al. (2020)</span>
<span class="ltx_bibblock">
Tharindu Ranasinghe, Constantin Orasan, and Ruslan Mitkov. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.coling-main.445.pdf" title="">TransQuest: Translation Quality Estimation with Cross-lingual Transformers</a>.

</span>
<span class="ltx_bibblock">pages 5070–5081. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2020)</span>
<span class="ltx_bibblock">
Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.213" title="">COMET: A neural framework for MT evaluation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 2685–2702, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022)</span>
<span class="ltx_bibblock">
Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova, Duarte Alves, Luisa Coheur, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.60" title="">CometKiwi: IST-unbabel 2022 submission for the quality estimation shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 634–645, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruiz-Garcia (2022)</span>
<span class="ltx_bibblock">
Miguel Ruiz-Garcia. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41598-022-14348-x" title="">Model architecture can transform catastrophic forgetting into positive transfer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Scientific Reports</em>, 12.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saadany et al. (2023)</span>
<span class="ltx_bibblock">
Hadeel Saadany, Constantin Orasan, Rocio Caro Quintana, Felix Do Carmo, and Leonardo Zilio. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.eamt-1.27" title="">Analysing mistranslation of emotions in multilingual tweets by online MT tools</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, pages 275–284, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snover et al. (2006)</span>
<span class="ltx_bibblock">
Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, and John Makhoul. 2006.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2006.amta-papers.25" title="">A study of translation edit rate with targeted human annotation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers</em>, pages 223–231, Cambridge, Massachusetts, USA. Association for Machine Translation in the Americas.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spearman (1904)</span>
<span class="ltx_bibblock">
Charles Spearman. 1904.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://www.jstor.org/stable/1412159?origin=JSTOR-pdf" title="">The proof and measurement of association between two things</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">The American Journal of Psychology</em>, 15:72–101.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Specia et al. (2020)</span>
<span class="ltx_bibblock">
Lucia Specia, Frédéric Blain, Marina Fomicheva, Erick Fonseca, Vishrav Chaudhary, Francisco Guzmán, and André F. T. Martins. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.wmt-1.79" title="">Findings of the WMT 2020 shared task on quality estimation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the Fifth Conference on Machine Translation</em>, pages 743–764, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Specia et al. (2021)</span>
<span class="ltx_bibblock">
Lucia Specia, Frédéric Blain, Marina Fomicheva, Chrysoula Zerva, Zhenhao Li, Vishrav Chaudhary, and André F. T. Martins. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.71" title="">Findings of the WMT 2021 shared task on quality estimation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the Sixth Conference on Machine Translation</em>, pages 684–725, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Specia et al. (2018)</span>
<span class="ltx_bibblock">
Lucia Specia, Carolina Scarton, and Gustavo Henrique Paetzold. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-3-031-02168-8_1" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1.1">Quality Estimation for Machine Translation</em></a>.

</span>
<span class="ltx_bibblock">Spinger, Cham, Germany.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stewart et al. (2020)</span>
<span class="ltx_bibblock">
Craig Stewart, Ricardo Rei, Catarina Farinha, and Alon Lavie. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.amta-user.4" title="">COMET - deploying a new state-of-the-art MT evaluation metric in production</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 2: User Track)</em>, pages 78–109, Virtual. Association for Machine Translation in the Americas.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Preprint</em>, arXiv:2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Shuo Wang, Zhaopeng Tu, Zhixing Tan, Wenxuan Wang, Maosong Sun, and Yang Liu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2106.13627" title="">Language models are good translators</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024)</span>
<span class="ltx_bibblock">
Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Shaochen Zhong, Bing Yin, and Xia Hu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3649506" title="">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">ACM Trans. Knowl. Discov. Data</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zerva et al. (2022)</span>
<span class="ltx_bibblock">
Chrysoula Zerva, Frédéric Blain, Ricardo Rei, Piyawat Lertvittayakumjorn, José G. C. de Souza, Steffen Eger, Diptesh Kanojia, Duarte Alves, Constantin Orăsan, Marina Fomicheva, André F. T. Martins, and Lucia Specia. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.3" title="">Findings of the WMT 2022 shared task on quality estimation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 69–99, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024)</span>
<span class="ltx_bibblock">
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2403.13372" title="">LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)</em>, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 20:15:30 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
