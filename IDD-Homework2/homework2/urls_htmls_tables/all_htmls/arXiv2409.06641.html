<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Segmenting sea ice floes in close-range optical imagery with active contour and foundation models</title>
<!--Generated on Wed Sep 11 07:18:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %\date{September␣9,␣1985}¯%␣Here␣you␣can␣change␣the␣date␣presented␣in␣the␣paper␣title 
     %****␣template.tex␣Line␣25␣**** .-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.06641v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S1" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Image acquisition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Pre-processing</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.SS1" title="In 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Orthorectification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.SS2" title="In 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Effect of ship motion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.SS3" title="In 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Image enhancement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Image segmentation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS1" title="In 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Active contours model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS2" title="In 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Segment Anything Model</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS2.SSS1" title="In 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Automatic mask generator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS2.SSS2" title="In 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Prompt-based</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS3" title="In 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>A combination of SAM and GVF Snake algorithms</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Validation of methods for sea ice analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.SS1" title="In 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Creation of benchmark segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.SS2" title="In 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Comparison of floe properties: automated vs. manual segmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S6" title="In Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Segmenting sea ice floes in close-range optical imagery with active contour and foundation models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giulio Passerotti 
<br class="ltx_break"/>The University of Melbourne, Australia
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">giuliopasserotti@gmail.com</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id2.2.id2">\And</span>Alberto Alberello 
<br class="ltx_break"/>University of East Anglia, Norwich, UK
<span class="ltx_ERROR undefined" id="id3.3.id3">\And</span>Marcello Vichi 
<br class="ltx_break"/>University of Cape Town, South Africa
<span class="ltx_ERROR undefined" id="id4.4.id4">\And</span>Luke G. Bennetts 
<br class="ltx_break"/>University of Adelaide, Australia
<span class="ltx_ERROR undefined" id="id5.5.id5">\And</span>James Bailey 
<br class="ltx_break"/>The University of Melbourne, Australia
<span class="ltx_ERROR undefined" id="id6.6.id6">\And</span>Alessandro Toffoli 
<br class="ltx_break"/>The University of Melbourne, Australia 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id7.7.id7">toffoli.alessandro@gmail.com</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">The size and shape of sea ice floes play a crucial role in influencing ocean-atmosphere energy exchanges, sea ice concentrations, albedo, and wave propagation through ice-covered waters. Despite the availability of diverse image segmentation techniques for analyzing sea ice imagery, accurately detecting and measuring floes remains a considerable challenge.
This study presents a precise methodology for in-situ sea ice imagery acquisition, including automated orthorectification to correct perspective distortions. The image dataset, collected during an Antarctic winter expedition, was used to evaluate various automated image segmentation approaches: the traditional GVF Snake algorithm and the advanced deep learning model, Segment Anything Model (SAM). To address the limitations of each method, a hybrid algorithm combining traditional and AI-based techniques is proposed.
The effectiveness of these approaches was validated through a detailed analysis of ice floe detection accuracy, floe size, and ice concentration statistics, with the outcomes normalized against a manually segmented benchmark.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The analysis of sea ice characteristics in the Antarctic Marginal Ice Zone (MIZ) is crucial for understanding and predicting changes in sea-ice dynamics and their broader climatic effects. The MIZ is exposed to oceanic waves and swells, which can break up ice floes, creating smaller fragments <cite class="ltx_cite ltx_citemacro_citep">(Herman et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib1" title="">2021</a>)</cite>. This fragmentation process is influenced by floe size and ice concentration, which determine how waves transmit energy through the ice <cite class="ltx_cite ltx_citemacro_citep">(Dolatshah et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib2" title="">2018</a>; Montiel et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib3" title="">2016</a>; Meylan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib4" title="">2021</a>; Passerotti et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib5" title="">2022</a>)</cite>.
Floe size and shape distributions play a significant role in the melting process <cite class="ltx_cite ltx_citemacro_citep">(Horvat et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib6" title="">2016</a>)</cite>, while ice concentration impacts the ocean surface energy budget by modifying the albedo effect (the reflection of solar energy back into space) <cite class="ltx_cite ltx_citemacro_citep">(Tsamados et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib7" title="">2014</a>; Lüpkes et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib8" title="">2012</a>)</cite>. Additionally, floe size distribution affects sea ice rheology, influencing how the ice deforms and moves under external forces, which in turn affects overall ice dynamics, including the formation of ice ridges and leads (openings in sea ice) <cite class="ltx_cite ltx_citemacro_citep">(Feltham, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib9" title="">2005</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Due to the harsh conditions in Antarctica, along with the logistical challenges and high costs associated with field campaigns, observations of sea ice have traditionally been sparse.
Most of the available sea ice data rely on visual observations made following the ASPeCT protocol during voyages at high latitudes <cite class="ltx_cite ltx_citemacro_citep">(WORBY, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib10" title="">2004</a>; Hepworth et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib11" title="">2020</a>)</cite>. However, visual observations are prone to human error and interpretation, introducing inconsistencies and uncertainties into the datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recent advancements in image acquisition and processing techniques have helped reduce the uncertainties and errors associated with manual methods.
Numerous in-situ sea ice imagery studies <cite class="ltx_cite ltx_citemacro_citep">(Sandru et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib12" title="">2020</a>; Zhang and Skjetne, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib13" title="">2015</a>; Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>; Parmiggiani et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib15" title="">2018</a>; Weissling et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib16" title="">2009</a>; Alsharay et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib17" title="">2022</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib18" title="">2016</a>)</cite> have been undertaken to detect ice floes from digital images obtained aboard ships or from aerial perspectives. The primary challenge in processing sea ice images resides in associating each individual pixel with its corresponding floe. Ice floes may be densely packed or overlapping, making it difficult to distinguish their boundaries. Additionally, variable lighting conditions across different times of the day further complicate image analysis.
A classical approach for identifying ice floes involves threshold segmentation algorithms, but these typically rely on subjective, user-dependent threshold values <cite class="ltx_cite ltx_citemacro_citep">(Heyn et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib19" title="">2017</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib20" title="">2008</a>; Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>)</cite>. Efforts to automate the segmentation process have led to the exploration of more advanced techniques, such as the k-means algorithm <cite class="ltx_cite ltx_citemacro_citep">(Weissling et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib16" title="">2009</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib18" title="">2016</a>)</cite>, the gradient vector flow (GVF) snake algorithm <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Skjetne, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib13" title="">2015</a>)</cite>, and watershed segmentation <cite class="ltx_cite ltx_citemacro_citep">(Dumas-Lefebvre and Dumont, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib21" title="">2023</a>; Parmiggiani et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib15" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In recent years, deep learning has revolutionized image processing, achieving unprecedented levels of accuracy in object detection, image classification, and semantic segmentation. Convolutional neural networks (CNNs) automatically identify and classify pixels in images based on patterns learned from a training dataset. In sea ice research, CNNs have been applied <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib22" title="">2022</a>; Panchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib23" title="">2021</a>; Dowden et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib24" title="">2021</a>)</cite> to digital images obtained aboard ships to identify elements such as ice, water, and sky. However, these studies focus on semantic segmentation, assigning each pixel to a category without distinguishing individual objects within those categories. Moreover, deep learning methods require large amounts of labeled data <cite class="ltx_cite ltx_citemacro_citep">(Maška et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib25" title="">2023</a>)</cite>, meaning extensive datasets with each floe distinctly labeled would be needed to accurately identify and segment individual ice floes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To ease the requirements of data annotation and model training, vision foundation models have been developed <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib26" title="">2020</a>)</cite>. These large-scale deep learning models are pre-trained on massive datasets and can transfer the knowledge they acquire to new, less familiar tasks, functioning as general-purpose systems <cite class="ltx_cite ltx_citemacro_citep">(Raghu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib27" title="">2021</a>)</cite>.
The first vision foundation model, the Segment Anything Model (SAM), developed by Meta AI Research <cite class="ltx_cite ltx_citemacro_citep">(Kirillov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib28" title="">2023</a>)</cite>, was trained on an unprecedented dataset of 1 billion masks across 11 million images, enabling it to generate segmentation masks without additional training data.
SAM’s utility was investigated by <cite class="ltx_cite ltx_citemacro_citet">Shankar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib29" title="">2023</a>)</cite> for performing semantic segmentation of large icebergs in satellite images, where it achieved accuracy comparable to highly specialized CNNs. This advancement significantly reduces the need to build deep learning models from scratch <cite class="ltx_cite ltx_citemacro_citep">(Ma and Wang, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib30" title="">2023</a>)</cite>, making it more feasible to apply sophisticated AI techniques in the challenging context of polar ice research.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this study, a precise image acquisition protocol was developed to operate aboard the S.A. Agulhas II icebreaker during a winter expedition in the Antarctic MIZ. This protocol included automated image orthorectification to mitigate wave-induced perspective distortions and enable the conversion of image data into metric measurements. An extensive dataset of high-resolution, close-range sea ice images, with varying levels of clarity, was used to assess different automated image segmentation approaches: the traditional GVF Snake algorithm and the advanced deep learning model SAM. To address the limitations of each approach, a hybrid algorithm combining traditional and AI-based techniques was proposed. A statistical comparison was performed to determine the most effective segmentation method for accurately identifying ice floes and estimating floe size and ice concentration.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Image acquisition</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.2">Close-range optical sea ice imagery was acquired underway from a sensor installed on the icebreaker S.A. Agulhas II, during an austral winter expedition to the Antarctic MIZ in the Eastern Weddell Sea (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2.F1" title="Figure 1 ‣ 2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">1</span></a>). The voyage was part of the Southern oCean seAsonaL Experiment <cite class="ltx_cite ltx_citemacro_citep">(SCALE; Ryan-Keogh and Vichi, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib31" title="">2022</a>)</cite>. The sea ice region was reached at approximately 58 degrees South and 1 degree West on 19 July 2022 (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2.F1" title="Figure 1 ‣ 2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">1</span></a>b). The vessel then continued along a Southward route until it reached consolidated sea ice at latitude 58.8<sup class="ltx_sup" id="S2.p1.2.1"><span class="ltx_text ltx_font_italic" id="S2.p1.2.1.1">∘</span></sup>S (<math alttext="\approx" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mo id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><approx id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">≈</annotation></semantics></math>85 km from the ice edge). Overall, the expedition spent six days in the MIZ before heading back North <cite class="ltx_cite ltx_citemacro_citep">(see details on the expedition in Tersigni et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib32" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="604" id="S2.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Antarctic SCALE expedition, winter 2022: (a) camera mounted on S.A. Agulhas II; (b) ship’s track; (c) high-resolution image of the sea ice surface obtained under clear sky conditions; (d) exhibiting varying ice gradients; (e) taken at nighttime.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.6">The sensor consisted of a GigE monochrome industrial camera (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2.F1" title="Figure 1 ‣ 2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">1</span></a>a) equipped with 2/3” Sony CMOS Pregius sensors and 5 mm F1.8 C-mount lenses (angle of view <math alttext="\approx" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mo id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><approx id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">≈</annotation></semantics></math>120 degrees). It was mounted on the port side of the monkey bridge at 25 m above the water line and tilted by <math alttext="\approx" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mo id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><approx id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">≈</annotation></semantics></math>70 degrees relative to the ground. The field of view covered a portion of the ocean surface of <math alttext="\approx" class="ltx_Math" display="inline" id="S2.p2.3.m3.1"><semantics id="S2.p2.3.m3.1a"><mo id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><approx id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.1d">≈</annotation></semantics></math> 200<math alttext="\times" class="ltx_Math" display="inline" id="S2.p2.4.m4.1"><semantics id="S2.p2.4.m4.1a"><mo id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><times id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.p2.4.m4.1d">×</annotation></semantics></math>200 m<sup class="ltx_sup" id="S2.p2.6.1">2</sup>. Images were recorded continuously with a resolution of 1920<math alttext="\times" class="ltx_Math" display="inline" id="S2.p2.6.m6.1"><semantics id="S2.p2.6.m6.1a"><mo id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><times id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.p2.6.m6.1d">×</annotation></semantics></math>1080 pixels and at a sampling rate of 1 Hz; around 90,000 images were collected during the expedition. Flashlights were used to illuminate sea ice overnight.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Therefore, the database spans through a wide range of photo quality, with approximately 70% capturing complex ice scenarios. This significant portion includes images taken in the darkness of night or featuring irregularly shaped and densely packed ice floes with varying gradients; sample images are reported in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2.F1" title="Figure 1 ‣ 2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">1</span></a>c-e. While many image segmentation methods perform well under ideal conditions, field conditions seldom meet this criterion, presenting a non-uniform and unpredictable environment.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Pre-processing</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Orthorectification</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The tilt of the sensor produces a perspective distortion, so that ice floes close to the camera appear bigger than those at a farther location. This creates inconsistencies in the scaling, which changes throughout the imagery scene and, hence, compromises the pixel-to-metre conversion. Therefore, a correction process that rectifies the sensor orientation, known as orthorectification, was applied to rearrange the displaced pixels as if the image were aligned with the focal plane (i.e. pixels are projected onto a plane perpendicular to the optical axis).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The process relies on the interpolation of the pixels in the original image as a function of the camera projection matrix, which maps the conversion from a three dimensional point cloud in the real world into a two dimensional plane (the image) through intrinsic and extrinsic parameters <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib33" title="">2004</a>)</cite>. The former depend on how the sensor captures the images and include, but they are not limited to, the focal length, aperture, resolution and the optical center of the camera’s sensor.
These parameters were derived from a calibration process <cite class="ltx_cite ltx_citemacro_citep">(a common method is presented in Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib34" title="">2000</a>)</cite>, which evaluated image distortion by analysing multiple images of a planar pattern with known geometry <cite class="ltx_cite ltx_citemacro_cite">(a chessboard; see technical details in Sturm and Maybank, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib35" title="">1999</a>; Bouguet, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib36" title="">2004</a>)</cite>. The calibration was performed before and after the expedition to verify that intrinsic features remained constant throughout the campaign.
The extrinsic parameters, on the other hand, describe the translations and rotations of the sensor relative to a reference Cartesian coordinate system. For simplicity, the camera was centered at the origin of the horizontal axis, so that translations in the x and y directions were nil, and at a height of 25 m above the water line. The rotations encompass three components: the tilt around the transverse axis, which was applied during deployment; the roll around the optical axis, which was negligible assuming alignment with the horizon; and the heading around the vertical axis, which aligned with the sensor’s direction. The latter is relevant only if the target is a specific object in the field of view, but it becomes negligible if the target is an extended portion of the image (the ocean surface in the present application). In the absence of any external forcing such as the ship motion, translations and rotations are constant over time. A sensitivity analysis relative to ship motion is discussed in §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.SS2" title="3.2 Effect of ship motion ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The orthorectification was undertaken with the CameraTransfor Python package <cite class="ltx_cite ltx_citemacro_citep">(Gerum et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib37" title="">2019</a>)</cite>, while the calibration was conducted through the Computer Vision Toolbox for  MatLab <cite class="ltx_cite ltx_citemacro_citep">(Bouguet, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib36" title="">2004</a>)</cite>. The process was limited to a portion of the ocean surface confined into a rectangle of about 95 m <math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mo id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><times id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">×</annotation></semantics></math> 165 m, which, based on a visual assessment over samples of images, includes clearly visible floes. The resolution (i.e. pixel-to-metre conversion) was forced to 0.05 m, to ensure both a good object accuracy and capacity of determine small-scale features in sea ice <cite class="ltx_cite ltx_citemacro_citep">(in the order of tens of centimetres; Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>)</cite>. A sample image and its orthorectified counterpart are showed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F2" title="Figure 2 ‣ 3.1 Orthorectification ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="236" id="S3.F2.g1" src="x2.png" width="706"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Sample sea ice image (a) from Antarctic SCALE expedition, winter 2022, after perspective correction, with the region of interest for analysis highlighted in red (b).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">A quality check after the orthorectification revealed that floe edges loosed sharpness with distance from the sensor (see upper band of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F2" title="Figure 2 ‣ 3.1 Orthorectification ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">2</span></a>b). To avoid ambiguity in the far field and, thus, reduce the risk of detecting unrealistic floes, the workable portion of the orthorectified images was restricted to an area of about 60 m <math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mo id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><times id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">×</annotation></semantics></math> 120 m close to the sensors (see area within the red rectangle in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F2" title="Figure 2 ‣ 3.1 Orthorectification ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">2</span></a>b).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Effect of ship motion</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="950" id="S3.F3.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Uncertainty analysis of extrinsic camera parameters on the average diameter of ice floes, highlighted in red. This analysis includes variations of (a) <math alttext="\pm" class="ltx_Math" display="inline" id="S3.F3.4.m1.1"><semantics id="S3.F3.4.m1.1b"><mo id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.1c"><csymbol cd="latexml" id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.F3.4.m1.1e">±</annotation></semantics></math> 1 m in elevation, (b) <math alttext="\pm" class="ltx_Math" display="inline" id="S3.F3.5.m2.1"><semantics id="S3.F3.5.m2.1b"><mo id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c"><csymbol cd="latexml" id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.F3.5.m2.1e">±</annotation></semantics></math> 1 degree in tilt, and (c) <math alttext="\pm" class="ltx_Math" display="inline" id="S3.F3.6.m3.1"><semantics id="S3.F3.6.m3.1b"><mo id="S3.F3.6.m3.1.1" xref="S3.F3.6.m3.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.F3.6.m3.1c"><csymbol cd="latexml" id="S3.F3.6.m3.1.1.cmml" xref="S3.F3.6.m3.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m3.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.F3.6.m3.1e">±</annotation></semantics></math> 2 degrees in roll. Diameters are normalized with those derived from the image orthorectified using the extrinsics measured aboard the ship. The shaded blue area indicates a 5% range.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The orthorectification, upon which segmentation is based, relies on the positioning of the sensor (the extrinsic parameters). Consistently with similar applications from mobile platforms like aircraft <cite class="ltx_cite ltx_citemacro_citep">(Parmiggiani et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib15" title="">2018</a>; Zhang and Skjetne, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib13" title="">2015</a>)</cite> and ships <cite class="ltx_cite ltx_citemacro_citep">(Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>; Heyn et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib19" title="">2017</a>)</cite>, it was assumed that the sensor was fixed and, hence, the ship-induced motion was neglected. Although this hypothesis holds under in relatively calm seas, the ship motion was substantial during the expedition <cite class="ltx_cite ltx_citemacro_citep">(cf. Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib38" title="">2022</a>)</cite>. As the displacement of the supporting platform can shift the camera’s orientation relative to the ocean surface, it affects the orthorectification and, eventually, the floe size.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.3">An image recorded in clear sky condition is used as a proxy to assess the sensitivity to ship motion. The orthorectification is obtained considering several misalignment relative to the original position, varying <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mo id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">±</annotation></semantics></math> 1 m, <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mo id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">±</annotation></semantics></math> 1 degrees, and <math alttext="\pm" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mo id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">±</annotation></semantics></math> 2 degrees for elevation, tilt and roll, respectively. These ranges are consistent with extreme ship motion recordings.
A few clearly distinguishable floes are then manually segmented by meticulously outlining their contours using photo editing software, ensuring accurate comparison of their dimensions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F3" title="Figure 3 ‣ 3.2 Effect of ship motion ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">3</span></a> shows the average variation in size, relative to the dimension extrapolated from the image with sensor in its original position, as a function of the misalignment. Uncertainties associated to variations of elevation are confined within 5% (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F3" title="Figure 3 ‣ 3.2 Effect of ship motion ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">3</span></a>a). Variations in the tilt result in a slightly more substantial impact on floe size (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F3" title="Figure 3 ‣ 3.2 Effect of ship motion ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">3</span></a>b), but they only marginally exceed 5%. Changes of roll has the least impact, with variations of size less than 2% (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F3" title="Figure 3 ‣ 3.2 Effect of ship motion ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">3</span></a>c). It should be noted that the impact of ship motion is evaluated considering elevation, tilt and roll independently. However, they are concurrent during navigation, counteracting each other and so mitigating the overall error, which can be confirmed negligible.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Image enhancement</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Sea ice imagery captured in natural environments suffers from varying light intensity, contrast, shadows, impurities, and other dynamic factors, making segmentation challenging. Within the database, image illumination and contrast varied significantly due to differences in lighting and weather conditions (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2.F1" title="Figure 1 ‣ 2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">1</span></a>c-e). Consequently, the boundaries of ice floes in the raw images often remained uncertain, complicating the automation of segmentation processes <cite class="ltx_cite ltx_citemacro_citep">(see, for example, Maška et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib25" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Image enhancement techniques were applied to sharpen the edges. This was achieved through the homogenization of gray-scale levels <cite class="ltx_cite ltx_citemacro_citep">(see, for example, Parmiggiani et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib15" title="">2018</a>)</cite>, using a combination of an edge-preserving Gaussian bilateral filter <cite class="ltx_cite ltx_citemacro_citep">(Tomasi and Manduchi, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib39" title="">1998</a>)</cite> and an anisotropic diffusion filter <cite class="ltx_cite ltx_citemacro_citep">(Perona and Malik, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib40" title="">1990</a>)</cite>. These filters smoothed regions with low gradients while preserving the boundaries of the ice floes. Contrast enhancement was then applied using contrast-limited adaptive histogram equalization (CLAHE) <cite class="ltx_cite ltx_citemacro_citep">(Zuiderveld, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib41" title="">1994</a>)</cite> to accentuate the boundaries and reveal fine details (see transition from original to enhanced image in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F4" title="Figure 4 ‣ 3.3 Image enhancement ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4</span></a>a,b). It is worth mentioning that the adaptive nature of this method allows it to tailor its adjustments to the specific characteristics of each image, eliminating the need for predefined thresholds. For night photographs, image enhancement was limited to the area illuminated by the vessel’s spotlight, which was identified through haze removal techniques <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib42" title="">2011</a>)</cite>. These techniques were used to estimate the illumination map by inverting the low-light image, applying dehazing, and then reinverting the result, effectively highlighting the spotlight-illuminated areas.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="175" id="S3.F4.g1" src="x4.png" width="706"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Image enhancement: (a) region of interest of the image in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S3.F2" title="Figure 2 ‣ 3.1 Orthorectification ‣ 3 Pre-processing ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">2</span></a>b; (b) gray-level homogenization through Gaussian bilateral and anisotropic diffusion filter, and contrast enhancement using CLAHE;</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Image segmentation</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Active contours model</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Active contour models, or snakes, have proven effective for segmenting connected floes in images <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Skjetne, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib13" title="">2015</a>)</cite>, a common occurrence in the Southern Ocean. These models adjust an evolving curve to align with floe boundaries <cite class="ltx_cite ltx_citemacro_citep">(Kass et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib43" title="">1988</a>)</cite> (an example of the evolution of an initial contour is presented in the inset of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F5" title="Figure 5 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">5</span></a>). Their accuracy, however, depends on the initial contour placement. Poor placement may result in incorrect boundaries, while contours placed near the true edges enable faster and more precise convergence. To eliminate the need for manual contouring, an automated contour generator, capable of adapting to various floe shapes, has been introduced, making the segmentation process fully autonomous.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="321" id="S4.F5.g1" src="x5.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Graphical representation of the Gradient Vector Flow (GVF) algorithm, featuring a dynamic curve that adjusts to precisely conform to the boundaries of the ice floes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The several steps for the image segmentation are illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>. The process starts with the separation of the foreground (i.e. the objects) from the background through the transformation of the enhanced ice image into a binary counterpart (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>b). This is achieved by selecting an appropriate threshold in the gray-scale histogram of the entire image. Pixels below the threshold are allocated a value of zero and labeled as non-feature pixels (background), while those above it are assigned a value of one and labeled as feature pixels (foreground; this corresponds to the white islands in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>b). In the presence of many objects with low gray-scale contrast, the histograms does not show distinctive modes necessarily, leaving ambiguities in the selection of appropriate thresholds. To prevent uncertainties, the Otsu method <cite class="ltx_cite ltx_citemacro_citep">(Otsu, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib44" title="">1979</a>)</cite> is used for automated thresholding. Otsu’s method automatically determines the optimal threshold by maximizing the variance between the foreground and background pixel intensities. To further improve accuracy, the binarization is applied on small clusters of size 12 m <math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><times id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">×</annotation></semantics></math> 12 m, each of which contains approximately 20 floes. The smaller size of the clusters produces more segregated modes in the grey-scale histogram, enhancing the effectiveness of automated thresholding <cite class="ltx_cite ltx_citemacro_citep">(Byun and Nam, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib45" title="">2021</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="864" id="S4.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>GVF Snake algorithm: (a) enhanced sea ice image; (b) seeds in red of the ice floes in the binary equivalent of the image; (c) perimeter in red of the floes containing a single seed; (d) elliptical initial contour in red of the floes containing a single seed after a morphological erosion; (e) circular initial contour in red for each remaining and unused seed; (f) ice floes already identified in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>c; (g) ice floes detected by the GVF snake algorithm initialized with the elliptical contours; (h) ice floes detected by the GVF snake algorithm initialized with the circular contours; (i) final binary image with all the detected ice floes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">A distance transformation <cite class="ltx_cite ltx_citemacro_citep">(Paglieroni, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib46" title="">1992</a>)</cite> is then applied to the binary image to assign each feature pixel a value corresponding to its distance from the nearest non-feature pixel <cite class="ltx_cite ltx_citemacro_citep">(Maurer et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib47" title="">2003</a>)</cite>. The local maxima within this matrix, defined as pixels with values greater than or equal to those of their neighbors, identify seeds that pinpoint individual objects <cite class="ltx_cite ltx_citemacro_citep">(cf. Zhang and Skjetne, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib13" title="">2015</a>)</cite>. Similarly to the clustering of binarisation, regional local maxima from sub-regions of the whole image were considered to enhance accuracy. If the portion of image within a sub-region is sharp, objects are well separated and possesses only one seed. Therefore, their segmentation automatically follows from the binarisation. This initial phase of floe detection is reported in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>c,f, which show seeds and the concurrent segmented objects respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">For the majority of sub-regions, however, adjacent objects were merged through the process and thus could not be segmented by binarisation alone. This resulted in large and irregular (white) islands pinpointed by more that one seed (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>b). For these cases, the segmentation is achieved through a second phase, which relies on a gradient vector flow (GVF) Snake algorithm <cite class="ltx_cite ltx_citemacro_citep">(Xu and Prince, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib48" title="">1998</a>)</cite>.
As an extension of traditional active contour models, the GVF Snake is less dependent on the initial contour and, thus, it can process objects with complex shapes more efficiently, even in noisy and low contrast images. The initial contour shape does not restrict the final segmentation from aligning with irregular boundaries.
As most of the objects are connected to each others through only a few pixels, they can be isolated by smoothing the edges with a morphological erosion process <cite class="ltx_cite ltx_citemacro_citep">(Adams, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib49" title="">1993</a>)</cite>. These newly emerging objects are initialised by ellipses, which represent a natural shape for ice floes <cite class="ltx_cite ltx_citemacro_citep">(cf. Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>; Passerotti et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib5" title="">2022</a>)</cite>. The initial contour is selected so that the second moment of the covariance matrix matches the one of the object <cite class="ltx_cite ltx_citemacro_citep">(Mulchrone and Choudhury, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib50" title="">2004</a>)</cite>; see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>d.
The unprocessed objects remain within conglomerates of white regions as they share a significant portion of the edge with their neighbors, which cannot be consumed with morphological erosion. Segmentation is achieved by applying circles as initial contours to seeds, noting that the circular shape is an alternative to ellipses for approximating ice floes of small dimensions <cite class="ltx_cite ltx_citemacro_citep">(Alberello et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib14" title="">2019</a>)</cite>. Relying on the distance transform, the radius is selected such that the contour is within the object, but not too far from the presumed edge (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>e). Once initial contours are assigned to all seeds, the GVF snake algorithm is applied to expand the contours and, hence, identify the object’s boundaries (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>g,h). The algorithm requires approximately 30 seconds per floe to complete the segmentation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">The GVF approach is not free from anomalies and inaccuracies, which can result in features that are not present in the original image. Coefficients of circularity and eccentricity are used to quantify how closely the various shape resembles a perfect circle or how much elongated the feature is <cite class="ltx_cite ltx_citemacro_citep">(see Ayoub, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib51" title="">2003</a>; Bottema, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib52" title="">2000</a>)</cite>. Through the imposition of high-valued thresholds, spurious features in the form of nearly-perfect circular shapes or line segments are eliminated. Furthermore, objects without closed boundaries at the image’s edges are also disregarded.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">The final output of the analysis combines results from the various phases and is reported in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>i. From this binary mask, geometric properties such as area, perimeter, and diameter are extracted by identifying connected pixel regions corresponding to each floe. Area is calculated from the number of pixels in each region, while perimeter and diameter are determined using boundary tracing techniques <cite class="ltx_cite ltx_citemacro_citep">(Biswas and Hazra, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib53" title="">2018</a>)</cite>, which follow the edges of each floe to measure their outlines and maximum span.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Segment Anything Model</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Unlike traditional snake-based models, which rely on pixel-level features such as smoothness, roughness, and contrast specific to each image, modern AI-driven techniques interpret images based on general patterns learned from extensive training datasets.
Vision foundation models <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib26" title="">2020</a>)</cite> exemplify this innovation in image segmentation. By leveraging deep learning techniques, these models process entire images without requiring prior knowledge of an object’s shape, eliminating the need for manual feature engineering or predefined contours.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Segment Anything Model (SAM) <cite class="ltx_cite ltx_citemacro_citep">(Kirillov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib28" title="">2023</a>)</cite>, developed by Meta AI Research, stands as the first and only vision foundation model capable, in principle, of segmenting any object in an image. Built on the widely-used PyTorch deep learning framework <cite class="ltx_cite ltx_citemacro_citep">(Ketkar and Moolayil, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib54" title="">2021</a>)</cite>, SAM offers two distinct segmentation modes.
The first, an automatic mask generator, segments all identifiable elements in an image independently, requiring no input from the user. SAM autonomously determines which areas to segment based on its internal parameters, providing a fully automated solution.
The second, a prompt-based mode, allows users to guide the segmentation process by marking regions of interest with points or bounding boxes. This modality is particularly valuable when precision and control over the segmented areas are critical.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Automatic mask generator</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">In the automatic mask generator mode, SAM autonomously selects a set of sample points from a fixed grid that spans the entire input image (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F7" title="Figure 7 ‣ 4.2.1 Automatic mask generator ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">7</span></a>a for a visual representation of a sample grid layout). For each selected point in the grid, the model generates one or more candidate masks, where pixels associated with identified objects are assigned a value of one (feature pixels), and pixels representing the background are assigned a value of zero (non-feature pixels).
SAM then processes these candidate masks to eliminate redundancy by identifying and removing overlapping or duplicate masks. Additionally, it filters the remaining masks for quality, ensuring that only the most accurate and relevant masks are kept.
The final output is a list of filtered masks representing all distinct elements in the image that SAM successfully identifies (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F7" title="Figure 7 ‣ 4.2.1 Automatic mask generator ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">7</span></a>b). For a sea ice image, this list includes separate masks for ice floes, interstitial ice, and open water regions. This entire process is fully autonomous, without any need for user input at any stage.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="720" id="S4.F7.g1" src="x7.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>SAM’s automatic mask generator algorithm: (a) fixed points selected by SAM over the grid in the enhanced sea ice image; (b) consolidation of the list of filtered masks returned by the model; (c) final unified mask with all the detected ice floes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">SAM requires post-processing to eliminate anomalies, inaccuracies, and objects with open boundaries at the image’s edges (cf. §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS1" title="4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.1</span></a>). While circularity and eccentricity effectively remove many of these irregularities, they are not sufficient to filter out masks representing open water regions, which are not the target of the sea ice analysis.
To resolve this, the convexity coefficient <cite class="ltx_cite ltx_citemacro_citep">(Sklansky, <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib55" title="">1970</a>)</cite> is used as an additional filtering criterion. Convexity measures how closely an object’s boundary resembles that of a convex shape; the smoother and more regular the boundary, the closer its convexity value will be to 1. Ice floes, which can often be approximated by ellipses or circles, typically have convexity values near 1. Because the image consists of only ice and water, the surrounding water regions, having more irregular boundaries, naturally exhibit much lower convexity values in comparison. By applying a high convexity threshold, these irrelevant water regions can be easily filtered out <cite class="ltx_cite ltx_citemacro_citep">(cf. Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib56" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1">A closer examination of the output list reveals that some masks redundantly represent the same ice floes, indicating that the model’s deduplication process is not always optimal. This issue is especially prevalent with adjacent or overlapping floes that have poorly defined boundaries. In such cases, the model may generate multiple identical or overlapping masks for the same floe. If left unresolved, this redundancy makes the output list unsuitable for direct quantitative analysis, as it may lead to the repeated inclusion of the same floe (see first two layers in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F7" title="Figure 7 ‣ 4.2.1 Automatic mask generator ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">7</span></a>b).
To address this, the masks in the output list are consolidated into a single, unified mask <cite class="ltx_cite ltx_citemacro_citep">(cf. Shankar et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#bib.bib29" title="">2023</a>)</cite>. This consolidation performs a union operation, where a pixel is marked as a feature pixel in the final binary mask if it was labeled as a feature pixel in any of the initial masks. This process effectively eliminates redundancy, as multiple occurrences of identical feature pixels in separate masks are included only once in the final mask (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F7" title="Figure 7 ‣ 4.2.1 Automatic mask generator ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">7</span></a>c).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p4">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1">Perimeters and properties of the ice floes segmented by SAM are finally extracted from the comprehensive mask using boundary tracing techniques. It is worth mentioning that the model was run on a consumer CPU, with a runtime of approximately 3 minutes per image. For faster processing, deployment on a GPU is recommended, as its parallel computing capabilities significantly accelerate deep learning.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Prompt-based</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">In the prompt-based mode, the user provides single or multiple prompts, such as points or bounding boxes, to guide the segmentation process. These prompts can indicate the object or area to segment, or specify both the object and areas to exclude. Since SAM’s prompt-based mode does not apply any automatic filtering, the model segments only the objects explicitly highlighted by the user’s prompts, without further refinement.</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="720" id="S4.F8.g1" src="x8.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>SAM’s prompt-based algorithm: (a) seeds in red of the ice floes in the enhanced sea ice image; (b) consolidation of the list of filtered masks returned by the model; (c) final unified mask with all the detected ice floes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">For sea ice images, seeds derived from the distance transform matrix (see description in §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS1" title="4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.1</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F6" title="Figure 6 ‣ 4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">6</span></a>b) have been found to effectively pinpoint individual ice floes. Each seed is then used as a prompt, which is fed into the model to generate a mask for the corresponding ice floe (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F8" title="Figure 8 ‣ 4.2.2 Prompt-based ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">8</span></a>a). The output is a list of masks of size n, where n corresponds to the number of seeds in the image.
However, when a seed is placed in a region of high uncertainty in the image, the resulting mask may not accurately isolate the intended floe. Instead of containing just the floe, the mask may also erroneously capture unwanted areas, such as discontinuous water regions or parts of adjacent floes (see first two layers in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F8" title="Figure 8 ‣ 4.2.2 Prompt-based ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">8</span></a>b).
The application of the shape-based filters – measuring circularity, eccentricity, and convexity – removes clusters of feature pixels that do not match the typical shape of ice floes, such as water regions.
While clusters representing parts of adjacent floes are merged with the correct floe through a union operation during the consolidation process. This operation unifies all the masks in the output list into a single mask, effectively combining the segmented portions of floes into their appropriate masks (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F8" title="Figure 8 ‣ 4.2.2 Prompt-based ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">8</span></a>c). From this final binary mask, all properties of each individual ice floe can be easily extracted.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">SAM is up to 5 times faster when using seeds as prompts compared to the automatic mode and also segments more floes. The prompt-based mode is quicker because it bypasses the model’s internal point selection process, speeding up segmentation. Additionally, in the automatic mode, SAM selects a fixed number of points, which is often insufficient to cover all the ice floes in the image, resulting in fewer floes being segmented.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>A combination of SAM and GVF Snake algorithms</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Snake-based models excel at accurately delineating floes but struggle in complex scenarios, such as ice floes with varied gradients, due to their reliance solely on visual characteristics. SAM, on the other hand, benefits from training on extensive and diverse datasets but does not integrate shape details into its segmentation process, leading to issues with adjacent floes that have weak edges. Combining SAM with active contours overcomes these limitations, with the GVF model enhancing SAM’s segmentation by incorporating detailed floe shape information.</p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="844" id="S4.F9.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>SAM-GVF hybrid algorithm: (a) enhanced sea ice image; (b) unified binary mask produced by SAM’s prompt mode with seeds in red of the ice floes; (c) contour in red of the floes containing a single seed because already correctly segmented by SAM; (d) initial contour in red of the floes containing a single seed after a morphological erosion; (e) circular initial contour in red for each remaining and unused seed; (f) ice floes already identified in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>c; (g) ice floes detected by the GVF snake algorithm initialized with the initial contours in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>d; (h) ice floes detected by the GVF snake algorithm initialized with the circular contours; (i) final binary image with all the detected ice floes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The combination of SAM and GVF begins with a broad identification of ice floes using SAM, followed by precise shape-specific refinements with GVF. The steps for this hybrid segmentation approach are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>. The process starts with SAM’s prompt-based mode applied to the enhanced sea ice image, as outlined in §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS2.SSS2" title="4.2.2 Prompt-based ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>. Seeds from the distance transform matrix (see description in §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS1" title="4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.1</span></a>) are used to initialize SAM, generating masks for individual floes. While this method efficiently isolates floes, it can sometimes produce inaccuracies due to uncertainty in certain areas of the image. To address this, the individual masks are consolidated into a unified binary mask (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>b).
The consolidation corrects segmentation by eliminating uncertain masks and retaining those clearly associated with floes. However, even though most floes are successfully detected and separated, challenges arise when adjacent floes have blurred or unclear edges. The model struggles to accurately assign these ambiguous edge regions to a single floe, causing such floes to be welded together at their unclear boundaries during the mask unification process. This underscores the need for further refinement to distinguish closely adjacent floes that lack clear discontinuity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">The refinement of SAM’s segmentation is achieved through a subsequent phase using the GVF model. In this process, the binary mask used to find the seeds for generating the initial contours is the final output of SAM’s prompt-based mode (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>b). As a result, most floes are already detected and require no further processing, represented by feature pixel regions pinpointed by only one seed (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>c). Excluding these floes (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>f) from the GVF processing reduces computational time and focuses the initial contour placement on the floes SAM did not segment correctly, represented by withe regions with multiple seeds (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>d,e).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Some of the interconnected objects are linked by only a few pixels and can be separated through morphological erosion, which smooths the edges and isolates the objects. The contours of the newly emerged objects (identifiable as white islands pinpointed by one seed after the erosion) serve as the initial contours for the GVF snake model (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>d). These objects represent the ice floes that SAM partially segments, capturing their general shapes but not fully separating them. By using their contours, the shape characteristics of the floes are preserved, enabling the snake model to expand the contours to the true boundaries of each floe.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">The remaining unprocessed objects, which share a significant portion of their edges with neighboring objects, cannot be effectively separated using morphological erosion. For these cases, circles are used as initial contours around the seeds – a common approach for approximating ice floes in the marginal ice zone. The radius of each circle is determined by leveraging the distance transform matrix to ensure the contour stays within the object while remaining close to its edge (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>e). Once all seeds are associated with an initial contour, the GVF snake algorithm is applied to expand these contours and accurately trace the true boundaries of each object (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>g-h).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">The advantage of applying the GVF snake algorithm is its ability to capture the shape of ice floes in densely packed environments where SAM struggles to define boundaries. However, even the combined SAM and GVF approach may introduce anomalies and inaccuracies not present in the original image. As with the standalone GVF application, spurious features such as nearly-perfect circles or elongated line segments are removed using circularity and eccentricity coefficients (see §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS1" title="4.1 Active contours model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.1</span></a> for details). The final output, combining results from all phases, is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.F9" title="Figure 9 ‣ 4.3 A combination of SAM and GVF Snake algorithms ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">9</span></a>i, from which floe properties are extracted using boundary tracing algorithms.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Validation of methods for sea ice analysis</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Creation of benchmark segmentation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In the field of image segmentation, establishing a ground truth dataset is essential as it provides the benchmark for evaluating the performance of automated segmentation algorithms. A ground truth dataset consists of images that have been manually annotated by experts to offer the most accurate and reliable segmentation of objects. These manually segmented results represent the true or correct outputs that automated methods aim to replicate.
Such a reference is particularly important in complex environments, such as the Southern Ocean, where segmentation algorithms face challenges due to variable lighting, textures, and scene composition. Without a ground truth as a baseline, it would be difficult, if not impossible, to objectively determine how well these detection algorithms perform.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">A robust ground truth was created by manually segmenting a subset of 20 images from the original dataset (refer to §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S2" title="2 Image acquisition ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">2</span></a>) that capture diverse visual conditions in the Southern Ocean. These images reflect varying levels of sea ice clarity, deviating from idealized conditions like clear ice boundaries and consistent contrast. The manual segmentation, conducted using Pixelmator on MacOS but compatible with any photo editing software, involved meticulously outlining ice floes to create high-fidelity reference data. This diversity ensures the dataset is representative of the environmental variability. However, it is important to acknowledge that manual segmentation inherently involves some subjectivity, arising not only from individual interpretation but also from the ambiguous definition of what constitutes an ice floe. To mitigate this subjectivity and enhance the benchmark’s robustness, increasing the number of images in the dataset is a practical approach.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">The segmented images enable the extraction and analysis of key floe parameters, such as size and concentration. This dataset provides a critical benchmark for accurately evaluating automated detection methods, revealing their strengths and identifying areas for improvement. Without this comparison, the accuracy and reliability of algorithm performance would be uncertain, potentially compromising the validity of quantitative analyses from these image segmentation methods.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Comparison of floe properties: automated vs. manual segmentation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The automated segmentation methods – GVF, SAM, and the combined SAM-GVF – were applied to the same subset of 20 benchmark images. For each image, key floe properties, such as the number of detected floes, concentration, and size distribution, were extracted. These overall statistics were then compared to those derived from the manual segmentation to assess the accuracy and reliability of each method.
The floes parameters comparison is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>. The upper panel (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>a-b) displays the number of detected floes and ice concentration, with all values normalized to the manual benchmark. Each black line segment extending from the circles to the horizontal line (representing the manual benchmark at 1) shows how far each method’s results deviate from the benchmark. Shorter lines indicate closer agreement with the manual segmentation.
The middle panel (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>c) shows the floe size distribution based on diameter, with the manual segmentation on the left side as a benchmark for visual comparison.
The lower panel (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>d-g) presents QQ (Quantile-Quantile) plots, comparing the probability density functions (PDFs) of floe diameters at 10% intervals from 10% to 90%. A QQ plot is a graphical tool used to assess whether two datasets follow the same distribution by plotting their quantiles against each other. In these plots, the solid line represents the 1:1 line of equality, where points would align if the automated segmentation results matched the manual benchmark. The closer the data points are to this line, the more similar the automated segmentation is to the manual reference.</p>
</div>
<figure class="ltx_figure" id="S5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="757" id="S5.F10.g1" src="x10.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Comparison of floe size statistics obtained through segmentation with GVF (green), SAM automatic (red) and prompt-based (pink) mode, and the combined SAM-GVF (purple) against the manual benchmark (orange) segmentation: (a) number of detected floes for each method, normalized by the corresponding parameter from manual segmentation (horizontal line); (b) ice concentration for each method, normalized by the corresponding parameter from manual segmentation (horizontal line); (c) floe size distribution illustrated as violin plots for all methods, with the manual size distribution shown on the left. Medians and quartiles are represented respectively by squares inside the violins and darker shaded areas; (d-g) QQ plots comparing the quantiles (10% to 90%) of ice floe size distributions derived from the segmentation methods against the benchmark. The solid line indicates the alignment between the method and benchmark quantiles.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>a shows that the number of floes detected by the automated methods varies when compared to the manual benchmark. GVF and SAM in automatic mode tend to underestimate the number of floes, with values of 0.78 and 0.75, respectively, while SAM in prompt mode tends to overestimate, with a value of 1.05. Despite these discrepancies, the error for this statistic generally stays within 25% of the actual number of floes in the images. The underestimation in both GVF and SAM automatic modes reflects the difficulty these methods face in detecting floes in complex scenarios, such as obscure or irregular ice formations.
In SAM’s automatic mode, a fixed number of points are internally selected for initializing the segmentation, which causes the model to prioritize larger, more distinctly detectable floes. As a result, smaller floes or those in more uncertain areas of the image may be overlooked, reducing the total number of segmented floes.
On the other hand, the overestimation in SAM prompt mode is due to the model’s tendency to hallucinate, i.e. to generate false contours that resemble floes but do not correspond to any real object in the image. This is particularly common in images with heterogeneous ice gradients or low contrast between ice and water. These false detections are not corrected by the mask consolidation process or by the shape-based filtering described in §<a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S4.SS2.SSS2" title="4.2.2 Prompt-based ‣ 4.2 Segment Anything Model ‣ 4 Image segmentation ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>. The combined GVF-SAM algorithm addresses both underestimation and overestimation issues, resulting in a more accurate floe count, with only a slight underestimation (0.93) of the actual number of floes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>b compares sea ice concentration, showing that the SAM-based methods, regardless of the mode, closely match the manual benchmark, with values of 1.02 for the automatic mode and 1.03 for the prompt-based mode.
Interestingly, although SAM in automatic mode may struggle to separate adjacent floes with poorly defined edges or overlapping floes – affecting the floe count – it excels at distinguishing between ice and water, leading to high accuracy in estimating the overall sea ice fraction.
The combined SAM-GVF method (0.92) has an error range of about 10%, introducing slightly more uncertainty than SAM alone. However, it still outperforms the GVF method (0.73), which tends to under-detect floes or produce contours smaller than the actual floe boundaries, especially when the gradient across the ice floes is not uniform. This limitation causes GVF to underestimate ice concentration, highlighting the benefit of combining it with SAM.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>c illustrates the floe size distribution using violin plots, which combine elements of box plots and probability density functions. Violin plots show the distribution of data, including the density of values at different points, and provide information on the median (squares inside the violins) and the first and third quartiles (darker shaded areas). In the benchmark, the size distribution is bimodal, with peaks around 2 meters and 4 meters in floe diameter. Fifty percent of the floe sizes fall between 2 and 4.3 meters, with a median of 3 meters.
Both the GVF and SAM-GVF methods capture the overall shape of the distribution, including the median and quartiles. The median is slightly overestimated (3.2 meters for GVF and 3.1 meters for SAM-GVF), but the quartiles match the benchmark. Minor discrepancies arise due to the lower detection of smaller floes, preventing accurate capture of the peak at smaller sizes.
The SAM distribution varies significantly depending on the mode used. The prompt-based SAM approach closely aligns with the benchmark in terms of median (3 meters) and quartiles, though Q1 is underestimated at 1.6 meters. While the bimodality is captured, there is a skew towards smaller floes (around 1 meter), exaggerating the distribution’s shape compared to the benchmark. The automatic SAM mode, on the other hand, produces the least accurate distribution. Its median is overestimated at 3.8 meters, and the distribution appears unimodal (peaking around 3.5 meters), failing to reflect the bimodal nature of the benchmark. Quartiles are also poorly represented, highlighting the limitations of the automated SAM approach in accurately detecting individual floes without seed-based prompts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>d-g present QQ plots, which compare the quantiles of the PDF of the automated methods against the benchmark. The 1:1 line in the plots represents perfect agreement between the two distributions; points lying on this line indicate that the automated method’s distribution matches the benchmark exactly. Deviations from this line highlight differences between the distributions, helping to identify where the automated methods deviate from the manual segmentation.
In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>d, the GVF method shows reasonable agreement with the benchmark, particularly for floe sizes between 2 and 6 meters, where most floes are concentrated. Beyond the lower tails, the data points are fairly close to the 1:1 line, indicating a good match with the benchmark for larger floes. However, in the first 30% of the distribution (corresponding to smaller floes), the data points deviate from the benchmark, suggesting that GVF struggles to accurately detect smaller floes. The root mean square error (RMSE) for this method is 0.14 meters.
In contrast, SAM in automatic mode (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>e) exhibits a more significant difference from the benchmark, as already observed in the previous panel. For this method, the first 50% of floes range between 0 and 3.8 meters, whereas the benchmark ranges from 0 to 3 meters. The quantiles do not follow the 1:1 line, reflecting the deviation in the distribution and the unimodality of SAM automatic mode compared to the bimodality of the benchmark. The RMSE for SAM automatic mode is 0.85 meters.
Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.06641v2#S5.F10" title="Figure 10 ‣ 5.2 Comparison of floe properties: automated vs. manual segmentation ‣ 5 Validation of methods for sea ice analysis ‣ Segmenting sea ice floes in close-range optical imagery with active contour and foundation models"><span class="ltx_text ltx_ref_tag">10</span></a>f,g display the QQ plots for SAM prompt mode and SAM-GVF, respectively, both of which show similar distributions. The 10% quantile for both methods is around 0.6 meters, compared to 1 meter for the benchmark. This suggests that both methods detect a large number of very small floes not present in the original image, likely corresponding to noise or spurious features that were not filtered out. The 20% and 30% quantiles in SAM prompt mode indicate that the peak towards smaller floes is more pronounced than in the benchmark. Despite this, the rest of the distribution aligns well with the benchmark for both SAM prompt mode and SAM-GVF.
The RMSE for SAM-GVF is around 0.13 meters, similar to GVF, whereas the RMSE for SAM prompt mode is 0.25 meters. These values represent the average deviation in the size of floes extracted by the automated methods compared to the manual benchmark. It is important to note that the pixel-to-meter conversion during orthorectification was set to 0.05 meters, meaning the RMSE values for these methods are only 3 to 5 times the smallest measurable unit in the images.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The most challenging task in analyzing sea-ice images of the Antarctic marginal ice zone (MIZ) is identifying individual ice floes, especially when boundaries are poorly defined due to variable ice and lighting conditions. In this study, local-scale ice images acquired from the icebreaker S.A. Agulhas II were segmented following three different approaches: the traditional GVF snake method, the modern deep learning technique SAM by Meta, and a hybrid approach combining SAM and GVF.
To optimize the images for segmentation analysis, an automated image pre-processing pipeline was developed, which includes orthorectification to correct image distortions and enable pixel-to-meter conversion, as well as image quality enhancement.
From the original dataset, 20 images representing the MIZ under varying lighting, weather, and ice conditions were selected and manually segmented to create a benchmark for comparing the performance of the different methods. Quantitative differences in floe size, ice concentration, and the number of correctly identified floes were evaluated against this benchmark.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The analysis reveals that the GVF method is not the most accurate among the tested segmentation approaches when considering the resulting ice concentration and number of floes detected. However, the floe size distribution obtained fairly matches the benchmark.
Combining GVF with SAM allows to improve the ice concentration estimates and floe detection, while maintaining accuracy in the size distribution. SAM-GVF produces the floe size distribution most closely aligned with the benchmark, with the lowest RMSE.
The segmentation through SAM automatic mode identifies the lowest number of floes in the image and leads to the least accurate size distribution. Despite this, it outperforms the other approaches when considering the resulting sea ice concentration. For this parameter a similar result is obtained when using prompt-based SAM. This mode also improves floe detection and captures the bimodality of the benchmark size distribution more clearly than the other methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Declaring one method as superior to another in absolute terms is not possible, as the choice depends on the specific use case. SAM in prompt mode and the hybrid SAM-GVF approach emerged as the most effective overall. Prompt-based SAM, with its faster computational speed and strong performance in estimating ice concentration and detecting floes, is better suited for real-time applications where immediacy is critical.
In contrast, the hybrid SAM-GVF approach, along with GVF alone, proved more effective at capturing the floe size distribution. However, their longer computational time makes them more suitable for post-processing and further data refinement.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">The growing reliability and applicability of these automated segmentation methods, coupled with rapid advancements in AI, will increasingly enable long-term and real-time observation of sea ice dynamics, revolutionizing our ability to monitor and predict changes in the critical polar regions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herman et al. [2021]</span>
<span class="ltx_bibblock">
Agnieszka Herman, Marta Wenta, and Sukun Cheng.

</span>
<span class="ltx_bibblock">Sizes and shapes of sea ice floes broken by waves–a case study from the east antarctic coast.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Frontiers in Earth Science</em>, 9, May 2021.

</span>
<span class="ltx_bibblock">ISSN 2296-6463.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.3389/feart.2021.655977" title="">10.3389/feart.2021.655977</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dolatshah et al. [2018]</span>
<span class="ltx_bibblock">
A. Dolatshah, F. Nelli, L. G. Bennetts, A. Alberello, M. H. Meylan, J. P. Monty, and A. Toffoli.

</span>
<span class="ltx_bibblock">Letter: Hydroelastic interactions between water waves and floating freshwater ice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Physics of Fluids</em>, 30(9), September 2018.

</span>
<span class="ltx_bibblock">ISSN 1089-7666.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1063/1.5050262" title="">10.1063/1.5050262</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Montiel et al. [2016]</span>
<span class="ltx_bibblock">
Fabien Montiel, V. A. Squire, and L. G. Bennetts.

</span>
<span class="ltx_bibblock">Attenuation and directional spreading of ocean wave spectra in the marginal ice zone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of Fluid Mechanics</em>, 790:492–522, February 2016.

</span>
<span class="ltx_bibblock">ISSN 1469-7645.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1017/jfm.2016.21" title="">10.1017/jfm.2016.21</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meylan et al. [2021]</span>
<span class="ltx_bibblock">
Michael H. Meylan, Christopher Horvat, Cecilia M. Bitz, and Luke G. Bennetts.

</span>
<span class="ltx_bibblock">A floe size dependent scattering model in two- and three-dimensions for wave attenuation by ice floes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Ocean Modelling</em>, 161:101779, May 2021.

</span>
<span class="ltx_bibblock">ISSN 1463-5003.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.ocemod.2021.101779" title="">10.1016/j.ocemod.2021.101779</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Passerotti et al. [2022]</span>
<span class="ltx_bibblock">
Giulio Passerotti, Luke G. Bennetts, Franz von Bock und Polach, Alberto Alberello, Otto Puolakka, Azam Dolatshah, Jaak Monbaliu, and Alessandro Toffoli.

</span>
<span class="ltx_bibblock">Interactions between irregular wave fields and sea ice: A physical model for wave attenuation and ice breakup in an ice tank.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Journal of Physical Oceanography</em>, 52(7):1431–1446, July 2022.

</span>
<span class="ltx_bibblock">ISSN 1520-0485.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1175/jpo-d-21-0238.1" title="">10.1175/jpo-d-21-0238.1</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horvat et al. [2016]</span>
<span class="ltx_bibblock">
Christopher Horvat, Eli Tziperman, and Jean-Michel Campin.

</span>
<span class="ltx_bibblock">Interaction of sea ice floe size, ocean eddies, and sea ice melting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Geophysical Research Letters</em>, 43(15):8083–8090, August 2016.

</span>
<span class="ltx_bibblock">ISSN 1944-8007.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1002/2016gl069742" title="">10.1002/2016gl069742</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsamados et al. [2014]</span>
<span class="ltx_bibblock">
Michel Tsamados, Daniel L. Feltham, David Schroeder, Daniela Flocco, Sinead L. Farrell, Nathan Kurtz, Seymour W. Laxon, and Sheldon Bacon.

</span>
<span class="ltx_bibblock">Impact of variable atmospheric and oceanic form drag on simulations of arctic sea ice*.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Journal of Physical Oceanography</em>, 44(5):1329–1353, April 2014.

</span>
<span class="ltx_bibblock">ISSN 1520-0485.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1175/jpo-d-13-0215.1" title="">10.1175/jpo-d-13-0215.1</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lüpkes et al. [2012]</span>
<span class="ltx_bibblock">
Christof Lüpkes, Vladimir M. Gryanik, Jörg Hartmann, and Edgar L. Andreas.

</span>
<span class="ltx_bibblock">A parametrization, based on sea ice morphology, of the neutral atmospheric drag coefficients for weather prediction and climate models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Journal of Geophysical Research: Atmospheres</em>, 117(D13), July 2012.

</span>
<span class="ltx_bibblock">ISSN 0148-0227.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1029/2012jd017630" title="">10.1029/2012jd017630</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feltham [2005]</span>
<span class="ltx_bibblock">
Daniel L Feltham.

</span>
<span class="ltx_bibblock">Granular flow in the marginal ice zone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, 363(1832):1677–1700, July 2005.

</span>
<span class="ltx_bibblock">ISSN 1471-2962.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1098/rsta.2005.1601" title="">10.1098/rsta.2005.1601</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">WORBY [2004]</span>
<span class="ltx_bibblock">
A WORBY.

</span>
<span class="ltx_bibblock">Studies of the antarctic sea ice edge and ice extent from satellite and ship observations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Remote Sensing of Environment</em>, 92(1):98–111, July 2004.

</span>
<span class="ltx_bibblock">ISSN 0034-4257.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.rse.2004.05.007" title="">10.1016/j.rse.2004.05.007</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hepworth et al. [2020]</span>
<span class="ltx_bibblock">
Ehlke Hepworth, Marcello Vichi, Armand van Zuydam, Nicole Catherine Taylor, Jesslyn Bossau, Martinique Engelbrecht, and Tor Aarskog.

</span>
<span class="ltx_bibblock">Sea ice observations in the antarctic marginal ice zone during winter 2019, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sandru et al. [2020]</span>
<span class="ltx_bibblock">
Andrei Sandru, Heikki Hyyti, Arto Visala, and Pentti Kujala.

</span>
<span class="ltx_bibblock">A complete process for shipborne sea-ice field analysis using machine vision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IFAC-PapersOnLine</em>, 53(2):14539–14545, 2020.

</span>
<span class="ltx_bibblock">ISSN 2405-8963.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.ifacol.2020.12.1458" title="">10.1016/j.ifacol.2020.12.1458</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Skjetne [2015]</span>
<span class="ltx_bibblock">
Qin Zhang and Roger Skjetne.

</span>
<span class="ltx_bibblock">Image processing for identification of sea-ice floes and the floe size distributions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">IEEE Transactions on Geoscience and Remote Sensing</em>, 53(5):2913–2924, May 2015.

</span>
<span class="ltx_bibblock">ISSN 1558-0644.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/tgrs.2014.2366640" title="">10.1109/tgrs.2014.2366640</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alberello et al. [2019]</span>
<span class="ltx_bibblock">
Alberto Alberello, Miguel Onorato, Luke Bennetts, Marcello Vichi, Clare Eayrs, Keith MacHutchon, and Alessandro Toffoli.

</span>
<span class="ltx_bibblock">Brief communication: Pancake ice floe size distribution during the winter expansion of the antarctic marginal ice zone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">The Cryosphere</em>, 13(1):41–48, January 2019.

</span>
<span class="ltx_bibblock">ISSN 1994-0424.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.5194/tc-13-41-2019" title="">10.5194/tc-13-41-2019</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmiggiani et al. [2018]</span>
<span class="ltx_bibblock">
F. Parmiggiani, M. Moctezuma-Flores, P. Wadhams, and G. Aulicino.

</span>
<span class="ltx_bibblock">Image processing for pancake ice detection and size distribution computation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">International Journal of Remote Sensing</em>, 40(9):3368–3383, November 2018.

</span>
<span class="ltx_bibblock">ISSN 1366-5901.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1080/01431161.2018.1541367" title="">10.1080/01431161.2018.1541367</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weissling et al. [2009]</span>
<span class="ltx_bibblock">
B. Weissling, S. Ackley, P. Wagner, and H. Xie.

</span>
<span class="ltx_bibblock">Eiscam — digital image acquisition and processing for sea ice parameters from ships.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Cold Regions Science and Technology</em>, 57(1):49–60, June 2009.

</span>
<span class="ltx_bibblock">ISSN 0165-232X.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.coldregions.2009.01.001" title="">10.1016/j.coldregions.2009.01.001</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alsharay et al. [2022]</span>
<span class="ltx_bibblock">
Nahed M. Alsharay, Yuanzhu Chen, Octavia A. Dobre, and Oscar De Silva.

</span>
<span class="ltx_bibblock">Improved sea-ice identification using semantic segmentation with raindrop removal.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">IEEE Access</em>, 10:21599–21607, 2022.

</span>
<span class="ltx_bibblock">ISSN 2169-3536.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/access.2022.3150969" title="">10.1109/access.2022.3150969</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2016]</span>
<span class="ltx_bibblock">
Wenjun Lu, Qin Zhang, Raed Lubbad, Sveinung Løset, and Roger Skjetne.

</span>
<span class="ltx_bibblock">A shipborne measurement system to acquire sea ice thickness and concentration at engineering scale.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">All Days</em>, 16OARC. OTC, October 2016.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.4043/27361-ms" title="">10.4043/27361-ms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heyn et al. [2017]</span>
<span class="ltx_bibblock">
Hans-Martin Heyn, Martin Knoche, Qin Zhang, and Roger Skjetne.

</span>
<span class="ltx_bibblock">A system for automated vision-based sea-ice concentration detection and floe-size distribution indication from an icebreaker.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Volume 8: Polar and Arctic Sciences and Technology; Petroleum Technology</em>, OMAE2017. American Society of Mechanical Engineers, June 2017.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1115/omae2017-61822" title="">10.1115/omae2017-61822</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2008]</span>
<span class="ltx_bibblock">
P. Lu, Z. J. Li, Z. H. Zhang, and X. L. Dong.

</span>
<span class="ltx_bibblock">Aerial observations of floe size distribution in the marginal ice zone of summer prydz bay.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Journal of Geophysical Research: Oceans</em>, 113(C2), February 2008.

</span>
<span class="ltx_bibblock">ISSN 0148-0227.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1029/2006jc003965" title="">10.1029/2006jc003965</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dumas-Lefebvre and Dumont [2023]</span>
<span class="ltx_bibblock">
Elie Dumas-Lefebvre and Dany Dumont.

</span>
<span class="ltx_bibblock">Aerial observations of sea ice breakup by ship waves.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">The Cryosphere</em>, 17(2):827–842, February 2023.

</span>
<span class="ltx_bibblock">ISSN 1994-0424.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.5194/tc-17-827-2023" title="">10.5194/tc-17-827-2023</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022]</span>
<span class="ltx_bibblock">
Chengqian Zhang, Xiaodong Chen, and Shunying Ji.

</span>
<span class="ltx_bibblock">Semantic image segmentation for sea ice parameters recognition using deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Journal of Applied Earth Observation and Geoinformation</em>, 112:102885, August 2022.

</span>
<span class="ltx_bibblock">ISSN 1569-8432.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.jag.2022.102885" title="">10.1016/j.jag.2022.102885</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panchi et al. [2021]</span>
<span class="ltx_bibblock">
Nabil Panchi, Ekaterina Kim, and Anirban Bhattacharyya.

</span>
<span class="ltx_bibblock">Supplementing remote sensing of ice: Deep learning-based image segmentation system for automatic detection and localization of sea-ice formations from close-range optical images.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE Sensors Journal</em>, 21(16):18004–18019, August 2021.

</span>
<span class="ltx_bibblock">ISSN 2379-9153.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/jsen.2021.3084556" title="">10.1109/jsen.2021.3084556</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dowden et al. [2021]</span>
<span class="ltx_bibblock">
Benjamin Dowden, Oscar De Silva, Weimin Huang, and Dan Oldford.

</span>
<span class="ltx_bibblock">Sea ice classification via deep neural network semantic segmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">IEEE Sensors Journal</em>, 21(10):11879–11888, May 2021.

</span>
<span class="ltx_bibblock">ISSN 2379-9153.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/jsen.2020.3031475" title="">10.1109/jsen.2020.3031475</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maška et al. [2023]</span>
<span class="ltx_bibblock">
Martin Maška, Vladimír Ulman, Pablo Delgado-Rodriguez, Estibaliz Gómez-de Mariscal, Tereza Nečasová, Fidel A. Guerrero Peña, Tsang Ing Ren, Elliot M. Meyerowitz, Tim Scherr, Katharina Löffler, Ralf Mikut, Tianqi Guo, Yin Wang, Jan P. Allebach, Rina Bao, Noor M. Al-Shakarji, Gani Rahmon, Imad Eddine Toubal, Kannappan Palaniappan, Filip Lux, Petr Matula, Ko Sugawara, Klas E. G. Magnusson, Layton Aho, Andrew R. Cohen, Assaf Arbelle, Tal Ben-Haim, Tammy Riklin Raviv, Fabian Isensee, Paul F. Jäger, Klaus H. Maier-Hein, Yanming Zhu, Cristina Ederra, Ainhoa Urbiola, Erik Meijering, Alexandre Cunha, Arrate Muñoz-Barrutia, Michal Kozubek, and Carlos Ortiz-de Solórzano.

</span>
<span class="ltx_bibblock">The cell tracking challenge: 10 years of objective benchmarking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Nature Methods</em>, 20(7):1010–1020, May 2023.

</span>
<span class="ltx_bibblock">ISSN 1548-7105.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41592-023-01879-y" title="">10.1038/s41592-023-01879-y</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al. [2020]</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raghu et al. [2021]</span>
<span class="ltx_bibblock">
Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang, and Alexey Dosovitskiy.

</span>
<span class="ltx_bibblock">Do vision transformers see like convolutional neural networks?, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirillov et al. [2023]</span>
<span class="ltx_bibblock">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, and Ross Girshick.

</span>
<span class="ltx_bibblock">Segment anything, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shankar et al. [2023]</span>
<span class="ltx_bibblock">
Siddharth Shankar, Leigh A. Stearns, and C. J. van der Veen.

</span>
<span class="ltx_bibblock">Semantic segmentation of glaciological features across multiple remote sensing platforms with the segment anything model (sam).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Journal of Glaciology</em>, pages 1–10, November 2023.

</span>
<span class="ltx_bibblock">ISSN 1727-5652.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1017/jog.2023.95" title="">10.1017/jog.2023.95</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma and Wang [2023]</span>
<span class="ltx_bibblock">
Jun Ma and Bo Wang.

</span>
<span class="ltx_bibblock">Towards foundation models of biological image segmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Nature Methods</em>, 20(7):953–955, July 2023.

</span>
<span class="ltx_bibblock">ISSN 1548-7105.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41592-023-01885-0" title="">10.1038/s41592-023-01885-0</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryan-Keogh and Vichi [2022]</span>
<span class="ltx_bibblock">
Thomas Ryan-Keogh and Marcello Vichi.

</span>
<span class="ltx_bibblock">Scale-win19 &amp; scale-spr19 cruise report, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tersigni et al. [2023]</span>
<span class="ltx_bibblock">
Ippolita Tersigni, Alberto Alberello, Gabriele Messori, Marcello Vichi, Miguel Onorato, and Alessandro Toffoli.

</span>
<span class="ltx_bibblock">High-resolution thermal imaging in the antarctic marginal ice zone: Skin temperature heterogeneity and effects on heat fluxes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Earth and Space Science</em>, 10(9), September 2023.

</span>
<span class="ltx_bibblock">ISSN 2333-5084.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1029/2023ea003078" title="">10.1029/2023ea003078</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartley and Zisserman [2004]</span>
<span class="ltx_bibblock">
Richard Hartley and Andrew Zisserman.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Multiple View Geometry in Computer Vision</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, March 2004.

</span>
<span class="ltx_bibblock">ISBN 9780511811685.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1017/cbo9780511811685" title="">10.1017/cbo9780511811685</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang [2000]</span>
<span class="ltx_bibblock">
Z. Zhang.

</span>
<span class="ltx_bibblock">A flexible new technique for camera calibration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 22(11):1330–1334, 2000.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/34.888718" title="">10.1109/34.888718</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sturm and Maybank [1999]</span>
<span class="ltx_bibblock">
P.F. Sturm and S.J. Maybank.

</span>
<span class="ltx_bibblock">On plane-based camera calibration: A general algorithm, singularities, applications.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)</em>, CVPR-99. IEEE Comput. Soc, 1999.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/cvpr.1999.786974" title="">10.1109/cvpr.1999.786974</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouguet [2004]</span>
<span class="ltx_bibblock">
Jean-Yves Bouguet.

</span>
<span class="ltx_bibblock">Camera calibration toolbox for matlab.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">http://www. vision. caltech. edu/bouguetj/calib_doc/</em>, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerum et al. [2019]</span>
<span class="ltx_bibblock">
Richard C. Gerum, Sebastian Richter, Alexander Winterl, Christoph Mark, Ben Fabry, Céline Le Bohec, and Daniel P. Zitterbart.

</span>
<span class="ltx_bibblock">Cameratransform: A python package for perspective corrections and image mapping.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">SoftwareX</em>, 10:100333, July 2019.

</span>
<span class="ltx_bibblock">ISSN 2352-7110.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.softx.2019.100333" title="">10.1016/j.softx.2019.100333</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alberello et al. [2022]</span>
<span class="ltx_bibblock">
Alberto Alberello, Luke G. Bennetts, Miguel Onorato, Marcello Vichi, Keith MacHutchon, Clare Eayrs, Butteur Ntamba Ntamba, Alvise Benetazzo, Filippo Bergamasco, Filippo Nelli, Rohinee Pattani, Hans Clarke, Ippolita Tersigni, and Alessandro Toffoli.

</span>
<span class="ltx_bibblock">Three-dimensional imaging of waves and floes in the marginal ice zone during a cyclone.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Nature Communications</em>, 13(1), August 2022.

</span>
<span class="ltx_bibblock">ISSN 2041-1723.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41467-022-32036-2" title="">10.1038/s41467-022-32036-2</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tomasi and Manduchi [1998]</span>
<span class="ltx_bibblock">
C. Tomasi and R. Manduchi.

</span>
<span class="ltx_bibblock">Bilateral filtering for gray and color images.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)</em>, ICCV-98. Narosa Publishing House, 1998.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/iccv.1998.710815" title="">10.1109/iccv.1998.710815</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perona and Malik [1990]</span>
<span class="ltx_bibblock">
P. Perona and J. Malik.

</span>
<span class="ltx_bibblock">Scale-space and edge detection using anisotropic diffusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 12(7):629–639, July 1990.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/34.56205" title="">10.1109/34.56205</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zuiderveld [1994]</span>
<span class="ltx_bibblock">
Karel Zuiderveld.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Contrast Limited Adaptive Histogram Equalization</em>, pages 474–485.

</span>
<span class="ltx_bibblock">Elsevier, 1994.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/b978-0-12-336156-1.50061-6" title="">10.1016/b978-0-12-336156-1.50061-6</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2011]</span>
<span class="ltx_bibblock">
Kaiming He, Jian Sun, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Single image haze removal using dark channel prior.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 33(12):2341–2353, December 2011.

</span>
<span class="ltx_bibblock">ISSN 2160-9292.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/tpami.2010.168" title="">10.1109/tpami.2010.168</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kass et al. [1988]</span>
<span class="ltx_bibblock">
Michael Kass, Andrew Witkin, and Demetri Terzopoulos.

</span>
<span class="ltx_bibblock">Snakes: Active contour models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">International Journal of Computer Vision</em>, 1(4):321–331, January 1988.

</span>
<span class="ltx_bibblock">ISSN 1573-1405.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1007/bf00133570" title="">10.1007/bf00133570</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Otsu [1979]</span>
<span class="ltx_bibblock">
Nobuyuki Otsu.

</span>
<span class="ltx_bibblock">A threshold selection method from gray-level histograms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IEEE Transactions on Systems, Man, and Cybernetics</em>, 9(1):62–66, January 1979.

</span>
<span class="ltx_bibblock">ISSN 2168-2909.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/tsmc.1979.4310076" title="">10.1109/tsmc.1979.4310076</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byun and Nam [2021]</span>
<span class="ltx_bibblock">
Seok-Ho Byun and Jong-Ho Nam.

</span>
<span class="ltx_bibblock">Estimation of pack ice concentration using histogram peak analysis and image subdivision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Cold Regions Science and Technology</em>, 181:103185, January 2021.

</span>
<span class="ltx_bibblock">ISSN 0165-232X.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.coldregions.2020.103185" title="">10.1016/j.coldregions.2020.103185</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paglieroni [1992]</span>
<span class="ltx_bibblock">
David W Paglieroni.

</span>
<span class="ltx_bibblock">Distance transforms: Properties and machine vision applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">CVGIP: Graphical Models and Image Processing</em>, 54(1):56–74, January 1992.

</span>
<span class="ltx_bibblock">ISSN 1049-9652.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/1049-9652(92)90034-u" title="">10.1016/1049-9652(92)90034-u</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maurer et al. [2003]</span>
<span class="ltx_bibblock">
C.R. Maurer, Rensheng Qi, and V. Raghavan.

</span>
<span class="ltx_bibblock">A linear time algorithm for computing exact euclidean distance transforms of binary images in arbitrary dimensions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 25(2):265–270, February 2003.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/tpami.2003.1177156" title="">10.1109/tpami.2003.1177156</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Prince [1998]</span>
<span class="ltx_bibblock">
Chenyang Xu and J.L. Prince.

</span>
<span class="ltx_bibblock">Snakes, shapes, and gradient vector flow.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">IEEE Transactions on Image Processing</em>, 7(3):359–369, March 1998.

</span>
<span class="ltx_bibblock">ISSN 1057-7149.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/83.661186" title="">10.1109/83.661186</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adams [1993]</span>
<span class="ltx_bibblock">
R. Adams.

</span>
<span class="ltx_bibblock">Radial decomposition of disks and spheres.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">CVGIP: Graphical Models and Image Processing</em>, 55(5):325–332, September 1993.

</span>
<span class="ltx_bibblock">ISSN 1049-9652.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1006/cgip.1993.1024" title="">10.1006/cgip.1993.1024</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mulchrone and Choudhury [2004]</span>
<span class="ltx_bibblock">
Kieran F. Mulchrone and Kingshuk Roy Choudhury.

</span>
<span class="ltx_bibblock">Fitting an ellipse to an arbitrary shape: implications for strain analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Journal of Structural Geology</em>, 26(1):143–153, January 2004.

</span>
<span class="ltx_bibblock">ISSN 0191-8141.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/s0191-8141(03)00093-2" title="">10.1016/s0191-8141(03)00093-2</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ayoub [2003]</span>
<span class="ltx_bibblock">
Ayoub B. Ayoub.

</span>
<span class="ltx_bibblock">The eccentricity of a conic section.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">The College Mathematics Journal</em>, 34(2):116–121, March 2003.

</span>
<span class="ltx_bibblock">ISSN 1931-1346.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1080/07468342.2003.11921994" title="">10.1080/07468342.2003.11921994</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bottema [2000]</span>
<span class="ltx_bibblock">
M.J. Bottema.

</span>
<span class="ltx_bibblock">Circularity of objects in images.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)</em>, ICASSP-00. IEEE, 2000.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/icassp.2000.859286" title="">10.1109/icassp.2000.859286</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biswas and Hazra [2018]</span>
<span class="ltx_bibblock">
Soumen Biswas and Ranjay Hazra.

</span>
<span class="ltx_bibblock">Robust edge detection based on modified moore-neighbor.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Optik</em>, 168:931–943, September 2018.

</span>
<span class="ltx_bibblock">ISSN 0030-4026.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.ijleo.2018.05.011" title="">10.1016/j.ijleo.2018.05.011</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ketkar and Moolayil [2021]</span>
<span class="ltx_bibblock">
Nikhil Ketkar and Jojo Moolayil.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Introduction to PyTorch</em>, pages 27–91.

</span>
<span class="ltx_bibblock">Apress, 2021.

</span>
<span class="ltx_bibblock">ISBN 9781484253649.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-1-4842-5364-9_2" title="">10.1007/978-1-4842-5364-9_2</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sklansky [1970]</span>
<span class="ltx_bibblock">
J. Sklansky.

</span>
<span class="ltx_bibblock">Recognition of convex blobs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Pattern Recognition</em>, 2(1):3–10, January 1970.

</span>
<span class="ltx_bibblock">ISSN 0031-3203.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/0031-3203(70)90037-3" title="">10.1016/0031-3203(70)90037-3</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2024]</span>
<span class="ltx_bibblock">
A. Wang, B. Wei, J. Sui, J. Wang, N. Xu, and G. Hao.

</span>
<span class="ltx_bibblock">Integrating a data-driven classifier and shape-modulated segmentation for sea-ice floe extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">International Journal of Applied Earth Observation and Geoinformation</em>, 128:103726, April 2024.

</span>
<span class="ltx_bibblock">ISSN 1569-8432.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.jag.2024.103726" title="">10.1016/j.jag.2024.103726</a>.

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="Giulio Passerotti, Alessandro Toffoli" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="sea ice, floe size distribution, image segmentation, active contour model, vision foundation model, segment anything model" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="physics.ao-ph" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="A template for the arxiv style" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 11 07:18:10 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
