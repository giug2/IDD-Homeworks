<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation</title>
<!--Generated on Tue Sep 24 17:43:30 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.16278v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S1" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S2" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S3" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Preliminary Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S4" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS1" title="In 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Training and Evaluation Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS2" title="In 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS3" title="In 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS4" title="In 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5" title="In 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Ablations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px1" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Effect of Fine-tuning Different Layers in CLIP.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px2" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Comparison with Other Efficient Fine-Tuning Methods.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px3" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Effect of Using Different Number of Layers in Distribution Adapter.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px4" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Importance of Semantic-guided Mask Attention (SMA) and Query Projection Tuning (QPT)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px5" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Effect of Fine-tuning Other Modules.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px6" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Scalability to Different VLM Backbones.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5.SSS0.Px7" title="In 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title">Preservation of CLIP’s Pre-trained Knowledge.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S6" title="In Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yong Xien Chng<sup class="ltx_sup" id="id8.7.id1"><span class="ltx_text ltx_font_italic" id="id8.7.id1.1">1,2</span></sup>,
Xuchong Qiu<sup class="ltx_sup" id="id9.8.id2"><span class="ltx_text ltx_font_italic" id="id9.8.id2.1">2,†</span></sup>,
Yizeng Han<sup class="ltx_sup" id="id10.9.id3">1</sup>,
Kai Ding<sup class="ltx_sup" id="id11.10.id4">2</sup>,
Wan Ding<sup class="ltx_sup" id="id12.11.id5">2</sup>,
Gao Huang<sup class="ltx_sup" id="id13.12.id6"><span class="ltx_text ltx_font_italic" id="id13.12.id6.1">1</span></sup><sup class="ltx_sup" id="id14.13.id7">🖂</sup>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.1">Open-vocabulary panoptic segmentation is an emerging task aiming to accurately segment the image into semantically meaningful masks based on a set of texts. Despite existing efforts, it remains challenging to develop a high-performing method that generalizes effectively across new domains and requires minimal training resources. Our in-depth analysis of current methods reveals a crucial insight: <span class="ltx_text ltx_font_italic" id="id7.1.2">mask classification is the main performance bottleneck for open-vocab. panoptic segmentation</span>. Based on this, we propose <span class="ltx_text ltx_framed ltx_framed_underline" id="id7.1.3">S</span>e<span class="ltx_text ltx_framed ltx_framed_underline" id="id7.1.4">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="id7.1.5">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="id7.1.6">T</span>uning (SMART), a novel framework that greatly enhances open-vocab. panoptic segmentation by improving mask classification through two key innovations. First, SMART adopts a multimodal Semantic-guided Mask Attention mechanism that injects task-awareness into the regional information extraction process. This enables the model to capture task-specific and contextually relevant information for more effective mask classification. Second, it incorporates Query Projection Tuning, which strategically fine-tunes the <span class="ltx_text ltx_font_italic" id="id7.1.7">query projection layers</span> within the Vision Language Model (VLM) used for mask classification. This adjustment allows the model to adapt the image focus of mask tokens to new distributions with minimal training resources, while preserving the VLM’s pre-trained knowledge. Extensive ablation studies confirm the superiority of our approach. Notably, SMART sets new state-of-the-art results, demonstrating improvements of up to +<span class="ltx_text ltx_font_bold" id="id7.1.8">1.3</span> PQ and +<span class="ltx_text ltx_font_bold" id="id7.1.9">5.4</span> mIoU across representative benchmarks, while reducing training costs by nearly <span class="ltx_text ltx_font_bold" id="id7.1.1">10<math alttext="\boldsymbol{\times}" class="ltx_Math" display="inline" id="id7.1.1.m1.1"><semantics id="id7.1.1.m1.1a"><mo class="ltx_mathvariant_bold" id="id7.1.1.m1.1.1" mathvariant="bold" xref="id7.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id7.1.1.m1.1b"><times id="id7.1.1.m1.1.1.cmml" xref="id7.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id7.1.1.m1.1c">\boldsymbol{\times}</annotation><annotation encoding="application/x-llamapun" id="id7.1.1.m1.1d">bold_×</annotation></semantics></math></span> compared to the previous best method. Our code and data will be released.</p>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Y. X. Chng is an intern at Bosch Corporate Research.</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex2"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span><math alttext="\dagger" class="ltx_Math" display="inline" id="footnotex2.m1.1"><semantics id="footnotex2.m1.1b"><mo id="footnotex2.m1.1.1" xref="footnotex2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="footnotex2.m1.1c"><ci id="footnotex2.m1.1.1.cmml" xref="footnotex2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="footnotex2.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="footnotex2.m1.1e">†</annotation></semantics></math> Project lead.</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex3"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span><sup class="ltx_sup" id="footnotex3.1">🖂</sup>Corresponding author.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Open-vocabulary panoptic segmentation <cite class="ltx_cite ltx_citemacro_citep">(Kirillov et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib23" title="">2019</a>; Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib6" title="">2020</a>)</cite> combines semantic segmentation <cite class="ltx_cite ltx_citemacro_citep">(Chen et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib5" title="">2017</a>; Long, Shelhamer, and Darrell <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib31" title="">2015</a>)</cite> of unseen background elements with instance segmentation <cite class="ltx_cite ltx_citemacro_citep">(He et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib18" title="">2017</a>)</cite> of unseen foreground objects. Its application has profound implications for enhancing scene comprehension in domains like autonomous driving <cite class="ltx_cite ltx_citemacro_citep">(Codevilla et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib11" title="">2019</a>; Toromanoff, Wirbel, and Moutarde <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib41" title="">2020</a>)</cite> and robotics <cite class="ltx_cite ltx_citemacro_citep">(Pate et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib35" title="">2021</a>; Ahn et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib1" title="">2018</a>)</cite>, leading to widespread research interest. Despite considerable progress, existing methods still show limited real-world performance and require substantial computational resources for training, often taking up to a week to complete. <cite class="ltx_cite ltx_citemacro_citep">(Wu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib42" title="">2024</a>; Zhu and Chen <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib53" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="659" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>a) Comparison between one-stage and two-stage open-vocab. panoptic segmentation methods. b) Our proposed Semantic Refocused Tuning enhances performance for this task by refining mask classification through two key innovations. Specifically, it employs a novel Semantic-guided Mask Attention mechanism to improve task-relevant regional information extraction and utilizes Query Projection Tuning to enable the VLM to adapt to new distributions while preserving its original pre-trained knowledge.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Current open-vocabulary panoptic segmentation methods primarily leverage Vision-Language Models (VLMs) <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>; Cherti et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib8" title="">2023</a>; Sun et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib40" title="">2023</a>)</cite> with robust zero-shot abilities <cite class="ltx_cite ltx_citemacro_citep">(Xian et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib43" title="">2018</a>)</cite>. However, since VLMs generally lack training on specific image regions, adaptations are necessary for effective usage in dense segmentation task that requires precise image part categorization. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>, these adaptations manifest in two primary methodologies: one-stage <cite class="ltx_cite ltx_citemacro_citep">(Yu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib49" title="">2023</a>; Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib45" title="">2023a</a>)</cite> and two-stage <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>; Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib48" title="">2023c</a>)</cite> approaches. One-stage methods utilize VLM features to concurrently generate masks and perform classification, leading to improved performance through better task synergy. However, these methods often require extended training time to reconcile the gap between image-level and mask-level classification, posing challenges for many practical applications. In contrast, two-stage methods first generate class-agnostic mask proposals, then classify them. While improving training efficiency by decoupling the learning process, they often exhibit inferior performance due to suboptimal synergy between mask generation and classification.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This naturally leads to the question: Can we combine the strengths of both approaches, achieving the <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">high performance of one-stage methods</span> while maintaining the <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">training efficiency of two-stage methods</span> in a unified manner?</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Due to its high modularity and fast training speed, the representative MaskCLIP <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite> model serves as a good starting point for our research. By carefully analysing this model, we uncover a critical insight that guides our development of a high-performing method that also trains efficiently. As detailed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S3" title="3 Preliminary Analysis ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>, this analysis show that <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">mask classification is the main performance bottleneck for open-vocabulary panoptic segmentation</span>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Based on this insight, we propose <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p5.1.1">S</span>e<span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p5.1.2">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p5.1.3">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p5.1.4">T</span>uning, a novel framework designed to enhance open-vocab. panoptic segmentation by improving mask classification through two key innovations. First, SMART introduces a multimodal Semantic-guided Mask Attention (SMA) mechanism that infuses task awareness into the regional information extraction process. This mechanism begins by cross-attending mask tokens with target class tokens, thereby conditioning the mask tokens on all relevant task information. It then cross-attends the mask tokens with image tokens to extract task-specific and contextually relevant details, leading to more effective mask classification. Second, we propose a highly targeted fine-tuning method called Query Projection Tuning. This approach strategically fine-tunes only the <span class="ltx_text ltx_font_italic" id="S1.p5.1.5">query projection layers</span> within the VLM used for mask classification. By focusing solely on adjusting the image focus of mask tokens while keeping all other layers fixed, this method enables the VLM to efficiently adapt to new distributions with minimal disruption to its pre-trained knowledge.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Comprehensive experiments and ablations confirm the superiority of our method. Notably, SMART achieves new state-of-the-art results across multiple key benchmarks, while reducing training costs by nearly <span class="ltx_text ltx_font_bold" id="S1.p6.1.1">10<math alttext="\boldsymbol{\times}" class="ltx_Math" display="inline" id="S1.p6.1.1.m1.1"><semantics id="S1.p6.1.1.m1.1a"><mo class="ltx_mathvariant_bold" id="S1.p6.1.1.m1.1.1" mathvariant="bold" xref="S1.p6.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p6.1.1.m1.1b"><times id="S1.p6.1.1.m1.1.1.cmml" xref="S1.p6.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.1.m1.1c">\boldsymbol{\times}</annotation><annotation encoding="application/x-llamapun" id="S1.p6.1.1.m1.1d">bold_×</annotation></semantics></math></span> compared to the previous best method, FC-CLIP <cite class="ltx_cite ltx_citemacro_citep">(Yu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib49" title="">2023</a>)</cite>. Specifically, SMART outperforms FC-CLIP by up to <span class="ltx_text ltx_font_bold" id="S1.p6.1.2">1.3</span> points in PQ and <span class="ltx_text ltx_font_bold" id="S1.p6.1.3">5.4</span> points in mIoU across multiple representative datasets. Our main contributions are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p7">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We carefully analyze existing open-vocabulary panoptic segmentation methodology, revealing that <span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.1">mask classification is the main performance bottleneck for open-vocabulary panoptic segmentation</span>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.I1.i2.p1.1.1">S</span>e<span class="ltx_text ltx_framed ltx_framed_underline" id="S1.I1.i2.p1.1.2">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.I1.i2.p1.1.3">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.I1.i2.p1.1.4">T</span>uning (SMART), a novel framework for open-vocabulary panoptic segmentation that incorporates two novel components: (i) Semantic-guided Mask Attention, which integrates task awareness into the regional information extraction process and (ii) Query Projection Tuning, which allows the VLM-based mask classifier to adapt efficiently to new distributions while retaining its pretrained knowledge.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Our novel method sets new state-of-the-art results across multiple representative datasets, while using nearly <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">10<math alttext="\boldsymbol{\times}" class="ltx_Math" display="inline" id="S1.I1.i3.p1.1.1.m1.1"><semantics id="S1.I1.i3.p1.1.1.m1.1a"><mo class="ltx_mathvariant_bold" id="S1.I1.i3.p1.1.1.m1.1.1" mathvariant="bold" xref="S1.I1.i3.p1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.1.1.m1.1b"><times id="S1.I1.i3.p1.1.1.m1.1.1.cmml" xref="S1.I1.i3.p1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.1.m1.1c">\boldsymbol{\times}</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i3.p1.1.1.m1.1d">bold_×</annotation></semantics></math></span> less training cost than previous best method. We extensively ablate our method to show its effectiveness.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Open-vocabulary panoptic segmentation</span> combines both semantic and instance segmentation of unseen classes. Current methods primarily adopt Vision-Language Models (VLM) such as CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>; Jia et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib21" title="">2021</a>; Sun et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib40" title="">2023</a>)</cite> that can perform zero-shot classification. Initially, most methods adopt a two-stage approach for its simplicity and training efficiency. The seminal MaskCLIP <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite> proposes a novel Relative Mask Attention mechanism to extract regional mask information. MasQCLIP <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib48" title="">2023c</a>)</cite> enhances MaskCLIP by using progressive distillation to improve mask generation and adding a query adapter to enhance model adaptation. However, recent methods have shifted towards one-stage approach, stemming from the belief that one-stage approach can enhance performance through improved synergy between mask classification and mask generation. In particular, ODISE <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib45" title="">2023a</a>)</cite> explores using frozen internal representations of Stable Diffusion <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib38" title="">2022</a>)</cite> for open-vocab. panoptic segmentation, whereas FC-CLIP <cite class="ltx_cite ltx_citemacro_citep">(Yu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib49" title="">2023</a>)</cite> explores using a CNN-based CLIP model that can efficiently provide feature map with much higher resolution. Our proposed method combines the best of one-stage and two-stage approach and can outperform previous state-of-the-art method with much less training resources.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Open-vocabulary semantic segmentation</span> aims to partition an image into semantic regions described by previously unseen text descriptions. LSeg <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib24" title="">2022a</a>)</cite> directly fine-tunes a CLIP model to learn dense image features. OpenSeg <cite class="ltx_cite ltx_citemacro_citep">(Ghiasi et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib16" title="">2022</a>)</cite>, ZSseg <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib47" title="">2022</a>)</cite>, and ZegFormer <cite class="ltx_cite ltx_citemacro_citep">(Ding et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib13" title="">2022</a>)</cite> all propose generating region proposals before using CLIP for final classification, but they differ in their implementation details. OVSeg <cite class="ltx_cite ltx_citemacro_citep">(Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib27" title="">2023</a>)</cite> collects mask-image pairs to improve CLIP’s performance on masked images. SAN <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib46" title="">2023b</a>)</cite> employs a side adapter network which leverages outputs from a frozen CLIP model to perform mask prediction and classification. CAT-Seg <cite class="ltx_cite ltx_citemacro_citep">(Cho et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib10" title="">2024</a>)</cite> proposes a novel cost-aggregation method to refine CLIP’s dense predictions. SED <cite class="ltx_cite ltx_citemacro_citep">(Xie et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib44" title="">2024</a>)</cite> further improves upon CAT-Seg by using a hierarchical CLIP model to generate hierarchical dense predictions. Our proposed method is more general and can perform both open-vocabulary semantic segmentation and open-vocabulary panoptic segmentation simultaneously.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Resource-efficient fine-tuning</span> techniques can significantly reduce the computational demands of deep learning models. Adapter-based methods <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib50" title="">2024</a>; Liu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib29" title="">2024</a>; Gao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib15" title="">2024</a>)</cite> introduce minimal trainable parameters at strategic locations within the model, whereas prompt tuning <cite class="ltx_cite ltx_citemacro_citep">(Jia et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib22" title="">2022</a>; Li and Liang <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib25" title="">2021</a>)</cite> injects these parameters into the input space. LoRA and its variants <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib20" title="">2022</a>; Dettmers et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib12" title="">2024</a>)</cite> avoid additional parameters by low-rank adapting only the linear layers. Alternatively, adapting the normalization layers <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib51" title="">2024</a>)</cite> or the network biases <cite class="ltx_cite ltx_citemacro_citep">(Cai et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib4" title="">2020</a>)</cite> are also very effective in minimizing learnable parameters. In contrast to previous methods that entirely freeze their CLIP-based mask classifiers, we explore fine-tuning a minimal subset of CLIP’s parameters for efficient adaptation to open-vocabulary panoptic segmentation.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminary Analysis</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we conduct a preliminary analysis of the representative two-stage MaskCLIP <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite> method to identify key components affecting performance in open-vocabulary panoptic segmentation. This process yields critical insights that shape our approach in developing a method that performs effectively and trains efficiently. We detail the results of our analysis as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">1) <span class="ltx_text ltx_font_bold" id="S3.p2.1.1">Between mask generator and mask classifier, which is the main performance bottleneck for open-vocab. panoptic segmentation?</span> To answer this question, we conduct an experiment comparing the effects of an ideal mask generator and an ideal mask classifier on performance. We replace the mask generator with an “oracle” that provides ground-truth masks and the mask classifier with an “oracle” that assigns ground-truth labels based on the highest overlap with the corresponding ground-truth masks. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S3.F2" title="Figure 2 ‣ 3 Preliminary Analysis ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a>(a) shows that MaskCLIP with the “oracle” classifier greatly outperforms MaskCLIP with the “oracle” mask generator, achieving an mIoU of 60.5 and a PQ of 44.6 on the ADE150 dataset. This huge improvement of 32.1 points in mIoU and 12.7 points in PQ demonstrates that, for training-efficient two-stage methods like MaskCLIP, <span class="ltx_text ltx_font_italic" id="S3.p2.1.2">mask classification is the main performance bottleneck for open-vocab. panoptic segmentation</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">2) <span class="ltx_text ltx_font_bold" id="S3.p3.1.1">Can we use a frozen pre-trained mask generator to improve training efficiency and focus on mask classification?</span> To explore this possibility, we replace the mask generator with a COCO pre-trained version from Mask2Former’s model zoo <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib7" title="">2022</a>)</cite>, keeping it frozen during training. As depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S3.F2" title="Figure 2 ‣ 3 Preliminary Analysis ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a>(b), the performance of the pre-trained mask generator matches that of a newly trained one. This suggests <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">it is possible to freeze the mask generator, allowing us to focus solely on mask classification and enhance training efficiency without degrading performance.</span></p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="465" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>a) MaskCLIP shows a much greater performance gain with a perfect “oracle” mask classifier than with a perfect “oracle” mask generator, highlighting <span class="ltx_text ltx_font_italic" id="S3.F2.2.1">mask classification as the main performance bottleneck for open-vocab. panoptic segmentation</span>. b) Using a pre-trained mask generator achieves performance comparable to re-training it from scratch, indicating that mask generator can be frozen to enhance training efficiency without performance degradation.</figcaption>
</figure>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">In summary, our analysis shows that <span class="ltx_text ltx_font_italic" id="S3.p4.1.1">mask classification is the main performance bottleneck for open-vocab. panoptic segmentation</span>. Based on this insight, we conduct further experiments to show that we can freeze the mask generator to increase training efficiency with minimal performance degradation. With these findings, we are now ready to present our proposed method.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="336" id="S3.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overview of <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.F3.9.1">S</span>e<span class="ltx_text ltx_framed ltx_framed_underline" id="S3.F3.10.2">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.F3.11.3">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.F3.12.4">T</span>uning (SMART). Guided by the insight that <span class="ltx_text ltx_font_italic" id="S3.F3.13.5">mask classification is the main performance bottleneck for open-vocabulary panoptic segmentation</span>, SMART freezes the mask generator and introduces two key innovations to improve mask classification. First, it introduces Semantic-guided Mask Attention, which injects task-awareness into regional information extraction by cross-attending mask tokens with target class tokens. Second, SMART fine-tunes only the <span class="ltx_text ltx_font_italic" id="S3.F3.14.6">query projection layer</span> <math alttext="f_{q}" class="ltx_Math" display="inline" id="S3.F3.2.m1.1"><semantics id="S3.F3.2.m1.1b"><msub id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml"><mi id="S3.F3.2.m1.1.1.2" xref="S3.F3.2.m1.1.1.2.cmml">f</mi><mi id="S3.F3.2.m1.1.1.3" xref="S3.F3.2.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><apply id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.2.m1.1.1.1.cmml" xref="S3.F3.2.m1.1.1">subscript</csymbol><ci id="S3.F3.2.m1.1.1.2.cmml" xref="S3.F3.2.m1.1.1.2">𝑓</ci><ci id="S3.F3.2.m1.1.1.3.cmml" xref="S3.F3.2.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">f_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.2.m1.1e">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> in CLIP, allowing for domain adaptation while preserving CLIP’s pre-trained knowledge.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we first describe the two-stage open-vocabulary panoptic segmentation framework, which our proposed Semantic Refocused Tuning is designed to improve. We then explain in detail the core components of our method, namely Semantic-guided Mask Attention and Query Projection Tuning. Finally, we present the overall loss function used to train our model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Two-stage open-vocabulary panoptic segmentation framework.</span> As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S3.F3" title="Figure 3 ‣ 3 Preliminary Analysis ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>, this framework sequentially generates and classifies mask proposals. Initially, a mask generator, which can be any conventional pre-trained segmentation network, produces mask proposals. Subsequently, a VLM capable of performing zero-shot classification is employed as a mask classifier. In this work, we use CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>)</cite> as the mask classifier. CLIP comprises an image encoder and a language encoder, extracting features from image tokens and language labels, respectively. Zero-shot classification is performed by calculating the cosine similarity between the image and label embeddings, then assigning the image to the category with the closest embedding. To adapt CLIP for regional classification in open-vocabulary panoptic segmentation, mask tokens are introduced for each mask proposal. These tokens can only attend to image tokens within their corresponding masked regions. They function similarly to the <math alttext="\mathtt{[CLS]}" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mrow id="S4.p2.1.m1.1.2.2" xref="S4.p2.1.m1.1.2.1.cmml"><mo id="S4.p2.1.m1.1.2.2.1" stretchy="false" xref="S4.p2.1.m1.1.2.1.1.cmml">[</mo><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">𝙲𝙻𝚂</mi><mo id="S4.p2.1.m1.1.2.2.2" stretchy="false" xref="S4.p2.1.m1.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.2.1.cmml" xref="S4.p2.1.m1.1.2.2"><csymbol cd="latexml" id="S4.p2.1.m1.1.2.1.1.cmml" xref="S4.p2.1.m1.1.2.2.1">delimited-[]</csymbol><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝙲𝙻𝚂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\mathtt{[CLS]}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">[ typewriter_CLS ]</annotation></semantics></math> token in CLIP, serving as a compact vector representation of the information contained in each masked region.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.p3.1.1">S</span><span class="ltx_text ltx_font_bold" id="S4.p3.1.2">e<span class="ltx_text ltx_framed ltx_framed_underline" id="S4.p3.1.2.1">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.p3.1.2.2">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.p3.1.2.3">T</span>uning (SMART)</span> is a simple yet effective framework that can substantially enhance the performance of two-stage open-vocabulary panoptic segmentation networks. Grounded in insights gained from previous analyses, SMART freezes the mask generator and introduces two novel methods to improve mask classification:</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Semantic-guided Mask Attention.</span> This method imbues task-awareness into mask tokens, enabling adaptive extraction of important task-relevant information.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Query Projection Tuning.</span> Only the <span class="ltx_text ltx_font_italic" id="S4.I1.i2.p1.1.2">query projection layer</span> is fine-tuned while other layers remain frozen, ensuring efficient knowledge transfer to open-vocabulary tasks without degrading the pre-trained CLIP knowledge.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.9"><span class="ltx_text ltx_font_bold" id="S4.p4.9.1">Semantic-guided Mask Attention (SMA).</span> Existing two-stage open-vocabulary panoptic segmentation methods primarily rely on mask attention <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite> to extract regional information. However, these methods often struggle with large and unpredictable vocabularies in open-vocabulary tasks. Given the vast amount of information within each image, indiscriminately extracting all available information can overwhelm the mask tokens with small embedding size. To address this issue, we propose SMA, an innovative multimodal attention mechanism that incorporates task-awareness into the regional information extraction process. Our approach involves two key steps. First, in the <span class="ltx_text ltx_font_italic" id="S4.p4.9.2">Task Information Extraction</span> step, the mask tokens cross-attend with target class tokens generated by CLIP’s language encoder. This process infuses task-awareness into the mask tokens, conditioning them to capture more task-specific and contextually relevant information. Second, in the <span class="ltx_text ltx_font_italic" id="S4.p4.9.3">Task-aware Mask Attention</span> step, these enhanced mask tokens are used to perform attention over masked image regions. Before applying mask attention, a lightweight Distribution Adapter, consisting of only two convolutional layers, adjusts the mask proposals to align with CLIP’s preferred input distribution. This adjustment is beneficial due to the large input-output distribution gap between the independently trained CLIP and the mask generator, as demonstrated in prior work <cite class="ltx_cite ltx_citemacro_citep">(Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib27" title="">2023</a>)</cite>. By using task-aware mask tokens, task-specific information can be more effectively extracted, leading to improved open-vocab. panoptic segmentation. Mathematically, SMA is computed as follows: Given <math alttext="m" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">italic_m</annotation></semantics></math> mask tokens <math alttext="\mathtt{[MASK]}\in\mathbb{R}^{m\times C}" class="ltx_Math" display="inline" id="S4.p4.2.m2.1"><semantics id="S4.p4.2.m2.1a"><mrow id="S4.p4.2.m2.1.2" xref="S4.p4.2.m2.1.2.cmml"><mrow id="S4.p4.2.m2.1.2.2.2" xref="S4.p4.2.m2.1.2.2.1.cmml"><mo id="S4.p4.2.m2.1.2.2.2.1" stretchy="false" xref="S4.p4.2.m2.1.2.2.1.1.cmml">[</mo><mi id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml">𝙼𝙰𝚂𝙺</mi><mo id="S4.p4.2.m2.1.2.2.2.2" stretchy="false" xref="S4.p4.2.m2.1.2.2.1.1.cmml">]</mo></mrow><mo id="S4.p4.2.m2.1.2.1" xref="S4.p4.2.m2.1.2.1.cmml">∈</mo><msup id="S4.p4.2.m2.1.2.3" xref="S4.p4.2.m2.1.2.3.cmml"><mi id="S4.p4.2.m2.1.2.3.2" xref="S4.p4.2.m2.1.2.3.2.cmml">ℝ</mi><mrow id="S4.p4.2.m2.1.2.3.3" xref="S4.p4.2.m2.1.2.3.3.cmml"><mi id="S4.p4.2.m2.1.2.3.3.2" xref="S4.p4.2.m2.1.2.3.3.2.cmml">m</mi><mo id="S4.p4.2.m2.1.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.p4.2.m2.1.2.3.3.1.cmml">×</mo><mi id="S4.p4.2.m2.1.2.3.3.3" xref="S4.p4.2.m2.1.2.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.2.cmml" xref="S4.p4.2.m2.1.2"><in id="S4.p4.2.m2.1.2.1.cmml" xref="S4.p4.2.m2.1.2.1"></in><apply id="S4.p4.2.m2.1.2.2.1.cmml" xref="S4.p4.2.m2.1.2.2.2"><csymbol cd="latexml" id="S4.p4.2.m2.1.2.2.1.1.cmml" xref="S4.p4.2.m2.1.2.2.2.1">delimited-[]</csymbol><ci id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">𝙼𝙰𝚂𝙺</ci></apply><apply id="S4.p4.2.m2.1.2.3.cmml" xref="S4.p4.2.m2.1.2.3"><csymbol cd="ambiguous" id="S4.p4.2.m2.1.2.3.1.cmml" xref="S4.p4.2.m2.1.2.3">superscript</csymbol><ci id="S4.p4.2.m2.1.2.3.2.cmml" xref="S4.p4.2.m2.1.2.3.2">ℝ</ci><apply id="S4.p4.2.m2.1.2.3.3.cmml" xref="S4.p4.2.m2.1.2.3.3"><times id="S4.p4.2.m2.1.2.3.3.1.cmml" xref="S4.p4.2.m2.1.2.3.3.1"></times><ci id="S4.p4.2.m2.1.2.3.3.2.cmml" xref="S4.p4.2.m2.1.2.3.3.2">𝑚</ci><ci id="S4.p4.2.m2.1.2.3.3.3.cmml" xref="S4.p4.2.m2.1.2.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">\mathtt{[MASK]}\in\mathbb{R}^{m\times C}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.2.m2.1d">[ typewriter_MASK ] ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_C end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="n" class="ltx_Math" display="inline" id="S4.p4.3.m3.1"><semantics id="S4.p4.3.m3.1a"><mi id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><ci id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p4.3.m3.1d">italic_n</annotation></semantics></math> image tokens <math alttext="\mathtt{[IMG]}\in\mathbb{R}^{n\times C}" class="ltx_Math" display="inline" id="S4.p4.4.m4.1"><semantics id="S4.p4.4.m4.1a"><mrow id="S4.p4.4.m4.1.2" xref="S4.p4.4.m4.1.2.cmml"><mrow id="S4.p4.4.m4.1.2.2.2" xref="S4.p4.4.m4.1.2.2.1.cmml"><mo id="S4.p4.4.m4.1.2.2.2.1" stretchy="false" xref="S4.p4.4.m4.1.2.2.1.1.cmml">[</mo><mi id="S4.p4.4.m4.1.1" xref="S4.p4.4.m4.1.1.cmml">𝙸𝙼𝙶</mi><mo id="S4.p4.4.m4.1.2.2.2.2" stretchy="false" xref="S4.p4.4.m4.1.2.2.1.1.cmml">]</mo></mrow><mo id="S4.p4.4.m4.1.2.1" xref="S4.p4.4.m4.1.2.1.cmml">∈</mo><msup id="S4.p4.4.m4.1.2.3" xref="S4.p4.4.m4.1.2.3.cmml"><mi id="S4.p4.4.m4.1.2.3.2" xref="S4.p4.4.m4.1.2.3.2.cmml">ℝ</mi><mrow id="S4.p4.4.m4.1.2.3.3" xref="S4.p4.4.m4.1.2.3.3.cmml"><mi id="S4.p4.4.m4.1.2.3.3.2" xref="S4.p4.4.m4.1.2.3.3.2.cmml">n</mi><mo id="S4.p4.4.m4.1.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.p4.4.m4.1.2.3.3.1.cmml">×</mo><mi id="S4.p4.4.m4.1.2.3.3.3" xref="S4.p4.4.m4.1.2.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.1b"><apply id="S4.p4.4.m4.1.2.cmml" xref="S4.p4.4.m4.1.2"><in id="S4.p4.4.m4.1.2.1.cmml" xref="S4.p4.4.m4.1.2.1"></in><apply id="S4.p4.4.m4.1.2.2.1.cmml" xref="S4.p4.4.m4.1.2.2.2"><csymbol cd="latexml" id="S4.p4.4.m4.1.2.2.1.1.cmml" xref="S4.p4.4.m4.1.2.2.2.1">delimited-[]</csymbol><ci id="S4.p4.4.m4.1.1.cmml" xref="S4.p4.4.m4.1.1">𝙸𝙼𝙶</ci></apply><apply id="S4.p4.4.m4.1.2.3.cmml" xref="S4.p4.4.m4.1.2.3"><csymbol cd="ambiguous" id="S4.p4.4.m4.1.2.3.1.cmml" xref="S4.p4.4.m4.1.2.3">superscript</csymbol><ci id="S4.p4.4.m4.1.2.3.2.cmml" xref="S4.p4.4.m4.1.2.3.2">ℝ</ci><apply id="S4.p4.4.m4.1.2.3.3.cmml" xref="S4.p4.4.m4.1.2.3.3"><times id="S4.p4.4.m4.1.2.3.3.1.cmml" xref="S4.p4.4.m4.1.2.3.3.1"></times><ci id="S4.p4.4.m4.1.2.3.3.2.cmml" xref="S4.p4.4.m4.1.2.3.3.2">𝑛</ci><ci id="S4.p4.4.m4.1.2.3.3.3.cmml" xref="S4.p4.4.m4.1.2.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.1c">\mathtt{[IMG]}\in\mathbb{R}^{n\times C}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.4.m4.1d">[ typewriter_IMG ] ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_C end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="t" class="ltx_Math" display="inline" id="S4.p4.5.m5.1"><semantics id="S4.p4.5.m5.1a"><mi id="S4.p4.5.m5.1.1" xref="S4.p4.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p4.5.m5.1b"><ci id="S4.p4.5.m5.1.1.cmml" xref="S4.p4.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p4.5.m5.1d">italic_t</annotation></semantics></math> target class tokens <math alttext="\mathtt{[TGT]}\in\mathbb{R}^{t\times C}" class="ltx_Math" display="inline" id="S4.p4.6.m6.1"><semantics id="S4.p4.6.m6.1a"><mrow id="S4.p4.6.m6.1.2" xref="S4.p4.6.m6.1.2.cmml"><mrow id="S4.p4.6.m6.1.2.2.2" xref="S4.p4.6.m6.1.2.2.1.cmml"><mo id="S4.p4.6.m6.1.2.2.2.1" stretchy="false" xref="S4.p4.6.m6.1.2.2.1.1.cmml">[</mo><mi id="S4.p4.6.m6.1.1" xref="S4.p4.6.m6.1.1.cmml">𝚃𝙶𝚃</mi><mo id="S4.p4.6.m6.1.2.2.2.2" stretchy="false" xref="S4.p4.6.m6.1.2.2.1.1.cmml">]</mo></mrow><mo id="S4.p4.6.m6.1.2.1" xref="S4.p4.6.m6.1.2.1.cmml">∈</mo><msup id="S4.p4.6.m6.1.2.3" xref="S4.p4.6.m6.1.2.3.cmml"><mi id="S4.p4.6.m6.1.2.3.2" xref="S4.p4.6.m6.1.2.3.2.cmml">ℝ</mi><mrow id="S4.p4.6.m6.1.2.3.3" xref="S4.p4.6.m6.1.2.3.3.cmml"><mi id="S4.p4.6.m6.1.2.3.3.2" xref="S4.p4.6.m6.1.2.3.3.2.cmml">t</mi><mo id="S4.p4.6.m6.1.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.p4.6.m6.1.2.3.3.1.cmml">×</mo><mi id="S4.p4.6.m6.1.2.3.3.3" xref="S4.p4.6.m6.1.2.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.6.m6.1b"><apply id="S4.p4.6.m6.1.2.cmml" xref="S4.p4.6.m6.1.2"><in id="S4.p4.6.m6.1.2.1.cmml" xref="S4.p4.6.m6.1.2.1"></in><apply id="S4.p4.6.m6.1.2.2.1.cmml" xref="S4.p4.6.m6.1.2.2.2"><csymbol cd="latexml" id="S4.p4.6.m6.1.2.2.1.1.cmml" xref="S4.p4.6.m6.1.2.2.2.1">delimited-[]</csymbol><ci id="S4.p4.6.m6.1.1.cmml" xref="S4.p4.6.m6.1.1">𝚃𝙶𝚃</ci></apply><apply id="S4.p4.6.m6.1.2.3.cmml" xref="S4.p4.6.m6.1.2.3"><csymbol cd="ambiguous" id="S4.p4.6.m6.1.2.3.1.cmml" xref="S4.p4.6.m6.1.2.3">superscript</csymbol><ci id="S4.p4.6.m6.1.2.3.2.cmml" xref="S4.p4.6.m6.1.2.3.2">ℝ</ci><apply id="S4.p4.6.m6.1.2.3.3.cmml" xref="S4.p4.6.m6.1.2.3.3"><times id="S4.p4.6.m6.1.2.3.3.1.cmml" xref="S4.p4.6.m6.1.2.3.3.1"></times><ci id="S4.p4.6.m6.1.2.3.3.2.cmml" xref="S4.p4.6.m6.1.2.3.3.2">𝑡</ci><ci id="S4.p4.6.m6.1.2.3.3.3.cmml" xref="S4.p4.6.m6.1.2.3.3.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.6.m6.1c">\mathtt{[TGT]}\in\mathbb{R}^{t\times C}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.6.m6.1d">[ typewriter_TGT ] ∈ blackboard_R start_POSTSUPERSCRIPT italic_t × italic_C end_POSTSUPERSCRIPT</annotation></semantics></math>, CLIP’s query, key, value projections <math alttext="f_{q},f_{k},f_{v}" class="ltx_Math" display="inline" id="S4.p4.7.m7.3"><semantics id="S4.p4.7.m7.3a"><mrow id="S4.p4.7.m7.3.3.3" xref="S4.p4.7.m7.3.3.4.cmml"><msub id="S4.p4.7.m7.1.1.1.1" xref="S4.p4.7.m7.1.1.1.1.cmml"><mi id="S4.p4.7.m7.1.1.1.1.2" xref="S4.p4.7.m7.1.1.1.1.2.cmml">f</mi><mi id="S4.p4.7.m7.1.1.1.1.3" xref="S4.p4.7.m7.1.1.1.1.3.cmml">q</mi></msub><mo id="S4.p4.7.m7.3.3.3.4" xref="S4.p4.7.m7.3.3.4.cmml">,</mo><msub id="S4.p4.7.m7.2.2.2.2" xref="S4.p4.7.m7.2.2.2.2.cmml"><mi id="S4.p4.7.m7.2.2.2.2.2" xref="S4.p4.7.m7.2.2.2.2.2.cmml">f</mi><mi id="S4.p4.7.m7.2.2.2.2.3" xref="S4.p4.7.m7.2.2.2.2.3.cmml">k</mi></msub><mo id="S4.p4.7.m7.3.3.3.5" xref="S4.p4.7.m7.3.3.4.cmml">,</mo><msub id="S4.p4.7.m7.3.3.3.3" xref="S4.p4.7.m7.3.3.3.3.cmml"><mi id="S4.p4.7.m7.3.3.3.3.2" xref="S4.p4.7.m7.3.3.3.3.2.cmml">f</mi><mi id="S4.p4.7.m7.3.3.3.3.3" xref="S4.p4.7.m7.3.3.3.3.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.7.m7.3b"><list id="S4.p4.7.m7.3.3.4.cmml" xref="S4.p4.7.m7.3.3.3"><apply id="S4.p4.7.m7.1.1.1.1.cmml" xref="S4.p4.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S4.p4.7.m7.1.1.1.1.1.cmml" xref="S4.p4.7.m7.1.1.1.1">subscript</csymbol><ci id="S4.p4.7.m7.1.1.1.1.2.cmml" xref="S4.p4.7.m7.1.1.1.1.2">𝑓</ci><ci id="S4.p4.7.m7.1.1.1.1.3.cmml" xref="S4.p4.7.m7.1.1.1.1.3">𝑞</ci></apply><apply id="S4.p4.7.m7.2.2.2.2.cmml" xref="S4.p4.7.m7.2.2.2.2"><csymbol cd="ambiguous" id="S4.p4.7.m7.2.2.2.2.1.cmml" xref="S4.p4.7.m7.2.2.2.2">subscript</csymbol><ci id="S4.p4.7.m7.2.2.2.2.2.cmml" xref="S4.p4.7.m7.2.2.2.2.2">𝑓</ci><ci id="S4.p4.7.m7.2.2.2.2.3.cmml" xref="S4.p4.7.m7.2.2.2.2.3">𝑘</ci></apply><apply id="S4.p4.7.m7.3.3.3.3.cmml" xref="S4.p4.7.m7.3.3.3.3"><csymbol cd="ambiguous" id="S4.p4.7.m7.3.3.3.3.1.cmml" xref="S4.p4.7.m7.3.3.3.3">subscript</csymbol><ci id="S4.p4.7.m7.3.3.3.3.2.cmml" xref="S4.p4.7.m7.3.3.3.3.2">𝑓</ci><ci id="S4.p4.7.m7.3.3.3.3.3.cmml" xref="S4.p4.7.m7.3.3.3.3.3">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.7.m7.3c">f_{q},f_{k},f_{v}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.7.m7.3d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math>, randomly initialized query, key, value projections <math alttext="g_{q},g_{k},g_{v}" class="ltx_Math" display="inline" id="S4.p4.8.m8.3"><semantics id="S4.p4.8.m8.3a"><mrow id="S4.p4.8.m8.3.3.3" xref="S4.p4.8.m8.3.3.4.cmml"><msub id="S4.p4.8.m8.1.1.1.1" xref="S4.p4.8.m8.1.1.1.1.cmml"><mi id="S4.p4.8.m8.1.1.1.1.2" xref="S4.p4.8.m8.1.1.1.1.2.cmml">g</mi><mi id="S4.p4.8.m8.1.1.1.1.3" xref="S4.p4.8.m8.1.1.1.1.3.cmml">q</mi></msub><mo id="S4.p4.8.m8.3.3.3.4" xref="S4.p4.8.m8.3.3.4.cmml">,</mo><msub id="S4.p4.8.m8.2.2.2.2" xref="S4.p4.8.m8.2.2.2.2.cmml"><mi id="S4.p4.8.m8.2.2.2.2.2" xref="S4.p4.8.m8.2.2.2.2.2.cmml">g</mi><mi id="S4.p4.8.m8.2.2.2.2.3" xref="S4.p4.8.m8.2.2.2.2.3.cmml">k</mi></msub><mo id="S4.p4.8.m8.3.3.3.5" xref="S4.p4.8.m8.3.3.4.cmml">,</mo><msub id="S4.p4.8.m8.3.3.3.3" xref="S4.p4.8.m8.3.3.3.3.cmml"><mi id="S4.p4.8.m8.3.3.3.3.2" xref="S4.p4.8.m8.3.3.3.3.2.cmml">g</mi><mi id="S4.p4.8.m8.3.3.3.3.3" xref="S4.p4.8.m8.3.3.3.3.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.8.m8.3b"><list id="S4.p4.8.m8.3.3.4.cmml" xref="S4.p4.8.m8.3.3.3"><apply id="S4.p4.8.m8.1.1.1.1.cmml" xref="S4.p4.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S4.p4.8.m8.1.1.1.1.1.cmml" xref="S4.p4.8.m8.1.1.1.1">subscript</csymbol><ci id="S4.p4.8.m8.1.1.1.1.2.cmml" xref="S4.p4.8.m8.1.1.1.1.2">𝑔</ci><ci id="S4.p4.8.m8.1.1.1.1.3.cmml" xref="S4.p4.8.m8.1.1.1.1.3">𝑞</ci></apply><apply id="S4.p4.8.m8.2.2.2.2.cmml" xref="S4.p4.8.m8.2.2.2.2"><csymbol cd="ambiguous" id="S4.p4.8.m8.2.2.2.2.1.cmml" xref="S4.p4.8.m8.2.2.2.2">subscript</csymbol><ci id="S4.p4.8.m8.2.2.2.2.2.cmml" xref="S4.p4.8.m8.2.2.2.2.2">𝑔</ci><ci id="S4.p4.8.m8.2.2.2.2.3.cmml" xref="S4.p4.8.m8.2.2.2.2.3">𝑘</ci></apply><apply id="S4.p4.8.m8.3.3.3.3.cmml" xref="S4.p4.8.m8.3.3.3.3"><csymbol cd="ambiguous" id="S4.p4.8.m8.3.3.3.3.1.cmml" xref="S4.p4.8.m8.3.3.3.3">subscript</csymbol><ci id="S4.p4.8.m8.3.3.3.3.2.cmml" xref="S4.p4.8.m8.3.3.3.3.2">𝑔</ci><ci id="S4.p4.8.m8.3.3.3.3.3.cmml" xref="S4.p4.8.m8.3.3.3.3.3">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.8.m8.3c">g_{q},g_{k},g_{v}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.8.m8.3d">italic_g start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> for <span class="ltx_text ltx_font_italic" id="S4.p4.9.4">Task Information Extraction</span> and Softmax operator <math alttext="\sigma" class="ltx_Math" display="inline" id="S4.p4.9.m9.1"><semantics id="S4.p4.9.m9.1a"><mi id="S4.p4.9.m9.1.1" xref="S4.p4.9.m9.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.p4.9.m9.1b"><ci id="S4.p4.9.m9.1.1.cmml" xref="S4.p4.9.m9.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.9.m9.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S4.p4.9.m9.1d">italic_σ</annotation></semantics></math>,</p>
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="S6.EGx1">
<tbody id="S4.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\begin{aligned} \text{SMA}(\mathtt{[MASK]},\mathtt{[IMG]},\mathtt%
{[TGT]})=\sigma(\hat{\textbf{q}}_{\text{mask}}\textbf{k}_{\text{img}}^{T}+%
\mathcal{M}_{\text{mask}})\cdot\textbf{v}_{\text{img}},\end{aligned}" class="ltx_Math" display="block" id="S4.E1.m1.4"><semantics id="S4.E1.m1.4a"><mtable displaystyle="true" id="S4.E1.m1.4.4" xref="S4.E1.m1.4.4.cmml"><mtr id="S4.E1.m1.4.4a" xref="S4.E1.m1.4.4.cmml"><mtd class="ltx_align_right" columnalign="right" id="S4.E1.m1.4.4b" xref="S4.E1.m1.4.4.cmml"><mrow id="S4.E1.m1.4.4.4.4.4.4" xref="S4.E1.m1.4.4.4.4.4.4.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.4.4.1" xref="S4.E1.m1.4.4.4.4.4.4.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.4.4.1.3" xref="S4.E1.m1.4.4.4.4.4.4.1.3.cmml"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.3.5" xref="S4.E1.m1.4.4.4.4.4.4.1.3.5a.cmml">SMA</mtext><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.4" xref="S4.E1.m1.4.4.4.4.4.4.1.3.4.cmml">⁢</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml"><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.4" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml">(</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.2" xref="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.1.cmml"><mo id="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.2.1" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.1.1.cmml">[</mo><mi id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml">𝙼𝙰𝚂𝙺</mi><mo id="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.2.2" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.5" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml">,</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.2" xref="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.1.cmml"><mo id="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.2.1" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.1.1.cmml">[</mo><mi id="S4.E1.m1.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.2.cmml">𝙸𝙼𝙶</mi><mo id="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.2.2" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.1.1.cmml">]</mo></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.6" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml">,</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.2" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.1.cmml"><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.2.1" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.1.1.cmml">[</mo><mi id="S4.E1.m1.3.3.3.3.3.3" xref="S4.E1.m1.3.3.3.3.3.3.cmml">𝚃𝙶𝚃</mi><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.2.2" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.1.1.cmml">]</mo></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.7" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.5" xref="S4.E1.m1.4.4.4.4.4.4.1.5.cmml">=</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.4" xref="S4.E1.m1.4.4.4.4.4.4.1.4.cmml"><mrow id="S4.E1.m1.4.4.4.4.4.4.1.4.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.cmml"><mi id="S4.E1.m1.4.4.4.4.4.4.1.4.1.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.3.cmml">σ</mi><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.cmml"><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.2" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.cmml"><msub id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.cmml"><mover accent="true" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2a.cmml">q</mtext><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.1.cmml">^</mo></mover><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3a.cmml">mask</mtext></msub><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.1.cmml">⁢</mo><msubsup id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2a.cmml">k</mtext><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3a.cmml">img</mtext><mi id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.3.cmml">T</mi></msubsup></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.1" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.1.cmml">+</mo><msub id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.2.cmml">ℳ</mi><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3a.cmml">mask</mtext></msub></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.3" rspace="0.055em" stretchy="false" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.1.4.2" rspace="0.222em" xref="S4.E1.m1.4.4.4.4.4.4.1.4.2.cmml">⋅</mo><msub id="S4.E1.m1.4.4.4.4.4.4.1.4.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.3.2" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.2a.cmml">v</mtext><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.3.3" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.3a.cmml">img</mtext></msub></mrow></mrow><mo id="S4.E1.m1.4.4.4.4.4.4.2" xref="S4.E1.m1.4.4.4.4.4.4.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E1.m1.4b"><matrix id="S4.E1.m1.4.4.cmml" xref="S4.E1.m1.4.4"><matrixrow id="S4.E1.m1.4.4a.cmml" xref="S4.E1.m1.4.4"><apply id="S4.E1.m1.4.4.4.4.4.4.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4"><eq id="S4.E1.m1.4.4.4.4.4.4.1.5.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.5"></eq><apply id="S4.E1.m1.4.4.4.4.4.4.1.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3"><times id="S4.E1.m1.4.4.4.4.4.4.1.3.4.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.4"></times><ci id="S4.E1.m1.4.4.4.4.4.4.1.3.5a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.5"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.3.5.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.5">SMA</mtext></ci><vector id="S4.E1.m1.4.4.4.4.4.4.1.3.3.4.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3"><apply id="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.2"><csymbol cd="latexml" id="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.1.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1">𝙼𝙰𝚂𝙺</ci></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.2"><csymbol cd="latexml" id="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.2.2.2.2.2.1">delimited-[]</csymbol><ci id="S4.E1.m1.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2">𝙸𝙼𝙶</ci></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.2"><csymbol cd="latexml" id="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.3.3.3.3.2.1">delimited-[]</csymbol><ci id="S4.E1.m1.3.3.3.3.3.3.cmml" xref="S4.E1.m1.3.3.3.3.3.3">𝚃𝙶𝚃</ci></apply></vector></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4"><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.2">⋅</ci><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1"><times id="S4.E1.m1.4.4.4.4.4.4.1.4.1.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.2"></times><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.3">𝜎</ci><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1"><plus id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.1"></plus><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2"><times id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.1"></times><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2">subscript</csymbol><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2"><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.1">^</ci><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.2.2">q</mtext></ci></apply><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.2.3">mask</mtext></ci></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3">superscript</csymbol><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.2">k</mtext></ci><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3.cmml" mathsize="70%" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.2.3">img</mtext></ci></apply><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.2">ℳ</ci><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3.cmml" mathsize="70%" xref="S4.E1.m1.4.4.4.4.4.4.1.4.1.1.1.1.3.3">mask</mtext></ci></apply></apply></apply><apply id="S4.E1.m1.4.4.4.4.4.4.1.4.3.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.4.4.1.4.3.1.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.3.2a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.2"><mtext class="ltx_mathvariant_bold" id="S4.E1.m1.4.4.4.4.4.4.1.4.3.2.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.2">v</mtext></ci><ci id="S4.E1.m1.4.4.4.4.4.4.1.4.3.3a.cmml" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.3"><mtext id="S4.E1.m1.4.4.4.4.4.4.1.4.3.3.cmml" mathsize="70%" xref="S4.E1.m1.4.4.4.4.4.4.1.4.3.3">img</mtext></ci></apply></apply></apply></matrixrow></matrix></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.4c">\displaystyle\begin{aligned} \text{SMA}(\mathtt{[MASK]},\mathtt{[IMG]},\mathtt%
{[TGT]})=\sigma(\hat{\textbf{q}}_{\text{mask}}\textbf{k}_{\text{img}}^{T}+%
\mathcal{M}_{\text{mask}})\cdot\textbf{v}_{\text{img}},\end{aligned}</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.4d">start_ROW start_CELL SMA ( [ typewriter_MASK ] , [ typewriter_IMG ] , [ typewriter_TGT ] ) = italic_σ ( over^ start_ARG q end_ARG start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT k start_POSTSUBSCRIPT img end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT + caligraphic_M start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT ) ⋅ v start_POSTSUBSCRIPT img end_POSTSUBSCRIPT , end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\hat{\textbf{q}}_{\text{mask}},\textbf{k}_{\text{img}},\textbf{v}%
_{\text{img}}=f_{q}(\hat{\mathtt{[MASK]}}),f_{k}(\mathtt{[IMG]}),f_{v}(\mathtt%
{[IMG]})," class="ltx_Math" display="block" id="S4.E2.m1.4"><semantics id="S4.E2.m1.4a"><mrow id="S4.E2.m1.4.4.1"><mrow id="S4.E2.m1.4.4.1.1.2" xref="S4.E2.m1.4.4.1.1.3.cmml"><mrow id="S4.E2.m1.4.4.1.1.1.1" xref="S4.E2.m1.4.4.1.1.1.1.cmml"><mrow id="S4.E2.m1.4.4.1.1.1.1.3.3" xref="S4.E2.m1.4.4.1.1.1.1.3.4.cmml"><msub id="S4.E2.m1.4.4.1.1.1.1.1.1.1" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2a.cmml">q</mtext><mo id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.1" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mtext id="S4.E2.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.3a.cmml">mask</mtext></msub><mo id="S4.E2.m1.4.4.1.1.1.1.3.3.4" xref="S4.E2.m1.4.4.1.1.1.1.3.4.cmml">,</mo><msub id="S4.E2.m1.4.4.1.1.1.1.2.2.2" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.2.2.2.2" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.2a.cmml">k</mtext><mtext id="S4.E2.m1.4.4.1.1.1.1.2.2.2.3" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.3a.cmml">img</mtext></msub><mo id="S4.E2.m1.4.4.1.1.1.1.3.3.5" xref="S4.E2.m1.4.4.1.1.1.1.3.4.cmml">,</mo><msub id="S4.E2.m1.4.4.1.1.1.1.3.3.3" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.3.3.3.2" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.2a.cmml">v</mtext><mtext id="S4.E2.m1.4.4.1.1.1.1.3.3.3.3" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.3a.cmml">img</mtext></msub></mrow><mo id="S4.E2.m1.4.4.1.1.1.1.4" xref="S4.E2.m1.4.4.1.1.1.1.4.cmml">=</mo><mrow id="S4.E2.m1.4.4.1.1.1.1.5" xref="S4.E2.m1.4.4.1.1.1.1.5.cmml"><msub id="S4.E2.m1.4.4.1.1.1.1.5.2" xref="S4.E2.m1.4.4.1.1.1.1.5.2.cmml"><mi id="S4.E2.m1.4.4.1.1.1.1.5.2.2" xref="S4.E2.m1.4.4.1.1.1.1.5.2.2.cmml">f</mi><mi id="S4.E2.m1.4.4.1.1.1.1.5.2.3" xref="S4.E2.m1.4.4.1.1.1.1.5.2.3.cmml">q</mi></msub><mo id="S4.E2.m1.4.4.1.1.1.1.5.1" xref="S4.E2.m1.4.4.1.1.1.1.5.1.cmml">⁢</mo><mrow id="S4.E2.m1.4.4.1.1.1.1.5.3.2" xref="S4.E2.m1.1.1.cmml"><mo id="S4.E2.m1.4.4.1.1.1.1.5.3.2.1" stretchy="false" xref="S4.E2.m1.1.1.cmml">(</mo><mover accent="true" id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.3" xref="S4.E2.m1.1.1.1.2.cmml"><mo id="S4.E2.m1.1.1.1.3.1" stretchy="false" xref="S4.E2.m1.1.1.1.2.1.cmml">[</mo><mi id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml">𝙼𝙰𝚂𝙺</mi><mo id="S4.E2.m1.1.1.1.3.2" stretchy="false" xref="S4.E2.m1.1.1.1.2.1.cmml">]</mo></mrow><mo id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">^</mo></mover><mo id="S4.E2.m1.4.4.1.1.1.1.5.3.2.2" stretchy="false" xref="S4.E2.m1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E2.m1.4.4.1.1.2.3" xref="S4.E2.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.2" xref="S4.E2.m1.4.4.1.1.2.2.3.cmml"><mrow id="S4.E2.m1.4.4.1.1.2.2.1.1" xref="S4.E2.m1.4.4.1.1.2.2.1.1.cmml"><msub id="S4.E2.m1.4.4.1.1.2.2.1.1.3" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3.cmml"><mi id="S4.E2.m1.4.4.1.1.2.2.1.1.3.2" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3.2.cmml">f</mi><mi id="S4.E2.m1.4.4.1.1.2.2.1.1.3.3" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3.3.cmml">k</mi></msub><mo id="S4.E2.m1.4.4.1.1.2.2.1.1.2" xref="S4.E2.m1.4.4.1.1.2.2.1.1.2.cmml">⁢</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1" xref="S4.E2.m1.4.4.1.1.2.2.1.1.cmml"><mo id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.2" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.1.1.cmml">(</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2" xref="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml">[</mo><mi id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">𝙸𝙼𝙶</mi><mo id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.2" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.3" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.4.4.1.1.2.2.2.3" xref="S4.E2.m1.4.4.1.1.2.2.3.cmml">,</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.2.2" xref="S4.E2.m1.4.4.1.1.2.2.2.2.cmml"><msub id="S4.E2.m1.4.4.1.1.2.2.2.2.3" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3.cmml"><mi id="S4.E2.m1.4.4.1.1.2.2.2.2.3.2" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3.2.cmml">f</mi><mi id="S4.E2.m1.4.4.1.1.2.2.2.2.3.3" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3.3.cmml">v</mi></msub><mo id="S4.E2.m1.4.4.1.1.2.2.2.2.2" xref="S4.E2.m1.4.4.1.1.2.2.2.2.2.cmml">⁢</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1" xref="S4.E2.m1.4.4.1.1.2.2.2.2.cmml"><mo id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.2" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.2.2.cmml">(</mo><mrow id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.2" xref="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.1.cmml"><mo id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.2.1" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml">[</mo><mi id="S4.E2.m1.3.3" xref="S4.E2.m1.3.3.cmml">𝙸𝙼𝙶</mi><mo id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.2.2" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.3" stretchy="false" xref="S4.E2.m1.4.4.1.1.2.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E2.m1.4.4.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.4b"><apply id="S4.E2.m1.4.4.1.1.3.cmml" xref="S4.E2.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.3a.cmml" xref="S4.E2.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S4.E2.m1.4.4.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1"><eq id="S4.E2.m1.4.4.1.1.1.1.4.cmml" xref="S4.E2.m1.4.4.1.1.1.1.4"></eq><list id="S4.E2.m1.4.4.1.1.1.1.3.4.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3"><apply id="S4.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2"><ci id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.1">^</ci><ci id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.2.2">q</mtext></ci></apply><ci id="S4.E2.m1.4.4.1.1.1.1.1.1.1.3a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.3"><mtext id="S4.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S4.E2.m1.4.4.1.1.1.1.1.1.1.3">mask</mtext></ci></apply><apply id="S4.E2.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.1.1.2.2.2.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E2.m1.4.4.1.1.1.1.2.2.2.2a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.2">k</mtext></ci><ci id="S4.E2.m1.4.4.1.1.1.1.2.2.2.3a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.3"><mtext id="S4.E2.m1.4.4.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S4.E2.m1.4.4.1.1.1.1.2.2.2.3">img</mtext></ci></apply><apply id="S4.E2.m1.4.4.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.1.1.3.3.3.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E2.m1.4.4.1.1.1.1.3.3.3.2a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.1.1.1.1.3.3.3.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.2">v</mtext></ci><ci id="S4.E2.m1.4.4.1.1.1.1.3.3.3.3a.cmml" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.3"><mtext id="S4.E2.m1.4.4.1.1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S4.E2.m1.4.4.1.1.1.1.3.3.3.3">img</mtext></ci></apply></list><apply id="S4.E2.m1.4.4.1.1.1.1.5.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5"><times id="S4.E2.m1.4.4.1.1.1.1.5.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.1"></times><apply id="S4.E2.m1.4.4.1.1.1.1.5.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.2"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.1.1.5.2.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.2">subscript</csymbol><ci id="S4.E2.m1.4.4.1.1.1.1.5.2.2.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.2.2">𝑓</ci><ci id="S4.E2.m1.4.4.1.1.1.1.5.2.3.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.2.3">𝑞</ci></apply><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.1.1.5.3.2"><ci id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2">^</ci><apply id="S4.E2.m1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.3"><csymbol cd="latexml" id="S4.E2.m1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.3.1">delimited-[]</csymbol><ci id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1">𝙼𝙰𝚂𝙺</ci></apply></apply></apply></apply><list id="S4.E2.m1.4.4.1.1.2.2.3.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2"><apply id="S4.E2.m1.4.4.1.1.2.2.1.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1"><times id="S4.E2.m1.4.4.1.1.2.2.1.1.2.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.2"></times><apply id="S4.E2.m1.4.4.1.1.2.2.1.1.3.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.2.2.1.1.3.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3">subscript</csymbol><ci id="S4.E2.m1.4.4.1.1.2.2.1.1.3.2.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3.2">𝑓</ci><ci id="S4.E2.m1.4.4.1.1.2.2.1.1.3.3.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.3.3">𝑘</ci></apply><apply id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2"><csymbol cd="latexml" id="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.1.1.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">𝙸𝙼𝙶</ci></apply></apply><apply id="S4.E2.m1.4.4.1.1.2.2.2.2.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2"><times id="S4.E2.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.2"></times><apply id="S4.E2.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.4.4.1.1.2.2.2.2.3.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3">subscript</csymbol><ci id="S4.E2.m1.4.4.1.1.2.2.2.2.3.2.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3.2">𝑓</ci><ci id="S4.E2.m1.4.4.1.1.2.2.2.2.3.3.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.3.3">𝑣</ci></apply><apply id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.2"><csymbol cd="latexml" id="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E2.m1.4.4.1.1.2.2.2.2.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3">𝙸𝙼𝙶</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.4c">\displaystyle\hat{\textbf{q}}_{\text{mask}},\textbf{k}_{\text{img}},\textbf{v}%
_{\text{img}}=f_{q}(\hat{\mathtt{[MASK]}}),f_{k}(\mathtt{[IMG]}),f_{v}(\mathtt%
{[IMG]}),</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.4d">over^ start_ARG q end_ARG start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT , k start_POSTSUBSCRIPT img end_POSTSUBSCRIPT , v start_POSTSUBSCRIPT img end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over^ start_ARG [ typewriter_MASK ] end_ARG ) , italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( [ typewriter_IMG ] ) , italic_f start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( [ typewriter_IMG ] ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\hat{\mathtt{[MASK]}}=\sigma(\textbf{q}_{\text{mask}}\textbf{k}_{%
\text{tgt}}^{T})\cdot\textbf{v}_{\text{tgt}}," class="ltx_Math" display="block" id="S4.E3.m1.2"><semantics id="S4.E3.m1.2a"><mrow id="S4.E3.m1.2.2.1" xref="S4.E3.m1.2.2.1.1.cmml"><mrow id="S4.E3.m1.2.2.1.1" xref="S4.E3.m1.2.2.1.1.cmml"><mover accent="true" id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.3" xref="S4.E3.m1.1.1.1.2.cmml"><mo id="S4.E3.m1.1.1.1.3.1" stretchy="false" xref="S4.E3.m1.1.1.1.2.1.cmml">[</mo><mi id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml">𝙼𝙰𝚂𝙺</mi><mo id="S4.E3.m1.1.1.1.3.2" stretchy="false" xref="S4.E3.m1.1.1.1.2.1.cmml">]</mo></mrow><mo id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">^</mo></mover><mo id="S4.E3.m1.2.2.1.1.2" xref="S4.E3.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E3.m1.2.2.1.1.1" xref="S4.E3.m1.2.2.1.1.1.cmml"><mrow id="S4.E3.m1.2.2.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.cmml"><mi id="S4.E3.m1.2.2.1.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.1.3.cmml">σ</mi><mo id="S4.E3.m1.2.2.1.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E3.m1.2.2.1.1.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.2.2.1.1.1.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2a.cmml">q</mtext><mtext id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3a.cmml">mask</mtext></msub><mo id="S4.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><msubsup id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2a.cmml">k</mtext><mtext id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3a.cmml">tgt</mtext><mi id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">T</mi></msubsup></mrow><mo id="S4.E3.m1.2.2.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.2.2.1.1.1.2" rspace="0.222em" xref="S4.E3.m1.2.2.1.1.1.2.cmml">⋅</mo><msub id="S4.E3.m1.2.2.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.3.2" xref="S4.E3.m1.2.2.1.1.1.3.2a.cmml">v</mtext><mtext id="S4.E3.m1.2.2.1.1.1.3.3" xref="S4.E3.m1.2.2.1.1.1.3.3a.cmml">tgt</mtext></msub></mrow></mrow><mo id="S4.E3.m1.2.2.1.2" xref="S4.E3.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.2b"><apply id="S4.E3.m1.2.2.1.1.cmml" xref="S4.E3.m1.2.2.1"><eq id="S4.E3.m1.2.2.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.2"></eq><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><ci id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2">^</ci><apply id="S4.E3.m1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.3"><csymbol cd="latexml" id="S4.E3.m1.1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.1.3.1">delimited-[]</csymbol><ci id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1">𝙼𝙰𝚂𝙺</ci></apply></apply><apply id="S4.E3.m1.2.2.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1"><ci id="S4.E3.m1.2.2.1.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.1.2">⋅</ci><apply id="S4.E3.m1.2.2.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1"><times id="S4.E3.m1.2.2.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.2"></times><ci id="S4.E3.m1.2.2.1.1.1.1.3.cmml" xref="S4.E3.m1.2.2.1.1.1.1.3">𝜎</ci><apply id="S4.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1"><times id="S4.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.1"></times><apply id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.2">q</mtext></ci><ci id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3"><mtext id="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" mathsize="70%" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.2.3">mask</mtext></ci></apply><apply id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.2">k</mtext></ci><ci id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3"><mtext id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.2.3">tgt</mtext></ci></apply><ci id="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.1.1.3.3">𝑇</ci></apply></apply></apply><apply id="S4.E3.m1.2.2.1.1.1.3.cmml" xref="S4.E3.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.1.1.1.3.1.cmml" xref="S4.E3.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.2.2.1.1.1.3.2a.cmml" xref="S4.E3.m1.2.2.1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.3.2.cmml" xref="S4.E3.m1.2.2.1.1.1.3.2">v</mtext></ci><ci id="S4.E3.m1.2.2.1.1.1.3.3a.cmml" xref="S4.E3.m1.2.2.1.1.1.3.3"><mtext id="S4.E3.m1.2.2.1.1.1.3.3.cmml" mathsize="70%" xref="S4.E3.m1.2.2.1.1.1.3.3">tgt</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.2c">\displaystyle\hat{\mathtt{[MASK]}}=\sigma(\textbf{q}_{\text{mask}}\textbf{k}_{%
\text{tgt}}^{T})\cdot\textbf{v}_{\text{tgt}},</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.2d">over^ start_ARG [ typewriter_MASK ] end_ARG = italic_σ ( q start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT k start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) ⋅ v start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\textbf{q}_{\text{mask}},\textbf{k}_{\text{tgt}},\textbf{v}_{%
\text{tgt}}=g_{q}(\mathtt{[MASK]}),g_{k}(\mathtt{[TGT]}),g_{v}(\mathtt{[TGT]})," class="ltx_Math" display="block" id="S4.E4.m1.4"><semantics id="S4.E4.m1.4a"><mrow id="S4.E4.m1.4.4.1"><mrow id="S4.E4.m1.4.4.1.1.2" xref="S4.E4.m1.4.4.1.1.3.cmml"><mrow id="S4.E4.m1.4.4.1.1.1.1" xref="S4.E4.m1.4.4.1.1.1.1.cmml"><mrow id="S4.E4.m1.4.4.1.1.1.1.3.3" xref="S4.E4.m1.4.4.1.1.1.1.3.4.cmml"><msub id="S4.E4.m1.4.4.1.1.1.1.1.1.1" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.1.1.1.2" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.2a.cmml">q</mtext><mtext id="S4.E4.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.3a.cmml">mask</mtext></msub><mo id="S4.E4.m1.4.4.1.1.1.1.3.3.4" xref="S4.E4.m1.4.4.1.1.1.1.3.4.cmml">,</mo><msub id="S4.E4.m1.4.4.1.1.1.1.2.2.2" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.2.2.2.2" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.2a.cmml">k</mtext><mtext id="S4.E4.m1.4.4.1.1.1.1.2.2.2.3" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.3a.cmml">tgt</mtext></msub><mo id="S4.E4.m1.4.4.1.1.1.1.3.3.5" xref="S4.E4.m1.4.4.1.1.1.1.3.4.cmml">,</mo><msub id="S4.E4.m1.4.4.1.1.1.1.3.3.3" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.3.3.3.2" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.2a.cmml">v</mtext><mtext id="S4.E4.m1.4.4.1.1.1.1.3.3.3.3" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.3a.cmml">tgt</mtext></msub></mrow><mo id="S4.E4.m1.4.4.1.1.1.1.5" xref="S4.E4.m1.4.4.1.1.1.1.5.cmml">=</mo><mrow id="S4.E4.m1.4.4.1.1.1.1.4" xref="S4.E4.m1.4.4.1.1.1.1.4.cmml"><msub id="S4.E4.m1.4.4.1.1.1.1.4.3" xref="S4.E4.m1.4.4.1.1.1.1.4.3.cmml"><mi id="S4.E4.m1.4.4.1.1.1.1.4.3.2" xref="S4.E4.m1.4.4.1.1.1.1.4.3.2.cmml">g</mi><mi id="S4.E4.m1.4.4.1.1.1.1.4.3.3" xref="S4.E4.m1.4.4.1.1.1.1.4.3.3.cmml">q</mi></msub><mo id="S4.E4.m1.4.4.1.1.1.1.4.2" xref="S4.E4.m1.4.4.1.1.1.1.4.2.cmml">⁢</mo><mrow id="S4.E4.m1.4.4.1.1.1.1.4.1.1" xref="S4.E4.m1.4.4.1.1.1.1.4.cmml"><mo id="S4.E4.m1.4.4.1.1.1.1.4.1.1.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.1.1.4.cmml">(</mo><mrow id="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.2" xref="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.1.cmml"><mo id="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.2.1" stretchy="false" xref="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.1.1.cmml">[</mo><mi id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">𝙼𝙰𝚂𝙺</mi><mo id="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.2.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E4.m1.4.4.1.1.1.1.4.1.1.3" stretchy="false" xref="S4.E4.m1.4.4.1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E4.m1.4.4.1.1.2.3" xref="S4.E4.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.2" xref="S4.E4.m1.4.4.1.1.2.2.3.cmml"><mrow id="S4.E4.m1.4.4.1.1.2.2.1.1" xref="S4.E4.m1.4.4.1.1.2.2.1.1.cmml"><msub id="S4.E4.m1.4.4.1.1.2.2.1.1.3" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3.cmml"><mi id="S4.E4.m1.4.4.1.1.2.2.1.1.3.2" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3.2.cmml">g</mi><mi id="S4.E4.m1.4.4.1.1.2.2.1.1.3.3" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3.3.cmml">k</mi></msub><mo id="S4.E4.m1.4.4.1.1.2.2.1.1.2" xref="S4.E4.m1.4.4.1.1.2.2.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1" xref="S4.E4.m1.4.4.1.1.2.2.1.1.cmml"><mo id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.1.1.cmml">(</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.2" xref="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml"><mo id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.2.1" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml">[</mo><mi id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml">𝚃𝙶𝚃</mi><mo id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.2.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.3" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.4.4.1.1.2.2.2.3" xref="S4.E4.m1.4.4.1.1.2.2.3.cmml">,</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.2.2" xref="S4.E4.m1.4.4.1.1.2.2.2.2.cmml"><msub id="S4.E4.m1.4.4.1.1.2.2.2.2.3" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3.cmml"><mi id="S4.E4.m1.4.4.1.1.2.2.2.2.3.2" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3.2.cmml">g</mi><mi id="S4.E4.m1.4.4.1.1.2.2.2.2.3.3" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3.3.cmml">v</mi></msub><mo id="S4.E4.m1.4.4.1.1.2.2.2.2.2" xref="S4.E4.m1.4.4.1.1.2.2.2.2.2.cmml">⁢</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1" xref="S4.E4.m1.4.4.1.1.2.2.2.2.cmml"><mo id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.2.2.cmml">(</mo><mrow id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.2" xref="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.1.cmml"><mo id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.2.1" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml">[</mo><mi id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml">𝚃𝙶𝚃</mi><mo id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.2.2" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml">]</mo></mrow><mo id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.3" stretchy="false" xref="S4.E4.m1.4.4.1.1.2.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E4.m1.4.4.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.4b"><apply id="S4.E4.m1.4.4.1.1.3.cmml" xref="S4.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.3a.cmml" xref="S4.E4.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S4.E4.m1.4.4.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1"><eq id="S4.E4.m1.4.4.1.1.1.1.5.cmml" xref="S4.E4.m1.4.4.1.1.1.1.5"></eq><list id="S4.E4.m1.4.4.1.1.1.1.3.4.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3"><apply id="S4.E4.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.1.1.1.1.1.2a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.2">q</mtext></ci><ci id="S4.E4.m1.4.4.1.1.1.1.1.1.1.3a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.3"><mtext id="S4.E4.m1.4.4.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S4.E4.m1.4.4.1.1.1.1.1.1.1.3">mask</mtext></ci></apply><apply id="S4.E4.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.1.1.2.2.2.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.1.1.2.2.2.2a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.2.2.2.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.2">k</mtext></ci><ci id="S4.E4.m1.4.4.1.1.1.1.2.2.2.3a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.3"><mtext id="S4.E4.m1.4.4.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S4.E4.m1.4.4.1.1.1.1.2.2.2.3">tgt</mtext></ci></apply><apply id="S4.E4.m1.4.4.1.1.1.1.3.3.3.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.1.1.3.3.3.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.1.1.3.3.3.2a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S4.E4.m1.4.4.1.1.1.1.3.3.3.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.2">v</mtext></ci><ci id="S4.E4.m1.4.4.1.1.1.1.3.3.3.3a.cmml" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.3"><mtext id="S4.E4.m1.4.4.1.1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S4.E4.m1.4.4.1.1.1.1.3.3.3.3">tgt</mtext></ci></apply></list><apply id="S4.E4.m1.4.4.1.1.1.1.4.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4"><times id="S4.E4.m1.4.4.1.1.1.1.4.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.2"></times><apply id="S4.E4.m1.4.4.1.1.1.1.4.3.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.1.1.4.3.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.3">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.1.1.4.3.2.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.3.2">𝑔</ci><ci id="S4.E4.m1.4.4.1.1.1.1.4.3.3.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.3.3">𝑞</ci></apply><apply id="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.2"><csymbol cd="latexml" id="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.1.1.4.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">𝙼𝙰𝚂𝙺</ci></apply></apply></apply><list id="S4.E4.m1.4.4.1.1.2.2.3.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2"><apply id="S4.E4.m1.4.4.1.1.2.2.1.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1"><times id="S4.E4.m1.4.4.1.1.2.2.1.1.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.2"></times><apply id="S4.E4.m1.4.4.1.1.2.2.1.1.3.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.2.2.1.1.3.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.2.2.1.1.3.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3.2">𝑔</ci><ci id="S4.E4.m1.4.4.1.1.2.2.1.1.3.3.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.3.3">𝑘</ci></apply><apply id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.2"><csymbol cd="latexml" id="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.1.1.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2">𝚃𝙶𝚃</ci></apply></apply><apply id="S4.E4.m1.4.4.1.1.2.2.2.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2"><times id="S4.E4.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.2"></times><apply id="S4.E4.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.1.1.2.2.2.2.3.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3">subscript</csymbol><ci id="S4.E4.m1.4.4.1.1.2.2.2.2.3.2.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3.2">𝑔</ci><ci id="S4.E4.m1.4.4.1.1.2.2.2.2.3.3.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.3.3">𝑣</ci></apply><apply id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.2"><csymbol cd="latexml" id="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E4.m1.4.4.1.1.2.2.2.2.1.1.1.2.1">delimited-[]</csymbol><ci id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3">𝚃𝙶𝚃</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.4c">\displaystyle\textbf{q}_{\text{mask}},\textbf{k}_{\text{tgt}},\textbf{v}_{%
\text{tgt}}=g_{q}(\mathtt{[MASK]}),g_{k}(\mathtt{[TGT]}),g_{v}(\mathtt{[TGT]}),</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.4d">q start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT , k start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT , v start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( [ typewriter_MASK ] ) , italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( [ typewriter_TGT ] ) , italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( [ typewriter_TGT ] ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p4.10">where <math alttext="\mathcal{M}_{\text{mask}}\in\mathbb{R}^{m\times n}" class="ltx_Math" display="inline" id="S4.p4.10.m1.1"><semantics id="S4.p4.10.m1.1a"><mrow id="S4.p4.10.m1.1.1" xref="S4.p4.10.m1.1.1.cmml"><msub id="S4.p4.10.m1.1.1.2" xref="S4.p4.10.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p4.10.m1.1.1.2.2" xref="S4.p4.10.m1.1.1.2.2.cmml">ℳ</mi><mtext id="S4.p4.10.m1.1.1.2.3" xref="S4.p4.10.m1.1.1.2.3a.cmml">mask</mtext></msub><mo id="S4.p4.10.m1.1.1.1" xref="S4.p4.10.m1.1.1.1.cmml">∈</mo><msup id="S4.p4.10.m1.1.1.3" xref="S4.p4.10.m1.1.1.3.cmml"><mi id="S4.p4.10.m1.1.1.3.2" xref="S4.p4.10.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S4.p4.10.m1.1.1.3.3" xref="S4.p4.10.m1.1.1.3.3.cmml"><mi id="S4.p4.10.m1.1.1.3.3.2" xref="S4.p4.10.m1.1.1.3.3.2.cmml">m</mi><mo id="S4.p4.10.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S4.p4.10.m1.1.1.3.3.1.cmml">×</mo><mi id="S4.p4.10.m1.1.1.3.3.3" xref="S4.p4.10.m1.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.10.m1.1b"><apply id="S4.p4.10.m1.1.1.cmml" xref="S4.p4.10.m1.1.1"><in id="S4.p4.10.m1.1.1.1.cmml" xref="S4.p4.10.m1.1.1.1"></in><apply id="S4.p4.10.m1.1.1.2.cmml" xref="S4.p4.10.m1.1.1.2"><csymbol cd="ambiguous" id="S4.p4.10.m1.1.1.2.1.cmml" xref="S4.p4.10.m1.1.1.2">subscript</csymbol><ci id="S4.p4.10.m1.1.1.2.2.cmml" xref="S4.p4.10.m1.1.1.2.2">ℳ</ci><ci id="S4.p4.10.m1.1.1.2.3a.cmml" xref="S4.p4.10.m1.1.1.2.3"><mtext id="S4.p4.10.m1.1.1.2.3.cmml" mathsize="70%" xref="S4.p4.10.m1.1.1.2.3">mask</mtext></ci></apply><apply id="S4.p4.10.m1.1.1.3.cmml" xref="S4.p4.10.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p4.10.m1.1.1.3.1.cmml" xref="S4.p4.10.m1.1.1.3">superscript</csymbol><ci id="S4.p4.10.m1.1.1.3.2.cmml" xref="S4.p4.10.m1.1.1.3.2">ℝ</ci><apply id="S4.p4.10.m1.1.1.3.3.cmml" xref="S4.p4.10.m1.1.1.3.3"><times id="S4.p4.10.m1.1.1.3.3.1.cmml" xref="S4.p4.10.m1.1.1.3.3.1"></times><ci id="S4.p4.10.m1.1.1.3.3.2.cmml" xref="S4.p4.10.m1.1.1.3.3.2">𝑚</ci><ci id="S4.p4.10.m1.1.1.3.3.3.cmml" xref="S4.p4.10.m1.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.10.m1.1c">\mathcal{M}_{\text{mask}}\in\mathbb{R}^{m\times n}</annotation><annotation encoding="application/x-llamapun" id="S4.p4.10.m1.1d">caligraphic_M start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_n end_POSTSUPERSCRIPT</annotation></semantics></math> is obtained by</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{M}_{\text{mask}}(i,j)=\begin{cases}0,&amp;\text{if mask${}_{i}$ contains %
any patch${}_{j}$'s pixel},\\
-\infty,&amp;\text{otherwise}.\end{cases}" class="ltx_Math" display="block" id="S4.E5.m1.7"><semantics id="S4.E5.m1.7a"><mrow id="S4.E5.m1.7.8" xref="S4.E5.m1.7.8.cmml"><mrow id="S4.E5.m1.7.8.2" xref="S4.E5.m1.7.8.2.cmml"><msub id="S4.E5.m1.7.8.2.2" xref="S4.E5.m1.7.8.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.7.8.2.2.2" xref="S4.E5.m1.7.8.2.2.2.cmml">ℳ</mi><mtext id="S4.E5.m1.7.8.2.2.3" xref="S4.E5.m1.7.8.2.2.3a.cmml">mask</mtext></msub><mo id="S4.E5.m1.7.8.2.1" xref="S4.E5.m1.7.8.2.1.cmml">⁢</mo><mrow id="S4.E5.m1.7.8.2.3.2" xref="S4.E5.m1.7.8.2.3.1.cmml"><mo id="S4.E5.m1.7.8.2.3.2.1" stretchy="false" xref="S4.E5.m1.7.8.2.3.1.cmml">(</mo><mi id="S4.E5.m1.6.6" xref="S4.E5.m1.6.6.cmml">i</mi><mo id="S4.E5.m1.7.8.2.3.2.2" xref="S4.E5.m1.7.8.2.3.1.cmml">,</mo><mi id="S4.E5.m1.7.7" xref="S4.E5.m1.7.7.cmml">j</mi><mo id="S4.E5.m1.7.8.2.3.2.3" stretchy="false" xref="S4.E5.m1.7.8.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.7.8.1" xref="S4.E5.m1.7.8.1.cmml">=</mo><mrow id="S4.E5.m1.5.5" xref="S4.E5.m1.7.8.3.1.cmml"><mo id="S4.E5.m1.5.5.6" xref="S4.E5.m1.7.8.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S4.E5.m1.5.5.5" rowspacing="0pt" xref="S4.E5.m1.7.8.3.1.cmml"><mtr id="S4.E5.m1.5.5.5a" xref="S4.E5.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.5.5.5b" xref="S4.E5.m1.7.8.3.1.cmml"><mrow id="S4.E5.m1.3.3.3.3.3.1.3" xref="S4.E5.m1.7.8.3.1.cmml"><mn id="S4.E5.m1.3.3.3.3.3.1.1" xref="S4.E5.m1.3.3.3.3.3.1.1.cmml">0</mn><mo id="S4.E5.m1.3.3.3.3.3.1.3.1" xref="S4.E5.m1.7.8.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.5.5.5c" xref="S4.E5.m1.7.8.3.1.cmml"><mrow id="S4.E5.m1.2.2.2.2.2.2.4" xref="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml"><mrow id="S4.E5.m1.2.2.2.2.2.2.2.2" xref="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml"><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2a" xref="S4.E5.m1.2.2.2.2.2.2.2.2a.cmml">if mask</mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2b" xref="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml"><sub class="ltx_sub" id="S4.E5.m1.2.2.2.2.2.2.2.2.3nest"><span class="ltx_text ltx_font_italic" id="S4.E5.m1.2.2.2.2.2.2.2.2.3.1nest">i</span></sub></mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2e" xref="S4.E5.m1.2.2.2.2.2.2.2.2a.cmml"> contains any patch</mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2f" xref="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml"><sub class="ltx_sub" id="S4.E5.m1.2.2.2.2.2.2.2.2.4nest"><span class="ltx_text ltx_font_italic" id="S4.E5.m1.2.2.2.2.2.2.2.2.4.1nest">j</span></sub></mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2i" xref="S4.E5.m1.2.2.2.2.2.2.2.2a.cmml">’s pixel</mtext></mrow><mo id="S4.E5.m1.2.2.2.2.2.2.4.1" xref="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml">,</mo></mrow></mtd></mtr><mtr id="S4.E5.m1.5.5.5d" xref="S4.E5.m1.7.8.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.5.5.5e" xref="S4.E5.m1.7.8.3.1.cmml"><mrow id="S4.E5.m1.4.4.4.4.1.1.1" xref="S4.E5.m1.4.4.4.4.1.1.1.1.cmml"><mrow id="S4.E5.m1.4.4.4.4.1.1.1.1" xref="S4.E5.m1.4.4.4.4.1.1.1.1.cmml"><mo id="S4.E5.m1.4.4.4.4.1.1.1.1a" xref="S4.E5.m1.4.4.4.4.1.1.1.1.cmml">−</mo><mi id="S4.E5.m1.4.4.4.4.1.1.1.1.2" mathvariant="normal" xref="S4.E5.m1.4.4.4.4.1.1.1.1.2.cmml">∞</mi></mrow><mo id="S4.E5.m1.4.4.4.4.1.1.1.2" xref="S4.E5.m1.4.4.4.4.1.1.1.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.5.5.5f" xref="S4.E5.m1.7.8.3.1.cmml"><mrow id="S4.E5.m1.5.5.5.5.2.1.3" xref="S4.E5.m1.5.5.5.5.2.1.1a.cmml"><mtext id="S4.E5.m1.5.5.5.5.2.1.1" xref="S4.E5.m1.5.5.5.5.2.1.1.cmml">otherwise</mtext><mo id="S4.E5.m1.5.5.5.5.2.1.3.1" lspace="0em" xref="S4.E5.m1.5.5.5.5.2.1.1a.cmml">.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.7b"><apply id="S4.E5.m1.7.8.cmml" xref="S4.E5.m1.7.8"><eq id="S4.E5.m1.7.8.1.cmml" xref="S4.E5.m1.7.8.1"></eq><apply id="S4.E5.m1.7.8.2.cmml" xref="S4.E5.m1.7.8.2"><times id="S4.E5.m1.7.8.2.1.cmml" xref="S4.E5.m1.7.8.2.1"></times><apply id="S4.E5.m1.7.8.2.2.cmml" xref="S4.E5.m1.7.8.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.7.8.2.2.1.cmml" xref="S4.E5.m1.7.8.2.2">subscript</csymbol><ci id="S4.E5.m1.7.8.2.2.2.cmml" xref="S4.E5.m1.7.8.2.2.2">ℳ</ci><ci id="S4.E5.m1.7.8.2.2.3a.cmml" xref="S4.E5.m1.7.8.2.2.3"><mtext id="S4.E5.m1.7.8.2.2.3.cmml" mathsize="70%" xref="S4.E5.m1.7.8.2.2.3">mask</mtext></ci></apply><interval closure="open" id="S4.E5.m1.7.8.2.3.1.cmml" xref="S4.E5.m1.7.8.2.3.2"><ci id="S4.E5.m1.6.6.cmml" xref="S4.E5.m1.6.6">𝑖</ci><ci id="S4.E5.m1.7.7.cmml" xref="S4.E5.m1.7.7">𝑗</ci></interval></apply><apply id="S4.E5.m1.7.8.3.1.cmml" xref="S4.E5.m1.5.5"><csymbol cd="latexml" id="S4.E5.m1.7.8.3.1.1.cmml" xref="S4.E5.m1.5.5.6">cases</csymbol><cn id="S4.E5.m1.3.3.3.3.3.1.1.cmml" type="integer" xref="S4.E5.m1.3.3.3.3.3.1.1">0</cn><ci id="S4.E5.m1.2.2.2.2.2.2.2.2j.cmml" xref="S4.E5.m1.2.2.2.2.2.2.4"><mrow id="S4.E5.m1.2.2.2.2.2.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2.2.2.4"><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2a.cmml" xref="S4.E5.m1.2.2.2.2.2.2.2.2a">if mask</mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2b.cmml" xref="S4.E5.m1.2.2.2.2.2.2.4"><sub class="ltx_sub" id="S4.E5.m1.2.2.2.2.2.2.2.2.3anest"><span class="ltx_text ltx_font_italic" id="S4.E5.m1.2.2.2.2.2.2.2.2.3.1anest">i</span></sub></mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2e.cmml" xref="S4.E5.m1.2.2.2.2.2.2.2.2a"> contains any patch</mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2f.cmml" xref="S4.E5.m1.2.2.2.2.2.2.4"><sub class="ltx_sub" id="S4.E5.m1.2.2.2.2.2.2.2.2.4anest"><span class="ltx_text ltx_font_italic" id="S4.E5.m1.2.2.2.2.2.2.2.2.4.1anest">j</span></sub></mtext><mtext id="S4.E5.m1.2.2.2.2.2.2.2.2i.cmml" xref="S4.E5.m1.2.2.2.2.2.2.2.2a">’s pixel</mtext></mrow></ci><apply id="S4.E5.m1.4.4.4.4.1.1.1.1.cmml" xref="S4.E5.m1.4.4.4.4.1.1.1"><minus id="S4.E5.m1.4.4.4.4.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.4.4.1.1.1"></minus><infinity id="S4.E5.m1.4.4.4.4.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.4.4.1.1.1.1.2"></infinity></apply><ci id="S4.E5.m1.5.5.5.5.2.1.1a.cmml" xref="S4.E5.m1.5.5.5.5.2.1.3"><mtext id="S4.E5.m1.5.5.5.5.2.1.1.cmml" xref="S4.E5.m1.5.5.5.5.2.1.1">otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.7c">\mathcal{M}_{\text{mask}}(i,j)=\begin{cases}0,&amp;\text{if mask${}_{i}$ contains %
any patch${}_{j}$'s pixel},\\
-\infty,&amp;\text{otherwise}.\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.7d">caligraphic_M start_POSTSUBSCRIPT mask end_POSTSUBSCRIPT ( italic_i , italic_j ) = { start_ROW start_CELL 0 , end_CELL start_CELL if mask contains any patch ’s pixel , end_CELL end_ROW start_ROW start_CELL - ∞ , end_CELL start_CELL otherwise . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p4.11">Self-attention for image tokens is omitted here for brevity, as it remains unchanged and follows the original CLIP model.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p5">
<p class="ltx_p" id="S4.p5.10"><span class="ltx_text ltx_font_bold" id="S4.p5.10.1">Query Projection Tuning (QPT).</span> While foundation models like CLIP already possess the necessary knowledge for open-vocabulary tasks, they often need some fine-tuning to adapt to new distributions. To guide our fine-tuning method, we revisit the Probably Approximately Correct (PAC) learning framework <cite class="ltx_cite ltx_citemacro_citep">(Shalev-Shwartz and Ben-David <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib39" title="">2014</a>)</cite>. PAC explains a learning algorithm’s generalization capability by relating it to the complexity of its hypothesis class <math alttext="\mathcal{H}" class="ltx_Math" display="inline" id="S4.p5.1.m1.1"><semantics id="S4.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><ci id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">\mathcal{H}</annotation><annotation encoding="application/x-llamapun" id="S4.p5.1.m1.1d">caligraphic_H</annotation></semantics></math> (i.e., the number of trainable parameters). Specifically, PAC connects the hypothesis class <math alttext="\mathcal{H}" class="ltx_Math" display="inline" id="S4.p5.2.m2.1"><semantics id="S4.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><ci id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">\mathcal{H}</annotation><annotation encoding="application/x-llamapun" id="S4.p5.2.m2.1d">caligraphic_H</annotation></semantics></math>, a confidence level <math alttext="\delta" class="ltx_Math" display="inline" id="S4.p5.3.m3.1"><semantics id="S4.p5.3.m3.1a"><mi id="S4.p5.3.m3.1.1" xref="S4.p5.3.m3.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.3.m3.1b"><ci id="S4.p5.3.m3.1.1.cmml" xref="S4.p5.3.m3.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.3.m3.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S4.p5.3.m3.1d">italic_δ</annotation></semantics></math>, and a desired accuracy <math alttext="\epsilon" class="ltx_Math" display="inline" id="S4.p5.4.m4.1"><semantics id="S4.p5.4.m4.1a"><mi id="S4.p5.4.m4.1.1" xref="S4.p5.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.4.m4.1b"><ci id="S4.p5.4.m4.1.1.cmml" xref="S4.p5.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.4.m4.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S4.p5.4.m4.1d">italic_ϵ</annotation></semantics></math> to determine the minimum sample size <math alttext="m" class="ltx_Math" display="inline" id="S4.p5.5.m5.1"><semantics id="S4.p5.5.m5.1a"><mi id="S4.p5.5.m5.1.1" xref="S4.p5.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.p5.5.m5.1b"><ci id="S4.p5.5.m5.1.1.cmml" xref="S4.p5.5.m5.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.5.m5.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.p5.5.m5.1d">italic_m</annotation></semantics></math> required for effective generalization, given by <math alttext="m\geq\frac{\log(|\mathcal{H}|/\delta)}{\epsilon}" class="ltx_Math" display="inline" id="S4.p5.6.m6.3"><semantics id="S4.p5.6.m6.3a"><mrow id="S4.p5.6.m6.3.4" xref="S4.p5.6.m6.3.4.cmml"><mi id="S4.p5.6.m6.3.4.2" xref="S4.p5.6.m6.3.4.2.cmml">m</mi><mo id="S4.p5.6.m6.3.4.1" xref="S4.p5.6.m6.3.4.1.cmml">≥</mo><mfrac id="S4.p5.6.m6.3.3" xref="S4.p5.6.m6.3.3.cmml"><mrow id="S4.p5.6.m6.3.3.3.3" xref="S4.p5.6.m6.3.3.3.4.cmml"><mi id="S4.p5.6.m6.2.2.2.2" xref="S4.p5.6.m6.2.2.2.2.cmml">log</mi><mo id="S4.p5.6.m6.3.3.3.3a" xref="S4.p5.6.m6.3.3.3.4.cmml">⁡</mo><mrow id="S4.p5.6.m6.3.3.3.3.1" xref="S4.p5.6.m6.3.3.3.4.cmml"><mo id="S4.p5.6.m6.3.3.3.3.1.2" stretchy="false" xref="S4.p5.6.m6.3.3.3.4.cmml">(</mo><mrow id="S4.p5.6.m6.3.3.3.3.1.1" xref="S4.p5.6.m6.3.3.3.3.1.1.cmml"><mrow id="S4.p5.6.m6.3.3.3.3.1.1.2.2" xref="S4.p5.6.m6.3.3.3.3.1.1.2.1.cmml"><mo id="S4.p5.6.m6.3.3.3.3.1.1.2.2.1" stretchy="false" xref="S4.p5.6.m6.3.3.3.3.1.1.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S4.p5.6.m6.1.1.1.1" xref="S4.p5.6.m6.1.1.1.1.cmml">ℋ</mi><mo id="S4.p5.6.m6.3.3.3.3.1.1.2.2.2" stretchy="false" xref="S4.p5.6.m6.3.3.3.3.1.1.2.1.1.cmml">|</mo></mrow><mo id="S4.p5.6.m6.3.3.3.3.1.1.1" xref="S4.p5.6.m6.3.3.3.3.1.1.1.cmml">/</mo><mi id="S4.p5.6.m6.3.3.3.3.1.1.3" xref="S4.p5.6.m6.3.3.3.3.1.1.3.cmml">δ</mi></mrow><mo id="S4.p5.6.m6.3.3.3.3.1.3" stretchy="false" xref="S4.p5.6.m6.3.3.3.4.cmml">)</mo></mrow></mrow><mi id="S4.p5.6.m6.3.3.5" xref="S4.p5.6.m6.3.3.5.cmml">ϵ</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.6.m6.3b"><apply id="S4.p5.6.m6.3.4.cmml" xref="S4.p5.6.m6.3.4"><geq id="S4.p5.6.m6.3.4.1.cmml" xref="S4.p5.6.m6.3.4.1"></geq><ci id="S4.p5.6.m6.3.4.2.cmml" xref="S4.p5.6.m6.3.4.2">𝑚</ci><apply id="S4.p5.6.m6.3.3.cmml" xref="S4.p5.6.m6.3.3"><divide id="S4.p5.6.m6.3.3.4.cmml" xref="S4.p5.6.m6.3.3"></divide><apply id="S4.p5.6.m6.3.3.3.4.cmml" xref="S4.p5.6.m6.3.3.3.3"><log id="S4.p5.6.m6.2.2.2.2.cmml" xref="S4.p5.6.m6.2.2.2.2"></log><apply id="S4.p5.6.m6.3.3.3.3.1.1.cmml" xref="S4.p5.6.m6.3.3.3.3.1.1"><divide id="S4.p5.6.m6.3.3.3.3.1.1.1.cmml" xref="S4.p5.6.m6.3.3.3.3.1.1.1"></divide><apply id="S4.p5.6.m6.3.3.3.3.1.1.2.1.cmml" xref="S4.p5.6.m6.3.3.3.3.1.1.2.2"><abs id="S4.p5.6.m6.3.3.3.3.1.1.2.1.1.cmml" xref="S4.p5.6.m6.3.3.3.3.1.1.2.2.1"></abs><ci id="S4.p5.6.m6.1.1.1.1.cmml" xref="S4.p5.6.m6.1.1.1.1">ℋ</ci></apply><ci id="S4.p5.6.m6.3.3.3.3.1.1.3.cmml" xref="S4.p5.6.m6.3.3.3.3.1.1.3">𝛿</ci></apply></apply><ci id="S4.p5.6.m6.3.3.5.cmml" xref="S4.p5.6.m6.3.3.5">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.6.m6.3c">m\geq\frac{\log(|\mathcal{H}|/\delta)}{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S4.p5.6.m6.3d">italic_m ≥ divide start_ARG roman_log ( | caligraphic_H | / italic_δ ) end_ARG start_ARG italic_ϵ end_ARG</annotation></semantics></math>. This theorem suggests that when the sample size is fixed, reducing the model’s parameters, thereby shrinking <math alttext="\mathcal{H}" class="ltx_Math" display="inline" id="S4.p5.7.m7.1"><semantics id="S4.p5.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S4.p5.7.m7.1.1" xref="S4.p5.7.m7.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.7.m7.1b"><ci id="S4.p5.7.m7.1.1.cmml" xref="S4.p5.7.m7.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.7.m7.1c">\mathcal{H}</annotation><annotation encoding="application/x-llamapun" id="S4.p5.7.m7.1d">caligraphic_H</annotation></semantics></math>, can decrease the necessary sample size <math alttext="m" class="ltx_Math" display="inline" id="S4.p5.8.m8.1"><semantics id="S4.p5.8.m8.1a"><mi id="S4.p5.8.m8.1.1" xref="S4.p5.8.m8.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.p5.8.m8.1b"><ci id="S4.p5.8.m8.1.1.cmml" xref="S4.p5.8.m8.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.8.m8.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.p5.8.m8.1d">italic_m</annotation></semantics></math> to achieve the same accuracy <math alttext="\epsilon" class="ltx_Math" display="inline" id="S4.p5.9.m9.1"><semantics id="S4.p5.9.m9.1a"><mi id="S4.p5.9.m9.1.1" xref="S4.p5.9.m9.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.p5.9.m9.1b"><ci id="S4.p5.9.m9.1.1.cmml" xref="S4.p5.9.m9.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.9.m9.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S4.p5.9.m9.1d">italic_ϵ</annotation></semantics></math> at the same confidence level <math alttext="1-\delta" class="ltx_Math" display="inline" id="S4.p5.10.m10.1"><semantics id="S4.p5.10.m10.1a"><mrow id="S4.p5.10.m10.1.1" xref="S4.p5.10.m10.1.1.cmml"><mn id="S4.p5.10.m10.1.1.2" xref="S4.p5.10.m10.1.1.2.cmml">1</mn><mo id="S4.p5.10.m10.1.1.1" xref="S4.p5.10.m10.1.1.1.cmml">−</mo><mi id="S4.p5.10.m10.1.1.3" xref="S4.p5.10.m10.1.1.3.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.10.m10.1b"><apply id="S4.p5.10.m10.1.1.cmml" xref="S4.p5.10.m10.1.1"><minus id="S4.p5.10.m10.1.1.1.cmml" xref="S4.p5.10.m10.1.1.1"></minus><cn id="S4.p5.10.m10.1.1.2.cmml" type="integer" xref="S4.p5.10.m10.1.1.2">1</cn><ci id="S4.p5.10.m10.1.1.3.cmml" xref="S4.p5.10.m10.1.1.3">𝛿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.10.m10.1c">1-\delta</annotation><annotation encoding="application/x-llamapun" id="S4.p5.10.m10.1d">1 - italic_δ</annotation></semantics></math>. When applied to CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>)</cite>, this principle highlights the importance of fine-tuning as few parameters as possible for effective cross-domain generalization. Based on this insight, we propose QPT, a method that diverges from traditional approaches by selectively fine-tuning only the <span class="ltx_text ltx_font_italic" id="S4.p5.10.2">query projection layers</span> within each attention block of CLIP, rather than freezing the entire model. We hypothesize that this targeted fine-tuning approach, which solely refines the parameters influencing the image focus of mask tokens, is sufficient to enable efficient and effective domain adaptation to new contexts. Empirical evidence (Tables. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T2" title="Table 2 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a>,<a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>) supports our hypothesis, demonstrating our method’s effectiveness in facilitating domain adaptation for open-vocabulary tasks while maintaining computational efficiency.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.4" style="width:433.6pt;height:135.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-129.9pt,40.5pt) scale(0.625362316177526,0.625362316177526) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T1.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.2" rowspan="2"><span class="ltx_text" id="S4.T1.1.1.1.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.3">Feature</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.4">VLM</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S4.T1.1.1.1.1">COCO<sup class="ltx_sup" id="S4.T1.1.1.1.1.1">∗</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S4.T1.1.1.1.5">ADE150</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S4.T1.1.1.1.6">Mapillary</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.7">ADE847</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.8">PC59</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.9">PC459</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.5.1">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.1">Backbone</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.2">Backbone</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.5.1.3">PQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.4">mIoU</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.5.1.5">PQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.6">mIoU</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.5.1.7">PQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.8">mIoU</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.9">mIoU</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.5.1.10">mIoU</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.5.1.11">mIoU</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.1">OVSeg<sup class="ltx_sup" id="S4.T1.2.2.2.1.1">†</sup> <cite class="ltx_cite ltx_citemacro_citep">(Liang et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib27" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.3">ViT-L/14-336</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.7">29.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.10">9.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.11">57.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.12">15.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.1">SAN<sup class="ltx_sup" id="S4.T1.3.3.3.1.1">†</sup> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib46" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.3">ViT-L/14-336</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.7">33.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.10">13.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.3.11">60.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3.12">17.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.1">SED<sup class="ltx_sup" id="S4.T1.4.4.4.1.1">†</sup> <cite class="ltx_cite ltx_citemacro_citep">(Xie et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib44" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.3">ConvNeXt-L</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.7">35.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.10">13.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.11">60.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4.12">22.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.6.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.1">MaskCLIP <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.2">ResNet50</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.3">ViT-L/14-336</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.6.2.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.6.2.6">15.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.7">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.6.2.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.10">8.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.6.2.11">45.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.6.2.12">10.0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.7.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.1">FreeSeg <cite class="ltx_cite ltx_citemacro_citep">(Qin et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib36" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.2">ResNet101</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.3">ViT-B/16</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.7.3.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.7.3.6">16.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.7">24.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.7.3.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.7.3.11">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.7.3.12">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.8.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.1">ODISE <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib45" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.2">SD v1.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.3">ViT-L/14-336</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.8.4.4">55.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.5">65.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.8.4.6">22.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.7">29.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.8.4.8">14.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.10">11.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.8.4.11">57.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.8.4.12">14.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.9.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.1">MasQCLIP <cite class="ltx_cite ltx_citemacro_citep">(Xu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib48" title="">2023c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.2">ResNet50</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.3">ViT-L/14-336</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.9.5.4">48.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.5">62.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.9.5.6">23.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.7">30.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.9.5.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.10">10.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.9.5.11">57.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.9.5.12">18.2</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.10.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.1">FC-CLIP <cite class="ltx_cite ltx_citemacro_citep">(Yu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib49" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.3">ConvNeXt-L</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.10.6.4">54.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.5">63.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.10.6.6">26.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.7">34.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.10.6.8">18.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.9">27.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.10">14.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.10.6.11">58.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.10.6.12">18.2</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.11.7" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.1"><span class="ltx_text" id="S4.T1.4.4.11.7.1.1" style="background-color:#E6E6E6;">SMART-R50 (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.2"><span class="ltx_text" id="S4.T1.4.4.11.7.2.1" style="background-color:#E6E6E6;">ResNet50</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.3"><span class="ltx_text" id="S4.T1.4.4.11.7.3.1" style="background-color:#E6E6E6;">ViT-L/14-336</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.11.7.4"><span class="ltx_text" id="S4.T1.4.4.11.7.4.1" style="background-color:#E6E6E6;">51.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.5"><span class="ltx_text" id="S4.T1.4.4.11.7.5.1" style="background-color:#E6E6E6;">61.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.11.7.6"><span class="ltx_text" id="S4.T1.4.4.11.7.6.1" style="background-color:#E6E6E6;">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.7"><span class="ltx_text" id="S4.T1.4.4.11.7.7.1" style="background-color:#E6E6E6;">35.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.11.7.8"><span class="ltx_text" id="S4.T1.4.4.11.7.8.1" style="background-color:#E6E6E6;">16.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.9"><span class="ltx_text" id="S4.T1.4.4.11.7.9.1" style="background-color:#E6E6E6;">28.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.10"><span class="ltx_text" id="S4.T1.4.4.11.7.10.1" style="background-color:#E6E6E6;">15.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.11.7.11"><span class="ltx_text" id="S4.T1.4.4.11.7.11.1" style="background-color:#E6E6E6;">61.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.11.7.12"><span class="ltx_text" id="S4.T1.4.4.11.7.12.1" style="background-color:#E6E6E6;">22.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.12.8" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.1"><span class="ltx_text" id="S4.T1.4.4.12.8.1.1" style="background-color:#E6E6E6;">SMART-SwinB (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.2"><span class="ltx_text" id="S4.T1.4.4.12.8.2.1" style="background-color:#E6E6E6;">Swin-B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.3"><span class="ltx_text" id="S4.T1.4.4.12.8.3.1" style="background-color:#E6E6E6;">ViT-L/14-336</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.12.8.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.4.1" style="background-color:#E6E6E6;">56.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.5.1" style="background-color:#E6E6E6;">67.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.12.8.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.6.1" style="background-color:#E6E6E6;">28.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.7"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.7.1" style="background-color:#E6E6E6;">36.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.12.8.8"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.8.1" style="background-color:#E6E6E6;">19.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.9"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.9.1" style="background-color:#E6E6E6;">29.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.10"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.10.1" style="background-color:#E6E6E6;">16.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.4.4.12.8.11"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.11.1" style="background-color:#E6E6E6;">62.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.12.8.12"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.12.8.12.1" style="background-color:#E6E6E6;">23.6</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison with leading open-vocabulary panoptic segmentation and semantic segmentation methods. Feature backbone refers to backbone used for mask generation or mask refinement. <sup class="ltx_sup" id="S4.T1.12.1">†</sup> indicates models that can only perform semantic segmentation. <sup class="ltx_sup" id="S4.T1.13.2">∗</sup> indicates close-vocabulary evaluation. <span class="ltx_text ltx_font_bold" id="S4.T1.14.3">Bold</span> indicates best.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p6">
<p class="ltx_p" id="S4.p6.3"><span class="ltx_text ltx_font_bold" id="S4.p6.3.1">Loss Function.</span> Following prior work <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite>, our loss function combines cross-entropy loss <math alttext="\mathcal{L}_{\text{CE}}" class="ltx_Math" display="inline" id="S4.p6.1.m1.1"><semantics id="S4.p6.1.m1.1a"><msub id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p6.1.m1.1.1.2" xref="S4.p6.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S4.p6.1.m1.1.1.3" xref="S4.p6.1.m1.1.1.3a.cmml">CE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><apply id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p6.1.m1.1.1.1.cmml" xref="S4.p6.1.m1.1.1">subscript</csymbol><ci id="S4.p6.1.m1.1.1.2.cmml" xref="S4.p6.1.m1.1.1.2">ℒ</ci><ci id="S4.p6.1.m1.1.1.3a.cmml" xref="S4.p6.1.m1.1.1.3"><mtext id="S4.p6.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.p6.1.m1.1.1.3">CE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">\mathcal{L}_{\text{CE}}</annotation><annotation encoding="application/x-llamapun" id="S4.p6.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT CE end_POSTSUBSCRIPT</annotation></semantics></math>, dice loss <math alttext="\mathcal{L}_{\text{Dice}}" class="ltx_Math" display="inline" id="S4.p6.2.m2.1"><semantics id="S4.p6.2.m2.1a"><msub id="S4.p6.2.m2.1.1" xref="S4.p6.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p6.2.m2.1.1.2" xref="S4.p6.2.m2.1.1.2.cmml">ℒ</mi><mtext id="S4.p6.2.m2.1.1.3" xref="S4.p6.2.m2.1.1.3a.cmml">Dice</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p6.2.m2.1b"><apply id="S4.p6.2.m2.1.1.cmml" xref="S4.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p6.2.m2.1.1.1.cmml" xref="S4.p6.2.m2.1.1">subscript</csymbol><ci id="S4.p6.2.m2.1.1.2.cmml" xref="S4.p6.2.m2.1.1.2">ℒ</ci><ci id="S4.p6.2.m2.1.1.3a.cmml" xref="S4.p6.2.m2.1.1.3"><mtext id="S4.p6.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.p6.2.m2.1.1.3">Dice</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.2.m2.1c">\mathcal{L}_{\text{Dice}}</annotation><annotation encoding="application/x-llamapun" id="S4.p6.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT Dice end_POSTSUBSCRIPT</annotation></semantics></math> and binary cross entropy loss <math alttext="\mathcal{L}_{\text{BCE}}" class="ltx_Math" display="inline" id="S4.p6.3.m3.1"><semantics id="S4.p6.3.m3.1a"><msub id="S4.p6.3.m3.1.1" xref="S4.p6.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.p6.3.m3.1.1.2" xref="S4.p6.3.m3.1.1.2.cmml">ℒ</mi><mtext id="S4.p6.3.m3.1.1.3" xref="S4.p6.3.m3.1.1.3a.cmml">BCE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p6.3.m3.1b"><apply id="S4.p6.3.m3.1.1.cmml" xref="S4.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p6.3.m3.1.1.1.cmml" xref="S4.p6.3.m3.1.1">subscript</csymbol><ci id="S4.p6.3.m3.1.1.2.cmml" xref="S4.p6.3.m3.1.1.2">ℒ</ci><ci id="S4.p6.3.m3.1.1.3a.cmml" xref="S4.p6.3.m3.1.1.3"><mtext id="S4.p6.3.m3.1.1.3.cmml" mathsize="70%" xref="S4.p6.3.m3.1.1.3">BCE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.3.m3.1c">\mathcal{L}_{\text{BCE}}</annotation><annotation encoding="application/x-llamapun" id="S4.p6.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT BCE end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="S6.EGx2">
<tbody id="S4.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\mathcal{L}=\lambda_{\text{CE}}\mathcal{L}_{\text{CE}}+\lambda_{%
\text{Dice}}\mathcal{L}_{\text{Dice}}+\lambda_{\text{BCE}}\mathcal{L}_{\text{%
BCE}}." class="ltx_Math" display="block" id="S4.E6.m1.1"><semantics id="S4.E6.m1.1a"><mrow id="S4.E6.m1.1.1.1" xref="S4.E6.m1.1.1.1.1.cmml"><mrow id="S4.E6.m1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.2.cmml">ℒ</mi><mo id="S4.E6.m1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.E6.m1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.3.cmml"><mrow id="S4.E6.m1.1.1.1.1.3.2" xref="S4.E6.m1.1.1.1.1.3.2.cmml"><msub id="S4.E6.m1.1.1.1.1.3.2.2" xref="S4.E6.m1.1.1.1.1.3.2.2.cmml"><mi id="S4.E6.m1.1.1.1.1.3.2.2.2" xref="S4.E6.m1.1.1.1.1.3.2.2.2.cmml">λ</mi><mtext id="S4.E6.m1.1.1.1.1.3.2.2.3" xref="S4.E6.m1.1.1.1.1.3.2.2.3a.cmml">CE</mtext></msub><mo id="S4.E6.m1.1.1.1.1.3.2.1" xref="S4.E6.m1.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="S4.E6.m1.1.1.1.1.3.2.3" xref="S4.E6.m1.1.1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.1.1.1.1.3.2.3.2" xref="S4.E6.m1.1.1.1.1.3.2.3.2.cmml">ℒ</mi><mtext id="S4.E6.m1.1.1.1.1.3.2.3.3" xref="S4.E6.m1.1.1.1.1.3.2.3.3a.cmml">CE</mtext></msub></mrow><mo id="S4.E6.m1.1.1.1.1.3.1" xref="S4.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S4.E6.m1.1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.1.3.3.cmml"><msub id="S4.E6.m1.1.1.1.1.3.3.2" xref="S4.E6.m1.1.1.1.1.3.3.2.cmml"><mi id="S4.E6.m1.1.1.1.1.3.3.2.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.cmml">λ</mi><mtext id="S4.E6.m1.1.1.1.1.3.3.2.3" xref="S4.E6.m1.1.1.1.1.3.3.2.3a.cmml">Dice</mtext></msub><mo id="S4.E6.m1.1.1.1.1.3.3.1" xref="S4.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><msub id="S4.E6.m1.1.1.1.1.3.3.3" xref="S4.E6.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.1.1.1.1.3.3.3.2" xref="S4.E6.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S4.E6.m1.1.1.1.1.3.3.3.3" xref="S4.E6.m1.1.1.1.1.3.3.3.3a.cmml">Dice</mtext></msub></mrow><mo id="S4.E6.m1.1.1.1.1.3.1a" xref="S4.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S4.E6.m1.1.1.1.1.3.4" xref="S4.E6.m1.1.1.1.1.3.4.cmml"><msub id="S4.E6.m1.1.1.1.1.3.4.2" xref="S4.E6.m1.1.1.1.1.3.4.2.cmml"><mi id="S4.E6.m1.1.1.1.1.3.4.2.2" xref="S4.E6.m1.1.1.1.1.3.4.2.2.cmml">λ</mi><mtext id="S4.E6.m1.1.1.1.1.3.4.2.3" xref="S4.E6.m1.1.1.1.1.3.4.2.3a.cmml">BCE</mtext></msub><mo id="S4.E6.m1.1.1.1.1.3.4.1" xref="S4.E6.m1.1.1.1.1.3.4.1.cmml">⁢</mo><msub id="S4.E6.m1.1.1.1.1.3.4.3" xref="S4.E6.m1.1.1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.1.1.1.1.3.4.3.2" xref="S4.E6.m1.1.1.1.1.3.4.3.2.cmml">ℒ</mi><mtext id="S4.E6.m1.1.1.1.1.3.4.3.3" xref="S4.E6.m1.1.1.1.1.3.4.3.3a.cmml">BCE</mtext></msub></mrow></mrow></mrow><mo id="S4.E6.m1.1.1.1.2" lspace="0em" xref="S4.E6.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.1b"><apply id="S4.E6.m1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1"><eq id="S4.E6.m1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1"></eq><ci id="S4.E6.m1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.2">ℒ</ci><apply id="S4.E6.m1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.3"><plus id="S4.E6.m1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.1"></plus><apply id="S4.E6.m1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.2"><times id="S4.E6.m1.1.1.1.1.3.2.1.cmml" xref="S4.E6.m1.1.1.1.1.3.2.1"></times><apply id="S4.E6.m1.1.1.1.1.3.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.E6.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.2.2.2">𝜆</ci><ci id="S4.E6.m1.1.1.1.1.3.2.2.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.2.2.3"><mtext id="S4.E6.m1.1.1.1.1.3.2.2.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.2.2.3">CE</mtext></ci></apply><apply id="S4.E6.m1.1.1.1.1.3.2.3.cmml" xref="S4.E6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.2.3.2">ℒ</ci><ci id="S4.E6.m1.1.1.1.1.3.2.3.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.2.3.3"><mtext id="S4.E6.m1.1.1.1.1.3.2.3.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.2.3.3">CE</mtext></ci></apply></apply><apply id="S4.E6.m1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3"><times id="S4.E6.m1.1.1.1.1.3.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.1"></times><apply id="S4.E6.m1.1.1.1.1.3.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2">𝜆</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.3"><mtext id="S4.E6.m1.1.1.1.1.3.3.2.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.3.2.3">Dice</mtext></ci></apply><apply id="S4.E6.m1.1.1.1.1.3.3.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.3.2">ℒ</ci><ci id="S4.E6.m1.1.1.1.1.3.3.3.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.3.3.3"><mtext id="S4.E6.m1.1.1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.3.3.3">Dice</mtext></ci></apply></apply><apply id="S4.E6.m1.1.1.1.1.3.4.cmml" xref="S4.E6.m1.1.1.1.1.3.4"><times id="S4.E6.m1.1.1.1.1.3.4.1.cmml" xref="S4.E6.m1.1.1.1.1.3.4.1"></times><apply id="S4.E6.m1.1.1.1.1.3.4.2.cmml" xref="S4.E6.m1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.4.2.1.cmml" xref="S4.E6.m1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.4.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.4.2.2">𝜆</ci><ci id="S4.E6.m1.1.1.1.1.3.4.2.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.4.2.3"><mtext id="S4.E6.m1.1.1.1.1.3.4.2.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.4.2.3">BCE</mtext></ci></apply><apply id="S4.E6.m1.1.1.1.1.3.4.3.cmml" xref="S4.E6.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.4.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.4.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.4.3.2">ℒ</ci><ci id="S4.E6.m1.1.1.1.1.3.4.3.3a.cmml" xref="S4.E6.m1.1.1.1.1.3.4.3.3"><mtext id="S4.E6.m1.1.1.1.1.3.4.3.3.cmml" mathsize="70%" xref="S4.E6.m1.1.1.1.1.3.4.3.3">BCE</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.1c">\displaystyle\mathcal{L}=\lambda_{\text{CE}}\mathcal{L}_{\text{CE}}+\lambda_{%
\text{Dice}}\mathcal{L}_{\text{Dice}}+\lambda_{\text{BCE}}\mathcal{L}_{\text{%
BCE}}.</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.1d">caligraphic_L = italic_λ start_POSTSUBSCRIPT CE end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT CE end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT Dice end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT Dice end_POSTSUBSCRIPT + italic_λ start_POSTSUBSCRIPT BCE end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT BCE end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p6.4">In our experiments, we set <math alttext="\lambda_{\text{CE}}=2,\lambda_{\text{Dice}}=5,\lambda_{\text{BCE}}=5" class="ltx_Math" display="inline" id="S4.p6.4.m1.2"><semantics id="S4.p6.4.m1.2a"><mrow id="S4.p6.4.m1.2.2.2" xref="S4.p6.4.m1.2.2.3.cmml"><mrow id="S4.p6.4.m1.1.1.1.1" xref="S4.p6.4.m1.1.1.1.1.cmml"><msub id="S4.p6.4.m1.1.1.1.1.2" xref="S4.p6.4.m1.1.1.1.1.2.cmml"><mi id="S4.p6.4.m1.1.1.1.1.2.2" xref="S4.p6.4.m1.1.1.1.1.2.2.cmml">λ</mi><mtext id="S4.p6.4.m1.1.1.1.1.2.3" xref="S4.p6.4.m1.1.1.1.1.2.3a.cmml">CE</mtext></msub><mo id="S4.p6.4.m1.1.1.1.1.1" xref="S4.p6.4.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.p6.4.m1.1.1.1.1.3" xref="S4.p6.4.m1.1.1.1.1.3.cmml">2</mn></mrow><mo id="S4.p6.4.m1.2.2.2.3" xref="S4.p6.4.m1.2.2.3a.cmml">,</mo><mrow id="S4.p6.4.m1.2.2.2.2.2" xref="S4.p6.4.m1.2.2.2.2.3.cmml"><mrow id="S4.p6.4.m1.2.2.2.2.1.1" xref="S4.p6.4.m1.2.2.2.2.1.1.cmml"><msub id="S4.p6.4.m1.2.2.2.2.1.1.2" xref="S4.p6.4.m1.2.2.2.2.1.1.2.cmml"><mi id="S4.p6.4.m1.2.2.2.2.1.1.2.2" xref="S4.p6.4.m1.2.2.2.2.1.1.2.2.cmml">λ</mi><mtext id="S4.p6.4.m1.2.2.2.2.1.1.2.3" xref="S4.p6.4.m1.2.2.2.2.1.1.2.3a.cmml">Dice</mtext></msub><mo id="S4.p6.4.m1.2.2.2.2.1.1.1" xref="S4.p6.4.m1.2.2.2.2.1.1.1.cmml">=</mo><mn id="S4.p6.4.m1.2.2.2.2.1.1.3" xref="S4.p6.4.m1.2.2.2.2.1.1.3.cmml">5</mn></mrow><mo id="S4.p6.4.m1.2.2.2.2.2.3" xref="S4.p6.4.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S4.p6.4.m1.2.2.2.2.2.2" xref="S4.p6.4.m1.2.2.2.2.2.2.cmml"><msub id="S4.p6.4.m1.2.2.2.2.2.2.2" xref="S4.p6.4.m1.2.2.2.2.2.2.2.cmml"><mi id="S4.p6.4.m1.2.2.2.2.2.2.2.2" xref="S4.p6.4.m1.2.2.2.2.2.2.2.2.cmml">λ</mi><mtext id="S4.p6.4.m1.2.2.2.2.2.2.2.3" xref="S4.p6.4.m1.2.2.2.2.2.2.2.3a.cmml">BCE</mtext></msub><mo id="S4.p6.4.m1.2.2.2.2.2.2.1" xref="S4.p6.4.m1.2.2.2.2.2.2.1.cmml">=</mo><mn id="S4.p6.4.m1.2.2.2.2.2.2.3" xref="S4.p6.4.m1.2.2.2.2.2.2.3.cmml">5</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.4.m1.2b"><apply id="S4.p6.4.m1.2.2.3.cmml" xref="S4.p6.4.m1.2.2.2"><csymbol cd="ambiguous" id="S4.p6.4.m1.2.2.3a.cmml" xref="S4.p6.4.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.p6.4.m1.1.1.1.1.cmml" xref="S4.p6.4.m1.1.1.1.1"><eq id="S4.p6.4.m1.1.1.1.1.1.cmml" xref="S4.p6.4.m1.1.1.1.1.1"></eq><apply id="S4.p6.4.m1.1.1.1.1.2.cmml" xref="S4.p6.4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.p6.4.m1.1.1.1.1.2.1.cmml" xref="S4.p6.4.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.p6.4.m1.1.1.1.1.2.2.cmml" xref="S4.p6.4.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.p6.4.m1.1.1.1.1.2.3a.cmml" xref="S4.p6.4.m1.1.1.1.1.2.3"><mtext id="S4.p6.4.m1.1.1.1.1.2.3.cmml" mathsize="70%" xref="S4.p6.4.m1.1.1.1.1.2.3">CE</mtext></ci></apply><cn id="S4.p6.4.m1.1.1.1.1.3.cmml" type="integer" xref="S4.p6.4.m1.1.1.1.1.3">2</cn></apply><apply id="S4.p6.4.m1.2.2.2.2.3.cmml" xref="S4.p6.4.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p6.4.m1.2.2.2.2.3a.cmml" xref="S4.p6.4.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.p6.4.m1.2.2.2.2.1.1.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1"><eq id="S4.p6.4.m1.2.2.2.2.1.1.1.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1.1"></eq><apply id="S4.p6.4.m1.2.2.2.2.1.1.2.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.p6.4.m1.2.2.2.2.1.1.2.1.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1.2">subscript</csymbol><ci id="S4.p6.4.m1.2.2.2.2.1.1.2.2.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1.2.2">𝜆</ci><ci id="S4.p6.4.m1.2.2.2.2.1.1.2.3a.cmml" xref="S4.p6.4.m1.2.2.2.2.1.1.2.3"><mtext id="S4.p6.4.m1.2.2.2.2.1.1.2.3.cmml" mathsize="70%" xref="S4.p6.4.m1.2.2.2.2.1.1.2.3">Dice</mtext></ci></apply><cn id="S4.p6.4.m1.2.2.2.2.1.1.3.cmml" type="integer" xref="S4.p6.4.m1.2.2.2.2.1.1.3">5</cn></apply><apply id="S4.p6.4.m1.2.2.2.2.2.2.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2"><eq id="S4.p6.4.m1.2.2.2.2.2.2.1.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2.1"></eq><apply id="S4.p6.4.m1.2.2.2.2.2.2.2.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p6.4.m1.2.2.2.2.2.2.2.1.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p6.4.m1.2.2.2.2.2.2.2.2.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2.2.2">𝜆</ci><ci id="S4.p6.4.m1.2.2.2.2.2.2.2.3a.cmml" xref="S4.p6.4.m1.2.2.2.2.2.2.2.3"><mtext id="S4.p6.4.m1.2.2.2.2.2.2.2.3.cmml" mathsize="70%" xref="S4.p6.4.m1.2.2.2.2.2.2.2.3">BCE</mtext></ci></apply><cn id="S4.p6.4.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.p6.4.m1.2.2.2.2.2.2.3">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.4.m1.2c">\lambda_{\text{CE}}=2,\lambda_{\text{Dice}}=5,\lambda_{\text{BCE}}=5</annotation><annotation encoding="application/x-llamapun" id="S4.p6.4.m1.2d">italic_λ start_POSTSUBSCRIPT CE end_POSTSUBSCRIPT = 2 , italic_λ start_POSTSUBSCRIPT Dice end_POSTSUBSCRIPT = 5 , italic_λ start_POSTSUBSCRIPT BCE end_POSTSUBSCRIPT = 5</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we first describe the datasets (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS1" title="5.1 Training and Evaluation Datasets ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5.1</span></a>) and evaluation metrics (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS2" title="5.2 Evaluation Metrics ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5.2</span></a>) used. Next, we describe our implementation details (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS3" title="5.3 Implementation Details ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5.3</span></a>). Then, we quantitatively and qualitatively compare our method with leading open-vocabulary segmentation methods (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS4" title="5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5.4</span></a>). Finally, we carefully ablate our proposed method (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.SS5" title="5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5.5</span></a>). Detailed implementation details can be found in the Supplementary.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Training and Evaluation Datasets</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We train our method on the COCO-Panoptic <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.1">train</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib28" title="">2014</a>)</cite> and evaluate its performance using the COCO, Mapillary Vistas <cite class="ltx_cite ltx_citemacro_citep">(Neuhold et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib34" title="">2017</a>)</cite>, ADE20K <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib52" title="">2019</a>)</cite> and PASCAL Context <cite class="ltx_cite ltx_citemacro_citep">(Mottaghi et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib33" title="">2014</a>)</cite> <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.2">val</span> datasets. Splitting into <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.3">train</span> and <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.4">val</span> datasets with distinct labels is the standard practice in open-vocab. segmentation. Note that ADE20K has two subsets, ADE150 and ADE847, containing 150 and 847 classes, respectively. Similarly, PASCAL Context has two subsets, PC59 and PC459, containing 59 and 459 classes, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Metrics</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We evaluate our method using two main metrics: Panoptic Quality (PQ) for panoptic segmentation and mean intersection-over-union (mIoU) for semantic segmentation. mIoU measures the average overlap between the predicted mask and the ground truth across all classes, while PQ measures the overall quality of a panoptic segmentation by combining semantic and instance segmentation accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Implementation Details</h3>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">Architecture.</span> We use the pre-trained ViT-L/16-336 CLIP model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>)</cite> as our mask classifier. Following FC-CLIP <cite class="ltx_cite ltx_citemacro_citep">(Yu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib49" title="">2023</a>)</cite>, we use high-resolution input image with size <math alttext="896\times 896" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mn id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">896</mn><mo id="S5.SS3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">896</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><times id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1"></times><cn id="S5.SS3.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1.2">896</cn><cn id="S5.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1.3">896</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">896\times 896</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">896 × 896</annotation></semantics></math>.
Following standard practice in vision transformers <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib26" title="">2022b</a>; He et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib17" title="">2022</a>; Bolya et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib2" title="">2024</a>)</cite>, we adjust the position embeddings through direct bilinear interpolation to accommodate the change in input size. The text inputs to our model are the category names defined by each dataset. We use various sizes of the pre-trained Mask2Former models <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib7" title="">2022</a>)</cite> as our mask generator without making any modification. We do not use Mask2Former’s predicted class labels in our method.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.6"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.6.1">Training Details.</span> We train our model using the AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib32" title="">2019</a>)</cite> optimizer, with a learning rate of <math alttext="0.0001" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mn id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">0.0001</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><cn id="S5.SS3.p2.1.m1.1.1.cmml" type="float" xref="S5.SS3.p2.1.m1.1.1">0.0001</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">0.0001</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">0.0001</annotation></semantics></math> and a weight decay of 0.05. A learning rate multiplier
of <math alttext="0.1" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mn id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><cn id="S5.SS3.p2.2.m2.1.1.cmml" type="float" xref="S5.SS3.p2.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">0.1</annotation></semantics></math> is applied to the feature backbone. We use a crop size of <math alttext="1024\times 1024" class="ltx_Math" display="inline" id="S5.SS3.p2.3.m3.1"><semantics id="S5.SS3.p2.3.m3.1a"><mrow id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml"><mn id="S5.SS3.p2.3.m3.1.1.2" xref="S5.SS3.p2.3.m3.1.1.2.cmml">1024</mn><mo id="S5.SS3.p2.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p2.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS3.p2.3.m3.1.1.3" xref="S5.SS3.p2.3.m3.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><apply id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1"><times id="S5.SS3.p2.3.m3.1.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1.1"></times><cn id="S5.SS3.p2.3.m3.1.1.2.cmml" type="integer" xref="S5.SS3.p2.3.m3.1.1.2">1024</cn><cn id="S5.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="S5.SS3.p2.3.m3.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">1024\times 1024</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.3.m3.1d">1024 × 1024</annotation></semantics></math>. The batch size is set to <math alttext="16" class="ltx_Math" display="inline" id="S5.SS3.p2.4.m4.1"><semantics id="S5.SS3.p2.4.m4.1a"><mn id="S5.SS3.p2.4.m4.1.1" xref="S5.SS3.p2.4.m4.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.4.m4.1b"><cn id="S5.SS3.p2.4.m4.1.1.cmml" type="integer" xref="S5.SS3.p2.4.m4.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.4.m4.1c">16</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.4.m4.1d">16</annotation></semantics></math>, and the model is trained for <math alttext="10,000" class="ltx_Math" display="inline" id="S5.SS3.p2.5.m5.2"><semantics id="S5.SS3.p2.5.m5.2a"><mrow id="S5.SS3.p2.5.m5.2.3.2" xref="S5.SS3.p2.5.m5.2.3.1.cmml"><mn id="S5.SS3.p2.5.m5.1.1" xref="S5.SS3.p2.5.m5.1.1.cmml">10</mn><mo id="S5.SS3.p2.5.m5.2.3.2.1" xref="S5.SS3.p2.5.m5.2.3.1.cmml">,</mo><mn id="S5.SS3.p2.5.m5.2.2" xref="S5.SS3.p2.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.5.m5.2b"><list id="S5.SS3.p2.5.m5.2.3.1.cmml" xref="S5.SS3.p2.5.m5.2.3.2"><cn id="S5.SS3.p2.5.m5.1.1.cmml" type="integer" xref="S5.SS3.p2.5.m5.1.1">10</cn><cn id="S5.SS3.p2.5.m5.2.2.cmml" type="integer" xref="S5.SS3.p2.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.5.m5.2c">10,000</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.5.m5.2d">10 , 000</annotation></semantics></math> iterations for all ablation experiments and <math alttext="25,000" class="ltx_Math" display="inline" id="S5.SS3.p2.6.m6.2"><semantics id="S5.SS3.p2.6.m6.2a"><mrow id="S5.SS3.p2.6.m6.2.3.2" xref="S5.SS3.p2.6.m6.2.3.1.cmml"><mn id="S5.SS3.p2.6.m6.1.1" xref="S5.SS3.p2.6.m6.1.1.cmml">25</mn><mo id="S5.SS3.p2.6.m6.2.3.2.1" xref="S5.SS3.p2.6.m6.2.3.1.cmml">,</mo><mn id="S5.SS3.p2.6.m6.2.2" xref="S5.SS3.p2.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.6.m6.2b"><list id="S5.SS3.p2.6.m6.2.3.1.cmml" xref="S5.SS3.p2.6.m6.2.3.2"><cn id="S5.SS3.p2.6.m6.1.1.cmml" type="integer" xref="S5.SS3.p2.6.m6.1.1">25</cn><cn id="S5.SS3.p2.6.m6.2.2.cmml" type="integer" xref="S5.SS3.p2.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.6.m6.2c">25,000</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.6.m6.2d">25 , 000</annotation></semantics></math> iterations for the main results in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S4.T1" title="Table 1 ‣ 4 Method ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Main Results</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S4.T1" title="Table 1 ‣ 4 Method ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare our method with all leading methods on COCO, ADE20K and PASCAL datasets using mIoU and PQ metrics. We include two versions of our method that use different feature backbones for mask generators, namely ResNet50 <cite class="ltx_cite ltx_citemacro_citep">(He et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib19" title="">2016</a>)</cite> and Swin-B <cite class="ltx_cite ltx_citemacro_citep">(Liu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib30" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.1">Open-Vocabulary Panoptic Segmentation</span> Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S4.T1" title="Table 1 ‣ 4 Method ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a> shows that our best method, SMART-SwinB, outperforms both two-stage and one-stage approaches across various panoptic segmentation datasets. Compared to two-stage methods like MaskCLIP and MasQCLIP, SMART-SwinB achieves a PQ improvement of up to <span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.2">13.0</span> points on ADE150. Compared to one-stage methods like ODISE and FC-CLIP, SMART-SwinB attains a PQ improvement of up to <span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.3">5.5</span> points on both the indoor ADE150 and outdoor Mapillary Vistas datasets, establishing itself as the new state-of-the-art in this domain.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.1">Open-Vocabulary Semantic Segmentation on ADE847, PC59 and PC459.</span> Leading open-vocabulary semantic segmentation methods generally train on COCO-Stuff <cite class="ltx_cite ltx_citemacro_citep">(Caesar, Uijlings, and Ferrari <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib3" title="">2018</a>)</cite> that provides extra annotations for semantic segmentation. Despite this unfair setup, our best method, SMART-SwinB still manages to outperform all previous leading methods in semantic segmentation. Compared to the current best method, SED, SMART-SwinB demonstrates improvements of <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.2">+1.6</span>, <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.3">+2.2</span>, <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.4">+1.8</span> and <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.5">+1.0</span> mIoU on ADE150, ADE847, PC59 and PC459, respectively. Furthermore, SMART-SwinB also significantly outperforms all previous methods capable of performing both panoptic and semantic segmentation. Specifically, it surpasses the current leader in this category, FC-CLIP, by <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.6">+2.7</span>, <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.7">+1.3</span>, <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.8">+4.0</span> and <span class="ltx_text ltx_font_bold" id="S5.SS4.p3.1.9">+5.4</span> mIoU on ADE150, ADE847, PC59, and PC459, respectively. SMART-SwinB is the first method that can simultaneously achieve state-of-the-art results for both tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.2"><span class="ltx_text ltx_font_bold" id="S5.SS4.p4.2.3">Efficiency Analysis.</span> Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T2" title="Table 2 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a> compares the efficiency of our method with several other leading open-vocabulary segmentation methods. SMART-SwinB achieves comparable inference speed and significantly lower memory cost than FC-CLIP. Specifically, SMART-SwinB requires only 45 GPU training hours and 10.2GB of GPU inference memory, compared to FC-CLIP’s 424 GPU hours and 17.1GB. This results in a substantial <span class="ltx_text ltx_font_bold" id="S5.SS4.p4.1.1">9.4<math alttext="\boldsymbol{\times}" class="ltx_Math" display="inline" id="S5.SS4.p4.1.1.m1.1"><semantics id="S5.SS4.p4.1.1.m1.1a"><mo class="ltx_mathvariant_bold" id="S5.SS4.p4.1.1.m1.1.1" mathvariant="bold" xref="S5.SS4.p4.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.1.1.m1.1b"><times id="S5.SS4.p4.1.1.m1.1.1.cmml" xref="S5.SS4.p4.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.1.1.m1.1c">\boldsymbol{\times}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p4.1.1.m1.1d">bold_×</annotation></semantics></math></span> reduction in training time and <span class="ltx_text ltx_font_bold" id="S5.SS4.p4.2.2">40.4<math alttext="\boldsymbol{\%}" class="ltx_Math" display="inline" id="S5.SS4.p4.2.2.m1.1"><semantics id="S5.SS4.p4.2.2.m1.1a"><mo class="ltx_mathvariant_bold" id="S5.SS4.p4.2.2.m1.1.1" mathvariant="bold" xref="S5.SS4.p4.2.2.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p4.2.2.m1.1b"><csymbol cd="latexml" id="S5.SS4.p4.2.2.m1.1.1.cmml" xref="S5.SS4.p4.2.2.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p4.2.2.m1.1c">\boldsymbol{\%}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p4.2.2.m1.1d">bold_%</annotation></semantics></math></span> memory savings. These efficiency gains are due to the absence of a feature refinement module (e.g., pixel decoder in FC-CLIP) and minimal parameters tuned (26M). Notably, these efficiency improvements does not compromise performance, as our method still achieves new state-of-the-art results across multiple representative datasets.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:88.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-3.2pt,0.7pt) scale(0.985498416799123,0.985498416799123) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T2.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.2">Inference</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.3">Inference</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.4">Train</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.5">Train</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T2.1.1.1.1.6">ADE150</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T2.1.1.2.2.1">FPS</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T2.1.1.2.2.2">Memory (GB)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T2.1.1.2.2.3">GPU Hours</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S5.T2.1.1.2.2.4">Iterations (K)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T2.1.1.2.2.5">PQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T2.1.1.2.2.6">mIoU</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.1.1">ODISE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.2">0.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.4">4760</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.1.5">369</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.6">22.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.7">29.9</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.4.2.1">FC-CLIP</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.4.2.2.1">2.71</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.3">17.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.4">424</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.4.2.5">369</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.6">26.8</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.7">34.1</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.3" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.5.3.1"><span class="ltx_text" id="S5.T2.1.1.5.3.1.1" style="background-color:#E6E6E6;">SMART-SwinB (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.5.3.2"><span class="ltx_text" id="S5.T2.1.1.5.3.2.1" style="background-color:#E6E6E6;">2.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.3.3.1" style="background-color:#E6E6E6;">10.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.5.3.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.3.4.1" style="background-color:#E6E6E6;">45</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.5.3.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.3.5.1" style="background-color:#E6E6E6;">25</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.3.6.1" style="background-color:#E6E6E6;">28.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.5.3.7"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.3.7.1" style="background-color:#E6E6E6;">36.8</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison with leading open-vocabulary segmentation methods on several important efficiency metrics.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T3">
<p class="ltx_p" id="S5.T3.3"><span class="ltx_text ltx_inline-block" id="S5.T3.3.1" style="width:505.9pt;"><span class="ltx_inline-logical-block ltx_minipage ltx_align_middle" id="S5.T3.3.1.1" style="width:433.6pt;">
<span class="ltx_table" id="S5.T3.sf1">
<span class="ltx_tabular ltx_centering ltx_minipage ltx_align_middle" id="S5.T3.sf1.6.6.6" style="width:130.1pt;">
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf1.6.6.6.7.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.6.6.6.7.1.1" style="padding:0.25pt 4.0pt;">Parameters tuned</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.6.6.6.7.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.6.6.6.7.1.2.1">
<span class="ltx_p" id="S5.T3.sf1.6.6.6.7.1.2.1.1" style="width:24.0pt;">PQ</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.6.6.6.8.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.sf1.6.6.6.8.2.1" style="padding:0.25pt 4.0pt;">All</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf1.6.6.6.8.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.6.6.6.8.2.2.1">
<span class="ltx_p" id="S5.T3.sf1.6.6.6.8.2.2.1.1" style="width:24.0pt;">14.9</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.6.6.6.9.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.6.6.6.9.3.1" style="padding:0.25pt 4.0pt;">MLP</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.6.6.6.9.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.6.6.6.9.3.2.1">
<span class="ltx_p" id="S5.T3.sf1.6.6.6.9.3.2.1.1" style="width:24.0pt;">17.7</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.1.1.1.1.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{q},f_{k},f_{v}" class="ltx_Math" display="inline" id="S5.T3.sf1.1.1.1.1.1.m1.3"><semantics id="S5.T3.sf1.1.1.1.1.1.m1.3a"><mrow id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.4.cmml"><msub id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.cmml"><mi id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.2" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.3" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.3.cmml">q</mi></msub><mo id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.4" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.4.cmml">,</mo><msub id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.cmml"><mi id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.2" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.3" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></msub><mo id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.5" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.4.cmml">,</mo><msub id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.cmml"><mi id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.2" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.2.cmml">f</mi><mi id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.3" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.1.1.1.1.1.m1.3b"><list id="S5.T3.sf1.1.1.1.1.1.m1.3.3.4.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3"><apply id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.1.1.1.1.3">𝑞</ci></apply><apply id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2">subscript</csymbol><ci id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.2.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.2">𝑓</ci><ci id="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.2.2.2.2.3">𝑘</ci></apply><apply id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3">subscript</csymbol><ci id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.2.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.2">𝑓</ci><ci id="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="S5.T3.sf1.1.1.1.1.1.m1.3.3.3.3.3">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.1.1.1.1.1.m1.3c">f_{q},f_{k},f_{v}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.1.1.1.1.1.m1.3d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.1.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.1.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf1.1.1.1.1.2.1.1" style="width:24.0pt;">23.2</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.2.2.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.2.2.2.2.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{q},f_{v}" class="ltx_Math" display="inline" id="S5.T3.sf1.2.2.2.2.1.m1.2"><semantics id="S5.T3.sf1.2.2.2.2.1.m1.2a"><mrow id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.3.cmml"><msub id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.cmml"><mi id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.2" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.3" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.3.cmml">q</mi></msub><mo id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.3" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.3.cmml">,</mo><msub id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.cmml"><mi id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.2" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.3" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.2.2.2.2.1.m1.2b"><list id="S5.T3.sf1.2.2.2.2.1.m1.2.2.3.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2"><apply id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.1.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1">subscript</csymbol><ci id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.2.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.3.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.1.1.1.1.3">𝑞</ci></apply><apply id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.1.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2">subscript</csymbol><ci id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.2.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.2">𝑓</ci><ci id="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.3.cmml" xref="S5.T3.sf1.2.2.2.2.1.m1.2.2.2.2.3">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.2.2.2.2.1.m1.2c">f_{q},f_{v}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.2.2.2.2.1.m1.2d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.2.2.2.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.2.2.2.2.2.1">
<span class="ltx_p" id="S5.T3.sf1.2.2.2.2.2.1.1" style="width:24.0pt;">24.3</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.3.3.3.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.3.3.3.3.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{q},f_{k}" class="ltx_Math" display="inline" id="S5.T3.sf1.3.3.3.3.1.m1.2"><semantics id="S5.T3.sf1.3.3.3.3.1.m1.2a"><mrow id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.3.cmml"><msub id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.cmml"><mi id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.2" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.3" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.3.cmml">q</mi></msub><mo id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.3" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.3.cmml">,</mo><msub id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.cmml"><mi id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.2" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.3" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.3.3.3.3.1.m1.2b"><list id="S5.T3.sf1.3.3.3.3.1.m1.2.2.3.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2"><apply id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.1.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1">subscript</csymbol><ci id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.2.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.3.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.1.1.1.1.3">𝑞</ci></apply><apply id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.1.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2">subscript</csymbol><ci id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.2.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.2">𝑓</ci><ci id="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.3.cmml" xref="S5.T3.sf1.3.3.3.3.1.m1.2.2.2.2.3">𝑘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.3.3.3.3.1.m1.2c">f_{q},f_{k}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.3.3.3.3.1.m1.2d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.3.3.3.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.3.3.3.3.2.1">
<span class="ltx_p" id="S5.T3.sf1.3.3.3.3.2.1.1" style="width:24.0pt;">25.9</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.4.4.4.4.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{v}" class="ltx_Math" display="inline" id="S5.T3.sf1.4.4.4.4.1.m1.1"><semantics id="S5.T3.sf1.4.4.4.4.1.m1.1a"><msub id="S5.T3.sf1.4.4.4.4.1.m1.1.1" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1.cmml"><mi id="S5.T3.sf1.4.4.4.4.1.m1.1.1.2" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.4.4.4.4.1.m1.1.1.3" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.4.4.4.4.1.m1.1b"><apply id="S5.T3.sf1.4.4.4.4.1.m1.1.1.cmml" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.4.4.4.4.1.m1.1.1.1.cmml" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1">subscript</csymbol><ci id="S5.T3.sf1.4.4.4.4.1.m1.1.1.2.cmml" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.4.4.4.4.1.m1.1.1.3.cmml" xref="S5.T3.sf1.4.4.4.4.1.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.4.4.4.4.1.m1.1c">f_{v}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.4.4.4.4.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.4.4.4.4.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.4.4.4.4.2.1">
<span class="ltx_p" id="S5.T3.sf1.4.4.4.4.2.1.1" style="width:24.0pt;">22.6</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.5.5.5.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.5.5.5.5.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{k}" class="ltx_Math" display="inline" id="S5.T3.sf1.5.5.5.5.1.m1.1"><semantics id="S5.T3.sf1.5.5.5.5.1.m1.1a"><msub id="S5.T3.sf1.5.5.5.5.1.m1.1.1" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1.cmml"><mi id="S5.T3.sf1.5.5.5.5.1.m1.1.1.2" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.5.5.5.5.1.m1.1.1.3" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.5.5.5.5.1.m1.1b"><apply id="S5.T3.sf1.5.5.5.5.1.m1.1.1.cmml" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.5.5.5.5.1.m1.1.1.1.cmml" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1">subscript</csymbol><ci id="S5.T3.sf1.5.5.5.5.1.m1.1.1.2.cmml" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.5.5.5.5.1.m1.1.1.3.cmml" xref="S5.T3.sf1.5.5.5.5.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.5.5.5.5.1.m1.1c">f_{k}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.5.5.5.5.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.5.5.5.5.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.5.5.5.5.2.1">
<span class="ltx_p" id="S5.T3.sf1.5.5.5.5.2.1.1" style="width:24.0pt;">26.7</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf1.6.6.6.6" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf1.6.6.6.6.1" style="padding:0.25pt 4.0pt;"><math alttext="f_{q}" class="ltx_Math" display="inline" id="S5.T3.sf1.6.6.6.6.1.m1.1" style="background-color:#E6E6E6;"><semantics id="S5.T3.sf1.6.6.6.6.1.m1.1a"><msub id="S5.T3.sf1.6.6.6.6.1.m1.1.1" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1.cmml"><mi id="S5.T3.sf1.6.6.6.6.1.m1.1.1.2" mathbackground="#E6E6E6" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1.2.cmml">f</mi><mi id="S5.T3.sf1.6.6.6.6.1.m1.1.1.3" mathbackground="#E6E6E6" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T3.sf1.6.6.6.6.1.m1.1b"><apply id="S5.T3.sf1.6.6.6.6.1.m1.1.1.cmml" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.sf1.6.6.6.6.1.m1.1.1.1.cmml" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="S5.T3.sf1.6.6.6.6.1.m1.1.1.2.cmml" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1.2">𝑓</ci><ci id="S5.T3.sf1.6.6.6.6.1.m1.1.1.3.cmml" xref="S5.T3.sf1.6.6.6.6.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.sf1.6.6.6.6.1.m1.1c">f_{q}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.sf1.6.6.6.6.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf1.6.6.6.6.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf1.6.6.6.6.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf1.6.6.6.6.2.1.1" style="width:24.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.sf1.6.6.6.6.2.1.1.1">27.5</span></span>
</span></span></span>
</span>
</span>
<span class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(a) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf1.8.1">Effect of fine-tuning different layers in CLIP.</span> Tuning only the query projection layer provides the best performance.
</span>
</span>
<span class="ltx_table" id="S5.T3.sf2">
<span class="ltx_block ltx_minipage ltx_align_middle" id="S5.T3.sf2.1" style="width:130.1pt;">
<span class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.sf2.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T3.sf2.1.1.1.1">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf2.1.1.1.1.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.1.1.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.1.1.1.1.1" style="width:60.0pt;">Method</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf2.1.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.1.1.2.1.1" style="width:16.0pt;">Rank</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf2.1.1.1.1.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.1.1.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.1.1.3.1.1" style="width:16.0pt;">PQ</span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf2.1.1.2.1" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf2.1.1.2.1.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.2.1.1.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf2.1.1.2.1.1.1.1" style="width:60.0pt;">SMART</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf2.1.1.2.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.2.1.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf2.1.1.2.1.2.1.1" style="width:16.0pt;">-</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf2.1.1.2.1.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.2.1.3.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf2.1.1.2.1.3.1.1" style="width:16.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.sf2.1.1.2.1.3.1.1.1">27.5</span></span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.3.2">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.3.2.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.3.2.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.3.2.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.3.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.3.2.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.3.2.2.1.1" style="width:16.0pt;">256</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.3.2.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.3.2.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.3.2.3.1.1" style="width:16.0pt;">25.3</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.4.3">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.4.3.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.4.3.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.4.3.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.4.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.4.3.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.4.3.2.1.1" style="width:16.0pt;">128</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.4.3.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.4.3.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.4.3.3.1.1" style="width:16.0pt;">25.4</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.5.4">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.5.4.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.5.4.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.5.4.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.5.4.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.5.4.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.5.4.2.1.1" style="width:16.0pt;">64</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.5.4.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.5.4.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.5.4.3.1.1" style="width:16.0pt;">25.9</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.6.5">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.6.5.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.6.5.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.6.5.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.6.5.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.6.5.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.6.5.2.1.1" style="width:16.0pt;">32</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.6.5.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.6.5.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.6.5.3.1.1" style="width:16.0pt;">25.5</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.7.6">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.7.6.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.7.6.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.7.6.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.7.6.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.7.6.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.7.6.2.1.1" style="width:16.0pt;">16</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.7.6.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.7.6.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.7.6.3.1.1" style="width:16.0pt;">25.4</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.8.7">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.8.7.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.8.7.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.8.7.1.1.1" style="width:60.0pt;">LoRA</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.8.7.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.8.7.2.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.8.7.2.1.1" style="width:16.0pt;">8</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.8.7.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.8.7.3.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.8.7.3.1.1" style="width:16.0pt;">25.2</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf2.1.1.9.8">
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.9.8.1" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf2.1.1.9.8.1.1">
<span class="ltx_p" id="S5.T3.sf2.1.1.9.8.1.1.1" style="width:60.0pt;"></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.9.8.2" style="padding:0.25pt 4.0pt;"></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf2.1.1.9.8.3" style="padding:0.25pt 4.0pt;"></span></span>
</span>
</span>
</span>
<span class="ltx_caption"><span class="ltx_tag ltx_tag_table">(b) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf2.3.1">Comparison with other efficient fine-tuning method.</span> SMART outperforms LoRA across all ranks.

</span>
</span>
<span class="ltx_table" id="S5.T3.sf3">
<span class="ltx_tabular ltx_minipage ltx_align_middle" id="S5.T3.sf3.1" style="width:130.1pt;">
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf3.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf3.1.1.1.1" style="padding:0.25pt 4.0pt;">Number of layers</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf3.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf3.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf3.1.1.1.2.1.1" style="width:24.0pt;">PQ</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf3.1.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.sf3.1.2.2.1" style="padding:0.25pt 4.0pt;">0 (w/o Distribution Adapter)</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf3.1.2.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf3.1.2.2.2.1">
<span class="ltx_p" id="S5.T3.sf3.1.2.2.2.1.1" style="width:24.0pt;">26.7</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf3.1.3.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf3.1.3.3.1" style="padding:0.25pt 4.0pt;">1</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf3.1.3.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf3.1.3.3.2.1">
<span class="ltx_p" id="S5.T3.sf3.1.3.3.2.1.1" style="width:24.0pt;">26.9</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf3.1.4.4" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf3.1.4.4.1" style="padding:0.25pt 4.0pt;"><span class="ltx_text" id="S5.T3.sf3.1.4.4.1.1" style="background-color:#E6E6E6;">2</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf3.1.4.4.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf3.1.4.4.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf3.1.4.4.2.1.1" style="width:24.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.sf3.1.4.4.2.1.1.1">27.5</span></span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf3.1.5.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf3.1.5.5.1" style="padding:0.25pt 4.0pt;">3</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf3.1.5.5.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf3.1.5.5.2.1">
<span class="ltx_p" id="S5.T3.sf3.1.5.5.2.1.1" style="width:24.0pt;">27.2</span>
</span></span></span>
</span>
</span>
<span class="ltx_caption"><span class="ltx_tag ltx_tag_table">(c) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf3.3.1">Optimal size of Distribution Adapter.</span> Two layers provide the best performance.
</span>
</span>
<span class="ltx_table" id="S5.T3.sf4">
<span class="ltx_tabular ltx_centering ltx_minipage ltx_align_middle" id="S5.T3.sf4.1.1.1" style="width:130.1pt;">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T3.sf4.1.1.1.2.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S5.T3.sf4.1.1.1.2.1.1" style="padding:0.25pt 4.0pt;">Method</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf4.1.1.1.2.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf4.1.1.1.2.1.2.1">
<span class="ltx_p" id="S5.T3.sf4.1.1.1.2.1.2.1.1" style="width:24.0pt;">PQ</span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf4.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.sf4.1.1.1.1.1" style="padding:0.25pt 4.0pt;">Baseline<sup class="ltx_sup" id="S5.T3.sf4.1.1.1.1.1.1">∗</sup></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf4.1.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf4.1.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf4.1.1.1.1.2.1.1" style="width:24.0pt;">9.6</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf4.1.1.1.3.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf4.1.1.1.3.1.1" style="padding:0.25pt 4.0pt;">+ SMA</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf4.1.1.1.3.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf4.1.1.1.3.1.2.1">
<span class="ltx_p" id="S5.T3.sf4.1.1.1.3.1.2.1.1" style="width:24.0pt;">18.9</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf4.1.1.1.4.2" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf4.1.1.1.4.2.1" style="padding:0.25pt 4.0pt;"><span class="ltx_text" id="S5.T3.sf4.1.1.1.4.2.1.1" style="background-color:#E6E6E6;">    + SMA + QPT (SMART)</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf4.1.1.1.4.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf4.1.1.1.4.2.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf4.1.1.1.4.2.2.1.1" style="width:24.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.sf4.1.1.1.4.2.2.1.1.1">27.5</span></span>
</span></span></span>
</span>
</span>
<span class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(d) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf4.3.1">Importance of Semantic-guided Mask Attention (SMA) and Query Projection Tuning (QPT).</span>
</span>
</span>
<span class="ltx_table" id="S5.T3.sf5">
<span class="ltx_tabular ltx_minipage ltx_align_middle" id="S5.T3.sf5.1" style="width:130.1pt;">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T3.sf5.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S5.T3.sf5.1.1.1.1" style="padding:0.25pt 4.0pt;">Parameters tuned</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf5.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf5.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf5.1.1.1.2.1.1" style="width:24.0pt;">PQ</span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf5.1.2.1" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.sf5.1.2.1.1" style="padding:0.25pt 4.0pt;"><span class="ltx_text" id="S5.T3.sf5.1.2.1.1.1" style="background-color:#E6E6E6;">SMART</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf5.1.2.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf5.1.2.1.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf5.1.2.1.2.1.1" style="width:24.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.sf5.1.2.1.2.1.1.1">27.5</span></span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf5.1.3.2">
<span class="ltx_td ltx_align_left" id="S5.T3.sf5.1.3.2.1" style="padding:0.25pt 4.0pt;">+ Tune language encoder</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf5.1.3.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf5.1.3.2.2.1">
<span class="ltx_p" id="S5.T3.sf5.1.3.2.2.1.1" style="width:24.0pt;">24.6</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf5.1.4.3">
<span class="ltx_td ltx_align_left" id="S5.T3.sf5.1.4.3.1" style="padding:0.25pt 4.0pt;">+ Tune mask generator</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf5.1.4.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf5.1.4.3.2.1">
<span class="ltx_p" id="S5.T3.sf5.1.4.3.2.1.1" style="width:24.0pt;">21.9</span>
</span></span></span>
</span>
</span>
<span class="ltx_caption"><span class="ltx_tag ltx_tag_table">(e) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf5.3.1">Effect of fine-tuning additional modules.</span> Tuning language encoder and mask generator do not provide performance gain.
</span>
</span>
<span class="ltx_table" id="S5.T3.sf6">
<span class="ltx_tabular ltx_centering ltx_minipage ltx_align_middle" id="S5.T3.sf6.1" style="width:130.1pt;">
<span class="ltx_thead">
<span class="ltx_tr" id="S5.T3.sf6.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S5.T3.sf6.1.1.1.1" style="padding:0.25pt 4.0pt;">VLM backbone</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf6.1.1.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.sf6.1.1.1.2.1.1" style="width:24.0pt;">PQ</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="S5.T3.sf6.1.1.1.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.1.1.3.1">
<span class="ltx_p" id="S5.T3.sf6.1.1.1.3.1.1" style="width:24.0pt;">mIoU</span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S5.T3.sf6.1.2.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.sf6.1.2.1.1" style="padding:0.25pt 4.0pt;">ViT-B-16</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf6.1.2.1.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.2.1.2.1">
<span class="ltx_p" id="S5.T3.sf6.1.2.1.2.1.1" style="width:24.0pt;">25.7</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.sf6.1.2.1.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.2.1.3.1">
<span class="ltx_p" id="S5.T3.sf6.1.2.1.3.1.1" style="width:24.0pt;">34.1</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf6.1.3.2" style="background-color:#E6E6E6;">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf6.1.3.2.1" style="padding:0.25pt 4.0pt;"><span class="ltx_text" id="S5.T3.sf6.1.3.2.1.1" style="background-color:#E6E6E6;">ViT-L-14-336</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf6.1.3.2.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.3.2.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf6.1.3.2.2.1.1" style="width:24.0pt;">27.5</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf6.1.3.2.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.3.2.3.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S5.T3.sf6.1.3.2.3.1.1" style="width:24.0pt;">36.2</span>
</span></span></span>
<span class="ltx_tr" id="S5.T3.sf6.1.4.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.sf6.1.4.3.1" style="padding:0.25pt 4.0pt;">EVA01-g-14-plus</span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf6.1.4.3.2" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.4.3.2.1">
<span class="ltx_p" id="S5.T3.sf6.1.4.3.2.1.1" style="width:24.0pt;">26.9</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S5.T3.sf6.1.4.3.3" style="padding:0.25pt 4.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.sf6.1.4.3.3.1">
<span class="ltx_p" id="S5.T3.sf6.1.4.3.3.1.1" style="width:24.0pt;">36.4</span>
</span></span></span>
</span>
</span>
<span class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(f) </span>
<span class="ltx_text ltx_font_bold" id="S5.T3.sf6.3.1">Scalability to different VLM backbone.</span> SMART is generally compatible with many other VLM backbones.
</span>
</span></span></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S5.T3.7.1">Ablation experiments</span> on ADE150 using SMART-SwinB. All experiments here are run with a shorter training schedule of 10000 iterations, causing the results to be different from Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S4.T1" title="Table 1 ‣ 4 Method ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>. The entries marked in <span class="ltx_text" id="S5.T3.8.2" style="background-color:#E6E6E6;">gray</span> are the same, which specify the default settings. <sup class="ltx_sup" id="S5.T3.9.3">∗</sup>Baseline is a direct combination of a frozen pretrained mask generator and a frozen CLIP.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS4.p5">
<p class="ltx_p" id="S5.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p5.1.1">Qualitative Results.</span> In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.F4" title="Figure 4 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.F5" title="Figure 5 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">5</span></a>, we present representative mask predictions of SMART-SwinB on the ADE150 dataset for both semantic and panoptic segmentation. Compared to FC-CLIP, the current state-of-the-art in open-vocabulary segmentation, our method generates more masks and predicts mask classes more accurately. More visualizations can be found in the Supplementary.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="516" id="S5.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative comparison on open-vocabulary semantic segmentation. Our method successfully identifies buildings deceptively shaped like a <span class="ltx_text ltx_font_italic" id="S5.F4.4.1">bus</span> and differentiates <span class="ltx_text ltx_font_italic" id="S5.F4.5.2">sidewalk</span> from <span class="ltx_text ltx_font_italic" id="S5.F4.6.3">road</span>, tasks at which FC-CLIP fails. </figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="502" id="S5.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative comparison on open-vocab. panoptic segmentation. Our method is able to produce more masks and predict classes more accurately. Zoom-in for better view.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablations</h3>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.1">Effect of Training Length and Data Size on Model Performance.</span> Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.F6" title="Figure 6 ‣ 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates the robustness of our method across varying training iterations and data sizes. As depicted, our method consistently outperforms competitors, particularly at lower iteration counts. For instance, at just 100 iterations, we observe a significant performance gap of <span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.2">+21.3</span> PQ on ADE150, highlighting our method’s rapid convergence and potential for reducing training costs under resource constraints. Moreover, the results further showcase our method’s superiority across various training data sizes sampled at different percentages from COCO-Panoptic. Compared to the second-best method, FC-CLIP, we achieve improvements of up to <span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.3">+4.4</span> PQ on ADE150, demonstrating its effectiveness in data-limited scenarios.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="328" id="S5.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Effect of Training Length and Data Size on Model Performance. Our method consistently outperforms other leading methods across all training schedules and data sizes.</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Effect of Fine-tuning Different Layers in CLIP.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px1.p1.1">In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(a), we evaluate the effects of adjusting various parameters in the mask classifier. The results demonstrate that tuning only the <span class="ltx_text ltx_font_italic" id="S5.SS5.SSS0.Px1.p1.1.1">query projection layer</span> <math alttext="f_{q}" class="ltx_Math" display="inline" id="S5.SS5.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS5.SSS0.Px1.p1.1.m1.1a"><msub id="S5.SS5.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1.2.cmml">f</mi><mi id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS5.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1.2">𝑓</ci><ci id="S5.SS5.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS5.SSS0.Px1.p1.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.SSS0.Px1.p1.1.m1.1c">f_{q}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.SSS0.Px1.p1.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> yields the best performance. This finding underscores the effectiveness of our approach, which focuses solely on modifying image focus of the mask tokens. Notably, a clear trend emerges. As more parameters are tuned, performance decreases. This observation reinforces the insight that effective cross-domain generalization requires minimal parameter adjustments.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Comparison with Other Efficient Fine-Tuning Methods.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px2.p1.1">Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib20" title="">2022</a>)</cite> is widely used for efficiently fine-tuning pre-trained networks in transfer learning. In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(b), we compare SMART with LoRA. Following common practice, we apply LoRA to the attention projection layers of the CLIP model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib37" title="">2021</a>)</cite>. As shown in the table, our method significantly outperforms LoRA across different ranks, demonstrating its effectiveness in fine-tuning CLIP for open-vocab. panoptic segmentation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Effect of Using Different Number of Layers in Distribution Adapter.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px3.p1.1">In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(c), we evaluate the sensitivity of Distribution Adapter in SMA to different number of convolutional layers. We observe that using two layer achieves the best performance and adhere to this design choice.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Importance of Semantic-guided Mask Attention (SMA) and Query Projection Tuning (QPT)</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px4.p1.1">In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(d), we incrementally integrate our proposed modules into the baseline model, which initially combines a frozen pretrained mask generator with a frozen CLIP using mask attention to extract regional information <cite class="ltx_cite ltx_citemacro_citep">(Ding, Wang, and Tu <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib14" title="">2023</a>)</cite>. Our proposed SMA module significantly enhances this baseline, achieving a notable improvement of +9.3 PQ. Additionally, when combined with QPT, the performance further improves by +8.6 PQ, resulting in a final model that reaches 27.5 PQ, establishing a new state-of-the-art for this task.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Effect of Fine-tuning Other Modules.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px5.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px5.p1.1">Aside from the <span class="ltx_text ltx_font_italic" id="S5.SS5.SSS0.Px5.p1.1.1">query projection layers</span>, other modules within CLIP are kept frozen in SMART. In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(e), we explore the effect of further fine-tuning the mask generator and language encoder. The results reveal a noticeable performance decline after these adjustments. This suggests that additional tuning of the mask generator or language encoder may lead to overfitting, impairing the model’s ability to generalize to different datasets. This outcome underscores the importance of careful parameter adjustment for cross-domain generalization.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Scalability to Different VLM Backbones.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px6.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px6.p1.1">In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T3" title="Table 3 ‣ 5.4 Main Results ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>(f), we investigate the scalability of our method with respect to various VLM backbones. As shown, SMART is compatible with different VLM backbones, allowing it to benefit easily from future advancements in VLM backbones.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS5.SSS0.Px7">
<h4 class="ltx_title ltx_title_paragraph">Preservation of CLIP’s Pre-trained Knowledge.</h4>
<div class="ltx_para" id="S5.SS5.SSS0.Px7.p1">
<p class="ltx_p" id="S5.SS5.SSS0.Px7.p1.1">To show that CLIP’s internal knowledge is preserved after applying SMART, we compare the performance of the original CLIP backbone with our minimally fine-tuned version on referring image segmentation <cite class="ltx_cite ltx_citemacro_citep">(Chng et al. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#bib.bib9" title="">2024</a>)</cite>. As shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.16278v1#S5.T4" title="Table 4 ‣ Preservation of CLIP’s Pre-trained Knowledge. ‣ 5.5 Ablations ‣ 5 Experiments ‣ Semantic Refocused Tuning for Open-Vocabulary Panoptic Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>, the performance remains unchanged after fine-tuning. This is achievable because SMART restricts weight updates to the <span class="ltx_text ltx_font_italic" id="S5.SS5.SSS0.Px7.p1.1.1">query projection layer</span> and uses very few tuning iterations.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.1" style="width:216.8pt;height:78.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.1pt,-3.3pt) scale(1.09208725070686,1.09208725070686) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T4.1.1.1.1.1.1">case</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T4.1.1.1.1.2">oIoU</th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.1.2.2.1">RefCOCO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.1.1.2.2.2">RefCOCO+</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.1.1.3.1.1">before tuning</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.2">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.3.1.3">25.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.4.2" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T4.1.1.4.2.1"><span class="ltx_text" id="S5.T4.1.1.4.2.1.1" style="background-color:#E6E6E6;">after tuning</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.4.2.2"><span class="ltx_text" id="S5.T4.1.1.4.2.2.1" style="background-color:#E6E6E6;">24.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.4.2.3"><span class="ltx_text" id="S5.T4.1.1.4.2.3.1" style="background-color:#E6E6E6;">25.9</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>CLIP performance on Referring Image Seg. before and after SMART fine-tuning, evaluated by the oIoU metric.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduce <span class="ltx_text ltx_framed ltx_framed_underline" id="S6.p1.1.2">S</span>e<span class="ltx_text ltx_framed ltx_framed_underline" id="S6.p1.1.3">ma</span>ntic <span class="ltx_text ltx_framed ltx_framed_underline" id="S6.p1.1.4">R</span>efocused <span class="ltx_text ltx_framed ltx_framed_underline" id="S6.p1.1.5">T</span>uning (SMART), a novel framework that can greatly enhance the performance and training efficiency of open-vocabulary panoptic segmentation networks. Based on the insight that <span class="ltx_text ltx_font_italic" id="S6.p1.1.6">mask classification is the main performance bottleneck for open-vocabulary panoptic segmentation</span>, SMART introduces two innovations to improve mask classification. First, it introduces an innovative Semantic-guided Mask Attention mechanism to inject task-awareness into the regional information extraction process. Second, it incorporates Query Projection Tuning to fine-tune only the <span class="ltx_text ltx_font_italic" id="S6.p1.1.7">query projection layer</span> in VLM used for mask classification, allowing for domain adaptation while preserving the VLM’s pre-trained knowledge. These techniques enable our method to achieve new state-of-the-art results for open-vocab. panoptic segmentation, demonstrating improvements of up to <span class="ltx_text ltx_font_bold" id="S6.p1.1.8">1.3</span> points in PQ and <span class="ltx_text ltx_font_bold" id="S6.p1.1.9">5.4</span> points in mIoU across multiple representative datasets, while also reducing training costs by nearly <span class="ltx_text ltx_font_bold" id="S6.p1.1.1">10<math alttext="\boldsymbol{\times}" class="ltx_Math" display="inline" id="S6.p1.1.1.m1.1"><semantics id="S6.p1.1.1.m1.1a"><mo class="ltx_mathvariant_bold" id="S6.p1.1.1.m1.1.1" mathvariant="bold" xref="S6.p1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.p1.1.1.m1.1b"><times id="S6.p1.1.1.m1.1.1.cmml" xref="S6.p1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.1.m1.1c">\boldsymbol{\times}</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.1.m1.1d">bold_×</annotation></semantics></math></span> compared to the previous best method. We believe SMART has strong potential beyond open-vocabulary segmentation and plan to explore its broader applications in the future.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Acknowledgements.</span> This work is supported in part by the National Key R&amp;D Program of China under Grant 2021ZD0140407, the National Natural Science Foundation of China under Grants 62321005 and 62276150, and the THU-Bosch JCML.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahn et al. (2018)</span>
<span class="ltx_bibblock">
Ahn, H.; Choi, S.; Kim, N.; Cha, G.; and Oh, S. 2018.

</span>
<span class="ltx_bibblock">Interactive text2pickup networks for natural language-based human–robot collaboration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">IEEE Robotics and Automation Letters</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolya et al. (2024)</span>
<span class="ltx_bibblock">
Bolya, D.; Ryali, C.; Hoffman, J.; and Feichtenhofer, C. 2024.

</span>
<span class="ltx_bibblock">Window Attention is Bugged: How not to Interpolate Position Embeddings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caesar, Uijlings, and Ferrari (2018)</span>
<span class="ltx_bibblock">
Caesar, H.; Uijlings, J.; and Ferrari, V. 2018.

</span>
<span class="ltx_bibblock">Coco-stuff: Thing and stuff classes in context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2020)</span>
<span class="ltx_bibblock">
Cai, H.; Gan, C.; Zhu, L.; and Han, S. 2020.

</span>
<span class="ltx_bibblock">Tinytl: Reduce activations, not trainable parameters for efficient on-device learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Chen, L.; Papandreou, G.; Kokkinos, I.; Murphy, K.; and Yuille, A. 2017.

</span>
<span class="ltx_bibblock">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">PAMI</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2020)</span>
<span class="ltx_bibblock">
Cheng, B.; Collins, M.; Zhu, Y.; Liu, T.; Huang, T.; Hartwig, A.; and Chen, L. 2020.

</span>
<span class="ltx_bibblock">Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2022)</span>
<span class="ltx_bibblock">
Cheng, B.; Misra, I.; Schwing, A. G.; Kirillov, A.; and Girdhar, R. 2022.

</span>
<span class="ltx_bibblock">Masked-attention mask transformer for universal image segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherti et al. (2023)</span>
<span class="ltx_bibblock">
Cherti, M.; Beaumont, R.; Wightman, R.; Wortsman, M.; Ilharco, G.; Gordon, C.; Schuhmann, C.; Schmidt, L.; and Jitsev, J. 2023.

</span>
<span class="ltx_bibblock">Reproducible scaling laws for contrastive language-image learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chng et al. (2024)</span>
<span class="ltx_bibblock">
Chng, Y. X.; Zheng, H.; Y. Han, X. Q.; and Huang, G. 2024.

</span>
<span class="ltx_bibblock">Mask Grounding for Referring Image Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al. (2024)</span>
<span class="ltx_bibblock">
Cho, S.; Shin, H.; Hong, S.; An, S.; Lee, S.; Arnab, A.; Seo, P. H.; and Kim, S. 2024.

</span>
<span class="ltx_bibblock">CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Codevilla et al. (2019)</span>
<span class="ltx_bibblock">
Codevilla, F.; Santana, E.; López, A. M.; and Gaidon, A. 2019.

</span>
<span class="ltx_bibblock">Exploring the limitations of behavior cloning for autonomous driving.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">ICCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2024)</span>
<span class="ltx_bibblock">
Dettmers, T.; Pagnoni, A.; Holtzman, A.; and Zettlemoyer, L. 2024.

</span>
<span class="ltx_bibblock">Qlora: Efficient finetuning of quantized llms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. (2022)</span>
<span class="ltx_bibblock">
Ding, J.; Xue, N.; Xia, G.-S.; and Dai, D. 2022.

</span>
<span class="ltx_bibblock">Decoupling zero-shot semantic segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding, Wang, and Tu (2023)</span>
<span class="ltx_bibblock">
Ding, Z.; Wang, J.; and Tu, Z. 2023.

</span>
<span class="ltx_bibblock">Open-Vocabulary Universal Image Segmentation with MaskCLIP.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ICML</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Gao, P.; Geng, S.; Zhang, R.; Ma, T.; Fang, R.; Zhang, Y.; Li, H.; and Qiao, Y. 2024.

</span>
<span class="ltx_bibblock">Clip-adapter: Better vision-language models with feature adapters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IJCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghiasi et al. (2022)</span>
<span class="ltx_bibblock">
Ghiasi, G.; Gu, X.; Cui, Y.; and Lin, T.-Y. 2022.

</span>
<span class="ltx_bibblock">Scaling open-vocabulary image segmentation with image-level labels.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">ECCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2022)</span>
<span class="ltx_bibblock">
He, K.; Chen, X.; Xie, S.; Li, Y.; Dollár, P.; and Girshick, R. 2022.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2017)</span>
<span class="ltx_bibblock">
He, K.; Gkioxari, G.; Dollár, P.; and Girshick, R. 2017.

</span>
<span class="ltx_bibblock">Mask r-cnn.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ICCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; and Chen, W. 2022.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2021)</span>
<span class="ltx_bibblock">
Jia, C.; Yang, Y.; Xia, Y.; Chen, Y.-T.; Parekh, Z.; Pham, H.; Le, Q.; Sung, Y.-H.; Li, Z.; and Duerig, T. 2021.

</span>
<span class="ltx_bibblock">Scaling up visual and vision-language representation learning with noisy text supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ICML</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al. (2022)</span>
<span class="ltx_bibblock">
Jia, M.; Tang, L.; Chen, B.-C.; Cardie, C.; Belongie, S.; Hariharan, B.; and Lim, S.-N. 2022.

</span>
<span class="ltx_bibblock">Visual prompt tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ECCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirillov et al. (2019)</span>
<span class="ltx_bibblock">
Kirillov, A.; He, K.; Girshick, R.; Rother, C.; and Dollár, P. 2019.

</span>
<span class="ltx_bibblock">Panoptic segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022a)</span>
<span class="ltx_bibblock">
Li, B.; Weinberger, K. Q.; Belongie, S.; Koltun, V.; and Ranftl, R. 2022a.

</span>
<span class="ltx_bibblock">Language-driven Semantic Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Liang (2021)</span>
<span class="ltx_bibblock">
Li, X.; and Liang, P. 2021.

</span>
<span class="ltx_bibblock">Prefix-tuning: Optimizing continuous prompts for generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ACL</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022b)</span>
<span class="ltx_bibblock">
Li, Y.; Mao, H.; Girshick, R.; and He, K. 2022b.

</span>
<span class="ltx_bibblock">Exploring plain vision transformer backbones for object detection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">ECCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2023)</span>
<span class="ltx_bibblock">
Liang, F.; Wu, B.; Dai, X.; Li, K.; Zhao, Y.; Zhang, H.; Zhang, P.; Vajda, P.; and Marculescu, D. 2023.

</span>
<span class="ltx_bibblock">Open-vocabulary semantic segmentation with mask-adapted clip.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Lin, T.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollár, P.; and Zitnick, C. L. 2014.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">ECCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Liu, H.; Li, C.; Wu, Q.; and Lee, Y. J. 2024.

</span>
<span class="ltx_bibblock">Visual instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Liu, Z.; Lin, Y.; Cao, Y.; Hu, H.; Wei, Y.; Zhang, Z.; Lin, S.; and Guo, B. 2021.

</span>
<span class="ltx_bibblock">Swin transformer: Hierarchical vision transformer using shifted windows.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">ICCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long, Shelhamer, and Darrell (2015)</span>
<span class="ltx_bibblock">
Long, J.; Shelhamer, E.; and Darrell, T. 2015.

</span>
<span class="ltx_bibblock">Fully convolutional networks for semantic segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Loshchilov, I.; and Hutter, F. 2019.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mottaghi et al. (2014)</span>
<span class="ltx_bibblock">
Mottaghi, R.; Chen, X.; Liu, X.; Cho, N.-G.; Lee, S.-W.; Fidler, S.; Urtasun, R.; and Yuille, A. 2014.

</span>
<span class="ltx_bibblock">The Role of Context for Object Detection and Semantic Segmentation in the Wild.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neuhold et al. (2017)</span>
<span class="ltx_bibblock">
Neuhold, G.; Ollmann, T.; Rota Bulo, S.; and Kontschieder, P. 2017.

</span>
<span class="ltx_bibblock">The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ICCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pate et al. (2021)</span>
<span class="ltx_bibblock">
Pate, S.; Xu, W.; Yang, Z.; Love, M.; Ganguri, S.; and Wong, L. L. 2021.

</span>
<span class="ltx_bibblock">Natural language for human-robot collaboration: Problems beyond language grounding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv:2110.04441</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al. (2023)</span>
<span class="ltx_bibblock">
Qin, J.; Wu, J.; Yan, P.; Li, M.; Yuxi, R.; Xiao, X.; Wang, Y.; Wang, R.; Wen, S.; Pan, X.; et al. 2023.

</span>
<span class="ltx_bibblock">FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; Krueger, G.; and Sutskever, I. 2021.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">ICML</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022)</span>
<span class="ltx_bibblock">
Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Ommer, B. 2022.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shalev-Shwartz and Ben-David (2014)</span>
<span class="ltx_bibblock">
Shalev-Shwartz, S.; and Ben-David, S. 2014.

</span>
<span class="ltx_bibblock">Understanding Machine Learning: From Theory to Algorithms.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Sun, Q.; Fang, Y.; Wu, L.; Wang, X.; and Cao, Y. 2023.

</span>
<span class="ltx_bibblock">EVA-CLIP: Improved Training Techniques for CLIP at Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv:2303.15389</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Toromanoff, Wirbel, and Moutarde (2020)</span>
<span class="ltx_bibblock">
Toromanoff, M.; Wirbel, E.; and Moutarde, F. 2020.

</span>
<span class="ltx_bibblock">End-to-end model-free reinforcement learning for urban driving using implicit affordances.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Wu, J.; Li, X.; Xu, S.; Yuan, H.; Ding, H.; Yang, Y.; Li, X.; Zhang, J.; Tong, Y.; Jiang, X.; et al. 2024.

</span>
<span class="ltx_bibblock">Towards open vocabulary learning: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">PAMI</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xian et al. (2018)</span>
<span class="ltx_bibblock">
Xian, Y.; Lampert, C. H.; Schiele, B.; and Akata, Z. 2018.

</span>
<span class="ltx_bibblock">Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">PAMI</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2024)</span>
<span class="ltx_bibblock">
Xie, B.; Cao, J.; Xie, J.; Khan, F. S.; and Pang, Y. 2024.

</span>
<span class="ltx_bibblock">SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023a)</span>
<span class="ltx_bibblock">
Xu, J.; Liu, S.; Vahdat, A.; Byeon, W.; Wang, X.; and Mello, S. D. 2023a.

</span>
<span class="ltx_bibblock">Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023b)</span>
<span class="ltx_bibblock">
Xu, M.; Zhang, Z.; Wei, F.; Hu, H.; and Bai, X. 2023b.

</span>
<span class="ltx_bibblock">Side Adapter Network for Open-Vocabulary Semantic Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">CVPR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2022)</span>
<span class="ltx_bibblock">
Xu, M.; Zhang, Z.; Wei, F.; Lin, Y.; Cao, Y.; Hu, H.; and Bai, X. 2022.

</span>
<span class="ltx_bibblock">A simple baseline for open-vocabulary semantic segmentation with pre-trained vision-language model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">ECCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023c)</span>
<span class="ltx_bibblock">
Xu, X.; Xiong, T.; Ding, Z.; and Tu, Z. 2023c.

</span>
<span class="ltx_bibblock">MasQCLIP for Open-Vocabulary Universal Image Segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">ICCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Yu, Q.; He, J.; Deng, X.; Shen, X.; and Chen, L.-C. 2023.

</span>
<span class="ltx_bibblock">Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Zhang, R.; Han, J.; Zhou, A.; Hu, X.; Yan, S.; Lu, P.; Li, H.; Gao, P.; and Qiao, Y. 2024.

</span>
<span class="ltx_bibblock">Llama-adapter: Efficient fine-tuning of language models with zero-init attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Zhao, B.; Tu, H.; Wei, C.; Mei, J.; and Xie, C. 2024.

</span>
<span class="ltx_bibblock">Tuning LayerNorm in Attention: Towards efficient multi-modal llm finetuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2019)</span>
<span class="ltx_bibblock">
Zhou, B.; Zhao, H.; Puig, X.; Xiao, T.; Fidler, S.; Barriuso, A.; and Torralba, A. 2019.

</span>
<span class="ltx_bibblock">Semantic understanding of scenes through the ade20k dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">IJCV</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Chen (2023)</span>
<span class="ltx_bibblock">
Zhu, C.; and Chen, L. 2023.

</span>
<span class="ltx_bibblock">A survey on open-vocabulary detection and segmentation: Past, present, and future.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">PAMI</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 24 17:43:30 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
