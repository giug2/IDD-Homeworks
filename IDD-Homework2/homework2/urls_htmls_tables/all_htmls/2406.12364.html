<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Does Context Help Mitigate Gender Bias in Neural Machine Translation?</title>
<!--Generated on Tue Jun 18 07:39:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.12364v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S1" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S2" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S2.SS1" title="In 2 Experimental Setup ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S2.SS2" title="In 2 Experimental Setup ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S2.SS3" title="In 2 Experimental Setup ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results and Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.SS1" title="In 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Stereotypical Professions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.SS2" title="In 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Non-informative Context</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S4" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S5" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S6" title="In Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Ethical Considerations</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Does Context Help Mitigate Gender Bias in Neural Machine Translation?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id5.5.id1">\And</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id6.6.id2">\And</span>Harritxu Gete<sup class="ltx_sup" id="id7.7.id3"><span class="ltx_text ltx_font_italic" id="id7.7.id3.1">1,2</span></sup>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id8.8.id4">\And</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id9.9.id5"><span class="ltx_text ltx_font_italic" id="id9.9.id5.1">1</span></sup>Vicomtech Foundation, Basque Research and Technology Alliance (BRTA)
<br class="ltx_break"/><sup class="ltx_sup" id="id10.10.id6"><span class="ltx_text ltx_font_italic" id="id10.10.id6.1">2</span></sup>University of the Basque Country UPV/EHU
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id11.11.id7">{hgete,tetchegoyhen}@vicomtech.org</span>
<span class="ltx_ERROR undefined" id="id12.12.id8">\And</span>Thierry Etchegoyhen<sup class="ltx_sup" id="id13.13.id9"><span class="ltx_text ltx_font_italic" id="id13.13.id9.1">1</span></sup>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id14.14.id10">\And</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id15.15.id11">\And</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id16.id1">Neural Machine Translation models tend to perpetuate gender bias present in their training data distribution. Context-aware models have been previously suggested as a means to mitigate this type of bias. In this work, we examine this claim by analysing in detail the translation of stereotypical professions in English to German, and translation with non-informative context in Basque to Spanish. Our results show that, although context-aware models can significantly enhance translation accuracy for feminine terms, they can still maintain or even amplify gender bias. These results highlight the need for more fine-grained approaches to bias mitigation in Neural Machine Translation.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.4">
<p class="ltx_p" id="p1.4.5"><span class="ltx_text ltx_font_bold" id="p1.4.5.1">Does Context Help Mitigate Gender Bias in Neural Machine Translation?</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.4.4" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.4.4.5" style="width:0.0pt;"></span>                      <span class="ltx_text ltx_inline-block" id="p1.4.4.6" style="width:0.0pt;"></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.1.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1.1.1.1.1">Harritxu Gete<sup class="ltx_sup" id="p1.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.1.1.1.1.1.1.1.1.1">1,2</span></sup></span></span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.3.3.3" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.3.3.3.2">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.2.2.2.1.1">
<span class="ltx_td ltx_align_center" id="p1.2.2.2.1.1.1"><sup class="ltx_sup" id="p1.2.2.2.1.1.1.1"><span class="ltx_text ltx_font_italic" id="p1.2.2.2.1.1.1.1.1">1</span></sup>Vicomtech Foundation, Basque Research and Technology Alliance (BRTA)</span></span>
<span class="ltx_tr" id="p1.3.3.3.2.2">
<span class="ltx_td ltx_align_center" id="p1.3.3.3.2.2.1"><sup class="ltx_sup" id="p1.3.3.3.2.2.1.1"><span class="ltx_text ltx_font_italic" id="p1.3.3.3.2.2.1.1.1">2</span></sup>University of the Basque Country UPV/EHU</span></span>
<span class="ltx_tr" id="p1.3.3.3.2.3.1">
<span class="ltx_td ltx_align_center" id="p1.3.3.3.2.3.1.1"><span class="ltx_text ltx_font_typewriter" id="p1.3.3.3.2.3.1.1.1">{hgete,tetchegoyhen}@vicomtech.org</span></span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.4.4.4" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.4.4.4.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.4.4.4.1.1">
<span class="ltx_td ltx_align_center" id="p1.4.4.4.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.4.4.4.1.1.1.1">Thierry Etchegoyhen<sup class="ltx_sup" id="p1.4.4.4.1.1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.4.4.4.1.1.1.1.1.1">1</span></sup></span></span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.4.4.7" style="width:0.0pt;"></span>                      <span class="ltx_text ltx_inline-block" id="p1.4.4.8" style="width:0.0pt;"></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Neural machine translation (NMT) models tend to exhibit gender bias, originating from their training data <cite class="ltx_cite ltx_citemacro_citep">(Stanovsky et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib13" title="">2019</a>; Saunders and Byrne, <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib12" title="">2020</a>)</cite>. A typical example is the translation of gender-neutral professions in a language like English, into languages with differentiated feminine and masculine forms. In this case, NMT systems often produce translations that reflect gender-stereotypical biases <cite class="ltx_cite ltx_citemacro_citep">(Troles and Schmid, <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib15" title="">2021</a>)</cite>. Beyond translation errors, bias perpetuation has a clear negative impact overall.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Several studies have addressed gender bias in NMT, highlighting various sources and manifestations of gender bias in NMT models. For example, <cite class="ltx_cite ltx_citemacro_citet">Prates et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib10" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Rescigno and Monti (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib11" title="">2023</a>)</cite> examined gender bias in commercial machine translation systems, revealing a systematic bias towards masculine translation. A variety of approaches have been explored to mitigate these effects, such as data augmentation by swapping gender-specific words <cite class="ltx_cite ltx_citemacro_citep">(Zmigrod et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib19" title="">2019</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib18" title="">2022</a>)</cite>, or the incorporation of gender tags in the input to guide the translation process <cite class="ltx_cite ltx_citemacro_citep">(Vanmassenhove et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib16" title="">2018</a>; Corral and Saralegi, <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib4" title="">2022</a>)</cite>. The use of context has also been studied as a potential solution, as context-aware models have been shown to significantly enhance translation quality for specific linguistic phenomena, including gender agreement <cite class="ltx_cite ltx_citemacro_citep">(Bawden et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib2" title="">2018</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Basta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib1" title="">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Currey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib5" title="">2022</a>)</cite> suggested that context-aware models could help mitigate gender bias in NMT. However, a more detailed study over specific gender categories is still warranted.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we further explore the role of context in reducing gender bias in NMT, by addressing the following question: does context always help mitigate bias in NMT or can it have bias perpetuation effects? To tackle this question, we studied two specific phenomena related to gender bias.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">First, we evaluated the performance of context-aware models in the translation of stereotypical professions from English into German and French, measuring translation accuracy on gender-based subsets of the data. Our results in this case indicate that, although context-aware models lead to significantly increasing the use of feminine forms, this was achieved mainly for professions that are stereotypically viewed as feminine, thus with limited bias mitigation.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We then studied the impact on gender bias of non-informative context in Basque to Spanish, i.e., where context lacks gender disambiguating information but nonetheless provides information that may impact the translation. In this case, our results showed significant increases in accuracy for masculine translation options, but notable losses for feminine ones. The use of context was thus detrimental in this case, exacerbating gender biases present in sentence-level models.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Although context can contribute positively to more accurate gender translation, our results highlight the complexity of gender bias in context-aware NMT systems and the need for more fine-grained approaches to mitigate this type of bias.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Experimental Setup</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As training data for our sentence-level baselines, for English-German, we selected the data from the WMT 2017 news translation task; for English-French, we used a mix of publicly available sentence-level parallel data to train baseline models, namely Europarl v7, NewsCommentary v10, CommonCrawl, UN, Giga from WMT 2017 and the IWSLT17 TED Talks <cite class="ltx_cite ltx_citemacro_citep">(Cettolo et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib3" title="">2012</a>)</cite>. We then selected the document-level IWSLT17 dataset to train our context-aware models. For evaluation, we selected the contextual subset of MT-GenEval <cite class="ltx_cite ltx_citemacro_citep">(Currey et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib5" title="">2022</a>)</cite> for both language pairs.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">For Basque to Spanish, we selected the TANDO<sup class="ltx_sup" id="S2.SS1.p2.1.1"><span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1.1">+</span></sup> <cite class="ltx_cite ltx_citemacro_citep">(Gete et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib6" title="">2024</a>)</cite> dataset to train our sentence- and context-level models, and the COH-TGT:GENDER challenge test set for evaluation, which features gender-related context phenomena where the disambiguating information only occurs on the target side. When using models that only have access to the source target context, this test will allow us to measure the impact of non-informative context.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Models</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We trained sentence-level baselines and concatenation-based context-aware models. Since the MT-GenEval test set contains only one context sentence in the source language, our analysis is focused solely on models with one source context sentence and no target context (2to1 model).</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Our 2to1 models follow the concatenation approach of <cite class="ltx_cite ltx_citemacro_citet">Tiedemann and Scherrer (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib14" title="">2017</a>)</cite>, using a Transformer-base architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib17" title="">2017</a>)</cite>, and were trained with MarianNMT <cite class="ltx_cite ltx_citemacro_citep">(Junczys-Dowmunt et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib7" title="">2018</a>)</cite>.
The embeddings for source, target and output layers were tied and the training was performed using the Adam optimiser <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib8" title="">2015</a>)</cite>. Context-aware models were initialised with weights from the sentence-level model.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Evaluation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Since both selected challenge test sets provide contrastive translations, we calculated models accuracy based on their preference for one translation over the other. As proposed by <cite class="ltx_cite ltx_citemacro_citet">Post and Junczys-Dowmunt (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib9" title="">2024</a>)</cite>, we also translated the source sentences and classified the translations as correct or incorrect. We will refer to this type of evaluation as <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.1">Generative</span>. To do this, we first identified correct and incorrect tokens by comparing correct translations with their contrastive counterparts. We then measured accuracy by categorising a translation as successful if it generated a correct token without producing any incorrect ones<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This differs from <cite class="ltx_cite ltx_citemacro_citet">Currey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib5" title="">2022</a>)</cite>, where any case with no incorrect tokens is categorised as successful.</span></span></span>. We also measured incorrect instances, where tokens determined as incorrect are present, and categorised as neutral those cases with neither correct nor incorrect tokens.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results and Analysis</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Stereotypical Professions</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We compare sentence-level models with context-aware models in their ability to translate professions from English into German and French, where, contrary to English, gender-specific forms for professions exist. The test selected for evaluation, MT-GenEval, is balanced in terms of feminine and masculine instances, and contains professions stereotypically viewed as masculine or feminine.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The results for English to German and English to French are shown in Tables <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T2" title="Table 2 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T2" title="Table 2 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">2</span></a>, respectively. Overall, context-aware models significantly improved accuracy, in both contrastive and generative evaluations for both language pairs. To assess whether these improvements correlate with a reduction in gender bias, we analysed these results in more details.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.2.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T2.2.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T2.2.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.2.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.m1.1.1" stretchy="false" xref="S3.T2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.m1.1a"><mo id="S3.T2.2.2.2.m1.1.1" stretchy="false" xref="S3.T2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.2.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.4.1.2">54.18%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.4.1.3">38.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.4.1.4">36.18%</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.2.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.5.2.2.1">69.27%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.5.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.5.2.3.1">45.09%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.2.5.2.4.1">27.27%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overall accuracy in MT-GenEval (EN-DE)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T2.4.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T2.4.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T2.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.4.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.3.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.3.1.1.m1.1"><semantics id="S3.T2.3.1.1.m1.1a"><mo id="S3.T2.3.1.1.m1.1.1" stretchy="false" xref="S3.T2.3.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.1.1.m1.1b"><ci id="S3.T2.3.1.1.m1.1.1.cmml" xref="S3.T2.3.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.4.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.4.2.2.m1.1"><semantics id="S3.T2.4.2.2.m1.1a"><mo id="S3.T2.4.2.2.m1.1.1" stretchy="false" xref="S3.T2.4.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.2.2.m1.1b"><ci id="S3.T2.4.2.2.m1.1.1.cmml" xref="S3.T2.4.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.4.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.1.2">53.41%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.1.3">42.95%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.1.4">39.40%</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.4.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.4.5.2.2.1">69.24%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.5.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.5.2.3.1">53.41%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.5.2.4.1">27.93%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Overall accuracy in the MT-GenEval (EN-FR)</figcaption>
</figure>
<figure class="ltx_table" id="S3.T6">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T6.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.2.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T6.2.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.2.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T6.2.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.2.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.2.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T6.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T6.2.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T6.1.1.1.m1.1"><semantics id="S3.T6.1.1.1.m1.1a"><mo id="S3.T6.1.1.1.m1.1.1" stretchy="false" xref="S3.T6.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T6.1.1.1.m1.1b"><ci id="S3.T6.1.1.1.m1.1.1.cmml" xref="S3.T6.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.1.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.2.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T6.2.2.2.m1.1"><semantics id="S3.T6.2.2.2.m1.1a"><mo id="S3.T6.2.2.2.m1.1.1" stretchy="false" xref="S3.T6.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T6.2.2.2.m1.1b"><ci id="S3.T6.2.2.2.m1.1.1.cmml" xref="S3.T6.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.2.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.2.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T6.2.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.2.4.1.2"><span class="ltx_text ltx_font_bold" id="S3.T6.2.4.1.2.1">92.00%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.2.4.1.3"><span class="ltx_text ltx_font_bold" id="S3.T6.2.4.1.3.1">71.09%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.2.4.1.4"><span class="ltx_text ltx_font_bold" id="S3.T6.2.4.1.4.1">5.64%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.2.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T6.2.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.2.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T6.2.5.2.2.1">91.45%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.2.5.2.3">67.27%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.2.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T6.2.5.2.4.1">6.73%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Accuracy over masculine forms (EN-DE)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T6.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.4.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T6.4.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.4.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T6.4.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.4.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.4.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T6.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T6.4.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.3.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T6.3.1.1.m1.1"><semantics id="S3.T6.3.1.1.m1.1a"><mo id="S3.T6.3.1.1.m1.1.1" stretchy="false" xref="S3.T6.3.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T6.3.1.1.m1.1b"><ci id="S3.T6.3.1.1.m1.1.1.cmml" xref="S3.T6.3.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.3.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.3.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.4.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T6.4.2.2.m1.1"><semantics id="S3.T6.4.2.2.m1.1a"><mo id="S3.T6.4.2.2.m1.1.1" stretchy="false" xref="S3.T6.4.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T6.4.2.2.m1.1b"><ci id="S3.T6.4.2.2.m1.1.1.cmml" xref="S3.T6.4.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.4.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.4.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.4.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T6.4.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.4.4.1.2">92.55%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.4.4.1.3"><span class="ltx_text ltx_font_bold" id="S3.T6.4.4.1.3.1">76.91%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.4.4.1.4"><span class="ltx_text ltx_font_bold" id="S3.T6.4.4.1.4.1">6.00%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.4.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T6.4.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.4.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T6.4.5.2.2.1">96.36%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.4.5.2.3"><span class="ltx_text ltx_font_bold" id="S3.T6.4.5.2.3.1">77.09%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.4.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T6.4.5.2.4.1">4.73%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Accuracy over masculine forms (EN-FR)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T6.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.6.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T6.6.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.6.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T6.6.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.6.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.6.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T6.6.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T6.6.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.5.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T6.5.1.1.m1.1"><semantics id="S3.T6.5.1.1.m1.1a"><mo id="S3.T6.5.1.1.m1.1.1" stretchy="false" xref="S3.T6.5.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T6.5.1.1.m1.1b"><ci id="S3.T6.5.1.1.m1.1.1.cmml" xref="S3.T6.5.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.5.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.5.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.6.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T6.6.2.2.m1.1"><semantics id="S3.T6.6.2.2.m1.1a"><mo id="S3.T6.6.2.2.m1.1.1" stretchy="false" xref="S3.T6.6.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T6.6.2.2.m1.1b"><ci id="S3.T6.6.2.2.m1.1.1.cmml" xref="S3.T6.6.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.6.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.6.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.6.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T6.6.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.6.4.1.2">16.36%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.6.4.1.3">4.91%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.6.4.1.4">66.73%</td>
</tr>
<tr class="ltx_tr" id="S3.T6.6.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T6.6.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.6.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T6.6.5.2.2.1">47.09%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.6.5.2.3"><span class="ltx_text ltx_font_bold" id="S3.T6.6.5.2.3.1">22.91%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.6.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T6.6.5.2.4.1">47.82%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Accuracy over feminine forms (EN-DE)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T6.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.8.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T6.8.3.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.8.3.1.2" rowspan="2"><span class="ltx_text" id="S3.T6.8.3.1.2.1">Contrast.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.8.3.1.3">Gen.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.8.3.1.4">Gen.</th>
</tr>
<tr class="ltx_tr" id="S3.T6.8.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T6.8.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.7.1.1">Correct (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T6.7.1.1.m1.1"><semantics id="S3.T6.7.1.1.m1.1a"><mo id="S3.T6.7.1.1.m1.1.1" stretchy="false" xref="S3.T6.7.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T6.7.1.1.m1.1b"><ci id="S3.T6.7.1.1.m1.1.1.cmml" xref="S3.T6.7.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.7.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.7.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.8.2.2">Incorrect (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T6.8.2.2.m1.1"><semantics id="S3.T6.8.2.2.m1.1a"><mo id="S3.T6.8.2.2.m1.1.1" stretchy="false" xref="S3.T6.8.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T6.8.2.2.m1.1b"><ci id="S3.T6.8.2.2.m1.1.1.cmml" xref="S3.T6.8.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.8.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T6.8.2.2.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.8.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T6.8.4.1.1">Sent-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.8.4.1.2">14.21%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.8.4.1.3">8.93%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.8.4.1.4">72.86%</td>
</tr>
<tr class="ltx_tr" id="S3.T6.8.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T6.8.5.2.1">2to1</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.8.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T6.8.5.2.2.1">42.08%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.8.5.2.3"><span class="ltx_text ltx_font_bold" id="S3.T6.8.5.2.3.1">29.69%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.8.5.2.4"><span class="ltx_text ltx_font_bold" id="S3.T6.8.5.2.4.1">51.18%</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Accuracy over feminine forms (EN-FR)</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We manually divided the test into two subsets based on the expected gender and calculated accuracy for each category, with the results shown in Tables <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T6" title="Table 6 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a> to <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T6" title="Table 6 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">6</span></a>.
The high scores in the masculine category, and the low scores in the feminine category, in both language pairs with the sentence-level baselines, suggest a significant bias in the data, causing the models to predominantly translate professions into the masculine form. Even when translating stereotypically feminine professions, the models generally tend to favour the masculine form as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.F1" title="Figure 1 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="87" id="S3.F1.g1" src="x1.png" width="132"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="87" id="S3.F1.g2" src="x2.png" width="132"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Distribution of sentence-level predictions in stereotipically feminine professions.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">When comparing the results with and without context, improvements are most notable in the feminine category, which increases by about 30 percentage points in both language pairs. In contrast, in the masculine category the increase is less than 4 points for English to French, and there is no significant difference for English to German. It thus seems that context might help mitigate the bias towards masculine forms when translating professions.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">We further analysed these results by focusing on professions categorised as stereotypically feminine or masculine, dividing the results into four subcategories based on the type of profession and the expected gender, and assessing accuracy using contrastive evaluation. Results in Tables <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T8" title="Table 8 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T8" title="Table 8 ‣ 3.1 Stereotypical Professions ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">8</span></a> show that, for both language pairs, the largest gains from context originate from the feminine category as expected, but to a much larger degree for professions stereotypically seen as feminine.</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">The differences in accuracy for the feminine category, between professions classified as feminine and those classified as masculine, thus increased with the use of context. This was the case both in English-German, where the baselines reflected almost no initial differences between the two groups, and English-French where the initial baseline differences were amplified.</p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1">These results indicate that context-aware models can help mitigate the bias in favour of masculine translations, significantly increasing the use of feminine forms, but at the same time maintaining or increasing the differences in accuracy between instances that belong to an existing stereotype and those that do not.</p>
</div>
<figure class="ltx_table" id="S3.T8">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T8.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T8.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.5.1.1" rowspan="2"><span class="ltx_text" id="S3.T8.4.5.1.1.1">Sentence-level</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T8.4.5.1.2">Actual gender</th>
<th class="ltx_td ltx_th ltx_th_column" id="S3.T8.4.5.1.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.5.1.4" rowspan="2"><span class="ltx_text" id="S3.T8.4.5.1.4.1">Context-aware</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T8.4.5.1.5">Actual gender</th>
</tr>
<tr class="ltx_tr" id="S3.T8.4.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.6.2.1">Feminine</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.6.2.2">Masculine</th>
<th class="ltx_td ltx_th ltx_th_column" id="S3.T8.4.6.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.6.2.4">Feminine</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.4.6.2.5">Masculine</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T8.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.2.2.3">Stereot. Fem.</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.2.2.4">17.33%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.2.2.5">88.67%</td>
<td class="ltx_td" id="S3.T8.2.2.6"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.2.2.7">Stereot. Fem.</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.1.1.1">56.00% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.1.1.1.m1.1"><semantics id="S3.T8.1.1.1.m1.1a"><mo id="S3.T8.1.1.1.m1.1.1" stretchy="false" xref="S3.T8.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.1.1.1.m1.1b"><ci id="S3.T8.1.1.1.m1.1.1.cmml" xref="S3.T8.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.1.1.1.m1.1d">↑</annotation></semantics></math> 38.67%)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.2.2.2">89.33% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.2.2.2.m1.1"><semantics id="S3.T8.2.2.2.m1.1a"><mo id="S3.T8.2.2.2.m1.1.1" stretchy="false" xref="S3.T8.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.2.2.2.m1.1b"><ci id="S3.T8.2.2.2.m1.1.1.cmml" xref="S3.T8.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.2.2.2.m1.1d">↑</annotation></semantics></math> 0.66%)</td>
</tr>
<tr class="ltx_tr" id="S3.T8.4.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.4.4.3">Stereot. Masc.</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.4.4.4">18.00%</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.4.4.5">97.33%</td>
<td class="ltx_td" id="S3.T8.4.4.6"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.4.4.7">Stereot. Masc.</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.3.3.1">40.00% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.3.3.1.m1.1"><semantics id="S3.T8.3.3.1.m1.1a"><mo id="S3.T8.3.3.1.m1.1.1" stretchy="false" xref="S3.T8.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.3.3.1.m1.1b"><ci id="S3.T8.3.3.1.m1.1.1.cmml" xref="S3.T8.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.3.3.1.m1.1d">↑</annotation></semantics></math> 22.00%)</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.4.4.2">93.33% (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T8.4.4.2.m1.1"><semantics id="S3.T8.4.4.2.m1.1a"><mo id="S3.T8.4.4.2.m1.1.1" stretchy="false" xref="S3.T8.4.4.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T8.4.4.2.m1.1b"><ci id="S3.T8.4.4.2.m1.1.1.cmml" xref="S3.T8.4.4.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.4.4.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.4.4.2.m1.1d">↓</annotation></semantics></math> 4.00%)</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Accuracy over gender-specific subsets (EN-DE)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T8.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T8.8.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.5.1.1" rowspan="2"><span class="ltx_text" id="S3.T8.8.5.1.1.1">Sentence-level</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T8.8.5.1.2">Actual gender</th>
<th class="ltx_td ltx_th ltx_th_column" id="S3.T8.8.5.1.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.5.1.4" rowspan="2"><span class="ltx_text" id="S3.T8.8.5.1.4.1">Context-aware</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T8.8.5.1.5">Actual gender</th>
</tr>
<tr class="ltx_tr" id="S3.T8.8.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.6.2.1">Feminine</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.6.2.2">Masculine</th>
<th class="ltx_td ltx_th ltx_th_column" id="S3.T8.8.6.2.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.6.2.4">Feminine</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T8.8.6.2.5">Masculine</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T8.6.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.6.2.3">Stereot. Fem.</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.6.2.4">21.33%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.6.2.5">87.33%</td>
<td class="ltx_td" id="S3.T8.6.2.6"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.6.2.7">Stereot. Fem.</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T8.5.1.1">49.33% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.5.1.1.m1.1"><semantics id="S3.T8.5.1.1.m1.1a"><mo id="S3.T8.5.1.1.m1.1.1" stretchy="false" xref="S3.T8.5.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.5.1.1.m1.1b"><ci id="S3.T8.5.1.1.m1.1.1.cmml" xref="S3.T8.5.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.5.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.5.1.1.m1.1d">↑</annotation></semantics></math> 28.00%)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.6.2.2">96.67% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.6.2.2.m1.1"><semantics id="S3.T8.6.2.2.m1.1a"><mo id="S3.T8.6.2.2.m1.1.1" stretchy="false" xref="S3.T8.6.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.6.2.2.m1.1b"><ci id="S3.T8.6.2.2.m1.1.1.cmml" xref="S3.T8.6.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.6.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.6.2.2.m1.1d">↑</annotation></semantics></math> 9.34%)</td>
</tr>
<tr class="ltx_tr" id="S3.T8.8.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.8.4.3">Stereot. Masc.</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.8.4.4">8.72%</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.8.4.5">97.33%</td>
<td class="ltx_td" id="S3.T8.8.4.6"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.8.4.7">Stereot. Masc.</td>
<td class="ltx_td ltx_align_right ltx_border_b" id="S3.T8.7.3.1">30.87% (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T8.7.3.1.m1.1"><semantics id="S3.T8.7.3.1.m1.1a"><mo id="S3.T8.7.3.1.m1.1.1" stretchy="false" xref="S3.T8.7.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T8.7.3.1.m1.1b"><ci id="S3.T8.7.3.1.m1.1.1.cmml" xref="S3.T8.7.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.7.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T8.7.3.1.m1.1d">↑</annotation></semantics></math> 22.15%)</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.8.4.2">97.33% (<math alttext="=" class="ltx_Math" display="inline" id="S3.T8.8.4.2.m1.1"><semantics id="S3.T8.8.4.2.m1.1a"><mo id="S3.T8.8.4.2.m1.1.1" xref="S3.T8.8.4.2.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.T8.8.4.2.m1.1b"><eq id="S3.T8.8.4.2.m1.1.1.cmml" xref="S3.T8.8.4.2.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.T8.8.4.2.m1.1c">=</annotation><annotation encoding="application/x-llamapun" id="S3.T8.8.4.2.m1.1d">=</annotation></semantics></math>)</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Accuracy over gender-specific subsets (EN-FR)</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Non-informative Context</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In this section, we focus on the effect of introducing context that lacks relevant disambiguating information for the translation into the correct gender. Although this type of analysis is unusual, because standard tests aim to evaluate if a model is able to use contextual information to handle extra-sentential phenomena, context does not always provide relevant information to solve a specific phenomenon, but is still nonetheless present and impacts the actual translation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">For this analysis, we used the COH-TGT:GENDER test of TANDO<sup class="ltx_sup" id="S3.SS2.p2.1.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.1.1">+</span></sup> for Basque to Spanish translation, where the disambiguating information is on the target side. Specifically, we analysed the parliamentary domain subset of the test, as the results of <cite class="ltx_cite ltx_citemacro_citet">Gete et al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#bib.bib6" title="">2024</a>)</cite> indicate a clear tendency towards masculine translation in this domain. Since we compare a sentence-level model with a 2to1 model that only has access to the source context, we ensure that neither model has access to the disambiguating information on the target side.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The contrastive evaluation results shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T9" title="Table 9 ‣ 3.2 Non-informative Context ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">9</span></a> indicate that, as expected, the overall accuracy does not vary with or without context with uninformative context. However, when dividing the results by gender category, the accuracy for the masculine category increased to 98%, while the accuracy for the feminine category decreased from 10% to 2%. Using uninformative context actually increased gender bias in this case.</p>
</div>
<figure class="ltx_table" id="S3.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T9.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T9.1.2.1">
<td class="ltx_td ltx_border_tt" id="S3.T9.1.2.1.1"></td>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S3.T9.1.2.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T9.1.2.1.3">Total</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T9.1.2.1.4">Masculine</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T9.1.2.1.5">Feminine</th>
</tr>
<tr class="ltx_tr" id="S3.T9.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.1.3.2.1">Sentence-level</td>
<td class="ltx_td ltx_border_t" id="S3.T9.1.3.2.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T9.1.3.2.3">50%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T9.1.3.2.4">90%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T9.1.3.2.5">10%</td>
</tr>
<tr class="ltx_tr" id="S3.T9.1.4.3">
<td class="ltx_td ltx_align_left" id="S3.T9.1.4.3.1">2to1</td>
<td class="ltx_td" id="S3.T9.1.4.3.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T9.1.4.3.3">50%</td>
<td class="ltx_td ltx_align_center" id="S3.T9.1.4.3.4">98%</td>
<td class="ltx_td ltx_align_center" id="S3.T9.1.4.3.5">2%</td>
</tr>
<tr class="ltx_tr" id="S3.T9.1.1">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T9.1.1.1">2to1<sup class="ltx_sup" id="S3.T9.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S3.T9.1.1.1.1.1">∗</span></sup> - ctxTED</td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S3.T9.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T9.1.1.3">50%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T9.1.1.4">88%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T9.1.1.5">12%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Contrastive accuracy on the parliamentary subsets of COH-TGT:GENDER (EU-ES)</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Additionally, we performed a generative evaluation over feminine forms only (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.12364v1#S3.T10" title="Table 10 ‣ 3.2 Non-informative Context ‣ 3 Results and Analysis ‣ Does Context Help Mitigate Gender Bias in Neural Machine Translation?"><span class="ltx_text ltx_ref_tag">10</span></a>). In line with the contrastive results, the sentence-level results indicate a clear tendency towards masculine translation in this domain, with 70% of incorrect instances in the feminine subset. The results also confirm that the use of context exacerbates this tendency, resulting in even fewer correct feminine forms translation.</p>
</div>
<figure class="ltx_table" id="S3.T10">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T10.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T10.1.2.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T10.1.2.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T10.1.2.1.2">Correct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T10.1.2.1.3">Incorrect</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T10.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T10.1.3.1.1">Sentence-level</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T10.1.3.1.2">4%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T10.1.3.1.3">70%</td>
</tr>
<tr class="ltx_tr" id="S3.T10.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T10.1.4.2.1">2to1</th>
<td class="ltx_td ltx_align_center" id="S3.T10.1.4.2.2">0%</td>
<td class="ltx_td ltx_align_center" id="S3.T10.1.4.2.3">74%</td>
</tr>
<tr class="ltx_tr" id="S3.T10.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T10.1.1.1">2to1<sup class="ltx_sup" id="S3.T10.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S3.T10.1.1.1.1.1">∗</span></sup> - ctxTED</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T10.1.1.2">4%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T10.1.1.3">70%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Generative accuracy on the feminine parliamentary subset of COH-TGT:GENDER (EU-ES)</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">A possible explanation for these results is that, even if the context does not contain relevant disambiguating information, it may still include domain-related information. In the political domain, which strongly favours masculine translations, the introduction of context might reinforce this bias.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1">To test this hypothesis, we evaluated the same sentences from the political domain, but using context from another domain, namely the TED talks subset of the COH-TGT:GENDER test (ctxTED), which also lacks disambiguating information in the source context side.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">In the contrastive evaluation, there was a 10 percentage point difference favoring the feminine category over the original 2to1 model, at the expense of the masculine category. In the generative evaluation, the results were identical to sentence-level results. It thus seems that an uninformative context from the same domain can be a factor in actually increasing gender bias.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusions</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This study investigated the impact of context-aware models on mitigating gender bias in NMT, focusing on the translation of professions from English into German and French, as well as translation with uninformative context in Basque to Spanish.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Our results show that, although contextual models can significantly improve the overall translation accuracy on gender-specific terms, this was achieved mainly over stereotypically feminine professions. The use of context actually increased the disparity between stereotypical genders in this case. Non-informative context was also shown to increase gender-related bias in a domain with strong latent bias, when using context from a different domain had no such effects.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">These results underscore the need for more comprehensive approaches to bias in NMT, including more specific evaluations over balanced datasets. Novel mitigation techniques and a deeper understanding of the impact of context will also be needed to further address translation bias.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The experiments were conducted exclusively with 2to1 context-aware models. This choice was influenced by the characteristics of one of the test sets, which only provided one context sentence in the source language. As a result, our findings are specific to this type of model, and further research is needed to explore the effects of other context-aware architectures. Expanding the range of test sets and domains would also provide a more comprehensive understanding of biased translation with and without context.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Ethical Considerations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our analysis focused solely on binary gender categories, examining translations in terms of masculine and feminine forms. This binary perspective excludes individuals who do not identify with either of these normative genders. Addressing this issue would require developing and incorporating more inclusive linguistic resources and methodologies that recognize and respect non-binary identities.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Basta et al. (2020)</span>
<span class="ltx_bibblock">
Christine Basta, Marta R. Costa-jussà, and José A. R. Fonollosa. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.winlp-1.25" title="">Towards mitigating gender bias in a decoder-based neural machine translation model by adding contextual information</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the Fourth Widening Natural Language Processing Workshop</em>, pages 99–102, Seattle, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bawden et al. (2018)</span>
<span class="ltx_bibblock">
Rachel Bawden, Rico Sennrich, Alexandra Birch, and Barry Haddow. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N18-1118" title="">Evaluating discourse phenomena in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</em>, pages 1304–1313, New Orleans, Louisiana. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cettolo et al. (2012)</span>
<span class="ltx_bibblock">
Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2012.eamt-1.60" title="">WIT3: Web inventory of transcribed and translated talks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 16th Annual Conference of the European Association for Machine Translation</em>, pages 261–268, Trento, Italy. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corral and Saralegi (2022)</span>
<span class="ltx_bibblock">
Ander Corral and Xabier Saralegi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.10" title="">Gender bias mitigation for NMT involving genderless languages</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 165–176, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Currey et al. (2022)</span>
<span class="ltx_bibblock">
Anna Currey, Maria Nadejde, Raghavendra Reddy Pappagari, Mia Mayer, Stanislas Lauly, Xing Niu, Benjamin Hsu, and Georgiana Dinu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.288" title="">MT-GenEval: A counterfactual and contextual dataset for evaluating gender accuracy in machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 4287–4299, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gete et al. (2024)</span>
<span class="ltx_bibblock">
Harritxu Gete, Thierry Etchegoyhen, Gorka Labaka, Ander Corral, Xabier Saralegi, Nora Aranberri, David Ponce, Igor Ellakuria Santos, and Maite Martin. 2024.

</span>
<span class="ltx_bibblock">Tando^+: Corpus and baselines for document-level machine translation in basque-spanish and basque-french.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Junczys-Dowmunt et al. (2018)</span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri Aji, Nikolay Bogoychev, André F. T. Martins, and Alexandra Birch. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P18-4020" title="">Marian: Fast neural machine translation in C++</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of ACL 2018, System Demonstrations</em>, pages 116–121, Melbourne, Australia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
Diederick P. Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1412.6980" title="">Adam: A method for stochastic optimization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post and Junczys-Dowmunt (2024)</span>
<span class="ltx_bibblock">
Matt Post and Marcin Junczys-Dowmunt. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2304.12959" title="">Escaping the sentence-level paradigm in machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Preprint</em>, arXiv:2304.12959.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prates et al. (2019)</span>
<span class="ltx_bibblock">
Marcelo O. R. Prates, Pedro H. C. Avelar, and Luis Lamb. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1809.02208" title="">Assessing gender bias in machine translation – a case study with google translate</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Preprint</em>, arXiv:1809.02208.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rescigno and Monti (2023)</span>
<span class="ltx_bibblock">
Argentina Rescigno and Johanna Monti. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.26615/issn.2683-0078.2023_001" title="">Gender bias in machine translation: a statistical evaluation of google translate and deepl for english, italian and german</a>.

</span>
<span class="ltx_bibblock">pages 1–11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saunders and Byrne (2020)</span>
<span class="ltx_bibblock">
Danielle Saunders and Bill Byrne. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.690" title="">Reducing gender bias in neural machine translation as a domain adaptation problem</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7724–7736, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stanovsky et al. (2019)</span>
<span class="ltx_bibblock">
Gabriel Stanovsky, Noah A. Smith, and Luke Zettlemoyer. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1164" title="">Evaluating gender bias in machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 1679–1684, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann and Scherrer (2017)</span>
<span class="ltx_bibblock">
Jörg Tiedemann and Yves Scherrer. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W17-4811" title="">Neural machine translation with extended context</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Third Workshop on Discourse in Machine Translation</em>, pages 82–92, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Troles and Schmid (2021)</span>
<span class="ltx_bibblock">
Jonas-Dario Troles and Ute Schmid. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wmt-1.61" title="">Extending challenge sets to uncover gender bias in machine translation: Impact of stereotypical verbs and adjectives</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the Sixth Conference on Machine Translation</em>, pages 531–541, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vanmassenhove et al. (2018)</span>
<span class="ltx_bibblock">
Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1334" title="">Getting gender right in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 3003–3008, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in Neural Information Processing Systems 30</em>, pages 5998–6008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Jun Wang, Benjamin Rubinstein, and Trevor Cohn. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.184" title="">Measuring and mitigating name biases in neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 2576–2590, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zmigrod et al. (2019)</span>
<span class="ltx_bibblock">
Ran Zmigrod, Sabrina J. Mielke, Hanna Wallach, and Ryan Cotterell. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1161" title="">Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 1651–1661, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun 18 07:39:50 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
