<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.11724] TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning</title><meta property="og:description" content="Current Large Language Models (LLMs) exhibit limited ability to understand table structures and to apply precise numerical reasoning, which is crucial for tasks such as table question answering (TQA) and table-based faâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.11724">

<!--Generated on Sun Oct  6 01:26:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">TART: An Open-Source Tool-Augmented Framework 
<br class="ltx_break">for Explainable Table-based Reasoning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Xinyuan Lu<sup id="id1.1.id1" class="ltx_sup">1</sup>,
Liangming Pan<sup id="id2.2.id2" class="ltx_sup">2</sup>,
Yubo Ma<sup id="id3.3.id3" class="ltx_sup">3</sup>,
Preslav Nakov<sup id="id4.4.id4" class="ltx_sup">4</sup>,
Min-Yen Kan<sup id="id5.5.id5" class="ltx_sup">1</sup>
</span><span class="ltx_author_notes">Corresponding Author</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Current Large Language Models (LLMs) exhibit limited ability to understand table structures and to apply precise numerical reasoning, which is crucial for tasks such as <span id="id6.id1.1" class="ltx_text ltx_font_italic">table question answering (TQA)</span> and <span id="id6.id1.2" class="ltx_text ltx_font_italic">table-based fact verification (TFV)</span>. To address these challenges, we introduce our <span id="id6.id1.3" class="ltx_text ltx_font_italic">Tool-Augmented Reasoning framework for Tables</span> (<span id="id6.id1.4" class="ltx_text ltx_font_smallcaps">TART</span>), which integrates LLMs with specialized tools. <span id="id6.id1.5" class="ltx_text ltx_font_smallcaps">TART</span> contains three key components: a <span id="id6.id1.6" class="ltx_text ltx_font_italic">table formatter</span> to ensure accurate data representation, a <span id="id6.id1.7" class="ltx_text ltx_font_italic">tool maker</span> to develop specific computational tools, and an <span id="id6.id1.8" class="ltx_text ltx_font_italic">explanation generator</span> to maintain explainability. We also present the <span id="id6.id1.9" class="ltx_text ltx_font_smallcaps">ToolTab</span> dataset, a new benchmark designed specifically for training LLMs in tableâ€“tool integration. Our experiments indicate that <span id="id6.id1.10" class="ltx_text ltx_font_smallcaps">TART</span> achieves substantial improvements over existing methods (<span id="id6.id1.11" class="ltx_text ltx_font_italic">e.g.,</span> Chain-of-Thought) by improving both the precision of data processing and the clarity of the reasoning process. Notably, <span id="id6.id1.12" class="ltx_text ltx_font_smallcaps">TART</span> paired with <span id="id6.id1.13" class="ltx_text ltx_font_typewriter">CodeLlama</span> achieves 90.0% of the accuracy of the closed-sourced LLM <span id="id6.id1.14" class="ltx_text ltx_font_typewriter">GPT-3.5-turbo</span>, highlighting its robustness in diverse real-world scenarios. All the code and data are available at <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self">https://github.com/XinyuanLu00/TART</span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Tabular data is prevalent across multiple fields such as scientific research, financial reporting, and healthcare recordsÂ <cite class="ltx_cite ltx_citemacro_citep">(Dong etÂ al. <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. Manual handling of such data can be both routine and error-prone, or may require specialized skills, highlighting the need for automated table reasoning to improve efficiencyÂ <cite class="ltx_cite ltx_citemacro_citep">(Badaro, Saeed, and Papotti <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>.
Typical table-based reasoning tasks include <span id="S1.p1.1.1" class="ltx_text ltx_font_italic"> table question answering (TQA)</span>, which extracts precise information from tables to answer given queriesÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib7" title="" class="ltx_ref">2020b</a>; Zhu etÂ al. <a href="#bib.bib49" title="" class="ltx_ref">2021</a>; Nan etÂ al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite>, and <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">table-based fact verification (TFV)</span>, which verifies the correctness of statements by cross-referencing them with facts stored in tablesÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib33" title="" class="ltx_ref">2021</a>; Lu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2023c</a>)</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.11724/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="257" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of the TableQA task, demonstrating the verification of travel time via boat schedule and demonstrating the critical skills needed for accurate table reasoning: table structure understanding, precise numerical calculations, and executing sequential reasoning steps.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2409.11724/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="514" height="243" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overall framework of <span id="S1.F2.8.1" class="ltx_text ltx_font_smallcaps">TART</span>, which contains three main modules: (<em id="S1.F2.9.2" class="ltx_emph ltx_font_italic">i</em>)Â <span id="S1.F2.10.3" class="ltx_text ltx_font_italic">table formatter</span>, which prepares and organizes the raw table data, (<em id="S1.F2.11.4" class="ltx_emph ltx_font_italic">ii</em>)Â <span id="S1.F2.12.5" class="ltx_text ltx_font_italic">tool maker</span>, which creates specialized tools for precise table manipulation, and (<em id="S1.F2.13.6" class="ltx_emph ltx_font_italic">iii</em>)Â <span id="S1.F2.14.7" class="ltx_text ltx_font_italic">explanation generator</span>, which produces user-friendly explanations integrating the output of different tools.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Modern large language models (LLMs) such as GPT-4Â <cite class="ltx_cite ltx_citemacro_citep">(OpenAI <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> have shown remarkable reasoning capabilities across a variety of tasks, spurring interest in their application to table-based tasksÂ <cite class="ltx_cite ltx_citemacro_citep">(Ye etÂ al. <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>. However, table-based reasoning presents unique challenges for LLMs, which are primarily trained on sequential text dataÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib45" title="" class="ltx_ref">2023a</a>)</cite>, as illustrated by a real-world example in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">(1) Understanding and operating on table structure</span>: LLMs must adapt to the non-linear format of the tables, which demands unique reasoning skills such as recognizing headers, interpreting the roles of the rows and the columns, and precisely extracting information from relevant table cells. <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">(2) Precise numerical reasoning:</span> Tables often contain quantitative information that requires precise calculations and comparisons. LLMs must perform operations such as summation, averaging, or trend analysis accurately, often over multiple cells or tables, which is a shift from their usual text-based reasoning tasksÂ <cite class="ltx_cite ltx_citemacro_citep">(Herzig etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Liu etÂ al. <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>. <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">(3) Reasoning planning:</span> LLMs often need to plan several reasoning steps ahead, as shown in the example in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. This includes decomposing the original question, determining which table parts are relevant and anticipating intermediate calculations or data transformations.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Existing approaches that use LLMs for table-based reasoning can be broadly classified into two categories. One is <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">chain-of-thought (CoT) reasoning</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Wei etÂ al. <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>, in which the model is prompted to perform step-by-step reasoning over the input table flattened as a textual sequenceÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib45" title="" class="ltx_ref">2023a</a>; Jin and Lu <a href="#bib.bib16" title="" class="ltx_ref">2023</a>; Chen <a href="#bib.bib4" title="" class="ltx_ref">2023</a>; Ye etÂ al. <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>. Despite its flexibility, CoT often lacks precision in tabular operations and numerical reasoning, such as sorting, counting, and filteringÂ <cite class="ltx_cite ltx_citemacro_citep">(Wu and Feng <a href="#bib.bib40" title="" class="ltx_ref">2024</a>)</cite>. The second approach, <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">program-based reasoning (PoT)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al. <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Chen etÂ al. <a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite> prompts the model to generate SQL or Python code to enable precise reasoningÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu, Wang, and Chen <a href="#bib.bib19" title="" class="ltx_ref">2023</a>; Zhang etÂ al. <a href="#bib.bib46" title="" class="ltx_ref">2023b</a>; Wang etÂ al. <a href="#bib.bib37" title="" class="ltx_ref">2024c</a>; Wu and Feng <a href="#bib.bib40" title="" class="ltx_ref">2024</a>)</cite>. However, this method struggles with reasoning planning and its reasoning is less understandable to humansÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib46" title="" class="ltx_ref">2023b</a>)</cite>. Therefore, there is potential value in integrating the advantages of program-based and textual reasoning, to achieve both high precision and explainability in table-based reasoning.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Inspired by the recent paradigm of tool-augmented language modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al. <a href="#bib.bib35" title="" class="ltx_ref">2024a</a>; Schick etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>, we propose <span id="S1.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T<span id="S1.p4.1.1.1" class="ltx_text ltx_font_medium">ool-</span>A<span id="S1.p4.1.1.2" class="ltx_text ltx_font_medium">ugmented </span>R<span id="S1.p4.1.1.3" class="ltx_text ltx_font_medium">easoning framework for </span>T<span id="S1.p4.1.1.4" class="ltx_text ltx_font_medium">ables</span></span> (<span id="S1.p4.1.2" class="ltx_text ltx_font_smallcaps">TART</span>), which integrates external tool calling into the chain-of-thought reasoning process, as shown in FigureÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Initially, <span id="S1.p4.1.3" class="ltx_text ltx_font_smallcaps">TART</span> processes the input table using a specialized module <span id="S1.p4.1.4" class="ltx_text ltx_font_italic">table formatter</span> to clean and to format the raw table data, preparing it for the subsequent table operations. Subsequently, the <span id="S1.p4.1.5" class="ltx_text ltx_font_italic">tool maker</span> calls specialized tools (Python functions) for tabular manipulation and numerical reasoning (e.g., adding columns, selecting rows, and grouping). Alongside these tools, <span id="S1.p4.1.6" class="ltx_text ltx_font_smallcaps">TART</span> also crafts a <span id="S1.p4.1.7" class="ltx_text ltx_font_italic">reasoning plan</span> that outlines the programmatic calling sequence of the tools, specifying the necessary arguments and the expected return values for each call.
Finally, following the structured reasoning plan, the <span id="S1.p4.1.8" class="ltx_text ltx_font_italic">explanation generator</span> produces a hybrid text-and-program output, integrating calls to external tools into coherent, human-readable chain-of-thought explanations. In doing so, <span id="S1.p4.1.9" class="ltx_text ltx_font_smallcaps">TART</span> efficiently delegates table operations and precise numerical calculations to generated tools, while preserving the planning ability and explainability of CoT.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To train the modules in <span id="S1.p5.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, we further synthesize the <span id="S1.p5.1.2" class="ltx_text ltx_font_smallcaps">ToolTab</span> dataset by distilling knowledge from a teacher LLM.
We evaluate <span id="S1.p5.1.3" class="ltx_text ltx_font_smallcaps">TART</span> on nine different table-based reasoning benchmarks. The results highlight the effectiveness of integrating task-specific tools for enhancing complex reasoning capabilities. Notably, TART consistently outperformed the CoT baseline, achieving near-parity with <span id="S1.p5.1.4" class="ltx_text ltx_font_typewriter">GPT-3.5-turbo</span> on several benchmarks, showcasing its practical utility in real-world scenarios.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In summary, our contributions are threefold:</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><math id="S1.p7.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.p7.1.m1.1a"><mo id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><ci id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">\bullet</annotation></semantics></math> We propose <span id="S1.p7.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, a novel framework that enhances table-based reasoning by integrating tools into the reasoning process, which addresses the limitations of current LLMs in handling table structures and executing precise calculations.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p"><math id="S1.p8.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.p8.1.m1.1a"><mo id="S1.p8.1.m1.1.1" xref="S1.p8.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.p8.1.m1.1b"><ci id="S1.p8.1.m1.1.1.cmml" xref="S1.p8.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.1.m1.1c">\bullet</annotation></semantics></math> We develop <span id="S1.p8.1.1" class="ltx_text ltx_font_smallcaps">ToolTab</span>, a comprehensive benchmark specifically designed to train LLMs on table-tool integration. It includes diverse real-world tables, uniform format, and careful validation to ensure high-quality training.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p"><math id="S1.p9.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.p9.1.m1.1a"><mo id="S1.p9.1.m1.1.1" xref="S1.p9.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.p9.1.m1.1b"><ci id="S1.p9.1.m1.1.1.cmml" xref="S1.p9.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p9.1.m1.1c">\bullet</annotation></semantics></math> Our experiments confirm that <span id="S1.p9.1.1" class="ltx_text ltx_font_smallcaps">TART</span> not only improves the precision and the explainability of table-based reasoning, but also generalizes effectively to out-of-domain datasets.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Table-based reasoning tasks involve interpreting and manipulating data from structured tabular sources to answer questions, verify facts, or generate summaries. Early approaches used executable SQL or SPARQL to interact with tabular dataÂ <cite class="ltx_cite ltx_citemacro_citep">(Yin etÂ al. <a href="#bib.bib43" title="" class="ltx_ref">2015</a>; Yu etÂ al. <a href="#bib.bib44" title="" class="ltx_ref">2018</a>)</cite>, or graph neural networks to better encode table structuresÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhong etÂ al. <a href="#bib.bib47" title="" class="ltx_ref">2020</a>; Yang etÂ al. <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>. However, they typically suffer from poor generalization capabilities due to their reliance on specific table formats and linguistic patterns.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Recently, large language models (LLMs) have shown great potential in improving table-based reasoning tasks. Pioneering studies have focused on developing table pre-training strategies, where LLMs are trained with sentence-table pairs to enhance their general table reasoning capabilitiesÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib6" title="" class="ltx_ref">2020a</a>; Herzig etÂ al. <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Zhou etÂ al. <a href="#bib.bib48" title="" class="ltx_ref">2022</a>; Gu etÂ al. <a href="#bib.bib13" title="" class="ltx_ref">2022</a>; Ye etÂ al. <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>. Subsequent work further explored different reasoning strategies to improve efficacy. For example, <cite class="ltx_cite ltx_citemacro_citet">Ye etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> proposed using LLMs as decomposers to effectively reason over tables by breaking down large tables into smaller sub-evidence and complex questions into simpler sub-questions. <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2024c</a>)</cite> introduced the <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">Chain-of-Table</span> framework, where tabular data is explicitly used in the reasoning chain for intermediate thoughts.
<span id="S2.p2.1.2" class="ltx_text ltx_font_italic">ReAcTable</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib46" title="" class="ltx_ref">2023b</a>)</cite> combined reactive and proactive reasoning strategies to improve accuracy and retrieval from complex tables.
Despite these advances, these approaches primarily rely on pure textual reasoning, such as chain-of-thought, which sacrifices the precision required for table manipulations and numerical reasoning, both crucial for table-based reasoning.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">To address these limitations, <span id="S2.p3.1.1" class="ltx_text ltx_font_smallcaps">TART</span> extends the use of LLMs with integrated external tools, aimed at improving reasoning precision with function execution while maintaining explainability with LLM-based reasoning. Unlike previous methods that focus on a single reasoning strategy, <span id="S2.p3.1.2" class="ltx_text ltx_font_smallcaps">TART</span> enhances table reasoning with multiple strategies: formatting tables for better data representation, calling tools for precise calculation, and generating user-friendly explanations that clarify the reasoning process.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.20" class="ltx_p">Generally, a table-based reasoning model, <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="f_{\theta}(\cdot)" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.2" xref="S3.p1.1.m1.1.2.cmml"><msub id="S3.p1.1.m1.1.2.2" xref="S3.p1.1.m1.1.2.2.cmml"><mi id="S3.p1.1.m1.1.2.2.2" xref="S3.p1.1.m1.1.2.2.2.cmml">f</mi><mi id="S3.p1.1.m1.1.2.2.3" xref="S3.p1.1.m1.1.2.2.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.p1.1.m1.1.2.1" xref="S3.p1.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S3.p1.1.m1.1.2.3.2" xref="S3.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S3.p1.1.m1.1.2.3.2.1" xref="S3.p1.1.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.p1.1.m1.1.2.3.2.2" xref="S3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.2.cmml" xref="S3.p1.1.m1.1.2"><times id="S3.p1.1.m1.1.2.1.cmml" xref="S3.p1.1.m1.1.2.1"></times><apply id="S3.p1.1.m1.1.2.2.cmml" xref="S3.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.2.2.1.cmml" xref="S3.p1.1.m1.1.2.2">subscript</csymbol><ci id="S3.p1.1.m1.1.2.2.2.cmml" xref="S3.p1.1.m1.1.2.2.2">ğ‘“</ci><ci id="S3.p1.1.m1.1.2.2.3.cmml" xref="S3.p1.1.m1.1.2.2.3">ğœƒ</ci></apply><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">f_{\theta}(\cdot)</annotation></semantics></math>, parameterized by <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\theta</annotation></semantics></math>, takes an input query <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">Q</annotation></semantics></math> and a table <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{T}</annotation></semantics></math> to produce a response <math id="S3.p1.5.m5.2" class="ltx_Math" alttext="Y=f_{\theta}(Q,\mathcal{T})" display="inline"><semantics id="S3.p1.5.m5.2a"><mrow id="S3.p1.5.m5.2.3" xref="S3.p1.5.m5.2.3.cmml"><mi id="S3.p1.5.m5.2.3.2" xref="S3.p1.5.m5.2.3.2.cmml">Y</mi><mo id="S3.p1.5.m5.2.3.1" xref="S3.p1.5.m5.2.3.1.cmml">=</mo><mrow id="S3.p1.5.m5.2.3.3" xref="S3.p1.5.m5.2.3.3.cmml"><msub id="S3.p1.5.m5.2.3.3.2" xref="S3.p1.5.m5.2.3.3.2.cmml"><mi id="S3.p1.5.m5.2.3.3.2.2" xref="S3.p1.5.m5.2.3.3.2.2.cmml">f</mi><mi id="S3.p1.5.m5.2.3.3.2.3" xref="S3.p1.5.m5.2.3.3.2.3.cmml">Î¸</mi></msub><mo lspace="0em" rspace="0em" id="S3.p1.5.m5.2.3.3.1" xref="S3.p1.5.m5.2.3.3.1.cmml">â€‹</mo><mrow id="S3.p1.5.m5.2.3.3.3.2" xref="S3.p1.5.m5.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.p1.5.m5.2.3.3.3.2.1" xref="S3.p1.5.m5.2.3.3.3.1.cmml">(</mo><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">Q</mi><mo id="S3.p1.5.m5.2.3.3.3.2.2" xref="S3.p1.5.m5.2.3.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.5.m5.2.2" xref="S3.p1.5.m5.2.2.cmml">ğ’¯</mi><mo stretchy="false" id="S3.p1.5.m5.2.3.3.3.2.3" xref="S3.p1.5.m5.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.2b"><apply id="S3.p1.5.m5.2.3.cmml" xref="S3.p1.5.m5.2.3"><eq id="S3.p1.5.m5.2.3.1.cmml" xref="S3.p1.5.m5.2.3.1"></eq><ci id="S3.p1.5.m5.2.3.2.cmml" xref="S3.p1.5.m5.2.3.2">ğ‘Œ</ci><apply id="S3.p1.5.m5.2.3.3.cmml" xref="S3.p1.5.m5.2.3.3"><times id="S3.p1.5.m5.2.3.3.1.cmml" xref="S3.p1.5.m5.2.3.3.1"></times><apply id="S3.p1.5.m5.2.3.3.2.cmml" xref="S3.p1.5.m5.2.3.3.2"><csymbol cd="ambiguous" id="S3.p1.5.m5.2.3.3.2.1.cmml" xref="S3.p1.5.m5.2.3.3.2">subscript</csymbol><ci id="S3.p1.5.m5.2.3.3.2.2.cmml" xref="S3.p1.5.m5.2.3.3.2.2">ğ‘“</ci><ci id="S3.p1.5.m5.2.3.3.2.3.cmml" xref="S3.p1.5.m5.2.3.3.2.3">ğœƒ</ci></apply><interval closure="open" id="S3.p1.5.m5.2.3.3.3.1.cmml" xref="S3.p1.5.m5.2.3.3.3.2"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ğ‘„</ci><ci id="S3.p1.5.m5.2.2.cmml" xref="S3.p1.5.m5.2.2">ğ’¯</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.2c">Y=f_{\theta}(Q,\mathcal{T})</annotation></semantics></math>. Based on this generic formulation, the nature of <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.6.m6.1a"><mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">Q</annotation></semantics></math> and <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">Y</annotation></semantics></math> differs depending on the specific table reasoning task:
in table-based QA, <math id="S3.p1.8.m8.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.8.m8.1a"><mi id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">Q</annotation></semantics></math> is a question and <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.p1.9.m9.1a"><mi id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">Y</annotation></semantics></math> is the answer; in table-based fact verification, <math id="S3.p1.10.m10.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.10.m10.1a"><mi id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><ci id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">Q</annotation></semantics></math> is a claim and <math id="S3.p1.11.m11.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.p1.11.m11.1a"><mi id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><ci id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">Y</annotation></semantics></math> is its veracity label; in table summarization, <math id="S3.p1.12.m12.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.p1.12.m12.1a"><mi id="S3.p1.12.m12.1.1" xref="S3.p1.12.m12.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.12.m12.1b"><ci id="S3.p1.12.m12.1.1.cmml" xref="S3.p1.12.m12.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.12.m12.1c">Q</annotation></semantics></math> specifies the requirement and <math id="S3.p1.13.m13.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.p1.13.m13.1a"><mi id="S3.p1.13.m13.1.1" xref="S3.p1.13.m13.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.p1.13.m13.1b"><ci id="S3.p1.13.m13.1.1.cmml" xref="S3.p1.13.m13.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.13.m13.1c">Y</annotation></semantics></math> is the summary. A table <math id="S3.p1.14.m14.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.p1.14.m14.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.14.m14.1.1" xref="S3.p1.14.m14.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.p1.14.m14.1b"><ci id="S3.p1.14.m14.1.1.cmml" xref="S3.p1.14.m14.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.14.m14.1c">\mathcal{T}</annotation></semantics></math> is characterized by a caption <math id="S3.p1.15.m15.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.p1.15.m15.1a"><mi id="S3.p1.15.m15.1.1" xref="S3.p1.15.m15.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.p1.15.m15.1b"><ci id="S3.p1.15.m15.1.1.cmml" xref="S3.p1.15.m15.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.15.m15.1c">P</annotation></semantics></math> and its contents <math id="S3.p1.16.m16.4" class="ltx_Math" alttext="{T_{i,j}\mid i\leq R_{T},j\leq C_{T}}" display="inline"><semantics id="S3.p1.16.m16.4a"><mrow id="S3.p1.16.m16.4.4.2" xref="S3.p1.16.m16.4.4.3.cmml"><mrow id="S3.p1.16.m16.3.3.1.1" xref="S3.p1.16.m16.3.3.1.1.cmml"><mrow id="S3.p1.16.m16.3.3.1.1.2" xref="S3.p1.16.m16.3.3.1.1.2.cmml"><msub id="S3.p1.16.m16.3.3.1.1.2.2" xref="S3.p1.16.m16.3.3.1.1.2.2.cmml"><mi id="S3.p1.16.m16.3.3.1.1.2.2.2" xref="S3.p1.16.m16.3.3.1.1.2.2.2.cmml">T</mi><mrow id="S3.p1.16.m16.2.2.2.4" xref="S3.p1.16.m16.2.2.2.3.cmml"><mi id="S3.p1.16.m16.1.1.1.1" xref="S3.p1.16.m16.1.1.1.1.cmml">i</mi><mo id="S3.p1.16.m16.2.2.2.4.1" xref="S3.p1.16.m16.2.2.2.3.cmml">,</mo><mi id="S3.p1.16.m16.2.2.2.2" xref="S3.p1.16.m16.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.p1.16.m16.3.3.1.1.2.1" xref="S3.p1.16.m16.3.3.1.1.2.1.cmml">âˆ£</mo><mi id="S3.p1.16.m16.3.3.1.1.2.3" xref="S3.p1.16.m16.3.3.1.1.2.3.cmml">i</mi></mrow><mo id="S3.p1.16.m16.3.3.1.1.1" xref="S3.p1.16.m16.3.3.1.1.1.cmml">â‰¤</mo><msub id="S3.p1.16.m16.3.3.1.1.3" xref="S3.p1.16.m16.3.3.1.1.3.cmml"><mi id="S3.p1.16.m16.3.3.1.1.3.2" xref="S3.p1.16.m16.3.3.1.1.3.2.cmml">R</mi><mi id="S3.p1.16.m16.3.3.1.1.3.3" xref="S3.p1.16.m16.3.3.1.1.3.3.cmml">T</mi></msub></mrow><mo id="S3.p1.16.m16.4.4.2.3" xref="S3.p1.16.m16.4.4.3a.cmml">,</mo><mrow id="S3.p1.16.m16.4.4.2.2" xref="S3.p1.16.m16.4.4.2.2.cmml"><mi id="S3.p1.16.m16.4.4.2.2.2" xref="S3.p1.16.m16.4.4.2.2.2.cmml">j</mi><mo id="S3.p1.16.m16.4.4.2.2.1" xref="S3.p1.16.m16.4.4.2.2.1.cmml">â‰¤</mo><msub id="S3.p1.16.m16.4.4.2.2.3" xref="S3.p1.16.m16.4.4.2.2.3.cmml"><mi id="S3.p1.16.m16.4.4.2.2.3.2" xref="S3.p1.16.m16.4.4.2.2.3.2.cmml">C</mi><mi id="S3.p1.16.m16.4.4.2.2.3.3" xref="S3.p1.16.m16.4.4.2.2.3.3.cmml">T</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.16.m16.4b"><apply id="S3.p1.16.m16.4.4.3.cmml" xref="S3.p1.16.m16.4.4.2"><csymbol cd="ambiguous" id="S3.p1.16.m16.4.4.3a.cmml" xref="S3.p1.16.m16.4.4.2.3">formulae-sequence</csymbol><apply id="S3.p1.16.m16.3.3.1.1.cmml" xref="S3.p1.16.m16.3.3.1.1"><leq id="S3.p1.16.m16.3.3.1.1.1.cmml" xref="S3.p1.16.m16.3.3.1.1.1"></leq><apply id="S3.p1.16.m16.3.3.1.1.2.cmml" xref="S3.p1.16.m16.3.3.1.1.2"><csymbol cd="latexml" id="S3.p1.16.m16.3.3.1.1.2.1.cmml" xref="S3.p1.16.m16.3.3.1.1.2.1">conditional</csymbol><apply id="S3.p1.16.m16.3.3.1.1.2.2.cmml" xref="S3.p1.16.m16.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.16.m16.3.3.1.1.2.2.1.cmml" xref="S3.p1.16.m16.3.3.1.1.2.2">subscript</csymbol><ci id="S3.p1.16.m16.3.3.1.1.2.2.2.cmml" xref="S3.p1.16.m16.3.3.1.1.2.2.2">ğ‘‡</ci><list id="S3.p1.16.m16.2.2.2.3.cmml" xref="S3.p1.16.m16.2.2.2.4"><ci id="S3.p1.16.m16.1.1.1.1.cmml" xref="S3.p1.16.m16.1.1.1.1">ğ‘–</ci><ci id="S3.p1.16.m16.2.2.2.2.cmml" xref="S3.p1.16.m16.2.2.2.2">ğ‘—</ci></list></apply><ci id="S3.p1.16.m16.3.3.1.1.2.3.cmml" xref="S3.p1.16.m16.3.3.1.1.2.3">ğ‘–</ci></apply><apply id="S3.p1.16.m16.3.3.1.1.3.cmml" xref="S3.p1.16.m16.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.p1.16.m16.3.3.1.1.3.1.cmml" xref="S3.p1.16.m16.3.3.1.1.3">subscript</csymbol><ci id="S3.p1.16.m16.3.3.1.1.3.2.cmml" xref="S3.p1.16.m16.3.3.1.1.3.2">ğ‘…</ci><ci id="S3.p1.16.m16.3.3.1.1.3.3.cmml" xref="S3.p1.16.m16.3.3.1.1.3.3">ğ‘‡</ci></apply></apply><apply id="S3.p1.16.m16.4.4.2.2.cmml" xref="S3.p1.16.m16.4.4.2.2"><leq id="S3.p1.16.m16.4.4.2.2.1.cmml" xref="S3.p1.16.m16.4.4.2.2.1"></leq><ci id="S3.p1.16.m16.4.4.2.2.2.cmml" xref="S3.p1.16.m16.4.4.2.2.2">ğ‘—</ci><apply id="S3.p1.16.m16.4.4.2.2.3.cmml" xref="S3.p1.16.m16.4.4.2.2.3"><csymbol cd="ambiguous" id="S3.p1.16.m16.4.4.2.2.3.1.cmml" xref="S3.p1.16.m16.4.4.2.2.3">subscript</csymbol><ci id="S3.p1.16.m16.4.4.2.2.3.2.cmml" xref="S3.p1.16.m16.4.4.2.2.3.2">ğ¶</ci><ci id="S3.p1.16.m16.4.4.2.2.3.3.cmml" xref="S3.p1.16.m16.4.4.2.2.3.3">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.16.m16.4c">{T_{i,j}\mid i\leq R_{T},j\leq C_{T}}</annotation></semantics></math>, where <math id="S3.p1.17.m17.1" class="ltx_Math" alttext="R_{T}" display="inline"><semantics id="S3.p1.17.m17.1a"><msub id="S3.p1.17.m17.1.1" xref="S3.p1.17.m17.1.1.cmml"><mi id="S3.p1.17.m17.1.1.2" xref="S3.p1.17.m17.1.1.2.cmml">R</mi><mi id="S3.p1.17.m17.1.1.3" xref="S3.p1.17.m17.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.17.m17.1b"><apply id="S3.p1.17.m17.1.1.cmml" xref="S3.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S3.p1.17.m17.1.1.1.cmml" xref="S3.p1.17.m17.1.1">subscript</csymbol><ci id="S3.p1.17.m17.1.1.2.cmml" xref="S3.p1.17.m17.1.1.2">ğ‘…</ci><ci id="S3.p1.17.m17.1.1.3.cmml" xref="S3.p1.17.m17.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.17.m17.1c">R_{T}</annotation></semantics></math> and <math id="S3.p1.18.m18.1" class="ltx_Math" alttext="C_{T}" display="inline"><semantics id="S3.p1.18.m18.1a"><msub id="S3.p1.18.m18.1.1" xref="S3.p1.18.m18.1.1.cmml"><mi id="S3.p1.18.m18.1.1.2" xref="S3.p1.18.m18.1.1.2.cmml">C</mi><mi id="S3.p1.18.m18.1.1.3" xref="S3.p1.18.m18.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.18.m18.1b"><apply id="S3.p1.18.m18.1.1.cmml" xref="S3.p1.18.m18.1.1"><csymbol cd="ambiguous" id="S3.p1.18.m18.1.1.1.cmml" xref="S3.p1.18.m18.1.1">subscript</csymbol><ci id="S3.p1.18.m18.1.1.2.cmml" xref="S3.p1.18.m18.1.1.2">ğ¶</ci><ci id="S3.p1.18.m18.1.1.3.cmml" xref="S3.p1.18.m18.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.18.m18.1c">C_{T}</annotation></semantics></math> represent the number of rows and columns, respectively. Each cell <math id="S3.p1.19.m19.2" class="ltx_Math" alttext="(i,j)" display="inline"><semantics id="S3.p1.19.m19.2a"><mrow id="S3.p1.19.m19.2.3.2" xref="S3.p1.19.m19.2.3.1.cmml"><mo stretchy="false" id="S3.p1.19.m19.2.3.2.1" xref="S3.p1.19.m19.2.3.1.cmml">(</mo><mi id="S3.p1.19.m19.1.1" xref="S3.p1.19.m19.1.1.cmml">i</mi><mo id="S3.p1.19.m19.2.3.2.2" xref="S3.p1.19.m19.2.3.1.cmml">,</mo><mi id="S3.p1.19.m19.2.2" xref="S3.p1.19.m19.2.2.cmml">j</mi><mo stretchy="false" id="S3.p1.19.m19.2.3.2.3" xref="S3.p1.19.m19.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.19.m19.2b"><interval closure="open" id="S3.p1.19.m19.2.3.1.cmml" xref="S3.p1.19.m19.2.3.2"><ci id="S3.p1.19.m19.1.1.cmml" xref="S3.p1.19.m19.1.1">ğ‘–</ci><ci id="S3.p1.19.m19.2.2.cmml" xref="S3.p1.19.m19.2.2">ğ‘—</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.19.m19.2c">(i,j)</annotation></semantics></math> contains data <math id="S3.p1.20.m20.2" class="ltx_Math" alttext="T_{i,j}" display="inline"><semantics id="S3.p1.20.m20.2a"><msub id="S3.p1.20.m20.2.3" xref="S3.p1.20.m20.2.3.cmml"><mi id="S3.p1.20.m20.2.3.2" xref="S3.p1.20.m20.2.3.2.cmml">T</mi><mrow id="S3.p1.20.m20.2.2.2.4" xref="S3.p1.20.m20.2.2.2.3.cmml"><mi id="S3.p1.20.m20.1.1.1.1" xref="S3.p1.20.m20.1.1.1.1.cmml">i</mi><mo id="S3.p1.20.m20.2.2.2.4.1" xref="S3.p1.20.m20.2.2.2.3.cmml">,</mo><mi id="S3.p1.20.m20.2.2.2.2" xref="S3.p1.20.m20.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p1.20.m20.2b"><apply id="S3.p1.20.m20.2.3.cmml" xref="S3.p1.20.m20.2.3"><csymbol cd="ambiguous" id="S3.p1.20.m20.2.3.1.cmml" xref="S3.p1.20.m20.2.3">subscript</csymbol><ci id="S3.p1.20.m20.2.3.2.cmml" xref="S3.p1.20.m20.2.3.2">ğ‘‡</ci><list id="S3.p1.20.m20.2.2.2.3.cmml" xref="S3.p1.20.m20.2.2.2.4"><ci id="S3.p1.20.m20.1.1.1.1.cmml" xref="S3.p1.20.m20.1.1.1.1">ğ‘–</ci><ci id="S3.p1.20.m20.2.2.2.2.cmml" xref="S3.p1.20.m20.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.20.m20.2c">T_{i,j}</annotation></semantics></math>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To build an accurate and explainable table-reasoning framework, our proposed <span id="S3.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T<span id="S3.p2.1.1.1" class="ltx_text ltx_font_medium">ool-</span>A<span id="S3.p2.1.1.2" class="ltx_text ltx_font_medium">ugmented </span>R<span id="S3.p2.1.1.3" class="ltx_text ltx_font_medium">easoning framework for </span>T<span id="S3.p2.1.1.4" class="ltx_text ltx_font_medium">ables (<span id="S3.p2.1.1.4.1" class="ltx_text ltx_font_smallcaps">TART</span>)</span></span> integrates the call to external tools into the chain-of-thought reasoning process. <span id="S3.p2.1.2" class="ltx_text ltx_font_smallcaps">TART</span> consists of three reasoning modules (Figure <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>):
\small{\textbf{1}}âƒ <span id="S3.p2.1.3" class="ltx_text ltx_font_italic">Table Formatter</span>; \small{\textbf{2}}âƒ <span id="S3.p2.1.4" class="ltx_text ltx_font_italic">Tool Maker</span>; \small{\textbf{3}}âƒ <span id="S3.p2.1.5" class="ltx_text ltx_font_italic">Explanation Generator</span>.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Table Formatter.</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.3" class="ltx_p"><span id="S3.SS0.SSS0.Px1.p1.3.1" class="ltx_text ltx_font_smallcaps">TART</span> first transforms the original table <math id="S3.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">\mathcal{T}</annotation></semantics></math> with guidance from the query <math id="S3.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">Q</annotation></semantics></math> into a formatted table <math id="S3.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a"><msup id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2">ğ’¯</ci><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">\mathcal{T}^{\prime}</annotation></semantics></math>. The formatter optimizes data formats, aligns columns, and adjusts data types as needed for the query, producing a well-formatted table that is used in subsequent reasoning.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Tool Maker.</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.4" class="ltx_p">Given <math id="S3.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><msup id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2">ğ’¯</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">\mathcal{T}^{\prime}</annotation></semantics></math> , the <span id="S3.SS0.SSS0.Px2.p1.4.1" class="ltx_text ltx_font_italic">tool maker</span> generates a set of candidate tools <math id="S3.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.1c">S</annotation></semantics></math> useful for solving <math id="S3.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.3.m3.1a"><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.3.m3.1c">Q</annotation></semantics></math>. It also develops a reasoning plan <math id="S3.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.4.m4.1c">R</annotation></semantics></math> that details the high-level reasoning which includes the tool calling order, as well as the necessary arguments and the expected return values for the tool calls.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3. Explanation Generator.</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.4" class="ltx_p">Given the reasoning plan <math id="S3.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.1.m1.1c">R</annotation></semantics></math> as a programmatic guide for chain-of-thought reasoning, the explanation generator is responsible for producing a user-friendly explanation <math id="S3.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.2.m2.1c">E</annotation></semantics></math> that incorporates the use of the tools. The explanation also concludes with the final answer <math id="S3.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.3.m3.1c">\mathcal{A}</annotation></semantics></math>, derived from the execution of the reasoning plan <math id="S3.SS0.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS0.SSS0.Px3.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.4.m4.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.4.m4.1c">R</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Table Formatter</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">We first train a specialized open-sourced large language model as the table formatter <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathcal{F}</annotation></semantics></math>, which transforms the noisy raw input table <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{T}</annotation></semantics></math>, into a more structured and manageable format, <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msup id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ’¯</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathcal{T}^{\prime}</annotation></semantics></math>, to facilitate subsequent reasoning.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.2" class="ltx_Math" alttext="\mathcal{T}^{\prime}=\mathcal{F}(\mathcal{T},Q)" display="block"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.3" xref="S3.Ex1.m1.2.3.cmml"><msup id="S3.Ex1.m1.2.3.2" xref="S3.Ex1.m1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.2.3.2.2" xref="S3.Ex1.m1.2.3.2.2.cmml">ğ’¯</mi><mo id="S3.Ex1.m1.2.3.2.3" xref="S3.Ex1.m1.2.3.2.3.cmml">â€²</mo></msup><mo id="S3.Ex1.m1.2.3.1" xref="S3.Ex1.m1.2.3.1.cmml">=</mo><mrow id="S3.Ex1.m1.2.3.3" xref="S3.Ex1.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.2.3.3.2" xref="S3.Ex1.m1.2.3.3.2.cmml">â„±</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.3.3.1" xref="S3.Ex1.m1.2.3.3.1.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.3.3.3.2" xref="S3.Ex1.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.3.3.3.2.1" xref="S3.Ex1.m1.2.3.3.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">ğ’¯</mi><mo id="S3.Ex1.m1.2.3.3.3.2.2" xref="S3.Ex1.m1.2.3.3.3.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml">Q</mi><mo stretchy="false" id="S3.Ex1.m1.2.3.3.3.2.3" xref="S3.Ex1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.3.cmml" xref="S3.Ex1.m1.2.3"><eq id="S3.Ex1.m1.2.3.1.cmml" xref="S3.Ex1.m1.2.3.1"></eq><apply id="S3.Ex1.m1.2.3.2.cmml" xref="S3.Ex1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.3.2.1.cmml" xref="S3.Ex1.m1.2.3.2">superscript</csymbol><ci id="S3.Ex1.m1.2.3.2.2.cmml" xref="S3.Ex1.m1.2.3.2.2">ğ’¯</ci><ci id="S3.Ex1.m1.2.3.2.3.cmml" xref="S3.Ex1.m1.2.3.2.3">â€²</ci></apply><apply id="S3.Ex1.m1.2.3.3.cmml" xref="S3.Ex1.m1.2.3.3"><times id="S3.Ex1.m1.2.3.3.1.cmml" xref="S3.Ex1.m1.2.3.3.1"></times><ci id="S3.Ex1.m1.2.3.3.2.cmml" xref="S3.Ex1.m1.2.3.3.2">â„±</ci><interval closure="open" id="S3.Ex1.m1.2.3.3.3.1.cmml" xref="S3.Ex1.m1.2.3.3.3.2"><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">ğ’¯</ci><ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">ğ‘„</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">\mathcal{T}^{\prime}=\mathcal{F}(\mathcal{T},Q)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p">where the output table <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msup id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ’¯</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{T}^{\prime}</annotation></semantics></math> is formatted in three aspects. 1) <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">Data Cleaning</span>: the model formats the cell values, such as removing currency symbols and textual footnotes to facilitate the execution of external functions to perform table operations or numerical reasoning. 2) <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">Data Standardization</span>: It converts different data representations into a uniform format, <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">e.g.,</span> transforms the data from formats like â€œ<span id="S3.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">MM/DD/YYYY</span>â€ to a consistent â€œ<span id="S3.SS1.p3.1.5" class="ltx_text ltx_font_typewriter">YYYY-MM-DD</span>â€ format across the entire table. 3) <span id="S3.SS1.p3.1.6" class="ltx_text ltx_font_italic">Error Handling</span>: the model is also responsible for fixing obvious errors or missing values in the table, such as automatically inferring header names for columns without the table headers.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">We introduce the table formatter to ensure that the data in the input table is uniform and optimized for subsequent reasoning, especially to make it more compatible with function execution. In practice, we transform the formatted table <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ’¯</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\mathcal{T}^{\prime}</annotation></semantics></math> into a Python array, facilitating easier interpretation and processing by subsequent reasoning modules.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Tool Maker</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.5" class="ltx_p">Recent studies have shown that LLMs have the capability of synthesizing relevant tools by understanding the problem context and creating solutions based on the crafted toolsÂ <cite class="ltx_cite ltx_citemacro_citep">(Schick etÂ al. <a href="#bib.bib31" title="" class="ltx_ref">2023</a>; Cai etÂ al. <a href="#bib.bib3" title="" class="ltx_ref">2024</a>; Wang etÂ al. <a href="#bib.bib36" title="" class="ltx_ref">2024b</a>)</cite>. Motivated by this, we train another specialized LLM <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{M}</annotation></semantics></math> as a <span id="S3.SS2.p1.5.1" class="ltx_text ltx_font_italic">tool maker</span>, which takes as input the reformatted table <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}^{\prime}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">ğ’¯</mi><mo id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ’¯</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{T}^{\prime}</annotation></semantics></math> and the query <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">Q</annotation></semantics></math> to generate a set of candidate tools <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">S</annotation></semantics></math> and develops a reasoning plan <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">R</annotation></semantics></math> that details the high-level reasoning steps, as follows.</p>
<table id="S3.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex2.m1.4" class="ltx_Math" alttext="S,R=\mathcal{M}(\mathcal{T^{\prime}},Q)" display="block"><semantics id="S3.Ex2.m1.4a"><mrow id="S3.Ex2.m1.4.4" xref="S3.Ex2.m1.4.4.cmml"><mrow id="S3.Ex2.m1.4.4.3.2" xref="S3.Ex2.m1.4.4.3.1.cmml"><mi id="S3.Ex2.m1.2.2" xref="S3.Ex2.m1.2.2.cmml">S</mi><mo id="S3.Ex2.m1.4.4.3.2.1" xref="S3.Ex2.m1.4.4.3.1.cmml">,</mo><mi id="S3.Ex2.m1.3.3" xref="S3.Ex2.m1.3.3.cmml">R</mi></mrow><mo id="S3.Ex2.m1.4.4.2" xref="S3.Ex2.m1.4.4.2.cmml">=</mo><mrow id="S3.Ex2.m1.4.4.1" xref="S3.Ex2.m1.4.4.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.4.4.1.3" xref="S3.Ex2.m1.4.4.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.4.4.1.2" xref="S3.Ex2.m1.4.4.1.2.cmml">â€‹</mo><mrow id="S3.Ex2.m1.4.4.1.1.1" xref="S3.Ex2.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S3.Ex2.m1.4.4.1.1.1.2" xref="S3.Ex2.m1.4.4.1.1.2.cmml">(</mo><msup id="S3.Ex2.m1.4.4.1.1.1.1" xref="S3.Ex2.m1.4.4.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.4.4.1.1.1.1.2" xref="S3.Ex2.m1.4.4.1.1.1.1.2.cmml">ğ’¯</mi><mo id="S3.Ex2.m1.4.4.1.1.1.1.3" xref="S3.Ex2.m1.4.4.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.Ex2.m1.4.4.1.1.1.3" xref="S3.Ex2.m1.4.4.1.1.2.cmml">,</mo><mi id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml">Q</mi><mo stretchy="false" id="S3.Ex2.m1.4.4.1.1.1.4" xref="S3.Ex2.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.4b"><apply id="S3.Ex2.m1.4.4.cmml" xref="S3.Ex2.m1.4.4"><eq id="S3.Ex2.m1.4.4.2.cmml" xref="S3.Ex2.m1.4.4.2"></eq><list id="S3.Ex2.m1.4.4.3.1.cmml" xref="S3.Ex2.m1.4.4.3.2"><ci id="S3.Ex2.m1.2.2.cmml" xref="S3.Ex2.m1.2.2">ğ‘†</ci><ci id="S3.Ex2.m1.3.3.cmml" xref="S3.Ex2.m1.3.3">ğ‘…</ci></list><apply id="S3.Ex2.m1.4.4.1.cmml" xref="S3.Ex2.m1.4.4.1"><times id="S3.Ex2.m1.4.4.1.2.cmml" xref="S3.Ex2.m1.4.4.1.2"></times><ci id="S3.Ex2.m1.4.4.1.3.cmml" xref="S3.Ex2.m1.4.4.1.3">â„³</ci><interval closure="open" id="S3.Ex2.m1.4.4.1.1.2.cmml" xref="S3.Ex2.m1.4.4.1.1.1"><apply id="S3.Ex2.m1.4.4.1.1.1.1.cmml" xref="S3.Ex2.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.1.1.1.1.1.cmml" xref="S3.Ex2.m1.4.4.1.1.1.1">superscript</csymbol><ci id="S3.Ex2.m1.4.4.1.1.1.1.2.cmml" xref="S3.Ex2.m1.4.4.1.1.1.1.2">ğ’¯</ci><ci id="S3.Ex2.m1.4.4.1.1.1.1.3.cmml" xref="S3.Ex2.m1.4.4.1.1.1.1.3">â€²</ci></apply><ci id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1">ğ‘„</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.4c">S,R=\mathcal{M}(\mathcal{T^{\prime}},Q)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.3" class="ltx_p">The tool set <math id="S3.SS2.p2.1.m1.3" class="ltx_Math" alttext="S=\{s_{1},\cdots,s_{n}\}" display="inline"><semantics id="S3.SS2.p2.1.m1.3a"><mrow id="S3.SS2.p2.1.m1.3.3" xref="S3.SS2.p2.1.m1.3.3.cmml"><mi id="S3.SS2.p2.1.m1.3.3.4" xref="S3.SS2.p2.1.m1.3.3.4.cmml">S</mi><mo id="S3.SS2.p2.1.m1.3.3.3" xref="S3.SS2.p2.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS2.p2.1.m1.3.3.2.2" xref="S3.SS2.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.3.3.2.2.3" xref="S3.SS2.p2.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.SS2.p2.1.m1.2.2.1.1.1" xref="S3.SS2.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.2.2.1.1.1.2" xref="S3.SS2.p2.1.m1.2.2.1.1.1.2.cmml">s</mi><mn id="S3.SS2.p2.1.m1.2.2.1.1.1.3" xref="S3.SS2.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p2.1.m1.3.3.2.2.4" xref="S3.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">â‹¯</mi><mo id="S3.SS2.p2.1.m1.3.3.2.2.5" xref="S3.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS2.p2.1.m1.3.3.2.2.2" xref="S3.SS2.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p2.1.m1.3.3.2.2.2.2" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2.cmml">s</mi><mi id="S3.SS2.p2.1.m1.3.3.2.2.2.3" xref="S3.SS2.p2.1.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS2.p2.1.m1.3.3.2.2.6" xref="S3.SS2.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.3b"><apply id="S3.SS2.p2.1.m1.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3"><eq id="S3.SS2.p2.1.m1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.3.3.3"></eq><ci id="S3.SS2.p2.1.m1.3.3.4.cmml" xref="S3.SS2.p2.1.m1.3.3.4">ğ‘†</ci><set id="S3.SS2.p2.1.m1.3.3.2.3.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2"><apply id="S3.SS2.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1.2">ğ‘ </ci><cn type="integer" id="S3.SS2.p2.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">â‹¯</ci><apply id="S3.SS2.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2">ğ‘ </ci><ci id="S3.SS2.p2.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2.3">ğ‘›</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.3c">S=\{s_{1},\cdots,s_{n}\}</annotation></semantics></math> consists of <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">n</annotation></semantics></math> specialized tools and each tool <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="s_{i}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">s</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘ </ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">s_{i}</annotation></semantics></math> is a Python function that performs table operations (<span id="S3.SS2.p2.3.1" class="ltx_text ltx_font_italic">e.g.</span>, <span id="S3.SS2.p2.3.2" class="ltx_text ltx_font_typewriter">get_column_by_name</span>), numerical reasoning (<span id="S3.SS2.p2.3.3" class="ltx_text ltx_font_italic">e.g.</span>, <span id="S3.SS2.p2.3.4" class="ltx_text ltx_font_typewriter">average</span>, <span id="S3.SS2.p2.3.5" class="ltx_text ltx_font_typewriter">argmax</span>), or higher-level functions (<span id="S3.SS2.p2.3.6" class="ltx_text ltx_font_italic">e.g.</span>, <span id="S3.SS2.p2.3.7" class="ltx_text ltx_font_typewriter">linear_regression</span>). In table-based reasoning, these automated tools are essential to handle reasoning tasks that textual-based LLMs cannot address effectively, thereby significantly enhancing their problem-solving capacities.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Unlike previous work that manually defined a small number (<math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="&lt;10" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml"></mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">&lt;</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><lt id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">&lt;10</annotation></semantics></math>) of hand-crafted toolsÂ <cite class="ltx_cite ltx_citemacro_citep">(Lu etÂ al. <a href="#bib.bib20" title="" class="ltx_ref">2023a</a>; Pan etÂ al. <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> or retrieved tools from a predefined setÂ <cite class="ltx_cite ltx_citemacro_citep">(Qin etÂ al. <a href="#bib.bib29" title="" class="ltx_ref">2024</a>; Ma etÂ al. <a href="#bib.bib23" title="" class="ltx_ref">2024</a>)</cite>, we choose to train a specialized <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_italic">tool maker</span> model that <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_bold">learns to <span id="S3.SS2.p3.1.2.1" class="ltx_text ltx_font_italic">generate</span> tools dynamically, based on the specifics of the table and the context of the problem.</span>
This approach not only preserves the modelâ€™s ability to â€œextractâ€ previously encountered tools from its parametric memory, but also empowers the model to create novel tools as needed for unique problems, as shown in SectionÂ <a href="#S4.SS4" title="4.4 Analysis of Tool Creation â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.
While generating tools offer greater flexibility, it is crucial to prevent the tool maker from creating overly-specific tools (<span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_italic">e.g.</span>, <span id="S3.SS2.p3.1.4" class="ltx_text ltx_font_typewriter">count_people_on_third_floor</span>), as this would hinder its ability to generalize to new problems. To address this issue, we incorporate <span id="S3.SS2.p3.1.5" class="ltx_text ltx_font_italic">tool abstraction</span> and <span id="S3.SS2.p3.1.6" class="ltx_text ltx_font_italic">tool deduplication</span> steps when constructing synthetic data for training the module (elaborated on in SectionÂ <a href="#S3.SS4" title="3.4 Model Training â€£ 3 Methodology â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.9" class="ltx_p">In addition to generating useful tools, the model also constructs a high-level reasoning plan <math id="S3.SS2.p4.1.m1.3" class="ltx_Math" alttext="R=[r_{1},\cdots,r_{N}]" display="inline"><semantics id="S3.SS2.p4.1.m1.3a"><mrow id="S3.SS2.p4.1.m1.3.3" xref="S3.SS2.p4.1.m1.3.3.cmml"><mi id="S3.SS2.p4.1.m1.3.3.4" xref="S3.SS2.p4.1.m1.3.3.4.cmml">R</mi><mo id="S3.SS2.p4.1.m1.3.3.3" xref="S3.SS2.p4.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS2.p4.1.m1.3.3.2.2" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS2.p4.1.m1.3.3.2.2.3" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">[</mo><msub id="S3.SS2.p4.1.m1.2.2.1.1.1" xref="S3.SS2.p4.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.2.2.1.1.1.2" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2.cmml">r</mi><mn id="S3.SS2.p4.1.m1.2.2.1.1.1.3" xref="S3.SS2.p4.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p4.1.m1.3.3.2.2.4" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">â‹¯</mi><mo id="S3.SS2.p4.1.m1.3.3.2.2.5" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS2.p4.1.m1.3.3.2.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p4.1.m1.3.3.2.2.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2.cmml">r</mi><mi id="S3.SS2.p4.1.m1.3.3.2.2.2.3" xref="S3.SS2.p4.1.m1.3.3.2.2.2.3.cmml">N</mi></msub><mo stretchy="false" id="S3.SS2.p4.1.m1.3.3.2.2.6" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.3b"><apply id="S3.SS2.p4.1.m1.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3"><eq id="S3.SS2.p4.1.m1.3.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3.3"></eq><ci id="S3.SS2.p4.1.m1.3.3.4.cmml" xref="S3.SS2.p4.1.m1.3.3.4">ğ‘…</ci><list id="S3.SS2.p4.1.m1.3.3.2.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2"><apply id="S3.SS2.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2">ğ‘Ÿ</ci><cn type="integer" id="S3.SS2.p4.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">â‹¯</ci><apply id="S3.SS2.p4.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2">ğ‘Ÿ</ci><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.3">ğ‘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.3c">R=[r_{1},\cdots,r_{N}]</annotation></semantics></math>, which outlines how the tools should be applied. The reasoning plan is formulated as a sequence of <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">N</annotation></semantics></math> function calls. Each <span id="S3.SS2.p4.9.1" class="ltx_text ltx_font_italic">function call</span> <math id="S3.SS2.p4.3.m3.3" class="ltx_Math" alttext="r_{i}=(s_{i},A_{i},V_{i})" display="inline"><semantics id="S3.SS2.p4.3.m3.3a"><mrow id="S3.SS2.p4.3.m3.3.3" xref="S3.SS2.p4.3.m3.3.3.cmml"><msub id="S3.SS2.p4.3.m3.3.3.5" xref="S3.SS2.p4.3.m3.3.3.5.cmml"><mi id="S3.SS2.p4.3.m3.3.3.5.2" xref="S3.SS2.p4.3.m3.3.3.5.2.cmml">r</mi><mi id="S3.SS2.p4.3.m3.3.3.5.3" xref="S3.SS2.p4.3.m3.3.3.5.3.cmml">i</mi></msub><mo id="S3.SS2.p4.3.m3.3.3.4" xref="S3.SS2.p4.3.m3.3.3.4.cmml">=</mo><mrow id="S3.SS2.p4.3.m3.3.3.3.3" xref="S3.SS2.p4.3.m3.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p4.3.m3.3.3.3.3.4" xref="S3.SS2.p4.3.m3.3.3.3.4.cmml">(</mo><msub id="S3.SS2.p4.3.m3.1.1.1.1.1" xref="S3.SS2.p4.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.1.1.1.2" xref="S3.SS2.p4.3.m3.1.1.1.1.1.2.cmml">s</mi><mi id="S3.SS2.p4.3.m3.1.1.1.1.1.3" xref="S3.SS2.p4.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p4.3.m3.3.3.3.3.5" xref="S3.SS2.p4.3.m3.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.3.m3.2.2.2.2.2" xref="S3.SS2.p4.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS2.p4.3.m3.2.2.2.2.2.2" xref="S3.SS2.p4.3.m3.2.2.2.2.2.2.cmml">A</mi><mi id="S3.SS2.p4.3.m3.2.2.2.2.2.3" xref="S3.SS2.p4.3.m3.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p4.3.m3.3.3.3.3.6" xref="S3.SS2.p4.3.m3.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.3.m3.3.3.3.3.3" xref="S3.SS2.p4.3.m3.3.3.3.3.3.cmml"><mi id="S3.SS2.p4.3.m3.3.3.3.3.3.2" xref="S3.SS2.p4.3.m3.3.3.3.3.3.2.cmml">V</mi><mi id="S3.SS2.p4.3.m3.3.3.3.3.3.3" xref="S3.SS2.p4.3.m3.3.3.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p4.3.m3.3.3.3.3.7" xref="S3.SS2.p4.3.m3.3.3.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.3b"><apply id="S3.SS2.p4.3.m3.3.3.cmml" xref="S3.SS2.p4.3.m3.3.3"><eq id="S3.SS2.p4.3.m3.3.3.4.cmml" xref="S3.SS2.p4.3.m3.3.3.4"></eq><apply id="S3.SS2.p4.3.m3.3.3.5.cmml" xref="S3.SS2.p4.3.m3.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.3.3.5.1.cmml" xref="S3.SS2.p4.3.m3.3.3.5">subscript</csymbol><ci id="S3.SS2.p4.3.m3.3.3.5.2.cmml" xref="S3.SS2.p4.3.m3.3.3.5.2">ğ‘Ÿ</ci><ci id="S3.SS2.p4.3.m3.3.3.5.3.cmml" xref="S3.SS2.p4.3.m3.3.3.5.3">ğ‘–</ci></apply><vector id="S3.SS2.p4.3.m3.3.3.3.4.cmml" xref="S3.SS2.p4.3.m3.3.3.3.3"><apply id="S3.SS2.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.1.1.1.2">ğ‘ </ci><ci id="S3.SS2.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p4.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p4.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p4.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p4.3.m3.2.2.2.2.2.2">ğ´</ci><ci id="S3.SS2.p4.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p4.3.m3.2.2.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p4.3.m3.3.3.3.3.3.cmml" xref="S3.SS2.p4.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.3.3.3.3.3.1.cmml" xref="S3.SS2.p4.3.m3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p4.3.m3.3.3.3.3.3.2.cmml" xref="S3.SS2.p4.3.m3.3.3.3.3.3.2">ğ‘‰</ci><ci id="S3.SS2.p4.3.m3.3.3.3.3.3.3.cmml" xref="S3.SS2.p4.3.m3.3.3.3.3.3.3">ğ‘–</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.3c">r_{i}=(s_{i},A_{i},V_{i})</annotation></semantics></math> includes the function <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="s_{i}\in\mathcal{S}" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msub id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.cmml">s</mi><mi id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p4.4.m4.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><in id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></in><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2">ğ‘ </ci><ci id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">s_{i}\in\mathcal{S}</annotation></semantics></math>, the <span id="S3.SS2.p4.9.2" class="ltx_text ltx_font_italic">argument</span> <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="A_{i}" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><msub id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">A</mi><mi id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">ğ´</ci><ci id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">A_{i}</annotation></semantics></math> passed to the function, and the <span id="S3.SS2.p4.9.3" class="ltx_text ltx_font_italic">variable</span> <math id="S3.SS2.p4.6.m6.1" class="ltx_Math" alttext="V_{i}" display="inline"><semantics id="S3.SS2.p4.6.m6.1a"><msub id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">V</mi><mi id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">ğ‘‰</ci><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">V_{i}</annotation></semantics></math> that stores the result of the function call <math id="S3.SS2.p4.7.m7.1" class="ltx_Math" alttext="s_{i}(A_{i})" display="inline"><semantics id="S3.SS2.p4.7.m7.1a"><mrow id="S3.SS2.p4.7.m7.1.1" xref="S3.SS2.p4.7.m7.1.1.cmml"><msub id="S3.SS2.p4.7.m7.1.1.3" xref="S3.SS2.p4.7.m7.1.1.3.cmml"><mi id="S3.SS2.p4.7.m7.1.1.3.2" xref="S3.SS2.p4.7.m7.1.1.3.2.cmml">s</mi><mi id="S3.SS2.p4.7.m7.1.1.3.3" xref="S3.SS2.p4.7.m7.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.1.1.2" xref="S3.SS2.p4.7.m7.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p4.7.m7.1.1.1.1" xref="S3.SS2.p4.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p4.7.m7.1.1.1.1.2" xref="S3.SS2.p4.7.m7.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p4.7.m7.1.1.1.1.1" xref="S3.SS2.p4.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.7.m7.1.1.1.1.1.2" xref="S3.SS2.p4.7.m7.1.1.1.1.1.2.cmml">A</mi><mi id="S3.SS2.p4.7.m7.1.1.1.1.1.3" xref="S3.SS2.p4.7.m7.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p4.7.m7.1.1.1.1.3" xref="S3.SS2.p4.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.1b"><apply id="S3.SS2.p4.7.m7.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1"><times id="S3.SS2.p4.7.m7.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.2"></times><apply id="S3.SS2.p4.7.m7.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.3.1.cmml" xref="S3.SS2.p4.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.3.2.cmml" xref="S3.SS2.p4.7.m7.1.1.3.2">ğ‘ </ci><ci id="S3.SS2.p4.7.m7.1.1.3.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3.3">ğ‘–</ci></apply><apply id="S3.SS2.p4.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.1.2">ğ´</ci><ci id="S3.SS2.p4.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.1c">s_{i}(A_{i})</annotation></semantics></math>.
This reasoning plan acts as a programmatic blueprint, guiding the table-based reasoning process. Both the tool set <math id="S3.SS2.p4.8.m8.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS2.p4.8.m8.1a"><mi id="S3.SS2.p4.8.m8.1.1" xref="S3.SS2.p4.8.m8.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m8.1b"><ci id="S3.SS2.p4.8.m8.1.1.cmml" xref="S3.SS2.p4.8.m8.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m8.1c">S</annotation></semantics></math> and the reasoning plan <math id="S3.SS2.p4.9.m9.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS2.p4.9.m9.1a"><mi id="S3.SS2.p4.9.m9.1.1" xref="S3.SS2.p4.9.m9.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.9.m9.1b"><ci id="S3.SS2.p4.9.m9.1.1.cmml" xref="S3.SS2.p4.9.m9.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.9.m9.1c">R</annotation></semantics></math> are then provided to the explanation generator, which produces the final explainable reasoning output.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Explanation Generator</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">While program-based reasoning plans are precise, they are often difficult for non-expert users to understand. Moreover, certain types of reasoning, such as commonsense or narrative-based reasoning, are better communicated in natural language. To address this, <span id="S3.SS3.p1.2.1" class="ltx_text ltx_font_smallcaps">TART</span> incorporates a specialized module called the <span id="S3.SS3.p1.2.2" class="ltx_text ltx_font_italic">explanation generator</span> <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{E}</annotation></semantics></math>, which generates chain-of-thought natural language explanations integrated with function calls, following the steps outlined in the reasoning plan <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">R</annotation></semantics></math>.</p>
<table id="S3.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex3.m1.2" class="ltx_Math" alttext="O=\mathcal{E}(S,R)" display="block"><semantics id="S3.Ex3.m1.2a"><mrow id="S3.Ex3.m1.2.3" xref="S3.Ex3.m1.2.3.cmml"><mi id="S3.Ex3.m1.2.3.2" xref="S3.Ex3.m1.2.3.2.cmml">O</mi><mo id="S3.Ex3.m1.2.3.1" xref="S3.Ex3.m1.2.3.1.cmml">=</mo><mrow id="S3.Ex3.m1.2.3.3" xref="S3.Ex3.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex3.m1.2.3.3.2" xref="S3.Ex3.m1.2.3.3.2.cmml">â„°</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.2.3.3.1" xref="S3.Ex3.m1.2.3.3.1.cmml">â€‹</mo><mrow id="S3.Ex3.m1.2.3.3.3.2" xref="S3.Ex3.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.Ex3.m1.2.3.3.3.2.1" xref="S3.Ex3.m1.2.3.3.3.1.cmml">(</mo><mi id="S3.Ex3.m1.1.1" xref="S3.Ex3.m1.1.1.cmml">S</mi><mo id="S3.Ex3.m1.2.3.3.3.2.2" xref="S3.Ex3.m1.2.3.3.3.1.cmml">,</mo><mi id="S3.Ex3.m1.2.2" xref="S3.Ex3.m1.2.2.cmml">R</mi><mo stretchy="false" id="S3.Ex3.m1.2.3.3.3.2.3" xref="S3.Ex3.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.2b"><apply id="S3.Ex3.m1.2.3.cmml" xref="S3.Ex3.m1.2.3"><eq id="S3.Ex3.m1.2.3.1.cmml" xref="S3.Ex3.m1.2.3.1"></eq><ci id="S3.Ex3.m1.2.3.2.cmml" xref="S3.Ex3.m1.2.3.2">ğ‘‚</ci><apply id="S3.Ex3.m1.2.3.3.cmml" xref="S3.Ex3.m1.2.3.3"><times id="S3.Ex3.m1.2.3.3.1.cmml" xref="S3.Ex3.m1.2.3.3.1"></times><ci id="S3.Ex3.m1.2.3.3.2.cmml" xref="S3.Ex3.m1.2.3.3.2">â„°</ci><interval closure="open" id="S3.Ex3.m1.2.3.3.3.1.cmml" xref="S3.Ex3.m1.2.3.3.3.2"><ci id="S3.Ex3.m1.1.1.cmml" xref="S3.Ex3.m1.1.1">ğ‘†</ci><ci id="S3.Ex3.m1.2.2.cmml" xref="S3.Ex3.m1.2.2">ğ‘…</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.2c">O=\mathcal{E}(S,R)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">The final output <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="O" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ğ‘‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">O</annotation></semantics></math> of <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_smallcaps">TART</span> provides detailed explanations for the function calls. For example, the function call <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">get_column_by_name</span> is explained as, â€œ<span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_italic">First, retrieve the column listing snowfall in inches.</span>â€ Additionally, the explanation generator groups related function calls together to create coherent and easy-to-follow explanations, as illustrated in FigureÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Model Training</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.7" class="ltx_p">As no prior work adopts the tool-augmented LLM framework for table reasoning, there does not exist training data to train the modules <span id="S3.SS4.p1.7.1" class="ltx_text ltx_font_italic">Table Formatter</span>, <span id="S3.SS4.p1.7.2" class="ltx_text ltx_font_italic">Tool Maker</span> and <span id="S3.SS4.p1.7.3" class="ltx_text ltx_font_italic">Explanation Generator</span>
(<math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{F}</annotation></semantics></math>, <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\mathcal{M}</annotation></semantics></math>, and <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">\mathcal{E}</annotation></semantics></math>) in <span id="S3.SS4.p1.7.4" class="ltx_text ltx_font_smallcaps">TART</span>. Previous studies have demonstrated that smaller LLMs can learn from distilling the generated outputs of larger teacher LLMs that have better reasoning capabilitiesÂ <cite class="ltx_cite ltx_citemacro_citep">(West etÂ al. <a href="#bib.bib39" title="" class="ltx_ref">2022</a>; Wang etÂ al. <a href="#bib.bib34" title="" class="ltx_ref">2023</a>; Kim etÂ al. <a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>. Following this, we use a teacher LLM <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">\mathcal{L}</annotation></semantics></math> to first synthesize tool-integrated solution trajectories for a set of seed table-based reasoning tasks. These high-quality solution trajectories serve as the blueprint from which we automatically extract and rearrange their components to build training sets for <math id="S3.SS4.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS4.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><ci id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">\mathcal{F}</annotation></semantics></math>, <math id="S3.SS4.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS4.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.6.m6.1.1" xref="S3.SS4.p1.6.m6.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m6.1b"><ci id="S3.SS4.p1.6.m6.1.1.cmml" xref="S3.SS4.p1.6.m6.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m6.1c">\mathcal{M}</annotation></semantics></math>, and <math id="S3.SS4.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS4.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.7.m7.1.1" xref="S3.SS4.p1.7.m7.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m7.1b"><ci id="S3.SS4.p1.7.m7.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m7.1c">\mathcal{E}</annotation></semantics></math>.</p>
</div>
<section id="S3.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training Data Synthesis.</h5>

<div id="S3.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px1.p1.2" class="ltx_p">For all modules, we use GPT-4 as the teacher LLM <math id="S3.SS4.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS4.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.1.m1.1c">\mathcal{L}</annotation></semantics></math> to generate training data. As shown in TableÂ <a href="#A3.T4" title="Table 4 â€£ Appendix C Dataset Composition for TART Training â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we select five diverse table reasoning datasets: two from TQA and three from TFV, spanning general knowledge (Wikipedia) as well as domains such as finance, health, and scientific documents. These datasets provide a broad range of reasoning types. We few-shot prompt <math id="S3.SS4.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS4.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.2.m2.1c">\mathcal{L}</annotation></semantics></math> to generate tool-integrated solutions for training instances for each dataset. In each solution, the model is prompted to clean the table, invent useful tools, and propose a reasoning plan along with explanations. We provide our prompt in AppendixÂ <a href="#A7" title="Appendix G Prompts â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">G</span></a>.</p>
</div>
<div id="S3.SS4.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS4.SSS0.Px1.p2.3" class="ltx_p">After generating the solutions, we evaluate the final answers against the ground truth, retaining only the instances with correct answers. Subsequently, we refine the solutions by removing overly specific tools through <span id="S3.SS4.SSS0.Px1.p2.3.1" class="ltx_text ltx_font_italic">tool abstraction</span> and <span id="S3.SS4.SSS0.Px1.p2.3.2" class="ltx_text ltx_font_italic">tool deduplication</span>. Tool abstraction filters out tools that appear only once, keeping those with broader applicability. Tool deduplication consolidates similar tools that perform the same function, but have different names or implementations (e.g., <span id="S3.SS4.SSS0.Px1.p2.3.3" class="ltx_text ltx_font_typewriter">add</span> and <span id="S3.SS4.SSS0.Px1.p2.3.4" class="ltx_text ltx_font_typewriter">sum</span>).
As a result, we obtain 11,701, 9,916, and 9,916 training instances for the table formatter <math id="S3.SS4.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS4.SSS0.Px1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.1.m1.1c">\mathcal{F}</annotation></semantics></math>, tool maker <math id="S3.SS4.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS4.SSS0.Px1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.2.m2.1c">\mathcal{M}</annotation></semantics></math>, and explanation generator <math id="S3.SS4.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS4.SSS0.Px1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.3.m3.1b"><ci id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.3.m3.1c">\mathcal{E}</annotation></semantics></math>, We refer to this training dataset as <span id="S3.SS4.SSS0.Px1.p2.3.5" class="ltx_text ltx_font_smallcaps">ToolTab</span>, with detailed statistics provided in TableÂ <a href="#A3.T5" title="Table 5 â€£ Appendix C Dataset Composition for TART Training â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section id="S3.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training Configurations.</h5>

<div id="S3.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px2.p1.1" class="ltx_p">Instruction fine-tuningÂ <cite class="ltx_cite ltx_citemacro_citep">(Mishra etÂ al. <a href="#bib.bib24" title="" class="ltx_ref">2022</a>; Chung etÂ al. <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> has emerged as a critical strategy that directs LLMs to adhere to specified instructions, facilitating their reasoning capability across a wide range of table-based tasks. Therefore, we use open-source LLMs with instruction tuning as the backbone models for the modules of <span id="S3.SS4.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, specifically <span id="S3.SS4.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_typewriter">Llama2-7B</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al. <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>, <span id="S3.SS4.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_typewriter">Llama3-8B</span>, <span id="S3.SS4.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_typewriter">CodeLlama-7B</span>Â <cite class="ltx_cite ltx_citemacro_citep">(RoziÃ¨re etÂ al. <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> and <span id="S3.SS4.SSS0.Px2.p1.1.5" class="ltx_text ltx_font_typewriter">Deepseek-Coder-7B-Instruct-V1.5</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Guo etÂ al. <a href="#bib.bib14" title="" class="ltx_ref">2024</a>)</cite>. We fine-tune all <span id="S3.SS4.SSS0.Px2.p1.1.6" class="ltx_text ltx_font_smallcaps">TART</span> modules independently on their respective training datasets from <span id="S3.SS4.SSS0.Px2.p1.1.7" class="ltx_text ltx_font_smallcaps">ToolTab</span>, using the standard next-token prediction objective.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_border_tt"></td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">TableFV</span></td>
<td id="S3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T1.1.1.1.5.1" class="ltx_text ltx_font_bold">TableQA</span></td>
<td id="S3.T1.1.1.1.6" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.2.2.1" class="ltx_td"></td>
<td id="S3.T1.1.2.2.2" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.2.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S3.T1.1.2.2.3" class="ltx_td ltx_align_left"><span id="S3.T1.1.2.2.3.1" class="ltx_text ltx_font_bold">Setting</span></td>
<td id="S3.T1.1.2.2.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.4.1" class="ltx_text ltx_font_bold">TabFact</span></td>
<td id="S3.T1.1.2.2.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.5.1" class="ltx_text ltx_font_bold">PubHT</span></td>
<td id="S3.T1.1.2.2.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.6.1" class="ltx_text ltx_font_bold">SCITAB</span></td>
<td id="S3.T1.1.2.2.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.7.1" class="ltx_text ltx_font_bold">TabMWP</span></td>
<td id="S3.T1.1.2.2.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.8.1" class="ltx_text ltx_font_bold">FinQA</span></td>
<td id="S3.T1.1.2.2.9" class="ltx_td ltx_align_center"><span id="S3.T1.1.2.2.9.1" class="ltx_text ltx_font_bold">Avg. Acc.</span></td>
</tr>
<tr id="S3.T1.1.3.3" class="ltx_tr">
<td id="S3.T1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.1.3.3.1.1" class="ltx_text">I.</span></td>
<td id="S3.T1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T1.1.3.3.2.1" class="ltx_text ltx_font_bold">TableLlama</span></td>
<td id="S3.T1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">w/o Fine-tuning</td>
<td id="S3.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">72.3</td>
<td id="S3.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">72.5</td>
<td id="S3.T1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">67.4</td>
<td id="S3.T1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">46.8</td>
<td id="S3.T1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">3.2</td>
<td id="S3.T1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">52.4</td>
</tr>
<tr id="S3.T1.1.4.4" class="ltx_tr">
<td id="S3.T1.1.4.4.1" class="ltx_td ltx_align_left">w/ DirectQA</td>
<td id="S3.T1.1.4.4.2" class="ltx_td ltx_align_center">72.9</td>
<td id="S3.T1.1.4.4.3" class="ltx_td ltx_align_center">70.5</td>
<td id="S3.T1.1.4.4.4" class="ltx_td ltx_align_center">74.2</td>
<td id="S3.T1.1.4.4.5" class="ltx_td ltx_align_center">48.4</td>
<td id="S3.T1.1.4.4.6" class="ltx_td ltx_align_center">3.7</td>
<td id="S3.T1.1.4.4.7" class="ltx_td ltx_align_center">54.0</td>
</tr>
<tr id="S3.T1.1.5.5" class="ltx_tr">
<td id="S3.T1.1.5.5.1" class="ltx_td ltx_align_center">
<span id="S3.T1.1.5.5.1.1" class="ltx_ERROR undefined">\cdashline</span>2-9</td>
<td id="S3.T1.1.5.5.2" class="ltx_td ltx_align_left" rowspan="2"><span id="S3.T1.1.5.5.2.1" class="ltx_text ltx_font_bold">StructLM</span></td>
<td id="S3.T1.1.5.5.3" class="ltx_td ltx_align_left">w/o Fine-tuning</td>
<td id="S3.T1.1.5.5.4" class="ltx_td ltx_align_center">81.9</td>
<td id="S3.T1.1.5.5.5" class="ltx_td ltx_align_center">81.9</td>
<td id="S3.T1.1.5.5.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.5.5.6.1" class="ltx_text ltx_framed ltx_framed_underline">78.1</span></td>
<td id="S3.T1.1.5.5.7" class="ltx_td ltx_align_center">73.9</td>
<td id="S3.T1.1.5.5.8" class="ltx_td ltx_align_center">10.6</td>
<td id="S3.T1.1.5.5.9" class="ltx_td ltx_align_center">65.3</td>
</tr>
<tr id="S3.T1.1.6.6" class="ltx_tr">
<td id="S3.T1.1.6.6.1" class="ltx_td"></td>
<td id="S3.T1.1.6.6.2" class="ltx_td ltx_align_left">w/ DirectQA</td>
<td id="S3.T1.1.6.6.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.6.6.3.1" class="ltx_text ltx_framed ltx_framed_underline">83.5</span></td>
<td id="S3.T1.1.6.6.4" class="ltx_td ltx_align_center">81.2</td>
<td id="S3.T1.1.6.6.5" class="ltx_td ltx_align_center">75.3</td>
<td id="S3.T1.1.6.6.6" class="ltx_td ltx_align_center">74.5</td>
<td id="S3.T1.1.6.6.7" class="ltx_td ltx_align_center">9.6</td>
<td id="S3.T1.1.6.6.8" class="ltx_td ltx_align_center">64.8</td>
</tr>
<tr id="S3.T1.1.7.7" class="ltx_tr">
<td id="S3.T1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T1.1.7.7.1.1" class="ltx_text">II.</span></td>
<td id="S3.T1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S3.T1.1.7.7.2.1" class="ltx_text ltx_font_bold">Llama2-7b</span></td>
<td id="S3.T1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_t">w/ DirectQA</td>
<td id="S3.T1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_t">64.4</td>
<td id="S3.T1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t">81.2</td>
<td id="S3.T1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_t">64.0</td>
<td id="S3.T1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_t">55.3</td>
<td id="S3.T1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_t">6.4</td>
<td id="S3.T1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t">54.3</td>
</tr>
<tr id="S3.T1.1.8.8" class="ltx_tr">
<td id="S3.T1.1.8.8.1" class="ltx_td ltx_align_left">w/ CoT</td>
<td id="S3.T1.1.8.8.2" class="ltx_td ltx_align_center">52.6</td>
<td id="S3.T1.1.8.8.3" class="ltx_td ltx_align_center">55.0</td>
<td id="S3.T1.1.8.8.4" class="ltx_td ltx_align_center">42.7</td>
<td id="S3.T1.1.8.8.5" class="ltx_td ltx_align_center">74.5</td>
<td id="S3.T1.1.8.8.6" class="ltx_td ltx_align_center">4.2</td>
<td id="S3.T1.1.8.8.7" class="ltx_td ltx_align_center">45.8</td>
</tr>
<tr id="S3.T1.1.9.9" class="ltx_tr">
<td id="S3.T1.1.9.9.1" class="ltx_td ltx_align_left"><span id="S3.T1.1.9.9.1.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></td>
<td id="S3.T1.1.9.9.2" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.2.1" class="ltx_text" style="background-color:#D3E3FD;">69.2</span></td>
<td id="S3.T1.1.9.9.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.3.1" class="ltx_text" style="background-color:#D3E3FD;">55.0</span></td>
<td id="S3.T1.1.9.9.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.4.1" class="ltx_text" style="background-color:#D3E3FD;">53.4</span></td>
<td id="S3.T1.1.9.9.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.5.1" class="ltx_text" style="background-color:#D3E3FD;">88.8</span></td>
<td id="S3.T1.1.9.9.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.6.1" class="ltx_text" style="background-color:#D3E3FD;">19.2</span></td>
<td id="S3.T1.1.9.9.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.9.9.7.1" class="ltx_text" style="background-color:#D3E3FD;">57.1 <span id="S3.T1.1.9.9.7.1.1" class="ltx_text" style="color:#FF0000;">(+24.7%)</span></span></td>
</tr>
<tr id="S3.T1.1.10.10" class="ltx_tr">
<td id="S3.T1.1.10.10.1" class="ltx_td ltx_align_center">
<span id="S3.T1.1.10.10.1.1" class="ltx_ERROR undefined">\cdashline</span>2-9</td>
<td id="S3.T1.1.10.10.2" class="ltx_td ltx_align_left" rowspan="3"><span id="S3.T1.1.10.10.2.1" class="ltx_text ltx_font_bold">Llama3-8b</span></td>
<td id="S3.T1.1.10.10.3" class="ltx_td ltx_align_left">w/ DirectQA</td>
<td id="S3.T1.1.10.10.4" class="ltx_td ltx_align_center">74.5</td>
<td id="S3.T1.1.10.10.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.10.10.5.1" class="ltx_text ltx_font_bold">85.9</span></td>
<td id="S3.T1.1.10.10.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.10.10.6.1" class="ltx_text ltx_font_bold">82.0</span></td>
<td id="S3.T1.1.10.10.7" class="ltx_td ltx_align_center">68.6</td>
<td id="S3.T1.1.10.10.8" class="ltx_td ltx_align_center">10.6</td>
<td id="S3.T1.1.10.10.9" class="ltx_td ltx_align_center">64.3</td>
</tr>
<tr id="S3.T1.1.11.11" class="ltx_tr">
<td id="S3.T1.1.11.11.1" class="ltx_td"></td>
<td id="S3.T1.1.11.11.2" class="ltx_td ltx_align_left">w/ CoT</td>
<td id="S3.T1.1.11.11.3" class="ltx_td ltx_align_center">48.4</td>
<td id="S3.T1.1.11.11.4" class="ltx_td ltx_align_center">62.4</td>
<td id="S3.T1.1.11.11.5" class="ltx_td ltx_align_center">41.0</td>
<td id="S3.T1.1.11.11.6" class="ltx_td ltx_align_center">88.3</td>
<td id="S3.T1.1.11.11.7" class="ltx_td ltx_align_center">8.5</td>
<td id="S3.T1.1.11.11.8" class="ltx_td ltx_align_center">49.7</td>
</tr>
<tr id="S3.T1.1.12.12" class="ltx_tr">
<td id="S3.T1.1.12.12.1" class="ltx_td"></td>
<td id="S3.T1.1.12.12.2" class="ltx_td ltx_align_left"><span id="S3.T1.1.12.12.2.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></td>
<td id="S3.T1.1.12.12.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.3.1" class="ltx_text" style="background-color:#D3E3FD;">69.7</span></td>
<td id="S3.T1.1.12.12.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.4.1" class="ltx_text" style="background-color:#D3E3FD;">68.5</span></td>
<td id="S3.T1.1.12.12.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.5.1" class="ltx_text" style="background-color:#D3E3FD;">47.2</span></td>
<td id="S3.T1.1.12.12.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.6.1" class="ltx_text" style="background-color:#D3E3FD;">92.6</span></td>
<td id="S3.T1.1.12.12.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.7.1" class="ltx_text" style="background-color:#D3E3FD;">27.1</span></td>
<td id="S3.T1.1.12.12.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.12.12.8.1" class="ltx_text" style="background-color:#D3E3FD;">61.0 <span id="S3.T1.1.12.12.8.1.1" class="ltx_text" style="color:#FF0000;">(+22.7%)</span></span></td>
</tr>
<tr id="S3.T1.1.13.13" class="ltx_tr">
<td id="S3.T1.1.13.13.1" class="ltx_td ltx_align_center">
<span id="S3.T1.1.13.13.1.1" class="ltx_ERROR undefined">\cdashline</span>2-9</td>
<td id="S3.T1.1.13.13.2" class="ltx_td ltx_align_left" rowspan="3"><span id="S3.T1.1.13.13.2.1" class="ltx_text ltx_font_bold">CodeLlama-7b</span></td>
<td id="S3.T1.1.13.13.3" class="ltx_td ltx_align_left">w/ DirectQA</td>
<td id="S3.T1.1.13.13.4" class="ltx_td ltx_align_center">65.4</td>
<td id="S3.T1.1.13.13.5" class="ltx_td ltx_align_center">75.8</td>
<td id="S3.T1.1.13.13.6" class="ltx_td ltx_align_center">64.6</td>
<td id="S3.T1.1.13.13.7" class="ltx_td ltx_align_center">44.7</td>
<td id="S3.T1.1.13.13.8" class="ltx_td ltx_align_center">4.3</td>
<td id="S3.T1.1.13.13.9" class="ltx_td ltx_align_center">51.0</td>
</tr>
<tr id="S3.T1.1.14.14" class="ltx_tr">
<td id="S3.T1.1.14.14.1" class="ltx_td"></td>
<td id="S3.T1.1.14.14.2" class="ltx_td ltx_align_left">w/ CoT</td>
<td id="S3.T1.1.14.14.3" class="ltx_td ltx_align_center">45.2</td>
<td id="S3.T1.1.14.14.4" class="ltx_td ltx_align_center">51.7</td>
<td id="S3.T1.1.14.14.5" class="ltx_td ltx_align_center">38.8</td>
<td id="S3.T1.1.14.14.6" class="ltx_td ltx_align_center">70.7</td>
<td id="S3.T1.1.14.14.7" class="ltx_td ltx_align_center">2.7</td>
<td id="S3.T1.1.14.14.8" class="ltx_td ltx_align_center">41.8</td>
</tr>
<tr id="S3.T1.1.15.15" class="ltx_tr">
<td id="S3.T1.1.15.15.1" class="ltx_td"></td>
<td id="S3.T1.1.15.15.2" class="ltx_td ltx_align_left"><span id="S3.T1.1.15.15.2.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></td>
<td id="S3.T1.1.15.15.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.3.1" class="ltx_text" style="background-color:#D3E3FD;">66.5</span></td>
<td id="S3.T1.1.15.15.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.4.1" class="ltx_text" style="background-color:#D3E3FD;">69.8</span></td>
<td id="S3.T1.1.15.15.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.5.1" class="ltx_text" style="background-color:#D3E3FD;">44.9</span></td>
<td id="S3.T1.1.15.15.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.6.1" class="ltx_text" style="background-color:#D3E3FD;">90.1</span></td>
<td id="S3.T1.1.15.15.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.7.1" class="ltx_text" style="background-color:#D3E3FD;">25.0</span></td>
<td id="S3.T1.1.15.15.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.15.15.8.1" class="ltx_text" style="background-color:#D3E3FD;">59.3 <span id="S3.T1.1.15.15.8.1.1" class="ltx_text" style="color:#FF0000;">(+41.9%)</span></span></td>
</tr>
<tr id="S3.T1.1.16.16" class="ltx_tr">
<td id="S3.T1.1.16.16.1" class="ltx_td ltx_align_center">
<span id="S3.T1.1.16.16.1.1" class="ltx_ERROR undefined">\cdashline</span>2-9</td>
<td id="S3.T1.1.16.16.2" class="ltx_td ltx_align_left" rowspan="3"><span id="S3.T1.1.16.16.2.1" class="ltx_text ltx_font_bold">DeepSeek-7b</span></td>
<td id="S3.T1.1.16.16.3" class="ltx_td ltx_align_left">w/ DirectQA</td>
<td id="S3.T1.1.16.16.4" class="ltx_td ltx_align_center">72.9</td>
<td id="S3.T1.1.16.16.5" class="ltx_td ltx_align_center">76.5</td>
<td id="S3.T1.1.16.16.6" class="ltx_td ltx_align_center">73.0</td>
<td id="S3.T1.1.16.16.7" class="ltx_td ltx_align_center">62.2</td>
<td id="S3.T1.1.16.16.8" class="ltx_td ltx_align_center">9.0</td>
<td id="S3.T1.1.16.16.9" class="ltx_td ltx_align_center">58.7</td>
</tr>
<tr id="S3.T1.1.17.17" class="ltx_tr">
<td id="S3.T1.1.17.17.1" class="ltx_td"></td>
<td id="S3.T1.1.17.17.2" class="ltx_td ltx_align_left">w/ CoT</td>
<td id="S3.T1.1.17.17.3" class="ltx_td ltx_align_center">52.1</td>
<td id="S3.T1.1.17.17.4" class="ltx_td ltx_align_center">62.4</td>
<td id="S3.T1.1.17.17.5" class="ltx_td ltx_align_center">45.5</td>
<td id="S3.T1.1.17.17.6" class="ltx_td ltx_align_center">84.6</td>
<td id="S3.T1.1.17.17.7" class="ltx_td ltx_align_center">8.5</td>
<td id="S3.T1.1.17.17.8" class="ltx_td ltx_align_center">50.6</td>
</tr>
<tr id="S3.T1.1.18.18" class="ltx_tr">
<td id="S3.T1.1.18.18.1" class="ltx_td"></td>
<td id="S3.T1.1.18.18.2" class="ltx_td ltx_align_left"><span id="S3.T1.1.18.18.2.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></td>
<td id="S3.T1.1.18.18.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.3.1" class="ltx_text" style="background-color:#D3E3FD;">71.3</span></td>
<td id="S3.T1.1.18.18.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.4.1" class="ltx_text" style="background-color:#D3E3FD;">69.1</span></td>
<td id="S3.T1.1.18.18.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.5.1" class="ltx_text" style="background-color:#D3E3FD;">47.8</span></td>
<td id="S3.T1.1.18.18.6" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.6.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#D3E3FD;">93.1</span></td>
<td id="S3.T1.1.18.18.7" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.7.1" class="ltx_text" style="background-color:#D3E3FD;">30.9</span></td>
<td id="S3.T1.1.18.18.8" class="ltx_td ltx_align_center"><span id="S3.T1.1.18.18.8.1" class="ltx_text" style="background-color:#D3E3FD;">62.4 <span id="S3.T1.1.18.18.8.1.1" class="ltx_text" style="color:#FF0000;">(+23.3%)</span></span></td>
</tr>
<tr id="S3.T1.1.19.19" class="ltx_tr">
<td id="S3.T1.1.19.19.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="S3.T1.1.19.19.1.1" class="ltx_text">III.</span></td>
<td id="S3.T1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.1.19.19.2.1" class="ltx_text ltx_font_bold">GPT-3.5-turbo</span></td>
<td id="S3.T1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_t">w/ TART</td>
<td id="S3.T1.1.19.19.4" class="ltx_td ltx_align_center ltx_border_t">78.7</td>
<td id="S3.T1.1.19.19.5" class="ltx_td ltx_align_center ltx_border_t">63.6</td>
<td id="S3.T1.1.19.19.6" class="ltx_td ltx_align_center ltx_border_t">59.3</td>
<td id="S3.T1.1.19.19.7" class="ltx_td ltx_align_center ltx_border_t">88.3</td>
<td id="S3.T1.1.19.19.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.19.19.8.1" class="ltx_text ltx_framed ltx_framed_underline">56.4</span></td>
<td id="S3.T1.1.19.19.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.19.19.9.1" class="ltx_text ltx_framed ltx_framed_underline">69.3</span></td>
</tr>
<tr id="S3.T1.1.20.20" class="ltx_tr">
<td id="S3.T1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.1.20.20.1.1" class="ltx_text ltx_font_bold">GPT-4</span></td>
<td id="S3.T1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_bb">w/ TART</td>
<td id="S3.T1.1.20.20.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.1.20.20.3.1" class="ltx_text ltx_font_bold">87.7</span></td>
<td id="S3.T1.1.20.20.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.1.20.20.4.1" class="ltx_text ltx_framed ltx_framed_underline">84.1</span></td>
<td id="S3.T1.1.20.20.5" class="ltx_td ltx_align_center ltx_border_bb">63.6</td>
<td id="S3.T1.1.20.20.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.1.20.20.6.1" class="ltx_text ltx_font_bold">98.3</span></td>
<td id="S3.T1.1.20.20.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.1.20.20.7.1" class="ltx_text ltx_font_bold">68.5</span></td>
<td id="S3.T1.1.20.20.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.1.20.20.8.1" class="ltx_text ltx_font_bold">80.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance evaluation across backbone models using the <span id="S3.T1.4.1" class="ltx_text ltx_font_smallcaps">TART</span> framework, highlighting the best (bold) and second-best (underlined) results. The accuracy is calculated on testing sets, with overall average accuracy in the last column (<span id="S3.T1.5.2" class="ltx_text ltx_font_italic">Avg. Acc.</span>).</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Datasets and Baselines.</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">To evaluate <span id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, we select two categories of benchmarks for table-based reasoning. <span id="S4.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">(1) Table question answering (TQA)</span>: <span id="S4.SS0.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_typewriter">WikiTableQuestion (WTQ)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Pasupat and Liang <a href="#bib.bib28" title="" class="ltx_ref">2015</a>)</cite> focuses on simple factoid questions. <span id="S4.SS0.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_typewriter">HiTab (HIT)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Cheng etÂ al. <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>, <span id="S4.SS0.SSS0.Px1.p1.1.5" class="ltx_text ltx_font_typewriter">TabMWP (TMP)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Lu etÂ al. <a href="#bib.bib21" title="" class="ltx_ref">2023b</a>)</cite> and <span id="S4.SS0.SSS0.Px1.p1.1.6" class="ltx_text ltx_font_typewriter">FinQA (FQA)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> datasets focus on numerical reasoning reasoning. <span id="S4.SS0.SSS0.Px1.p1.1.7" class="ltx_text ltx_font_typewriter">TAT-QA (TAT)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al. <a href="#bib.bib49" title="" class="ltx_ref">2021</a>)</cite> and <span id="S4.SS0.SSS0.Px1.p1.1.8" class="ltx_text ltx_font_typewriter">HybridQA (HYQ)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib7" title="" class="ltx_ref">2020b</a>)</cite> require joint reasoning over the table and the text for financial reports and Wikipedia tables, respectively. <span id="S4.SS0.SSS0.Px1.p1.1.9" class="ltx_text ltx_font_italic">2) Table-based fact verification (TFV)</span>: We select <span id="S4.SS0.SSS0.Px1.p1.1.10" class="ltx_text ltx_font_typewriter">TabFact (TAF)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al. <a href="#bib.bib6" title="" class="ltx_ref">2020a</a>)</cite>, <span id="S4.SS0.SSS0.Px1.p1.1.11" class="ltx_text ltx_font_typewriter">SCITAB (SCT)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Lu etÂ al. <a href="#bib.bib22" title="" class="ltx_ref">2023c</a>)</cite>, and <span id="S4.SS0.SSS0.Px1.p1.1.12" class="ltx_text ltx_font_typewriter">PubHealthTab (PHT)</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Akhtar, Cocarascu, and Simperl <a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite> datasets, which focus on verifying facts based on tables from Wikipedia, scientific articles, and public health articles, respectively.</p>
</div>
<div id="S4.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p2.1" class="ltx_p">For baseline comparisons, we select well-known table-based open-source LLMs such as <span id="S4.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_typewriter">TableLlama</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al. <a href="#bib.bib45" title="" class="ltx_ref">2023a</a>)</cite> and <span id="S4.SS0.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_typewriter">StructLM</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhuang etÂ al. <a href="#bib.bib50" title="" class="ltx_ref">2024</a>)</cite>, as well as text-pretrained models (<span id="S4.SS0.SSS0.Px1.p2.1.3" class="ltx_text ltx_font_typewriter">Llama2-7b</span>, <span id="S4.SS0.SSS0.Px1.p2.1.4" class="ltx_text ltx_font_typewriter">Llama3-8b</span>) and code-pretrained models (<span id="S4.SS0.SSS0.Px1.p2.1.5" class="ltx_text ltx_font_typewriter">CodeLlama-7b</span>, <span id="S4.SS0.SSS0.Px1.p2.1.6" class="ltx_text ltx_font_typewriter">DeepSeek-Coder-7b</span>). We choose the 7b and the 8b versions to represent a balance between computational efficiency and the capacity for complex reasoning and generalization. For each model, we fine-tune with two settings: (1) <span id="S4.SS0.SSS0.Px1.p2.1.7" class="ltx_text ltx_font_typewriter">DirectQA</span>, where models generate answers directly from questions and tables, and (2) <span id="S4.SS0.SSS0.Px1.p2.1.8" class="ltx_text ltx_font_typewriter">Chain-of-Thought (CoT)</span> reasoning, which requires models to formulate a step-by-step reasoning process before concluding with an answer.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Implementation</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">For TART, we use the answer given by executing the reasoning plan; if the reasoning plan is not executable, we use the answer given by CoT.
For each model, we train the model with <span id="S4.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">ToolTab</span> while leaving the rest (WTQ, HIT, TAT, and HYQ) as held-out unseen datasets.
All experiments were conducted on a GPU server with Intel Xeon Platinum 8480C (224) @ 2.900GHz CPU and 8 NVIDIA H100 (80G) GPUs. The training process for <span id="S4.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_typewriter">Llama-2-7b-hf</span>, <span id="S4.SS0.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_typewriter">CodeLlama-7b-hf</span>, and <span id="S4.SS0.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_typewriter">deepseek-coder-7b-instruct-v1.5</span> requires a single GPU for approximately 20 hours, using a batch size of 4, learning rate of 5e-5, sequence length of 1500, gradient accumulation steps of 2, and 10 training epochs. Training <span id="S4.SS0.SSS0.Px2.p1.1.5" class="ltx_text ltx_font_typewriter">Llama-3-8b</span> required up to two GPUs for around 20 hours with the same settings. To minimize randomness, a temperature of 0.0 was used, while all other hyperparameters for sampling the output from the LLMs remained at their default values. For the closed-source version of <span id="S4.SS0.SSS0.Px2.p1.1.6" class="ltx_text ltx_font_smallcaps">TART</span>, we use <span id="S4.SS0.SSS0.Px2.p1.1.7" class="ltx_text ltx_font_typewriter">GPT-3.5-turbo</span> and <span id="S4.SS0.SSS0.Px2.p1.1.8" class="ltx_text ltx_font_typewriter">GPT-4</span> with two in-context examples.</p>
</div>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Main Results</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We first evaluate <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> and the baselines on in-domain datasets, where their training sets are used to construct <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">ToolTab</span>. The experimental results, as shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ Training Configurations. â€£ 3.4 Model Training â€£ 3 Methodology â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, reveal a notable performance improvement in our model compared to baseline models. We have four major observations.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">1. <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">TART</span> consistently outperforms <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">CoT</span> across all four backbone models and datasets. For example, with <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">DeepSeek-7b</span> as the backbone model, <span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">TART</span> outperforms <span id="S4.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">DirectQA</span> and <span id="S4.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">CoT</span> by 16.3% and 41.9% on average, respectively. This highlights the effectiveness of integrating task-specific tools in enhancing complex reasoning capabilities.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">2. With <span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">CodeLlama-7b</span> as the backbone model of <span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_smallcaps">TART</span>, it achieves the highest accuracy increase of 41.9%., whereas <span id="S4.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">Llama3-8b</span> shows the least improvement of 22.7%. This discrepancy is likely because of <span id="S4.SS1.p3.1.4" class="ltx_text ltx_font_typewriter">CodeLlama-7b</span>â€™s specialized pre-training in coding tasks, which enhances the capabilities of creating tools for structured queries and operations.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">3. The performance gains of <span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_smallcaps">TART</span> also vary for different datasets, with <span id="S4.SS1.p4.1.2" class="ltx_text ltx_font_typewriter">FinQA</span> showing the highest increase, while <span id="S4.SS1.p4.1.3" class="ltx_text ltx_font_typewriter">PubHealthTab</span> shows the least. This discrepancy suggests that the financial focus of the <span id="S4.SS1.p4.1.4" class="ltx_text ltx_font_typewriter">FinQA</span> dataset, which demands extensive numerical reasoning and structured data manipulation, benefits significantly from the <span id="S4.SS1.p4.1.5" class="ltx_text ltx_font_typewriter">TART</span> approach.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">4. Using closed-source models (<span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_typewriter">GPT-3.5-turbo</span> and <span id="S4.SS1.p5.1.2" class="ltx_text ltx_font_typewriter">GPT-4</span>) as the backbone models for <span id="S4.SS1.p5.1.3" class="ltx_text ltx_font_smallcaps">TART</span> achieves an average accuracy of 74.9, significantly outperforming the open-source counterparts, which average at 60.0 accuracy. Nonetheless, the highest-performing open-source model, <span id="S4.SS1.p5.1.4" class="ltx_text ltx_font_typewriter">DeepSeek-7b</span>, reaches up to 90.0% of GPT-3.5-turboâ€™s performance and 77.6% of <span id="S4.SS1.p5.1.5" class="ltx_text ltx_font_typewriter">GPT-4</span>, illustrating the competitiveness of open-source models in the creation and use of tools despite the apparent model size gap.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Out-of-Domain Results</h3>

<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:229.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.0pt,11.3pt) scale(0.910222325177025,0.910222325177025) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"></th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"></th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;" colspan="2"><span id="S4.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">TQA</span></th>
<th id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;" colspan="2"><span id="S4.T2.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Hybrid TQA</span></th>
</tr>
<tr id="S4.T2.1.1.2.2" class="ltx_tr">
<th id="S4.T2.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T2.1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Setting</span></th>
<th id="S4.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.3.1" class="ltx_text ltx_font_bold">HIT</span></th>
<th id="S4.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.4.1" class="ltx_text ltx_font_bold">WTQ</span></th>
<th id="S4.T2.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.5.1" class="ltx_text ltx_font_bold">TAT</span></th>
<th id="S4.T2.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.2.2.6.1" class="ltx_text ltx_font_bold">HYQ</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.3.1" class="ltx_tr">
<th id="S4.T2.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;" rowspan="3"><span id="S4.T2.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Llama2-7b</span></th>
<th id="S4.T2.1.1.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;">w/ DirectQA</th>
<td id="S4.T2.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;">19.1</td>
<td id="S4.T2.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;">23.4</td>
<td id="S4.T2.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;">15.4</td>
<td id="S4.T2.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;">8.5</td>
</tr>
<tr id="S4.T2.1.1.4.2" class="ltx_tr">
<th id="S4.T2.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ CoT</th>
<td id="S4.T2.1.1.4.2.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">22.1</td>
<td id="S4.T2.1.1.4.2.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">12.7</td>
<td id="S4.T2.1.1.4.2.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">20.0</td>
<td id="S4.T2.1.1.4.2.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">6.7</td>
</tr>
<tr id="S4.T2.1.1.5.3" class="ltx_tr">
<th id="S4.T2.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.5.3.1.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></th>
<td id="S4.T2.1.1.5.3.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.5.3.2.1" class="ltx_text" style="background-color:#D3E3FD;">19.2</span></td>
<td id="S4.T2.1.1.5.3.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.5.3.3.1" class="ltx_text" style="background-color:#D3E3FD;">17.0</span></td>
<td id="S4.T2.1.1.5.3.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.5.3.4.1" class="ltx_text" style="background-color:#D3E3FD;">17.0</span></td>
<td id="S4.T2.1.1.5.3.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.5.3.5.1" class="ltx_text" style="background-color:#D3E3FD;">6.4</span></td>
</tr>
<tr id="S4.T2.1.1.6.4" class="ltx_tr">
<th id="S4.T2.1.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;" rowspan="3">
<span id="S4.T2.1.1.6.4.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S4.T2.1.1.6.4.1.2" class="ltx_text ltx_font_bold">Llama3-8b</span>
</th>
<th id="S4.T2.1.1.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ DirectQA</th>
<td id="S4.T2.1.1.6.4.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.6.4.3.1" class="ltx_text ltx_font_bold">51.1</span></td>
<td id="S4.T2.1.1.6.4.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.6.4.4.1" class="ltx_text ltx_font_bold">38.8</span></td>
<td id="S4.T2.1.1.6.4.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">20.2</td>
<td id="S4.T2.1.1.6.4.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">10.1</td>
</tr>
<tr id="S4.T2.1.1.7.5" class="ltx_tr">
<th id="S4.T2.1.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ CoT</th>
<td id="S4.T2.1.1.7.5.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">33.8</td>
<td id="S4.T2.1.1.7.5.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">26.8</td>
<td id="S4.T2.1.1.7.5.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.7.5.4.1" class="ltx_text ltx_framed ltx_framed_underline">29.3</span></td>
<td id="S4.T2.1.1.7.5.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">11.0</td>
</tr>
<tr id="S4.T2.1.1.8.6" class="ltx_tr">
<th id="S4.T2.1.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.8.6.1.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></th>
<td id="S4.T2.1.1.8.6.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.8.6.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#D3E3FD;">34.6</span></td>
<td id="S4.T2.1.1.8.6.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.8.6.3.1" class="ltx_text" style="background-color:#D3E3FD;">32.5</span></td>
<td id="S4.T2.1.1.8.6.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.8.6.4.1" class="ltx_text ltx_font_bold" style="background-color:#D3E3FD;">29.3</span></td>
<td id="S4.T2.1.1.8.6.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.8.6.5.1" class="ltx_text ltx_font_bold" style="background-color:#D3E3FD;">12.2</span></td>
</tr>
<tr id="S4.T2.1.1.9.7" class="ltx_tr">
<th id="S4.T2.1.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;" rowspan="3">
<span id="S4.T2.1.1.9.7.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S4.T2.1.1.9.7.1.2" class="ltx_text ltx_font_bold">Codellama-7b</span>
</th>
<th id="S4.T2.1.1.9.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ DirectQA</th>
<td id="S4.T2.1.1.9.7.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">17.0</td>
<td id="S4.T2.1.1.9.7.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">19.1</td>
<td id="S4.T2.1.1.9.7.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">13.8</td>
<td id="S4.T2.1.1.9.7.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">6.9</td>
</tr>
<tr id="S4.T2.1.1.10.8" class="ltx_tr">
<th id="S4.T2.1.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ CoT</th>
<td id="S4.T2.1.1.10.8.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">16.1</td>
<td id="S4.T2.1.1.10.8.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">22.6</td>
<td id="S4.T2.1.1.10.8.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">14.6</td>
<td id="S4.T2.1.1.10.8.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">9.7</td>
</tr>
<tr id="S4.T2.1.1.11.9" class="ltx_tr">
<th id="S4.T2.1.1.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.11.9.1.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></th>
<td id="S4.T2.1.1.11.9.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.11.9.2.1" class="ltx_text" style="background-color:#D3E3FD;">22.3</span></td>
<td id="S4.T2.1.1.11.9.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.11.9.3.1" class="ltx_text" style="background-color:#D3E3FD;">30.3</span></td>
<td id="S4.T2.1.1.11.9.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.11.9.4.1" class="ltx_text" style="background-color:#D3E3FD;">13.8</span></td>
<td id="S4.T2.1.1.11.9.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.11.9.5.1" class="ltx_text" style="background-color:#D3E3FD;">9.0</span></td>
</tr>
<tr id="S4.T2.1.1.12.10" class="ltx_tr">
<th id="S4.T2.1.1.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;" rowspan="3">
<span id="S4.T2.1.1.12.10.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S4.T2.1.1.12.10.1.2" class="ltx_text ltx_font_bold">Deepseek-7b</span>
</th>
<th id="S4.T2.1.1.12.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ DirectQA</th>
<td id="S4.T2.1.1.12.10.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">27.1</td>
<td id="S4.T2.1.1.12.10.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">26.2</td>
<td id="S4.T2.1.1.12.10.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">19.7</td>
<td id="S4.T2.1.1.12.10.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">11.2</td>
</tr>
<tr id="S4.T2.1.1.13.11" class="ltx_tr">
<th id="S4.T2.1.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:3.7pt;padding-right:3.7pt;">w/ CoT</th>
<td id="S4.T2.1.1.13.11.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">20.5</td>
<td id="S4.T2.1.1.13.11.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">26.2</td>
<td id="S4.T2.1.1.13.11.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">15.3</td>
<td id="S4.T2.1.1.13.11.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">8.1</td>
</tr>
<tr id="S4.T2.1.1.14.12" class="ltx_tr">
<th id="S4.T2.1.1.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.14.12.1.1" class="ltx_text" style="background-color:#D3E3FD;">w/ TART</span></th>
<td id="S4.T2.1.1.14.12.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.14.12.2.1" class="ltx_text" style="background-color:#D3E3FD;">29.8</span></td>
<td id="S4.T2.1.1.14.12.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.14.12.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#D3E3FD;">33.5</span></td>
<td id="S4.T2.1.1.14.12.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.14.12.4.1" class="ltx_text" style="background-color:#D3E3FD;">17.0</span></td>
<td id="S4.T2.1.1.14.12.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T2.1.1.14.12.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#D3E3FD;">11.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Out-of-Domain evaluation results for <span id="S4.T2.3.1" class="ltx_text ltx_font_smallcaps">TART</span> framework, highlighting the best (bold) and the second-best (underlined) results.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We hypothesize that the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> has enhanced generalization capabilities compared to CoT due to its ability to create and use general tools. To validate this, we further evaluate <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_smallcaps">TART</span> across four different out-of-domain (OOD) datasets: <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">HiTab (HIT)</span>, <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">WikiTableQuestion (WTQ)</span>, <span id="S4.SS2.p1.1.5" class="ltx_text ltx_font_typewriter">TAT-QA (TAT)</span>, and <span id="S4.SS2.p1.1.6" class="ltx_text ltx_font_typewriter">HybridQA (HYQ)</span>. The results are shown in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Out-of-Domain Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.8pt;height:145.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.9pt,17.3pt) scale(0.807627275238484,0.807627275238484) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Tab Formt</span></th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">TAF</span></th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">PHT</span></th>
<th id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">SCT</span></th>
<th id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">TMP</span></th>
<th id="S4.T3.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.1.1.6.1" class="ltx_text ltx_font_bold">FQA</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<td id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">Llama-2</td>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">71.8/78.5</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">75.8/66.4</td>
<td id="S4.T3.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.2.1.4.1" class="ltx_text ltx_framed ltx_framed_underline">64.0/57.0</span></td>
<td id="S4.T3.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">93.6/92.0</td>
<td id="S4.T3.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">73.4/37.7</td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<td id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">Llama-3</td>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.3.2.2.1" class="ltx_text ltx_framed ltx_framed_underline">76.6/84.7</span></td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.3.2.3.1" class="ltx_text ltx_framed ltx_framed_underline">79.2/67.8</span></td>
<td id="S4.T3.1.1.3.2.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">62.4/55.9</td>
<td id="S4.T3.1.1.3.2.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.3.2.5.1" class="ltx_text ltx_framed ltx_framed_underline">94.1/94.4</span></td>
<td id="S4.T3.1.1.3.2.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.3.2.6.1" class="ltx_text ltx_framed ltx_framed_underline">71.8/40.0</span></td>
</tr>
<tr id="S4.T3.1.1.4.3" class="ltx_tr">
<td id="S4.T3.1.1.4.3.1" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">Codellama</td>
<td id="S4.T3.1.1.4.3.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">67.6/78.0</td>
<td id="S4.T3.1.1.4.3.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.4.3.3.1" class="ltx_text ltx_font_bold">81.2/66.1</span></td>
<td id="S4.T3.1.1.4.3.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.4.3.4.1" class="ltx_text ltx_font_bold">64.6/53.9</span></td>
<td id="S4.T3.1.1.4.3.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">94.1/91.5</td>
<td id="S4.T3.1.1.4.3.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">76.1/35.7</td>
</tr>
<tr id="S4.T3.1.1.5.4" class="ltx_tr">
<td id="S4.T3.1.1.5.4.1" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">DeepSeek</td>
<td id="S4.T3.1.1.5.4.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.5.4.2.1" class="ltx_text ltx_font_bold">70.7/79.7</span></td>
<td id="S4.T3.1.1.5.4.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">72.5/71.3</td>
<td id="S4.T3.1.1.5.4.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">63.5/51.3</td>
<td id="S4.T3.1.1.5.4.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.5.4.5.1" class="ltx_text ltx_font_bold">95.7/93.9</span></td>
<td id="S4.T3.1.1.5.4.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.5.4.6.1" class="ltx_text ltx_font_bold">74.5/38.6</span></td>
</tr>
<tr id="S4.T3.1.1.6.5" class="ltx_tr">
<td id="S4.T3.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.1.1" class="ltx_text ltx_font_bold">Tool Mkr</span></td>
<td id="S4.T3.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.2.1" class="ltx_text ltx_font_bold">TAF</span></td>
<td id="S4.T3.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.3.1" class="ltx_text ltx_font_bold">PHT</span></td>
<td id="S4.T3.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.4.1" class="ltx_text ltx_font_bold">SCT</span></td>
<td id="S4.T3.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.5.1" class="ltx_text ltx_font_bold">TMP</span></td>
<td id="S4.T3.1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.6.5.6.1" class="ltx_text ltx_font_bold">FQA</span></td>
</tr>
<tr id="S4.T3.1.1.7.6" class="ltx_tr">
<td id="S4.T3.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">Llama-2</td>
<td id="S4.T3.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">70.2/81.8</td>
<td id="S4.T3.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">65.8/60.2</td>
<td id="S4.T3.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">53.9/61.5</td>
<td id="S4.T3.1.1.7.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">95.7/91.1</td>
<td id="S4.T3.1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.7pt;padding-right:3.7pt;">61.7/31.0</td>
</tr>
<tr id="S4.T3.1.1.8.7" class="ltx_tr">
<td id="S4.T3.1.1.8.7.1" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">Llama-3</td>
<td id="S4.T3.1.1.8.7.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">75.5/75.4</td>
<td id="S4.T3.1.1.8.7.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">71.1/69.8</td>
<td id="S4.T3.1.1.8.7.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">63.5/52.2</td>
<td id="S4.T3.1.1.8.7.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.8.7.5.1" class="ltx_text ltx_font_bold">97.9/92.4</span></td>
<td id="S4.T3.1.1.8.7.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">62.2/38.5</td>
</tr>
<tr id="S4.T3.1.1.9.8" class="ltx_tr">
<td id="S4.T3.1.1.9.8.1" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">Codellama</td>
<td id="S4.T3.1.1.9.8.2" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.9.8.2.1" class="ltx_text ltx_framed ltx_framed_underline">75.5/85.2</span></td>
<td id="S4.T3.1.1.9.8.3" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.9.8.3.1" class="ltx_text ltx_framed ltx_framed_underline">74.5/71.2</span></td>
<td id="S4.T3.1.1.9.8.4" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.9.8.4.1" class="ltx_text ltx_font_bold">62.9/57.1</span></td>
<td id="S4.T3.1.1.9.8.5" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;">95.7/91.7</td>
<td id="S4.T3.1.1.9.8.6" class="ltx_td ltx_align_center" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.9.8.6.1" class="ltx_text ltx_framed ltx_framed_underline">68.1/39.8</span></td>
</tr>
<tr id="S4.T3.1.1.10.9" class="ltx_tr">
<td id="S4.T3.1.1.10.9.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;">Deepseek</td>
<td id="S4.T3.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.10.9.2.1" class="ltx_text ltx_font_bold">76.6/84.7</span></td>
<td id="S4.T3.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.10.9.3.1" class="ltx_text ltx_font_bold">79.2/67.8</span></td>
<td id="S4.T3.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.10.9.4.1" class="ltx_text ltx_framed ltx_framed_underline">62.4/55.9</span></td>
<td id="S4.T3.1.1.10.9.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.10.9.5.1" class="ltx_text ltx_framed ltx_framed_underline">94.1/94.4</span></td>
<td id="S4.T3.1.1.10.9.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.7pt;padding-right:3.7pt;"><span id="S4.T3.1.1.10.9.6.1" class="ltx_text ltx_font_bold">71.8/40.0</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results of <span id="S4.T3.7.1" class="ltx_text ltx_font_smallcaps">TART</span> with different backbone modules. The top section uses <span id="S4.T3.8.2" class="ltx_text ltx_font_typewriter">deepseek-code-7b</span> as the Tool Maker, while the bottom section uses <span id="S4.T3.9.3" class="ltx_text ltx_font_typewriter">Llama-3-8b</span> as the Table Formatter. The best performance is highlighted in bold and the second-best is underlined. Tab Formt stands for <span id="S4.T3.10.4" class="ltx_text ltx_font_italic">Table Formatter</span> and Tool Mkr for <span id="S4.T3.11.5" class="ltx_text ltx_font_italic">Tool Maker</span>.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">TART</span> method demonstrates variable effectiveness, with notable improvements in certain contexts. For instance, it achieves an average accuracy increase of 29.3% on the WTQ dataset, indicating robust domain-transfer capabilities. The <span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">Deepseek-7b</span> backbone model particularly excels, with 30.6% increase in accuracy. We hypothesize that this superiority stems from its pre-training on coding tasks, which equips it with the capability of effectively creating and using tools in novel domains, surpassing pure-text-based pretraining models such as <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_typewriter">Llama-2-7b</span>. The analysis in SectionÂ <a href="#S4.SS4" title="4.4 Analysis of Tool Creation â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> supports our hypothesis, suggesting that <span id="S4.SS2.p2.1.4" class="ltx_text ltx_font_typewriter">TART</span> excels in developing generic table reasoning functions that generalize well across various domains.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:433.6pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F3.1.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_top" style="width:216.8pt;">
<img src="/html/2409.11724/assets/x3.png" id="S4.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="507" height="367" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F3.2.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:216.8pt;">
<img src="/html/2409.11724/assets/x4.png" id="S4.F3.2.2.g1" class="ltx_graphics ltx_img_portrait" width="322" height="403" alt="Refer to caption">
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Tool distributions and their categories for the top-20 tools.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:433.6pt;">
<div id="S4.F3.fig1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:147pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(57.5pt,-19.5pt) scale(1.36108594060237,1.36108594060237) ;">
<table id="S4.F3.fig1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.F3.fig1.1.1.1.1" class="ltx_tr">
<th id="S4.F3.fig1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Rank</th>
<th id="S4.F3.fig1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Tool Name</th>
<th id="S4.F3.fig1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Rank</th>
<th id="S4.F3.fig1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Tool Name</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.F3.fig1.1.1.2.1" class="ltx_tr">
<td id="S4.F3.fig1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.F3.fig1.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">get_column_by_name</td>
<td id="S4.F3.fig1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">6</td>
<td id="S4.F3.fig1.1.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">equal_to</td>
</tr>
<tr id="S4.F3.fig1.1.1.3.2" class="ltx_tr">
<td id="S4.F3.fig1.1.1.3.2.1" class="ltx_td ltx_align_center">2</td>
<td id="S4.F3.fig1.1.1.3.2.2" class="ltx_td ltx_align_left">get_column_cell_value</td>
<td id="S4.F3.fig1.1.1.3.2.3" class="ltx_td ltx_align_center">7</td>
<td id="S4.F3.fig1.1.1.3.2.4" class="ltx_td ltx_align_left">get_column_by_index</td>
</tr>
<tr id="S4.F3.fig1.1.1.4.3" class="ltx_tr">
<td id="S4.F3.fig1.1.1.4.3.1" class="ltx_td ltx_align_center">3</td>
<td id="S4.F3.fig1.1.1.4.3.2" class="ltx_td ltx_align_left">get_row_index_by_value</td>
<td id="S4.F3.fig1.1.1.4.3.3" class="ltx_td ltx_align_center">8</td>
<td id="S4.F3.fig1.1.1.4.3.4" class="ltx_td ltx_align_left">subtract</td>
</tr>
<tr id="S4.F3.fig1.1.1.5.4" class="ltx_tr">
<td id="S4.F3.fig1.1.1.5.4.1" class="ltx_td ltx_align_center">4</td>
<td id="S4.F3.fig1.1.1.5.4.2" class="ltx_td ltx_align_left">extract_price</td>
<td id="S4.F3.fig1.1.1.5.4.3" class="ltx_td ltx_align_center">9</td>
<td id="S4.F3.fig1.1.1.5.4.4" class="ltx_td ltx_align_left">divide</td>
</tr>
<tr id="S4.F3.fig1.1.1.6.5" class="ltx_tr">
<td id="S4.F3.fig1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">5</td>
<td id="S4.F3.fig1.1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_bb">get_row_by_name</td>
<td id="S4.F3.fig1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">10</td>
<td id="S4.F3.fig1.1.1.6.5.4" class="ltx_td ltx_align_left ltx_border_bb">add</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Top-10 tools in TART <span id="S4.F3.fig1.3.1" class="ltx_text ltx_font_typewriter">Codellama-7b</span>.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Analysis of tool usage in the <span id="S4.F3.6.1" class="ltx_text ltx_font_smallcaps">TART</span> framework. Panel (a) shows the distribution and the categories of the top-20 tools across models. Panel (b) shows the top-10 tools in <span id="S4.F3.7.2" class="ltx_text ltx_font_smallcaps">TART</span> <span id="S4.F3.8.3" class="ltx_text ltx_font_typewriter">Codellama-7b</span>.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Impact of Foundation Models</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To explore the optimal module combinations within the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> framework, we explore various pairings of table formatter and toolmaker modules shown in TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Out-of-Domain Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We find that using <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">Llama-3-8B</span> as the table formatter and <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">DeepSeek-7B</span> as the tool maker achieves the best average execution rate (76.8) and accuracy (68.6). This aligns with our expectations given that <span id="S4.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">Llama-3-8B</span> excels in processing long tables while <span id="S4.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">DeepSeek-7B</span>, with its pre-training on code, demonstrates superior capability in tool creation. Detailed results are shown in TableÂ <a href="#A4.T6" title="Table 6 â€£ Appendix D Different Backbone Combinations â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> in AppendixÂ <a href="#A4" title="Appendix D Different Backbone Combinations â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2409.11724/assets/x5.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="968" height="310" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Case Study of <span id="S4.F4.3.1" class="ltx_text ltx_font_smallcaps">TART</span> comparing with CoT reasoning. Panel (a) illustrates a numerical calculation error in CoT where incorrect arithmetic leads to a wrong answer, and panel (b) demonstrates a table location error where CoT fails to retrieve the correct table values. Both errors can be reduced by <span id="S4.F4.4.2" class="ltx_text ltx_font_smallcaps">TART</span> through tool integration.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2409.11724/assets/x6.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="416" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Tool overlap distribution between in-domain and OOD datasets across different backbone models.</figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2409.11724/assets/x7.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="369" height="189" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison of the number of repeat tools and correct tools across different backbone models.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Analysis of Tool Creation</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We then performed an in-depth analysis of how <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> creates and utilizes tools.</p>
</div>
<section id="S4.SS4.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Tool Distribution.</h4>

<div id="S4.SS4.SSSx1.p1" class="ltx_para">
<p id="S4.SS4.SSSx1.p1.1" class="ltx_p">FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Out-of-Domain Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a) illustrates the tool usage distribution across different backbone models in <span id="S4.SS4.SSSx1.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, highlighting a long-tail distribution. The most frequently used tools are primarily associated with table processing (e.g., <span id="S4.SS4.SSSx1.p1.1.2" class="ltx_text ltx_font_typewriter">get_column_by_name</span>) and numerical reasoning (e.g., <span id="S4.SS4.SSSx1.p1.1.3" class="ltx_text ltx_font_typewriter">add</span>), aligning with our observations in SectionÂ <a href="#S4.SS1" title="4.1 Main Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Out-of-Domain Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b) provides a detailed breakdown of tool categories for the top 30 tools, showing that table preprocessing and numerical reasoning tools are the most prevalent. This supports the consistency of tool utilization patterns within <span id="S4.SS4.SSSx1.p1.1.4" class="ltx_text ltx_font_smallcaps">TART</span>.</p>
</div>
</section>
<section id="S4.SS4.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Tool Overlap on OOD Datasets.</h4>

<div id="S4.SS4.SSSx2.p1" class="ltx_para">
<p id="S4.SS4.SSSx2.p1.1" class="ltx_p">FigureÂ <a href="#S4.F5" title="Figure 5 â€£ 4.3 Impact of Foundation Models â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the tool overlap between in-domain datasets and OOD datasets. We find that code pre-training models (<span id="S4.SS4.SSSx2.p1.1.1" class="ltx_text ltx_font_typewriter">CodeLlama-7b</span> and <span id="S4.SS4.SSSx2.p1.1.2" class="ltx_text ltx_font_typewriter">DeepSeek-7b</span>) exhibit a tendency to reuse existing tools when adapting to OOD data. However, text pre-training models demonstrate less overlap, indicating that they tend to solve problems by crafting new tools. The tendency to reuse tools might explain why code pre-training models gain better generalization capabilities in unfamiliar data.</p>
</div>
</section>
<section id="S4.SS4.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Tool Creation and Usage Analysis.</h4>

<div id="S4.SS4.SSSx3.p1" class="ltx_para">
<p id="S4.SS4.SSSx3.p1.1" class="ltx_p">FigureÂ <a href="#S4.F6" title="Figure 6 â€£ 4.3 Impact of Foundation Models â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> further reveals that although <span id="S4.SS4.SSSx3.p1.1.1" class="ltx_text ltx_font_typewriter">Llama2-7b</span> frequently reuses tools, it often applies them inappropriately. In contrast, <span id="S4.SS4.SSSx3.p1.1.2" class="ltx_text ltx_font_italic">CodeLlama-7b</span> not only exhibits a high rate of tool reuse, but also demonstrates a greater accuracy in their appropriate application. Meanwhile, <span id="S4.SS4.SSSx3.p1.1.3" class="ltx_text ltx_font_typewriter">Llama3-8b</span>, despite its lower rate of tool reuse, excels in the correct usage of tools, which contributes to its superior performance.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Case Study</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">To gain deeper insights into the advantages of <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> over CoT reasoning, we conducted a case study, shown in FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.3 Impact of Foundation Models â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The examples highlight the limitation of CoT in numerical reasoning and table preprocessing, such as incorrect calculation (FigureÂ <a href="#S4.SS5" title="4.5 Case Study â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a> a) and incorrect retrieval (FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.3 Impact of Foundation Models â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> b). Conversely, <span id="S4.SS5.p1.1.2" class="ltx_text ltx_font_smallcaps">TART</span> overcomes these challenges effectively via integrating specialized tools like <span id="S4.SS5.p1.1.3" class="ltx_text ltx_font_typewriter">subtract</span> and <span id="S4.SS5.p1.1.4" class="ltx_text ltx_font_typewriter">get_column_by_index</span>. Despite these strengths, <span id="S4.SS5.p1.1.5" class="ltx_text ltx_font_smallcaps">TART</span> still encounters issues related to data type mismatches and incorrect programming plans. A detailed analysis of error types in <span id="S4.SS5.p1.1.6" class="ltx_text ltx_font_smallcaps">TART</span> can be found in AppendixÂ <a href="#A6" title="Appendix F Error Analysis â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we introduce an open-source framework to improve table-based reasoning through the <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">Tool-Augmented Reasoning framework for Tables (<span id="S5.p1.1.1.1" class="ltx_text ltx_font_smallcaps">TART</span>)</span>. This framework solves the challenges of current LLMsâ€™ limited ability to understand table structure and execute precise numerical calculations, and maintains explainability. <span id="S5.p1.1.2" class="ltx_text ltx_font_smallcaps">TART</span> consists of a <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">table formatter</span> for accurate data representation, a <span id="S5.p1.1.4" class="ltx_text ltx_font_italic">tool maker</span> for creating specialized tools, and an <span id="S5.p1.1.5" class="ltx_text ltx_font_italic">explanation generator</span> maintaining interpretable explanations. To train <span id="S5.p1.1.6" class="ltx_text ltx_font_smallcaps">TART</span>, we present the <span id="S5.p1.1.7" class="ltx_text ltx_font_smallcaps">ToolTab</span> dataset, a novel benchmark containing a diverse set of real-world tables and their tool-augmented solutions. Experiments across nine benchmarks show that integrating our <span id="S5.p1.1.8" class="ltx_text ltx_font_smallcaps">TART</span> method into different open-sourced LLMs enhances accuracy on table-based reasoning. Furthermore, in-depth analyses reveal that <span id="S5.p1.1.9" class="ltx_text ltx_font_smallcaps">TART</span> effectively learns and uses tools. Future work could extend <span id="S5.p1.1.10" class="ltx_text ltx_font_smallcaps">TART</span> to a multimodal framework by incorporating image-based question-answering and fact-verification to generate richer explanations. Additionally, generating explanations to satisfy the needs of different end users, such as laypersons and experts, could further improve the <span id="S5.p1.1.11" class="ltx_text ltx_font_smallcaps">TART</span>â€™s applicability and impact.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akhtar, Cocarascu, and Simperl (2022)</span>
<span class="ltx_bibblock">
Akhtar, M.; Cocarascu, O.; and Simperl, E. 2022.

</span>
<span class="ltx_bibblock">PubHealthTab: A Public Health Table-based Dataset for Evidence-based Fact Checking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Findings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</em>, 1â€“16. Seattle, United States.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badaro, Saeed, and Papotti (2023)</span>
<span class="ltx_bibblock">
Badaro, G.; Saeed, M.; and Papotti, P. 2023.

</span>
<span class="ltx_bibblock">Transformers for Tabular Data Representation: A Survey of Models and Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Transactions of Association Computational Linguistics (TACL)</em>, 11: 227â€“249.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai etÂ al. (2024)</span>
<span class="ltx_bibblock">
Cai, T.; Wang, X.; Ma, T.; Chen, X.; and Zhou, D. 2024.

</span>
<span class="ltx_bibblock">Large Language Models as Tool Makers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of The Twelfth International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2023)</span>
<span class="ltx_bibblock">
Chen, W. 2023.

</span>
<span class="ltx_bibblock">Large Language Models are few(1)-shot Table Reasoners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Findings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</em>, 1090â€“1100.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chen, W.; Ma, X.; Wang, X.; and Cohen, W.Â W. 2023.

</span>
<span class="ltx_bibblock">Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Trans. Mach. Learn. Res.</em>, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2020a)</span>
<span class="ltx_bibblock">
Chen, W.; Wang, H.; Chen, J.; Zhang, Y.; Wang, H.; Li, S.; Zhou, X.; and Wang, W.Â Y. 2020a.

</span>
<span class="ltx_bibblock">TabFact: A Large-scale Dataset for Table-based Fact Verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 8th International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2020b)</span>
<span class="ltx_bibblock">
Chen, W.; Zha, H.; Chen, Z.; Xiong, W.; Wang, H.; and Wang, W.Â Y. 2020b.

</span>
<span class="ltx_bibblock">HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Findings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 1026â€“1036.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Chen, Z.; Chen, W.; Smiley, C.; Shah, S.; Borova, I.; Langdon, D.; Moussa, R.; Beane, M.; Huang, T.; Routledge, B.Â R.; and Wang, W.Â Y. 2021.

</span>
<span class="ltx_bibblock">FinQA: A Dataset of Numerical Reasoning over Financial Data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 3697â€“3711.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng etÂ al. (2022)</span>
<span class="ltx_bibblock">
Cheng, Z.; Dong, H.; Wang, Z.; Jia, R.; Guo, J.; Gao, Y.; Han, S.; Lou, J.; and Zhang, D. 2022.

</span>
<span class="ltx_bibblock">HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 1094â€“1110.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung etÂ al. (2022)</span>
<span class="ltx_bibblock">
Chung, H.Â W.; Hou, L.; Longpre, S.; Zoph, B.; Tay, Y.; Fedus, W.; Li, E.; Wang, X.; Dehghani, M.; Brahma, S.; Webson, A.; Gu, S.Â S.; Dai, Z.; Suzgun, M.; Chen, X.; Chowdhery, A.; Narang, S.; Mishra, G.; Yu, A.; Zhao, V.Â Y.; Huang, Y.; Dai, A.Â M.; Yu, H.; Petrov, S.; Chi, E.Â H.; Dean, J.; Devlin, J.; Roberts, A.; Zhou, D.; Le, Q.Â V.; and Wei, J. 2022.

</span>
<span class="ltx_bibblock">Scaling Instruction-Finetuned Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2210.11416.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. (2022)</span>
<span class="ltx_bibblock">
Dong, H.; Cheng, Z.; He, X.; Zhou, M.; Zhou, A.; Zhou, F.; Liu, A.; Han, S.; and Zhang, D. 2022.

</span>
<span class="ltx_bibblock">Table Pre-training: A Survey on Model Architectures, Pre-training Objectives, and Downstream Tasks.

</span>
<span class="ltx_bibblock">In Raedt, L.Â D., ed., <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022</em>, 5426â€“5435.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Gao, L.; Madaan, A.; Zhou, S.; Alon, U.; Liu, P.; Yang, Y.; Callan, J.; and Neubig, G. 2023.

</span>
<span class="ltx_bibblock">PAL: Program-aided Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Machine Learning (ICML)</em>, volume 202, 10764â€“10799.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gu, Z.; Fan, J.; Tang, N.; Nakov, P.; Zhao, X.; and Du, X. 2022.

</span>
<span class="ltx_bibblock">PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 4971â€“4983.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo etÂ al. (2024)</span>
<span class="ltx_bibblock">
Guo, D.; Zhu, Q.; Yang, D.; Xie, Z.; Dong, K.; Zhang, W.; Chen, G.; Bi, X.; Wu, Y.; Li, Y.Â K.; Luo, F.; Xiong, Y.; and Liang, W. 2024.

</span>
<span class="ltx_bibblock">DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2401.14196.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig etÂ al. (2020)</span>
<span class="ltx_bibblock">
Herzig, J.; Nowak, P.Â K.; MÃ¼ller, T.; Piccinno, F.; and Eisenschlos, J.Â M. 2020.

</span>
<span class="ltx_bibblock">TaPas: Weakly Supervised Table Parsing via Pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 4320â€“4333.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin and Lu (2023)</span>
<span class="ltx_bibblock">
Jin, Z.; and Lu, W. 2023.

</span>
<span class="ltx_bibblock">Tab-CoT: Zero-shot Tabular Chain of Thought.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, 10259â€“10277.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2024)</span>
<span class="ltx_bibblock">
Kim, J.; Paranjape, B.; Khot, T.; and Hajishirzi, H. 2024.

</span>
<span class="ltx_bibblock">Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2406.06469.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Liu, Q.; Chen, B.; Guo, J.; Ziyadi, M.; Lin, Z.; Chen, W.; and Lou, J. 2022.

</span>
<span class="ltx_bibblock">TAPEX: Table Pre-training via Learning a Neural SQL Executor.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu, Wang, and Chen (2023)</span>
<span class="ltx_bibblock">
Liu, T.; Wang, F.; and Chen, M. 2023.

</span>
<span class="ltx_bibblock">Rethinking Tabular Data Understanding with Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.16702.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Lu, P.; Peng, B.; Cheng, H.; Galley, M.; Chang, K.; Wu, Y.Â N.; Zhu, S.; and Gao, J. 2023a.

</span>
<span class="ltx_bibblock">Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS)</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Lu, P.; Qiu, L.; Chang, K.; Wu, Y.Â N.; Zhu, S.; Rajpurohit, T.; Clark, P.; and Kalyan, A. 2023b.

</span>
<span class="ltx_bibblock">Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2023c)</span>
<span class="ltx_bibblock">
Lu, X.; Pan, L.; Liu, Q.; Nakov, P.; and Kan, M. 2023c.

</span>
<span class="ltx_bibblock">SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, 7787â€“7813.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ma, Y.; Gou, Z.; Hao, J.; Xu, R.; Wang, S.; Pan, L.; Yang, Y.; Cao, Y.; Sun, A.; Awadalla, H.Â H.; and Chen, W. 2024.

</span>
<span class="ltx_bibblock">SciAgent: Tool-augmented Language Models for Scientific Reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2402.11451.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra etÂ al. (2022)</span>
<span class="ltx_bibblock">
Mishra, S.; Khashabi, D.; Baral, C.; and Hajishirzi, H. 2022.

</span>
<span class="ltx_bibblock">Cross-Task Generalization via Natural Language Crowdsourcing Instructions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, 3470â€“3487.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nan etÂ al. (2022)</span>
<span class="ltx_bibblock">
Nan, L.; Hsieh, C.; Mao, Z.; Lin, X.Â V.; Verma, N.; Zhang, R.; Kryscinski, W.; Schoelkopf, H.; Kong, R.; Tang, X.; Mutuma, M.; Rosand, B.; Trindade, I.; Bandaru, R.; Cunningham, J.; Xiong, C.; and Radev, D.Â R. 2022.

</span>
<span class="ltx_bibblock">FeTaQA: Free-form Table Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics (TACL)</em>, 10: 35â€“49.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan etÂ al. (2023)</span>
<span class="ltx_bibblock">
Pan, L.; Wu, X.; Lu, X.; Luu, A.Â T.; Wang, W.Â Y.; Kan, M.; and Nakov, P. 2023.

</span>
<span class="ltx_bibblock">Fact-Checking Complex Claims with Program-Guided Reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, 6981â€“7004.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Pasupat, P.; and Liang, P. 2015.

</span>
<span class="ltx_bibblock">Compositional Semantic Parsing on Semi-Structured Tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP)</em>, 1470â€“1480.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin etÂ al. (2024)</span>
<span class="ltx_bibblock">
Qin, Y.; Liang, S.; Ye, Y.; Zhu, K.; Yan, L.; Lu, Y.; Lin, Y.; Cong, X.; Tang, X.; Qian, B.; Zhao, S.; Hong, L.; Tian, R.; Xie, R.; Zhou, J.; Gerstein, M.; Li, D.; Liu, Z.; and Sun, M. 2024.

</span>
<span class="ltx_bibblock">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">RoziÃ¨re etÂ al. (2023)</span>
<span class="ltx_bibblock">
RoziÃ¨re, B.; Gehring, J.; Gloeckle, F.; Sootla, S.; Gat, I.; Tan, X.Â E.; Adi, Y.; Liu, J.; Remez, T.; Rapin, J.; Kozhevnikov, A.; Evtimov, I.; Bitton, J.; Bhatt, M.; Canton-Ferrer, C.; Grattafiori, A.; Xiong, W.; DÃ©fossez, A.; Copet, J.; Azhar, F.; Touvron, H.; Martin, L.; Usunier, N.; Scialom, T.; and Synnaeve, G. 2023.

</span>
<span class="ltx_bibblock">Code Llama: Open Foundation Models for Code.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.12950.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick etÂ al. (2023)</span>
<span class="ltx_bibblock">
Schick, T.; Dwivedi-Yu, J.; DessÃ¬, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Cancedda, N.; and Scialom, T. 2023.

</span>
<span class="ltx_bibblock">Toolformer: Language Models Can Teach Themselves to Use Tools.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.04761.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.; Blecher, L.; Canton-Ferrer, C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.; Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini, S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev, A.; Koura, P.Â S.; Lachaux, M.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.; Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E.Â M.; Subramanian, R.; Tan, X.Â E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J.Â X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.; Rodriguez, A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wang, N. X.Â R.; Mahajan, D.; Danilevsky, M.; and Rosenthal, S. 2021.

</span>
<span class="ltx_bibblock">SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS).

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021</em>, 317â€“326.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wang, Y.; Kordi, Y.; Mishra, S.; Liu, A.; Smith, N.Â A.; Khashabi, D.; and Hajishirzi, H. 2023.

</span>
<span class="ltx_bibblock">Self-Instruct: Aligning Language Models with Self-Generated Instructions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 13484â€“13508.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Wang, Z.; Cheng, Z.; Zhu, H.; Fried, D.; and Neubig, G. 2024a.

</span>
<span class="ltx_bibblock">What Are Tools Anyway? A Survey from the Language Model Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2403.15452.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Wang, Z.; Cheng, Z.; Zhu, H.; Fried, D.; and Neubig, G. 2024b.

</span>
<span class="ltx_bibblock">What Are Tools Anyway? A Survey from the Language Model Perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2403.15452.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2024c)</span>
<span class="ltx_bibblock">
Wang, Z.; Zhang, H.; Li, C.; Eisenschlos, J.Â M.; Perot, V.; Wang, Z.; Miculicich, L.; Fujii, Y.; Shang, J.; Lee, C.; and Pfister, T. 2024c.

</span>
<span class="ltx_bibblock">Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2022)</span>
<span class="ltx_bibblock">
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.; Xia, F.; Chi, E.Â H.; Le, Q.Â V.; and Zhou, D. 2022.

</span>
<span class="ltx_bibblock">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS)</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">West etÂ al. (2022)</span>
<span class="ltx_bibblock">
West, P.; Bhagavatula, C.; Hessel, J.; Hwang, J.Â D.; Jiang, L.; Bras, R.Â L.; Lu, X.; Welleck, S.; and Choi, Y. 2022.

</span>
<span class="ltx_bibblock">Symbolic Knowledge Distillation: from General Language Models to Commonsense Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</em>, 4602â€“4625.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Feng (2024)</span>
<span class="ltx_bibblock">
Wu, Z.; and Feng, Y. 2024.

</span>
<span class="ltx_bibblock">ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2403.02177.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yang, X.; Nie, F.; Feng, Y.; Liu, Q.; Chen, Z.; and Zhu, X. 2020.

</span>
<span class="ltx_bibblock">Program Enhanced Fact Verification with Verbalization and Graph Attention Network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 7810â€“7825.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. (2023)</span>
<span class="ltx_bibblock">
Ye, Y.; Hui, B.; Yang, M.; Li, B.; Huang, F.; and Li, Y. 2023.

</span>
<span class="ltx_bibblock">Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 46th International ACM Conference on Research and Development in Information Retrieval (SIGIR)</em>, 174â€“184.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. (2015)</span>
<span class="ltx_bibblock">
Yin, P.; Lu, Z.; Li, H.; and Kao, B. 2015.

</span>
<span class="ltx_bibblock">Neural Enquirer: Learning to Query Tables with Natural Language.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1512.00965.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2018)</span>
<span class="ltx_bibblock">
Yu, T.; Zhang, R.; Yang, K.; Yasunaga, M.; Wang, D.; Li, Z.; Ma, J.; Li, I.; Yao, Q.; Roman, S.; Zhang, Z.; and Radev, D. 2018.

</span>
<span class="ltx_bibblock">Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 3911â€“3921.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Zhang, T.; Yue, X.; Li, Y.; and Sun, H. 2023a.

</span>
<span class="ltx_bibblock">TableLlama: Towards Open Large Generalist Models for Tables.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.09206.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Zhang, Y.; Henkel, J.; Floratou, A.; Cahoon, J.; Deep, S.; and Patel, J.Â M. 2023b.

</span>
<span class="ltx_bibblock">ReAcTable: Enhancing ReAct for Table Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.00815.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong etÂ al. (2020)</span>
<span class="ltx_bibblock">
Zhong, W.; Tang, D.; Feng, Z.; Duan, N.; Zhou, M.; Gong, M.; Shou, L.; Jiang, D.; Wang, J.; and Yin, J. 2020.

</span>
<span class="ltx_bibblock">LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 6053â€“6065.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2022)</span>
<span class="ltx_bibblock">
Zhou, Y.; Liu, X.; Zhou, K.; and Wu, J. 2022.

</span>
<span class="ltx_bibblock">Table-based Fact Verification with Self-adaptive Mixture of Experts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Findings of the 60th Association for Computational Linguistics (ACL)</em>, 139â€“149.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Zhu, F.; Lei, W.; Huang, Y.; Wang, C.; Zhang, S.; Lv, J.; Feng, F.; and Chua, T. 2021.

</span>
<span class="ltx_bibblock">TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</em>, 3277â€“3287.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zhuang, A.; Zhang, G.; Zheng, T.; Du, X.; Wang, J.; Ren, W.; Huang, S.Â W.; Fu, J.; Yue, X.; and Chen, W. 2024.

</span>
<span class="ltx_bibblock">StructLM: Towards Building Generalist Models for Structured Knowledge Grounding.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2402.16671.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Ethic Statement</h2>

<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Transparency and Integrity.</h5>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p1.1" class="ltx_p">We ensure that all methodologies, data sources, and technologies used in this study are disclosed transparently. We aim to provide a comprehensive and honest account of our findings, acknowledging both the capabilities and limitations of our proposed solution.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Privacy and Security.</h5>

<div id="A1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px2.p1.1" class="ltx_p">Our research utilizes datasets that are either publicly available or collected with explicit consent. We adhere to strict data privacy and security protocols to protect the information and ensure it is used solely for the purposes of this research.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Limitation</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">Despite the promising results, our proposed framework has certain limitations that warrant further investigation:</p>
</div>
<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Computational Complexity.</h5>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px1.p1.1" class="ltx_p">The <span id="A2.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> model may affect efficacy, especially when handling simple questions in quick-response scenarios.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset Coverage.</h5>

<div id="A2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px2.p1.1" class="ltx_p">While our efforts have focused on expanding the range of our dataset to include a variety of tableQA datasets, some table-related datasets remain unrepresented in <span id="A2.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">ToolTab</span>. As a result, despite <span id="A2.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_smallcaps">TART</span>â€™s capacity to adapt to different OOD datasets and tasks, its performance might still different with the complexities and unique challenges of new table tasks and datasets that it has not yet encountered. Having initiated the development of an expansive, versatile tool-enhanced model for tables, we encourage for continued research in this area to further advance the modelâ€™s ability to generalize across diverse table configurations.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Dataset Composition for <span id="A3.1.1" class="ltx_text ltx_font_smallcaps">TART</span> Training</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.3" class="ltx_p">In TableÂ <a href="#A3.T4" title="Table 4 â€£ Appendix C Dataset Composition for TART Training â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we show the composition of the seed datasets utilized for training our <span id="A3.p1.3.1" class="ltx_text ltx_font_smallcaps">TART</span> model. These datasets vary in terms of the tasks, the domains, and the types of input and output data. For instance, TabMWP and FinQA focus on TableQA tasks within mathematics and finance domains respectively, requiring a combination of tables, text, and questions as inputs, with short answers as outputs. Meanwhile, PubHealthTab, TabFact, and SCITAB target table fact-checking tasks across health, general Wikipedia, and scientific article domains. These datasets similarly involve tables and claims as inputs but differ in the specifics of the domain-related claims, each producing a short label as an output. To construct the <span id="A3.p1.3.2" class="ltx_text ltx_font_smallcaps">ToolTab</span>, we obtain 11,701, 9,916, and 9,916 training instances for the table formatter <math id="A3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="A3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><ci id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\mathcal{F}</annotation></semantics></math>, tool maker <math id="A3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="A3.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><ci id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">\mathcal{M}</annotation></semantics></math>, and explanation generator <math id="A3.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="A3.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b"><ci id="A3.p1.3.m3.1.1.cmml" xref="A3.p1.3.m3.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">\mathcal{E}</annotation></semantics></math>, respectively. The detailed statistics is provided in TableÂ <a href="#A3.T5" title="Table 5 â€£ Appendix C Dataset Composition for TART Training â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="A3.T4" class="ltx_table">
<div id="A3.T4.1" class="ltx_inline-block ltx_transformed_outer" style="width:505.9pt;height:116pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(17.5pt,-4.0pt) scale(1.07451838873483,1.07451838873483) ;">
<table id="A3.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T4.1.1.1.1" class="ltx_tr">
<th id="A3.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A3.T4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="A3.T4.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A3.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Task</span></th>
<th id="A3.T4.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A3.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Domain</span></th>
<th id="A3.T4.1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A3.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Input</span></th>
<th id="A3.T4.1.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A3.T4.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Output</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T4.1.1.2.1" class="ltx_tr">
<td id="A3.T4.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">1. TabMWP</td>
<td id="A3.T4.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">TableQA</td>
<td id="A3.T4.1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Maths</td>
<td id="A3.T4.1.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">Table, Question</td>
<td id="A3.T4.1.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">Answer (Short)</td>
</tr>
<tr id="A3.T4.1.1.3.2" class="ltx_tr">
<td id="A3.T4.1.1.3.2.1" class="ltx_td ltx_align_left">2. FinQA</td>
<td id="A3.T4.1.1.3.2.2" class="ltx_td ltx_align_left">TableQA</td>
<td id="A3.T4.1.1.3.2.3" class="ltx_td ltx_align_left">Finance</td>
<td id="A3.T4.1.1.3.2.4" class="ltx_td ltx_align_left">Table, Text, Question</td>
<td id="A3.T4.1.1.3.2.5" class="ltx_td ltx_align_left">Answer (Short)</td>
</tr>
<tr id="A3.T4.1.1.4.3" class="ltx_tr">
<td id="A3.T4.1.1.4.3.1" class="ltx_td ltx_align_left">3. PubHealthTab</td>
<td id="A3.T4.1.1.4.3.2" class="ltx_td ltx_align_left">Table Fact Checking</td>
<td id="A3.T4.1.1.4.3.3" class="ltx_td ltx_align_left">Health</td>
<td id="A3.T4.1.1.4.3.4" class="ltx_td ltx_align_left">Table, Claim</td>
<td id="A3.T4.1.1.4.3.5" class="ltx_td ltx_align_left">Label (Short)</td>
</tr>
<tr id="A3.T4.1.1.5.4" class="ltx_tr">
<td id="A3.T4.1.1.5.4.1" class="ltx_td ltx_align_left">4. TabFact</td>
<td id="A3.T4.1.1.5.4.2" class="ltx_td ltx_align_left">Table Fact Checking</td>
<td id="A3.T4.1.1.5.4.3" class="ltx_td ltx_align_left">Wikipedia</td>
<td id="A3.T4.1.1.5.4.4" class="ltx_td ltx_align_left">Table, Claim</td>
<td id="A3.T4.1.1.5.4.5" class="ltx_td ltx_align_left">Label (Short)</td>
</tr>
<tr id="A3.T4.1.1.6.5" class="ltx_tr">
<td id="A3.T4.1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_bb">5. SCITAB</td>
<td id="A3.T4.1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_bb">Table Fact Checking</td>
<td id="A3.T4.1.1.6.5.3" class="ltx_td ltx_align_left ltx_border_bb">Scientific Articles</td>
<td id="A3.T4.1.1.6.5.4" class="ltx_td ltx_align_left ltx_border_bb">Table, Claim</td>
<td id="A3.T4.1.1.6.5.5" class="ltx_td ltx_align_left ltx_border_bb">Label (Short)</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Statistics of the seed datasets for <span id="A3.T4.3.1" class="ltx_text ltx_font_smallcaps">TART</span> training, highlighting their respective tasks, domains, and the nature of input and output data.</figcaption>
</figure>
<figure id="A3.T5" class="ltx_table">
<div id="A3.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:163.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(30.3pt,-9.8pt) scale(1.13594303003985,1.13594303003985) ;">
<table id="A3.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T5.1.1.1.1" class="ltx_tr">
<td id="A3.T5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Dataset</td>
<td id="A3.T5.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt">Train</td>
<td id="A3.T5.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt">Dev</td>
<td id="A3.T5.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_tt">Generated</td>
<td id="A3.T5.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_tt">Executable</td>
<td id="A3.T5.1.1.1.1.6" class="ltx_td ltx_align_left ltx_border_tt">Table</td>
<td id="A3.T5.1.1.1.1.7" class="ltx_td ltx_align_left ltx_border_tt">Tool</td>
<td id="A3.T5.1.1.1.1.8" class="ltx_td ltx_align_left ltx_border_tt">Explanation</td>
</tr>
<tr id="A3.T5.1.1.2.2" class="ltx_tr">
<td id="A3.T5.1.1.2.2.1" class="ltx_td"></td>
<td id="A3.T5.1.1.2.2.2" class="ltx_td"></td>
<td id="A3.T5.1.1.2.2.3" class="ltx_td"></td>
<td id="A3.T5.1.1.2.2.4" class="ltx_td ltx_align_left">Sample</td>
<td id="A3.T5.1.1.2.2.5" class="ltx_td ltx_align_left">Sample</td>
<td id="A3.T5.1.1.2.2.6" class="ltx_td ltx_align_left">Formatter</td>
<td id="A3.T5.1.1.2.2.7" class="ltx_td ltx_align_left">Maker</td>
<td id="A3.T5.1.1.2.2.8" class="ltx_td ltx_align_left">Generator</td>
</tr>
<tr id="A3.T5.1.1.3.3" class="ltx_tr">
<td id="A3.T5.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">TabMWP</td>
<td id="A3.T5.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">23,059</td>
<td id="A3.T5.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">7,686</td>
<td id="A3.T5.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">6,000</td>
<td id="A3.T5.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_t">5,835</td>
<td id="A3.T5.1.1.3.3.6" class="ltx_td ltx_align_left ltx_border_t">6,000</td>
<td id="A3.T5.1.1.3.3.7" class="ltx_td ltx_align_left ltx_border_t">5,713</td>
<td id="A3.T5.1.1.3.3.8" class="ltx_td ltx_align_left ltx_border_t">5,713</td>
</tr>
<tr id="A3.T5.1.1.4.4" class="ltx_tr">
<td id="A3.T5.1.1.4.4.1" class="ltx_td ltx_align_left">FinQA</td>
<td id="A3.T5.1.1.4.4.2" class="ltx_td ltx_align_left">6,251</td>
<td id="A3.T5.1.1.4.4.3" class="ltx_td ltx_align_left">883</td>
<td id="A3.T5.1.1.4.4.4" class="ltx_td ltx_align_left">1,984</td>
<td id="A3.T5.1.1.4.4.5" class="ltx_td ltx_align_left">1,609</td>
<td id="A3.T5.1.1.4.4.6" class="ltx_td ltx_align_left">1,967</td>
<td id="A3.T5.1.1.4.4.7" class="ltx_td ltx_align_left">1,148</td>
<td id="A3.T5.1.1.4.4.8" class="ltx_td ltx_align_left">1,148</td>
</tr>
<tr id="A3.T5.1.1.5.5" class="ltx_tr">
<td id="A3.T5.1.1.5.5.1" class="ltx_td ltx_align_left">TabFact</td>
<td id="A3.T5.1.1.5.5.2" class="ltx_td ltx_align_left">92,283</td>
<td id="A3.T5.1.1.5.5.3" class="ltx_td ltx_align_left">12,792</td>
<td id="A3.T5.1.1.5.5.4" class="ltx_td ltx_align_left">1,866</td>
<td id="A3.T5.1.1.5.5.5" class="ltx_td ltx_align_left">1,773</td>
<td id="A3.T5.1.1.5.5.6" class="ltx_td ltx_align_left">1,866</td>
<td id="A3.T5.1.1.5.5.7" class="ltx_td ltx_align_left">1,701</td>
<td id="A3.T5.1.1.5.5.8" class="ltx_td ltx_align_left">1,705</td>
</tr>
<tr id="A3.T5.1.1.6.6" class="ltx_tr">
<td id="A3.T5.1.1.6.6.1" class="ltx_td ltx_align_left">PubHealthTab</td>
<td id="A3.T5.1.1.6.6.2" class="ltx_td ltx_align_left">1,180</td>
<td id="A3.T5.1.1.6.6.3" class="ltx_td ltx_align_left">152</td>
<td id="A3.T5.1.1.6.6.4" class="ltx_td ltx_align_left">1,180</td>
<td id="A3.T5.1.1.6.6.5" class="ltx_td ltx_align_left">1,075</td>
<td id="A3.T5.1.1.6.6.6" class="ltx_td ltx_align_left">1,180</td>
<td id="A3.T5.1.1.6.6.7" class="ltx_td ltx_align_left">958</td>
<td id="A3.T5.1.1.6.6.8" class="ltx_td ltx_align_left">958</td>
</tr>
<tr id="A3.T5.1.1.7.7" class="ltx_tr">
<td id="A3.T5.1.1.7.7.1" class="ltx_td ltx_align_left">SciTab</td>
<td id="A3.T5.1.1.7.7.2" class="ltx_td ltx_align_left">690</td>
<td id="A3.T5.1.1.7.7.3" class="ltx_td ltx_align_left">-</td>
<td id="A3.T5.1.1.7.7.4" class="ltx_td ltx_align_left">690</td>
<td id="A3.T5.1.1.7.7.5" class="ltx_td ltx_align_left">625</td>
<td id="A3.T5.1.1.7.7.6" class="ltx_td ltx_align_left">688</td>
<td id="A3.T5.1.1.7.7.7" class="ltx_td ltx_align_left">396</td>
<td id="A3.T5.1.1.7.7.8" class="ltx_td ltx_align_left">396</td>
</tr>
<tr id="A3.T5.1.1.8.8" class="ltx_tr">
<td id="A3.T5.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_bb">Total</td>
<td id="A3.T5.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_bb">123,463</td>
<td id="A3.T5.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_bb">21,513</td>
<td id="A3.T5.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_bb">5,720</td>
<td id="A3.T5.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_bb">10,917</td>
<td id="A3.T5.1.1.8.8.6" class="ltx_td ltx_align_left ltx_border_bb">11,701</td>
<td id="A3.T5.1.1.8.8.7" class="ltx_td ltx_align_left ltx_border_bb">9,916</td>
<td id="A3.T5.1.1.8.8.8" class="ltx_td ltx_align_left ltx_border_bb">9,916</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Statistics in dataset <span id="A3.T5.4.1" class="ltx_text ltx_font_smallcaps">ToolTab</span> for training <span id="A3.T5.5.2" class="ltx_text ltx_font_smallcaps">TART</span> model. </figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Different Backbone Combinations</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In the pursuit of identifying optimal module combinations within the <span id="A4.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> framework, we explore various pairings of table formatter and toolmaker modules shown in TableÂ <a href="#A4.T6" title="Table 6 â€£ Appendix D Different Backbone Combinations â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The combination of <span id="A4.p1.1.2" class="ltx_text ltx_font_typewriter">Llama-3-8B</span> as the table formatter and <span id="A4.p1.1.3" class="ltx_text ltx_font_typewriter">DeepSeek-7B</span> as the tool maker performs the most effective pairing, having the best average execution rate and accuracy (76.8 and 68.6 respectively). This best combination aligns with our expectations given that <span id="A4.p1.1.4" class="ltx_text ltx_font_typewriter">Llama-3-8B</span> excels in processing long tables while <span id="A4.p1.1.5" class="ltx_text ltx_font_typewriter">DeepSeek-7B</span>, with its pre-training on code, demonstrates superior capability in tool creation.</p>
</div>
<figure id="A4.T6" class="ltx_table">
<div id="A4.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:329.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(4.5pt,-2.9pt) scale(1.01805613715241,1.01805613715241) ;">
<table id="A4.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T6.1.1.1.1" class="ltx_tr">
<th id="A4.T6.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2"><span id="A4.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Module Name</span></th>
<th id="A4.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="A4.T6.1.1.1.1.2.1" class="ltx_text ltx_font_bold">TableFV</span></th>
<th id="A4.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A4.T6.1.1.1.1.3.1" class="ltx_text ltx_font_bold">TableQA</span></th>
<th id="A4.T6.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Avg.</th>
</tr>
<tr id="A4.T6.1.1.2.2" class="ltx_tr">
<th id="A4.T6.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Table Formatter</th>
<th id="A4.T6.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Tool Maker</th>
<th id="A4.T6.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">TabFact</th>
<th id="A4.T6.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">PubHealthTab</th>
<th id="A4.T6.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">SCITAB</th>
<th id="A4.T6.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">TabMWP</th>
<th id="A4.T6.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">FinQA</th>
<th id="A4.T6.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">Exe./Acc.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T6.1.1.3.1" class="ltx_tr">
<th id="A4.T6.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Llama-2</th>
<td id="A4.T6.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">Llama-2</td>
<td id="A4.T6.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">64.9/79.5</td>
<td id="A4.T6.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">65.8/59.2</td>
<td id="A4.T6.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">55.1/60.2</td>
<td id="A4.T6.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">90.4/91.8</td>
<td id="A4.T6.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">65.4/26.0</td>
<td id="A4.T6.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">68.3/63.3</td>
</tr>
<tr id="A4.T6.1.1.4.2" class="ltx_tr">
<th id="A4.T6.1.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-2</th>
<td id="A4.T6.1.1.4.2.2" class="ltx_td ltx_align_center">Llama-3</td>
<td id="A4.T6.1.1.4.2.3" class="ltx_td ltx_align_center">70.7/75.9</td>
<td id="A4.T6.1.1.4.2.4" class="ltx_td ltx_align_center">73.2/65.1</td>
<td id="A4.T6.1.1.4.2.5" class="ltx_td ltx_align_center">64.0/46.5</td>
<td id="A4.T6.1.1.4.2.6" class="ltx_td ltx_align_center">91.0/93.6</td>
<td id="A4.T6.1.1.4.2.7" class="ltx_td ltx_align_center">60.6/37.7</td>
<td id="A4.T6.1.1.4.2.8" class="ltx_td ltx_align_center">71.9/63.8</td>
</tr>
<tr id="A4.T6.1.1.5.3" class="ltx_tr">
<th id="A4.T6.1.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-2</th>
<td id="A4.T6.1.1.5.3.2" class="ltx_td ltx_align_center">Codellama</td>
<td id="A4.T6.1.1.5.3.3" class="ltx_td ltx_align_center">70.2/76.5</td>
<td id="A4.T6.1.1.5.3.4" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.5.3.4.1" class="ltx_text ltx_framed ltx_framed_underline">73.8/74.5</span></td>
<td id="A4.T6.1.1.5.3.5" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.5.3.5.1" class="ltx_text ltx_font_bold">64.6/56.5</span></td>
<td id="A4.T6.1.1.5.3.6" class="ltx_td ltx_align_center">94.7/88.8</td>
<td id="A4.T6.1.1.5.3.7" class="ltx_td ltx_align_center">71.8/34.1</td>
<td id="A4.T6.1.1.5.3.8" class="ltx_td ltx_align_center">75.0/66.1</td>
</tr>
<tr id="A4.T6.1.1.6.4" class="ltx_tr">
<th id="A4.T6.1.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-2</th>
<td id="A4.T6.1.1.6.4.2" class="ltx_td ltx_align_center">Deepseek</td>
<td id="A4.T6.1.1.6.4.3" class="ltx_td ltx_align_center">71.8/78.5</td>
<td id="A4.T6.1.1.6.4.4" class="ltx_td ltx_align_center">75.8/66.4</td>
<td id="A4.T6.1.1.6.4.5" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.6.4.5.1" class="ltx_text ltx_framed ltx_framed_underline">64.0/57.0</span></td>
<td id="A4.T6.1.1.6.4.6" class="ltx_td ltx_align_center">93.6/92.0</td>
<td id="A4.T6.1.1.6.4.7" class="ltx_td ltx_align_center">73.4/37.7</td>
<td id="A4.T6.1.1.6.4.8" class="ltx_td ltx_align_center">75.7/66.3</td>
</tr>
<tr id="A4.T6.1.1.7.5" class="ltx_tr">
<th id="A4.T6.1.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="A4.T6.1.1.7.5.1.1" class="ltx_ERROR undefined">\hdashline</span>Llama-3</th>
<td id="A4.T6.1.1.7.5.2" class="ltx_td ltx_align_center">Llama-2</td>
<td id="A4.T6.1.1.7.5.3" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.7.5.3.1" class="ltx_text ltx_framed ltx_framed_underline">70.2/81.8</span></td>
<td id="A4.T6.1.1.7.5.4" class="ltx_td ltx_align_center">65.8/60.2</td>
<td id="A4.T6.1.1.7.5.5" class="ltx_td ltx_align_center">53.9/61.5</td>
<td id="A4.T6.1.1.7.5.6" class="ltx_td ltx_align_center">95.7/91.1</td>
<td id="A4.T6.1.1.7.5.7" class="ltx_td ltx_align_center">61.7/31.0</td>
<td id="A4.T6.1.1.7.5.8" class="ltx_td ltx_align_center">69.5/65.1</td>
</tr>
<tr id="A4.T6.1.1.8.6" class="ltx_tr">
<th id="A4.T6.1.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-3</th>
<td id="A4.T6.1.1.8.6.2" class="ltx_td ltx_align_center">Llama-3</td>
<td id="A4.T6.1.1.8.6.3" class="ltx_td ltx_align_center">75.5/75.4</td>
<td id="A4.T6.1.1.8.6.4" class="ltx_td ltx_align_center">71.1/69.8</td>
<td id="A4.T6.1.1.8.6.5" class="ltx_td ltx_align_center">63.5/52.2</td>
<td id="A4.T6.1.1.8.6.6" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.8.6.6.1" class="ltx_text ltx_font_bold">97.9/92.4</span></td>
<td id="A4.T6.1.1.8.6.7" class="ltx_td ltx_align_center">62.2/38.5</td>
<td id="A4.T6.1.1.8.6.8" class="ltx_td ltx_align_center">74.0/65.7</td>
</tr>
<tr id="A4.T6.1.1.9.7" class="ltx_tr">
<th id="A4.T6.1.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-3</th>
<td id="A4.T6.1.1.9.7.2" class="ltx_td ltx_align_center">Codellama</td>
<td id="A4.T6.1.1.9.7.3" class="ltx_td ltx_align_center">75.5/85.2</td>
<td id="A4.T6.1.1.9.7.4" class="ltx_td ltx_align_center">74.5/71.2</td>
<td id="A4.T6.1.1.9.7.5" class="ltx_td ltx_align_center">62.9/57.1</td>
<td id="A4.T6.1.1.9.7.6" class="ltx_td ltx_align_center">95.7/91.7</td>
<td id="A4.T6.1.1.9.7.7" class="ltx_td ltx_align_center">68.1/39.8</td>
<td id="A4.T6.1.1.9.7.8" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.9.7.8.1" class="ltx_text ltx_framed ltx_framed_underline">75.3/69.0</span></td>
</tr>
<tr id="A4.T6.1.1.10.8" class="ltx_tr">
<th id="A4.T6.1.1.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Llama-3</th>
<td id="A4.T6.1.1.10.8.2" class="ltx_td ltx_align_center">Deepseek</td>
<td id="A4.T6.1.1.10.8.3" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.10.8.3.1" class="ltx_text ltx_font_bold">76.6/84.7</span></td>
<td id="A4.T6.1.1.10.8.4" class="ltx_td ltx_align_center">79.2/67.8</td>
<td id="A4.T6.1.1.10.8.5" class="ltx_td ltx_align_center">62.4/55.9</td>
<td id="A4.T6.1.1.10.8.6" class="ltx_td ltx_align_center">94.1/94.4</td>
<td id="A4.T6.1.1.10.8.7" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.10.8.7.1" class="ltx_text ltx_framed ltx_framed_underline">71.8/40.0</span></td>
<td id="A4.T6.1.1.10.8.8" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.10.8.8.1" class="ltx_text ltx_font_bold">76.8/68.6</span></td>
</tr>
<tr id="A4.T6.1.1.11.9" class="ltx_tr">
<th id="A4.T6.1.1.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="A4.T6.1.1.11.9.1.1" class="ltx_ERROR undefined">\hdashline</span>Codellama</th>
<td id="A4.T6.1.1.11.9.2" class="ltx_td ltx_align_center">Llama-2</td>
<td id="A4.T6.1.1.11.9.3" class="ltx_td ltx_align_center">64.9/76.2</td>
<td id="A4.T6.1.1.11.9.4" class="ltx_td ltx_align_center">69.1/59.2</td>
<td id="A4.T6.1.1.11.9.5" class="ltx_td ltx_align_center">53.4/58.9</td>
<td id="A4.T6.1.1.11.9.6" class="ltx_td ltx_align_center">94.1/89.3</td>
<td id="A4.T6.1.1.11.9.7" class="ltx_td ltx_align_center">66.0/26.6</td>
<td id="A4.T6.1.1.11.9.8" class="ltx_td ltx_align_center">69.5/62.0</td>
</tr>
<tr id="A4.T6.1.1.12.10" class="ltx_tr">
<th id="A4.T6.1.1.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">CodeLlama</th>
<td id="A4.T6.1.1.12.10.2" class="ltx_td ltx_align_center">Llama-3</td>
<td id="A4.T6.1.1.12.10.3" class="ltx_td ltx_align_center">66.5/71.2</td>
<td id="A4.T6.1.1.12.10.4" class="ltx_td ltx_align_center">75.2/69.6</td>
<td id="A4.T6.1.1.12.10.5" class="ltx_td ltx_align_center">62.4/57.7</td>
<td id="A4.T6.1.1.12.10.6" class="ltx_td ltx_align_center">94.1/91.0</td>
<td id="A4.T6.1.1.12.10.7" class="ltx_td ltx_align_center">60.1/36.3</td>
<td id="A4.T6.1.1.12.10.8" class="ltx_td ltx_align_center">71.2/65.2</td>
</tr>
<tr id="A4.T6.1.1.13.11" class="ltx_tr">
<th id="A4.T6.1.1.13.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">CodeLlama</th>
<td id="A4.T6.1.1.13.11.2" class="ltx_td ltx_align_center">Codellama</td>
<td id="A4.T6.1.1.13.11.3" class="ltx_td ltx_align_center">64.9/75.4</td>
<td id="A4.T6.1.1.13.11.4" class="ltx_td ltx_align_center"><span id="A4.T6.1.1.13.11.4.1" class="ltx_text ltx_font_bold">77.9/75.0</span></td>
<td id="A4.T6.1.1.13.11.5" class="ltx_td ltx_align_center">68.5/50.8</td>
<td id="A4.T6.1.1.13.11.6" class="ltx_td ltx_align_center">95.2/92.2</td>
<td id="A4.T6.1.1.13.11.7" class="ltx_td ltx_align_center">71.3/34.3</td>
<td id="A4.T6.1.1.13.11.8" class="ltx_td ltx_align_center">75.6/65.5</td>
</tr>
<tr id="A4.T6.1.1.14.12" class="ltx_tr">
<th id="A4.T6.1.1.14.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">CodeLlama</th>
<td id="A4.T6.1.1.14.12.2" class="ltx_td ltx_align_center">DeepSeek</td>
<td id="A4.T6.1.1.14.12.3" class="ltx_td ltx_align_center">67.6/78.0</td>
<td id="A4.T6.1.1.14.12.4" class="ltx_td ltx_align_center">81.2/66.1</td>
<td id="A4.T6.1.1.14.12.5" class="ltx_td ltx_align_center">64.6/53.9</td>
<td id="A4.T6.1.1.14.12.6" class="ltx_td ltx_align_center">94.1/91.5</td>
<td id="A4.T6.1.1.14.12.7" class="ltx_td ltx_align_center">76.1/35.7</td>
<td id="A4.T6.1.1.14.12.8" class="ltx_td ltx_align_center">76.7/65.0</td>
</tr>
<tr id="A4.T6.1.1.15.13" class="ltx_tr">
<th id="A4.T6.1.1.15.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="A4.T6.1.1.15.13.1.1" class="ltx_ERROR undefined">\hdashline</span>DeepSeek</th>
<td id="A4.T6.1.1.15.13.2" class="ltx_td ltx_align_center">Llama-2</td>
<td id="A4.T6.1.1.15.13.3" class="ltx_td ltx_align_center">63.3/79.8</td>
<td id="A4.T6.1.1.15.13.4" class="ltx_td ltx_align_center">67.1/60.0</td>
<td id="A4.T6.1.1.15.13.5" class="ltx_td ltx_align_center">50.0/56.2</td>
<td id="A4.T6.1.1.15.13.6" class="ltx_td ltx_align_center">94.7/92.1</td>
<td id="A4.T6.1.1.15.13.7" class="ltx_td ltx_align_center">63.3/32.8</td>
<td id="A4.T6.1.1.15.13.8" class="ltx_td ltx_align_center">67.7/64.2</td>
</tr>
<tr id="A4.T6.1.1.16.14" class="ltx_tr">
<th id="A4.T6.1.1.16.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">DeepSeek</th>
<td id="A4.T6.1.1.16.14.2" class="ltx_td ltx_align_center">Llama-3</td>
<td id="A4.T6.1.1.16.14.3" class="ltx_td ltx_align_center">66.5/80.8</td>
<td id="A4.T6.1.1.16.14.4" class="ltx_td ltx_align_center">65.1/69.1</td>
<td id="A4.T6.1.1.16.14.5" class="ltx_td ltx_align_center">63.5/54.0</td>
<td id="A4.T6.1.1.16.14.6" class="ltx_td ltx_align_center">94.1/93.2</td>
<td id="A4.T6.1.1.16.14.7" class="ltx_td ltx_align_center">59.6/42.9</td>
<td id="A4.T6.1.1.16.14.8" class="ltx_td ltx_align_center">69.8/68.0</td>
</tr>
<tr id="A4.T6.1.1.17.15" class="ltx_tr">
<th id="A4.T6.1.1.17.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">DeepSeek</th>
<td id="A4.T6.1.1.17.15.2" class="ltx_td ltx_align_center">CodeLlama</td>
<td id="A4.T6.1.1.17.15.3" class="ltx_td ltx_align_center">67.0/80.2</td>
<td id="A4.T6.1.1.17.15.4" class="ltx_td ltx_align_center">71.1/70.8</td>
<td id="A4.T6.1.1.17.15.5" class="ltx_td ltx_align_center">58.4/52.9</td>
<td id="A4.T6.1.1.17.15.6" class="ltx_td ltx_align_center">96.8/90.1</td>
<td id="A4.T6.1.1.17.15.7" class="ltx_td ltx_align_center">69.7/36.6</td>
<td id="A4.T6.1.1.17.15.8" class="ltx_td ltx_align_center">72.6/66.1</td>
</tr>
<tr id="A4.T6.1.1.18.16" class="ltx_tr">
<th id="A4.T6.1.1.18.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">DeepSeek</th>
<td id="A4.T6.1.1.18.16.2" class="ltx_td ltx_align_center ltx_border_bb">DeepSeek</td>
<td id="A4.T6.1.1.18.16.3" class="ltx_td ltx_align_center ltx_border_bb">70.7/79.7</td>
<td id="A4.T6.1.1.18.16.4" class="ltx_td ltx_align_center ltx_border_bb">72.5/71.3</td>
<td id="A4.T6.1.1.18.16.5" class="ltx_td ltx_align_center ltx_border_bb">63.5/51.3</td>
<td id="A4.T6.1.1.18.16.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.18.16.6.1" class="ltx_text ltx_framed ltx_framed_underline">95.7/93.9</span></td>
<td id="A4.T6.1.1.18.16.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T6.1.1.18.16.7.1" class="ltx_text ltx_font_bold">74.5/38.6</span></td>
<td id="A4.T6.1.1.18.16.8" class="ltx_td ltx_align_center ltx_border_bb">75.4/67.0</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>The TART framework with different backbone modules. The best performance is bold. The second best performance is underlined.</figcaption>
</figure>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Tool Use on Different Backbone Models</h2>

<div id="A5.p1" class="ltx_para">
<p id="A5.p1.1" class="ltx_p">TableÂ <a href="#A5.T7" title="Table 7 â€£ Appendix E Tool Use on Different Backbone Models â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> show the top 10 tools dominate the table processing (e.g., <span id="A5.p1.1.1" class="ltx_text ltx_font_typewriter">get_column_by_name</span>) and numerical reasoning (e.g., <span id="A5.p1.1.2" class="ltx_text ltx_font_typewriter">add</span>), consistent with our earlier findings in SectionÂ <a href="#S4.SS1" title="4.1 Main Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. Further illustrating this, FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.2 Out-of-Domain Results â€£ 4 Experiments â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b) presents a tool categorization for the top 30 functions. Table preprocessing tools constitute the highest percentage at 71.0%, followed by numerical reasoning tools at 21.8%. Together, these categories account for over 90% of tool usage, verifying our assumption that <span id="A5.p1.1.3" class="ltx_text ltx_font_smallcaps">TART</span> is better at table preprocessing and numerical reasoning.</p>
</div>
<figure id="A5.T7" class="ltx_table">
<div id="A5.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:404.7pt;height:188.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.4pt,4.8pt) scale(0.95127087504936,0.95127087504936) ;">
<table id="A5.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A5.T7.1.1.1.1" class="ltx_tr">
<th id="A5.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Rank</th>
<th id="A5.T7.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Llama2</th>
<th id="A5.T7.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Llama3</th>
<th id="A5.T7.1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">DeepSeek</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A5.T7.1.1.2.1" class="ltx_tr">
<th id="A5.T7.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="A5.T7.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">get_column_by_name</td>
<td id="A5.T7.1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">get_column_by_name</td>
<td id="A5.T7.1.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">get_column_by_name</td>
</tr>
<tr id="A5.T7.1.1.3.2" class="ltx_tr">
<th id="A5.T7.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2</th>
<td id="A5.T7.1.1.3.2.2" class="ltx_td ltx_align_left">get_column_cell_value</td>
<td id="A5.T7.1.1.3.2.3" class="ltx_td ltx_align_left">get_column_cell_value</td>
<td id="A5.T7.1.1.3.2.4" class="ltx_td ltx_align_left">get_column_cell_value</td>
</tr>
<tr id="A5.T7.1.1.4.3" class="ltx_tr">
<th id="A5.T7.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="A5.T7.1.1.4.3.2" class="ltx_td ltx_align_left">get_row_index_by_value</td>
<td id="A5.T7.1.1.4.3.3" class="ltx_td ltx_align_left">get_row_index_by_value</td>
<td id="A5.T7.1.1.4.3.4" class="ltx_td ltx_align_left">get_row_index_by_value</td>
</tr>
<tr id="A5.T7.1.1.5.4" class="ltx_tr">
<th id="A5.T7.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">4</th>
<td id="A5.T7.1.1.5.4.2" class="ltx_td ltx_align_left">extract_price</td>
<td id="A5.T7.1.1.5.4.3" class="ltx_td ltx_align_left">extract_price</td>
<td id="A5.T7.1.1.5.4.4" class="ltx_td ltx_align_left">extract_price</td>
</tr>
<tr id="A5.T7.1.1.6.5" class="ltx_tr">
<th id="A5.T7.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">5</th>
<td id="A5.T7.1.1.6.5.2" class="ltx_td ltx_align_left">equal_to</td>
<td id="A5.T7.1.1.6.5.3" class="ltx_td ltx_align_left">equal_to</td>
<td id="A5.T7.1.1.6.5.4" class="ltx_td ltx_align_left">get_row_by_name</td>
</tr>
<tr id="A5.T7.1.1.7.6" class="ltx_tr">
<th id="A5.T7.1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">6</th>
<td id="A5.T7.1.1.7.6.2" class="ltx_td ltx_align_left">get_column_by_index</td>
<td id="A5.T7.1.1.7.6.3" class="ltx_td ltx_align_left">get_row_by_name</td>
<td id="A5.T7.1.1.7.6.4" class="ltx_td ltx_align_left">equal_to</td>
</tr>
<tr id="A5.T7.1.1.8.7" class="ltx_tr">
<th id="A5.T7.1.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">7</th>
<td id="A5.T7.1.1.8.7.2" class="ltx_td ltx_align_left">subtract</td>
<td id="A5.T7.1.1.8.7.3" class="ltx_td ltx_align_left">get_column_by_index</td>
<td id="A5.T7.1.1.8.7.4" class="ltx_td ltx_align_left">divide</td>
</tr>
<tr id="A5.T7.1.1.9.8" class="ltx_tr">
<th id="A5.T7.1.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">8</th>
<td id="A5.T7.1.1.9.8.2" class="ltx_td ltx_align_left">get_row_by_name</td>
<td id="A5.T7.1.1.9.8.3" class="ltx_td ltx_align_left">divide</td>
<td id="A5.T7.1.1.9.8.4" class="ltx_td ltx_align_left">get_column_by_index</td>
</tr>
<tr id="A5.T7.1.1.10.9" class="ltx_tr">
<th id="A5.T7.1.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">9</th>
<td id="A5.T7.1.1.10.9.2" class="ltx_td ltx_align_left">add</td>
<td id="A5.T7.1.1.10.9.3" class="ltx_td ltx_align_left">subtract</td>
<td id="A5.T7.1.1.10.9.4" class="ltx_td ltx_align_left">subtract</td>
</tr>
<tr id="A5.T7.1.1.11.10" class="ltx_tr">
<th id="A5.T7.1.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">10</th>
<td id="A5.T7.1.1.11.10.2" class="ltx_td ltx_align_left ltx_border_bb">multiply</td>
<td id="A5.T7.1.1.11.10.3" class="ltx_td ltx_align_left ltx_border_bb">add</td>
<td id="A5.T7.1.1.11.10.4" class="ltx_td ltx_align_left ltx_border_bb">add</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Comparison of the top 10 functions across TART-Llama2-7b, TART-Llama3-8b, and TART-DeepSeek-7b</figcaption>
</figure>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Error Analysis</h2>

<div id="A6.p1" class="ltx_para">
<p id="A6.p1.1" class="ltx_p">To precisely categorize error types in CoT reasoning, we annotate 50 randomly selected CoT error cases. The result (FigureÂ <a href="#A6.F7" title="Figure 7 â€£ Appendix F Error Analysis â€£ TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>) shows that the major error type is incorrect numerical reasoning, followed by errors related to table operations. This analysis verifies the necessity for our proposed <span id="A6.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span>, which addresses these issues by integrating specialized numerical and table operation tools.</p>
</div>
<figure id="A6.F7" class="ltx_figure"><img src="/html/2409.11724/assets/x8.png" id="A6.F7.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="197" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The error types and their distribution of CoT reasoning and <span id="A6.F7.2.1" class="ltx_text ltx_font_smallcaps">TART</span> framework.</figcaption>
</figure>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Prompts</h2>

<div id="A7.p1" class="ltx_para">
<p id="A7.p1.1" class="ltx_p">We provide detailed prompts of the <span id="A7.p1.1.1" class="ltx_text ltx_font_smallcaps">TART</span> framework, including the tool discovery process and explanation generation process.</p>
</div>
<figure id="A7.fig1" class="ltx_figure">
<blockquote id="A7.fig1.1" class="ltx_quote">
<p id="A7.fig1.1.1" class="ltx_p"><span id="A7.fig1.1.1.1" class="ltx_text ltx_font_bold">Tool Discovery Prompt:
<br class="ltx_break"></span><span id="A7.fig1.1.1.2" class="ltx_text ltx_font_typewriter">Task Description: Given a table and a question, 
<br class="ltx_break">the task is to generate a python program to 
<br class="ltx_break">answer the question. 
<br class="ltx_break">Requirements:
<br class="ltx_break">1. First define some functions to be used in the program.
<br class="ltx_break">2. Try to reuse the functions defined in the previous problems if possible.
<br class="ltx_break">3. When defining a new function, make sure this function is general enough to be used in other problems.
<br class="ltx_break">4. Define a function called solution(table_data) that takes the table data as input and returns the answer to the question. 
<br class="ltx_break">------ 
<br class="ltx_break">â€™â€™â€™
<br class="ltx_break">Table: <span id="A7.fig1.1.1.2.1" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Table Content</span>
<br class="ltx_break">Question: <span id="A7.fig1.1.1.2.2" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Question</span>
<br class="ltx_break">Answer: <span id="A7.fig1.1.1.2.3" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Answer</span>
<br class="ltx_break">â€™â€™â€™
<br class="ltx_break">
table_data = <span id="A7.fig1.1.1.2.4" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">table data array</span>
<br class="ltx_break">
<br class="ltx_break">#FUNCTION1 Description
<br class="ltx_break">def FUNCTION1():
<br class="ltx_break"><span id="A7.fig1.1.1.2.5" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Function Body</span>
<br class="ltx_break">
<br class="ltx_break">#FUNCTION2 Description
<br class="ltx_break">def FUNCTION2():
<br class="ltx_break"><span id="A7.fig1.1.1.2.6" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Function Body</span>
<br class="ltx_break">...
<br class="ltx_break">
<br class="ltx_break">def solution(table_data):
<br class="ltx_break"><span id="A7.fig1.1.1.2.7" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Solution Body</span>
<br class="ltx_break">return answer
<br class="ltx_break">
<br class="ltx_break">print(solution(table_data))
<br class="ltx_break"></span>
<span id="A7.fig1.1.1.3" class="ltx_text ltx_font_typewriter">------
<br class="ltx_break">[[FUNCTION_SOLUTION]]</span></p>
</blockquote>
</figure>
<figure id="A7.fig2" class="ltx_figure">
<blockquote id="A7.fig2.1" class="ltx_quote">
<p id="A7.fig2.1.1" class="ltx_p"><span id="A7.fig2.1.1.1" class="ltx_text ltx_font_bold">Explanation Generation Prompt:
<br class="ltx_break"></span><span id="A7.fig2.1.1.2" class="ltx_text ltx_font_typewriter">Task: Transform Python code used for a table question answering task into an easily understandable explanation in natural language embedded with function calls. 
<br class="ltx_break">Follow these requirements: 
<br class="ltx_break">1. The explanation should be the natural language combined with bracketed segments &lt;&lt;&lt; &gt;&gt;&gt; for code.
<br class="ltx_break">2. The code segments in the brackets &lt;&lt;&lt; &gt;&gt;&gt; should indicate the line number of the code, with the format: ###&lt;line number&gt;.
<br class="ltx_break">3. Multiple lines of codes are separated with â€™;;;â€™ in the brackets &lt;&lt;&lt; &gt;&gt;&gt;.</span> 
<br class="ltx_break"><span id="A7.fig2.1.1.3" class="ltx_text ltx_font_typewriter">------
<br class="ltx_break">â€™â€™â€™
<br class="ltx_break">Table: <span id="A7.fig2.1.1.3.1" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Table Content</span>
<br class="ltx_break">Question: <span id="A7.fig2.1.1.3.2" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Question</span>
<br class="ltx_break">Answer: <span id="A7.fig2.1.1.3.3" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Answer</span>
<br class="ltx_break">â€™â€™â€™
<br class="ltx_break">Python Code:
<br class="ltx_break">table_data = <span id="A7.fig2.1.1.3.4" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">table data array</span>
<br class="ltx_break">
<br class="ltx_break">def solution(table_data):
<br class="ltx_break"><span id="A7.fig2.1.1.3.5" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Line 1 ###1</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.6" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Line 2 ###2</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.7" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">...</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.8" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Line 5 ###5</span>
<br class="ltx_break">return answer
<br class="ltx_break">
<br class="ltx_break">print(solution(table_data))
<br class="ltx_break">
<br class="ltx_break">Output Explanation:
<br class="ltx_break"><span id="A7.fig2.1.1.3.9" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">First, we should get the column</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.10" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">that ... &lt;&lt;&lt;###1 ;;; ###2&gt;&gt;&gt;.</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.11" class="ltx_text ltx_font_serif" style="color:#FFFFFF;background-color:#808080;">â€¦</span>
<br class="ltx_break"><span id="A7.fig2.1.1.3.12" class="ltx_text" style="color:#FFFFFF;background-color:#808080;">Finally, we find that &lt;&lt;&lt;###5&gt;&gt;&gt;.</span>
<br class="ltx_break"></span>
<span id="A7.fig2.1.1.4" class="ltx_text ltx_font_typewriter">------
<br class="ltx_break">[[OUTPUT_EXPLANATION]]</span></p>
</blockquote>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.11723" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.11724" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.11724">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.11724" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.11725" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 01:26:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
