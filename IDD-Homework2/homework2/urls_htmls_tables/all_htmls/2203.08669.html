<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2203.08669] MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients</title><meta property="og:description" content="Existing model poisoning attacks to federated learning assume that an attacker has access to a large fraction of compromised genuine clients. However, such assumption is not realistic in production federated learning s…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2203.08669">

<!--Generated on Mon Mar 11 09:03:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoyu Cao
<br class="ltx_break">Duke University
<br class="ltx_break"> xiaoyu.cao@duke.edu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Neil Zhenqiang Gong
<br class="ltx_break">Duke University
<br class="ltx_break">neil.gong@duke.edu
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Existing model poisoning attacks to federated learning assume that an attacker has access to a large fraction of compromised genuine clients. However, such assumption is not realistic in production federated learning systems that involve millions of clients. In this work, we propose the first <span id="id1.id1.1" class="ltx_text ltx_framed ltx_framed_underline">M</span>odel <span id="id1.id1.2" class="ltx_text ltx_framed ltx_framed_underline">P</span>oisoning <span id="id1.id1.3" class="ltx_text ltx_framed ltx_framed_underline">A</span>ttack based on <span id="id1.id1.4" class="ltx_text ltx_framed ltx_framed_underline">F</span>ake clients called MPAF. Specifically, we assume the attacker injects fake clients to a federated learning system and sends carefully crafted fake local model updates to the cloud server during training, such that the learnt global model has low accuracy for many indiscriminate test inputs. Towards this goal, our attack drags the global model towards an attacker-chosen <em id="id1.id1.5" class="ltx_emph ltx_font_italic">base model</em> that has low accuracy. Specifically, in each round of federated learning, the fake clients craft fake local model updates that point to the base model and scale them up to amplify their impact before sending them to the cloud server. Our experiments show that MPAF can significantly decrease the test accuracy of the global model, even if classical defenses and norm clipping are adopted, highlighting the need for more advanced defenses.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) is an emerging machine learning paradigm for multiple clients (e.g., smartphones or IoT devices) to jointly learn a model with the help of a cloud server. Instead of sharing their private local training data with the cloud server, the clients maintain <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">local models</em> to fit their local training data and iteratively share <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">local model updates</em> with the cloud server, which aggregates the clients’ local model updates to obtain <em id="S1.p1.1.3" class="ltx_emph ltx_font_italic">global model updates</em> and uses them to update a <em id="S1.p1.1.4" class="ltx_emph ltx_font_italic">global model</em>. FL has attracted growing attention in both academia and industry. For instance, Google adopts FL in its Gboard application for next-world prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>; a union of world’s leading pharmaceutical companies uses FL for drug discovery in a project called MELLODDY <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>; and WeBank leverages FL to predict credit risk of borrowers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, due to its distributed nature, FL is fundamentally vulnerable to <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">model poisoning attacks</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. All existing model poisoning attacks assume that an attacker has access to compromised genuine clients and rely on their genuine local training data. Specifically, in all or some FL rounds, the compromised genuine clients first compute local model updates based on their genuine local training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> or their poisoned versions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, and then further manipulate the local model updates before sending them to the cloud server. As a result, the learnt global model misclassifies many indiscriminate test inputs (known as <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">untargeted attacks</em>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> or attacker-chosen ones (known as <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">targeted attacks</em>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In this work, we focus on untargeted attacks because they are harder to perform as they need to influence the predictions for many indiscriminate test inputs. Existing untargeted model poisoning attacks have shown their effectiveness to FL, even with the presence of Byzantine-robust defenses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, i.e., they can reduce the test accuracy of the learnt global model by a significant amount.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, existing untargeted model poisoning attacks all require a large fraction of compromised genuine clients and are less effective when the fraction of compromised genuine clients is small <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
A recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> argued that such requirement of a large fraction of compromised genuine clients is not realistic in production FL that involves millions of clients. Specifically, the cost for compromising genuine clients is so high that an attacker cannot afford to compromise a large fraction of genuine clients in production FL. For instance, to compromise genuine clients, an attacker needs to pay for the access to a large number of undetected zombie devices. As a result, the fraction of compromised genuine clients is usually small (e.g., 0.01%) in production FL. Moreover, only a subset of clients are selected in each round of production FL to participate in the training. Therefore, it is likely that no compromised genuine client is selected in many rounds of production FL. Based on these arguments, they came to a conclusion that production FL with the non-robust FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> or classical defenses (e.g., Trimmed-mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>) is robust enough against untargeted model poisoning attacks. However, as we will show later, this conclusion does not stand when the attacker can inject fake clients into FL systems and perform model poisoning attacks based on them.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Our work:</span>  In this work, we introduce MPAF, the first model poisoning attack to FL that is based on fake clients. We note that the cost of injecting fake clients is much lower than compromising genuine clients in FL. Specifically, the attacker can emulate many fake clients (e.g., android devices) easily using open-source projects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> or android emulators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> on their own machines.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">However, a key challenge of model poisoning attacks based on fake clients is that the fake clients provide no extra knowledge (e.g., no genuine local training data) about the FL system, beyond the global models they receive from the cloud server during training. All existing model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> rely on the assumption that the attacker has some degree of extra knowledge about the FL system, e.g., the genuine local training data on the compromised genuine clients. In this work, we consider an extreme case for the attacker, where no extra knowledge about the FL system (e.g., genuine local training data, global learning rate, or even the FL method) is available to the attacker, beyond the global models that fake clients receive during training. We note that in FL, the global model is shared with selected clients in each round, including both genuine clients and fake ones. Therefore, our threat model considers the minimum-knowledge scenario for an attacker.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To address the challenge, we propose MPAF, which crafts fake local model updates based on the global models only. Specifically, in MPAF, an attacker chooses an arbitrary model (called <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">base model</em>) that shares the same architecture as the global model and has low test accuracy. For instance, an attacker could randomly initialize a model as the base model. Our intuition is that if we can force the global model to behave like the base model whose test accuracy is low, then the test accuracy of the learnt global model would likely decrease. Therefore, in each round of FL, the fake clients generate the direction of fake local model updates via subtracting the current global model from the base model. The fake clients then scale up the magnitudes of the fake local model updates to enlarge their impact in the global model update. Our evaluations on multiple datasets and multiple FL methods show that MPAF is effective in reducing the test accuracy of the learnt global model even if classical defenses and norm clipping are adopted. For instance, on Purchase dataset, MPAF decreases the test accuracy of the global model learnt using Trimmed-mean by 32% when 10% fake clients are injected.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Our contribution can be summarized as follows:</p>
</div>
<div id="S1.p8" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We perform the first study on model poisoning attacks to
FL based on fake clients.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose MPAF, a novel untargeted model poisoning attack that is based on fake clients and requires no extra knowledge about the FL system beyond the received global models during training.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We evaluate MPAF on multiple datasets and multiple FL methods. Our results
show that MPAF is effective, even if classical defenses and norm clipping are leveraged as a countermeasure.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning (FL)</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.3" class="ltx_p">Assume there are <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">n</annotation></semantics></math> clients in FL, each holding some local training data. These clients aim to collaboratively learn a global model with the help of a cloud server. During training, each client maintains a local model based on its local training data and shares its local model updates with the cloud server. Specifically, in the <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">t</annotation></semantics></math>-th round of FL, the cloud server first sends the current global model <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bm{w}^{t}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msup id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">𝒘</mi><mi id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝒘</ci><ci id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\bm{w}^{t}</annotation></semantics></math> to all or a subset of clients. Then, the clients who receive the global model fine-tune their local models based on the global model using stochastic gradient descent (SGD) and their local training data.
The clients then send the local model updates to the cloud server. The cloud server aggregates the local model updates and updates the global model as follows:</p>
<table id="Sx1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\displaystyle\bm{w}^{t+1}\leftarrow\bm{w}^{t}+\eta\bm{g}^{t}," display="inline"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><msup id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.2.2.cmml">𝒘</mi><mrow id="S2.E1.m1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.3.2" xref="S2.E1.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.2.3.1" xref="S2.E1.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.1.1.2.3.3" xref="S2.E1.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml">←</mo><mrow id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><msup id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2.2" xref="S2.E1.m1.1.1.1.1.3.2.2.cmml">𝒘</mi><mi id="S2.E1.m1.1.1.1.1.3.2.3" xref="S2.E1.m1.1.1.1.1.3.2.3.cmml">t</mi></msup><mo id="S2.E1.m1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.3.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">​</mo><msup id="S2.E1.m1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.3.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.3.3.2" xref="S2.E1.m1.1.1.1.1.3.3.3.2.cmml">𝒈</mi><mi id="S2.E1.m1.1.1.1.1.3.3.3.3" xref="S2.E1.m1.1.1.1.1.3.3.3.3.cmml">t</mi></msup></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><ci id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1">←</ci><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2">𝒘</ci><apply id="S2.E1.m1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3"><plus id="S2.E1.m1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.3.1"></plus><ci id="S2.E1.m1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><plus id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.1"></plus><apply id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2">𝒘</ci><ci id="S2.E1.m1.1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.3">𝑡</ci></apply><apply id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3"><times id="S2.E1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.3.1"></times><ci id="S2.E1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.3.2">𝜂</ci><apply id="S2.E1.m1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3.2">𝒈</ci><ci id="S2.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle\bm{w}^{t+1}\leftarrow\bm{w}^{t}+\eta\bm{g}^{t},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.6" class="ltx_p">where <math id="S2.SS1.p1.4.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SS1.p1.4.m1.1a"><mi id="S2.SS1.p1.4.m1.1.1" xref="S2.SS1.p1.4.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m1.1b"><ci id="S2.SS1.p1.4.m1.1.1.cmml" xref="S2.SS1.p1.4.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m1.1c">\eta</annotation></semantics></math> is the <em id="S2.SS1.p1.6.1" class="ltx_emph ltx_font_italic">global learning rate</em>, and <math id="S2.SS1.p1.5.m2.1" class="ltx_Math" alttext="\bm{g}^{t}" display="inline"><semantics id="S2.SS1.p1.5.m2.1a"><msup id="S2.SS1.p1.5.m2.1.1" xref="S2.SS1.p1.5.m2.1.1.cmml"><mi id="S2.SS1.p1.5.m2.1.1.2" xref="S2.SS1.p1.5.m2.1.1.2.cmml">𝒈</mi><mi id="S2.SS1.p1.5.m2.1.1.3" xref="S2.SS1.p1.5.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m2.1b"><apply id="S2.SS1.p1.5.m2.1.1.cmml" xref="S2.SS1.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m2.1.1.1.cmml" xref="S2.SS1.p1.5.m2.1.1">superscript</csymbol><ci id="S2.SS1.p1.5.m2.1.1.2.cmml" xref="S2.SS1.p1.5.m2.1.1.2">𝒈</ci><ci id="S2.SS1.p1.5.m2.1.1.3.cmml" xref="S2.SS1.p1.5.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m2.1c">\bm{g}^{t}</annotation></semantics></math> is the <em id="S2.SS1.p1.6.2" class="ltx_emph ltx_font_italic">global model update</em> in the <math id="S2.SS1.p1.6.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.6.m3.1a"><mi id="S2.SS1.p1.6.m3.1.1" xref="S2.SS1.p1.6.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m3.1b"><ci id="S2.SS1.p1.6.m3.1.1.cmml" xref="S2.SS1.p1.6.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m3.1c">t</annotation></semantics></math>-th round obtained as follows:</p>
<table id="Sx1.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.2" class="ltx_Math" alttext="\displaystyle\bm{g}^{t}=\mathcal{A}(\bm{g}_{1}^{t},\bm{g}_{2}^{t},\cdots,\bm{g}_{n}^{t})." display="inline"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2.1" xref="S2.E2.m1.2.2.1.1.cmml"><mrow id="S2.E2.m1.2.2.1.1" xref="S2.E2.m1.2.2.1.1.cmml"><msup id="S2.E2.m1.2.2.1.1.5" xref="S2.E2.m1.2.2.1.1.5.cmml"><mi id="S2.E2.m1.2.2.1.1.5.2" xref="S2.E2.m1.2.2.1.1.5.2.cmml">𝒈</mi><mi id="S2.E2.m1.2.2.1.1.5.3" xref="S2.E2.m1.2.2.1.1.5.3.cmml">t</mi></msup><mo id="S2.E2.m1.2.2.1.1.4" xref="S2.E2.m1.2.2.1.1.4.cmml">=</mo><mrow id="S2.E2.m1.2.2.1.1.3" xref="S2.E2.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.2.2.1.1.3.5" xref="S2.E2.m1.2.2.1.1.3.5.cmml">𝒜</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.1.3.4" xref="S2.E2.m1.2.2.1.1.3.4.cmml">​</mo><mrow id="S2.E2.m1.2.2.1.1.3.3.3" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.3.3.3.4" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml">(</mo><msubsup id="S2.E2.m1.2.2.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.2.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.2.cmml">𝒈</mi><mn id="S2.E2.m1.2.2.1.1.1.1.1.1.2.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.3.cmml">1</mn><mi id="S2.E2.m1.2.2.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="S2.E2.m1.2.2.1.1.3.3.3.5" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml">,</mo><msubsup id="S2.E2.m1.2.2.1.1.2.2.2.2" xref="S2.E2.m1.2.2.1.1.2.2.2.2.cmml"><mi id="S2.E2.m1.2.2.1.1.2.2.2.2.2.2" xref="S2.E2.m1.2.2.1.1.2.2.2.2.2.2.cmml">𝒈</mi><mn id="S2.E2.m1.2.2.1.1.2.2.2.2.2.3" xref="S2.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">2</mn><mi id="S2.E2.m1.2.2.1.1.2.2.2.2.3" xref="S2.E2.m1.2.2.1.1.2.2.2.2.3.cmml">t</mi></msubsup><mo id="S2.E2.m1.2.2.1.1.3.3.3.6" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">⋯</mi><mo id="S2.E2.m1.2.2.1.1.3.3.3.7" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml">,</mo><msubsup id="S2.E2.m1.2.2.1.1.3.3.3.3" xref="S2.E2.m1.2.2.1.1.3.3.3.3.cmml"><mi id="S2.E2.m1.2.2.1.1.3.3.3.3.2.2" xref="S2.E2.m1.2.2.1.1.3.3.3.3.2.2.cmml">𝒈</mi><mi id="S2.E2.m1.2.2.1.1.3.3.3.3.2.3" xref="S2.E2.m1.2.2.1.1.3.3.3.3.2.3.cmml">n</mi><mi id="S2.E2.m1.2.2.1.1.3.3.3.3.3" xref="S2.E2.m1.2.2.1.1.3.3.3.3.3.cmml">t</mi></msubsup><mo stretchy="false" id="S2.E2.m1.2.2.1.1.3.3.3.8" xref="S2.E2.m1.2.2.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.2.2.1.2" xref="S2.E2.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.1.1.cmml" xref="S2.E2.m1.2.2.1"><eq id="S2.E2.m1.2.2.1.1.4.cmml" xref="S2.E2.m1.2.2.1.1.4"></eq><apply id="S2.E2.m1.2.2.1.1.5.cmml" xref="S2.E2.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.5.1.cmml" xref="S2.E2.m1.2.2.1.1.5">superscript</csymbol><ci id="S2.E2.m1.2.2.1.1.5.2.cmml" xref="S2.E2.m1.2.2.1.1.5.2">𝒈</ci><ci id="S2.E2.m1.2.2.1.1.5.3.cmml" xref="S2.E2.m1.2.2.1.1.5.3">𝑡</ci></apply><apply id="S2.E2.m1.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.3"><times id="S2.E2.m1.2.2.1.1.3.4.cmml" xref="S2.E2.m1.2.2.1.1.3.4"></times><ci id="S2.E2.m1.2.2.1.1.3.5.cmml" xref="S2.E2.m1.2.2.1.1.3.5">𝒜</ci><vector id="S2.E2.m1.2.2.1.1.3.3.4.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3"><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.2">𝒈</ci><cn type="integer" id="S2.E2.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.2.3">1</cn></apply><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S2.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2">superscript</csymbol><apply id="S2.E2.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2.2.2">𝒈</ci><cn type="integer" id="S2.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2.2.3">2</cn></apply><ci id="S2.E2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.1.1.2.2.2.2.3">𝑡</ci></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">⋯</ci><apply id="S2.E2.m1.2.2.1.1.3.3.3.3.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.3.3.3.3.1.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3">superscript</csymbol><apply id="S2.E2.m1.2.2.1.1.3.3.3.3.2.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.3.3.3.3.2.1.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.3.3.3.3.2.2.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3.2.2">𝒈</ci><ci id="S2.E2.m1.2.2.1.1.3.3.3.3.2.3.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3.2.3">𝑛</ci></apply><ci id="S2.E2.m1.2.2.1.1.3.3.3.3.3.cmml" xref="S2.E2.m1.2.2.1.1.3.3.3.3.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">\displaystyle\bm{g}^{t}=\mathcal{A}(\bm{g}_{1}^{t},\bm{g}_{2}^{t},\cdots,\bm{g}_{n}^{t}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.7" class="ltx_p">Here, <math id="S2.SS1.p1.7.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS1.p1.7.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.7.m1.1.1" xref="S2.SS1.p1.7.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m1.1b"><ci id="S2.SS1.p1.7.m1.1.1.cmml" xref="S2.SS1.p1.7.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m1.1c">\mathcal{A}</annotation></semantics></math> is the aggregation rule the cloud server uses to aggregate the local model updates, which plays an important role in FL. Different FL methods essentially use different aggregation rules. Next, we will discuss three popular aggregation rules, including the non-robust FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and two Byzantine-robust ones, i.e., Median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and Trimmed-mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">FedAvg:</span>  FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> is the most popular aggregation rule in FL. It calculates the average of the local model updates as the global model update. FedAvg achieves the state-of-the-art performance in non-adversarial settings.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Median:</span>  Median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> is a coordinate-wise aggregation rule. The server sorts the values of each parameter in local model updates and finds the median value as the aggregated value for the corresponding parameter in the global model update.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.3" class="ltx_p"><span id="S2.SS1.p4.3.1" class="ltx_text ltx_font_bold">Trimmed-mean:</span>  Trimmed-mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> is another coordinate-wise aggregation rule. For each model parameter, instead of using its median value, Trimmed-mean removes the largest and smallest <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><mi id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><ci id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">k</annotation></semantics></math> values from its sorted values, and then computes the average of the remaining values as the corresponding parameter in the global model update. In Trimmed-mean, <math id="S2.SS1.p4.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p4.2.m2.1a"><mi id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.1b"><ci id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.1c">k</annotation></semantics></math> achieves a trade-off between the robustness in adversarial settings and test accuracy in non-adversarial settings. In our experiments, we assume a strong defender who knows the number of fake clients, i.e., <math id="S2.SS1.p4.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p4.3.m3.1a"><mi id="S2.SS1.p4.3.m3.1.1" xref="S2.SS1.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.3.m3.1b"><ci id="S2.SS1.p4.3.m3.1.1.cmml" xref="S2.SS1.p4.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.3.m3.1c">k</annotation></semantics></math> equals to the number of fake clients in each round.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Existing Model Poisoning Attacks to FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Various attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> have been proposed to poison the global model in FL, all of which rely on compromised genuine clients. Based on the attacker’s goal, they can be divided into two categories: untargeted model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and targeted model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
Untargeted model poisoning attacks aim to decrease the test accuracy of the global model, while targeted model poisoning attacks aim to force the global model to output attacker-chosen target labels for attacker-chosen target inputs. We focus on untargeted model poisoning attacks in this work.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Existing untargeted model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> follow the following two steps in all or multiple rounds of FL. First, the compromised genuine clients compute the genuine local model updates based on their genuine local training data. Then, they perturb their genuine local model updates such that the poisoned global model updates will substantially deviate from the genuine ones. These attacks require many compromised genuine clients to be effective.
However, in production FL, it may not be affordable for an attacker to obtain access to a large number of compromised genuine clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Therefore, we consider a more practical scenario for model poisoning attacks that an attacker injects fake clients to the FL system. Unfortunately, existing attacks are not applicable to such scenario, since they require extra knowledge about the FL system (e.g., genuine local training data), which is not available on the fake clients. We notice that several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> studied the free-rider attacks with fake clients, which are orthogonal to model poisoning attacks.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Defenses against Model Poisoning Attacks</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Many defenses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> have been proposed against model poisoning attacks to FL, which fall into two main categories. The first type of defense <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> designs Byzantine-robust aggregation rules. Their idea is to mitigate the impact of statistical outliers among the local model updates. For instance, Trimmed-mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> removes the largest and smallest values of each coordinate in the local model updates before taking the average. The other type of defense <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> aims to provide provable guarantee against poisoning attacks. For instance, Cao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> leveraged the fundamental robustness of majority vote to design an ensemble-based provably secure federated learning framework. They proved that when the number of compromised genuine clients is bounded, the predictions for test inputs are not affected by any attack. However, their derived provable security guarantee does not consider fake clients.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">A recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> claims that production FL with the non-robust FedAvg or classical defenses such as Trimmed-mean is already robust against untargeted model poisoning attacks that rely on compromised genuine clients, because the fraction of compromised genuine clients is small in production FL systems.
However, this claim does not stand for fake clients based model poisoning attacks. As we will show, an attacker can inject many fake clients into FL systems and perform MPAF to degrade the performance of the learnt global model.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">In fact, the claim on the robustness of FedAvg is not accurate even if the attacker only has access to a small fraction of compromised genuine clients. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> claims that FedAvg is robust because 1) the server selects a small fraction of clients in each global training round, 2) compromised genuine clients are unlikely to be selected when their fraction is small, and 3) the compromised genuine clients’ impact on the global model will be eliminated during training even if they are selected in certain training rounds. However, robustness/security is about an FL system’s performance in the <em id="S2.SS3.p3.1.1" class="ltx_emph ltx_font_italic">worst-case</em> scenarios. A compromised genuine client can substantially degrade the global model’s accuracy in the scenario where it is selected near the end of the training process. Although such worst-case scenario happens with a small probability when the fraction of compromised genuine clients is small, it still invalidates the robustness of FedAvg.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Threat Model</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Attacker’s Goal</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The attacker’s goal is to decrease the test accuracy of the learnt global model. Specifically, a larger difference between the test accuracy of the global models with and without attack indicates a stronger attack.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Attacker’s Capability</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We assume the attacker can inject many fake clients into FL systems. The attacker can control these fake clients to send arbitrary fake local model updates to the cloud server.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Compared to compromising genuine clients, the cost of injecting fake clients is much more affordable. Specifically, to compromise genuine clients, an attacker needs to bypass the anti-malware software on the clients’ devices, which becomes more difficult as the anti-malware industry evolves. The attacker may also choose to pay for the zombie devices that are already compromised and could be remotely accessed. However, it would be too costly to buy a large number of zombie devices. Moreover, performing the attacks on compromised devices requires the attacker to evade the anomaly detection on the systems, making it even harder.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">On the contrary, it would be easy and cheap to perform attacks based on fake clients. First, an attacker can emulate fake clients using open-source projects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, or even the free softwares, e.g., android emulators on PC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. It is worth noting that modern android emulators support multi-instance functionality, which means that an attacker can emulate many instances (clients) using a single machine, significantly reducing the cost. Another advantage of using fake client is that the attacker has full control over the devices. For instance, the android emulators can grant the attacker root access to the devices, and the attacker does not need to deal with any alert that the system may probably raise during the attack.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Attacker’s Knowledge</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Existing model poisoning attacks that rely on compromised genuine clients assume the attacker knows extra knowledge about the FL system, e.g., the genuine local training data on the compromised genuine clients, other than the received global models during training. However, such assumption often does not hold when it comes to attacks based on fake clients. Specifically, the fake clients are created by the attacker and there are usually no genuine local training data on them. Therefore, we consider a more realistic threat model, where the attacker has no knowledge about the FL system other than the received global models during training. In particular, the attacker does not know any local training data or local model updates on any genuine client. Moreover, the attacker does not know the FL aggregation rule or the global learning rate that the cloud server uses. Since the global model is broadcast to selected clients in each round of FL, including both genuine and fake clients, our threat model considers the scenario with minimum knowledge for the attacker.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Our Attack</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We will first discuss two baseline attacks and analyze why they are not effective. Then, we will introduce our MPAF.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Baseline Attacks</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.6" class="ltx_p">A naive way of performing model poisoning attacks with limited knowledge is to use random noise as the fake local model updates. For instance, the fake clients could sample a Gaussian random noise for each model parameter. They can then enlarge the magnitudes of the random local model updates using a scaling factor <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\lambda</annotation></semantics></math>. The fake clients send the scaled random noise to the cloud server as the fake local model updates. Formally, the <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">i</annotation></semantics></math>-th fake client sends <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bm{g}_{i}^{t}=-\lambda\mathbf{\varepsilon}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><msubsup id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2.2.2" xref="S4.SS1.p1.3.m3.1.1.2.2.2.cmml">𝒈</mi><mi id="S4.SS1.p1.3.m3.1.1.2.2.3" xref="S4.SS1.p1.3.m3.1.1.2.2.3.cmml">i</mi><mi id="S4.SS1.p1.3.m3.1.1.2.3" xref="S4.SS1.p1.3.m3.1.1.2.3.cmml">t</mi></msubsup><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mo id="S4.SS1.p1.3.m3.1.1.3a" xref="S4.SS1.p1.3.m3.1.1.3.cmml">−</mo><mrow id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.2.2" xref="S4.SS1.p1.3.m3.1.1.3.2.2.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.3.m3.1.1.3.2.1" xref="S4.SS1.p1.3.m3.1.1.3.2.1.cmml">​</mo><mi id="S4.SS1.p1.3.m3.1.1.3.2.3" xref="S4.SS1.p1.3.m3.1.1.3.2.3.cmml">ε</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><apply id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2">superscript</csymbol><apply id="S4.SS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.2.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2.2">𝒈</ci><ci id="S4.SS1.p1.3.m3.1.1.2.2.3.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2.3">𝑖</ci></apply><ci id="S4.SS1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS1.p1.3.m3.1.1.2.3">𝑡</ci></apply><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><minus id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3"></minus><apply id="S4.SS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2"><times id="S4.SS1.p1.3.m3.1.1.3.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2.1"></times><ci id="S4.SS1.p1.3.m3.1.1.3.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2.2">𝜆</ci><ci id="S4.SS1.p1.3.m3.1.1.3.2.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2.3">𝜀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\bm{g}_{i}^{t}=-\lambda\mathbf{\varepsilon}</annotation></semantics></math> to the cloud server in the <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">t</annotation></semantics></math>-th round, where <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{\varepsilon}" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\mathbf{\varepsilon}</annotation></semantics></math> is a random vector sampled from the multivariate Gaussian distribution <math id="S4.SS1.p1.6.m6.2" class="ltx_Math" alttext="\mathcal{N}(\bm{0},\bm{I})" display="inline"><semantics id="S4.SS1.p1.6.m6.2a"><mrow id="S4.SS1.p1.6.m6.2.3" xref="S4.SS1.p1.6.m6.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.6.m6.2.3.2" xref="S4.SS1.p1.6.m6.2.3.2.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.6.m6.2.3.1" xref="S4.SS1.p1.6.m6.2.3.1.cmml">​</mo><mrow id="S4.SS1.p1.6.m6.2.3.3.2" xref="S4.SS1.p1.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS1.p1.6.m6.2.3.3.2.1" xref="S4.SS1.p1.6.m6.2.3.3.1.cmml">(</mo><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">𝟎</mn><mo id="S4.SS1.p1.6.m6.2.3.3.2.2" xref="S4.SS1.p1.6.m6.2.3.3.1.cmml">,</mo><mi id="S4.SS1.p1.6.m6.2.2" xref="S4.SS1.p1.6.m6.2.2.cmml">𝑰</mi><mo stretchy="false" id="S4.SS1.p1.6.m6.2.3.3.2.3" xref="S4.SS1.p1.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.2b"><apply id="S4.SS1.p1.6.m6.2.3.cmml" xref="S4.SS1.p1.6.m6.2.3"><times id="S4.SS1.p1.6.m6.2.3.1.cmml" xref="S4.SS1.p1.6.m6.2.3.1"></times><ci id="S4.SS1.p1.6.m6.2.3.2.cmml" xref="S4.SS1.p1.6.m6.2.3.2">𝒩</ci><interval closure="open" id="S4.SS1.p1.6.m6.2.3.3.1.cmml" xref="S4.SS1.p1.6.m6.2.3.3.2"><cn type="integer" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">0</cn><ci id="S4.SS1.p1.6.m6.2.2.cmml" xref="S4.SS1.p1.6.m6.2.2">𝑰</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.2c">\mathcal{N}(\bm{0},\bm{I})</annotation></semantics></math>.
We call such attack <em id="S4.SS1.p1.6.1" class="ltx_emph ltx_font_italic">random attack</em>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.14" class="ltx_p">Another intuitive attack based on fake clients is to estimate the benign global model updates using historical information, and then generate fake local model updates that have the opposite direction. Specifically, in the <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">t</annotation></semantics></math>-th round, given the current global model <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\bm{w}^{t}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><msup id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">𝒘</mi><mi id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝒘</ci><ci id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\bm{w}^{t}</annotation></semantics></math> and the previous global model <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\bm{w}^{t-1}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msup id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">𝒘</mi><mrow id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml"><mi id="S4.SS1.p2.3.m3.1.1.3.2" xref="S4.SS1.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p2.3.m3.1.1.3.1" xref="S4.SS1.p2.3.m3.1.1.3.1.cmml">−</mo><mn id="S4.SS1.p2.3.m3.1.1.3.3" xref="S4.SS1.p2.3.m3.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝒘</ci><apply id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3"><minus id="S4.SS1.p2.3.m3.1.1.3.1.cmml" xref="S4.SS1.p2.3.m3.1.1.3.1"></minus><ci id="S4.SS1.p2.3.m3.1.1.3.2.cmml" xref="S4.SS1.p2.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.3.m3.1.1.3.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\bm{w}^{t-1}</annotation></semantics></math>, we can compute the global model update <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\bm{g}^{t-1}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><msup id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">𝒈</mi><mrow id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml"><mi id="S4.SS1.p2.4.m4.1.1.3.2" xref="S4.SS1.p2.4.m4.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p2.4.m4.1.1.3.1" xref="S4.SS1.p2.4.m4.1.1.3.1.cmml">−</mo><mn id="S4.SS1.p2.4.m4.1.1.3.3" xref="S4.SS1.p2.4.m4.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝒈</ci><apply id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><minus id="S4.SS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3.1"></minus><ci id="S4.SS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\bm{g}^{t-1}</annotation></semantics></math> in the <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="(t-1)" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS1.p2.5.m5.1.1.1.2" xref="S4.SS1.p2.5.m5.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.5.m5.1.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.1.1.2" xref="S4.SS1.p2.5.m5.1.1.1.1.2.cmml">t</mi><mo id="S4.SS1.p2.5.m5.1.1.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.1.1.cmml">−</mo><mn id="S4.SS1.p2.5.m5.1.1.1.1.3" xref="S4.SS1.p2.5.m5.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.SS1.p2.5.m5.1.1.1.3" xref="S4.SS1.p2.5.m5.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"><minus id="S4.SS1.p2.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.1"></minus><ci id="S4.SS1.p2.5.m5.1.1.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.5.m5.1.1.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">(t-1)</annotation></semantics></math>-th round as <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="\bm{g}^{t-1}=(\bm{w}^{t}-\bm{w}^{t-1})/\eta" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mrow id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><msup id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml"><mi id="S4.SS1.p2.6.m6.1.1.3.2" xref="S4.SS1.p2.6.m6.1.1.3.2.cmml">𝒈</mi><mrow id="S4.SS1.p2.6.m6.1.1.3.3" xref="S4.SS1.p2.6.m6.1.1.3.3.cmml"><mi id="S4.SS1.p2.6.m6.1.1.3.3.2" xref="S4.SS1.p2.6.m6.1.1.3.3.2.cmml">t</mi><mo id="S4.SS1.p2.6.m6.1.1.3.3.1" xref="S4.SS1.p2.6.m6.1.1.3.3.1.cmml">−</mo><mn id="S4.SS1.p2.6.m6.1.1.3.3.3" xref="S4.SS1.p2.6.m6.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">=</mo><mrow id="S4.SS1.p2.6.m6.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.cmml"><mrow id="S4.SS1.p2.6.m6.1.1.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS1.p2.6.m6.1.1.1.1.1.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.6.m6.1.1.1.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><msup id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml"><mi id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.2.cmml">𝒘</mi><mi id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo id="S4.SS1.p2.6.m6.1.1.1.1.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.1.cmml">−</mo><msup id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.2.cmml">𝒘</mi><mrow id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.2" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.1" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><mo stretchy="false" id="S4.SS1.p2.6.m6.1.1.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS1.p2.6.m6.1.1.1.2" xref="S4.SS1.p2.6.m6.1.1.1.2.cmml">/</mo><mi id="S4.SS1.p2.6.m6.1.1.1.3" xref="S4.SS1.p2.6.m6.1.1.1.3.cmml">η</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><eq id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2"></eq><apply id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.3.1.cmml" xref="S4.SS1.p2.6.m6.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.3.2.cmml" xref="S4.SS1.p2.6.m6.1.1.3.2">𝒈</ci><apply id="S4.SS1.p2.6.m6.1.1.3.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3.3"><minus id="S4.SS1.p2.6.m6.1.1.3.3.1.cmml" xref="S4.SS1.p2.6.m6.1.1.3.3.1"></minus><ci id="S4.SS1.p2.6.m6.1.1.3.3.2.cmml" xref="S4.SS1.p2.6.m6.1.1.3.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.6.m6.1.1.3.3.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3.3.3">1</cn></apply></apply><apply id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1"><divide id="S4.SS1.p2.6.m6.1.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.2"></divide><apply id="S4.SS1.p2.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1"><minus id="S4.SS1.p2.6.m6.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.1"></minus><apply id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.2">𝒘</ci><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.2">𝒘</ci><apply id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3"><minus id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><ci id="S4.SS1.p2.6.m6.1.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.1.3">𝜂</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">\bm{g}^{t-1}=(\bm{w}^{t}-\bm{w}^{t-1})/\eta</annotation></semantics></math>, where <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mi id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><ci id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">\eta</annotation></semantics></math> is the global learning rate. Since the global model updates in consecutive rounds do not differ much, especially when the global model is near convergence, we can approximate the benign global model update in the <math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><mi id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><ci id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">t</annotation></semantics></math>-th round as <math id="S4.SS1.p2.9.m9.1" class="ltx_Math" alttext="\hat{\bm{g}}^{t}\approx\bm{g}^{t-1}=(\bm{w}^{t}-\bm{w}^{t-1})/\eta" display="inline"><semantics id="S4.SS1.p2.9.m9.1a"><mrow id="S4.SS1.p2.9.m9.1.1" xref="S4.SS1.p2.9.m9.1.1.cmml"><msup id="S4.SS1.p2.9.m9.1.1.3" xref="S4.SS1.p2.9.m9.1.1.3.cmml"><mover accent="true" id="S4.SS1.p2.9.m9.1.1.3.2" xref="S4.SS1.p2.9.m9.1.1.3.2.cmml"><mi id="S4.SS1.p2.9.m9.1.1.3.2.2" xref="S4.SS1.p2.9.m9.1.1.3.2.2.cmml">𝒈</mi><mo id="S4.SS1.p2.9.m9.1.1.3.2.1" xref="S4.SS1.p2.9.m9.1.1.3.2.1.cmml">^</mo></mover><mi id="S4.SS1.p2.9.m9.1.1.3.3" xref="S4.SS1.p2.9.m9.1.1.3.3.cmml">t</mi></msup><mo id="S4.SS1.p2.9.m9.1.1.4" xref="S4.SS1.p2.9.m9.1.1.4.cmml">≈</mo><msup id="S4.SS1.p2.9.m9.1.1.5" xref="S4.SS1.p2.9.m9.1.1.5.cmml"><mi id="S4.SS1.p2.9.m9.1.1.5.2" xref="S4.SS1.p2.9.m9.1.1.5.2.cmml">𝒈</mi><mrow id="S4.SS1.p2.9.m9.1.1.5.3" xref="S4.SS1.p2.9.m9.1.1.5.3.cmml"><mi id="S4.SS1.p2.9.m9.1.1.5.3.2" xref="S4.SS1.p2.9.m9.1.1.5.3.2.cmml">t</mi><mo id="S4.SS1.p2.9.m9.1.1.5.3.1" xref="S4.SS1.p2.9.m9.1.1.5.3.1.cmml">−</mo><mn id="S4.SS1.p2.9.m9.1.1.5.3.3" xref="S4.SS1.p2.9.m9.1.1.5.3.3.cmml">1</mn></mrow></msup><mo id="S4.SS1.p2.9.m9.1.1.6" xref="S4.SS1.p2.9.m9.1.1.6.cmml">=</mo><mrow id="S4.SS1.p2.9.m9.1.1.1" xref="S4.SS1.p2.9.m9.1.1.1.cmml"><mrow id="S4.SS1.p2.9.m9.1.1.1.1.1" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS1.p2.9.m9.1.1.1.1.1.2" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.9.m9.1.1.1.1.1.1" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.cmml"><msup id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.cmml"><mi id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.2" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.2.cmml">𝒘</mi><mi id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.3" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo id="S4.SS1.p2.9.m9.1.1.1.1.1.1.1" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.1.cmml">−</mo><msup id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.2" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.2.cmml">𝒘</mi><mrow id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.2" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.1" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.3" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><mo stretchy="false" id="S4.SS1.p2.9.m9.1.1.1.1.1.3" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS1.p2.9.m9.1.1.1.2" xref="S4.SS1.p2.9.m9.1.1.1.2.cmml">/</mo><mi id="S4.SS1.p2.9.m9.1.1.1.3" xref="S4.SS1.p2.9.m9.1.1.1.3.cmml">η</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m9.1b"><apply id="S4.SS1.p2.9.m9.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1"><and id="S4.SS1.p2.9.m9.1.1a.cmml" xref="S4.SS1.p2.9.m9.1.1"></and><apply id="S4.SS1.p2.9.m9.1.1b.cmml" xref="S4.SS1.p2.9.m9.1.1"><approx id="S4.SS1.p2.9.m9.1.1.4.cmml" xref="S4.SS1.p2.9.m9.1.1.4"></approx><apply id="S4.SS1.p2.9.m9.1.1.3.cmml" xref="S4.SS1.p2.9.m9.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.3.1.cmml" xref="S4.SS1.p2.9.m9.1.1.3">superscript</csymbol><apply id="S4.SS1.p2.9.m9.1.1.3.2.cmml" xref="S4.SS1.p2.9.m9.1.1.3.2"><ci id="S4.SS1.p2.9.m9.1.1.3.2.1.cmml" xref="S4.SS1.p2.9.m9.1.1.3.2.1">^</ci><ci id="S4.SS1.p2.9.m9.1.1.3.2.2.cmml" xref="S4.SS1.p2.9.m9.1.1.3.2.2">𝒈</ci></apply><ci id="S4.SS1.p2.9.m9.1.1.3.3.cmml" xref="S4.SS1.p2.9.m9.1.1.3.3">𝑡</ci></apply><apply id="S4.SS1.p2.9.m9.1.1.5.cmml" xref="S4.SS1.p2.9.m9.1.1.5"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.5.1.cmml" xref="S4.SS1.p2.9.m9.1.1.5">superscript</csymbol><ci id="S4.SS1.p2.9.m9.1.1.5.2.cmml" xref="S4.SS1.p2.9.m9.1.1.5.2">𝒈</ci><apply id="S4.SS1.p2.9.m9.1.1.5.3.cmml" xref="S4.SS1.p2.9.m9.1.1.5.3"><minus id="S4.SS1.p2.9.m9.1.1.5.3.1.cmml" xref="S4.SS1.p2.9.m9.1.1.5.3.1"></minus><ci id="S4.SS1.p2.9.m9.1.1.5.3.2.cmml" xref="S4.SS1.p2.9.m9.1.1.5.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.9.m9.1.1.5.3.3.cmml" xref="S4.SS1.p2.9.m9.1.1.5.3.3">1</cn></apply></apply></apply><apply id="S4.SS1.p2.9.m9.1.1c.cmml" xref="S4.SS1.p2.9.m9.1.1"><eq id="S4.SS1.p2.9.m9.1.1.6.cmml" xref="S4.SS1.p2.9.m9.1.1.6"></eq><share href="#S4.SS1.p2.9.m9.1.1.5.cmml" id="S4.SS1.p2.9.m9.1.1d.cmml" xref="S4.SS1.p2.9.m9.1.1"></share><apply id="S4.SS1.p2.9.m9.1.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1"><divide id="S4.SS1.p2.9.m9.1.1.1.2.cmml" xref="S4.SS1.p2.9.m9.1.1.1.2"></divide><apply id="S4.SS1.p2.9.m9.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1"><minus id="S4.SS1.p2.9.m9.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.1"></minus><apply id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.2">𝒘</ci><ci id="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.2">𝒘</ci><apply id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3"><minus id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS1.p2.9.m9.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><ci id="S4.SS1.p2.9.m9.1.1.1.3.cmml" xref="S4.SS1.p2.9.m9.1.1.1.3">𝜂</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m9.1c">\hat{\bm{g}}^{t}\approx\bm{g}^{t-1}=(\bm{w}^{t}-\bm{w}^{t-1})/\eta</annotation></semantics></math>. Under our threat model, the global learning rate <math id="S4.SS1.p2.10.m10.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S4.SS1.p2.10.m10.1a"><mi id="S4.SS1.p2.10.m10.1.1" xref="S4.SS1.p2.10.m10.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m10.1b"><ci id="S4.SS1.p2.10.m10.1.1.cmml" xref="S4.SS1.p2.10.m10.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m10.1c">\eta</annotation></semantics></math> is unknown to the attacker. However, an attacker does not need to know the exact magnitude of the benign global model update. Instead, the attacker can use a large scaling factor <math id="S4.SS1.p2.11.m11.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS1.p2.11.m11.1a"><mi id="S4.SS1.p2.11.m11.1.1" xref="S4.SS1.p2.11.m11.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.11.m11.1b"><ci id="S4.SS1.p2.11.m11.1.1.cmml" xref="S4.SS1.p2.11.m11.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.11.m11.1c">\lambda</annotation></semantics></math> to scale up the fake local model updates such that their magnitudes are no smaller than the ones from the genuine clients. Formally, a fake client <math id="S4.SS1.p2.12.m12.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.p2.12.m12.1a"><mi id="S4.SS1.p2.12.m12.1.1" xref="S4.SS1.p2.12.m12.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.12.m12.1b"><ci id="S4.SS1.p2.12.m12.1.1.cmml" xref="S4.SS1.p2.12.m12.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.12.m12.1c">i</annotation></semantics></math> sends <math id="S4.SS1.p2.13.m13.1" class="ltx_Math" alttext="\bm{g}_{i}^{t}=-\lambda(\bm{w}^{t}-\bm{w}^{t-1})" display="inline"><semantics id="S4.SS1.p2.13.m13.1a"><mrow id="S4.SS1.p2.13.m13.1.1" xref="S4.SS1.p2.13.m13.1.1.cmml"><msubsup id="S4.SS1.p2.13.m13.1.1.3" xref="S4.SS1.p2.13.m13.1.1.3.cmml"><mi id="S4.SS1.p2.13.m13.1.1.3.2.2" xref="S4.SS1.p2.13.m13.1.1.3.2.2.cmml">𝒈</mi><mi id="S4.SS1.p2.13.m13.1.1.3.2.3" xref="S4.SS1.p2.13.m13.1.1.3.2.3.cmml">i</mi><mi id="S4.SS1.p2.13.m13.1.1.3.3" xref="S4.SS1.p2.13.m13.1.1.3.3.cmml">t</mi></msubsup><mo id="S4.SS1.p2.13.m13.1.1.2" xref="S4.SS1.p2.13.m13.1.1.2.cmml">=</mo><mrow id="S4.SS1.p2.13.m13.1.1.1" xref="S4.SS1.p2.13.m13.1.1.1.cmml"><mo id="S4.SS1.p2.13.m13.1.1.1a" xref="S4.SS1.p2.13.m13.1.1.1.cmml">−</mo><mrow id="S4.SS1.p2.13.m13.1.1.1.1" xref="S4.SS1.p2.13.m13.1.1.1.1.cmml"><mi id="S4.SS1.p2.13.m13.1.1.1.1.3" xref="S4.SS1.p2.13.m13.1.1.1.1.3.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.13.m13.1.1.1.1.2" xref="S4.SS1.p2.13.m13.1.1.1.1.2.cmml">​</mo><mrow id="S4.SS1.p2.13.m13.1.1.1.1.1.1" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS1.p2.13.m13.1.1.1.1.1.1.2" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.cmml"><msup id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.cmml"><mi id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.2" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.2.cmml">𝒘</mi><mi id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.3" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.1" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.2" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.2.cmml">𝒘</mi><mrow id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.2" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.1" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.3" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><mo stretchy="false" id="S4.SS1.p2.13.m13.1.1.1.1.1.1.3" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.13.m13.1b"><apply id="S4.SS1.p2.13.m13.1.1.cmml" xref="S4.SS1.p2.13.m13.1.1"><eq id="S4.SS1.p2.13.m13.1.1.2.cmml" xref="S4.SS1.p2.13.m13.1.1.2"></eq><apply id="S4.SS1.p2.13.m13.1.1.3.cmml" xref="S4.SS1.p2.13.m13.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.13.m13.1.1.3.1.cmml" xref="S4.SS1.p2.13.m13.1.1.3">superscript</csymbol><apply id="S4.SS1.p2.13.m13.1.1.3.2.cmml" xref="S4.SS1.p2.13.m13.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.13.m13.1.1.3.2.1.cmml" xref="S4.SS1.p2.13.m13.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.13.m13.1.1.3.2.2.cmml" xref="S4.SS1.p2.13.m13.1.1.3.2.2">𝒈</ci><ci id="S4.SS1.p2.13.m13.1.1.3.2.3.cmml" xref="S4.SS1.p2.13.m13.1.1.3.2.3">𝑖</ci></apply><ci id="S4.SS1.p2.13.m13.1.1.3.3.cmml" xref="S4.SS1.p2.13.m13.1.1.3.3">𝑡</ci></apply><apply id="S4.SS1.p2.13.m13.1.1.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1"><minus id="S4.SS1.p2.13.m13.1.1.1.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1"></minus><apply id="S4.SS1.p2.13.m13.1.1.1.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1"><times id="S4.SS1.p2.13.m13.1.1.1.1.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.2"></times><ci id="S4.SS1.p2.13.m13.1.1.1.1.3.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.3">𝜆</ci><apply id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1"><minus id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.1"></minus><apply id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.2">𝒘</ci><ci id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.2">𝒘</ci><apply id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3"><minus id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS1.p2.13.m13.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.13.m13.1c">\bm{g}_{i}^{t}=-\lambda(\bm{w}^{t}-\bm{w}^{t-1})</annotation></semantics></math> to the cloud server in the <math id="S4.SS1.p2.14.m14.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p2.14.m14.1a"><mi id="S4.SS1.p2.14.m14.1.1" xref="S4.SS1.p2.14.m14.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.14.m14.1b"><ci id="S4.SS1.p2.14.m14.1.1.cmml" xref="S4.SS1.p2.14.m14.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.14.m14.1c">t</annotation></semantics></math>-th round, where the negative sign means the attacker aims to deviate the global model to the opposite direction. We call such attack <em id="S4.SS1.p2.14.1" class="ltx_emph ltx_font_italic">history attack</em>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The two baseline attacks are intuitive. However, as we will show in Section <a href="#S5" title="5 Evaluation ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, they have limited impact on the accuracy of the learnt global model when classical defenses (e.g., Trimmed-mean) are applied. We suspect that this is because the attacks are not <em id="S4.SS1.p3.1.1" class="ltx_emph ltx_font_italic">consistent</em> in consecutive rounds. Specifically, the attacks may successfully deviate the global model to some direction by a small step in each individual FL round. However, such deviations may have different directions in different rounds, which means the deviations may cancel out in multiple rounds.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/2203.08669/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="253" height="95" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.14.7.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S4.F1.12.6" class="ltx_text" style="font-size:90%;">Illustration of MPAF. <math id="S4.F1.7.1.m1.1" class="ltx_Math" alttext="\bm{w}^{\prime}" display="inline"><semantics id="S4.F1.7.1.m1.1b"><msup id="S4.F1.7.1.m1.1.1" xref="S4.F1.7.1.m1.1.1.cmml"><mi id="S4.F1.7.1.m1.1.1.2" xref="S4.F1.7.1.m1.1.1.2.cmml">𝒘</mi><mo id="S4.F1.7.1.m1.1.1.3" xref="S4.F1.7.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.F1.7.1.m1.1c"><apply id="S4.F1.7.1.m1.1.1.cmml" xref="S4.F1.7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F1.7.1.m1.1.1.1.cmml" xref="S4.F1.7.1.m1.1.1">superscript</csymbol><ci id="S4.F1.7.1.m1.1.1.2.cmml" xref="S4.F1.7.1.m1.1.1.2">𝒘</ci><ci id="S4.F1.7.1.m1.1.1.3.cmml" xref="S4.F1.7.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.7.1.m1.1d">\bm{w}^{\prime}</annotation></semantics></math> is an attacker-chosen base model. <math id="S4.F1.8.2.m2.1" class="ltx_Math" alttext="\bm{w}^{t-1},\bm{w}^{t}," display="inline"><semantics id="S4.F1.8.2.m2.1b"><mrow id="S4.F1.8.2.m2.1.1.1"><mrow id="S4.F1.8.2.m2.1.1.1.1.2" xref="S4.F1.8.2.m2.1.1.1.1.3.cmml"><msup id="S4.F1.8.2.m2.1.1.1.1.1.1" xref="S4.F1.8.2.m2.1.1.1.1.1.1.cmml"><mi id="S4.F1.8.2.m2.1.1.1.1.1.1.2" xref="S4.F1.8.2.m2.1.1.1.1.1.1.2.cmml">𝒘</mi><mrow id="S4.F1.8.2.m2.1.1.1.1.1.1.3" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S4.F1.8.2.m2.1.1.1.1.1.1.3.2" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S4.F1.8.2.m2.1.1.1.1.1.1.3.1" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="S4.F1.8.2.m2.1.1.1.1.1.1.3.3" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msup><mo id="S4.F1.8.2.m2.1.1.1.1.2.3" xref="S4.F1.8.2.m2.1.1.1.1.3.cmml">,</mo><msup id="S4.F1.8.2.m2.1.1.1.1.2.2" xref="S4.F1.8.2.m2.1.1.1.1.2.2.cmml"><mi id="S4.F1.8.2.m2.1.1.1.1.2.2.2" xref="S4.F1.8.2.m2.1.1.1.1.2.2.2.cmml">𝒘</mi><mi id="S4.F1.8.2.m2.1.1.1.1.2.2.3" xref="S4.F1.8.2.m2.1.1.1.1.2.2.3.cmml">t</mi></msup></mrow><mo id="S4.F1.8.2.m2.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.8.2.m2.1c"><list id="S4.F1.8.2.m2.1.1.1.1.3.cmml" xref="S4.F1.8.2.m2.1.1.1.1.2"><apply id="S4.F1.8.2.m2.1.1.1.1.1.1.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F1.8.2.m2.1.1.1.1.1.1.1.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1">superscript</csymbol><ci id="S4.F1.8.2.m2.1.1.1.1.1.1.2.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1.2">𝒘</ci><apply id="S4.F1.8.2.m2.1.1.1.1.1.1.3.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3"><minus id="S4.F1.8.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.1"></minus><ci id="S4.F1.8.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="S4.F1.8.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S4.F1.8.2.m2.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.F1.8.2.m2.1.1.1.1.2.2.cmml" xref="S4.F1.8.2.m2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.F1.8.2.m2.1.1.1.1.2.2.1.cmml" xref="S4.F1.8.2.m2.1.1.1.1.2.2">superscript</csymbol><ci id="S4.F1.8.2.m2.1.1.1.1.2.2.2.cmml" xref="S4.F1.8.2.m2.1.1.1.1.2.2.2">𝒘</ci><ci id="S4.F1.8.2.m2.1.1.1.1.2.2.3.cmml" xref="S4.F1.8.2.m2.1.1.1.1.2.2.3">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.8.2.m2.1d">\bm{w}^{t-1},\bm{w}^{t},</annotation></semantics></math> and <math id="S4.F1.9.3.m3.1" class="ltx_Math" alttext="\bm{w}^{t+1}" display="inline"><semantics id="S4.F1.9.3.m3.1b"><msup id="S4.F1.9.3.m3.1.1" xref="S4.F1.9.3.m3.1.1.cmml"><mi id="S4.F1.9.3.m3.1.1.2" xref="S4.F1.9.3.m3.1.1.2.cmml">𝒘</mi><mrow id="S4.F1.9.3.m3.1.1.3" xref="S4.F1.9.3.m3.1.1.3.cmml"><mi id="S4.F1.9.3.m3.1.1.3.2" xref="S4.F1.9.3.m3.1.1.3.2.cmml">t</mi><mo id="S4.F1.9.3.m3.1.1.3.1" xref="S4.F1.9.3.m3.1.1.3.1.cmml">+</mo><mn id="S4.F1.9.3.m3.1.1.3.3" xref="S4.F1.9.3.m3.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.F1.9.3.m3.1c"><apply id="S4.F1.9.3.m3.1.1.cmml" xref="S4.F1.9.3.m3.1.1"><csymbol cd="ambiguous" id="S4.F1.9.3.m3.1.1.1.cmml" xref="S4.F1.9.3.m3.1.1">superscript</csymbol><ci id="S4.F1.9.3.m3.1.1.2.cmml" xref="S4.F1.9.3.m3.1.1.2">𝒘</ci><apply id="S4.F1.9.3.m3.1.1.3.cmml" xref="S4.F1.9.3.m3.1.1.3"><plus id="S4.F1.9.3.m3.1.1.3.1.cmml" xref="S4.F1.9.3.m3.1.1.3.1"></plus><ci id="S4.F1.9.3.m3.1.1.3.2.cmml" xref="S4.F1.9.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="S4.F1.9.3.m3.1.1.3.3.cmml" xref="S4.F1.9.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.9.3.m3.1d">\bm{w}^{t+1}</annotation></semantics></math> are the global models in round <math id="S4.F1.10.4.m4.2" class="ltx_Math" alttext="t-1,t," display="inline"><semantics id="S4.F1.10.4.m4.2b"><mrow id="S4.F1.10.4.m4.2.2.1"><mrow id="S4.F1.10.4.m4.2.2.1.1.1" xref="S4.F1.10.4.m4.2.2.1.1.2.cmml"><mrow id="S4.F1.10.4.m4.2.2.1.1.1.1" xref="S4.F1.10.4.m4.2.2.1.1.1.1.cmml"><mi id="S4.F1.10.4.m4.2.2.1.1.1.1.2" xref="S4.F1.10.4.m4.2.2.1.1.1.1.2.cmml">t</mi><mo id="S4.F1.10.4.m4.2.2.1.1.1.1.1" xref="S4.F1.10.4.m4.2.2.1.1.1.1.1.cmml">−</mo><mn id="S4.F1.10.4.m4.2.2.1.1.1.1.3" xref="S4.F1.10.4.m4.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.F1.10.4.m4.2.2.1.1.1.2" xref="S4.F1.10.4.m4.2.2.1.1.2.cmml">,</mo><mi id="S4.F1.10.4.m4.1.1" xref="S4.F1.10.4.m4.1.1.cmml">t</mi></mrow><mo id="S4.F1.10.4.m4.2.2.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.10.4.m4.2c"><list id="S4.F1.10.4.m4.2.2.1.1.2.cmml" xref="S4.F1.10.4.m4.2.2.1.1.1"><apply id="S4.F1.10.4.m4.2.2.1.1.1.1.cmml" xref="S4.F1.10.4.m4.2.2.1.1.1.1"><minus id="S4.F1.10.4.m4.2.2.1.1.1.1.1.cmml" xref="S4.F1.10.4.m4.2.2.1.1.1.1.1"></minus><ci id="S4.F1.10.4.m4.2.2.1.1.1.1.2.cmml" xref="S4.F1.10.4.m4.2.2.1.1.1.1.2">𝑡</ci><cn type="integer" id="S4.F1.10.4.m4.2.2.1.1.1.1.3.cmml" xref="S4.F1.10.4.m4.2.2.1.1.1.1.3">1</cn></apply><ci id="S4.F1.10.4.m4.1.1.cmml" xref="S4.F1.10.4.m4.1.1">𝑡</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.10.4.m4.2d">t-1,t,</annotation></semantics></math> and <math id="S4.F1.11.5.m5.1" class="ltx_Math" alttext="t+1" display="inline"><semantics id="S4.F1.11.5.m5.1b"><mrow id="S4.F1.11.5.m5.1.1" xref="S4.F1.11.5.m5.1.1.cmml"><mi id="S4.F1.11.5.m5.1.1.2" xref="S4.F1.11.5.m5.1.1.2.cmml">t</mi><mo id="S4.F1.11.5.m5.1.1.1" xref="S4.F1.11.5.m5.1.1.1.cmml">+</mo><mn id="S4.F1.11.5.m5.1.1.3" xref="S4.F1.11.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F1.11.5.m5.1c"><apply id="S4.F1.11.5.m5.1.1.cmml" xref="S4.F1.11.5.m5.1.1"><plus id="S4.F1.11.5.m5.1.1.1.cmml" xref="S4.F1.11.5.m5.1.1.1"></plus><ci id="S4.F1.11.5.m5.1.1.2.cmml" xref="S4.F1.11.5.m5.1.1.2">𝑡</ci><cn type="integer" id="S4.F1.11.5.m5.1.1.3.cmml" xref="S4.F1.11.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.11.5.m5.1d">t+1</annotation></semantics></math>, respectively. <math id="S4.F1.12.6.m6.1" class="ltx_Math" alttext="\bm{w}^{*}" display="inline"><semantics id="S4.F1.12.6.m6.1b"><msup id="S4.F1.12.6.m6.1.1" xref="S4.F1.12.6.m6.1.1.cmml"><mi id="S4.F1.12.6.m6.1.1.2" xref="S4.F1.12.6.m6.1.1.2.cmml">𝒘</mi><mo id="S4.F1.12.6.m6.1.1.3" xref="S4.F1.12.6.m6.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.F1.12.6.m6.1c"><apply id="S4.F1.12.6.m6.1.1.cmml" xref="S4.F1.12.6.m6.1.1"><csymbol cd="ambiguous" id="S4.F1.12.6.m6.1.1.1.cmml" xref="S4.F1.12.6.m6.1.1">superscript</csymbol><ci id="S4.F1.12.6.m6.1.1.2.cmml" xref="S4.F1.12.6.m6.1.1.2">𝒘</ci><times id="S4.F1.12.6.m6.1.1.3.cmml" xref="S4.F1.12.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F1.12.6.m6.1d">\bm{w}^{*}</annotation></semantics></math> is the learnt global model without attack. The fake local model updates from the fake clients drag the global model towards the base model.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>MPAF</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">Figure <a href="#S4.F1" title="Figure 1 ‣ 4.1 Baseline Attacks ‣ 4 Our Attack ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates our MPAF. The attacker selects a <em id="S4.SS2.p1.3.1" class="ltx_emph ltx_font_italic">base model</em> <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\bm{w}^{\prime}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">𝒘</mi><mo id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝒘</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\bm{w}^{\prime}</annotation></semantics></math> that has low test accuracy. For instance, the attacker can select a randomly initialized model as the base model, whose test accuracy is near random guessing. In MPAF, the fake clients craft their local model updates to drag the global model towards the base model. Specifically, in the <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">t</annotation></semantics></math>-th round of FL, the fake clients generate fake local model updates, whose direction is determined via subtracting the current global model parameters from the base model parameters. Then the fake clients scale up their fake local model updates by a factor <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\lambda</annotation></semantics></math> to amplify their impact.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The key challenge of attacks based on fake clients is that the attacker has minimum knowledge about the FL system, i.e., only the global models received during training. Therefore, finding an effective way of leveraging such limited information becomes the critical component of attacks. In MPAF, our main idea is to force the global model to mimic the base model <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\bm{w}^{\prime}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msup id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">𝒘</mi><mo id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝒘</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\bm{w}^{\prime}</annotation></semantics></math>. Formally, we formulate our attack as the following optimization problem:</p>
<table id="Sx1.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3.m1.5" class="ltx_Math" alttext="\displaystyle\min_{\bm{g}_{i}^{t},i\in[n+1,n+m],t\in[0,T-1]}\|\bm{w}^{T}-\bm{w}^{\prime}\|," display="inline"><semantics id="S4.E3.m1.5a"><mrow id="S4.E3.m1.5.5.1" xref="S4.E3.m1.5.5.1.1.cmml"><mrow id="S4.E3.m1.5.5.1.1" xref="S4.E3.m1.5.5.1.1.cmml"><munder id="S4.E3.m1.5.5.1.1.2" xref="S4.E3.m1.5.5.1.1.2.cmml"><mi id="S4.E3.m1.5.5.1.1.2.2" xref="S4.E3.m1.5.5.1.1.2.2.cmml">min</mi><mrow id="S4.E3.m1.4.4.4.4" xref="S4.E3.m1.4.4.4.5.cmml"><mrow id="S4.E3.m1.3.3.3.3.1" xref="S4.E3.m1.3.3.3.3.1.cmml"><mrow id="S4.E3.m1.3.3.3.3.1.1.1" xref="S4.E3.m1.3.3.3.3.1.1.2.cmml"><msubsup id="S4.E3.m1.3.3.3.3.1.1.1.1" xref="S4.E3.m1.3.3.3.3.1.1.1.1.cmml"><mi id="S4.E3.m1.3.3.3.3.1.1.1.1.2.2" xref="S4.E3.m1.3.3.3.3.1.1.1.1.2.2.cmml">𝒈</mi><mi id="S4.E3.m1.3.3.3.3.1.1.1.1.2.3" xref="S4.E3.m1.3.3.3.3.1.1.1.1.2.3.cmml">i</mi><mi id="S4.E3.m1.3.3.3.3.1.1.1.1.3" xref="S4.E3.m1.3.3.3.3.1.1.1.1.3.cmml">t</mi></msubsup><mo id="S4.E3.m1.3.3.3.3.1.1.1.2" xref="S4.E3.m1.3.3.3.3.1.1.2.cmml">,</mo><mi id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml">i</mi></mrow><mo id="S4.E3.m1.3.3.3.3.1.4" xref="S4.E3.m1.3.3.3.3.1.4.cmml">∈</mo><mrow id="S4.E3.m1.3.3.3.3.1.3.2" xref="S4.E3.m1.3.3.3.3.1.3.3.cmml"><mo stretchy="false" id="S4.E3.m1.3.3.3.3.1.3.2.3" xref="S4.E3.m1.3.3.3.3.1.3.3.cmml">[</mo><mrow id="S4.E3.m1.3.3.3.3.1.2.1.1" xref="S4.E3.m1.3.3.3.3.1.2.1.1.cmml"><mi id="S4.E3.m1.3.3.3.3.1.2.1.1.2" xref="S4.E3.m1.3.3.3.3.1.2.1.1.2.cmml">n</mi><mo id="S4.E3.m1.3.3.3.3.1.2.1.1.1" xref="S4.E3.m1.3.3.3.3.1.2.1.1.1.cmml">+</mo><mn id="S4.E3.m1.3.3.3.3.1.2.1.1.3" xref="S4.E3.m1.3.3.3.3.1.2.1.1.3.cmml">1</mn></mrow><mo id="S4.E3.m1.3.3.3.3.1.3.2.4" xref="S4.E3.m1.3.3.3.3.1.3.3.cmml">,</mo><mrow id="S4.E3.m1.3.3.3.3.1.3.2.2" xref="S4.E3.m1.3.3.3.3.1.3.2.2.cmml"><mi id="S4.E3.m1.3.3.3.3.1.3.2.2.2" xref="S4.E3.m1.3.3.3.3.1.3.2.2.2.cmml">n</mi><mo id="S4.E3.m1.3.3.3.3.1.3.2.2.1" xref="S4.E3.m1.3.3.3.3.1.3.2.2.1.cmml">+</mo><mi id="S4.E3.m1.3.3.3.3.1.3.2.2.3" xref="S4.E3.m1.3.3.3.3.1.3.2.2.3.cmml">m</mi></mrow><mo stretchy="false" id="S4.E3.m1.3.3.3.3.1.3.2.5" xref="S4.E3.m1.3.3.3.3.1.3.3.cmml">]</mo></mrow></mrow><mo id="S4.E3.m1.4.4.4.4.3" xref="S4.E3.m1.4.4.4.5a.cmml">,</mo><mrow id="S4.E3.m1.4.4.4.4.2" xref="S4.E3.m1.4.4.4.4.2.cmml"><mi id="S4.E3.m1.4.4.4.4.2.3" xref="S4.E3.m1.4.4.4.4.2.3.cmml">t</mi><mo id="S4.E3.m1.4.4.4.4.2.2" xref="S4.E3.m1.4.4.4.4.2.2.cmml">∈</mo><mrow id="S4.E3.m1.4.4.4.4.2.1.1" xref="S4.E3.m1.4.4.4.4.2.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.4.4.4.4.2.1.1.2" xref="S4.E3.m1.4.4.4.4.2.1.2.cmml">[</mo><mn id="S4.E3.m1.2.2.2.2" xref="S4.E3.m1.2.2.2.2.cmml">0</mn><mo id="S4.E3.m1.4.4.4.4.2.1.1.3" xref="S4.E3.m1.4.4.4.4.2.1.2.cmml">,</mo><mrow id="S4.E3.m1.4.4.4.4.2.1.1.1" xref="S4.E3.m1.4.4.4.4.2.1.1.1.cmml"><mi id="S4.E3.m1.4.4.4.4.2.1.1.1.2" xref="S4.E3.m1.4.4.4.4.2.1.1.1.2.cmml">T</mi><mo id="S4.E3.m1.4.4.4.4.2.1.1.1.1" xref="S4.E3.m1.4.4.4.4.2.1.1.1.1.cmml">−</mo><mn id="S4.E3.m1.4.4.4.4.2.1.1.1.3" xref="S4.E3.m1.4.4.4.4.2.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.E3.m1.4.4.4.4.2.1.1.4" xref="S4.E3.m1.4.4.4.4.2.1.2.cmml">]</mo></mrow></mrow></mrow></munder><mo id="S4.E3.m1.5.5.1.1a" xref="S4.E3.m1.5.5.1.1.cmml">⁡</mo><mrow id="S4.E3.m1.5.5.1.1.1.1" xref="S4.E3.m1.5.5.1.1.1.2.cmml"><mo stretchy="false" id="S4.E3.m1.5.5.1.1.1.1.2" xref="S4.E3.m1.5.5.1.1.1.2.1.cmml">‖</mo><mrow id="S4.E3.m1.5.5.1.1.1.1.1" xref="S4.E3.m1.5.5.1.1.1.1.1.cmml"><msup id="S4.E3.m1.5.5.1.1.1.1.1.2" xref="S4.E3.m1.5.5.1.1.1.1.1.2.cmml"><mi id="S4.E3.m1.5.5.1.1.1.1.1.2.2" xref="S4.E3.m1.5.5.1.1.1.1.1.2.2.cmml">𝒘</mi><mi id="S4.E3.m1.5.5.1.1.1.1.1.2.3" xref="S4.E3.m1.5.5.1.1.1.1.1.2.3.cmml">T</mi></msup><mo id="S4.E3.m1.5.5.1.1.1.1.1.1" xref="S4.E3.m1.5.5.1.1.1.1.1.1.cmml">−</mo><msup id="S4.E3.m1.5.5.1.1.1.1.1.3" xref="S4.E3.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S4.E3.m1.5.5.1.1.1.1.1.3.2" xref="S4.E3.m1.5.5.1.1.1.1.1.3.2.cmml">𝒘</mi><mo id="S4.E3.m1.5.5.1.1.1.1.1.3.3" xref="S4.E3.m1.5.5.1.1.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S4.E3.m1.5.5.1.1.1.1.3" xref="S4.E3.m1.5.5.1.1.1.2.1.cmml">‖</mo></mrow></mrow><mo id="S4.E3.m1.5.5.1.2" xref="S4.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.5b"><apply id="S4.E3.m1.5.5.1.1.cmml" xref="S4.E3.m1.5.5.1"><apply id="S4.E3.m1.5.5.1.1.2.cmml" xref="S4.E3.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S4.E3.m1.5.5.1.1.2.1.cmml" xref="S4.E3.m1.5.5.1.1.2">subscript</csymbol><min id="S4.E3.m1.5.5.1.1.2.2.cmml" xref="S4.E3.m1.5.5.1.1.2.2"></min><apply id="S4.E3.m1.4.4.4.5.cmml" xref="S4.E3.m1.4.4.4.4"><csymbol cd="ambiguous" id="S4.E3.m1.4.4.4.5a.cmml" xref="S4.E3.m1.4.4.4.4.3">formulae-sequence</csymbol><apply id="S4.E3.m1.3.3.3.3.1.cmml" xref="S4.E3.m1.3.3.3.3.1"><in id="S4.E3.m1.3.3.3.3.1.4.cmml" xref="S4.E3.m1.3.3.3.3.1.4"></in><list id="S4.E3.m1.3.3.3.3.1.1.2.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1"><apply id="S4.E3.m1.3.3.3.3.1.1.1.1.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.3.3.3.3.1.1.1.1.1.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1">superscript</csymbol><apply id="S4.E3.m1.3.3.3.3.1.1.1.1.2.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.3.3.3.3.1.1.1.1.2.1.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1">subscript</csymbol><ci id="S4.E3.m1.3.3.3.3.1.1.1.1.2.2.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1.2.2">𝒈</ci><ci id="S4.E3.m1.3.3.3.3.1.1.1.1.2.3.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1.2.3">𝑖</ci></apply><ci id="S4.E3.m1.3.3.3.3.1.1.1.1.3.cmml" xref="S4.E3.m1.3.3.3.3.1.1.1.1.3">𝑡</ci></apply><ci id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1">𝑖</ci></list><interval closure="closed" id="S4.E3.m1.3.3.3.3.1.3.3.cmml" xref="S4.E3.m1.3.3.3.3.1.3.2"><apply id="S4.E3.m1.3.3.3.3.1.2.1.1.cmml" xref="S4.E3.m1.3.3.3.3.1.2.1.1"><plus id="S4.E3.m1.3.3.3.3.1.2.1.1.1.cmml" xref="S4.E3.m1.3.3.3.3.1.2.1.1.1"></plus><ci id="S4.E3.m1.3.3.3.3.1.2.1.1.2.cmml" xref="S4.E3.m1.3.3.3.3.1.2.1.1.2">𝑛</ci><cn type="integer" id="S4.E3.m1.3.3.3.3.1.2.1.1.3.cmml" xref="S4.E3.m1.3.3.3.3.1.2.1.1.3">1</cn></apply><apply id="S4.E3.m1.3.3.3.3.1.3.2.2.cmml" xref="S4.E3.m1.3.3.3.3.1.3.2.2"><plus id="S4.E3.m1.3.3.3.3.1.3.2.2.1.cmml" xref="S4.E3.m1.3.3.3.3.1.3.2.2.1"></plus><ci id="S4.E3.m1.3.3.3.3.1.3.2.2.2.cmml" xref="S4.E3.m1.3.3.3.3.1.3.2.2.2">𝑛</ci><ci id="S4.E3.m1.3.3.3.3.1.3.2.2.3.cmml" xref="S4.E3.m1.3.3.3.3.1.3.2.2.3">𝑚</ci></apply></interval></apply><apply id="S4.E3.m1.4.4.4.4.2.cmml" xref="S4.E3.m1.4.4.4.4.2"><in id="S4.E3.m1.4.4.4.4.2.2.cmml" xref="S4.E3.m1.4.4.4.4.2.2"></in><ci id="S4.E3.m1.4.4.4.4.2.3.cmml" xref="S4.E3.m1.4.4.4.4.2.3">𝑡</ci><interval closure="closed" id="S4.E3.m1.4.4.4.4.2.1.2.cmml" xref="S4.E3.m1.4.4.4.4.2.1.1"><cn type="integer" id="S4.E3.m1.2.2.2.2.cmml" xref="S4.E3.m1.2.2.2.2">0</cn><apply id="S4.E3.m1.4.4.4.4.2.1.1.1.cmml" xref="S4.E3.m1.4.4.4.4.2.1.1.1"><minus id="S4.E3.m1.4.4.4.4.2.1.1.1.1.cmml" xref="S4.E3.m1.4.4.4.4.2.1.1.1.1"></minus><ci id="S4.E3.m1.4.4.4.4.2.1.1.1.2.cmml" xref="S4.E3.m1.4.4.4.4.2.1.1.1.2">𝑇</ci><cn type="integer" id="S4.E3.m1.4.4.4.4.2.1.1.1.3.cmml" xref="S4.E3.m1.4.4.4.4.2.1.1.1.3">1</cn></apply></interval></apply></apply></apply><apply id="S4.E3.m1.5.5.1.1.1.2.cmml" xref="S4.E3.m1.5.5.1.1.1.1"><csymbol cd="latexml" id="S4.E3.m1.5.5.1.1.1.2.1.cmml" xref="S4.E3.m1.5.5.1.1.1.1.2">norm</csymbol><apply id="S4.E3.m1.5.5.1.1.1.1.1.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1"><minus id="S4.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.1"></minus><apply id="S4.E3.m1.5.5.1.1.1.1.1.2.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E3.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.2">superscript</csymbol><ci id="S4.E3.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.2.2">𝒘</ci><ci id="S4.E3.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.2.3">𝑇</ci></apply><apply id="S4.E3.m1.5.5.1.1.1.1.1.3.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E3.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.3.2">𝒘</ci><ci id="S4.E3.m1.5.5.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.5.5.1.1.1.1.1.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.5c">\displaystyle\min_{\bm{g}_{i}^{t},i\in[n+1,n+m],t\in[0,T-1]}\|\bm{w}^{T}-\bm{w}^{\prime}\|,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p2.8" class="ltx_p">where <math id="S4.SS2.p2.2.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p2.2.m1.1a"><mi id="S4.SS2.p2.2.m1.1.1" xref="S4.SS2.p2.2.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m1.1b"><ci id="S4.SS2.p2.2.m1.1.1.cmml" xref="S4.SS2.p2.2.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m1.1c">n</annotation></semantics></math> is the number of genuine clients, <math id="S4.SS2.p2.3.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS2.p2.3.m2.1a"><mi id="S4.SS2.p2.3.m2.1.1" xref="S4.SS2.p2.3.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m2.1b"><ci id="S4.SS2.p2.3.m2.1.1.cmml" xref="S4.SS2.p2.3.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m2.1c">m</annotation></semantics></math> is the number of fake clients (<math id="S4.SS2.p2.4.m3.4" class="ltx_Math" alttext="n+1,n+2,\cdots,n+m" display="inline"><semantics id="S4.SS2.p2.4.m3.4a"><mrow id="S4.SS2.p2.4.m3.4.4.3" xref="S4.SS2.p2.4.m3.4.4.4.cmml"><mrow id="S4.SS2.p2.4.m3.2.2.1.1" xref="S4.SS2.p2.4.m3.2.2.1.1.cmml"><mi id="S4.SS2.p2.4.m3.2.2.1.1.2" xref="S4.SS2.p2.4.m3.2.2.1.1.2.cmml">n</mi><mo id="S4.SS2.p2.4.m3.2.2.1.1.1" xref="S4.SS2.p2.4.m3.2.2.1.1.1.cmml">+</mo><mn id="S4.SS2.p2.4.m3.2.2.1.1.3" xref="S4.SS2.p2.4.m3.2.2.1.1.3.cmml">1</mn></mrow><mo id="S4.SS2.p2.4.m3.4.4.3.4" xref="S4.SS2.p2.4.m3.4.4.4.cmml">,</mo><mrow id="S4.SS2.p2.4.m3.3.3.2.2" xref="S4.SS2.p2.4.m3.3.3.2.2.cmml"><mi id="S4.SS2.p2.4.m3.3.3.2.2.2" xref="S4.SS2.p2.4.m3.3.3.2.2.2.cmml">n</mi><mo id="S4.SS2.p2.4.m3.3.3.2.2.1" xref="S4.SS2.p2.4.m3.3.3.2.2.1.cmml">+</mo><mn id="S4.SS2.p2.4.m3.3.3.2.2.3" xref="S4.SS2.p2.4.m3.3.3.2.2.3.cmml">2</mn></mrow><mo id="S4.SS2.p2.4.m3.4.4.3.5" xref="S4.SS2.p2.4.m3.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p2.4.m3.1.1" xref="S4.SS2.p2.4.m3.1.1.cmml">⋯</mi><mo id="S4.SS2.p2.4.m3.4.4.3.6" xref="S4.SS2.p2.4.m3.4.4.4.cmml">,</mo><mrow id="S4.SS2.p2.4.m3.4.4.3.3" xref="S4.SS2.p2.4.m3.4.4.3.3.cmml"><mi id="S4.SS2.p2.4.m3.4.4.3.3.2" xref="S4.SS2.p2.4.m3.4.4.3.3.2.cmml">n</mi><mo id="S4.SS2.p2.4.m3.4.4.3.3.1" xref="S4.SS2.p2.4.m3.4.4.3.3.1.cmml">+</mo><mi id="S4.SS2.p2.4.m3.4.4.3.3.3" xref="S4.SS2.p2.4.m3.4.4.3.3.3.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m3.4b"><list id="S4.SS2.p2.4.m3.4.4.4.cmml" xref="S4.SS2.p2.4.m3.4.4.3"><apply id="S4.SS2.p2.4.m3.2.2.1.1.cmml" xref="S4.SS2.p2.4.m3.2.2.1.1"><plus id="S4.SS2.p2.4.m3.2.2.1.1.1.cmml" xref="S4.SS2.p2.4.m3.2.2.1.1.1"></plus><ci id="S4.SS2.p2.4.m3.2.2.1.1.2.cmml" xref="S4.SS2.p2.4.m3.2.2.1.1.2">𝑛</ci><cn type="integer" id="S4.SS2.p2.4.m3.2.2.1.1.3.cmml" xref="S4.SS2.p2.4.m3.2.2.1.1.3">1</cn></apply><apply id="S4.SS2.p2.4.m3.3.3.2.2.cmml" xref="S4.SS2.p2.4.m3.3.3.2.2"><plus id="S4.SS2.p2.4.m3.3.3.2.2.1.cmml" xref="S4.SS2.p2.4.m3.3.3.2.2.1"></plus><ci id="S4.SS2.p2.4.m3.3.3.2.2.2.cmml" xref="S4.SS2.p2.4.m3.3.3.2.2.2">𝑛</ci><cn type="integer" id="S4.SS2.p2.4.m3.3.3.2.2.3.cmml" xref="S4.SS2.p2.4.m3.3.3.2.2.3">2</cn></apply><ci id="S4.SS2.p2.4.m3.1.1.cmml" xref="S4.SS2.p2.4.m3.1.1">⋯</ci><apply id="S4.SS2.p2.4.m3.4.4.3.3.cmml" xref="S4.SS2.p2.4.m3.4.4.3.3"><plus id="S4.SS2.p2.4.m3.4.4.3.3.1.cmml" xref="S4.SS2.p2.4.m3.4.4.3.3.1"></plus><ci id="S4.SS2.p2.4.m3.4.4.3.3.2.cmml" xref="S4.SS2.p2.4.m3.4.4.3.3.2">𝑛</ci><ci id="S4.SS2.p2.4.m3.4.4.3.3.3.cmml" xref="S4.SS2.p2.4.m3.4.4.3.3.3">𝑚</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m3.4c">n+1,n+2,\cdots,n+m</annotation></semantics></math> are the fake clients), <math id="S4.SS2.p2.5.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p2.5.m4.1a"><mi id="S4.SS2.p2.5.m4.1.1" xref="S4.SS2.p2.5.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m4.1b"><ci id="S4.SS2.p2.5.m4.1.1.cmml" xref="S4.SS2.p2.5.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m4.1c">T</annotation></semantics></math> is the number of FL rounds during training, <math id="S4.SS2.p2.6.m5.1" class="ltx_Math" alttext="\bm{w}^{T}" display="inline"><semantics id="S4.SS2.p2.6.m5.1a"><msup id="S4.SS2.p2.6.m5.1.1" xref="S4.SS2.p2.6.m5.1.1.cmml"><mi id="S4.SS2.p2.6.m5.1.1.2" xref="S4.SS2.p2.6.m5.1.1.2.cmml">𝒘</mi><mi id="S4.SS2.p2.6.m5.1.1.3" xref="S4.SS2.p2.6.m5.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m5.1b"><apply id="S4.SS2.p2.6.m5.1.1.cmml" xref="S4.SS2.p2.6.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.6.m5.1.1.1.cmml" xref="S4.SS2.p2.6.m5.1.1">superscript</csymbol><ci id="S4.SS2.p2.6.m5.1.1.2.cmml" xref="S4.SS2.p2.6.m5.1.1.2">𝒘</ci><ci id="S4.SS2.p2.6.m5.1.1.3.cmml" xref="S4.SS2.p2.6.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m5.1c">\bm{w}^{T}</annotation></semantics></math> is the learnt final global model, and <math id="S4.SS2.p2.7.m6.1" class="ltx_math_unparsed" alttext="\|\cdot\|" display="inline"><semantics id="S4.SS2.p2.7.m6.1a"><mrow id="S4.SS2.p2.7.m6.1b"><mo rspace="0em" id="S4.SS2.p2.7.m6.1.1">∥</mo><mo lspace="0em" rspace="0em" id="S4.SS2.p2.7.m6.1.2">⋅</mo><mo lspace="0em" id="S4.SS2.p2.7.m6.1.3">∥</mo></mrow><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m6.1c">\|\cdot\|</annotation></semantics></math> represents the <math id="S4.SS2.p2.8.m7.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S4.SS2.p2.8.m7.1a"><msub id="S4.SS2.p2.8.m7.1.1" xref="S4.SS2.p2.8.m7.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p2.8.m7.1.1.2" xref="S4.SS2.p2.8.m7.1.1.2.cmml">ℓ</mi><mn id="S4.SS2.p2.8.m7.1.1.3" xref="S4.SS2.p2.8.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.8.m7.1b"><apply id="S4.SS2.p2.8.m7.1.1.cmml" xref="S4.SS2.p2.8.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.8.m7.1.1.1.cmml" xref="S4.SS2.p2.8.m7.1.1">subscript</csymbol><ci id="S4.SS2.p2.8.m7.1.1.2.cmml" xref="S4.SS2.p2.8.m7.1.1.2">ℓ</ci><cn type="integer" id="S4.SS2.p2.8.m7.1.1.3.cmml" xref="S4.SS2.p2.8.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.8.m7.1c">\ell_{2}</annotation></semantics></math> norm.
Note that our problem formulation takes the entire training process into consideration. Specifically, in any FL round, the fake clients have the same goal of deviating the final global model towards a fixed attacker-chosen base model.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.6" class="ltx_p">We solve the optimization problem via driving the global model towards the base model in each FL round.
Specifically, in the <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">t</annotation></semantics></math>-th round of FL, the fake clients compute the direction of fake local model updates by subtracting the current global model from the base model, i.e., <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="\bm{d}=\bm{w}^{\prime}-\bm{w}^{t}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">𝒅</mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml"><msup id="S4.SS2.p3.2.m2.1.1.3.2" xref="S4.SS2.p3.2.m2.1.1.3.2.cmml"><mi id="S4.SS2.p3.2.m2.1.1.3.2.2" xref="S4.SS2.p3.2.m2.1.1.3.2.2.cmml">𝒘</mi><mo id="S4.SS2.p3.2.m2.1.1.3.2.3" xref="S4.SS2.p3.2.m2.1.1.3.2.3.cmml">′</mo></msup><mo id="S4.SS2.p3.2.m2.1.1.3.1" xref="S4.SS2.p3.2.m2.1.1.3.1.cmml">−</mo><msup id="S4.SS2.p3.2.m2.1.1.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.cmml"><mi id="S4.SS2.p3.2.m2.1.1.3.3.2" xref="S4.SS2.p3.2.m2.1.1.3.3.2.cmml">𝒘</mi><mi id="S4.SS2.p3.2.m2.1.1.3.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.3.cmml">t</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><eq id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></eq><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝒅</ci><apply id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><minus id="S4.SS2.p3.2.m2.1.1.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.1"></minus><apply id="S4.SS2.p3.2.m2.1.1.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.3.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.3.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2.2">𝒘</ci><ci id="S4.SS2.p3.2.m2.1.1.3.2.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2.3">′</ci></apply><apply id="S4.SS2.p3.2.m2.1.1.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.3.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.3.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3.2">𝒘</ci><ci id="S4.SS2.p3.2.m2.1.1.3.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\bm{d}=\bm{w}^{\prime}-\bm{w}^{t}</annotation></semantics></math>. The global model is closer to the base model if it is deviated to this direction. Then, the fake clients scale up <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="\bm{d}" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">𝒅</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">𝒅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\bm{d}</annotation></semantics></math> by a factor <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mi id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><ci id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">\lambda</annotation></semantics></math> to amplify the magnitude. The final fake local model update for a fake client <math id="S4.SS2.p3.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS2.p3.5.m5.1a"><mi id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><ci id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">i</annotation></semantics></math> in the <math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><mi id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><ci id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">t</annotation></semantics></math>-th round is as follows:</p>
<table id="Sx1.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4.m1.1" class="ltx_Math" alttext="\displaystyle\bm{g}^{t}_{i}=\lambda(\bm{w}^{\prime}-\bm{w}^{t})." display="inline"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><msubsup id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.3.2.2" xref="S4.E4.m1.1.1.1.1.3.2.2.cmml">𝒈</mi><mi id="S4.E4.m1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.3.3.cmml">i</mi><mi id="S4.E4.m1.1.1.1.1.3.2.3" xref="S4.E4.m1.1.1.1.1.3.2.3.cmml">t</mi></msubsup><mo id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.3.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><msup id="S4.E4.m1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml">𝒘</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml">′</mo></msup><mo id="S4.E4.m1.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="S4.E4.m1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝒘</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msup></mrow><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><eq id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2"></eq><apply id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.3">subscript</csymbol><apply id="S4.E4.m1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.1.1.3">superscript</csymbol><ci id="S4.E4.m1.1.1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2.2">𝒈</ci><ci id="S4.E4.m1.1.1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.1.1.3.2.3">𝑡</ci></apply><ci id="S4.E4.m1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.3">𝜆</ci><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"><minus id="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.2">𝒘</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.3">′</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.2">𝒘</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">\displaystyle\bm{g}^{t}_{i}=\lambda(\bm{w}^{\prime}-\bm{w}^{t}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p3.7" class="ltx_p">An attacker can choose a large <math id="S4.SS2.p3.7.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS2.p3.7.m1.1a"><mi id="S4.SS2.p3.7.m1.1.1" xref="S4.SS2.p3.7.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m1.1b"><ci id="S4.SS2.p3.7.m1.1.1.cmml" xref="S4.SS2.p3.7.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m1.1c">\lambda</annotation></semantics></math> to guarantee that the attack is still effective after the cloud server aggregates the fake local model updates from the fake clients and the genuine local model updates from the genuine clients.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Datasets and Global Model Architectures</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">We evaluate our attacks using multiple datasets, i.e., MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, Fashion-MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and Purchase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p2.2" class="ltx_p"><span id="S5.SS1.SSS1.p2.2.1" class="ltx_text ltx_font_bold">MNIST:</span>  MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> is a benchmark image classification dataset. There are 60,000 training examples and 10,000 testing examples of 10 classes, where each example is a hand-written digit image of size <math id="S5.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><mrow id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml"><mn id="S5.SS1.SSS1.p2.1.m1.1.1.2" xref="S5.SS1.SSS1.p2.1.m1.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS1.p2.1.m1.1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.SSS1.p2.1.m1.1.1.3" xref="S5.SS1.SSS1.p2.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b"><apply id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1"><times id="S5.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.2">32</cn><cn type="integer" id="S5.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">32\times 32</annotation></semantics></math>. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, we distributed the training examples to the clients with degree of non-IID <math id="S5.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="S5.SS1.SSS1.p2.2.m2.1a"><mrow id="S5.SS1.SSS1.p2.2.m2.1.1" xref="S5.SS1.SSS1.p2.2.m2.1.1.cmml"><mi id="S5.SS1.SSS1.p2.2.m2.1.1.2" xref="S5.SS1.SSS1.p2.2.m2.1.1.2.cmml">q</mi><mo id="S5.SS1.SSS1.p2.2.m2.1.1.1" xref="S5.SS1.SSS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS1.p2.2.m2.1.1.3" xref="S5.SS1.SSS1.p2.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.2.m2.1b"><apply id="S5.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS1.p2.2.m2.1.1"><eq id="S5.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.SSS1.p2.2.m2.1.1.1"></eq><ci id="S5.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.SSS1.p2.2.m2.1.1.2">𝑞</ci><cn type="float" id="S5.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.SSS1.p2.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.2.m2.1c">q=0.5</annotation></semantics></math> to simulate non-IID training data. We use the same CNN architecture for the global model as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p"><span id="S5.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Fashion-MNIST:</span>  Like MNIST, Fashion-MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> is a 10-class image classification dataset with 60,000 training examples and 10,000 testing examples. Similar to MNIST, we distribute the training examples to the clients with degree of non-IID <math id="S5.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="S5.SS1.SSS1.p3.1.m1.1a"><mrow id="S5.SS1.SSS1.p3.1.m1.1.1" xref="S5.SS1.SSS1.p3.1.m1.1.1.cmml"><mi id="S5.SS1.SSS1.p3.1.m1.1.1.2" xref="S5.SS1.SSS1.p3.1.m1.1.1.2.cmml">q</mi><mo id="S5.SS1.SSS1.p3.1.m1.1.1.1" xref="S5.SS1.SSS1.p3.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS1.p3.1.m1.1.1.3" xref="S5.SS1.SSS1.p3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p3.1.m1.1b"><apply id="S5.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p3.1.m1.1.1"><eq id="S5.SS1.SSS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.p3.1.m1.1.1.1"></eq><ci id="S5.SS1.SSS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.SSS1.p3.1.m1.1.1.2">𝑞</ci><cn type="float" id="S5.SS1.SSS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.SSS1.p3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p3.1.m1.1c">q=0.5</annotation></semantics></math>. We use the same CNN as the one for MNIST.</p>
</div>
<div id="S5.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p4.1" class="ltx_p"><span id="S5.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Purchase:</span>  Purchase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is a 100-class classification dataset, whose goal is to predict customer’s purchase styles. There are 197,324 purchase records in Purchase, each of which has 600 binary features. We split the dataset into 180,000 training records and 17,324 test records. We distribute the training data evenly to the clients. We use a fully connected neural network as the global model architecture. There is one hidden layer in the network, whose number of neurons is 1,024 and activation function is Tanh.</p>
</div>
<figure id="S5.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x2.png" id="S5.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x3.png" id="S5.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x4.png" id="S5.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x5.png" id="S5.F2.sf4.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x6.png" id="S5.F2.sf5.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F2.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x7.png" id="S5.F2.sf6.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf1a" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x8.png" id="S5.F2.sf1a.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf1a.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf2a" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x9.png" id="S5.F2.sf2a.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf2a.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F2.sf3a" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x10.png" id="S5.F2.sf3a.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.sf3a.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S5.F2.3.2" class="ltx_text" style="font-size:90%;">Test accuracy of the global models learnt by different FL methods under the three attacks when the fraction of fake clients varies. The datasets are MNIST (first row), Fashion-MNIST (second row) and
Purchase (third row).</span></figcaption>
</figure>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>FL and Attack Settings</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.12" class="ltx_p">For all three datasets, we assume there are <math id="S5.SS1.SSS2.p1.1.m1.2" class="ltx_Math" alttext="n=1,000" display="inline"><semantics id="S5.SS1.SSS2.p1.1.m1.2a"><mrow id="S5.SS1.SSS2.p1.1.m1.2.3" xref="S5.SS1.SSS2.p1.1.m1.2.3.cmml"><mi id="S5.SS1.SSS2.p1.1.m1.2.3.2" xref="S5.SS1.SSS2.p1.1.m1.2.3.2.cmml">n</mi><mo id="S5.SS1.SSS2.p1.1.m1.2.3.1" xref="S5.SS1.SSS2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S5.SS1.SSS2.p1.1.m1.2.3.3.2" xref="S5.SS1.SSS2.p1.1.m1.2.3.3.1.cmml"><mn id="S5.SS1.SSS2.p1.1.m1.1.1" xref="S5.SS1.SSS2.p1.1.m1.1.1.cmml">1</mn><mo id="S5.SS1.SSS2.p1.1.m1.2.3.3.2.1" xref="S5.SS1.SSS2.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S5.SS1.SSS2.p1.1.m1.2.2" xref="S5.SS1.SSS2.p1.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.1.m1.2b"><apply id="S5.SS1.SSS2.p1.1.m1.2.3.cmml" xref="S5.SS1.SSS2.p1.1.m1.2.3"><eq id="S5.SS1.SSS2.p1.1.m1.2.3.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.2.3.1"></eq><ci id="S5.SS1.SSS2.p1.1.m1.2.3.2.cmml" xref="S5.SS1.SSS2.p1.1.m1.2.3.2">𝑛</ci><list id="S5.SS1.SSS2.p1.1.m1.2.3.3.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.2.3.3.2"><cn type="integer" id="S5.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.1.1">1</cn><cn type="integer" id="S5.SS1.SSS2.p1.1.m1.2.2.cmml" xref="S5.SS1.SSS2.p1.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.1.m1.2c">n=1,000</annotation></semantics></math> genuine clients in total. We define the fraction of fake clients as the number of injected fake clients divided by the number of genuine clients, i.e., <math id="S5.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="m/n" display="inline"><semantics id="S5.SS1.SSS2.p1.2.m2.1a"><mrow id="S5.SS1.SSS2.p1.2.m2.1.1" xref="S5.SS1.SSS2.p1.2.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p1.2.m2.1.1.2" xref="S5.SS1.SSS2.p1.2.m2.1.1.2.cmml">m</mi><mo id="S5.SS1.SSS2.p1.2.m2.1.1.1" xref="S5.SS1.SSS2.p1.2.m2.1.1.1.cmml">/</mo><mi id="S5.SS1.SSS2.p1.2.m2.1.1.3" xref="S5.SS1.SSS2.p1.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.2.m2.1b"><apply id="S5.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1"><divide id="S5.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1.1"></divide><ci id="S5.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1.2">𝑚</ci><ci id="S5.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.2.m2.1c">m/n</annotation></semantics></math>. By default, we assume there are <math id="S5.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="m=100" display="inline"><semantics id="S5.SS1.SSS2.p1.3.m3.1a"><mrow id="S5.SS1.SSS2.p1.3.m3.1.1" xref="S5.SS1.SSS2.p1.3.m3.1.1.cmml"><mi id="S5.SS1.SSS2.p1.3.m3.1.1.2" xref="S5.SS1.SSS2.p1.3.m3.1.1.2.cmml">m</mi><mo id="S5.SS1.SSS2.p1.3.m3.1.1.1" xref="S5.SS1.SSS2.p1.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p1.3.m3.1.1.3" xref="S5.SS1.SSS2.p1.3.m3.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.3.m3.1b"><apply id="S5.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1"><eq id="S5.SS1.SSS2.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1.1"></eq><ci id="S5.SS1.SSS2.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1.2">𝑚</ci><cn type="integer" id="S5.SS1.SSS2.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.3.m3.1c">m=100</annotation></semantics></math> fake clients, i.e., the fraction of injected fake clients is 10%, unless otherwise mentioned. In each round of FL, the genuine clients train their local model using SGD with batch size of 32, 32, and 128 for MNIST, Fashion-MNIST, and Purchase, respectively. We set the global learning rate <math id="S5.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S5.SS1.SSS2.p1.4.m4.1a"><mi id="S5.SS1.SSS2.p1.4.m4.1.1" xref="S5.SS1.SSS2.p1.4.m4.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.4.m4.1b"><ci id="S5.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS2.p1.4.m4.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.4.m4.1c">\eta</annotation></semantics></math> to 0.01, 0.01, and 0.005 for the three datasets, respectively. We use different settings for different datasets to achieve high test accuracy in non-adversarial settings. In each FL round, we assume the cloud server randomly samples <math id="S5.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS1.SSS2.p1.5.m5.1a"><mi id="S5.SS1.SSS2.p1.5.m5.1.1" xref="S5.SS1.SSS2.p1.5.m5.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.5.m5.1b"><ci id="S5.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS2.p1.5.m5.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.5.m5.1c">\beta</annotation></semantics></math> fraction of clients to participate in training. We set the default value of <math id="S5.SS1.SSS2.p1.6.m6.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS1.SSS2.p1.6.m6.1a"><mi id="S5.SS1.SSS2.p1.6.m6.1.1" xref="S5.SS1.SSS2.p1.6.m6.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.6.m6.1b"><ci id="S5.SS1.SSS2.p1.6.m6.1.1.cmml" xref="S5.SS1.SSS2.p1.6.m6.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.6.m6.1c">\beta</annotation></semantics></math> to 1, i.e., the server selects all clients in each round during training. We will evaluate the impact of <math id="S5.SS1.SSS2.p1.7.m7.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS1.SSS2.p1.7.m7.1a"><mi id="S5.SS1.SSS2.p1.7.m7.1.1" xref="S5.SS1.SSS2.p1.7.m7.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.7.m7.1b"><ci id="S5.SS1.SSS2.p1.7.m7.1.1.cmml" xref="S5.SS1.SSS2.p1.7.m7.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.7.m7.1c">\beta</annotation></semantics></math> in our experiments. We further set the number of FL rounds <math id="S5.SS1.SSS2.p1.8.m8.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS1.SSS2.p1.8.m8.1a"><mi id="S5.SS1.SSS2.p1.8.m8.1.1" xref="S5.SS1.SSS2.p1.8.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.8.m8.1b"><ci id="S5.SS1.SSS2.p1.8.m8.1.1.cmml" xref="S5.SS1.SSS2.p1.8.m8.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.8.m8.1c">T</annotation></semantics></math> to <math id="S5.SS1.SSS2.p1.9.m9.3" class="ltx_Math" alttext="\frac{200}{\beta},\frac{200}{\beta}," display="inline"><semantics id="S5.SS1.SSS2.p1.9.m9.3a"><mrow id="S5.SS1.SSS2.p1.9.m9.3.3.1"><mrow id="S5.SS1.SSS2.p1.9.m9.3.3.1.1.2" xref="S5.SS1.SSS2.p1.9.m9.3.3.1.1.1.cmml"><mfrac id="S5.SS1.SSS2.p1.9.m9.1.1" xref="S5.SS1.SSS2.p1.9.m9.1.1.cmml"><mn id="S5.SS1.SSS2.p1.9.m9.1.1.2" xref="S5.SS1.SSS2.p1.9.m9.1.1.2.cmml">200</mn><mi id="S5.SS1.SSS2.p1.9.m9.1.1.3" xref="S5.SS1.SSS2.p1.9.m9.1.1.3.cmml">β</mi></mfrac><mo id="S5.SS1.SSS2.p1.9.m9.3.3.1.1.2.1" xref="S5.SS1.SSS2.p1.9.m9.3.3.1.1.1.cmml">,</mo><mfrac id="S5.SS1.SSS2.p1.9.m9.2.2" xref="S5.SS1.SSS2.p1.9.m9.2.2.cmml"><mn id="S5.SS1.SSS2.p1.9.m9.2.2.2" xref="S5.SS1.SSS2.p1.9.m9.2.2.2.cmml">200</mn><mi id="S5.SS1.SSS2.p1.9.m9.2.2.3" xref="S5.SS1.SSS2.p1.9.m9.2.2.3.cmml">β</mi></mfrac></mrow><mo id="S5.SS1.SSS2.p1.9.m9.3.3.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.9.m9.3b"><list id="S5.SS1.SSS2.p1.9.m9.3.3.1.1.1.cmml" xref="S5.SS1.SSS2.p1.9.m9.3.3.1.1.2"><apply id="S5.SS1.SSS2.p1.9.m9.1.1.cmml" xref="S5.SS1.SSS2.p1.9.m9.1.1"><divide id="S5.SS1.SSS2.p1.9.m9.1.1.1.cmml" xref="S5.SS1.SSS2.p1.9.m9.1.1"></divide><cn type="integer" id="S5.SS1.SSS2.p1.9.m9.1.1.2.cmml" xref="S5.SS1.SSS2.p1.9.m9.1.1.2">200</cn><ci id="S5.SS1.SSS2.p1.9.m9.1.1.3.cmml" xref="S5.SS1.SSS2.p1.9.m9.1.1.3">𝛽</ci></apply><apply id="S5.SS1.SSS2.p1.9.m9.2.2.cmml" xref="S5.SS1.SSS2.p1.9.m9.2.2"><divide id="S5.SS1.SSS2.p1.9.m9.2.2.1.cmml" xref="S5.SS1.SSS2.p1.9.m9.2.2"></divide><cn type="integer" id="S5.SS1.SSS2.p1.9.m9.2.2.2.cmml" xref="S5.SS1.SSS2.p1.9.m9.2.2.2">200</cn><ci id="S5.SS1.SSS2.p1.9.m9.2.2.3.cmml" xref="S5.SS1.SSS2.p1.9.m9.2.2.3">𝛽</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.9.m9.3c">\frac{200}{\beta},\frac{200}{\beta},</annotation></semantics></math> and <math id="S5.SS1.SSS2.p1.10.m10.1" class="ltx_Math" alttext="\frac{500}{\beta}" display="inline"><semantics id="S5.SS1.SSS2.p1.10.m10.1a"><mfrac id="S5.SS1.SSS2.p1.10.m10.1.1" xref="S5.SS1.SSS2.p1.10.m10.1.1.cmml"><mn id="S5.SS1.SSS2.p1.10.m10.1.1.2" xref="S5.SS1.SSS2.p1.10.m10.1.1.2.cmml">500</mn><mi id="S5.SS1.SSS2.p1.10.m10.1.1.3" xref="S5.SS1.SSS2.p1.10.m10.1.1.3.cmml">β</mi></mfrac><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.10.m10.1b"><apply id="S5.SS1.SSS2.p1.10.m10.1.1.cmml" xref="S5.SS1.SSS2.p1.10.m10.1.1"><divide id="S5.SS1.SSS2.p1.10.m10.1.1.1.cmml" xref="S5.SS1.SSS2.p1.10.m10.1.1"></divide><cn type="integer" id="S5.SS1.SSS2.p1.10.m10.1.1.2.cmml" xref="S5.SS1.SSS2.p1.10.m10.1.1.2">500</cn><ci id="S5.SS1.SSS2.p1.10.m10.1.1.3.cmml" xref="S5.SS1.SSS2.p1.10.m10.1.1.3">𝛽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.10.m10.1c">\frac{500}{\beta}</annotation></semantics></math> for the three datasets. This is because a smaller <math id="S5.SS1.SSS2.p1.11.m11.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS1.SSS2.p1.11.m11.1a"><mi id="S5.SS1.SSS2.p1.11.m11.1.1" xref="S5.SS1.SSS2.p1.11.m11.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.11.m11.1b"><ci id="S5.SS1.SSS2.p1.11.m11.1.1.cmml" xref="S5.SS1.SSS2.p1.11.m11.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.11.m11.1c">\beta</annotation></semantics></math> indicates fewer clients in each FL round, thus needs more rounds to converge. For our attacks, we set the default value of the scaling factor <math id="S5.SS1.SSS2.p1.12.m12.1" class="ltx_Math" alttext="\lambda=1\times 10^{6}" display="inline"><semantics id="S5.SS1.SSS2.p1.12.m12.1a"><mrow id="S5.SS1.SSS2.p1.12.m12.1.1" xref="S5.SS1.SSS2.p1.12.m12.1.1.cmml"><mi id="S5.SS1.SSS2.p1.12.m12.1.1.2" xref="S5.SS1.SSS2.p1.12.m12.1.1.2.cmml">λ</mi><mo id="S5.SS1.SSS2.p1.12.m12.1.1.1" xref="S5.SS1.SSS2.p1.12.m12.1.1.1.cmml">=</mo><mrow id="S5.SS1.SSS2.p1.12.m12.1.1.3" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.cmml"><mn id="S5.SS1.SSS2.p1.12.m12.1.1.3.2" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS2.p1.12.m12.1.1.3.1" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.1.cmml">×</mo><msup id="S5.SS1.SSS2.p1.12.m12.1.1.3.3" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3.cmml"><mn id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.2" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3.2.cmml">10</mn><mn id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.3" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3.3.cmml">6</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.12.m12.1b"><apply id="S5.SS1.SSS2.p1.12.m12.1.1.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1"><eq id="S5.SS1.SSS2.p1.12.m12.1.1.1.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.1"></eq><ci id="S5.SS1.SSS2.p1.12.m12.1.1.2.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.2">𝜆</ci><apply id="S5.SS1.SSS2.p1.12.m12.1.1.3.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3"><times id="S5.SS1.SSS2.p1.12.m12.1.1.3.1.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.1"></times><cn type="integer" id="S5.SS1.SSS2.p1.12.m12.1.1.3.2.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.2">1</cn><apply id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.1.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3">superscript</csymbol><cn type="integer" id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.2.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3.2">10</cn><cn type="integer" id="S5.SS1.SSS2.p1.12.m12.1.1.3.3.3.cmml" xref="S5.SS1.SSS2.p1.12.m12.1.1.3.3.3">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.12.m12.1c">\lambda=1\times 10^{6}</annotation></semantics></math> and we will explore its impact. We repeat the attacks in each experiment for 20 times with different random seeds and report the average results.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Evaluation Metric</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">We focus on untargeted model poisoning attacks in this work, whose goal is to decrease the test accuracy of the learnt global model. Therefore, we use the test accuracy of the learnt global models as our metric. A lower test accuracy indicates a stronger attack.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x11.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x12.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x13.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.4.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.2.1" class="ltx_text" style="font-size:90%;">Impact of the sample rate <math id="S5.F3.2.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.F3.2.1.m1.1b"><mi id="S5.F3.2.1.m1.1.1" xref="S5.F3.2.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.F3.2.1.m1.1c"><ci id="S5.F3.2.1.m1.1.1.cmml" xref="S5.F3.2.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.1.m1.1d">\beta</annotation></semantics></math> on the test accuracy of the global models learnt by Trimmed-mean. </span></figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x14.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x15.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2203.08669/assets/x16.png" id="S5.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="174" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.4.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S5.F4.2.1" class="ltx_text" style="font-size:90%;">Impact of the scaling factor <math id="S5.F4.2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.F4.2.1.m1.1b"><mi id="S5.F4.2.1.m1.1.1" xref="S5.F4.2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.F4.2.1.m1.1c"><ci id="S5.F4.2.1.m1.1.1.cmml" xref="S5.F4.2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.1.m1.1d">\lambda</annotation></semantics></math> on the test accuracy of the global models learnt by Trimmed-mean.</span></figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Results</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_bold">Impact of the fraction of fake clients:</span>  We explore the impact of the fraction of fake clients on two baseline attacks (i.e., random attack and history attack) and MPAF. Figure <a href="#S5.F2" title="Figure 2 ‣ 5.1.1 Datasets and Global Model Architectures ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the test accuracy of the global models learnt by different FL methods when the fraction of fake clients varies on the three datasets. We observe that when FedAvg is used, both baseline attacks and MPAF can reduce the test accuracy of the learnt global models to random guessing with only 1% fake clients. However, when classical defenses (e.g., Median and Trimmed-mean) are applied, MPAF can still significantly decrease the test accuracy while the baseline attacks cannot. For instance, on Purchase dataset, MPAF reduces the test accuracy of the global model learnt with Trimmed-mean by 32% when there are 10% fake clients, while the baseline attacks can only decrease the test accuracy by at most 4%. Moreover, we also observe that MPAF is more effective when the fraction of fake clients is larger. For instance, on Purchase dataset when Trimmed-mean is used, the test accuracy that MPAF can reduce increases from 32% to 49% when the fraction of malicious clients increases from 10% to 25%.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.4" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Impact of the sample rate <math id="S5.SS2.p2.1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS2.p2.1.1.m1.1a"><mi id="S5.SS2.p2.1.1.m1.1.1" xref="S5.SS2.p2.1.1.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.1.m1.1b"><ci id="S5.SS2.p2.1.1.m1.1.1.cmml" xref="S5.SS2.p2.1.1.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.1.m1.1c">\beta</annotation></semantics></math>:</span>  We evaluate the effectiveness of MPAF when the server samples different fractions of clients in each FL round. Figure <a href="#S5.F3" title="Figure 3 ‣ 5.1.3 Evaluation Metric ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the test accuracy of the global models learnt with Trimmed-mean on all three datasets. We omit the results of non-robust FedAvg for simplicity as the test accuracy is consistently close to random guessing under MPAF. We observe that the sample rate <math id="S5.SS2.p2.2.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS2.p2.2.m1.1a"><mi id="S5.SS2.p2.2.m1.1.1" xref="S5.SS2.p2.2.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m1.1b"><ci id="S5.SS2.p2.2.m1.1.1.cmml" xref="S5.SS2.p2.2.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m1.1c">\beta</annotation></semantics></math> does not have much impact on MPAF and that MPAF can significantly decrease the test accuracy when <math id="S5.SS2.p2.3.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS2.p2.3.m2.1a"><mi id="S5.SS2.p2.3.m2.1.1" xref="S5.SS2.p2.3.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m2.1b"><ci id="S5.SS2.p2.3.m2.1.1.cmml" xref="S5.SS2.p2.3.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m2.1c">\beta</annotation></semantics></math> ranges from 0.01 to 1.00. The previous claim that FedAvg and classical defenses are robust to untargeted model poisoning attacks when <math id="S5.SS2.p2.4.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS2.p2.4.m3.1a"><mi id="S5.SS2.p2.4.m3.1.1" xref="S5.SS2.p2.4.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m3.1b"><ci id="S5.SS2.p2.4.m3.1.1.cmml" xref="S5.SS2.p2.4.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m3.1c">\beta</annotation></semantics></math> is small <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> does not apply to our attack. This is because their claim is based on the assumption that an attacker can only compromise a small fraction of genuine clients.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.6" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Impact of the scaling factor <math id="S5.SS2.p3.1.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.p3.1.1.m1.1a"><mi id="S5.SS2.p3.1.1.m1.1.1" xref="S5.SS2.p3.1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.1.m1.1b"><ci id="S5.SS2.p3.1.1.m1.1.1.cmml" xref="S5.SS2.p3.1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.1.m1.1c">\lambda</annotation></semantics></math>:</span> 
We explore the impact of the scaling factor on MPAF. Figure <a href="#S5.F4" title="Figure 4 ‣ 5.1.3 Evaluation Metric ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the test accuracy of the global models learnt by Trimmed-mean on all three datasets. We observe that the test accuracy first decreases as <math id="S5.SS2.p3.2.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.p3.2.m1.1a"><mi id="S5.SS2.p3.2.m1.1.1" xref="S5.SS2.p3.2.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m1.1b"><ci id="S5.SS2.p3.2.m1.1.1.cmml" xref="S5.SS2.p3.2.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m1.1c">\lambda</annotation></semantics></math> increases, and then remains almost unchanged when <math id="S5.SS2.p3.3.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.p3.3.m2.1a"><mi id="S5.SS2.p3.3.m2.1.1" xref="S5.SS2.p3.3.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m2.1b"><ci id="S5.SS2.p3.3.m2.1.1.cmml" xref="S5.SS2.p3.3.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m2.1c">\lambda</annotation></semantics></math> further increases. Our results show that even though the attacker does not know the hyperparameters of FL (e.g., the global learning rate <math id="S5.SS2.p3.4.m3.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S5.SS2.p3.4.m3.1a"><mi id="S5.SS2.p3.4.m3.1.1" xref="S5.SS2.p3.4.m3.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.4.m3.1b"><ci id="S5.SS2.p3.4.m3.1.1.cmml" xref="S5.SS2.p3.4.m3.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.4.m3.1c">\eta</annotation></semantics></math>), by choosing a reasonably large value for <math id="S5.SS2.p3.5.m4.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS2.p3.5.m4.1a"><mi id="S5.SS2.p3.5.m4.1.1" xref="S5.SS2.p3.5.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.5.m4.1b"><ci id="S5.SS2.p3.5.m4.1.1.cmml" xref="S5.SS2.p3.5.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.5.m4.1c">\lambda</annotation></semantics></math>, e.g., <math id="S5.SS2.p3.6.m5.1" class="ltx_Math" alttext="\lambda\geq 1" display="inline"><semantics id="S5.SS2.p3.6.m5.1a"><mrow id="S5.SS2.p3.6.m5.1.1" xref="S5.SS2.p3.6.m5.1.1.cmml"><mi id="S5.SS2.p3.6.m5.1.1.2" xref="S5.SS2.p3.6.m5.1.1.2.cmml">λ</mi><mo id="S5.SS2.p3.6.m5.1.1.1" xref="S5.SS2.p3.6.m5.1.1.1.cmml">≥</mo><mn id="S5.SS2.p3.6.m5.1.1.3" xref="S5.SS2.p3.6.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.6.m5.1b"><apply id="S5.SS2.p3.6.m5.1.1.cmml" xref="S5.SS2.p3.6.m5.1.1"><geq id="S5.SS2.p3.6.m5.1.1.1.cmml" xref="S5.SS2.p3.6.m5.1.1.1"></geq><ci id="S5.SS2.p3.6.m5.1.1.2.cmml" xref="S5.SS2.p3.6.m5.1.1.2">𝜆</ci><cn type="integer" id="S5.SS2.p3.6.m5.1.1.3.cmml" xref="S5.SS2.p3.6.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.6.m5.1c">\lambda\geq 1</annotation></semantics></math> in our experiments, MPAF can reduce the test accuracy of the global model significantly.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Norm Clipping as A Countermeasure</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.11" class="ltx_p">A recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> has proposed norm clipping as a countermeasure against backdoor attacks in federated learning. Specifically, the server selects a norm threshold <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p1.1.m1.1a"><mi id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><ci id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">M</annotation></semantics></math>, and clips all local model updates whose <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S6.p1.2.m2.1a"><msub id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S6.p1.2.m2.1.1.2" xref="S6.p1.2.m2.1.1.2.cmml">ℓ</mi><mn id="S6.p1.2.m2.1.1.3" xref="S6.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><apply id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S6.p1.2.m2.1.1.1.cmml" xref="S6.p1.2.m2.1.1">subscript</csymbol><ci id="S6.p1.2.m2.1.1.2.cmml" xref="S6.p1.2.m2.1.1.2">ℓ</ci><cn type="integer" id="S6.p1.2.m2.1.1.3.cmml" xref="S6.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">\ell_{2}</annotation></semantics></math>-norm is larger than <math id="S6.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p1.3.m3.1a"><mi id="S6.p1.3.m3.1.1" xref="S6.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p1.3.m3.1b"><ci id="S6.p1.3.m3.1.1.cmml" xref="S6.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">M</annotation></semantics></math> such that their <math id="S6.p1.4.m4.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S6.p1.4.m4.1a"><msub id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml"><mi mathvariant="normal" id="S6.p1.4.m4.1.1.2" xref="S6.p1.4.m4.1.1.2.cmml">ℓ</mi><mn id="S6.p1.4.m4.1.1.3" xref="S6.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><apply id="S6.p1.4.m4.1.1.cmml" xref="S6.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S6.p1.4.m4.1.1.1.cmml" xref="S6.p1.4.m4.1.1">subscript</csymbol><ci id="S6.p1.4.m4.1.1.2.cmml" xref="S6.p1.4.m4.1.1.2">ℓ</ci><cn type="integer" id="S6.p1.4.m4.1.1.3.cmml" xref="S6.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">\ell_{2}</annotation></semantics></math>-norm becomes <math id="S6.p1.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p1.5.m5.1a"><mi id="S6.p1.5.m5.1.1" xref="S6.p1.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p1.5.m5.1b"><ci id="S6.p1.5.m5.1.1.cmml" xref="S6.p1.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.5.m5.1c">M</annotation></semantics></math>. The local model updates whose <math id="S6.p1.6.m6.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S6.p1.6.m6.1a"><msub id="S6.p1.6.m6.1.1" xref="S6.p1.6.m6.1.1.cmml"><mi mathvariant="normal" id="S6.p1.6.m6.1.1.2" xref="S6.p1.6.m6.1.1.2.cmml">ℓ</mi><mn id="S6.p1.6.m6.1.1.3" xref="S6.p1.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.6.m6.1b"><apply id="S6.p1.6.m6.1.1.cmml" xref="S6.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S6.p1.6.m6.1.1.1.cmml" xref="S6.p1.6.m6.1.1">subscript</csymbol><ci id="S6.p1.6.m6.1.1.2.cmml" xref="S6.p1.6.m6.1.1.2">ℓ</ci><cn type="integer" id="S6.p1.6.m6.1.1.3.cmml" xref="S6.p1.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.6.m6.1c">\ell_{2}</annotation></semantics></math>-norms are no larger than <math id="S6.p1.7.m7.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p1.7.m7.1a"><mi id="S6.p1.7.m7.1.1" xref="S6.p1.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p1.7.m7.1b"><ci id="S6.p1.7.m7.1.1.cmml" xref="S6.p1.7.m7.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.7.m7.1c">M</annotation></semantics></math> remain unchanged. Formally, a local model update <math id="S6.p1.8.m8.1" class="ltx_Math" alttext="\bm{g}" display="inline"><semantics id="S6.p1.8.m8.1a"><mi id="S6.p1.8.m8.1.1" xref="S6.p1.8.m8.1.1.cmml">𝒈</mi><annotation-xml encoding="MathML-Content" id="S6.p1.8.m8.1b"><ci id="S6.p1.8.m8.1.1.cmml" xref="S6.p1.8.m8.1.1">𝒈</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.8.m8.1c">\bm{g}</annotation></semantics></math> becomes <math id="S6.p1.9.m9.4" class="ltx_Math" alttext="\frac{\bm{g}}{\max(1,\|\bm{g}\|_{2}/M)}" display="inline"><semantics id="S6.p1.9.m9.4a"><mfrac id="S6.p1.9.m9.4.4" xref="S6.p1.9.m9.4.4.cmml"><mi id="S6.p1.9.m9.4.4.6" xref="S6.p1.9.m9.4.4.6.cmml">𝒈</mi><mrow id="S6.p1.9.m9.4.4.4.4" xref="S6.p1.9.m9.4.4.4.5.cmml"><mi id="S6.p1.9.m9.2.2.2.2" xref="S6.p1.9.m9.2.2.2.2.cmml">max</mi><mo id="S6.p1.9.m9.4.4.4.4a" xref="S6.p1.9.m9.4.4.4.5.cmml">⁡</mo><mrow id="S6.p1.9.m9.4.4.4.4.1" xref="S6.p1.9.m9.4.4.4.5.cmml"><mo stretchy="false" id="S6.p1.9.m9.4.4.4.4.1.2" xref="S6.p1.9.m9.4.4.4.5.cmml">(</mo><mn id="S6.p1.9.m9.3.3.3.3" xref="S6.p1.9.m9.3.3.3.3.cmml">1</mn><mo id="S6.p1.9.m9.4.4.4.4.1.3" xref="S6.p1.9.m9.4.4.4.5.cmml">,</mo><mrow id="S6.p1.9.m9.4.4.4.4.1.1" xref="S6.p1.9.m9.4.4.4.4.1.1.cmml"><msub id="S6.p1.9.m9.4.4.4.4.1.1.2" xref="S6.p1.9.m9.4.4.4.4.1.1.2.cmml"><mrow id="S6.p1.9.m9.4.4.4.4.1.1.2.2.2" xref="S6.p1.9.m9.4.4.4.4.1.1.2.2.1.cmml"><mo stretchy="false" id="S6.p1.9.m9.4.4.4.4.1.1.2.2.2.1" xref="S6.p1.9.m9.4.4.4.4.1.1.2.2.1.1.cmml">‖</mo><mi id="S6.p1.9.m9.1.1.1.1" xref="S6.p1.9.m9.1.1.1.1.cmml">𝒈</mi><mo stretchy="false" id="S6.p1.9.m9.4.4.4.4.1.1.2.2.2.2" xref="S6.p1.9.m9.4.4.4.4.1.1.2.2.1.1.cmml">‖</mo></mrow><mn id="S6.p1.9.m9.4.4.4.4.1.1.2.3" xref="S6.p1.9.m9.4.4.4.4.1.1.2.3.cmml">2</mn></msub><mo id="S6.p1.9.m9.4.4.4.4.1.1.1" xref="S6.p1.9.m9.4.4.4.4.1.1.1.cmml">/</mo><mi id="S6.p1.9.m9.4.4.4.4.1.1.3" xref="S6.p1.9.m9.4.4.4.4.1.1.3.cmml">M</mi></mrow><mo stretchy="false" id="S6.p1.9.m9.4.4.4.4.1.4" xref="S6.p1.9.m9.4.4.4.5.cmml">)</mo></mrow></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S6.p1.9.m9.4b"><apply id="S6.p1.9.m9.4.4.cmml" xref="S6.p1.9.m9.4.4"><divide id="S6.p1.9.m9.4.4.5.cmml" xref="S6.p1.9.m9.4.4"></divide><ci id="S6.p1.9.m9.4.4.6.cmml" xref="S6.p1.9.m9.4.4.6">𝒈</ci><apply id="S6.p1.9.m9.4.4.4.5.cmml" xref="S6.p1.9.m9.4.4.4.4"><max id="S6.p1.9.m9.2.2.2.2.cmml" xref="S6.p1.9.m9.2.2.2.2"></max><cn type="integer" id="S6.p1.9.m9.3.3.3.3.cmml" xref="S6.p1.9.m9.3.3.3.3">1</cn><apply id="S6.p1.9.m9.4.4.4.4.1.1.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1"><divide id="S6.p1.9.m9.4.4.4.4.1.1.1.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.1"></divide><apply id="S6.p1.9.m9.4.4.4.4.1.1.2.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.2"><csymbol cd="ambiguous" id="S6.p1.9.m9.4.4.4.4.1.1.2.1.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.2">subscript</csymbol><apply id="S6.p1.9.m9.4.4.4.4.1.1.2.2.1.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.2.2.2"><csymbol cd="latexml" id="S6.p1.9.m9.4.4.4.4.1.1.2.2.1.1.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.2.2.2.1">norm</csymbol><ci id="S6.p1.9.m9.1.1.1.1.cmml" xref="S6.p1.9.m9.1.1.1.1">𝒈</ci></apply><cn type="integer" id="S6.p1.9.m9.4.4.4.4.1.1.2.3.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.2.3">2</cn></apply><ci id="S6.p1.9.m9.4.4.4.4.1.1.3.cmml" xref="S6.p1.9.m9.4.4.4.4.1.1.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.9.m9.4c">\frac{\bm{g}}{\max(1,\|\bm{g}\|_{2}/M)}</annotation></semantics></math> after norm clipping. The largest <math id="S6.p1.10.m10.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S6.p1.10.m10.1a"><msub id="S6.p1.10.m10.1.1" xref="S6.p1.10.m10.1.1.cmml"><mi mathvariant="normal" id="S6.p1.10.m10.1.1.2" xref="S6.p1.10.m10.1.1.2.cmml">ℓ</mi><mn id="S6.p1.10.m10.1.1.3" xref="S6.p1.10.m10.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.p1.10.m10.1b"><apply id="S6.p1.10.m10.1.1.cmml" xref="S6.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S6.p1.10.m10.1.1.1.cmml" xref="S6.p1.10.m10.1.1">subscript</csymbol><ci id="S6.p1.10.m10.1.1.2.cmml" xref="S6.p1.10.m10.1.1.2">ℓ</ci><cn type="integer" id="S6.p1.10.m10.1.1.3.cmml" xref="S6.p1.10.m10.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.10.m10.1c">\ell_{2}</annotation></semantics></math>-norm of the clipped local model updates is <math id="S6.p1.11.m11.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p1.11.m11.1a"><mi id="S6.p1.11.m11.1.1" xref="S6.p1.11.m11.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p1.11.m11.1b"><ci id="S6.p1.11.m11.1.1.cmml" xref="S6.p1.11.m11.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.11.m11.1c">M</annotation></semantics></math>. Therefore, the impact of the malicious local model updates will be limited. As a result, the backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> that rely on scaled local model updates will have lower attack success rate when norm clipping is adopted as a countermeasure.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.3" class="ltx_p">We note that the idea of using norm clipping as a countermeasure is not limited to backdoor attacks. In fact, it may also be leveraged as a countermeasure against untargeted attacks that involve scaling. In MPAF, we use a scaling factor <math id="S6.p2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.p2.1.m1.1a"><mi id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><ci id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">\lambda</annotation></semantics></math> to increase the impact of fake local model updates during aggregation. Therefore, it is intuitive to apply norm clipping as a countermeasure against MPAF. We empirically evaluate the effectiveness of MPAF when norm clipping is used as a countermeasure. Specifically, we use our default setting for Fashion-MNIST dataset and Trimmed-mean as the aggregation rule. Before using Trimmed-mean to aggregate the local model updates, we clip them with norm threshold <math id="S6.p2.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p2.2.m2.1a"><mi id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><ci id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">M</annotation></semantics></math>, where we vary the value of <math id="S6.p2.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p2.3.m3.1a"><mi id="S6.p2.3.m3.1.1" xref="S6.p2.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p2.3.m3.1b"><ci id="S6.p2.3.m3.1.1.cmml" xref="S6.p2.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.3.m3.1c">M</annotation></semantics></math> in our experiments. We omit the results of FedAvg for simplicity as the test accuracy is consistently close to random guessing under MPAF.</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2203.08669/assets/x17.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="237" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F5.4.2.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S6.F5.2.1" class="ltx_text" style="font-size:90%;">Impact of the norm clipping bound <math id="S6.F5.2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.F5.2.1.m1.1b"><mi id="S6.F5.2.1.m1.1.1" xref="S6.F5.2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.F5.2.1.m1.1c"><ci id="S6.F5.2.1.m1.1.1.cmml" xref="S6.F5.2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.2.1.m1.1d">M</annotation></semantics></math> on the test accuracy of the global model learnt by Trimmed-mean on Fashion-MNIST.</span></figcaption>
</figure>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.9" class="ltx_p">Figure <a href="#S6.F5" title="Figure 5 ‣ 6 Norm Clipping as A Countermeasure ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the test accuracy of the global model learnt by Trimmed-mean on Fashion-MNIST. We use <math id="S6.p3.1.m1.1" class="ltx_Math" alttext="M\rightarrow\infty" display="inline"><semantics id="S6.p3.1.m1.1a"><mrow id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml"><mi id="S6.p3.1.m1.1.1.2" xref="S6.p3.1.m1.1.1.2.cmml">M</mi><mo stretchy="false" id="S6.p3.1.m1.1.1.1" xref="S6.p3.1.m1.1.1.1.cmml">→</mo><mi mathvariant="normal" id="S6.p3.1.m1.1.1.3" xref="S6.p3.1.m1.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><apply id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1"><ci id="S6.p3.1.m1.1.1.1.cmml" xref="S6.p3.1.m1.1.1.1">→</ci><ci id="S6.p3.1.m1.1.1.2.cmml" xref="S6.p3.1.m1.1.1.2">𝑀</ci><infinity id="S6.p3.1.m1.1.1.3.cmml" xref="S6.p3.1.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">M\rightarrow\infty</annotation></semantics></math> to represent the case when there is no norm clipping. We observe that MPAF can still effectively decrease the test accuracy of the global model when norm clipping is deployed. Specifically, under no attack, the global model achieves the largest test accuracy of 0.85 when <math id="S6.p3.2.m2.1" class="ltx_Math" alttext="M\rightarrow\infty" display="inline"><semantics id="S6.p3.2.m2.1a"><mrow id="S6.p3.2.m2.1.1" xref="S6.p3.2.m2.1.1.cmml"><mi id="S6.p3.2.m2.1.1.2" xref="S6.p3.2.m2.1.1.2.cmml">M</mi><mo stretchy="false" id="S6.p3.2.m2.1.1.1" xref="S6.p3.2.m2.1.1.1.cmml">→</mo><mi mathvariant="normal" id="S6.p3.2.m2.1.1.3" xref="S6.p3.2.m2.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.2.m2.1b"><apply id="S6.p3.2.m2.1.1.cmml" xref="S6.p3.2.m2.1.1"><ci id="S6.p3.2.m2.1.1.1.cmml" xref="S6.p3.2.m2.1.1.1">→</ci><ci id="S6.p3.2.m2.1.1.2.cmml" xref="S6.p3.2.m2.1.1.2">𝑀</ci><infinity id="S6.p3.2.m2.1.1.3.cmml" xref="S6.p3.2.m2.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.2.m2.1c">M\rightarrow\infty</annotation></semantics></math>. However, under MPAF, the global model achieves the largest test accuracy of 0.68 when <math id="S6.p3.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p3.3.m3.1a"><mi id="S6.p3.3.m3.1.1" xref="S6.p3.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p3.3.m3.1b"><ci id="S6.p3.3.m3.1.1.cmml" xref="S6.p3.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.3.m3.1c">M</annotation></semantics></math> is around 100, which represents 0.17 accuracy loss.
We also observe that the difference between the test accuracy of the global model under MPAF and the one under no attack is smaller as <math id="S6.p3.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p3.4.m4.1a"><mi id="S6.p3.4.m4.1.1" xref="S6.p3.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p3.4.m4.1b"><ci id="S6.p3.4.m4.1.1.cmml" xref="S6.p3.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.4.m4.1c">M</annotation></semantics></math> decreases. This is because more fake local model updates are clipped as <math id="S6.p3.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p3.5.m5.1a"><mi id="S6.p3.5.m5.1.1" xref="S6.p3.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p3.5.m5.1b"><ci id="S6.p3.5.m5.1.1.cmml" xref="S6.p3.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.5.m5.1c">M</annotation></semantics></math> decreases. However, as <math id="S6.p3.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p3.6.m6.1a"><mi id="S6.p3.6.m6.1.1" xref="S6.p3.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p3.6.m6.1b"><ci id="S6.p3.6.m6.1.1.cmml" xref="S6.p3.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.6.m6.1c">M</annotation></semantics></math> decreases, the test accuracy under no attack also decreases,
e.g., <math id="S6.p3.7.m7.1" class="ltx_Math" alttext="M&lt;100" display="inline"><semantics id="S6.p3.7.m7.1a"><mrow id="S6.p3.7.m7.1.1" xref="S6.p3.7.m7.1.1.cmml"><mi id="S6.p3.7.m7.1.1.2" xref="S6.p3.7.m7.1.1.2.cmml">M</mi><mo id="S6.p3.7.m7.1.1.1" xref="S6.p3.7.m7.1.1.1.cmml">&lt;</mo><mn id="S6.p3.7.m7.1.1.3" xref="S6.p3.7.m7.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.7.m7.1b"><apply id="S6.p3.7.m7.1.1.cmml" xref="S6.p3.7.m7.1.1"><lt id="S6.p3.7.m7.1.1.1.cmml" xref="S6.p3.7.m7.1.1.1"></lt><ci id="S6.p3.7.m7.1.1.2.cmml" xref="S6.p3.7.m7.1.1.2">𝑀</ci><cn type="integer" id="S6.p3.7.m7.1.1.3.cmml" xref="S6.p3.7.m7.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.7.m7.1c">M&lt;100</annotation></semantics></math> in Figure <a href="#S6.F5" title="Figure 5 ‣ 6 Norm Clipping as A Countermeasure ‣ MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> leads to a test accuracy that is much lower than that when <math id="S6.p3.8.m8.1" class="ltx_Math" alttext="M\rightarrow\infty" display="inline"><semantics id="S6.p3.8.m8.1a"><mrow id="S6.p3.8.m8.1.1" xref="S6.p3.8.m8.1.1.cmml"><mi id="S6.p3.8.m8.1.1.2" xref="S6.p3.8.m8.1.1.2.cmml">M</mi><mo stretchy="false" id="S6.p3.8.m8.1.1.1" xref="S6.p3.8.m8.1.1.1.cmml">→</mo><mi mathvariant="normal" id="S6.p3.8.m8.1.1.3" xref="S6.p3.8.m8.1.1.3.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.8.m8.1b"><apply id="S6.p3.8.m8.1.1.cmml" xref="S6.p3.8.m8.1.1"><ci id="S6.p3.8.m8.1.1.1.cmml" xref="S6.p3.8.m8.1.1.1">→</ci><ci id="S6.p3.8.m8.1.1.2.cmml" xref="S6.p3.8.m8.1.1.2">𝑀</ci><infinity id="S6.p3.8.m8.1.1.3.cmml" xref="S6.p3.8.m8.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.8.m8.1c">M\rightarrow\infty</annotation></semantics></math>. This is because when <math id="S6.p3.9.m9.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S6.p3.9.m9.1a"><mi id="S6.p3.9.m9.1.1" xref="S6.p3.9.m9.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.p3.9.m9.1b"><ci id="S6.p3.9.m9.1.1.cmml" xref="S6.p3.9.m9.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.9.m9.1c">M</annotation></semantics></math> decreases, more benign local model updates are also clipped, which results in a less accurate global model. Our results indicate that MPAF is still effective in reducing the test accuracy of the global model, even if both classical defenses (e.g., Trimmed-mean) and norm clipping are adopted.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Discussion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we proposed MPAF, the first model poisoning attack to FL that is based on fake clients. We considered a minimum-knowledge setting for the attacker and showed that our attack is effective even when classical defenses and norm clipping are applied, highlighting the need for more advanced defenses against model poisoning attacks based on fake clients.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">We hope our work can inspire more future studies on model poisoning attacks and their defenses. First, since it is unrealistic for an attacker to compromise a large fraction of genuine clients, it is more interesting to explore attacks based on fake clients. For instance, an interesting future work is to improve MPAF with extra knowledge, e.g., training data/model obtained from a similar learning task.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">Second, existing untargeted model poisoning attacks based on compromised genuine clients (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>) formulate round-wise optimization problems. Specifically, in each individual round of FL, the compromised genuine clients solve an independent problem to obtain the malicious local model updates. The solutions to these independent problems may contradict to each other. As a result, such malicious local model updates in different rounds may cancel each other out, leading to sub-optimal overall attack effect. On the contrary, our MPAF leverages a simple yet effective way of formulating a global optimization problem that deviates the global model towards a fixed base model.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">Third, it is an interesting future work to extend our MPAF to perform targeted model poisoning attacks. Specifically, an attacker can choose a base model that has an attacker-desired targeted behavior, e.g., a backdoored base model.
By forcing the learnt global model to be close to a backdoored base model, the learnt global model may have the same backdoor behavior as the base model and predict attacker-chosen target labels for attacker-chosen test inputs.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank the anonymous reviewers for constructive reviews and comments. This work was supported by National Science Foundation under grant No. 2112562 and 1937786, as well as Army Research Office under grant No. W911NF2110182.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Android-x86 run android on your pc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">https://www.android-x86.org/.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Federated learning: Collaborative machine learning without centralized training
data.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://ai.googleblog.com/2017/04/federated-learning-collaborative.html</a><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Machine learning ledger orchestration for drug discovery (melloddy).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">https://www.melloddy.eu/.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Noxplayer, the perfect android emulator to play mobile games on pc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">https://www.bignox.com/.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Utilization of fate in risk management of credit in small and micro
enterprises.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">https://www.fedai.org/cases/utilization-of-fate-in-risk-management-of-credit-in-small-and-micro-enterprises/.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
The world’s first cloud-based android gaming platform.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">https://www.bluestacks.com/.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Acquire valued shoppers challenge at kaggle.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/c/acquire-valued-shoppers-challenge/data" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.kaggle.com/c/acquire-valued-shoppers-challenge/data</a><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">, Last
accessed April, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly
Shmatikov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">How to backdoor federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AISTATS</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Analyzing federated learning through an adversarial lens.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Machine learning with adversaries: Byzantine tolerant gradient
descent.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Xiaoyu Cao, Minghong Fang, Jia Liu, and Neil Zhenqiang Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">FLTrust: Byzantine-robust federated learning via trust
bootstrapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NDSS</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Provably secure federated learning against malicious clients.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Yudong Chen, Lili Su, and Jiaming Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Distributed statistical machine learning in adversarial settings:
Byzantine gradient descent.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">POMACS</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Local model poisoning attacks to byzantine-robust federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">USENIX Security Symposium</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Yann Fraboni, Richard Vidal, and Marco Lorenzi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Free-rider attacks on model aggregation in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AISTATS</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Yann LeCun, Corinna Cortes, and CJ Burges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Mnist handwritten digit database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Available: http://yann. lecun. com/exdb/mnist</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 1998.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Jierui Lin, Min Du, and Jian Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Free-riders in federated learning: Attacks and defenses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1911.12560</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AISTATS</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
El Mahdi El Mhamdi, Rachid Guerraoui, and Sébastien Rouault.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">The hidden vulnerability of distributed learning in byzantium.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Shashank Rajput, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Detox: A redundancy-based framework for faster and more robust
gradient aggregation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NIPS</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Virat Shejwalkar, Amir Houmansadr, Peter Kairouz, and Daniel Ramage.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Back to the drawing board: A critical evaluation of poisoning attacks
on production federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">S&amp;P</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Shiqi Shen, Shruti Tople, and Prateek Saxena.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Auror: Defending against poisoning attacks in collaborative deep
learning systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACSAC</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H Brendan McMahan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Can you really backdoor federated learning?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">FL-NeurIPS 2019 Workshop</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Vale Tolpegin, Stacey Truex, Mehmet Emre Gursoy, and Ling Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Data poisoning attacks against federated learning systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.08432</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Han Xiao, Kashif Rasul, and Roland Vollgraf.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Chulin Xie, Minghao Chen, Pin-Yu Chen, and Bo Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Crfl: Certifiably robust federated learning against backdoor attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Dba: Distributed backdoor attacks against federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Fall of empires: Breaking byzantine-tolerant sgd by inner product
manipulation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">UAI</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Cong Xie, Sanmi Koyejo, and Indranil Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Zeno: Distributed stochastic gradient descent with suspicion-based
fault-tolerance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Byzantine-robust distributed learning: Towards optimal statistical
rates.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2203.08668" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2203.08669" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2203.08669">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2203.08669" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2203.08670" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 09:03:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
