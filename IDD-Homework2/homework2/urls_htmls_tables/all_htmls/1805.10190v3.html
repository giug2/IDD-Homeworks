<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1805.10190] Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces</title><meta property="og:description" content="This paper presents the machine learning architecture of the Snips Voice Platform, a software solution to perform Spoken Language Understanding on microprocessors typical of IoT devices. The embedded inference is fast …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1805.10190">

<!--Generated on Fri Mar 15 23:30:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Snips Voice Platform: an embedded 
<br class="ltx_break">Spoken Language Understanding system 
<br class="ltx_break">for private-by-design voice interfaces</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

<span id="id1.1.id1" class="ltx_tabular ltx_align_middle">
<span class="ltx_tbody">
<span id="id1.1.id1.1.1" class="ltx_tr">
<span id="id1.1.id1.1.1.1" class="ltx_td ltx_align_center">Alice Coucke</span>
<span id="id1.1.id1.1.1.2" class="ltx_td ltx_align_center">Alaa Saade</span>
<span id="id1.1.id1.1.1.3" class="ltx_td ltx_align_center">Adrien Ball</span></span>
<span id="id1.1.id1.2.2" class="ltx_tr">
<span id="id1.1.id1.2.2.1" class="ltx_td ltx_align_center">Théodore Bluche</span>
<span id="id1.1.id1.2.2.2" class="ltx_td ltx_align_center">Alexandre Caulier</span>
<span id="id1.1.id1.2.2.3" class="ltx_td ltx_align_center">David Leroy</span></span>
<span id="id1.1.id1.3.3" class="ltx_tr">
<span id="id1.1.id1.3.3.1" class="ltx_td ltx_align_center">Clément Doumouro</span>
<span id="id1.1.id1.3.3.2" class="ltx_td ltx_align_center">Thibault Gisselbrecht</span>
<span id="id1.1.id1.3.3.3" class="ltx_td ltx_align_center">Francesco Caltagirone</span></span>
<span id="id1.1.id1.4.4" class="ltx_tr">
<span id="id1.1.id1.4.4.1" class="ltx_td ltx_align_center">Thibaut Lavril</span>
<span id="id1.1.id1.4.4.2" class="ltx_td ltx_align_center">Maël Primet</span>
<span id="id1.1.id1.4.4.3" class="ltx_td ltx_align_center">Joseph Dureau</span></span>
<span id="id1.1.id1.5.5" class="ltx_tr">
<span id="id1.1.id1.5.5.1" class="ltx_td"></span>
<span id="id1.1.id1.5.5.2" class="ltx_td ltx_align_center">Snips</span>
<span id="id1.1.id1.5.5.3" class="ltx_td"></span></span>
<span id="id1.1.id1.6.6" class="ltx_tr">
<span id="id1.1.id1.6.6.1" class="ltx_td"></span>
<span id="id1.1.id1.6.6.2" class="ltx_td ltx_align_center">Paris, France</span>
<span id="id1.1.id1.6.6.3" class="ltx_td"></span></span>
</span>
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">This paper presents the machine learning architecture of the Snips Voice Platform, a software solution to perform Spoken Language Understanding on microprocessors typical of IoT devices. The embedded inference is fast and accurate while enforcing privacy by design, as no personal user data is ever collected. Focusing on Automatic Speech Recognition and Natural Language Understanding, we detail our approach to training high-performance Machine Learning models that are small enough to run in real-time on small devices. Additionally, we describe a data generation procedure that provides sufficient, high-quality training data without compromising user privacy.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Over the last years, thanks in part to steady improvements brought by deep learning approaches to speech recognition <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib33" title="" class="ltx_ref">mohamed2012acoustic </a>; <a href="#bib.bib17" title="" class="ltx_ref">hinton2012deep </a>; <a href="#bib.bib14" title="" class="ltx_ref">graves2013speech </a>; <a href="#bib.bib5" title="" class="ltx_ref">bahdanau2016end </a></cite>, voice interfaces have greatly evolved from spotting limited and predetermined keywords to understanding arbitrary formulations of a given intention. They also became much more reliable, with state-of-the-art speech recognition engines reaching human level in English <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">xiong2016achieving </a></cite>. This achievement unlocked many practical applications of voice assistants which are now used in many fields from customer support <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">customersupport1 </a>; <a href="#bib.bib47" title="" class="ltx_ref">customersupport2 </a></cite>, to autonomous cars <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">autonomouscars </a></cite>, or smart homes <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">smarthome1 </a>; <a href="#bib.bib26" title="" class="ltx_ref">smarthome2 </a></cite>. In particular, smart speaker adoption by the public is on the rise, with a recent study showing that nearly 20% of U.S. adults reported having a smart speaker at home<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.voicebot.ai/2018/03/07/new-voicebot-report-says-nearly-20-u-s-adults-smart-speakers/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.voicebot.ai/2018/03/07/new-voicebot-report-says-nearly-20-u-s-adults-smart-speakers/</a></span></span></span>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">These recent developments however raise questions about user privacy – especially since unique speaker identification is an active field of research using voice as a sensitive biometric feature <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib58" title="" class="ltx_ref">voicebiometrics </a></cite>. The CNIL (French Data Protection Authority)<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In French: <a target="_blank" href="https://www.cnil.fr/fr/enceintes-intelligentes-des-assistants-vocaux-connectes-votre-vie-privee" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.cnil.fr/fr/enceintes-intelligentes-des-assistants-vocaux-connectes-votre-vie-privee</a></span></span></span> advises owners of connected speakers to switch off the microphone when possible and to warn guests of the presence of such a device in their home. The General Data Protection Regulation which harmonizes data privacy laws across the European Union<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.eugdpr.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.eugdpr.org/</a></span></span></span> indeed requires companies to ask for explicit consent before collecting user data.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Some of the most popular commercial solutions for voice assistants include Microsoft’s <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">Cortana</span>, Google’s <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">DialogFlow</span>, IBM’s <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">Watson</span>, or Amazon <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">Alexa</span> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib23" title="" class="ltx_ref">ASK17 </a></cite>. In this paper, we introduce a competing solution, the Snips Voice Platform which, unlike the previous ones, is completely cloud independent and runs offline on typical IoT microprocessors, thus guaranteeing privacy by design, with no user data ever collected nor stored. The Natural Language Understanding component of the platform is already open source <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">SnipsNLU </a></cite>, while the other components will be opensourced in the future.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">The aim of this paper is to contribute to the collective effort towards ever more private and efficient cloud-independent voice interfaces. To this end, we devote this introduction to a brief description of the Snips Ecosystem and of some of the design principles behind the Snips Voice Platform.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>The Snips Ecosystem</h3>

<div id="S1.SS1.p1" class="ltx_para ltx_noindent">
<p id="S1.SS1.p1.1" class="ltx_p">The Snips ecosystem comprises a web console<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://console.snips.ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://console.snips.ai</a></span></span></span> to build voice assistants and train the corresponding Spoken Language Understanding (SLU) engine, made of an Automatic Speech Recognition (ASR) engine and a Natural Language Understanding (NLU) engine. The console can be used as a self-service development environment by businesses or individuals, or through professional services. The Snips Voice Platform is free for non-commercial use. Since its launch in Summer 2017, over 23,000 Snips voice assistants have been created by over 13,000 developers. The languages currently supported by the Snips platform are English, French and German, with additional NLU support for Spanish and Korean. More languages are added regularly.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para ltx_noindent">
<p id="S1.SS1.p2.1" class="ltx_p">An <span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_italic">assistant</span> is composed of a set of <span id="S1.SS1.p2.1.2" class="ltx_text ltx_font_italic">skills</span> – e.g. <span id="S1.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">SmartLights</span>, <span id="S1.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">SmartThermostat</span>, or <span id="S1.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">SmartOven</span> skills for a <span id="S1.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">SmartHome</span> assistant – that may be either selected from preexisting ones in a <span id="S1.SS1.p2.1.7" class="ltx_text ltx_font_italic">skill store</span> or created from scratch on the web console. A given skill may contain several <span id="S1.SS1.p2.1.8" class="ltx_text ltx_font_italic">intents</span>, or user intention – e.g. <span id="S1.SS1.p2.1.9" class="ltx_text ltx_font_typewriter">SwitchLightOn</span> and <span id="S1.SS1.p2.1.10" class="ltx_text ltx_font_typewriter">SwitchLightOff</span> for a <span id="S1.SS1.p2.1.11" class="ltx_text ltx_font_typewriter">SmartLights</span> skill. Finally, a given intent is bound to a list of <span id="S1.SS1.p2.1.12" class="ltx_text ltx_font_italic">entities</span> that must be extracted from the user’s query – e.g. <span id="S1.SS1.p2.1.13" class="ltx_text ltx_font_typewriter">room</span> for the <span id="S1.SS1.p2.1.14" class="ltx_text ltx_font_typewriter">SwitchLightOn</span> intent. We call <em id="S1.SS1.p2.1.15" class="ltx_emph ltx_font_italic">slot</em> the particular value of an entity in a query – e.g. <span id="S1.SS1.p2.1.16" class="ltx_text ltx_font_typewriter">kitchen</span> for the entity <span id="S1.SS1.p2.1.17" class="ltx_text ltx_font_typewriter">room</span>. When a user speaks to the assistant, the SLU engine trained on the different skills will handle the request by successively converting speech into text, classifying the user’s intent, and extracting the relevant slots.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para ltx_noindent">
<p id="S1.SS1.p3.1" class="ltx_p">Once the user’s request has been processed and based on the information that has been extracted from the query and fed to the device, a dialog management component is responsible for providing a feedback to the user, or performing an <span id="S1.SS1.p3.1.1" class="ltx_text ltx_font_italic">action</span>. It may take multiple forms, such as an audio response via speech synthesis or a direct action on a connected device – e.g. actually turning on the lights for a <span id="S1.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">SmartLights</span> skill. Figure <a href="#S1.F1" title="Figure 1 ‣ 1.1 The Snips Ecosystem ‣ 1 Introduction ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the typical interaction flow.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<br class="ltx_break">
<p id="S1.F1.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S1.F1.1.1.1" class="ltx_text"><img src="/html/1805.10190/assets/x1.png" id="S1.F1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="152" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Interaction flow</figcaption>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>A private-by-design embedded platform</h3>

<div id="S1.SS2.p1" class="ltx_para ltx_noindent">
<p id="S1.SS2.p1.1" class="ltx_p">The <em id="S1.SS2.p1.1.1" class="ltx_emph ltx_font_italic">Privacy by Design</em> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">cavoukian2009privacy </a>; <a href="#bib.bib25" title="" class="ltx_ref">langheinrich2001privacy </a></cite> principle sets privacy as the default standard in the design and engineering of a system. In the context of voice assistants, that can be deployed anywhere including users’ homes, this principle calls for a strong interpretation to protect users against any future misuse of their private data. In the following, we call <em id="S1.SS2.p1.1.2" class="ltx_emph ltx_font_italic">private-by-design</em> a system that does not transfer user data to any remote location, such as cloud servers.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para ltx_noindent">
<p id="S1.SS2.p2.1" class="ltx_p">Within the Snips ecosystem, the SLU components are trained on servers, but the inference happens directly on the device once the assistant has been deployed - no data from the user is ever collected nor stored. This design choice adds engineering complexity as most IoT devices run on specific hardware with limited memory and computing power. Cross-platform support is also a requirement in the IoT industry, since IoT devices are powered by many different hardware boards, with sustained innovation in that field.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para ltx_noindent">
<p id="S1.SS2.p3.1" class="ltx_p">For these reasons, the Snips Voice Platform has been built with portability and footprint in mind. Its embedded inference runs on common IoT hardware as light as the Raspberry Pi 3 (CPU with 1.4 GHz and 1GB of RAM), a popular choice among developers and therefore our reference hardware setting throughout this paper. Other Linux boards are also supported, such as IMX.7D, i.MX8M, DragonBoard 410c, and Jetson TX2. The Snips SDK for Android works with devices with Android 5 and ARM CPU, while the iOS SDK targets iOS 11 and newer. For efficiency and portability reasons, the algorithms have been re-implemented whenever needed in Rust <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib29" title="" class="ltx_ref">Rust14 </a></cite> – a modern programming language offering high performance, low memory overhead, and cross-compilation.</p>
</div>
<div id="S1.SS2.p4" class="ltx_para ltx_noindent">
<p id="S1.SS2.p4.1" class="ltx_p">SLU engines are usually broken down into two parts: Automatic Speech Recognition (ASR) and Natural Language Understanding (NLU). The ASR engine translates a spoken utterance into text through an acoustic model, mapping raw audio to a phonetic representation, and a Language Model (LM), mapping this phonetic representation to text. The NLU then extracts intent and slots from the decoded query. As discussed in section <a href="#S3" title="3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, LM and NLU have to be mutually consistent in order to optimize the accuracy of the SLU engine. It is therefore useful to introduce a <em id="S1.SS2.p4.1.1" class="ltx_emph ltx_font_italic">language modeling</em> component composed of the LM and NLU.
Figure <a href="#S1.F2" title="Figure 2 ‣ 1.2 A private-by-design embedded platform ‣ 1 Introduction ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> describes the building blocks of the SLU pipeline.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<p id="S1.F2.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S1.F2.1.1.1" class="ltx_text"><img src="/html/1805.10190/assets/x2.png" id="S1.F2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="107" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Spoken Language Understanding pipeline</figcaption>
</figure>
<div id="S1.SS2.p5" class="ltx_para ltx_noindent">
<p id="S1.SS2.p5.1" class="ltx_p">As stated above, ASR engines relying on large deep learning models have improved drastically over the past few years. Yet, they still have a major drawback today. For example, the model achieving human
parity in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">xiong2016achieving </a></cite> is a combination of several neural networks,
each containing several hundreds of millions of parameters, and large-vocabulary language models made of several millions of n-grams. The size of these models, along with the computational resources necessary to run them in real-time, make them unfit for deployment on small devices, so that solutions implementing them are bound to rely on the cloud for speech recognition.</p>
</div>
<div id="S1.SS2.p6" class="ltx_para ltx_noindent">
<p id="S1.SS2.p6.1" class="ltx_p">Enforcing privacy by design therefore implies developing new tools to build reliable SLU engines that are constrained in size and computational requirements, which we detail in this paper. In section <a href="#S2" title="2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we describe strategies to obtain small (10MB) and robust acoustic models trained on general speech corpora of a few hundred to a few thousand hours. Section <a href="#S3" title="3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> is devoted to a description of the language modeling approach of the Snips SLU engine. Notably, we show how to ensure consistency between the language model of the ASR engine and the NLU engine while specializing them to a particular use case. The resulting SLU engine is lightweight and fast to execute, making it fit for deployment on small devices and the NLU component is open source <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">SnipsNLU </a></cite>. In section <a href="#S4" title="4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we illustrate the high generalization accuracy of the SLU engine in the context of real-word voice assistants. Finally, we discuss in section <a href="#S5.F9" title="Figure 9 ‣ 5.2 Evaluation ‣ 5 Training models without user data ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> a data generation procedure to automatically create training sets replacing user data.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Acoustic model</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">The acoustic model is the first step of the SLU pipeline, and is therefore crucial to its functioning. If the decoding contains errors, it might compromise the subsequent steps and trigger a different action than that intended by the user.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">The acoustic model is responsible for converting raw audio data to what can approximately be interpreted as phone probabilities, i.e. context-dependent clustered Hidden Markov Model (HMM) state probabilities. These probabilities are then fed to a language model, which decodes a sequence of words corresponding to the user utterance. The acoustic and language models are thus closely related in the Automatic Speech Recognition (ASR) engine, but are often designed and trained separately. The construction of the language model used in the SLU engine is detailed in section <a href="#S3" title="3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">In this section, we present the acoustic model. First, we give details about
how the training data is collected, processed, cleaned, and augmented. Then, we present the acoustic model itself (a hybrid of Neural Networks and Hidden Markov Models, or NN/HMM)
and how it is trained. Finally, we present the performance of the acoustic model
in a large-vocabulary setup, in terms of word error rate (WER), speed, and memory usage.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data</h3>

<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training data.</h5>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px1.p1.1" class="ltx_p">To train the acoustic model, we need several hundreds to thousands of hours of audio data with corresponding transcripts. The data is collected from public or commercial sources. A realignment of transcripts to the audio is performed to match transcripts to timestamps. This additionally helps in removing transcription errors that might be present in the data.
The result is a set of audio extracts and matching transcripts, with lengths suitable for acoustic training (up to a few dozen seconds). This data is split in a training, testing, and development sets.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data augmentation.</h5>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px2.p1.1" class="ltx_p">One of the main issues regarding the training of the acoustic model is the lack of data corresponding to real usage scenari. Most of the available training data is clear close-field speech, but voice assistants will often be used in noisy conditions (music, television, environment noise), from a distance of several meters in far-field conditions, and in rooms or cars with reverberation.
From a machine learning perspective, data corresponding to real usage of the system –- or in-domain data – is extremely valuable. Since spoken utterances from the user are not collected by our platform for privacy reasons, noisy and reverberant conditions are simulated by augmenting the data. Thousands of virtual rooms of different sizes are thus generated with random microphone and speaker locations, and the rerecording of the original data in those conditions is simulated using a method close to that presented in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">kim2017generation </a></cite>.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Model training</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">Acoustic models are hybrid NN/HMM models. More specifically, they are a custom
version of the <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">s5</span> training recipe of the Kaldi toolkit <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref">povey2011kaldi </a></cite>. 40 MFCC features are extracted from the audio signal with windows of size 25ms every 10ms.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p">Models with a variable number of layers and neurons can be trained, which will impact their accuracy and computational cost. We can thus train different model architectures depending on the target hardware and the desired application accuracy. In the following evaluation (section <a href="#S2.SS3" title="2.3 Acoustic model evaluation ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), we present performance results of a model targeted for the Raspberry Pi 3.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p">First, a speaker-adaptive Gaussian Mixture Model Hidden Markov Model (GMM-HMM) is trained on the speech corpus to obtain a context-dependent bootstrapping model with which we align the full dataset and extract lattices to prepare the neural network training.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/1805.10190/assets/figures/TDNN-LSTM-1e.png" id="S2.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="299" height="270" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The TDNN-LSTM architecture used in the presented models.</figcaption>
</figure>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Network architecture.
The <span id="S2.T1.5.1" class="ltx_text ltx_font_italic">Context</span> denotes the number of relative frames seen by the layer at time t. For instance, the recurrent connections skip 3 frames in LSTMP layers. A projection layer size of <math id="S2.T1.2.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.T1.2.m1.1b"><mi id="S2.T1.2.m1.1.1" xref="S2.T1.2.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.T1.2.m1.1c"><ci id="S2.T1.2.m1.1.1.cmml" xref="S2.T1.2.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.m1.1d">N</annotation></semantics></math> is denoted <span id="S2.T1.6.2" class="ltx_text ltx_font_typewriter">pN</span>.
(TDNN: Time-Delay layer; LSTMP: Long Short-Term Memory with Projection layer).</figcaption>
<table id="S2.T1.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.7.1.1" class="ltx_tr">
<th id="S2.T1.7.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S2.T1.7.1.1.1.1" class="ltx_text ltx_font_bold">Layer Type</span></th>
<th id="S2.T1.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S2.T1.7.1.1.2.1" class="ltx_text ltx_font_bold">Context</span></th>
<td id="S2.T1.7.1.1.3" class="ltx_td ltx_align_left"><span id="S2.T1.7.1.1.3.1" class="ltx_text ltx_font_typewriter">nnet-256</span></td>
<td id="S2.T1.7.1.1.4" class="ltx_td ltx_align_left"><span id="S2.T1.7.1.1.4.1" class="ltx_text ltx_font_typewriter">nnet-512</span></td>
<td id="S2.T1.7.1.1.5" class="ltx_td ltx_align_left"><span id="S2.T1.7.1.1.5.1" class="ltx_text ltx_font_typewriter">nnet-768</span></td>
</tr>
<tr id="S2.T1.7.2.2" class="ltx_tr">
<th id="S2.T1.7.2.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">TDNN + BatchNorm + ReLU</th>
<th id="S2.T1.7.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="S2.T1.7.2.2.2.1" class="ltx_text ltx_font_typewriter">{-2, -1, 0, 1, 2}</span></th>
<td id="S2.T1.7.2.2.3" class="ltx_td ltx_align_left ltx_border_t">256</td>
<td id="S2.T1.7.2.2.4" class="ltx_td ltx_align_left ltx_border_t">512</td>
<td id="S2.T1.7.2.2.5" class="ltx_td ltx_align_left ltx_border_t">768</td>
</tr>
<tr id="S2.T1.7.3.3" class="ltx_tr">
<th id="S2.T1.7.3.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">TDNN + BatchNorm + ReLU</th>
<th id="S2.T1.7.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S2.T1.7.3.3.2.1" class="ltx_text ltx_font_typewriter">{-1, 0, 1}</span></th>
<td id="S2.T1.7.3.3.3" class="ltx_td ltx_align_left">256</td>
<td id="S2.T1.7.3.3.4" class="ltx_td ltx_align_left">512</td>
<td id="S2.T1.7.3.3.5" class="ltx_td ltx_align_left">768</td>
</tr>
<tr id="S2.T1.7.4.4" class="ltx_tr">
<th id="S2.T1.7.4.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">TDNN + BatchNorm + ReLU</th>
<th id="S2.T1.7.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S2.T1.7.4.4.2.1" class="ltx_text ltx_font_typewriter">{-1, 0, 1}</span></th>
<td id="S2.T1.7.4.4.3" class="ltx_td ltx_align_left">256</td>
<td id="S2.T1.7.4.4.4" class="ltx_td ltx_align_left">512</td>
<td id="S2.T1.7.4.4.5" class="ltx_td ltx_align_left">768</td>
</tr>
<tr id="S2.T1.7.5.5" class="ltx_tr">
<th id="S2.T1.7.5.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">LSTMP</th>
<th id="S2.T1.7.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">rec:<span id="S2.T1.7.5.5.2.1" class="ltx_text ltx_font_typewriter">-3</span>
</th>
<td id="S2.T1.7.5.5.3" class="ltx_td ltx_align_left">256, p128</td>
<td id="S2.T1.7.5.5.4" class="ltx_td ltx_align_left">512, p256</td>
<td id="S2.T1.7.5.5.5" class="ltx_td ltx_align_left">768, p256</td>
</tr>
<tr id="S2.T1.7.6.6" class="ltx_tr">
<th id="S2.T1.7.6.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">TDNN + BatchNorm + ReLU</th>
<th id="S2.T1.7.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S2.T1.7.6.6.2.1" class="ltx_text ltx_font_typewriter">{-3, 0, 3}</span></th>
<td id="S2.T1.7.6.6.3" class="ltx_td ltx_align_left">256</td>
<td id="S2.T1.7.6.6.4" class="ltx_td ltx_align_left">512</td>
<td id="S2.T1.7.6.6.5" class="ltx_td ltx_align_left">768</td>
</tr>
<tr id="S2.T1.7.7.7" class="ltx_tr">
<th id="S2.T1.7.7.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">TDNN + BatchNorm + ReLU</th>
<th id="S2.T1.7.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S2.T1.7.7.7.2.1" class="ltx_text ltx_font_typewriter">{-3, 0, 3}</span></th>
<td id="S2.T1.7.7.7.3" class="ltx_td ltx_align_left">256</td>
<td id="S2.T1.7.7.7.4" class="ltx_td ltx_align_left">512</td>
<td id="S2.T1.7.7.7.5" class="ltx_td ltx_align_left">768</td>
</tr>
<tr id="S2.T1.7.8.8" class="ltx_tr">
<th id="S2.T1.7.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">LSTMP</th>
<th id="S2.T1.7.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">rec:<span id="S2.T1.7.8.8.2.1" class="ltx_text ltx_font_typewriter">-3</span>
</th>
<td id="S2.T1.7.8.8.3" class="ltx_td ltx_align_left">256, p128</td>
<td id="S2.T1.7.8.8.4" class="ltx_td ltx_align_left">512, p256</td>
<td id="S2.T1.7.8.8.5" class="ltx_td ltx_align_left">768, p256</td>
</tr>
<tr id="S2.T1.7.9.9" class="ltx_tr">
<th id="S2.T1.7.9.9.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_t"><span id="S2.T1.7.9.9.1.1" class="ltx_text ltx_font_bold">Num. params</span></th>
<th id="S2.T1.7.9.9.2" class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_t"></th>
<td id="S2.T1.7.9.9.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">2.6M</td>
<td id="S2.T1.7.9.9.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">8.7M</td>
<td id="S2.T1.7.9.9.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">15.4M</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.1" class="ltx_p">We train a deep neural network, consisting of time-delay layers similar to those presented in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib39" title="" class="ltx_ref">tdnn </a></cite>, and long short-term memory layers similar to those of <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">peddinti2018low </a></cite>.
The architecture, close to that of <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">peddinti2018low </a></cite>, is summarized
in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.2 Model training ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Table <a href="#S2.T1" title="Table 1 ‣ 2.2 Model training ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The Raspberry Pi 3 model uses 7 layers, and is trained with the lattice-free Maximum Mutual Information (MMI) criterion <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">lfmmi </a></cite>,
using natural gradient descent, with a learning rate of 0.0005 and
the backstitching trick <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">backstitch </a></cite>. We follow the approach described
in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">lfmmi </a></cite> to create fast acoustic models, namely an HMM topology with one state for each of the 1,700 context-dependent senones, operating at a third of the original frame rate.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Acoustic model evaluation</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p">In this section, we present an evaluation of our acoustic model for English. Our goal is the design of an end-to-end SLU pipeline which runs in real-time on small embedded devices, but has state-of-the-art accuracy. This requires tradeoffs between speed and the generality of SLU task. More precisely, we use domain-adapted language models described in section <a href="#S3" title="3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, to compensate for the decrease of accuracy of smaller acoustic models.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.1" class="ltx_p">However in order to assess the quality of the acoustic model in a more general setting, the evaluation of this section is carried out in a large vocabulary setup, on the LibriSpeech evaluation dataset <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">panayotov2015Librispeech </a></cite>, chosen because it is freely available and widely used in state-of-the-art comparisons.
The language model for the large-vocabulary evaluation is also freely available online<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="http://www.openslr.org/11/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.openslr.org/11/</a></span></span></span>. It is a pruned trigram LM with a vocabulary of 200k words, trained on the content of public domain books.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para ltx_noindent">
<p id="S2.SS3.p3.1" class="ltx_p">Two sets of experiments are reported. In the first set, the models are trained
only on the LibriSpeech training set (or on a subset of it). It allows us to validate our
training approach and keep track of how the models we develop compare to the
state of the art when trained on public data. Then, the performance of the model in terms of speed and memory usage is studied, which allows us to select a good tradeoff for the targeted Raspberry Pi 3 setting.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Model architecture trained and evaluated on LibriSpeech</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">To evaluate the impact of the dataset and model sizes on the model accuracy, neural networks of different sizes are trained on different subsets of the
LibriSpeech dataset, with and without data augmentation. The results obtained
with <span id="S2.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_typewriter">nnet-512</span> are reported in Table <a href="#S2.T2" title="Table 2 ‣ 2.3.1 Model architecture trained and evaluated on LibriSpeech ‣ 2.3 Acoustic model evaluation ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The <span id="S2.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_italic">Num. hours</span>
column corresponds to the number of training hours (460h in the <span id="S2.SS3.SSS1.p1.1.3" class="ltx_text ltx_font_italic">train-clean</span> split of the LibriSpeech dataset and
500h in the <span id="S2.SS3.SSS1.p1.1.4" class="ltx_text ltx_font_italic">train-other</span> split). The data augmentation was only applied to the clean
data. For example <span id="S2.SS3.SSS1.p1.1.5" class="ltx_text ltx_font_italic">460x2</span> means 460h of clean data + 460h of augmented
data.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Decoding accuracy of <span id="S2.T2.2.1" class="ltx_text ltx_font_typewriter">nnet-512</span> with different amounts of training data (Word Error Rate, %)</figcaption>
<table id="S2.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.3.1.1" class="ltx_tr">
<th id="S2.T2.3.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row"><span id="S2.T2.3.1.1.1.1" class="ltx_text ltx_font_bold">Num. hours</span></th>
<th id="S2.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T2.3.1.1.2.1" class="ltx_text ltx_font_bold">dev-clean</span></th>
<th id="S2.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T2.3.1.1.3.1" class="ltx_text ltx_font_bold">dev-other</span></th>
<th id="S2.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T2.3.1.1.4.1" class="ltx_text ltx_font_bold">test-clean</span></th>
<th id="S2.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T2.3.1.1.5.1" class="ltx_text ltx_font_bold">test-other</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.3.2.1" class="ltx_tr">
<th id="S2.T2.3.2.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t">460</th>
<td id="S2.T2.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t">6.3</td>
<td id="S2.T2.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t">21.8</td>
<td id="S2.T2.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">6.6</td>
<td id="S2.T2.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t">23.1</td>
</tr>
<tr id="S2.T2.3.3.2" class="ltx_tr">
<th id="S2.T2.3.3.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">460x2</th>
<td id="S2.T2.3.3.2.2" class="ltx_td ltx_align_center">6.2</td>
<td id="S2.T2.3.3.2.3" class="ltx_td ltx_align_center">19.5</td>
<td id="S2.T2.3.3.2.4" class="ltx_td ltx_align_center">6.5</td>
<td id="S2.T2.3.3.2.5" class="ltx_td ltx_align_center">19.7</td>
</tr>
<tr id="S2.T2.3.4.3" class="ltx_tr">
<th id="S2.T2.3.4.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">960</th>
<td id="S2.T2.3.4.3.2" class="ltx_td ltx_align_center">6.2</td>
<td id="S2.T2.3.4.3.3" class="ltx_td ltx_align_center">16.4</td>
<td id="S2.T2.3.4.3.4" class="ltx_td ltx_align_center">6.4</td>
<td id="S2.T2.3.4.3.5" class="ltx_td ltx_align_center">16.5</td>
</tr>
<tr id="S2.T2.3.5.4" class="ltx_tr">
<th id="S2.T2.3.5.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row">460x6+500</th>
<td id="S2.T2.3.5.4.2" class="ltx_td ltx_align_center">6.1</td>
<td id="S2.T2.3.5.4.3" class="ltx_td ltx_align_center">16.3</td>
<td id="S2.T2.3.5.4.4" class="ltx_td ltx_align_center">6.4</td>
<td id="S2.T2.3.5.4.5" class="ltx_td ltx_align_center">16.5</td>
</tr>
<tr id="S2.T2.3.6.5" class="ltx_tr">
<th id="S2.T2.3.6.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_t">KALDI</th>
<td id="S2.T2.3.6.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.3</td>
<td id="S2.T2.3.6.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">11.2</td>
<td id="S2.T2.3.6.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.8</td>
<td id="S2.T2.3.6.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">11.5</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS1.p2.1" class="ltx_p">We observe that adding data does not have much impact on LibriSpeech’s clean
test sets (dev-clean and test-clean). The WER however decreases when adding data on the datasets marked as <span id="S2.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_italic">other</span> (dev-other, test-other). In general (not shown in those tests), adding more data and using data augmentation increases significantly the performance on noisy and reverberant conditions.</p>
</div>
<div id="S2.SS3.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS1.p3.1" class="ltx_p">In the next experiment, the neural networks are trained with the same architecture but different layer sizes on the 460x6+500 hours dataset. Results are reported in Table <a href="#S2.T3" title="Table 3 ‣ 2.3.1 Model architecture trained and evaluated on LibriSpeech ‣ 2.3 Acoustic model evaluation ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This shows that larger models are capable of fitting the data and generalizing better, as expected. This allows us to choose the best tradeoff between precision and computational cost depending on each target hardware and assistant needs.</p>
</div>
<figure id="S2.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Decoding accuracy of neural networks of different sizes (Word Error Rate, %)</figcaption>
<table id="S2.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T3.1.1.1" class="ltx_tr">
<th id="S2.T3.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row"><span id="S2.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S2.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">dev-clean</span></th>
<th id="S2.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">dev-other</span></th>
<th id="S2.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">test-clean</span></th>
<th id="S2.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">test-other</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T3.1.2.1" class="ltx_tr">
<th id="S2.T3.1.2.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t"><span id="S2.T3.1.2.1.1.1" class="ltx_text ltx_font_typewriter">nnet-256</span></th>
<td id="S2.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">7.3</td>
<td id="S2.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">19.2</td>
<td id="S2.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">7.6</td>
<td id="S2.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">19.6</td>
</tr>
<tr id="S2.T3.1.3.2" class="ltx_tr">
<th id="S2.T3.1.3.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S2.T3.1.3.2.1.1" class="ltx_text ltx_font_typewriter">nnet-512</span></th>
<td id="S2.T3.1.3.2.2" class="ltx_td ltx_align_center">6.4</td>
<td id="S2.T3.1.3.2.3" class="ltx_td ltx_align_center">17.1</td>
<td id="S2.T3.1.3.2.4" class="ltx_td ltx_align_center">6.6</td>
<td id="S2.T3.1.3.2.5" class="ltx_td ltx_align_center">17.6</td>
</tr>
<tr id="S2.T3.1.4.3" class="ltx_tr">
<th id="S2.T3.1.4.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S2.T3.1.4.3.1.1" class="ltx_text ltx_font_typewriter">nnet-768</span></th>
<td id="S2.T3.1.4.3.2" class="ltx_td ltx_align_center">6.4</td>
<td id="S2.T3.1.4.3.3" class="ltx_td ltx_align_center">16.8</td>
<td id="S2.T3.1.4.3.4" class="ltx_td ltx_align_center">6.6</td>
<td id="S2.T3.1.4.3.5" class="ltx_td ltx_align_center">17.5</td>
</tr>
<tr id="S2.T3.1.5.4" class="ltx_tr">
<th id="S2.T3.1.5.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_t">KALDI</th>
<td id="S2.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.3</td>
<td id="S2.T3.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">11.2</td>
<td id="S2.T3.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.8</td>
<td id="S2.T3.1.5.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">11.5</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Online recognition performance</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">While it is possible to get closer to the state of the art using larger neural network architectures, their associated memory and computational costs would prohibit their deployment on small devices. In section <a href="#S3" title="3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we show how carefully adapting the LM allows to reach high end-to-end accuracies using the acoustic models described here. We now report experiments on the processing speed of these models on our target Raspberry Pi 3 hardware setting. We trained models with various sizes enjoying a faster-than-real-time processing factor, to account for additional processing time (necessitated e.g. by the LM decoding or the NLU engine), and chose a model with a good compromise of accuracy to real-time factor and model size (on disk and in RAM).</p>
</div>
<figure id="S2.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Comparison of speed and memory performance of
<span id="S2.T4.6.1" class="ltx_text ltx_font_typewriter">nnet-256</span> and <span id="S2.T4.7.2" class="ltx_text ltx_font_typewriter">nnet-768</span>. RTF refers to real time ratio.</figcaption>
<table id="S2.T4.3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T4.3.3.4.1" class="ltx_tr">
<th id="S2.T4.3.3.4.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row"><span id="S2.T4.3.3.4.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S2.T4.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row"><span id="S2.T4.3.3.4.1.2.1" class="ltx_text ltx_font_bold">Num. Params (M)</span></th>
<th id="S2.T4.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T4.3.3.4.1.3.1" class="ltx_text ltx_font_bold">Size (MB)</span></th>
<th id="S2.T4.3.3.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S2.T4.3.3.4.1.4.1" class="ltx_text ltx_font_bold">RTF (Raspberry Pi 3)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T4.1.1.1" class="ltx_tr">
<th id="S2.T4.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t"><span id="S2.T4.1.1.1.2.1" class="ltx_text ltx_font_typewriter">nnet-256</span></th>
<th id="S2.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2.6</th>
<td id="S2.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">10</td>
<td id="S2.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="&lt;1" display="inline"><semantics id="S2.T4.1.1.1.1.m1.1a"><mrow id="S2.T4.1.1.1.1.m1.1.1" xref="S2.T4.1.1.1.1.m1.1.1.cmml"><mi id="S2.T4.1.1.1.1.m1.1.1.2" xref="S2.T4.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="S2.T4.1.1.1.1.m1.1.1.1" xref="S2.T4.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S2.T4.1.1.1.1.m1.1.1.3" xref="S2.T4.1.1.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T4.1.1.1.1.m1.1b"><apply id="S2.T4.1.1.1.1.m1.1.1.cmml" xref="S2.T4.1.1.1.1.m1.1.1"><lt id="S2.T4.1.1.1.1.m1.1.1.1.cmml" xref="S2.T4.1.1.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S2.T4.1.1.1.1.m1.1.1.2.cmml" xref="S2.T4.1.1.1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S2.T4.1.1.1.1.m1.1.1.3.cmml" xref="S2.T4.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T4.1.1.1.1.m1.1c">&lt;1</annotation></semantics></math></td>
</tr>
<tr id="S2.T4.3.3.3" class="ltx_tr">
<th id="S2.T4.3.3.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_row"><span id="S2.T4.3.3.3.3.1" class="ltx_text ltx_font_typewriter">nnet-768</span></th>
<th id="S2.T4.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">15.4</th>
<td id="S2.T4.3.3.3.5" class="ltx_td ltx_align_center">59</td>
<td id="S2.T4.3.3.3.2" class="ltx_td ltx_align_center">&gt;1</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS3.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS2.p2.1" class="ltx_p">As a reference, in terms of model size (as reported in Table <a href="#S2.T4" title="Table 4 ‣ 2.3.2 Online recognition performance ‣ 2.3 Acoustic model evaluation ‣ 2 Acoustic model ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) <span id="S2.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">nnet-256</span> is nearly six times smaller than <span id="S2.SS3.SSS2.p2.1.2" class="ltx_text ltx_font_typewriter">nnet-768</span>, with 2.6M parameters vs 15.4M, representing 10MB vs 59MB on disk. The gain is similar in RAM. In terms of speed, the <span id="S2.SS3.SSS2.p2.1.3" class="ltx_text ltx_font_typewriter">nnet-256</span> is 6 to 10 times faster than the <span id="S2.SS3.SSS2.p2.1.4" class="ltx_text ltx_font_typewriter">nnet-768</span>. These tradeoffs and comparison with other trained models led us to select the <span id="S2.SS3.SSS2.p2.1.5" class="ltx_text ltx_font_typewriter">nnet-256</span>. It has a reasonable speed and memory footprint, and the loss in accuracy is compensated by the adapted LM and robust NLU.</p>
</div>
<div id="S2.SS3.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS3.SSS2.p3.1" class="ltx_p">This network architecture and size will be the one used in the subsequent experiments. The different architecture variations presented in this section were chosen for the sake of comparison and demonstration. This experimental comparison, along with optional layer factorization (similar to <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref">prabhavalkar2016compression </a></cite>) or weight quantization are carried out for each target hardware setting, but this analysis is out of the scope of this paper.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Language Modeling</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">We now turn to the description of the language modeling component of the Snips platform, which is responsible for the extraction of the intent and slots from the output of the acoustic model. This component is made up of two closely-interacting parts. The first is the language model (LM), that turns the predictions of the acoustic model into likely sentences, taking into account the probability of co-occurrence of words. The second is the Natural Language Understanding (NLU) model, that extracts intent and slots from the prediction of the Automatic Speech Recognition (ASR) engine.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p">In typical commercial large vocabulary speech recognition systems, the LM component is usually the largest in size, and can take up to terabytes of storage <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">chelba2012large </a></cite>. Indeed, to account for the high variability of general spoken language, large vocabulary language models need to be trained on very large text corpora. The size of these models also has an impact on decoding performance: the search space of the ASR is expanded, making speech recognition harder and more computationally demanding. Additionally, the performance of an ASR engine on a given domain will strongly depend on the perplexity of its LM on queries from this domain, making the choice of the training text corpus critical. This question is sometimes addressed through massive use of users’ private data <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">chelba2010query </a></cite>.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p">One option to overcome these challenges is to <em id="S3.p3.1.1" class="ltx_emph ltx_font_italic">specialize</em> the language model of the assistant to a certain domain, e.g. by restricting its vocabulary as well as the variety of the queries it should model. While this approach appears to restrict the range of queries that can be made to an assistant, we argue that it does not impair the usability of the resulting assistant. In fact, while the performance of an ASR engine alone can be measured using e.g. the word error rate as in the previous section, we assess the performance of the SLU system through its end-to-end, speech-to-meaning accuracy, i.e. its ability to correctly predict the intent and slots of a spoken utterance. As a consequence, it is sufficient for the LM to correctly model the sentences that are in the domain that the NLU supports. The size of the model is thus greatly reduced, and the decoding speed increases. The resulting ASR is particularly robust within the use case, with an accuracy unreachable under our hardware constraints for an all-purpose, general ASR model. In the following, we detail the implementation of this design principle, allowing the Snips SLU component to run efficiently on small devices with high accuracy, and illustrate its performance on two real-world assistants.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">In application of the principles outlined above, we use the same data to train both LM and NLU. The next section is devoted to a description of this dataset. The generation of this dataset is discussed in section <a href="#S5" title="5 Training models without user data ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Training dataset</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">The dataset used to train both the LM and NLU contains written <em id="S3.SS1.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">queries</em> exemplifying <em id="S3.SS1.SSS1.p1.1.2" class="ltx_emph ltx_font_italic">intents</em> that depend on <em id="S3.SS1.SSS1.p1.1.3" class="ltx_emph ltx_font_italic">entities</em>.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p">Entities are bound to an intent and used to describe all the possible values for a given attribute. For example, in the case of a <span id="S3.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_typewriter">SmartLights</span> assistant handling connected lights, these entities are <span id="S3.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_typewriter">room</span>, <span id="S3.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_typewriter">brightness</span> and <span id="S3.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_typewriter">color</span>. They are required by the assistant logic to execute the right action. Another example dealing with weather-related queries is described in section <a href="#S4" title="4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. An intent often has several entities that it can share with other intents. For instance, the <span id="S3.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_typewriter">room</span> entity is used by several intents (<span id="S3.SS1.SSS1.p2.1.6" class="ltx_text ltx_font_typewriter">SwitchLightOn</span> and <span id="S3.SS1.SSS1.p2.1.7" class="ltx_text ltx_font_typewriter">SwitchLightOff</span>), since the user might want to specify the room for both switching on and switching off the lights.</p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p3.1" class="ltx_p">Entities can be of two types, either <em id="S3.SS1.SSS1.p3.1.1" class="ltx_emph ltx_font_italic">custom</em> or <em id="S3.SS1.SSS1.p3.1.2" class="ltx_emph ltx_font_italic">built-in</em>. Custom entities are user-defined entities that can be exhaustively specified by a list of values (e.g. <span id="S3.SS1.SSS1.p3.1.3" class="ltx_text ltx_font_typewriter">room</span>: kitchen, bedroom, etc. and <span id="S3.SS1.SSS1.p3.1.4" class="ltx_text ltx_font_typewriter">color</span>: blue, red, etc.). Built-in entities are common entities that cannot be easily listed exhaustively by a user, and are therefore provided by the platform (numbers, ordinals, amounts with unit, date and times, durations, etc.). In our <span id="S3.SS1.SSS1.p3.1.5" class="ltx_text ltx_font_typewriter">SmartLights</span> example, the entity <span id="S3.SS1.SSS1.p3.1.6" class="ltx_text ltx_font_typewriter">brightness</span> can be any number between 0 and 100, so that the built-in entity type <span id="S3.SS1.SSS1.p3.1.7" class="ltx_text ltx_font_typewriter">snips/number</span> can be used.</p>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p4.1" class="ltx_p">A query is the written expression of an intent. For instance, the query “<span id="S3.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_typewriter">set the kitchen lights intensity to 65</span>” is associated with the intent <span id="S3.SS1.SSS1.p4.1.2" class="ltx_text ltx_font_typewriter">SetLightBrightness</span>. Slot labeling is done by specifying chunks of the query that should be bound to a given entity. Using the same examples, the slots associated with the <span id="S3.SS1.SSS1.p4.1.3" class="ltx_text ltx_font_typewriter">room</span> and <span id="S3.SS1.SSS1.p4.1.4" class="ltx_text ltx_font_typewriter">brightness</span> entities in the query can be specified as follows: “<span id="S3.SS1.SSS1.p4.1.5" class="ltx_text ltx_font_typewriter">set the (kitchen)[room] lights intensity to (65)[brightness]</span>”. The number of queries per intent ranges from a few ones to several thousands depending on the variability needed to cover most common wordings.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Normalization</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">One key challenge related to end-to-end SLU is data consistency between training and inference. The dataset described above is collected via the console where no specific writing system, nor cleaning rules regarding non-alphanumeric characters are enforced. Before training the LM, this dataset therefore needs to be <em id="S3.SS1.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">verbalized</em>: entity values and user queries are tokenized, normalized to a canonical form, and verbalized to match entries from a lexicon. For instance, numbers and dates are spelled out, so that their pronunciation can be generated from their written form.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">Importantly, we apply the same preprocessing before training the NLU. This step ensures consistency when it comes to inference. More precisely, it guarantees that the words output by the ASR match those seen by the NLU during training. The normalization pipeline is used to handle languages specificities, through the use of a class-based tokenizer that allows support for case-by-case verbalization for each token class. For instance, numeric values are transliterated to words, punctuation tokens skipped, while quantities with units such as amounts of money require a more advanced verbalization (in English, “<span id="S3.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">$25</span>” should be verbalized as “<span id="S3.SS1.SSS2.p2.1.2" class="ltx_text ltx_font_typewriter">twenty five dollars</span>”). The tokenizer is implemented as a character-level finite state transducer, and is designed to be easily extensible to accommodate new token types as more languages are supported.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Language model</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">The mapping from the output of the acoustic model to likely word sequences is done via a Viterbi search in a weighted Finite State Transducer (wFST) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">mohri2001weighted </a></cite>, called <em id="S3.SS2.p1.1.1" class="ltx_emph ltx_font_italic">ASR decoding graph</em> in the following. Formally, the decoding graph may be written as the composition of four wFSTs,</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<table id="Sx2.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\displaystyle H*C*L*G\,," display="inline"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">∗</mo><mi id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.1.cmml">∗</mo><mi id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.1b" xref="S3.E1.m1.1.1.1.1.1.cmml">∗</mo><mi id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml">G</mi></mrow><mo lspace="0.170em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></times><ci id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">𝐻</ci><ci id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">𝐶</ci><ci id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4">𝐿</ci><ci id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle H*C*L*G\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.5" class="ltx_p">where <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mo id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><times id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">*</annotation></semantics></math> denotes transducer composition (see section <a href="#S3.SS2.SSS2" title="3.2.2 Dynamic Language Model ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>), <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">H</annotation></semantics></math> represents Hidden Markov Models (HMMs) modeling context-dependent phones, <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">C</annotation></semantics></math> represents the context-dependency, <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">L</annotation></semantics></math> is the lexicon and <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">G</annotation></semantics></math> is the LM, typically a bigram or a trigram model represented as a wFST. Determinization and minimization operations are also applied at each step in order to compute equivalent optimized transducers with less states, allowing the composition and the inference to run faster. More detailed definitions of the previous classical transducers are beyond the scope of this paper, and we refer the interested reader to <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">mohri2001weighted </a>; <a href="#bib.bib42" title="" class="ltx_ref">povey2011kaldi </a></cite> and references therein. In the following, we focus on the construction of the G transducer, encoding the LM, from the domain-specific dataset presented above.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Language Model Adaptation</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">As explained earlier, the ASR engine is required to understand arbitrary formulations of a finite set of intents described in the dataset. In particular, it should be able to generalize to unseen queries within the same domain, and allow entity values to be interchangeable. The generalization properties of the ASR engine are preserved by using a statistical n-gram LM <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">katz1987estimation </a></cite> allowing to mix parts of the training queries to create new ones, and by using class-based language modeling <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">brown1992class </a></cite> where the value of each entity may be replaced by any other. We now detail the resulting LM construction strategy.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p2.9" class="ltx_p">The first step in building the LM is the creation of <em id="S3.SS2.SSS1.p2.9.1" class="ltx_emph ltx_font_italic">patterns</em> abstracting the type of queries the user may make to the assistant. Starting from the dataset described above, we replace all occurrences of each entity by a symbol for the entity. For example, the query “<span id="S3.SS2.SSS1.p2.9.2" class="ltx_text ltx_font_typewriter">Play some music by (The Rolling Stones)[artist]</span>” is abstracted to “<span id="S3.SS2.SSS1.p2.9.3" class="ltx_text ltx_font_typewriter">Play some music by ARTIST</span>”. An n-gram model is then trained on the resulting set of patterns, which is then converted to a wFST called <math id="S3.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="G_{p}" display="inline"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><msub id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.2" xref="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml">G</mi><mi id="S3.SS2.SSS1.p2.1.m1.1.1.3" xref="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.2">𝐺</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">G_{p}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref">mohri2008speech </a></cite>. Next, for each entity <math id="S3.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><msub id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml">e</mi><mi id="S3.SS2.SSS1.p2.2.m2.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">e_{i}</annotation></semantics></math> where <math id="S3.SS2.SSS1.p2.3.m3.2" class="ltx_Math" alttext="i\in[1,n]" display="inline"><semantics id="S3.SS2.SSS1.p2.3.m3.2a"><mrow id="S3.SS2.SSS1.p2.3.m3.2.3" xref="S3.SS2.SSS1.p2.3.m3.2.3.cmml"><mi id="S3.SS2.SSS1.p2.3.m3.2.3.2" xref="S3.SS2.SSS1.p2.3.m3.2.3.2.cmml">i</mi><mo id="S3.SS2.SSS1.p2.3.m3.2.3.1" xref="S3.SS2.SSS1.p2.3.m3.2.3.1.cmml">∈</mo><mrow id="S3.SS2.SSS1.p2.3.m3.2.3.3.2" xref="S3.SS2.SSS1.p2.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p2.3.m3.2.3.3.2.1" xref="S3.SS2.SSS1.p2.3.m3.2.3.3.1.cmml">[</mo><mn id="S3.SS2.SSS1.p2.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.cmml">1</mn><mo id="S3.SS2.SSS1.p2.3.m3.2.3.3.2.2" xref="S3.SS2.SSS1.p2.3.m3.2.3.3.1.cmml">,</mo><mi id="S3.SS2.SSS1.p2.3.m3.2.2" xref="S3.SS2.SSS1.p2.3.m3.2.2.cmml">n</mi><mo stretchy="false" id="S3.SS2.SSS1.p2.3.m3.2.3.3.2.3" xref="S3.SS2.SSS1.p2.3.m3.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.m3.2b"><apply id="S3.SS2.SSS1.p2.3.m3.2.3.cmml" xref="S3.SS2.SSS1.p2.3.m3.2.3"><in id="S3.SS2.SSS1.p2.3.m3.2.3.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.2.3.1"></in><ci id="S3.SS2.SSS1.p2.3.m3.2.3.2.cmml" xref="S3.SS2.SSS1.p2.3.m3.2.3.2">𝑖</ci><interval closure="closed" id="S3.SS2.SSS1.p2.3.m3.2.3.3.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.2.3.3.2"><cn type="integer" id="S3.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1">1</cn><ci id="S3.SS2.SSS1.p2.3.m3.2.2.cmml" xref="S3.SS2.SSS1.p2.3.m3.2.2">𝑛</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.m3.2c">i\in[1,n]</annotation></semantics></math> and <math id="S3.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.SSS1.p2.4.m4.1a"><mi id="S3.SS2.SSS1.p2.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.m4.1b"><ci id="S3.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.m4.1c">n</annotation></semantics></math> is the number of entities, an acceptor <math id="S3.SS2.SSS1.p2.5.m5.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS1.p2.5.m5.1a"><msub id="S3.SS2.SSS1.p2.5.m5.1.1" xref="S3.SS2.SSS1.p2.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p2.5.m5.1.1.2" xref="S3.SS2.SSS1.p2.5.m5.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS1.p2.5.m5.1.1.3" xref="S3.SS2.SSS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.SSS1.p2.5.m5.1.1.3.2" xref="S3.SS2.SSS1.p2.5.m5.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS1.p2.5.m5.1.1.3.3" xref="S3.SS2.SSS1.p2.5.m5.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.5.m5.1b"><apply id="S3.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.2">𝐺</ci><apply id="S3.SS2.SSS1.p2.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.5.m5.1c">G_{e_{i}}</annotation></semantics></math> is defined to encode the values the entity can take.
The construction of <math id="S3.SS2.SSS1.p2.6.m6.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS1.p2.6.m6.1a"><msub id="S3.SS2.SSS1.p2.6.m6.1.1" xref="S3.SS2.SSS1.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS1.p2.6.m6.1.1.2" xref="S3.SS2.SSS1.p2.6.m6.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS1.p2.6.m6.1.1.3" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.cmml"><mi id="S3.SS2.SSS1.p2.6.m6.1.1.3.2" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS1.p2.6.m6.1.1.3.3" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.6.m6.1b"><apply id="S3.SS2.SSS1.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.2">𝐺</ci><apply id="S3.SS2.SSS1.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.6.m6.1.1.3.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p2.6.m6.1.1.3.2.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.6.m6.1.1.3.3.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.6.m6.1c">G_{e_{i}}</annotation></semantics></math> depends on the type of the entity. For custom entities, whose values are listed exhaustively in the dataset, <math id="S3.SS2.SSS1.p2.7.m7.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS1.p2.7.m7.1a"><msub id="S3.SS2.SSS1.p2.7.m7.1.1" xref="S3.SS2.SSS1.p2.7.m7.1.1.cmml"><mi id="S3.SS2.SSS1.p2.7.m7.1.1.2" xref="S3.SS2.SSS1.p2.7.m7.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS1.p2.7.m7.1.1.3" xref="S3.SS2.SSS1.p2.7.m7.1.1.3.cmml"><mi id="S3.SS2.SSS1.p2.7.m7.1.1.3.2" xref="S3.SS2.SSS1.p2.7.m7.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS1.p2.7.m7.1.1.3.3" xref="S3.SS2.SSS1.p2.7.m7.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.7.m7.1b"><apply id="S3.SS2.SSS1.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.7.m7.1.1.1.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.7.m7.1.1.2.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1.2">𝐺</ci><apply id="S3.SS2.SSS1.p2.7.m7.1.1.3.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.7.m7.1.1.3.1.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p2.7.m7.1.1.3.2.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.7.m7.1.1.3.3.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.7.m7.1c">G_{e_{i}}</annotation></semantics></math> can be defined either as a union of acceptors of the different values of the entity, or as an n-gram model trained specifically on the values of the entity. For built-in entities such as numbers or dates and times, <math id="S3.SS2.SSS1.p2.8.m8.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS1.p2.8.m8.1a"><msub id="S3.SS2.SSS1.p2.8.m8.1.1" xref="S3.SS2.SSS1.p2.8.m8.1.1.cmml"><mi id="S3.SS2.SSS1.p2.8.m8.1.1.2" xref="S3.SS2.SSS1.p2.8.m8.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS1.p2.8.m8.1.1.3" xref="S3.SS2.SSS1.p2.8.m8.1.1.3.cmml"><mi id="S3.SS2.SSS1.p2.8.m8.1.1.3.2" xref="S3.SS2.SSS1.p2.8.m8.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS1.p2.8.m8.1.1.3.3" xref="S3.SS2.SSS1.p2.8.m8.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.8.m8.1b"><apply id="S3.SS2.SSS1.p2.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.8.m8.1.1.1.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.8.m8.1.1.2.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1.2">𝐺</ci><apply id="S3.SS2.SSS1.p2.8.m8.1.1.3.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.8.m8.1.1.3.1.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p2.8.m8.1.1.3.2.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.8.m8.1.1.3.3.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.8.m8.1c">G_{e_{i}}</annotation></semantics></math> is a wFST representation of a generative grammar describing the construction of any instance of the entity. The LM transducer <math id="S3.SS2.SSS1.p2.9.m9.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS2.SSS1.p2.9.m9.1a"><mi id="S3.SS2.SSS1.p2.9.m9.1.1" xref="S3.SS2.SSS1.p2.9.m9.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.9.m9.1b"><ci id="S3.SS2.SSS1.p2.9.m9.1.1.cmml" xref="S3.SS2.SSS1.p2.9.m9.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.9.m9.1c">G</annotation></semantics></math> is then defined as <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib18" title="" class="ltx_ref">horndasch2016add </a></cite></p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<table id="Sx2.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.3" class="ltx_Math" alttext="\displaystyle G=\text{Replace}(G_{p},\{G_{e_{i}}\,,\forall i\in[1,n]\})\,," display="inline"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.4" xref="S3.E2.m1.3.3.1.1.4.cmml">G</mi><mo id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml"><mtext id="S3.E2.m1.3.3.1.1.2.4" xref="S3.E2.m1.3.3.1.1.2.4a.cmml">Replace</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.2.3" xref="S3.E2.m1.3.3.1.1.2.3.cmml">​</mo><mrow id="S3.E2.m1.3.3.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.3" xref="S3.E2.m1.3.3.1.1.2.2.3.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml">G</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.E2.m1.3.3.1.1.2.2.2.4" xref="S3.E2.m1.3.3.1.1.2.2.3.cmml">,</mo><mrow id="S3.E2.m1.3.3.1.1.2.2.2.2.1" xref="S3.E2.m1.3.3.1.1.2.2.2.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.2.cmml">{</mo><mrow id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.3.cmml"><msub id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.2.cmml">G</mi><msub id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.3.cmml">,</mo><mrow id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.1" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.1.cmml">∀</mo><mi id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.2.cmml">i</mi></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.3.cmml">∈</mo><mrow id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.2.1" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.1.cmml">[</mo><mn id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">1</mn><mo id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.2.2" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">n</mi><mo stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.2.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.3" xref="S3.E2.m1.3.3.1.1.2.2.2.2.2.cmml">}</mo></mrow><mo rspace="0.170em" stretchy="false" id="S3.E2.m1.3.3.1.1.2.2.2.5" xref="S3.E2.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"></eq><ci id="S3.E2.m1.3.3.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.4">𝐺</ci><apply id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"><times id="S3.E2.m1.3.3.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.2.3"></times><ci id="S3.E2.m1.3.3.1.1.2.4a.cmml" xref="S3.E2.m1.3.3.1.1.2.4"><mtext id="S3.E2.m1.3.3.1.1.2.4.cmml" xref="S3.E2.m1.3.3.1.1.2.4">Replace</mtext></ci><interval closure="open" id="S3.E2.m1.3.3.1.1.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2"><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2">𝐺</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3">𝑝</ci></apply><set id="S3.E2.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1"><apply id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1"><in id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.3"></in><list id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2"><apply id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.2">𝐺</ci><apply id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.2">𝑒</ci><ci id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.1">for-all</csymbol><ci id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.2.2.2.2">𝑖</ci></apply></list><interval closure="closed" id="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.1.cmml" xref="S3.E2.m1.3.3.1.1.2.2.2.2.1.1.4.2"><cn type="integer" id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">1</cn><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑛</ci></interval></apply></set></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\displaystyle G=\text{Replace}(G_{p},\{G_{e_{i}}\,,\forall i\in[1,n]\})\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p4.6" class="ltx_p">where <span id="S3.SS2.SSS1.p4.6.1" class="ltx_text ltx_markedasmath">Replace</span> denotes wFST replacement. For instance, in the example above, the arcs of <math id="S3.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="G_{p}" display="inline"><semantics id="S3.SS2.SSS1.p4.2.m2.1a"><msub id="S3.SS2.SSS1.p4.2.m2.1.1" xref="S3.SS2.SSS1.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p4.2.m2.1.1.2" xref="S3.SS2.SSS1.p4.2.m2.1.1.2.cmml">G</mi><mi id="S3.SS2.SSS1.p4.2.m2.1.1.3" xref="S3.SS2.SSS1.p4.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.2.m2.1b"><apply id="S3.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1.2">𝐺</ci><ci id="S3.SS2.SSS1.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.2.m2.1c">G_{p}</annotation></semantics></math> carrying the “<span id="S3.SS2.SSS1.p4.6.2" class="ltx_text ltx_font_typewriter">ARTIST</span>” symbol are expanded into the wFST representing the “<span id="S3.SS2.SSS1.p4.6.3" class="ltx_text ltx_font_typewriter">artist</span>” entity. This process is represented on a simple LM on Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2.1 Language Model Adaptation ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
The resulting <math id="S3.SS2.SSS1.p4.3.m3.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS2.SSS1.p4.3.m3.1a"><mi id="S3.SS2.SSS1.p4.3.m3.1.1" xref="S3.SS2.SSS1.p4.3.m3.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.3.m3.1b"><ci id="S3.SS2.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p4.3.m3.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.3.m3.1c">G</annotation></semantics></math> allows the ASR to generalize to unseen queries and to swap entity values. Continuing with the simple example introduced above, the query “<span id="S3.SS2.SSS1.p4.6.4" class="ltx_text ltx_font_typewriter">Play me some music by The Beatles</span>” has the same weight as “<span id="S3.SS2.SSS1.p4.6.5" class="ltx_text ltx_font_typewriter">Play me some music by The Rolling Stones</span>” in the LM, while the sentence “<span id="S3.SS2.SSS1.p4.6.6" class="ltx_text ltx_font_typewriter">Play music by The Rolling Stones</span>” also has a finite weight thanks to the n-gram back-off mechanism.
The lexicon transducer <math id="S3.SS2.SSS1.p4.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.SSS1.p4.4.m4.1a"><mi id="S3.SS2.SSS1.p4.4.m4.1.1" xref="S3.SS2.SSS1.p4.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.4.m4.1b"><ci id="S3.SS2.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p4.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.4.m4.1c">L</annotation></semantics></math> encodes the pronunciations of all the words in both <math id="S3.SS2.SSS1.p4.5.m5.1" class="ltx_Math" alttext="G_{p}" display="inline"><semantics id="S3.SS2.SSS1.p4.5.m5.1a"><msub id="S3.SS2.SSS1.p4.5.m5.1.1" xref="S3.SS2.SSS1.p4.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p4.5.m5.1.1.2" xref="S3.SS2.SSS1.p4.5.m5.1.1.2.cmml">G</mi><mi id="S3.SS2.SSS1.p4.5.m5.1.1.3" xref="S3.SS2.SSS1.p4.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.5.m5.1b"><apply id="S3.SS2.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p4.5.m5.1.1.2">𝐺</ci><ci id="S3.SS2.SSS1.p4.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p4.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.5.m5.1c">G_{p}</annotation></semantics></math> and <math id="S3.SS2.SSS1.p4.6.m6.3" class="ltx_Math" alttext="\{G_{e_{i}}\,,\forall i\in[1,n]\}" display="inline"><semantics id="S3.SS2.SSS1.p4.6.m6.3a"><mrow id="S3.SS2.SSS1.p4.6.m6.3.3.1" xref="S3.SS2.SSS1.p4.6.m6.3.3.2.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.3.3.1.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.2.cmml">{</mo><mrow id="S3.SS2.SSS1.p4.6.m6.3.3.1.1" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.cmml"><mrow id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.3.cmml"><msub id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.3.cmml">,</mo><mrow id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.1" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.1.cmml">∀</mo><mi id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.2.cmml">i</mi></mrow></mrow><mo id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.3.cmml">∈</mo><mrow id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.2.1" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.1.cmml">[</mo><mn id="S3.SS2.SSS1.p4.6.m6.1.1" xref="S3.SS2.SSS1.p4.6.m6.1.1.cmml">1</mn><mo id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.2.2" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.1.cmml">,</mo><mi id="S3.SS2.SSS1.p4.6.m6.2.2" xref="S3.SS2.SSS1.p4.6.m6.2.2.cmml">n</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.2.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.3.3.1.3" xref="S3.SS2.SSS1.p4.6.m6.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.6.m6.3b"><set id="S3.SS2.SSS1.p4.6.m6.3.3.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1"><apply id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1"><in id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.3.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.3"></in><list id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.3.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2"><apply id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.2">𝐺</ci><apply id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.1">for-all</csymbol><ci id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.2.2.2.2">𝑖</ci></apply></list><interval closure="closed" id="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.3.3.1.1.4.2"><cn type="integer" id="S3.SS2.SSS1.p4.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.1">1</cn><ci id="S3.SS2.SSS1.p4.6.m6.2.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.2.2">𝑛</ci></interval></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.6.m6.3c">\{G_{e_{i}}\,,\forall i\in[1,n]\}</annotation></semantics></math>. The pronunciations are obtained from large base dictionaries, with a fall-back to a statistical grapheme-to-phoneme (G2P) system <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">novak2016phonetisaurus </a></cite> to generate the missing pronunciations.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/1805.10190/assets/x3.png" id="S3.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="388" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Graphical representation of a class-based language model on a simple assistant understanding queries of the form “<span id="S3.F4.11.1" class="ltx_text ltx_font_typewriter">play ARTIST</span>”. The top wFST represents the pattern n-gram language model <math id="S3.F4.5.m1.1" class="ltx_Math" alttext="G_{p}" display="inline"><semantics id="S3.F4.5.m1.1b"><msub id="S3.F4.5.m1.1.1" xref="S3.F4.5.m1.1.1.cmml"><mi id="S3.F4.5.m1.1.1.2" xref="S3.F4.5.m1.1.1.2.cmml">G</mi><mi id="S3.F4.5.m1.1.1.3" xref="S3.F4.5.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F4.5.m1.1c"><apply id="S3.F4.5.m1.1.1.cmml" xref="S3.F4.5.m1.1.1"><csymbol cd="ambiguous" id="S3.F4.5.m1.1.1.1.cmml" xref="S3.F4.5.m1.1.1">subscript</csymbol><ci id="S3.F4.5.m1.1.1.2.cmml" xref="S3.F4.5.m1.1.1.2">𝐺</ci><ci id="S3.F4.5.m1.1.1.3.cmml" xref="S3.F4.5.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.5.m1.1d">G_{p}</annotation></semantics></math>. The middle wFST represent the “<span id="S3.F4.12.2" class="ltx_text ltx_font_typewriter">ARTIST</span>” entity wFST called here <math id="S3.F4.6.m2.1" class="ltx_Math" alttext="G_{e_{0}}" display="inline"><semantics id="S3.F4.6.m2.1b"><msub id="S3.F4.6.m2.1.1" xref="S3.F4.6.m2.1.1.cmml"><mi id="S3.F4.6.m2.1.1.2" xref="S3.F4.6.m2.1.1.2.cmml">G</mi><msub id="S3.F4.6.m2.1.1.3" xref="S3.F4.6.m2.1.1.3.cmml"><mi id="S3.F4.6.m2.1.1.3.2" xref="S3.F4.6.m2.1.1.3.2.cmml">e</mi><mn id="S3.F4.6.m2.1.1.3.3" xref="S3.F4.6.m2.1.1.3.3.cmml">0</mn></msub></msub><annotation-xml encoding="MathML-Content" id="S3.F4.6.m2.1c"><apply id="S3.F4.6.m2.1.1.cmml" xref="S3.F4.6.m2.1.1"><csymbol cd="ambiguous" id="S3.F4.6.m2.1.1.1.cmml" xref="S3.F4.6.m2.1.1">subscript</csymbol><ci id="S3.F4.6.m2.1.1.2.cmml" xref="S3.F4.6.m2.1.1.2">𝐺</ci><apply id="S3.F4.6.m2.1.1.3.cmml" xref="S3.F4.6.m2.1.1.3"><csymbol cd="ambiguous" id="S3.F4.6.m2.1.1.3.1.cmml" xref="S3.F4.6.m2.1.1.3">subscript</csymbol><ci id="S3.F4.6.m2.1.1.3.2.cmml" xref="S3.F4.6.m2.1.1.3.2">𝑒</ci><cn type="integer" id="S3.F4.6.m2.1.1.3.3.cmml" xref="S3.F4.6.m2.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.6.m2.1d">G_{e_{0}}</annotation></semantics></math>. The bottom wFST represents the result of the replacement operation (<a href="#S3.E2" title="In 3.2.1 Language Model Adaptation ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Note that in order to keep the determinization of the HCLG tractable, a disambiguation symbol “<span id="S3.F4.13.3" class="ltx_text ltx_font_typewriter">#artist</span>” is added on the input and output arcs of <math id="S3.F4.7.m3.1" class="ltx_Math" alttext="G_{e_{0}}" display="inline"><semantics id="S3.F4.7.m3.1b"><msub id="S3.F4.7.m3.1.1" xref="S3.F4.7.m3.1.1.cmml"><mi id="S3.F4.7.m3.1.1.2" xref="S3.F4.7.m3.1.1.2.cmml">G</mi><msub id="S3.F4.7.m3.1.1.3" xref="S3.F4.7.m3.1.1.3.cmml"><mi id="S3.F4.7.m3.1.1.3.2" xref="S3.F4.7.m3.1.1.3.2.cmml">e</mi><mn id="S3.F4.7.m3.1.1.3.3" xref="S3.F4.7.m3.1.1.3.3.cmml">0</mn></msub></msub><annotation-xml encoding="MathML-Content" id="S3.F4.7.m3.1c"><apply id="S3.F4.7.m3.1.1.cmml" xref="S3.F4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.F4.7.m3.1.1.1.cmml" xref="S3.F4.7.m3.1.1">subscript</csymbol><ci id="S3.F4.7.m3.1.1.2.cmml" xref="S3.F4.7.m3.1.1.2">𝐺</ci><apply id="S3.F4.7.m3.1.1.3.cmml" xref="S3.F4.7.m3.1.1.3"><csymbol cd="ambiguous" id="S3.F4.7.m3.1.1.3.1.cmml" xref="S3.F4.7.m3.1.1.3">subscript</csymbol><ci id="S3.F4.7.m3.1.1.3.2.cmml" xref="S3.F4.7.m3.1.1.3.2">𝑒</ci><cn type="integer" id="S3.F4.7.m3.1.1.3.3.cmml" xref="S3.F4.7.m3.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.7.m3.1d">G_{e_{0}}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib18" title="" class="ltx_ref">horndasch2016add </a></cite>. </figcaption>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Dynamic Language Model</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p1.3" class="ltx_p">The standard way to compute the decoding graph is to perform compositions from right to left with the following formula</p>
<table id="Sx2.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\displaystyle H*(C*(L*G))\,," display="inline"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">∗</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">∗</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">L</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">∗</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">G</mi></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.170em" stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3">𝐻</ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">𝐶</ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2">𝐿</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3">𝐺</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle H*(C*(L*G))\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p1.2" class="ltx_p">where each composition is followed by a determinization and a minimization. The order in which the compositions are done is important, as the composition <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="(H*C*L)*G" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mrow id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mrow id="S3.SS2.SSS2.p1.1.m1.1.1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1.cmml">∗</mo><mi id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1a" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1.cmml">∗</mo><mi id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.4" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.4.cmml">L</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml">∗</mo><mi id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><times id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2"></times><apply id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1"><times id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.1"></times><ci id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.2">𝐻</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.3">𝐶</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.4.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.1.1.4">𝐿</ci></apply><ci id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">(H*C*L)*G</annotation></semantics></math> is known to be intractable when <math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">G</annotation></semantics></math> is not deterministic, as is the case when G is a wFST representing an n-gram model <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">mohri2001weighted </a></cite>. We will refer to the result of equation <a href="#S3.E3" title="In 3.2.2 Dynamic Language Model ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> as a <em id="S3.SS2.SSS2.p1.2.1" class="ltx_emph ltx_font_italic">static model</em> in the following.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">In the context of embedded inference, a major drawback of this standard method is the necessity to compute and load the static HCLG decoding graph in memory in order to perform speech recognition. The size of this decoding graph can claim a large chunk of the <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mn id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><cn type="integer" id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">1</annotation></semantics></math>GB of RAM available on a Raspberry Pi 3, or even be too big for smaller devices. Additionally, since LMs are trained synchronously in the Snips web console after the user has created their dataset (see section <a href="#S1.SS1" title="1.1 The Snips Ecosystem ‣ 1 Introduction ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a>), it is important for the decoding graph to be generated as fast as possible.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">For these reasons, a <em id="S3.SS2.SSS2.p3.1.1" class="ltx_emph ltx_font_italic">dynamic</em> language model, composing the various transducers upon request instead of ahead of time, is employed. This is achieved by replacing the compositions of equation (<a href="#S3.E1" title="In 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) by delayed (or lazy) ones <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">allauzen2007openfst </a></cite>. Consequently, the states and transitions of the complete HCLG decoding graph are not computed at the time of creation, but rather at runtime during the inference, notably speeding up the building of the decoding graph. Additionally, employing lazy composition allows to break the decoding graph into two pieces (HCL on one hand, and G on the other). The sum of the sizes of these pieces is typically several times smaller than the equivalent, statically-composed HCLG.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p4.1" class="ltx_p">In order to preserve the decoding speed of the ASR engine using a dynamic language model, a better composition algorithm using lazy look-ahead operations must be used. Indeed, a naive lazy composition typically creates many non co-accessible states in the resulting wFST, wasting both time and memory. In the case of a static decoding graph, these states are removed through a final optimization step of the HCLG that cannot be applied in the dynamic case because the full HCLG is never built. This issue can be addressed through the use of composition filters <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref">allauzen2009generalized </a>; <a href="#bib.bib3" title="" class="ltx_ref">allauzen2010filters </a></cite>. In particular, the use of look-ahead filters followed by label-reachability filters with weights and labels pushing allows to discard inaccessible and costly decoding hypotheses early in the decoding. The lexicon can therefore be composed with the language model while simultaneously optimizing the resulting transducer.</p>
</div>
<div id="S3.SS2.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p5.4" class="ltx_p">Finally, the <span id="S3.SS2.SSS2.p5.4.1" class="ltx_text ltx_markedasmath">Replace</span> operation of equation (<a href="#S3.E2" title="In 3.2.1 Language Model Adaptation ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) is also delayed. This allows to further break the decoding graph into smaller distinct pieces: the <math id="S3.SS2.SSS2.p5.2.m2.1" class="ltx_Math" alttext="HCL" display="inline"><semantics id="S3.SS2.SSS2.p5.2.m2.1a"><mrow id="S3.SS2.SSS2.p5.2.m2.1.1" xref="S3.SS2.SSS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p5.2.m2.1.1.2" xref="S3.SS2.SSS2.p5.2.m2.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p5.2.m2.1.1.1" xref="S3.SS2.SSS2.p5.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS2.p5.2.m2.1.1.3" xref="S3.SS2.SSS2.p5.2.m2.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p5.2.m2.1.1.1a" xref="S3.SS2.SSS2.p5.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS2.p5.2.m2.1.1.4" xref="S3.SS2.SSS2.p5.2.m2.1.1.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.2.m2.1b"><apply id="S3.SS2.SSS2.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1"><times id="S3.SS2.SSS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.1"></times><ci id="S3.SS2.SSS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.2">𝐻</ci><ci id="S3.SS2.SSS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.3">𝐶</ci><ci id="S3.SS2.SSS2.p5.2.m2.1.1.4.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1.4">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.2.m2.1c">HCL</annotation></semantics></math> transducer mapping the output of the acoustic model to words, the query language model <math id="S3.SS2.SSS2.p5.3.m3.1" class="ltx_Math" alttext="G_{p}" display="inline"><semantics id="S3.SS2.SSS2.p5.3.m3.1a"><msub id="S3.SS2.SSS2.p5.3.m3.1.1" xref="S3.SS2.SSS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p5.3.m3.1.1.2" xref="S3.SS2.SSS2.p5.3.m3.1.1.2.cmml">G</mi><mi id="S3.SS2.SSS2.p5.3.m3.1.1.3" xref="S3.SS2.SSS2.p5.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.3.m3.1b"><apply id="S3.SS2.SSS2.p5.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1.2">𝐺</ci><ci id="S3.SS2.SSS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.3.m3.1c">G_{p}</annotation></semantics></math>, and the entities languages models <math id="S3.SS2.SSS2.p5.4.m4.3" class="ltx_Math" alttext="\{G_{e_{i}}\,,\forall i\in[1,n]\}" display="inline"><semantics id="S3.SS2.SSS2.p5.4.m4.3a"><mrow id="S3.SS2.SSS2.p5.4.m4.3.3.1" xref="S3.SS2.SSS2.p5.4.m4.3.3.2.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p5.4.m4.3.3.1.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.2.cmml">{</mo><mrow id="S3.SS2.SSS2.p5.4.m4.3.3.1.1" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.cmml"><mrow id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.3.cmml"><msub id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.3.cmml">,</mo><mrow id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.1" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.1.cmml">∀</mo><mi id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.2.cmml">i</mi></mrow></mrow><mo id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.3.cmml">∈</mo><mrow id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.1.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.2.1" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.1.cmml">[</mo><mn id="S3.SS2.SSS2.p5.4.m4.1.1" xref="S3.SS2.SSS2.p5.4.m4.1.1.cmml">1</mn><mo id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.2.2" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.1.cmml">,</mo><mi id="S3.SS2.SSS2.p5.4.m4.2.2" xref="S3.SS2.SSS2.p5.4.m4.2.2.cmml">n</mi><mo stretchy="false" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.2.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS2.p5.4.m4.3.3.1.3" xref="S3.SS2.SSS2.p5.4.m4.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.4.m4.3b"><set id="S3.SS2.SSS2.p5.4.m4.3.3.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1"><apply id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1"><in id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.3.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.3"></in><list id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.3.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2"><apply id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.2">𝐺</ci><apply id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.1">for-all</csymbol><ci id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.2.2.2.2">𝑖</ci></apply></list><interval closure="closed" id="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.3.3.1.1.4.2"><cn type="integer" id="S3.SS2.SSS2.p5.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1">1</cn><ci id="S3.SS2.SSS2.p5.4.m4.2.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.2.2">𝑛</ci></interval></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.4.m4.3c">\{G_{e_{i}}\,,\forall i\in[1,n]\}</annotation></semantics></math>. Formally, at runtime, the dynamic decoding graph is created using the following formula</p>
</div>
<div id="S3.SS2.SSS2.p6" class="ltx_para ltx_noindent">
<table id="Sx2.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\displaystyle(HCL)\circ\text{DynamicReplace}(G_{p},\{G_{e_{i}}\,,\forall i\in[1,n]\})\ ," display="inline"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.4.cmml">L</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E4.m1.3.3.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.2.cmml">∘</mo><mtext id="S3.E4.m1.3.3.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.3a.cmml">DynamicReplace</mtext></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.4" xref="S3.E4.m1.3.3.1.1.4.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml">(</mo><msub id="S3.E4.m1.3.3.1.1.2.1.1" xref="S3.E4.m1.3.3.1.1.2.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.2.1.1.2" xref="S3.E4.m1.3.3.1.1.2.1.1.2.cmml">G</mi><mi id="S3.E4.m1.3.3.1.1.2.1.1.3" xref="S3.E4.m1.3.3.1.1.2.1.1.3.cmml">p</mi></msub><mo id="S3.E4.m1.3.3.1.1.3.2.4" xref="S3.E4.m1.3.3.1.1.3.3.cmml">,</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.2.1" xref="S3.E4.m1.3.3.1.1.3.2.2.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.2.1.2" xref="S3.E4.m1.3.3.1.1.3.2.2.2.cmml">{</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.2.1.1" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.3.cmml"><msub id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.2.cmml">G</mi><msub id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.3.cmml">,</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.cmml"><mo rspace="0.167em" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.1" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.1.cmml">∀</mo><mi id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.2.cmml">i</mi></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.3.2.2.1.1.3" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.3.cmml">∈</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.2.1" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.1.cmml">[</mo><mn id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">1</mn><mo id="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.1.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">n</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.2.3" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.2.1.3" xref="S3.E4.m1.3.3.1.1.3.2.2.2.cmml">}</mo></mrow><mo rspace="0.500em" stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.5" xref="S3.E4.m1.3.3.1.1.3.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><times id="S3.E4.m1.3.3.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.4"></times><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><compose id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2"></compose><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1"></times><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2">𝐻</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3">𝐶</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.4">𝐿</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.3a.cmml" xref="S3.E4.m1.3.3.1.1.1.3"><mtext id="S3.E4.m1.3.3.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.3">DynamicReplace</mtext></ci></apply><interval closure="open" id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2"><apply id="S3.E4.m1.3.3.1.1.2.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.2.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.2.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1.2">𝐺</ci><ci id="S3.E4.m1.3.3.1.1.2.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.2.1.1.3">𝑝</ci></apply><set id="S3.E4.m1.3.3.1.1.3.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1"><apply id="S3.E4.m1.3.3.1.1.3.2.2.1.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1"><in id="S3.E4.m1.3.3.1.1.3.2.2.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.3"></in><list id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2"><apply id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.2">𝐺</ci><apply id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.2">𝑒</ci><ci id="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2"><csymbol cd="latexml" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.1">for-all</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.2.2.2.2">𝑖</ci></apply></list><interval closure="closed" id="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.1.1.4.2"><cn type="integer" id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">1</cn><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑛</ci></interval></apply></set></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\displaystyle(HCL)\circ\text{DynamicReplace}(G_{p},\{G_{e_{i}}\,,\forall i\in[1,n]\})\ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS2.p7" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p7.2" class="ltx_p">where the HCL transducer is computed beforehand using regular transducer compositions (i.e. <math id="S3.SS2.SSS2.p7.1.m1.1" class="ltx_Math" alttext="H*C*L" display="inline"><semantics id="S3.SS2.SSS2.p7.1.m1.1a"><mrow id="S3.SS2.SSS2.p7.1.m1.1.1" xref="S3.SS2.SSS2.p7.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p7.1.m1.1.1.2" xref="S3.SS2.SSS2.p7.1.m1.1.1.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p7.1.m1.1.1.1" xref="S3.SS2.SSS2.p7.1.m1.1.1.1.cmml">∗</mo><mi id="S3.SS2.SSS2.p7.1.m1.1.1.3" xref="S3.SS2.SSS2.p7.1.m1.1.1.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p7.1.m1.1.1.1a" xref="S3.SS2.SSS2.p7.1.m1.1.1.1.cmml">∗</mo><mi id="S3.SS2.SSS2.p7.1.m1.1.1.4" xref="S3.SS2.SSS2.p7.1.m1.1.1.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p7.1.m1.1b"><apply id="S3.SS2.SSS2.p7.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1"><times id="S3.SS2.SSS2.p7.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1.1"></times><ci id="S3.SS2.SSS2.p7.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1.2">𝐻</ci><ci id="S3.SS2.SSS2.p7.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1.3">𝐶</ci><ci id="S3.SS2.SSS2.p7.1.m1.1.1.4.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1.4">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p7.1.m1.1c">H*C*L</annotation></semantics></math>) and <math id="S3.SS2.SSS2.p7.2.m2.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S3.SS2.SSS2.p7.2.m2.1a"><mo id="S3.SS2.SSS2.p7.2.m2.1.1" xref="S3.SS2.SSS2.p7.2.m2.1.1.cmml">∘</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p7.2.m2.1b"><compose id="S3.SS2.SSS2.p7.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p7.2.m2.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p7.2.m2.1c">\circ</annotation></semantics></math> denotes the delayed transducer composition with composition filters.</p>
</div>
<div id="S3.SS2.SSS2.p8" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p8.1" class="ltx_p">These improvements yield real time decoding on a Raspberry Pi 3 with a small overhead compared to a <em id="S3.SS2.SSS2.p8.1.1" class="ltx_emph ltx_font_italic">static model</em>, and preserve decoding accuracy while reducing drastically the size of the model on disk. Additionally, this greatly reduces the training time of the LM. Finally, breaking down the LM into smaller, separate parts makes it possible to efficiently update it. It particular, performing on-device injection of new values in the LM becomes straightforward, enabling users to locally customize their SLU engine without going through the Snips web console. This feature is described in the following.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>On-device personalization</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Using contextual information in ASR is a promising approach to improving the recognition results by biasing the language model towards a user-specific vocabulary <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">aleksic2015bringing </a></cite>. A straightforward way of customizing the LM previously described is to update the list of values each entity can take. For instance, if we consider an assistant dedicated to making phone calls (“<span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_typewriter">call (Jane Doe)[contact]</span>”), the user’s list of contacts could be added to the values of the entity “<span id="S3.SS2.SSS3.p1.1.2" class="ltx_text ltx_font_typewriter">contact</span>” in an embedded way, without this sensitive data ever leaving the device. This operation is called entity injection in the following.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p2.7" class="ltx_p">In order to perform entity injection, two modifications of the decoding graph are necessary. First, the new words and their pronunciations are added to the <math id="S3.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="HCL" display="inline"><semantics id="S3.SS2.SSS3.p2.1.m1.1a"><mrow id="S3.SS2.SSS3.p2.1.m1.1.1" xref="S3.SS2.SSS3.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p2.1.m1.1.1.2" xref="S3.SS2.SSS3.p2.1.m1.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.1.m1.1.1.1" xref="S3.SS2.SSS3.p2.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.1.m1.1.1.3" xref="S3.SS2.SSS3.p2.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.1.m1.1.1.1a" xref="S3.SS2.SSS3.p2.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.1.m1.1.1.4" xref="S3.SS2.SSS3.p2.1.m1.1.1.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.1.m1.1b"><apply id="S3.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1"><times id="S3.SS2.SSS3.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.1"></times><ci id="S3.SS2.SSS3.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.2">𝐻</ci><ci id="S3.SS2.SSS3.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.3">𝐶</ci><ci id="S3.SS2.SSS3.p2.1.m1.1.1.4.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1.4">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.1.m1.1c">HCL</annotation></semantics></math> transducer. Second, the new values are added to the corresponding entity wFST <math id="S3.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS3.p2.2.m2.1a"><msub id="S3.SS2.SSS3.p2.2.m2.1.1" xref="S3.SS2.SSS3.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS3.p2.2.m2.1.1.2" xref="S3.SS2.SSS3.p2.2.m2.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS3.p2.2.m2.1.1.3" xref="S3.SS2.SSS3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS3.p2.2.m2.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS3.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS3.p2.2.m2.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.2.m2.1b"><apply id="S3.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1.2">𝐺</ci><apply id="S3.SS2.SSS3.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.2.m2.1c">G_{e_{i}}</annotation></semantics></math>.
The pronunciations of the words already supported by the ASR are cached to avoid recomputing them on-device. Pronunciations for words absent from the <math id="S3.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="HCL" display="inline"><semantics id="S3.SS2.SSS3.p2.3.m3.1a"><mrow id="S3.SS2.SSS3.p2.3.m3.1.1" xref="S3.SS2.SSS3.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p2.3.m3.1.1.2" xref="S3.SS2.SSS3.p2.3.m3.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.3.m3.1.1.1" xref="S3.SS2.SSS3.p2.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.3.m3.1.1.3" xref="S3.SS2.SSS3.p2.3.m3.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.3.m3.1.1.1a" xref="S3.SS2.SSS3.p2.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.3.m3.1.1.4" xref="S3.SS2.SSS3.p2.3.m3.1.1.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.3.m3.1b"><apply id="S3.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1"><times id="S3.SS2.SSS3.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1.1"></times><ci id="S3.SS2.SSS3.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1.2">𝐻</ci><ci id="S3.SS2.SSS3.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1.3">𝐶</ci><ci id="S3.SS2.SSS3.p2.3.m3.1.1.4.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1.4">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.3.m3.1c">HCL</annotation></semantics></math> transducer are computed via an embedded G2P. The updated <math id="S3.SS2.SSS3.p2.4.m4.1" class="ltx_Math" alttext="HCL" display="inline"><semantics id="S3.SS2.SSS3.p2.4.m4.1a"><mrow id="S3.SS2.SSS3.p2.4.m4.1.1" xref="S3.SS2.SSS3.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS3.p2.4.m4.1.1.2" xref="S3.SS2.SSS3.p2.4.m4.1.1.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.4.m4.1.1.1" xref="S3.SS2.SSS3.p2.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.4.m4.1.1.3" xref="S3.SS2.SSS3.p2.4.m4.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.4.m4.1.1.1a" xref="S3.SS2.SSS3.p2.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS2.SSS3.p2.4.m4.1.1.4" xref="S3.SS2.SSS3.p2.4.m4.1.1.4.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.4.m4.1b"><apply id="S3.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1"><times id="S3.SS2.SSS3.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1.1"></times><ci id="S3.SS2.SSS3.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1.2">𝐻</ci><ci id="S3.SS2.SSS3.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1.3">𝐶</ci><ci id="S3.SS2.SSS3.p2.4.m4.1.1.4.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1.4">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.4.m4.1c">HCL</annotation></semantics></math> transducer can then be fully recompiled and optimized. The procedure for adding a new value to <math id="S3.SS2.SSS3.p2.5.m5.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS3.p2.5.m5.1a"><msub id="S3.SS2.SSS3.p2.5.m5.1.1" xref="S3.SS2.SSS3.p2.5.m5.1.1.cmml"><mi id="S3.SS2.SSS3.p2.5.m5.1.1.2" xref="S3.SS2.SSS3.p2.5.m5.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS3.p2.5.m5.1.1.3" xref="S3.SS2.SSS3.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.5.m5.1.1.3.2" xref="S3.SS2.SSS3.p2.5.m5.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS3.p2.5.m5.1.1.3.3" xref="S3.SS2.SSS3.p2.5.m5.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.5.m5.1b"><apply id="S3.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.5.m5.1.1.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.5.m5.1.1.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1.2">𝐺</ci><apply id="S3.SS2.SSS3.p2.5.m5.1.1.3.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS3.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.5.m5.1c">G_{e_{i}}</annotation></semantics></math> varies depending on whether a union of word acceptors or an n-gram model is used. In the former case, an acceptor of the new value is created and its union with <math id="S3.SS2.SSS3.p2.6.m6.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS3.p2.6.m6.1a"><msub id="S3.SS2.SSS3.p2.6.m6.1.1" xref="S3.SS2.SSS3.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS3.p2.6.m6.1.1.2" xref="S3.SS2.SSS3.p2.6.m6.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS3.p2.6.m6.1.1.3" xref="S3.SS2.SSS3.p2.6.m6.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.6.m6.1.1.3.2" xref="S3.SS2.SSS3.p2.6.m6.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS3.p2.6.m6.1.1.3.3" xref="S3.SS2.SSS3.p2.6.m6.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.6.m6.1b"><apply id="S3.SS2.SSS3.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1.2">𝐺</ci><apply id="S3.SS2.SSS3.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.6.m6.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.6.m6.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS3.p2.6.m6.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.6.m6.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.6.m6.1c">G_{e_{i}}</annotation></semantics></math> is computed. In the latter case, we update the n-gram counts with the new values and recompute <math id="S3.SS2.SSS3.p2.7.m7.1" class="ltx_Math" alttext="G_{e_{i}}" display="inline"><semantics id="S3.SS2.SSS3.p2.7.m7.1a"><msub id="S3.SS2.SSS3.p2.7.m7.1.1" xref="S3.SS2.SSS3.p2.7.m7.1.1.cmml"><mi id="S3.SS2.SSS3.p2.7.m7.1.1.2" xref="S3.SS2.SSS3.p2.7.m7.1.1.2.cmml">G</mi><msub id="S3.SS2.SSS3.p2.7.m7.1.1.3" xref="S3.SS2.SSS3.p2.7.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.7.m7.1.1.3.2" xref="S3.SS2.SSS3.p2.7.m7.1.1.3.2.cmml">e</mi><mi id="S3.SS2.SSS3.p2.7.m7.1.1.3.3" xref="S3.SS2.SSS3.p2.7.m7.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.7.m7.1b"><apply id="S3.SS2.SSS3.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.7.m7.1.1.1.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.7.m7.1.1.2.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1.2">𝐺</ci><apply id="S3.SS2.SSS3.p2.7.m7.1.1.3.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.7.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.7.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1.3.2">𝑒</ci><ci id="S3.SS2.SSS3.p2.7.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.7.m7.1c">G_{e_{i}}</annotation></semantics></math> using an embedded n-gram engine. The time required for the complete entity injection procedure just described ranges from a few seconds for small assistants, to a few dozen seconds for larger assistants supporting a vocabulary comprising tens of thousands of words. Breaking down the decoding graph into smaller, computationally manageable pieces, therefore allows to modify the model directly on device in order to provide a personalized user experience and increase the overall accuracy of the SLU component.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Confidence scoring</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">An important challenge of specialized SLU systems trained on small amounts of domain-specific text data is the ability to detect out-of-vocabulary (OOV) words. Indeed, while a sufficient amount of specific training data may guarantee sampling the important words which allow to discriminate between different intents, it will in general prove unable to correctly sample filler words from general spoken language. As a consequence, a specialized ASR such as the one described in the previous sections will tend to approximate unknown words using phonetically related ones from its vocabulary, potentially harming the subsequent NLU.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p">One way of addressing this issue is to extract a word-level confidence score from the ASR, assigning a probability for the word to be correctly decoded. Confidence scoring is a notoriously hard problem in speech recognition <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">jiang2005confidence </a>; <a href="#bib.bib59" title="" class="ltx_ref">yu2011calibration </a></cite>. Our approach is based on the so-called “confusion network” representation of the hypotheses of the ASR <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref">mangu2000finding </a>; <a href="#bib.bib57" title="" class="ltx_ref">xu2011minimum </a></cite> (see Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2.4 Confidence scoring ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). A confusion network is a graph encoding, for each speech segment in an utterance, the competing decoding hypotheses along with their posterior probability, thus providing a richer output than the <math id="S3.SS2.SSS4.p2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS2.SSS4.p2.1.m1.1a"><mn id="S3.SS2.SSS4.p2.1.m1.1.1" xref="S3.SS2.SSS4.p2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS4.p2.1.m1.1b"><cn type="integer" id="S3.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS4.p2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS4.p2.1.m1.1c">1</annotation></semantics></math>-best decoding hypothesis. In particular, confusion networks in conjunction with NLU systems typically improve end-to-end performance in speech-to-meaning tasks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref">hakkani2006beyond </a>; <a href="#bib.bib54" title="" class="ltx_ref">crfinslu1 </a>; <a href="#bib.bib53" title="" class="ltx_ref">tur2013semantic </a></cite>. In the following, we restrict our use of confusion networks to a greedy decoder that outputs, for each speech segment, the most probable decoded word along with its probability.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/1805.10190/assets/x4.png" id="S3.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="100" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Graphical representation of a confusion network. The vertices of this graph correspond to a time stamp in the audio signal, while the edges carry competing decoding hypotheses, along with their probability.</figcaption>
</figure>
<div id="S3.SS2.SSS4.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p">In this context, our strategy for identifying OOVs is to set a threshold on this word-level probability. Below this threshold, the word is declared misunderstood. In practice, a post-processing step is used to remove these words from the decoded sentence, replacing them with a special OOV symbol. This allows the SLU pipeline to proceed with the words the ASR has understood with sufficient probability, leaving out the filler words which are unimportant to extract the intent and the slots from the query, thus preserving the generalization properties of the SLU in the presence of unknown filler words (see section <a href="#S4" title="4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for a quantitative evaluation). Finally, we may define a sentence-level confidence by simply taking the geometric mean of the word-level confidence scores.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Natural Language Understanding</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">The Natural Language Understanding component of the Snips Voice Platform extracts structured data from queries written in natural language. Snips NLU – a Python library – can be used for training and inference, with a Rust implementation focusing solely on inference. Both have been recently open-sourced <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">SnipsNLU </a>; <a href="#bib.bib49" title="" class="ltx_ref">SnipsNLURust </a></cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">Three tasks are successively performed. <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_italic">Intent Classification</span> consists in extracting the <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_italic">intent</span> expressed in the query (e.g. <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_typewriter">SetTemperature</span> or <span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_typewriter">SwitchLightOn</span>). Once the intent is known, <span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_italic">Slot Filling</span> aims to extract the <span id="S3.SS3.p2.1.6" class="ltx_text ltx_font_italic">slots</span>, i.e. the values of the entities present in the query. Finally, <span id="S3.SS3.p2.1.7" class="ltx_text ltx_font_italic">Entity Resolution</span> focuses on built-in entities, such as date and times, durations, temperatures, for which Snips provides an extra resolution step. It basically transforms entity values such as <span id="S3.SS3.p2.1.8" class="ltx_text ltx_font_typewriter">"tomorrow evening"</span> into formatted values such as <span id="S3.SS3.p2.1.9" class="ltx_text ltx_font_typewriter">"2018-04-19 19:00:00 +00:00"</span>. Snippet <a href="#LST1" title="Snippet 1 ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates a typical output of the NLU component.</p>
</div>
<figure id="LST1" class="ltx_float ltx_lstlisting">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Snippet 1: </span>Typical parsing result for the input <span id="LST1.2.1" class="ltx_text ltx_font_typewriter">"Set the temperature to 23°C in the living room"</span></figcaption>
<div id="LST1.3" class="ltx_listing ltx_lst_language_Java ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ewogICJ0ZXh0IjogPEBcZGFya2dyZWVueyJTZXQgdGhlIHRlbXBlcmF0dXJlIHRvIDIzwrBDIGluIHRoZSBsaXZpbmcgcm9vbSJ9QD4sCiAgImludGVudCI6IHsKICAgICJpbnRlbnROYW1lIjogPEBcZGFya2dyZWVueyJTZXRUZW1wZXJhdHVyZSJ9QD4sCiAgICAicHJvYmFiaWxpdHkiOiA8QFxwdXJlYmx1ZXswLjk1fUA+CiAgfSwKICAic2xvdHMiOiBbCiAgICB7CiAgICAgICJlbnRpdHkiOiA8QFxkYXJrZ3JlZW57InJvb20ifUA+LAogICAgICAidmFsdWUiOiA8QFxkYXJrZ3JlZW57ImxpdmluZyByb29tIn1APiwKICAgIH0sCiAgICB7CiAgICAgICJlbnRpdHkiOiA8QFxkYXJrZ3JlZW57InNuaXBzL3RlbXBlcmF0dXJlIn1APiwKICAgICAgInZhbHVlIjogewogICAgICAgICAia2luZCI6IDxAXGRhcmtncmVlbnsiVGVtcGVyYXR1cmUifUA+LAogICAgICAgICAidW5pdCI6IDxAXGRhcmtncmVlbnsiY2Vsc2l1cyJ9QD4sCiAgICAgICAgICJ2YWx1ZSI6IDxAXHB1cmVibHVlezIzLjB9QD4KICAgICAgfQogICAgfQogIF0KfQ==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx2.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"text"</span><span id="lstnumberx2.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx2.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"Set the temperature to 23°C in the living room"</span><span id="lstnumberx2.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx3.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"intent"</span><span id="lstnumberx3.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.5" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx4.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"intentName"</span><span id="lstnumberx4.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx4.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"SetTemperature"</span><span id="lstnumberx4.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx5.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"probability"</span><span id="lstnumberx5.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx5.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.5" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">0.95</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx6.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx7.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"slots"</span><span id="lstnumberx7.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx7.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.5" class="ltx_text ltx_font_typewriter">[</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx8.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx9.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"entity"</span><span id="lstnumberx9.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx9.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"room"</span><span id="lstnumberx9.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"value"</span><span id="lstnumberx10.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx10.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx10.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"living room"</span><span id="lstnumberx10.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter">},</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx12.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"entity"</span><span id="lstnumberx13.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx13.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"snips/temperature"</span><span id="lstnumberx13.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx14.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"value"</span><span id="lstnumberx14.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx14.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.5" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_space ltx_font_typewriter">         </span><span id="lstnumberx15.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"kind"</span><span id="lstnumberx15.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx15.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx15.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"Temperature"</span><span id="lstnumberx15.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_typewriter">         </span><span id="lstnumberx16.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"unit"</span><span id="lstnumberx16.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.5" class="ltx_text ltx_font_typewriter" style="color:#178212;">"celsius"</span><span id="lstnumberx16.6" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_typewriter">         </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_string ltx_font_typewriter">"value"</span><span id="lstnumberx17.3" class="ltx_text ltx_font_typewriter">:</span><span id="lstnumberx17.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx17.5" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">23.0</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx18.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx19.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter">  </span><span id="lstnumberx20.2" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
</figure>
<figure id="S3.F6" class="ltx_figure">
<p id="S3.F6.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F6.1.1.1" class="ltx_text"><img src="/html/1805.10190/assets/x5.png" id="S3.F6.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="326" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Natural Language Understanding pipeline</figcaption>
</figure>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Models</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">The Snips NLU pipeline (Figure <a href="#S3.F6" title="Figure 6 ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) contains a main component, the <span id="S3.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">NLU Engine</span>, which itself is composed of several components. A first component is the <span id="S3.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_italic">Intent Parser</span>, which performs both intent classification and slot filling. It does not resolve entity values. The NLU Engine calls two intent parsers successively:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">a deterministic intent parser</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.i2.p1.1" class="ltx_p">a probabilistic intent parser</p>
</div>
</li>
</ol>
<p id="S3.SS3.SSS1.p1.2" class="ltx_p">The second one is called only when nothing is extracted by the first one.</p>
</div>
<section id="S3.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Deterministic Intent Parser.</h5>

<div id="S3.SS3.SSS1.Px1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px1.p1.1" class="ltx_p">The goal of the deterministic intent parser is to provide robustness and a predictable experience for the user as it is guaranteed to achieve a <math id="S3.SS3.SSS1.Px1.p1.1.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.1.m1.1a"><mn id="S3.SS3.SSS1.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.1.m1.1b"><cn type="float" id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.1.m1.1c">1.0</annotation></semantics></math> F1-score on the training examples.
Its implementation relies on regular expressions.
The queries contained in the training data are used to build patterns covering all combinations of entity values.
Let us consider, for instance, the training sample:</p>
</div>
<div id="S3.SS3.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p2.1" class="ltx_p ltx_align_center"><span id="S3.SS3.SSS1.Px1.p2.1.1" class="ltx_text ltx_font_typewriter">set the [kitchen](room) lights to [blue](color)</span></p>
</div>
<div id="S3.SS3.SSS1.Px1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px1.p3.1" class="ltx_p">Let us assume that the set of possible values for the <span id="S3.SS3.SSS1.Px1.p3.1.1" class="ltx_text ltx_font_typewriter">room</span> entity are <span id="S3.SS3.SSS1.Px1.p3.1.2" class="ltx_text ltx_font_typewriter">kitchen, hall, bedroom</span> and those for the <span id="S3.SS3.SSS1.Px1.p3.1.3" class="ltx_text ltx_font_typewriter">color</span> entity are <span id="S3.SS3.SSS1.Px1.p3.1.4" class="ltx_text ltx_font_typewriter">blue, yellow, red</span>. A representation of the generated pattern for this sample is:</p>
</div>
<div id="S3.SS3.SSS1.Px1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p4.1" class="ltx_p ltx_align_center"><span id="S3.SS3.SSS1.Px1.p4.1.1" class="ltx_text ltx_font_typewriter">set the (?P&lt;room&gt;kitchen|hall|bedroom) lights to (?P&lt;color&gt;blue|yellow|red)</span></p>
</div>
</section>
<section id="S3.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Probabilistic Intent Parser.</h5>

<div id="S3.SS3.SSS1.Px2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px2.p1.1" class="ltx_p">The probabilistic intent parser aims at extending parsing beyond training examples and recognizing variations which do not appear in the training data. It provides the generalization power that the deterministic parser lacks.
This parser runs in two cascaded steps: intent classification and slot filling. The intent classification is implemented with a logistic regression trained on the queries from every intent. The slot-filling step consists in several linear-chain Conditional Random Fields (CRFs) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref">crf01 </a></cite>, each of them being trained for a specific intent. Once the intent is extracted by the intent classifier, the corresponding slot filler is used to extract slots from the query.
The choice of CRFs for the slot-filling step results from careful considerations and experiments. They are indeed a standard approach for this task, and are known to have low generalization error <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">crfinslu1 </a>; <a href="#bib.bib45" title="" class="ltx_ref">crfinslu2 </a></cite>. Recently, more computationally demanding approaches based on deep learning models have been proposed <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib31" title="" class="ltx_ref">mesnil2013investigation </a>; <a href="#bib.bib30" title="" class="ltx_ref">mesnil2015using </a></cite>. Our experiments however showed that these approaches do not yield any significant gain in accuracy in the typical training size regime of custom voice assistants (a few hundred queries). The lightest option was therefore favored.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px2.p2.1" class="ltx_p">On top of the classical features used in slot-filling tasks such as n-grams, case, shape, etc. <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref">tkachenko2012named </a></cite>, additional features are crafted. In this kind of task, it appears that leveraging external knowledge is crucial. Hence, we apply a built-in entity extractor (see next paragraph about Entity Resolution) to build features that indicate whether or not a token in the sentence is part of a built-in entity. The value of the feature is the corresponding entity, if one is found, augmented with a BILOU coding scheme, indicating the position of the token in the matching entity value<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>BILOU is a standard acronym referring to the possible positions of a symbol in a sequence: Beginning, Inside, Last, Outside, Unit.</span></span></span>. We find empirically that the presence of such features improves the overall accuracy, thanks to the robustness of the built-in entities extractor.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px2.p3.1" class="ltx_p">The problem of data sparsity is addressed by integrating features based on word clusters <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref">liang2005semi </a></cite>. More specifically, we use Brown clusters <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">brown1992class </a></cite> released by the authors of <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">owoputi2013improved </a></cite>, as well as word clusters built from word2vec embeddings <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref">mikolov2013efficient </a></cite> using k-means clustering. We find that the use of these features helps in reducing generalization error, by bringing the effective size of the vocabulary from typically 50K words down to a few hundred word clusters.
Finally, gazetteer features are built, based on entity values provided in the training data. One gazetteer is created per entity type, and used to match tokens via a BILOU coding scheme. Table <a href="#S3.T5" title="Table 5 ‣ Probabilistic Intent Parser. ‣ 3.3.1 Models ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> displays some examples of features used in Snips NLU.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px2.p4.4" class="ltx_p">Overfitting is avoided by dropping a fraction of the features during training. More precisely, each feature <math id="S3.SS3.SSS1.Px2.p4.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS3.SSS1.Px2.p4.1.m1.1a"><mi id="S3.SS3.SSS1.Px2.p4.1.m1.1.1" xref="S3.SS3.SSS1.Px2.p4.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px2.p4.1.m1.1b"><ci id="S3.SS3.SSS1.Px2.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px2.p4.1.m1.1c">f</annotation></semantics></math> is assigned a dropout probability <math id="S3.SS3.SSS1.Px2.p4.2.m2.1" class="ltx_Math" alttext="p_{f}" display="inline"><semantics id="S3.SS3.SSS1.Px2.p4.2.m2.1a"><msub id="S3.SS3.SSS1.Px2.p4.2.m2.1.1" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.2" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.3" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px2.p4.2.m2.1b"><apply id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.Px2.p4.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.Px2.p4.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px2.p4.2.m2.1c">p_{f}</annotation></semantics></math>. For each training example, we compute the features and then erase feature <math id="S3.SS3.SSS1.Px2.p4.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS3.SSS1.Px2.p4.3.m3.1a"><mi id="S3.SS3.SSS1.Px2.p4.3.m3.1.1" xref="S3.SS3.SSS1.Px2.p4.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px2.p4.3.m3.1b"><ci id="S3.SS3.SSS1.Px2.p4.3.m3.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px2.p4.3.m3.1c">f</annotation></semantics></math> with probability <math id="S3.SS3.SSS1.Px2.p4.4.m4.1" class="ltx_Math" alttext="p_{f}" display="inline"><semantics id="S3.SS3.SSS1.Px2.p4.4.m4.1a"><msub id="S3.SS3.SSS1.Px2.p4.4.m4.1.1" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.2" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.3" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px2.p4.4.m4.1b"><apply id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.Px2.p4.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.Px2.p4.4.m4.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px2.p4.4.m4.1c">p_{f}</annotation></semantics></math>. Without this mechanism, we typically observed that the CRF learns to tag every value matching the entity gazetteer while discarding all those absent from it.</p>
</div>
<figure id="S3.T5" class="ltx_table ltx_align_center">
<table id="S3.T5.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T5.6.7.1" class="ltx_tr">
<th id="S3.T5.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r">Feature</th>
<th id="S3.T5.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.2.1" class="ltx_text ltx_font_typewriter">Will</span></th>
<th id="S3.T5.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.3.1" class="ltx_text ltx_font_typewriter">it</span></th>
<th id="S3.T5.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.4.1" class="ltx_text ltx_font_typewriter">rain</span></th>
<th id="S3.T5.6.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.5.1" class="ltx_text ltx_font_typewriter">in</span></th>
<th id="S3.T5.6.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.6.1" class="ltx_text ltx_font_typewriter">two</span></th>
<th id="S3.T5.6.7.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.7.1" class="ltx_text ltx_font_typewriter">days</span></th>
<th id="S3.T5.6.7.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.8.1" class="ltx_text ltx_font_typewriter">in</span></th>
<th id="S3.T5.6.7.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T5.6.7.1.9.1" class="ltx_text ltx_font_typewriter">Paris</span></th>
</tr>
<tr id="S3.T5.1.1" class="ltx_tr">
<th id="S3.T5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S3.T5.1.1.1.m1.1" class="ltx_Math" alttext="w_{-1}" display="inline"><semantics id="S3.T5.1.1.1.m1.1a"><msub id="S3.T5.1.1.1.m1.1.1" xref="S3.T5.1.1.1.m1.1.1.cmml"><mi id="S3.T5.1.1.1.m1.1.1.2" xref="S3.T5.1.1.1.m1.1.1.2.cmml">w</mi><mrow id="S3.T5.1.1.1.m1.1.1.3" xref="S3.T5.1.1.1.m1.1.1.3.cmml"><mo id="S3.T5.1.1.1.m1.1.1.3a" xref="S3.T5.1.1.1.m1.1.1.3.cmml">−</mo><mn id="S3.T5.1.1.1.m1.1.1.3.2" xref="S3.T5.1.1.1.m1.1.1.3.2.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T5.1.1.1.m1.1b"><apply id="S3.T5.1.1.1.m1.1.1.cmml" xref="S3.T5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T5.1.1.1.m1.1.1.1.cmml" xref="S3.T5.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T5.1.1.1.m1.1.1.2.cmml" xref="S3.T5.1.1.1.m1.1.1.2">𝑤</ci><apply id="S3.T5.1.1.1.m1.1.1.3.cmml" xref="S3.T5.1.1.1.m1.1.1.3"><minus id="S3.T5.1.1.1.m1.1.1.3.1.cmml" xref="S3.T5.1.1.1.m1.1.1.3"></minus><cn type="integer" id="S3.T5.1.1.1.m1.1.1.3.2.cmml" xref="S3.T5.1.1.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.1.1.1.m1.1c">w_{-1}</annotation></semantics></math></th>
<th id="S3.T5.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S3.T5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.3.1" class="ltx_text ltx_font_typewriter">Will</span></th>
<th id="S3.T5.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.4.1" class="ltx_text ltx_font_typewriter">it</span></th>
<th id="S3.T5.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.5.1" class="ltx_text ltx_font_typewriter">rain</span></th>
<th id="S3.T5.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.6.1" class="ltx_text ltx_font_typewriter">in</span></th>
<th id="S3.T5.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.7.1" class="ltx_text ltx_font_typewriter">two</span></th>
<th id="S3.T5.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.8.1" class="ltx_text ltx_font_typewriter">days</span></th>
<th id="S3.T5.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T5.1.1.9.1" class="ltx_text ltx_font_typewriter">in</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T5.2.2" class="ltx_tr">
<td id="S3.T5.2.2.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S3.T5.2.2.1.m1.1" class="ltx_Math" alttext="brown\_cluster" display="inline"><semantics id="S3.T5.2.2.1.m1.1a"><mrow id="S3.T5.2.2.1.m1.1.1" xref="S3.T5.2.2.1.m1.1.1.cmml"><mi id="S3.T5.2.2.1.m1.1.1.2" xref="S3.T5.2.2.1.m1.1.1.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.3" xref="S3.T5.2.2.1.m1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1a" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.4" xref="S3.T5.2.2.1.m1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1b" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.5" xref="S3.T5.2.2.1.m1.1.1.5.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1c" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.6" xref="S3.T5.2.2.1.m1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1d" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.T5.2.2.1.m1.1.1.7" xref="S3.T5.2.2.1.m1.1.1.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1e" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.8" xref="S3.T5.2.2.1.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1f" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.9" xref="S3.T5.2.2.1.m1.1.1.9.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1g" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.10" xref="S3.T5.2.2.1.m1.1.1.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1h" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.11" xref="S3.T5.2.2.1.m1.1.1.11.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1i" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.12" xref="S3.T5.2.2.1.m1.1.1.12.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1j" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.13" xref="S3.T5.2.2.1.m1.1.1.13.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.2.2.1.m1.1.1.1k" xref="S3.T5.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.2.2.1.m1.1.1.14" xref="S3.T5.2.2.1.m1.1.1.14.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.2.2.1.m1.1b"><apply id="S3.T5.2.2.1.m1.1.1.cmml" xref="S3.T5.2.2.1.m1.1.1"><times id="S3.T5.2.2.1.m1.1.1.1.cmml" xref="S3.T5.2.2.1.m1.1.1.1"></times><ci id="S3.T5.2.2.1.m1.1.1.2.cmml" xref="S3.T5.2.2.1.m1.1.1.2">𝑏</ci><ci id="S3.T5.2.2.1.m1.1.1.3.cmml" xref="S3.T5.2.2.1.m1.1.1.3">𝑟</ci><ci id="S3.T5.2.2.1.m1.1.1.4.cmml" xref="S3.T5.2.2.1.m1.1.1.4">𝑜</ci><ci id="S3.T5.2.2.1.m1.1.1.5.cmml" xref="S3.T5.2.2.1.m1.1.1.5">𝑤</ci><ci id="S3.T5.2.2.1.m1.1.1.6.cmml" xref="S3.T5.2.2.1.m1.1.1.6">𝑛</ci><ci id="S3.T5.2.2.1.m1.1.1.7.cmml" xref="S3.T5.2.2.1.m1.1.1.7">_</ci><ci id="S3.T5.2.2.1.m1.1.1.8.cmml" xref="S3.T5.2.2.1.m1.1.1.8">𝑐</ci><ci id="S3.T5.2.2.1.m1.1.1.9.cmml" xref="S3.T5.2.2.1.m1.1.1.9">𝑙</ci><ci id="S3.T5.2.2.1.m1.1.1.10.cmml" xref="S3.T5.2.2.1.m1.1.1.10">𝑢</ci><ci id="S3.T5.2.2.1.m1.1.1.11.cmml" xref="S3.T5.2.2.1.m1.1.1.11">𝑠</ci><ci id="S3.T5.2.2.1.m1.1.1.12.cmml" xref="S3.T5.2.2.1.m1.1.1.12">𝑡</ci><ci id="S3.T5.2.2.1.m1.1.1.13.cmml" xref="S3.T5.2.2.1.m1.1.1.13">𝑒</ci><ci id="S3.T5.2.2.1.m1.1.1.14.cmml" xref="S3.T5.2.2.1.m1.1.1.14">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.2.2.1.m1.1c">brown\_cluster</annotation></semantics></math></td>
<td id="S3.T5.2.2.2" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.2.1" class="ltx_text ltx_font_typewriter">001110</span></td>
<td id="S3.T5.2.2.3" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.3.1" class="ltx_text ltx_font_typewriter">011101</span></td>
<td id="S3.T5.2.2.4" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.4.1" class="ltx_text ltx_font_typewriter">111101</span></td>
<td id="S3.T5.2.2.5" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.5.1" class="ltx_text ltx_font_typewriter">101111</span></td>
<td id="S3.T5.2.2.6" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.6.1" class="ltx_text ltx_font_typewriter">111111</span></td>
<td id="S3.T5.2.2.7" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.7.1" class="ltx_text ltx_font_typewriter">111100</span></td>
<td id="S3.T5.2.2.8" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.8.1" class="ltx_text ltx_font_typewriter">101111</span></td>
<td id="S3.T5.2.2.9" class="ltx_td ltx_align_center"><span id="S3.T5.2.2.9.1" class="ltx_text ltx_font_typewriter">111001</span></td>
</tr>
<tr id="S3.T5.3.3" class="ltx_tr">
<td id="S3.T5.3.3.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S3.T5.3.3.1.m1.1" class="ltx_Math" alttext="location\_entity" display="inline"><semantics id="S3.T5.3.3.1.m1.1a"><mrow id="S3.T5.3.3.1.m1.1.1" xref="S3.T5.3.3.1.m1.1.1.cmml"><mi id="S3.T5.3.3.1.m1.1.1.2" xref="S3.T5.3.3.1.m1.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.3" xref="S3.T5.3.3.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1a" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.4" xref="S3.T5.3.3.1.m1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1b" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.5" xref="S3.T5.3.3.1.m1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1c" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.6" xref="S3.T5.3.3.1.m1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1d" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.7" xref="S3.T5.3.3.1.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1e" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.8" xref="S3.T5.3.3.1.m1.1.1.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1f" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.9" xref="S3.T5.3.3.1.m1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1g" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.T5.3.3.1.m1.1.1.10" xref="S3.T5.3.3.1.m1.1.1.10.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1h" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.11" xref="S3.T5.3.3.1.m1.1.1.11.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1i" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.12" xref="S3.T5.3.3.1.m1.1.1.12.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1j" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.13" xref="S3.T5.3.3.1.m1.1.1.13.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1k" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.14" xref="S3.T5.3.3.1.m1.1.1.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1l" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.15" xref="S3.T5.3.3.1.m1.1.1.15.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.3.3.1.m1.1.1.1m" xref="S3.T5.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.3.3.1.m1.1.1.16" xref="S3.T5.3.3.1.m1.1.1.16.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.3.3.1.m1.1b"><apply id="S3.T5.3.3.1.m1.1.1.cmml" xref="S3.T5.3.3.1.m1.1.1"><times id="S3.T5.3.3.1.m1.1.1.1.cmml" xref="S3.T5.3.3.1.m1.1.1.1"></times><ci id="S3.T5.3.3.1.m1.1.1.2.cmml" xref="S3.T5.3.3.1.m1.1.1.2">𝑙</ci><ci id="S3.T5.3.3.1.m1.1.1.3.cmml" xref="S3.T5.3.3.1.m1.1.1.3">𝑜</ci><ci id="S3.T5.3.3.1.m1.1.1.4.cmml" xref="S3.T5.3.3.1.m1.1.1.4">𝑐</ci><ci id="S3.T5.3.3.1.m1.1.1.5.cmml" xref="S3.T5.3.3.1.m1.1.1.5">𝑎</ci><ci id="S3.T5.3.3.1.m1.1.1.6.cmml" xref="S3.T5.3.3.1.m1.1.1.6">𝑡</ci><ci id="S3.T5.3.3.1.m1.1.1.7.cmml" xref="S3.T5.3.3.1.m1.1.1.7">𝑖</ci><ci id="S3.T5.3.3.1.m1.1.1.8.cmml" xref="S3.T5.3.3.1.m1.1.1.8">𝑜</ci><ci id="S3.T5.3.3.1.m1.1.1.9.cmml" xref="S3.T5.3.3.1.m1.1.1.9">𝑛</ci><ci id="S3.T5.3.3.1.m1.1.1.10.cmml" xref="S3.T5.3.3.1.m1.1.1.10">_</ci><ci id="S3.T5.3.3.1.m1.1.1.11.cmml" xref="S3.T5.3.3.1.m1.1.1.11">𝑒</ci><ci id="S3.T5.3.3.1.m1.1.1.12.cmml" xref="S3.T5.3.3.1.m1.1.1.12">𝑛</ci><ci id="S3.T5.3.3.1.m1.1.1.13.cmml" xref="S3.T5.3.3.1.m1.1.1.13">𝑡</ci><ci id="S3.T5.3.3.1.m1.1.1.14.cmml" xref="S3.T5.3.3.1.m1.1.1.14">𝑖</ci><ci id="S3.T5.3.3.1.m1.1.1.15.cmml" xref="S3.T5.3.3.1.m1.1.1.15">𝑡</ci><ci id="S3.T5.3.3.1.m1.1.1.16.cmml" xref="S3.T5.3.3.1.m1.1.1.16">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.3.3.1.m1.1c">location\_entity</annotation></semantics></math></td>
<td id="S3.T5.3.3.2" class="ltx_td"></td>
<td id="S3.T5.3.3.3" class="ltx_td"></td>
<td id="S3.T5.3.3.4" class="ltx_td"></td>
<td id="S3.T5.3.3.5" class="ltx_td"></td>
<td id="S3.T5.3.3.6" class="ltx_td"></td>
<td id="S3.T5.3.3.7" class="ltx_td"></td>
<td id="S3.T5.3.3.8" class="ltx_td"></td>
<td id="S3.T5.3.3.9" class="ltx_td ltx_align_center"><span id="S3.T5.3.3.9.1" class="ltx_text ltx_font_typewriter">U</span></td>
</tr>
<tr id="S3.T5.4.4" class="ltx_tr">
<td id="S3.T5.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S3.T5.4.4.1.m1.1" class="ltx_Math" alttext="datetime\_builtin" display="inline"><semantics id="S3.T5.4.4.1.m1.1a"><mrow id="S3.T5.4.4.1.m1.1.1" xref="S3.T5.4.4.1.m1.1.1.cmml"><mi id="S3.T5.4.4.1.m1.1.1.2" xref="S3.T5.4.4.1.m1.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.3" xref="S3.T5.4.4.1.m1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1a" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.4" xref="S3.T5.4.4.1.m1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1b" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.5" xref="S3.T5.4.4.1.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1c" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.6" xref="S3.T5.4.4.1.m1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1d" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.7" xref="S3.T5.4.4.1.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1e" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.8" xref="S3.T5.4.4.1.m1.1.1.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1f" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.9" xref="S3.T5.4.4.1.m1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1g" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.T5.4.4.1.m1.1.1.10" xref="S3.T5.4.4.1.m1.1.1.10.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1h" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.11" xref="S3.T5.4.4.1.m1.1.1.11.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1i" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.12" xref="S3.T5.4.4.1.m1.1.1.12.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1j" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.13" xref="S3.T5.4.4.1.m1.1.1.13.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1k" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.14" xref="S3.T5.4.4.1.m1.1.1.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1l" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.15" xref="S3.T5.4.4.1.m1.1.1.15.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1m" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.16" xref="S3.T5.4.4.1.m1.1.1.16.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.4.4.1.m1.1.1.1n" xref="S3.T5.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.4.4.1.m1.1.1.17" xref="S3.T5.4.4.1.m1.1.1.17.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.4.4.1.m1.1b"><apply id="S3.T5.4.4.1.m1.1.1.cmml" xref="S3.T5.4.4.1.m1.1.1"><times id="S3.T5.4.4.1.m1.1.1.1.cmml" xref="S3.T5.4.4.1.m1.1.1.1"></times><ci id="S3.T5.4.4.1.m1.1.1.2.cmml" xref="S3.T5.4.4.1.m1.1.1.2">𝑑</ci><ci id="S3.T5.4.4.1.m1.1.1.3.cmml" xref="S3.T5.4.4.1.m1.1.1.3">𝑎</ci><ci id="S3.T5.4.4.1.m1.1.1.4.cmml" xref="S3.T5.4.4.1.m1.1.1.4">𝑡</ci><ci id="S3.T5.4.4.1.m1.1.1.5.cmml" xref="S3.T5.4.4.1.m1.1.1.5">𝑒</ci><ci id="S3.T5.4.4.1.m1.1.1.6.cmml" xref="S3.T5.4.4.1.m1.1.1.6">𝑡</ci><ci id="S3.T5.4.4.1.m1.1.1.7.cmml" xref="S3.T5.4.4.1.m1.1.1.7">𝑖</ci><ci id="S3.T5.4.4.1.m1.1.1.8.cmml" xref="S3.T5.4.4.1.m1.1.1.8">𝑚</ci><ci id="S3.T5.4.4.1.m1.1.1.9.cmml" xref="S3.T5.4.4.1.m1.1.1.9">𝑒</ci><ci id="S3.T5.4.4.1.m1.1.1.10.cmml" xref="S3.T5.4.4.1.m1.1.1.10">_</ci><ci id="S3.T5.4.4.1.m1.1.1.11.cmml" xref="S3.T5.4.4.1.m1.1.1.11">𝑏</ci><ci id="S3.T5.4.4.1.m1.1.1.12.cmml" xref="S3.T5.4.4.1.m1.1.1.12">𝑢</ci><ci id="S3.T5.4.4.1.m1.1.1.13.cmml" xref="S3.T5.4.4.1.m1.1.1.13">𝑖</ci><ci id="S3.T5.4.4.1.m1.1.1.14.cmml" xref="S3.T5.4.4.1.m1.1.1.14">𝑙</ci><ci id="S3.T5.4.4.1.m1.1.1.15.cmml" xref="S3.T5.4.4.1.m1.1.1.15">𝑡</ci><ci id="S3.T5.4.4.1.m1.1.1.16.cmml" xref="S3.T5.4.4.1.m1.1.1.16">𝑖</ci><ci id="S3.T5.4.4.1.m1.1.1.17.cmml" xref="S3.T5.4.4.1.m1.1.1.17">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.4.4.1.m1.1c">datetime\_builtin</annotation></semantics></math></td>
<td id="S3.T5.4.4.2" class="ltx_td"></td>
<td id="S3.T5.4.4.3" class="ltx_td"></td>
<td id="S3.T5.4.4.4" class="ltx_td"></td>
<td id="S3.T5.4.4.5" class="ltx_td ltx_align_center"><span id="S3.T5.4.4.5.1" class="ltx_text ltx_font_typewriter">B</span></td>
<td id="S3.T5.4.4.6" class="ltx_td ltx_align_center"><span id="S3.T5.4.4.6.1" class="ltx_text ltx_font_typewriter">I</span></td>
<td id="S3.T5.4.4.7" class="ltx_td ltx_align_center"><span id="S3.T5.4.4.7.1" class="ltx_text ltx_font_typewriter">L</span></td>
<td id="S3.T5.4.4.8" class="ltx_td"></td>
<td id="S3.T5.4.4.9" class="ltx_td"></td>
</tr>
<tr id="S3.T5.5.5" class="ltx_tr">
<td id="S3.T5.5.5.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S3.T5.5.5.1.m1.1" class="ltx_Math" alttext="number\_builtin" display="inline"><semantics id="S3.T5.5.5.1.m1.1a"><mrow id="S3.T5.5.5.1.m1.1.1" xref="S3.T5.5.5.1.m1.1.1.cmml"><mi id="S3.T5.5.5.1.m1.1.1.2" xref="S3.T5.5.5.1.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.3" xref="S3.T5.5.5.1.m1.1.1.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1a" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.4" xref="S3.T5.5.5.1.m1.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1b" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.5" xref="S3.T5.5.5.1.m1.1.1.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1c" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.6" xref="S3.T5.5.5.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1d" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.7" xref="S3.T5.5.5.1.m1.1.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1e" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.T5.5.5.1.m1.1.1.8" xref="S3.T5.5.5.1.m1.1.1.8.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1f" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.9" xref="S3.T5.5.5.1.m1.1.1.9.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1g" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.10" xref="S3.T5.5.5.1.m1.1.1.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1h" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.11" xref="S3.T5.5.5.1.m1.1.1.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1i" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.12" xref="S3.T5.5.5.1.m1.1.1.12.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1j" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.13" xref="S3.T5.5.5.1.m1.1.1.13.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1k" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.14" xref="S3.T5.5.5.1.m1.1.1.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.5.5.1.m1.1.1.1l" xref="S3.T5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.5.5.1.m1.1.1.15" xref="S3.T5.5.5.1.m1.1.1.15.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.5.5.1.m1.1b"><apply id="S3.T5.5.5.1.m1.1.1.cmml" xref="S3.T5.5.5.1.m1.1.1"><times id="S3.T5.5.5.1.m1.1.1.1.cmml" xref="S3.T5.5.5.1.m1.1.1.1"></times><ci id="S3.T5.5.5.1.m1.1.1.2.cmml" xref="S3.T5.5.5.1.m1.1.1.2">𝑛</ci><ci id="S3.T5.5.5.1.m1.1.1.3.cmml" xref="S3.T5.5.5.1.m1.1.1.3">𝑢</ci><ci id="S3.T5.5.5.1.m1.1.1.4.cmml" xref="S3.T5.5.5.1.m1.1.1.4">𝑚</ci><ci id="S3.T5.5.5.1.m1.1.1.5.cmml" xref="S3.T5.5.5.1.m1.1.1.5">𝑏</ci><ci id="S3.T5.5.5.1.m1.1.1.6.cmml" xref="S3.T5.5.5.1.m1.1.1.6">𝑒</ci><ci id="S3.T5.5.5.1.m1.1.1.7.cmml" xref="S3.T5.5.5.1.m1.1.1.7">𝑟</ci><ci id="S3.T5.5.5.1.m1.1.1.8.cmml" xref="S3.T5.5.5.1.m1.1.1.8">_</ci><ci id="S3.T5.5.5.1.m1.1.1.9.cmml" xref="S3.T5.5.5.1.m1.1.1.9">𝑏</ci><ci id="S3.T5.5.5.1.m1.1.1.10.cmml" xref="S3.T5.5.5.1.m1.1.1.10">𝑢</ci><ci id="S3.T5.5.5.1.m1.1.1.11.cmml" xref="S3.T5.5.5.1.m1.1.1.11">𝑖</ci><ci id="S3.T5.5.5.1.m1.1.1.12.cmml" xref="S3.T5.5.5.1.m1.1.1.12">𝑙</ci><ci id="S3.T5.5.5.1.m1.1.1.13.cmml" xref="S3.T5.5.5.1.m1.1.1.13">𝑡</ci><ci id="S3.T5.5.5.1.m1.1.1.14.cmml" xref="S3.T5.5.5.1.m1.1.1.14">𝑖</ci><ci id="S3.T5.5.5.1.m1.1.1.15.cmml" xref="S3.T5.5.5.1.m1.1.1.15">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.5.5.1.m1.1c">number\_builtin</annotation></semantics></math></td>
<td id="S3.T5.5.5.2" class="ltx_td"></td>
<td id="S3.T5.5.5.3" class="ltx_td"></td>
<td id="S3.T5.5.5.4" class="ltx_td"></td>
<td id="S3.T5.5.5.5" class="ltx_td"></td>
<td id="S3.T5.5.5.6" class="ltx_td ltx_align_center"><span id="S3.T5.5.5.6.1" class="ltx_text ltx_font_typewriter">U</span></td>
<td id="S3.T5.5.5.7" class="ltx_td"></td>
<td id="S3.T5.5.5.8" class="ltx_td"></td>
<td id="S3.T5.5.5.9" class="ltx_td"></td>
</tr>
<tr id="S3.T5.6.6" class="ltx_tr">
<td id="S3.T5.6.6.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S3.T5.6.6.1.m1.1" class="ltx_Math" alttext="number\_builtin_{-2}" display="inline"><semantics id="S3.T5.6.6.1.m1.1a"><mrow id="S3.T5.6.6.1.m1.1.1" xref="S3.T5.6.6.1.m1.1.1.cmml"><mi id="S3.T5.6.6.1.m1.1.1.2" xref="S3.T5.6.6.1.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.3" xref="S3.T5.6.6.1.m1.1.1.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1a" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.4" xref="S3.T5.6.6.1.m1.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1b" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.5" xref="S3.T5.6.6.1.m1.1.1.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1c" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.6" xref="S3.T5.6.6.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1d" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.7" xref="S3.T5.6.6.1.m1.1.1.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1e" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.T5.6.6.1.m1.1.1.8" xref="S3.T5.6.6.1.m1.1.1.8.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1f" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.9" xref="S3.T5.6.6.1.m1.1.1.9.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1g" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.10" xref="S3.T5.6.6.1.m1.1.1.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1h" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.11" xref="S3.T5.6.6.1.m1.1.1.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1i" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.12" xref="S3.T5.6.6.1.m1.1.1.12.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1j" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.13" xref="S3.T5.6.6.1.m1.1.1.13.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1k" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><mi id="S3.T5.6.6.1.m1.1.1.14" xref="S3.T5.6.6.1.m1.1.1.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T5.6.6.1.m1.1.1.1l" xref="S3.T5.6.6.1.m1.1.1.1.cmml">​</mo><msub id="S3.T5.6.6.1.m1.1.1.15" xref="S3.T5.6.6.1.m1.1.1.15.cmml"><mi id="S3.T5.6.6.1.m1.1.1.15.2" xref="S3.T5.6.6.1.m1.1.1.15.2.cmml">n</mi><mrow id="S3.T5.6.6.1.m1.1.1.15.3" xref="S3.T5.6.6.1.m1.1.1.15.3.cmml"><mo id="S3.T5.6.6.1.m1.1.1.15.3a" xref="S3.T5.6.6.1.m1.1.1.15.3.cmml">−</mo><mn id="S3.T5.6.6.1.m1.1.1.15.3.2" xref="S3.T5.6.6.1.m1.1.1.15.3.2.cmml">2</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.6.6.1.m1.1b"><apply id="S3.T5.6.6.1.m1.1.1.cmml" xref="S3.T5.6.6.1.m1.1.1"><times id="S3.T5.6.6.1.m1.1.1.1.cmml" xref="S3.T5.6.6.1.m1.1.1.1"></times><ci id="S3.T5.6.6.1.m1.1.1.2.cmml" xref="S3.T5.6.6.1.m1.1.1.2">𝑛</ci><ci id="S3.T5.6.6.1.m1.1.1.3.cmml" xref="S3.T5.6.6.1.m1.1.1.3">𝑢</ci><ci id="S3.T5.6.6.1.m1.1.1.4.cmml" xref="S3.T5.6.6.1.m1.1.1.4">𝑚</ci><ci id="S3.T5.6.6.1.m1.1.1.5.cmml" xref="S3.T5.6.6.1.m1.1.1.5">𝑏</ci><ci id="S3.T5.6.6.1.m1.1.1.6.cmml" xref="S3.T5.6.6.1.m1.1.1.6">𝑒</ci><ci id="S3.T5.6.6.1.m1.1.1.7.cmml" xref="S3.T5.6.6.1.m1.1.1.7">𝑟</ci><ci id="S3.T5.6.6.1.m1.1.1.8.cmml" xref="S3.T5.6.6.1.m1.1.1.8">_</ci><ci id="S3.T5.6.6.1.m1.1.1.9.cmml" xref="S3.T5.6.6.1.m1.1.1.9">𝑏</ci><ci id="S3.T5.6.6.1.m1.1.1.10.cmml" xref="S3.T5.6.6.1.m1.1.1.10">𝑢</ci><ci id="S3.T5.6.6.1.m1.1.1.11.cmml" xref="S3.T5.6.6.1.m1.1.1.11">𝑖</ci><ci id="S3.T5.6.6.1.m1.1.1.12.cmml" xref="S3.T5.6.6.1.m1.1.1.12">𝑙</ci><ci id="S3.T5.6.6.1.m1.1.1.13.cmml" xref="S3.T5.6.6.1.m1.1.1.13">𝑡</ci><ci id="S3.T5.6.6.1.m1.1.1.14.cmml" xref="S3.T5.6.6.1.m1.1.1.14">𝑖</ci><apply id="S3.T5.6.6.1.m1.1.1.15.cmml" xref="S3.T5.6.6.1.m1.1.1.15"><csymbol cd="ambiguous" id="S3.T5.6.6.1.m1.1.1.15.1.cmml" xref="S3.T5.6.6.1.m1.1.1.15">subscript</csymbol><ci id="S3.T5.6.6.1.m1.1.1.15.2.cmml" xref="S3.T5.6.6.1.m1.1.1.15.2">𝑛</ci><apply id="S3.T5.6.6.1.m1.1.1.15.3.cmml" xref="S3.T5.6.6.1.m1.1.1.15.3"><minus id="S3.T5.6.6.1.m1.1.1.15.3.1.cmml" xref="S3.T5.6.6.1.m1.1.1.15.3"></minus><cn type="integer" id="S3.T5.6.6.1.m1.1.1.15.3.2.cmml" xref="S3.T5.6.6.1.m1.1.1.15.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.6.6.1.m1.1c">number\_builtin_{-2}</annotation></semantics></math></td>
<td id="S3.T5.6.6.2" class="ltx_td"></td>
<td id="S3.T5.6.6.3" class="ltx_td"></td>
<td id="S3.T5.6.6.4" class="ltx_td"></td>
<td id="S3.T5.6.6.5" class="ltx_td"></td>
<td id="S3.T5.6.6.6" class="ltx_td"></td>
<td id="S3.T5.6.6.7" class="ltx_td"></td>
<td id="S3.T5.6.6.8" class="ltx_td ltx_align_center"><span id="S3.T5.6.6.8.1" class="ltx_text ltx_font_typewriter">U</span></td>
<td id="S3.T5.6.6.9" class="ltx_td"></td>
</tr>
</tbody>
</table>
<br class="ltx_break">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Examples of CRF features used in Snips NLU</figcaption>
</figure>
</section>
<section id="S3.SS3.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Entity resolution.</h5>

<div id="S3.SS3.SSS1.Px3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.Px3.p1.1" class="ltx_p">The last step of the NLU pipeline consists in resolving slot values (e.g. from raw strings to ISO formatted values for date and time entities). Entity values that can be resolved (e.g. dates, temperatures, numbers) correspond to the built-in entities introduced in section <a href="#S3.SS1.SSS1" title="3.1.1 Training dataset ‣ 3.1 Data ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.1</span></a><span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Complete list available here: <a target="_blank" href="https://github.com/snipsco/snips-nlu-ontology" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/snips-nlu-ontology</a></span></span></span>, and are supported natively without requiring training examples. The resolution is done with <span id="S3.SS3.SSS1.Px3.p1.1.1" class="ltx_text ltx_font_italic">Rustling</span>, an in-house re-implementation of Facebook’s <span id="S3.SS3.SSS1.Px3.p1.1.2" class="ltx_text ltx_font_italic">Duckling</span> library <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref">Duckling </a></cite> in Rust, which we also open sourced <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib48" title="" class="ltx_ref">SnipsRustling </a></cite>, with modifications to make its runtime more stable with regards to the length of the sentences parsed.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Evaluation</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Snips NLU is evaluated and compared to various NLU services on two datasets: a previously published comparison <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">bench17 </a></cite>, and an in-house open dataset. The latter has been made freely accessible on GitHub to promote transparency and reproducibility<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span> <a target="_blank" href="https://github.com/snipsco/nlu-benchmark" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/nlu-benchmark</a></span></span></span>.</p>
</div>
<section id="S3.SS3.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation on Braun et al., 2017 <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">bench17 </a></cite>.</h5>

<div id="S3.SS3.SSS2.Px1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.Px1.p1.1" class="ltx_p">In January 2018, we evaluated Snips NLU on a previously published comparison between various NLU services <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">bench17 </a></cite>: a few of the main cloud-based solutions (Microsoft’s Luis, IBM Watson, API.AI now Google’s Dialogflow), and the open-source platform Rasa NLU <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">bocklisch2017rasa </a></cite>. For the raw results and methodology, see <a target="_blank" href="https://github.com/snipsco/nlu-benchmark" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/nlu-benchmark</a>. The main metric used in this benchmark is the average F1-score of intent classification and slot filling. The data consists in three corpora. Two of the corpora were extracted from StackExchange, one from a Telegram chatbot. The exact same splits as in the original paper were used for the Ubuntu and Web Applications corpora. At the date we ran the evaluation, the train and test splits were not explicit for the Chatbot dataset (although they were added later on). In that case, we ran a 5-fold cross-validation. The results are presented in Table <a href="#S3.T6" title="Table 6 ‣ Evaluation on Braun et al., 2017 bench17 . ‣ 3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Figure <a href="#S3.F7" title="Figure 7 ‣ Evaluation on Braun et al., 2017 bench17 . ‣ 3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> presents the average results on the three corpora, corresponding to the <span id="S3.SS3.SSS2.Px1.p1.1.1" class="ltx_text ltx_font_italic">overall</span> section of Table <a href="#S3.T6" title="Table 6 ‣ Evaluation on Braun et al., 2017 bench17 . ‣ 3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. For Rasa, we considered all three possible backends (Spacy, SKLearn + MITIE, MITIE), see the abovementioned GitHub repository for more details. However, only Spacy was run on all 3 datasets, for train time reasons. For fairness, the latest version of Rasa NLU is also displayed. Results show that Snips NLU ranks second highest overall.</p>
</div>
<figure id="S3.T6" class="ltx_table ltx_align_center">
<table id="S3.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T6.1.1.1" class="ltx_tr">
<th id="S3.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">corpus</th>
<th id="S3.T6.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">NLU provider</th>
<th id="S3.T6.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">precision</th>
<th id="S3.T6.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">recall</th>
<th id="S3.T6.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T6.1.2.1" class="ltx_tr">
<td id="S3.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" rowspan="6"><span id="S3.T6.1.2.1.1.1" class="ltx_text">chatbot</span></td>
<td id="S3.T6.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Luis*</td>
<td id="S3.T6.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.970</td>
<td id="S3.T6.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.918</td>
<td id="S3.T6.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.943</td>
</tr>
<tr id="S3.T6.1.3.2" class="ltx_tr">
<td id="S3.T6.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r">IBM Watson*</td>
<td id="S3.T6.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">0.686</td>
<td id="S3.T6.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r">0.8</td>
<td id="S3.T6.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r">0.739</td>
</tr>
<tr id="S3.T6.1.4.3" class="ltx_tr">
<td id="S3.T6.1.4.3.1" class="ltx_td ltx_align_left ltx_border_r">API.ai*</td>
<td id="S3.T6.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">0.936</td>
<td id="S3.T6.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r">0.532</td>
<td id="S3.T6.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r">0.678</td>
</tr>
<tr id="S3.T6.1.5.4" class="ltx_tr">
<td id="S3.T6.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r">Rasa*</td>
<td id="S3.T6.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">0.970</td>
<td id="S3.T6.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r">0.918</td>
<td id="S3.T6.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r">0.943</td>
</tr>
<tr id="S3.T6.1.6.5" class="ltx_tr">
<td id="S3.T6.1.6.5.1" class="ltx_td ltx_align_left ltx_border_r">Rasa**</td>
<td id="S3.T6.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r">0.933</td>
<td id="S3.T6.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r">0.921</td>
<td id="S3.T6.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r">0.927</td>
</tr>
<tr id="S3.T6.1.7.6" class="ltx_tr">
<td id="S3.T6.1.7.6.1" class="ltx_td ltx_align_left ltx_border_r">Snips**</td>
<td id="S3.T6.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">0.963</td>
<td id="S3.T6.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r">0.899</td>
<td id="S3.T6.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r">0.930</td>
</tr>
<tr id="S3.T6.1.8.7" class="ltx_tr">
<td id="S3.T6.1.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="6"><span id="S3.T6.1.8.7.1.1" class="ltx_text">web apps</span></td>
<td id="S3.T6.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Luis*</td>
<td id="S3.T6.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.828</td>
<td id="S3.T6.1.8.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.653</td>
<td id="S3.T6.1.8.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.73</td>
</tr>
<tr id="S3.T6.1.9.8" class="ltx_tr">
<td id="S3.T6.1.9.8.1" class="ltx_td ltx_align_left ltx_border_r">IBM Watson*</td>
<td id="S3.T6.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">0.828</td>
<td id="S3.T6.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r">0.585</td>
<td id="S3.T6.1.9.8.4" class="ltx_td ltx_align_left ltx_border_r">0.686</td>
</tr>
<tr id="S3.T6.1.10.9" class="ltx_tr">
<td id="S3.T6.1.10.9.1" class="ltx_td ltx_align_left ltx_border_r">API.ai*</td>
<td id="S3.T6.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r">0.810</td>
<td id="S3.T6.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r">0.382</td>
<td id="S3.T6.1.10.9.4" class="ltx_td ltx_align_left ltx_border_r">0.519</td>
</tr>
<tr id="S3.T6.1.11.10" class="ltx_tr">
<td id="S3.T6.1.11.10.1" class="ltx_td ltx_align_left ltx_border_r">Rasa*</td>
<td id="S3.T6.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r">0.466</td>
<td id="S3.T6.1.11.10.3" class="ltx_td ltx_align_left ltx_border_r">0.724</td>
<td id="S3.T6.1.11.10.4" class="ltx_td ltx_align_left ltx_border_r">0.567</td>
</tr>
<tr id="S3.T6.1.12.11" class="ltx_tr">
<td id="S3.T6.1.12.11.1" class="ltx_td ltx_align_left ltx_border_r">Rasa**</td>
<td id="S3.T6.1.12.11.2" class="ltx_td ltx_align_left ltx_border_r">0.593</td>
<td id="S3.T6.1.12.11.3" class="ltx_td ltx_align_left ltx_border_r">0.613</td>
<td id="S3.T6.1.12.11.4" class="ltx_td ltx_align_left ltx_border_r">0.603</td>
</tr>
<tr id="S3.T6.1.13.12" class="ltx_tr">
<td id="S3.T6.1.13.12.1" class="ltx_td ltx_align_left ltx_border_r">Snips**</td>
<td id="S3.T6.1.13.12.2" class="ltx_td ltx_align_left ltx_border_r">0.655</td>
<td id="S3.T6.1.13.12.3" class="ltx_td ltx_align_left ltx_border_r">0.655</td>
<td id="S3.T6.1.13.12.4" class="ltx_td ltx_align_left ltx_border_r">0.655</td>
</tr>
<tr id="S3.T6.1.14.13" class="ltx_tr">
<td id="S3.T6.1.14.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="6"><span id="S3.T6.1.14.13.1.1" class="ltx_text">ask ubuntu</span></td>
<td id="S3.T6.1.14.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Luis*</td>
<td id="S3.T6.1.14.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.885</td>
<td id="S3.T6.1.14.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.842</td>
<td id="S3.T6.1.14.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.863</td>
</tr>
<tr id="S3.T6.1.15.14" class="ltx_tr">
<td id="S3.T6.1.15.14.1" class="ltx_td ltx_align_left ltx_border_r">IBM Watson*</td>
<td id="S3.T6.1.15.14.2" class="ltx_td ltx_align_left ltx_border_r">0.807</td>
<td id="S3.T6.1.15.14.3" class="ltx_td ltx_align_left ltx_border_r">0.825</td>
<td id="S3.T6.1.15.14.4" class="ltx_td ltx_align_left ltx_border_r">0.816</td>
</tr>
<tr id="S3.T6.1.16.15" class="ltx_tr">
<td id="S3.T6.1.16.15.1" class="ltx_td ltx_align_left ltx_border_r">API.ai*</td>
<td id="S3.T6.1.16.15.2" class="ltx_td ltx_align_left ltx_border_r">0.815</td>
<td id="S3.T6.1.16.15.3" class="ltx_td ltx_align_left ltx_border_r">0.754</td>
<td id="S3.T6.1.16.15.4" class="ltx_td ltx_align_left ltx_border_r">0.783</td>
</tr>
<tr id="S3.T6.1.17.16" class="ltx_tr">
<td id="S3.T6.1.17.16.1" class="ltx_td ltx_align_left ltx_border_r">Rasa*</td>
<td id="S3.T6.1.17.16.2" class="ltx_td ltx_align_left ltx_border_r">0.791</td>
<td id="S3.T6.1.17.16.3" class="ltx_td ltx_align_left ltx_border_r">0.823</td>
<td id="S3.T6.1.17.16.4" class="ltx_td ltx_align_left ltx_border_r">0.807</td>
</tr>
<tr id="S3.T6.1.18.17" class="ltx_tr">
<td id="S3.T6.1.18.17.1" class="ltx_td ltx_align_left ltx_border_r">Rasa**</td>
<td id="S3.T6.1.18.17.2" class="ltx_td ltx_align_left ltx_border_r">0.796</td>
<td id="S3.T6.1.18.17.3" class="ltx_td ltx_align_left ltx_border_r">0.768</td>
<td id="S3.T6.1.18.17.4" class="ltx_td ltx_align_left ltx_border_r">0.782</td>
</tr>
<tr id="S3.T6.1.19.18" class="ltx_tr">
<td id="S3.T6.1.19.18.1" class="ltx_td ltx_align_left ltx_border_r">Snips**</td>
<td id="S3.T6.1.19.18.2" class="ltx_td ltx_align_left ltx_border_r">0.812</td>
<td id="S3.T6.1.19.18.3" class="ltx_td ltx_align_left ltx_border_r">0.828</td>
<td id="S3.T6.1.19.18.4" class="ltx_td ltx_align_left ltx_border_r">0.820</td>
</tr>
<tr id="S3.T6.1.20.19" class="ltx_tr">
<td id="S3.T6.1.20.19.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="6"><span id="S3.T6.1.20.19.1.1" class="ltx_text">overall</span></td>
<td id="S3.T6.1.20.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Luis*</td>
<td id="S3.T6.1.20.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.945</td>
<td id="S3.T6.1.20.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.889</td>
<td id="S3.T6.1.20.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.916</td>
</tr>
<tr id="S3.T6.1.21.20" class="ltx_tr">
<td id="S3.T6.1.21.20.1" class="ltx_td ltx_align_left ltx_border_r">IBM Watson*</td>
<td id="S3.T6.1.21.20.2" class="ltx_td ltx_align_left ltx_border_r">0.738</td>
<td id="S3.T6.1.21.20.3" class="ltx_td ltx_align_left ltx_border_r">0.767</td>
<td id="S3.T6.1.21.20.4" class="ltx_td ltx_align_left ltx_border_r">0.752</td>
</tr>
<tr id="S3.T6.1.22.21" class="ltx_tr">
<td id="S3.T6.1.22.21.1" class="ltx_td ltx_align_left ltx_border_r">API.ai*</td>
<td id="S3.T6.1.22.21.2" class="ltx_td ltx_align_left ltx_border_r">0.871</td>
<td id="S3.T6.1.22.21.3" class="ltx_td ltx_align_left ltx_border_r">0.567</td>
<td id="S3.T6.1.22.21.4" class="ltx_td ltx_align_left ltx_border_r">0.687</td>
</tr>
<tr id="S3.T6.1.23.22" class="ltx_tr">
<td id="S3.T6.1.23.22.1" class="ltx_td ltx_align_left ltx_border_r">Rasa*</td>
<td id="S3.T6.1.23.22.2" class="ltx_td ltx_align_left ltx_border_r">0.789</td>
<td id="S3.T6.1.23.22.3" class="ltx_td ltx_align_left ltx_border_r">0.855</td>
<td id="S3.T6.1.23.22.4" class="ltx_td ltx_align_left ltx_border_r">0.821</td>
</tr>
<tr id="S3.T6.1.24.23" class="ltx_tr">
<td id="S3.T6.1.24.23.1" class="ltx_td ltx_align_left ltx_border_r">Rasa**</td>
<td id="S3.T6.1.24.23.2" class="ltx_td ltx_align_left ltx_border_r">0.866</td>
<td id="S3.T6.1.24.23.3" class="ltx_td ltx_align_left ltx_border_r">0.856</td>
<td id="S3.T6.1.24.23.4" class="ltx_td ltx_align_left ltx_border_r">0.861</td>
</tr>
<tr id="S3.T6.1.25.24" class="ltx_tr">
<td id="S3.T6.1.25.24.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">Snips**</td>
<td id="S3.T6.1.25.24.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.896</td>
<td id="S3.T6.1.25.24.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.858</td>
<td id="S3.T6.1.25.24.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.877</td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Precision, recall and F1-score on Braun et al. corpora. *Benchmark run in August 2017 by the authors of <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">bench17 </a></cite>. **Benchmark run in January 2018 by the authors of this paper.</figcaption>
</figure>
<figure id="S3.F7" class="ltx_figure">
<br class="ltx_break">
<p id="S3.F7.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F7.1.1.1" class="ltx_text"><img src="/html/1805.10190/assets/x6.png" id="S3.F7.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Average F1-scores, of both intent classification and slot filling, for the different NLU services over the three corpora</figcaption>
</figure>
</section>
<section id="S3.SS3.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation on an in-house open dataset.</h5>

<div id="S3.SS3.SSS2.Px2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.Px2.p1.1" class="ltx_p">In June 2017, Snips NLU was evaluated on an in-house dataset of over 16K crowdsourced queries (freely available<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>See footnote <a href="#footnote8" title="footnote 8 ‣ 3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a></span></span></span>) distributed among 7 user intents of various complexity:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">SearchCreativeWork</span> (e.g. Find me the I, Robot television show),</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">GetWeather</span> (e.g. Is it windy in Boston, MA right now?),</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p"><span id="S3.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">BookRestaurant</span> (e.g. I want to book a highly rated restaurant in Paris tomorrow night),</p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p"><span id="S3.I2.i4.p1.1.1" class="ltx_text ltx_font_typewriter">PlayMusic</span> (e.g. Play the last track from Beyoncé off Spotify),</p>
</div>
</li>
<li id="S3.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i5.p1" class="ltx_para">
<p id="S3.I2.i5.p1.1" class="ltx_p"><span id="S3.I2.i5.p1.1.1" class="ltx_text ltx_font_typewriter">AddToPlaylist</span> (e.g. Add Diamonds to my roadtrip playlist)</p>
</div>
</li>
<li id="S3.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i6.p1" class="ltx_para">
<p id="S3.I2.i6.p1.1" class="ltx_p"><span id="S3.I2.i6.p1.1.1" class="ltx_text ltx_font_typewriter">RateBook</span> (e.g. Give 6 stars to Of Mice and Men)</p>
</div>
</li>
<li id="S3.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i7.p1" class="ltx_para ltx_noindent">
<p id="S3.I2.i7.p1.1" class="ltx_p"><span id="S3.I2.i7.p1.1.1" class="ltx_text ltx_font_typewriter">SearchScreeningEvent</span> (e.g. Check the showtimes for Wonder Woman in Paris)</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.Px2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.Px2.p2.1" class="ltx_p">The full ontology is available on Table <a href="#Sx2.T15" title="Table 15 ‣ Appendix: NLU benchmark on an in-house dataset ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> in Appendix. In this experiment, the comparison is done separately on each intent to focus on slot filling (rather than intent classification). The main metric used in this benchmark is the average F1-score of slot filling on all slots. Three training sets of 70 and 2000 queries have been drawn from the total pool of queries to gain in statistical relevance. Validation sets consist in 100 queries per intent. Five different cloud-based providers are compared to Snips NLU (Microsoft’s Luis, API.AI now Google’s Dialogflow, Facebook’s Wit.ai, and Amazon Alexa). For more details about the specific methodology for each provider and access to the full dataset, see <a target="_blank" href="https://github.com/snipsco/nlu-benchmark" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/nlu-benchmark</a>. Each solution is trained and evaluated on the exact same datasets. Table <a href="#S3.T7" title="Table 7 ‣ Evaluation on an in-house open dataset. ‣ 3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the precision, recall and F1-score averaged on all slots and on all intents. Results specific to each intent are available in Tables <a href="#Sx2.T16" title="Table 16 ‣ Appendix: NLU benchmark on an in-house dataset ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a> &amp; <a href="#Sx2.T17" title="Table 17 ‣ Appendix: NLU benchmark on an in-house dataset ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a> in Appendix. Snips NLU is as accurate or better than competing cloud-based solutions in slot filling, regardless of the training set size.</p>
</div>
<figure id="S3.T7" class="ltx_table ltx_align_center">
<table id="S3.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T7.1.1.1" class="ltx_tr">
<th id="S3.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">NLU provider</th>
<th id="S3.T7.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">train size</th>
<th id="S3.T7.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">precision</th>
<th id="S3.T7.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">recall</th>
<th id="S3.T7.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T7.1.2.1" class="ltx_tr">
<th id="S3.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S3.T7.1.2.1.1.1" class="ltx_text">Luis</span></th>
<th id="S3.T7.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">70</th>
<td id="S3.T7.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.909</td>
<td id="S3.T7.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.537</td>
<td id="S3.T7.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">0.691</td>
</tr>
<tr id="S3.T7.1.3.2" class="ltx_tr">
<th id="S3.T7.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2000</th>
<td id="S3.T7.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">0.954</td>
<td id="S3.T7.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r">0.917</td>
<td id="S3.T7.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T7.1.3.2.4.1" class="ltx_text ltx_font_bold">0.932</span></td>
</tr>
<tr id="S3.T7.1.4.3" class="ltx_tr">
<th id="S3.T7.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T7.1.4.3.1.1" class="ltx_text">Wit</span></th>
<th id="S3.T7.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">70</th>
<td id="S3.T7.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.838</td>
<td id="S3.T7.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.561</td>
<td id="S3.T7.1.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.725</td>
</tr>
<tr id="S3.T7.1.5.4" class="ltx_tr">
<th id="S3.T7.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2000</th>
<td id="S3.T7.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">0.877</td>
<td id="S3.T7.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r">0.807</td>
<td id="S3.T7.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r">0.826</td>
</tr>
<tr id="S3.T7.1.6.5" class="ltx_tr">
<th id="S3.T7.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T7.1.6.5.1.1" class="ltx_text">API.ai</span></th>
<th id="S3.T7.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">70</th>
<td id="S3.T7.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.770</td>
<td id="S3.T7.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.654</td>
<td id="S3.T7.1.6.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.704</td>
</tr>
<tr id="S3.T7.1.7.6" class="ltx_tr">
<th id="S3.T7.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2000</th>
<td id="S3.T7.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">0.905</td>
<td id="S3.T7.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r">0.881</td>
<td id="S3.T7.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r">0.884</td>
</tr>
<tr id="S3.T7.1.8.7" class="ltx_tr">
<th id="S3.T7.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T7.1.8.7.1.1" class="ltx_text">Alexa</span></th>
<th id="S3.T7.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">70</th>
<td id="S3.T7.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.680</td>
<td id="S3.T7.1.8.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.495</td>
<td id="S3.T7.1.8.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.564</td>
</tr>
<tr id="S3.T7.1.9.8" class="ltx_tr">
<th id="S3.T7.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">2000</th>
<td id="S3.T7.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">0.720</td>
<td id="S3.T7.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r">0.592</td>
<td id="S3.T7.1.9.8.4" class="ltx_td ltx_align_left ltx_border_r">0.641</td>
</tr>
<tr id="S3.T7.1.10.9" class="ltx_tr">
<th id="S3.T7.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T7.1.10.9.1.1" class="ltx_text">Snips</span></th>
<th id="S3.T7.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">70</th>
<td id="S3.T7.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.795</td>
<td id="S3.T7.1.10.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.769</td>
<td id="S3.T7.1.10.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T7.1.10.9.5.1" class="ltx_text ltx_font_bold">0.790</span></td>
</tr>
<tr id="S3.T7.1.11.10" class="ltx_tr">
<th id="S3.T7.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">2000</th>
<td id="S3.T7.1.11.10.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.946</td>
<td id="S3.T7.1.11.10.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.921</td>
<td id="S3.T7.1.11.10.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">0.930</td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Precision, recall and F1-score averaged on all slots and on all intents of an in-house dataset, run in June 2017.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Embedded performance</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Using Rust for the NLU inference pipeline allows to keep the memory footprint and the inference runtime very low. Memory usage has been optimized, with model sizes ranging from a few hundred kilobytes of RAM for common cases to a few megabytes for the most complex assistants. They are therefore fit for deployment on a Raspberry Pi or a mobile app, and more powerful servers can handle hundreds of parallel instances. Using the embedded Snips Voice platform significantly reduces the inference runtime compared to a roundtrip to a cloud service, as displayed on Table <a href="#S3.T8" title="Table 8 ‣ 3.3.3 Embedded performance ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure id="S3.T8" class="ltx_table">
<table id="S3.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T8.1.1.1" class="ltx_tr">
<th id="S3.T8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S3.T8.1.1.1.1.1" class="ltx_text ltx_font_bold">Device</span></th>
<th id="S3.T8.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S3.T8.1.1.1.2.1" class="ltx_text ltx_font_bold">Runtime (ms)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T8.1.2.1" class="ltx_tr">
<th id="S3.T8.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">MacBook Pro 2.5GHz</th>
<td id="S3.T8.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">1.26</td>
</tr>
<tr id="S3.T8.1.3.2" class="ltx_tr">
<th id="S3.T8.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">iPhone 6s</th>
<td id="S3.T8.1.3.2.2" class="ltx_td ltx_align_right">2.12</td>
</tr>
<tr id="S3.T8.1.4.3" class="ltx_tr">
<th id="S3.T8.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Raspberry Pi 3</th>
<td id="S3.T8.1.4.3.2" class="ltx_td ltx_align_right">60.32</td>
</tr>
<tr id="S3.T8.1.5.4" class="ltx_tr">
<th id="S3.T8.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Raspberry Pi Zero</th>
<td id="S3.T8.1.5.4.2" class="ltx_td ltx_align_right">220.02</td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Inference runtimes of the Snips NLU Rust pipeline, in milliseconds</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>End-to-end Evaluation</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the performance of the Snips Spoken Language Understanding (SLU) pipeline in an end-to-end, speech-to-meaning setting.
To this end, we consider two real-world assistants of different sizes, namely <span id="S4.p1.1.1" class="ltx_text ltx_font_typewriter">SmartLights</span> and <span id="S4.p1.1.2" class="ltx_text ltx_font_typewriter">Weather</span>. The <span id="S4.p1.1.3" class="ltx_text ltx_font_typewriter">SmartLights</span> assistant specializes in interacting with light devices supporting different colors and levels of brightness, and positioned in various rooms. The <span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">Weather</span> assistant is targeted at weather queries in general, and supports various types of formulations and places. Tables <a href="#S4.T9" title="Table 9 ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#S4.T11" title="Table 11 ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> sum up the constitution and size of the datasets corresponding to these two assistants, while tables <a href="#S4.T10" title="Table 10 ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and <a href="#S4.T12" title="Table 12 ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> describe their entities. Note in particular the use of the built-in “<span id="S4.p1.1.5" class="ltx_text ltx_font_typewriter">snips/number</span>” (respectively “<span id="S4.p1.1.6" class="ltx_text ltx_font_typewriter">snips/datetime</span>”) entity to define the brightness (resp. datetime) slot, which allows the assistant to generalize to values absent from the dataset.</p>
</div>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span><span id="S4.T9.2.1" class="ltx_text ltx_font_typewriter">SmartLights</span> dataset summary</figcaption>
<table id="S4.T9.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T9.3.1.1" class="ltx_tr">
<th id="S4.T9.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Intent Name</th>
<th id="S4.T9.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Slots</th>
<th id="S4.T9.3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">Sample</th>
<th id="S4.T9.3.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column">#Utterances</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T9.3.2.1" class="ltx_tr">
<td id="S4.T9.3.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T9.3.2.1.1.1" class="ltx_text ltx_font_typewriter">IncreaseBrightness</span></td>
<td id="S4.T9.3.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T9.3.2.1.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Turn up the lights in the <span id="S4.T9.3.2.1.3.1" class="ltx_text" style="color:#9670D6;">living room</span>
</td>
<td id="S4.T9.3.2.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">299</td>
</tr>
<tr id="S4.T9.3.3.2" class="ltx_tr">
<td id="S4.T9.3.3.2.1" class="ltx_td ltx_align_left"><span id="S4.T9.3.3.2.1.1" class="ltx_text ltx_font_typewriter">DecreaseBrightness</span></td>
<td id="S4.T9.3.3.2.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.3.2.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.3.2.3" class="ltx_td ltx_align_left">Turn down the lights in the <span id="S4.T9.3.3.2.3.1" class="ltx_text" style="color:#9670D6;">kitchen</span>
</td>
<td id="S4.T9.3.3.2.4" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T9.3.4.3" class="ltx_tr">
<td id="S4.T9.3.4.3.1" class="ltx_td ltx_align_left"><span id="S4.T9.3.4.3.1.1" class="ltx_text ltx_font_typewriter">SwitchLightOff</span></td>
<td id="S4.T9.3.4.3.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.4.3.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.4.3.3" class="ltx_td ltx_align_left">Make certain no lights are on in the <span id="S4.T9.3.4.3.3.1" class="ltx_text" style="color:#9670D6;">bathroom</span>
</td>
<td id="S4.T9.3.4.3.4" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T9.3.5.4" class="ltx_tr">
<td id="S4.T9.3.5.4.1" class="ltx_td ltx_align_left"><span id="S4.T9.3.5.4.1.1" class="ltx_text ltx_font_typewriter">SwitchLightOn</span></td>
<td id="S4.T9.3.5.4.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.5.4.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.5.4.3" class="ltx_td ltx_align_left">Can you switch on my <span id="S4.T9.3.5.4.3.1" class="ltx_text" style="color:#9670D6;">apartment</span> lights?</td>
<td id="S4.T9.3.5.4.4" class="ltx_td ltx_nopad_r ltx_align_center">278</td>
</tr>
<tr id="S4.T9.3.6.5" class="ltx_tr">
<td id="S4.T9.3.6.5.1" class="ltx_td ltx_align_left"><span id="S4.T9.3.6.5.1.1" class="ltx_text ltx_font_typewriter">SetLightBrightness</span></td>
<td id="S4.T9.3.6.5.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.6.5.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.6.5.3" class="ltx_td ltx_align_left">Set the lights in the <span id="S4.T9.3.6.5.3.1" class="ltx_text" style="color:#9670D6;">living room</span>
</td>
<td id="S4.T9.3.6.5.4" class="ltx_td ltx_nopad_r ltx_align_center">299</td>
</tr>
<tr id="S4.T9.3.7.6" class="ltx_tr">
<td id="S4.T9.3.7.6.1" class="ltx_td"></td>
<td id="S4.T9.3.7.6.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.7.6.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">brightness</span></td>
<td id="S4.T9.3.7.6.3" class="ltx_td ltx_align_left">to level <span id="S4.T9.3.7.6.3.1" class="ltx_text" style="color:#78DE78;">thirty-two</span>
</td>
<td id="S4.T9.3.7.6.4" class="ltx_td"></td>
</tr>
<tr id="S4.T9.3.8.7" class="ltx_tr">
<td id="S4.T9.3.8.7.1" class="ltx_td ltx_align_left"><span id="S4.T9.3.8.7.1.1" class="ltx_text ltx_font_typewriter">SetLightColor</span></td>
<td id="S4.T9.3.8.7.2" class="ltx_td ltx_align_left"><span id="S4.T9.3.8.7.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">room</span></td>
<td id="S4.T9.3.8.7.3" class="ltx_td ltx_align_left">Can you change the color of the lights</td>
<td id="S4.T9.3.8.7.4" class="ltx_td ltx_nopad_r ltx_align_center">300</td>
</tr>
<tr id="S4.T9.3.9.8" class="ltx_tr">
<td id="S4.T9.3.9.8.1" class="ltx_td ltx_border_bb"></td>
<td id="S4.T9.3.9.8.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T9.3.9.8.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">color</span></td>
<td id="S4.T9.3.9.8.3" class="ltx_td ltx_align_left ltx_border_bb">to <span id="S4.T9.3.9.8.3.1" class="ltx_text" style="color:#DE5C82;">red</span> in the <span id="S4.T9.3.9.8.3.2" class="ltx_text" style="color:#9670D6;">large leaving room</span>?</td>
<td id="S4.T9.3.9.8.4" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span><span id="S4.T10.3.1" class="ltx_text ltx_font_typewriter">SmartLights</span> entities summary</figcaption>
<table id="S4.T10.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T10.1.2.1" class="ltx_tr">
<th id="S4.T10.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Slot Name</th>
<th id="S4.T10.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Type</th>
<th id="S4.T10.1.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">Range</th>
<th id="S4.T10.1.2.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column">Samples</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T10.1.3.1" class="ltx_tr">
<td id="S4.T10.1.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T10.1.3.1.1.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T10.1.3.1.2" class="ltx_td ltx_align_left ltx_border_t">custom</td>
<td id="S4.T10.1.3.1.3" class="ltx_td ltx_align_left ltx_border_t">34 values</td>
<td id="S4.T10.1.3.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">kitchen, bedroom</td>
</tr>
<tr id="S4.T10.1.4.2" class="ltx_tr">
<td id="S4.T10.1.4.2.1" class="ltx_td ltx_align_left"><span id="S4.T10.1.4.2.1.1" class="ltx_text ltx_font_typewriter">color</span></td>
<td id="S4.T10.1.4.2.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T10.1.4.2.3" class="ltx_td ltx_align_left">4 values</td>
<td id="S4.T10.1.4.2.4" class="ltx_td ltx_nopad_r ltx_align_left">blue, red</td>
</tr>
<tr id="S4.T10.1.1" class="ltx_tr">
<td id="S4.T10.1.1.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T10.1.1.2.1" class="ltx_text ltx_font_typewriter">brightness</span></td>
<td id="S4.T10.1.1.3" class="ltx_td ltx_align_left ltx_border_bb">built-in</td>
<td id="S4.T10.1.1.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T10.1.1.1.m1.2" class="ltx_Math" alttext="[-10^{12},10^{12}]" display="inline"><semantics id="S4.T10.1.1.1.m1.2a"><mrow id="S4.T10.1.1.1.m1.2.2.2" xref="S4.T10.1.1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.T10.1.1.1.m1.2.2.2.3" xref="S4.T10.1.1.1.m1.2.2.3.cmml">[</mo><mrow id="S4.T10.1.1.1.m1.1.1.1.1" xref="S4.T10.1.1.1.m1.1.1.1.1.cmml"><mo id="S4.T10.1.1.1.m1.1.1.1.1a" xref="S4.T10.1.1.1.m1.1.1.1.1.cmml">−</mo><msup id="S4.T10.1.1.1.m1.1.1.1.1.2" xref="S4.T10.1.1.1.m1.1.1.1.1.2.cmml"><mn id="S4.T10.1.1.1.m1.1.1.1.1.2.2" xref="S4.T10.1.1.1.m1.1.1.1.1.2.2.cmml">10</mn><mn id="S4.T10.1.1.1.m1.1.1.1.1.2.3" xref="S4.T10.1.1.1.m1.1.1.1.1.2.3.cmml">12</mn></msup></mrow><mo id="S4.T10.1.1.1.m1.2.2.2.4" xref="S4.T10.1.1.1.m1.2.2.3.cmml">,</mo><msup id="S4.T10.1.1.1.m1.2.2.2.2" xref="S4.T10.1.1.1.m1.2.2.2.2.cmml"><mn id="S4.T10.1.1.1.m1.2.2.2.2.2" xref="S4.T10.1.1.1.m1.2.2.2.2.2.cmml">10</mn><mn id="S4.T10.1.1.1.m1.2.2.2.2.3" xref="S4.T10.1.1.1.m1.2.2.2.2.3.cmml">12</mn></msup><mo stretchy="false" id="S4.T10.1.1.1.m1.2.2.2.5" xref="S4.T10.1.1.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T10.1.1.1.m1.2b"><interval closure="closed" id="S4.T10.1.1.1.m1.2.2.3.cmml" xref="S4.T10.1.1.1.m1.2.2.2"><apply id="S4.T10.1.1.1.m1.1.1.1.1.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1"><minus id="S4.T10.1.1.1.m1.1.1.1.1.1.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1"></minus><apply id="S4.T10.1.1.1.m1.1.1.1.1.2.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T10.1.1.1.m1.1.1.1.1.2.1.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S4.T10.1.1.1.m1.1.1.1.1.2.2.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1.2.2">10</cn><cn type="integer" id="S4.T10.1.1.1.m1.1.1.1.1.2.3.cmml" xref="S4.T10.1.1.1.m1.1.1.1.1.2.3">12</cn></apply></apply><apply id="S4.T10.1.1.1.m1.2.2.2.2.cmml" xref="S4.T10.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.T10.1.1.1.m1.2.2.2.2.1.cmml" xref="S4.T10.1.1.1.m1.2.2.2.2">superscript</csymbol><cn type="integer" id="S4.T10.1.1.1.m1.2.2.2.2.2.cmml" xref="S4.T10.1.1.1.m1.2.2.2.2.2">10</cn><cn type="integer" id="S4.T10.1.1.1.m1.2.2.2.2.3.cmml" xref="S4.T10.1.1.1.m1.2.2.2.2.3">12</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.1.1.1.m1.2c">[-10^{12},10^{12}]</annotation></semantics></math></td>
<td id="S4.T10.1.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">twenty, thirty-two</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T11" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span><span id="S4.T11.2.1" class="ltx_text ltx_font_typewriter">Weather</span> dataset summary</figcaption>
<table id="S4.T11.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T11.3.1.1" class="ltx_tr">
<th id="S4.T11.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Intent Name</th>
<th id="S4.T11.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Slots</th>
<th id="S4.T11.3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">Samples</th>
<th id="S4.T11.3.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column">#Utterances</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T11.3.2.1" class="ltx_tr">
<td id="S4.T11.3.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T11.3.2.1.1.1" class="ltx_text ltx_font_typewriter">ForecastCondition</span></td>
<td id="S4.T11.3.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T11.3.2.1.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">region</span></td>
<td id="S4.T11.3.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Is it <span id="S4.T11.3.2.1.3.1" class="ltx_text" style="color:#FFC40D;">cloudy</span> in <span id="S4.T11.3.2.1.3.2" class="ltx_text" style="color:#DE5C82;">Germany</span> <span id="S4.T11.3.2.1.3.3" class="ltx_text" style="color:#78DE78;">right now</span>?</td>
<td id="S4.T11.3.2.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">888</td>
</tr>
<tr id="S4.T11.3.3.2" class="ltx_tr">
<td id="S4.T11.3.3.2.1" class="ltx_td"></td>
<td id="S4.T11.3.3.2.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.3.2.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">country</span></td>
<td id="S4.T11.3.3.2.3" class="ltx_td ltx_align_left">Is <span id="S4.T11.3.3.2.3.1" class="ltx_text" style="color:#9670D6;">South Carolina</span> expected to be <span id="S4.T11.3.3.2.3.2" class="ltx_text" style="color:#FFC40D;">sunny</span>?</td>
<td id="S4.T11.3.3.2.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.4.3" class="ltx_tr">
<td id="S4.T11.3.4.3.1" class="ltx_td"></td>
<td id="S4.T11.3.4.3.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.4.3.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">datetime</span></td>
<td id="S4.T11.3.4.3.3" class="ltx_td ltx_align_left">Is there <span id="S4.T11.3.4.3.3.1" class="ltx_text" style="color:#FFC40D;">snow</span> in <span id="S4.T11.3.4.3.3.2" class="ltx_text" style="color:#0891D1;">Paris</span>?</td>
<td id="S4.T11.3.4.3.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.5.4" class="ltx_tr">
<td id="S4.T11.3.5.4.1" class="ltx_td"></td>
<td id="S4.T11.3.5.4.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.5.4.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">locality</span></td>
<td id="S4.T11.3.5.4.3" class="ltx_td ltx_align_left">Should I expect a <span id="S4.T11.3.5.4.3.1" class="ltx_text" style="color:#FFC40D;">storm</span> near <span id="S4.T11.3.5.4.3.2" class="ltx_text" style="color:#ED872E;">Mount Rushmore</span>?</td>
<td id="S4.T11.3.5.4.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.6.5" class="ltx_tr">
<td id="S4.T11.3.6.5.1" class="ltx_td"></td>
<td id="S4.T11.3.6.5.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.6.5.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">condition</span></td>
<td id="S4.T11.3.6.5.3" class="ltx_td"></td>
<td id="S4.T11.3.6.5.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.7.6" class="ltx_tr">
<td id="S4.T11.3.7.6.1" class="ltx_td"></td>
<td id="S4.T11.3.7.6.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.7.6.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">poi</span></td>
<td id="S4.T11.3.7.6.3" class="ltx_td"></td>
<td id="S4.T11.3.7.6.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.8.7" class="ltx_tr">
<td id="S4.T11.3.8.7.1" class="ltx_td ltx_align_left"><span id="S4.T11.3.8.7.1.1" class="ltx_text ltx_font_typewriter">ForecastTemperature</span></td>
<td id="S4.T11.3.8.7.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.8.7.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">region</span></td>
<td id="S4.T11.3.8.7.3" class="ltx_td ltx_align_left">Is it <span id="S4.T11.3.8.7.3.1" class="ltx_text" style="color:#FFC40D;">hot</span> <span id="S4.T11.3.8.7.3.2" class="ltx_text" style="color:#78DE78;">this afternoon</span> in <span id="S4.T11.3.8.7.3.3" class="ltx_text" style="color:#DE5C82;">France</span>?</td>
<td id="S4.T11.3.8.7.4" class="ltx_td ltx_nopad_r ltx_align_center">880</td>
</tr>
<tr id="S4.T11.3.9.8" class="ltx_tr">
<td id="S4.T11.3.9.8.1" class="ltx_td"></td>
<td id="S4.T11.3.9.8.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.9.8.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">country</span></td>
<td id="S4.T11.3.9.8.3" class="ltx_td ltx_align_left">Is it <span id="S4.T11.3.9.8.3.1" class="ltx_text" style="color:#FFC40D;">warmer</span> <span id="S4.T11.3.9.8.3.2" class="ltx_text" style="color:#78DE78;">tomorrow</span> in <span id="S4.T11.3.9.8.3.3" class="ltx_text" style="color:#9670D6;">Texas</span>?</td>
<td id="S4.T11.3.9.8.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.10.9" class="ltx_tr">
<td id="S4.T11.3.10.9.1" class="ltx_td"></td>
<td id="S4.T11.3.10.9.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.10.9.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">datetime</span></td>
<td id="S4.T11.3.10.9.3" class="ltx_td ltx_align_left">How <span id="S4.T11.3.10.9.3.1" class="ltx_text" style="color:#FFC40D;">chilly</span> is it near the <span id="S4.T11.3.10.9.3.2" class="ltx_text" style="color:#ED872E;">Ohio River</span>?</td>
<td id="S4.T11.3.10.9.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.11.10" class="ltx_tr">
<td id="S4.T11.3.11.10.1" class="ltx_td"></td>
<td id="S4.T11.3.11.10.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.11.10.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">locality</span></td>
<td id="S4.T11.3.11.10.3" class="ltx_td ltx_align_left">Will it be <span id="S4.T11.3.11.10.3.1" class="ltx_text" style="color:#FFC40D;">cold</span> <span id="S4.T11.3.11.10.3.2" class="ltx_text" style="color:#78DE78;">tomorrow</span>?</td>
<td id="S4.T11.3.11.10.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.12.11" class="ltx_tr">
<td id="S4.T11.3.12.11.1" class="ltx_td"></td>
<td id="S4.T11.3.12.11.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.12.11.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">poi</span></td>
<td id="S4.T11.3.12.11.3" class="ltx_td"></td>
<td id="S4.T11.3.12.11.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.13.12" class="ltx_tr">
<td id="S4.T11.3.13.12.1" class="ltx_td"></td>
<td id="S4.T11.3.13.12.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.13.12.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">temperature</span></td>
<td id="S4.T11.3.13.12.3" class="ltx_td"></td>
<td id="S4.T11.3.13.12.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.14.13" class="ltx_tr">
<td id="S4.T11.3.14.13.1" class="ltx_td ltx_align_left"><span id="S4.T11.3.14.13.1.1" class="ltx_text ltx_font_typewriter">Forecast</span></td>
<td id="S4.T11.3.14.13.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.14.13.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">locality</span></td>
<td id="S4.T11.3.14.13.3" class="ltx_td ltx_align_left">How’s the weather <span id="S4.T11.3.14.13.3.1" class="ltx_text" style="color:#78DE78;">this morning</span>?</td>
<td id="S4.T11.3.14.13.4" class="ltx_td ltx_nopad_r ltx_align_center">877</td>
</tr>
<tr id="S4.T11.3.15.14" class="ltx_tr">
<td id="S4.T11.3.15.14.1" class="ltx_td"></td>
<td id="S4.T11.3.15.14.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.15.14.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">poi</span></td>
<td id="S4.T11.3.15.14.3" class="ltx_td ltx_align_left">Forecast for <span id="S4.T11.3.15.14.3.1" class="ltx_text" style="color:#ED872E;">Mount Rainier</span>
</td>
<td id="S4.T11.3.15.14.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.16.15" class="ltx_tr">
<td id="S4.T11.3.16.15.1" class="ltx_td"></td>
<td id="S4.T11.3.16.15.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.16.15.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">country</span></td>
<td id="S4.T11.3.16.15.3" class="ltx_td ltx_align_left">What’s the weather like in <span id="S4.T11.3.16.15.3.1" class="ltx_text" style="color:#DE5C82;">France</span>?</td>
<td id="S4.T11.3.16.15.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.17.16" class="ltx_tr">
<td id="S4.T11.3.17.16.1" class="ltx_td"></td>
<td id="S4.T11.3.17.16.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.17.16.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">datetime</span></td>
<td id="S4.T11.3.17.16.3" class="ltx_td ltx_align_left">Weather in <span id="S4.T11.3.17.16.3.1" class="ltx_text" style="color:#0891D1;">New York</span>
</td>
<td id="S4.T11.3.17.16.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.18.17" class="ltx_tr">
<td id="S4.T11.3.18.17.1" class="ltx_td ltx_align_left"><span id="S4.T11.3.18.17.1.1" class="ltx_text ltx_font_typewriter">ForecastItem</span></td>
<td id="S4.T11.3.18.17.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.18.17.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">region</span></td>
<td id="S4.T11.3.18.17.3" class="ltx_td ltx_align_left">Should I wear a <span id="S4.T11.3.18.17.3.1" class="ltx_text" style="color:#FFC40D;">raincoat</span> <span id="S4.T11.3.18.17.3.2" class="ltx_text" style="color:#78DE78;">in February</span> in <span id="S4.T11.3.18.17.3.3" class="ltx_text" style="color:#DE5C82;">Canada</span>?</td>
<td id="S4.T11.3.18.17.4" class="ltx_td ltx_nopad_r ltx_align_center">904</td>
</tr>
<tr id="S4.T11.3.19.18" class="ltx_tr">
<td id="S4.T11.3.19.18.1" class="ltx_td"></td>
<td id="S4.T11.3.19.18.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.19.18.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">item</span></td>
<td id="S4.T11.3.19.18.3" class="ltx_td ltx_align_left">Do I pack <span id="S4.T11.3.19.18.3.1" class="ltx_text" style="color:#FFC40D;">warm socks</span> for my trip to <span id="S4.T11.3.19.18.3.2" class="ltx_text" style="color:#ED872E;">Santorini</span>?</td>
<td id="S4.T11.3.19.18.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.20.19" class="ltx_tr">
<td id="S4.T11.3.20.19.1" class="ltx_td"></td>
<td id="S4.T11.3.20.19.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.20.19.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">country</span></td>
<td id="S4.T11.3.20.19.3" class="ltx_td ltx_align_left">Is a <span id="S4.T11.3.20.19.3.1" class="ltx_text" style="color:#FFC40D;">woolen sweater</span> necessary in <span id="S4.T11.3.20.19.3.2" class="ltx_text" style="color:#9670D6;">Texas</span> <span id="S4.T11.3.20.19.3.3" class="ltx_text" style="color:#78DE78;">in May</span>?</td>
<td id="S4.T11.3.20.19.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.21.20" class="ltx_tr">
<td id="S4.T11.3.21.20.1" class="ltx_td"></td>
<td id="S4.T11.3.21.20.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.21.20.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">datetime</span></td>
<td id="S4.T11.3.21.20.3" class="ltx_td ltx_align_left">Can I wear <span id="S4.T11.3.21.20.3.1" class="ltx_text" style="color:#FFC40D;">open-toed shoes</span> in <span id="S4.T11.3.21.20.3.2" class="ltx_text" style="color:#0891D1;">Paris</span> <span id="S4.T11.3.21.20.3.3" class="ltx_text" style="color:#78DE78;">this spring</span>?</td>
<td id="S4.T11.3.21.20.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.22.21" class="ltx_tr">
<td id="S4.T11.3.22.21.1" class="ltx_td"></td>
<td id="S4.T11.3.22.21.2" class="ltx_td ltx_align_left"><span id="S4.T11.3.22.21.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">locality</span></td>
<td id="S4.T11.3.22.21.3" class="ltx_td"></td>
<td id="S4.T11.3.22.21.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="S4.T11.3.23.22" class="ltx_tr">
<td id="S4.T11.3.23.22.1" class="ltx_td ltx_border_bb"></td>
<td id="S4.T11.3.23.22.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T11.3.23.22.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">poi</span></td>
<td id="S4.T11.3.23.22.3" class="ltx_td ltx_border_bb"></td>
<td id="S4.T11.3.23.22.4" class="ltx_td ltx_nopad_r ltx_border_bb"></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span><span id="S4.T12.6.1" class="ltx_text ltx_font_typewriter">Weather</span> entities summary (<sup id="S4.T12.7.2" class="ltx_sup">⋆</sup>poi: point of interest)</figcaption>
<table id="S4.T12.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T12.3.2.1" class="ltx_tr">
<th id="S4.T12.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Slot Name</th>
<th id="S4.T12.3.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Type</th>
<th id="S4.T12.3.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">Range</th>
<th id="S4.T12.3.2.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column">Samples</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T12.3.1" class="ltx_tr">
<td id="S4.T12.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T12.3.1.1.1" class="ltx_text ltx_font_typewriter">poi<sup id="S4.T12.3.1.1.1.1" class="ltx_sup"><span id="S4.T12.3.1.1.1.1.1" class="ltx_text ltx_font_serif">⋆</span></sup></span></td>
<td id="S4.T12.3.1.2" class="ltx_td ltx_align_left ltx_border_t">custom</td>
<td id="S4.T12.3.1.3" class="ltx_td ltx_align_left ltx_border_t">124 values</td>
<td id="S4.T12.3.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Mount Everest, Ohio River</td>
</tr>
<tr id="S4.T12.3.3.1" class="ltx_tr">
<td id="S4.T12.3.3.1.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.3.1.1.1" class="ltx_text ltx_font_typewriter">condition</span></td>
<td id="S4.T12.3.3.1.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.3.1.3" class="ltx_td ltx_align_left">28 values</td>
<td id="S4.T12.3.3.1.4" class="ltx_td ltx_nopad_r ltx_align_left">windy, humid</td>
</tr>
<tr id="S4.T12.3.4.2" class="ltx_tr">
<td id="S4.T12.3.4.2.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.4.2.1.1" class="ltx_text ltx_font_typewriter">country</span></td>
<td id="S4.T12.3.4.2.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.4.2.3" class="ltx_td ltx_align_left">211 values</td>
<td id="S4.T12.3.4.2.4" class="ltx_td ltx_nopad_r ltx_align_left">Norway, France</td>
</tr>
<tr id="S4.T12.3.5.3" class="ltx_tr">
<td id="S4.T12.3.5.3.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.5.3.1.1" class="ltx_text ltx_font_typewriter">region</span></td>
<td id="S4.T12.3.5.3.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.5.3.3" class="ltx_td ltx_align_left">55 values</td>
<td id="S4.T12.3.5.3.4" class="ltx_td ltx_nopad_r ltx_align_left">California, Texas</td>
</tr>
<tr id="S4.T12.3.6.4" class="ltx_tr">
<td id="S4.T12.3.6.4.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.6.4.1.1" class="ltx_text ltx_font_typewriter">locality</span></td>
<td id="S4.T12.3.6.4.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.6.4.3" class="ltx_td ltx_align_left">535 values</td>
<td id="S4.T12.3.6.4.4" class="ltx_td ltx_nopad_r ltx_align_left">New York, Paris</td>
</tr>
<tr id="S4.T12.3.7.5" class="ltx_tr">
<td id="S4.T12.3.7.5.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.7.5.1.1" class="ltx_text ltx_font_typewriter">temperature</span></td>
<td id="S4.T12.3.7.5.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.7.5.3" class="ltx_td ltx_align_left">9 values</td>
<td id="S4.T12.3.7.5.4" class="ltx_td ltx_nopad_r ltx_align_left">hot, cold</td>
</tr>
<tr id="S4.T12.3.8.6" class="ltx_tr">
<td id="S4.T12.3.8.6.1" class="ltx_td ltx_align_left"><span id="S4.T12.3.8.6.1.1" class="ltx_text ltx_font_typewriter">item</span></td>
<td id="S4.T12.3.8.6.2" class="ltx_td ltx_align_left">custom</td>
<td id="S4.T12.3.8.6.3" class="ltx_td ltx_align_left">33 values</td>
<td id="S4.T12.3.8.6.4" class="ltx_td ltx_nopad_r ltx_align_left">umbrella, sweater</td>
</tr>
<tr id="S4.T12.3.9.7" class="ltx_tr">
<td id="S4.T12.3.9.7.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T12.3.9.7.1.1" class="ltx_text ltx_font_typewriter">datetime</span></td>
<td id="S4.T12.3.9.7.2" class="ltx_td ltx_align_left ltx_border_bb">built-in</td>
<td id="S4.T12.3.9.7.3" class="ltx_td ltx_align_left ltx_border_bb">N/A</td>
<td id="S4.T12.3.9.7.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">tomorrow, next month</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">We are interested in computing end-to-end metrics quantifying the ability of the assistants to extract intent and slots from spoken utterances. We create a test set by crowdsourcing a spoken corpus corresponding to the queries of each dataset. For each sentence of the speech corpus, we apply the ASR engine followed by the NLU engine, and compare the predicted output to the ground true intent and slots in the dataset. In the following, we present our results in terms of the classical precision, recall, and F1 scores.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Language Model Generalization Error</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">To be able to understand arbitrary formulations of an intent, the SLU engine must be able to generalize to unseen queries in the same domain. To test the generalization ability of the Snips SLU components, we use 5-fold cross-validation, and successively train the LM and NLU on four fifth of the dataset, testing on the last, unseen, fifth of the data. The training procedure is identical to the one detailed in section <a href="#S3.SS2" title="3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. We note that all the values of the entities are always included in the training set. Tables <a href="#S4.T13" title="Table 13 ‣ 4.1 Language Model Generalization Error ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> and <a href="#S4.T14" title="Table 14 ‣ 4.1 Language Model Generalization Error ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> sum up the results of this experiment, highlighting in particular the modest effect of the introduction of the ASR engine compared to the accuracy of the NLU evaluated directly on the ground true query.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">Because unseen test queries may contain out of vocabulary words absent from the training splits, the ability of the SLU to generalize in this setting relies heavily on the identification of unknown words through the strategy detailed in section <a href="#S3.SS2.SSS4" title="3.2.4 Confidence scoring ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.4</span></a>. As noted earlier and confirmed by these results, this confidence scoring strategy also allows to favor precision over recall by rejecting uncertain words that may be misinterpreted by the NLU. Figure <a href="#S4.F8" title="Figure 8 ‣ 4.1 Language Model Generalization Error ‣ 4 End-to-end Evaluation ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates the correlation between the sentence-level confidence score defined in section <a href="#S3.SS2.SSS4" title="3.2.4 Confidence scoring ‣ 3.2 Language model ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.4</span></a> and the word error rate. While noisy, the confidence allows to detect misunderstood queries, and can be mixed with the intent classification probability output by the NLU to reject dubious queries, thus promoting precision over recall.</p>
</div>
<figure id="S4.T13" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 13: </span>End-to-end generalization performance on the <span id="S4.T13.2.1" class="ltx_text ltx_font_typewriter">SmartLights</span> assistant</figcaption>
<table id="S4.T13.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T13.3.1.1" class="ltx_tr">
<th id="S4.T13.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T13.3.1.1.1.1" class="ltx_text">Intent Name</span></th>
<th id="S4.T13.3.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S4.T13.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Intent Classification</th>
<th id="S4.T13.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">Slot Filling</th>
</tr>
<tr id="S4.T13.3.2.2" class="ltx_tr">
<th id="S4.T13.3.2.2.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T13.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prec</th>
<th id="S4.T13.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Recall</th>
<th id="S4.T13.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="S4.T13.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">NLU F1</th>
<th id="S4.T13.3.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Slot</th>
<th id="S4.T13.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prec</th>
<th id="S4.T13.3.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rec</th>
<th id="S4.T13.3.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="S4.T13.3.2.2.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t">NLU F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T13.3.3.1" class="ltx_tr">
<td id="S4.T13.3.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T13.3.3.1.1.1" class="ltx_text ltx_font_typewriter">IncreaseBrightness</span></td>
<td id="S4.T13.3.3.1.2" class="ltx_td"></td>
<td id="S4.T13.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S4.T13.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.83</td>
<td id="S4.T13.3.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.87</td>
<td id="S4.T13.3.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.94</td>
<td id="S4.T13.3.3.1.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T13.3.3.1.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.3.1.8" class="ltx_td ltx_align_center ltx_border_t">0.98</td>
<td id="S4.T13.3.3.1.9" class="ltx_td ltx_align_center ltx_border_t">0.95</td>
<td id="S4.T13.3.3.1.10" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
<td id="S4.T13.3.3.1.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.96</td>
</tr>
<tr id="S4.T13.3.4.2" class="ltx_tr">
<td id="S4.T13.3.4.2.1" class="ltx_td ltx_align_left"><span id="S4.T13.3.4.2.1.1" class="ltx_text ltx_font_typewriter">DecreaseBrightness</span></td>
<td id="S4.T13.3.4.2.2" class="ltx_td"></td>
<td id="S4.T13.3.4.2.3" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T13.3.4.2.4" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T13.3.4.2.5" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T13.3.4.2.6" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T13.3.4.2.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.4.2.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.4.2.8" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T13.3.4.2.9" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T13.3.4.2.10" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T13.3.4.2.11" class="ltx_td ltx_nopad_r ltx_align_center">0.96</td>
</tr>
<tr id="S4.T13.3.5.3" class="ltx_tr">
<td id="S4.T13.3.5.3.1" class="ltx_td ltx_align_left"><span id="S4.T13.3.5.3.1.1" class="ltx_text ltx_font_typewriter">SwitchLightOff</span></td>
<td id="S4.T13.3.5.3.2" class="ltx_td"></td>
<td id="S4.T13.3.5.3.3" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.5.3.4" class="ltx_td ltx_align_center">0.81</td>
<td id="S4.T13.3.5.3.5" class="ltx_td ltx_align_center">0.87</td>
<td id="S4.T13.3.5.3.6" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.5.3.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.5.3.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.5.3.8" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T13.3.5.3.9" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T13.3.5.3.10" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T13.3.5.3.11" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T13.3.6.4" class="ltx_tr">
<td id="S4.T13.3.6.4.1" class="ltx_td ltx_align_left"><span id="S4.T13.3.6.4.1.1" class="ltx_text ltx_font_typewriter">SwitchLightOn</span></td>
<td id="S4.T13.3.6.4.2" class="ltx_td"></td>
<td id="S4.T13.3.6.4.3" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T13.3.6.4.4" class="ltx_td ltx_align_center">0.85</td>
<td id="S4.T13.3.6.4.5" class="ltx_td ltx_align_center">0.86</td>
<td id="S4.T13.3.6.4.6" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T13.3.6.4.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.6.4.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.6.4.8" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.6.4.9" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.6.4.10" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.6.4.11" class="ltx_td ltx_nopad_r ltx_align_center">0.97</td>
</tr>
<tr id="S4.T13.3.7.5" class="ltx_tr">
<td id="S4.T13.3.7.5.1" class="ltx_td ltx_align_left"><span id="S4.T13.3.7.5.1.1" class="ltx_text ltx_font_typewriter">SetLightBrightness</span></td>
<td id="S4.T13.3.7.5.2" class="ltx_td"></td>
<td id="S4.T13.3.7.5.3" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T13.3.7.5.4" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T13.3.7.5.5" class="ltx_td ltx_align_center">0.89</td>
<td id="S4.T13.3.7.5.6" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T13.3.7.5.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.7.5.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.7.5.8" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T13.3.7.5.9" class="ltx_td ltx_align_center">0.89</td>
<td id="S4.T13.3.7.5.10" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T13.3.7.5.11" class="ltx_td ltx_nopad_r ltx_align_center">0.97</td>
</tr>
<tr id="S4.T13.3.8.6" class="ltx_tr">
<td id="S4.T13.3.8.6.1" class="ltx_td"></td>
<td id="S4.T13.3.8.6.2" class="ltx_td"></td>
<td id="S4.T13.3.8.6.3" class="ltx_td"></td>
<td id="S4.T13.3.8.6.4" class="ltx_td"></td>
<td id="S4.T13.3.8.6.5" class="ltx_td"></td>
<td id="S4.T13.3.8.6.6" class="ltx_td"></td>
<td id="S4.T13.3.8.6.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.8.6.7.1" class="ltx_text ltx_font_typewriter">brightness</span></td>
<td id="S4.T13.3.8.6.8" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T13.3.8.6.9" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T13.3.8.6.10" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T13.3.8.6.11" class="ltx_td ltx_nopad_r ltx_align_center">1.0</td>
</tr>
<tr id="S4.T13.3.9.7" class="ltx_tr">
<td id="S4.T13.3.9.7.1" class="ltx_td ltx_align_left"><span id="S4.T13.3.9.7.1.1" class="ltx_text ltx_font_typewriter">SetLightColor</span></td>
<td id="S4.T13.3.9.7.2" class="ltx_td"></td>
<td id="S4.T13.3.9.7.3" class="ltx_td ltx_align_center">0.90</td>
<td id="S4.T13.3.9.7.4" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T13.3.9.7.5" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T13.3.9.7.6" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T13.3.9.7.7" class="ltx_td ltx_align_left"><span id="S4.T13.3.9.7.7.1" class="ltx_text ltx_font_typewriter">room</span></td>
<td id="S4.T13.3.9.7.8" class="ltx_td ltx_align_center">0.87</td>
<td id="S4.T13.3.9.7.9" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T13.3.9.7.10" class="ltx_td ltx_align_center">0.86</td>
<td id="S4.T13.3.9.7.11" class="ltx_td ltx_nopad_r ltx_align_center">0.96</td>
</tr>
<tr id="S4.T13.3.10.8" class="ltx_tr">
<td id="S4.T13.3.10.8.1" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.2" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.3" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.4" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.5" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.6" class="ltx_td ltx_border_bb"></td>
<td id="S4.T13.3.10.8.7" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T13.3.10.8.7.1" class="ltx_text ltx_font_typewriter">color</span></td>
<td id="S4.T13.3.10.8.8" class="ltx_td ltx_align_center ltx_border_bb">1.0</td>
<td id="S4.T13.3.10.8.9" class="ltx_td ltx_align_center ltx_border_bb">0.97</td>
<td id="S4.T13.3.10.8.10" class="ltx_td ltx_align_center ltx_border_bb">0.98</td>
<td id="S4.T13.3.10.8.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">1.0</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T14" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 14: </span>End-to-end generalization performance on the <span id="S4.T14.2.1" class="ltx_text ltx_font_typewriter">Weather</span> assistant</figcaption>
<table id="S4.T14.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T14.3.1.1" class="ltx_tr">
<th id="S4.T14.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T14.3.1.1.1.1" class="ltx_text">Intent Name</span></th>
<th id="S4.T14.3.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S4.T14.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Intent Classification</th>
<th id="S4.T14.3.1.1.4" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
<th id="S4.T14.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">Slot Filling</th>
</tr>
<tr id="S4.T14.3.2.2" class="ltx_tr">
<th id="S4.T14.3.2.2.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T14.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prec</th>
<th id="S4.T14.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Recall</th>
<th id="S4.T14.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="S4.T14.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">NLU F1</th>
<th id="S4.T14.3.2.2.6" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T14.3.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Slot</th>
<th id="S4.T14.3.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Prec</th>
<th id="S4.T14.3.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rec</th>
<th id="S4.T14.3.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="S4.T14.3.2.2.11" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t">NLU F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T14.3.3.1" class="ltx_tr">
<td id="S4.T14.3.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T14.3.3.1.1.1" class="ltx_text ltx_font_typewriter">ForecastCondition</span></td>
<td id="S4.T14.3.3.1.2" class="ltx_td"></td>
<td id="S4.T14.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
<td id="S4.T14.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.89</td>
<td id="S4.T14.3.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.93</td>
<td id="S4.T14.3.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.99</td>
<td id="S4.T14.3.3.1.7" class="ltx_td"></td>
<td id="S4.T14.3.3.1.8" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T14.3.3.1.8.1" class="ltx_text ltx_font_typewriter">region</span></td>
<td id="S4.T14.3.3.1.9" class="ltx_td ltx_align_center ltx_border_t">0.98</td>
<td id="S4.T14.3.3.1.10" class="ltx_td ltx_align_center ltx_border_t">0.95</td>
<td id="S4.T14.3.3.1.11" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
<td id="S4.T14.3.3.1.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.99</td>
</tr>
<tr id="S4.T14.3.4.2" class="ltx_tr">
<td id="S4.T14.3.4.2.1" class="ltx_td"></td>
<td id="S4.T14.3.4.2.2" class="ltx_td"></td>
<td id="S4.T14.3.4.2.3" class="ltx_td"></td>
<td id="S4.T14.3.4.2.4" class="ltx_td"></td>
<td id="S4.T14.3.4.2.5" class="ltx_td"></td>
<td id="S4.T14.3.4.2.6" class="ltx_td"></td>
<td id="S4.T14.3.4.2.7" class="ltx_td"></td>
<td id="S4.T14.3.4.2.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.4.2.8.1" class="ltx_text ltx_font_typewriter">country</span></td>
<td id="S4.T14.3.4.2.9" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T14.3.4.2.10" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T14.3.4.2.11" class="ltx_td ltx_align_center">0.91</td>
<td id="S4.T14.3.4.2.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.5.3" class="ltx_tr">
<td id="S4.T14.3.5.3.1" class="ltx_td"></td>
<td id="S4.T14.3.5.3.2" class="ltx_td"></td>
<td id="S4.T14.3.5.3.3" class="ltx_td"></td>
<td id="S4.T14.3.5.3.4" class="ltx_td"></td>
<td id="S4.T14.3.5.3.5" class="ltx_td"></td>
<td id="S4.T14.3.5.3.6" class="ltx_td"></td>
<td id="S4.T14.3.5.3.7" class="ltx_td"></td>
<td id="S4.T14.3.5.3.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.5.3.8.1" class="ltx_text ltx_font_typewriter">datetime</span></td>
<td id="S4.T14.3.5.3.9" class="ltx_td ltx_align_center">0.80</td>
<td id="S4.T14.3.5.3.10" class="ltx_td ltx_align_center">0.77</td>
<td id="S4.T14.3.5.3.11" class="ltx_td ltx_align_center">0.78</td>
<td id="S4.T14.3.5.3.12" class="ltx_td ltx_nopad_r ltx_align_center">0.95</td>
</tr>
<tr id="S4.T14.3.6.4" class="ltx_tr">
<td id="S4.T14.3.6.4.1" class="ltx_td"></td>
<td id="S4.T14.3.6.4.2" class="ltx_td"></td>
<td id="S4.T14.3.6.4.3" class="ltx_td"></td>
<td id="S4.T14.3.6.4.4" class="ltx_td"></td>
<td id="S4.T14.3.6.4.5" class="ltx_td"></td>
<td id="S4.T14.3.6.4.6" class="ltx_td"></td>
<td id="S4.T14.3.6.4.7" class="ltx_td"></td>
<td id="S4.T14.3.6.4.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.6.4.8.1" class="ltx_text ltx_font_typewriter">locality</span></td>
<td id="S4.T14.3.6.4.9" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T14.3.6.4.10" class="ltx_td ltx_align_center">0.82</td>
<td id="S4.T14.3.6.4.11" class="ltx_td ltx_align_center">0.87</td>
<td id="S4.T14.3.6.4.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.7.5" class="ltx_tr">
<td id="S4.T14.3.7.5.1" class="ltx_td"></td>
<td id="S4.T14.3.7.5.2" class="ltx_td"></td>
<td id="S4.T14.3.7.5.3" class="ltx_td"></td>
<td id="S4.T14.3.7.5.4" class="ltx_td"></td>
<td id="S4.T14.3.7.5.5" class="ltx_td"></td>
<td id="S4.T14.3.7.5.6" class="ltx_td"></td>
<td id="S4.T14.3.7.5.7" class="ltx_td"></td>
<td id="S4.T14.3.7.5.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.7.5.8.1" class="ltx_text ltx_font_typewriter">condition</span></td>
<td id="S4.T14.3.7.5.9" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T14.3.7.5.10" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T14.3.7.5.11" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.7.5.12" class="ltx_td ltx_nopad_r ltx_align_center">0.99</td>
</tr>
<tr id="S4.T14.3.8.6" class="ltx_tr">
<td id="S4.T14.3.8.6.1" class="ltx_td"></td>
<td id="S4.T14.3.8.6.2" class="ltx_td"></td>
<td id="S4.T14.3.8.6.3" class="ltx_td"></td>
<td id="S4.T14.3.8.6.4" class="ltx_td"></td>
<td id="S4.T14.3.8.6.5" class="ltx_td"></td>
<td id="S4.T14.3.8.6.6" class="ltx_td"></td>
<td id="S4.T14.3.8.6.7" class="ltx_td"></td>
<td id="S4.T14.3.8.6.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.8.6.8.1" class="ltx_text ltx_font_typewriter">poi</span></td>
<td id="S4.T14.3.8.6.9" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T14.3.8.6.10" class="ltx_td ltx_align_center">0.86</td>
<td id="S4.T14.3.8.6.11" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T14.3.8.6.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.9.7" class="ltx_tr">
<td id="S4.T14.3.9.7.1" class="ltx_td ltx_align_left"><span id="S4.T14.3.9.7.1.1" class="ltx_text ltx_font_typewriter">ForecastTemperature</span></td>
<td id="S4.T14.3.9.7.2" class="ltx_td"></td>
<td id="S4.T14.3.9.7.3" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T14.3.9.7.4" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T14.3.9.7.5" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T14.3.9.7.6" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T14.3.9.7.7" class="ltx_td"></td>
<td id="S4.T14.3.9.7.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.9.7.8.1" class="ltx_text ltx_font_typewriter">region</span></td>
<td id="S4.T14.3.9.7.9" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T14.3.9.7.10" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T14.3.9.7.11" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T14.3.9.7.12" class="ltx_td ltx_nopad_r ltx_align_center">1.0</td>
</tr>
<tr id="S4.T14.3.10.8" class="ltx_tr">
<td id="S4.T14.3.10.8.1" class="ltx_td"></td>
<td id="S4.T14.3.10.8.2" class="ltx_td"></td>
<td id="S4.T14.3.10.8.3" class="ltx_td"></td>
<td id="S4.T14.3.10.8.4" class="ltx_td"></td>
<td id="S4.T14.3.10.8.5" class="ltx_td"></td>
<td id="S4.T14.3.10.8.6" class="ltx_td"></td>
<td id="S4.T14.3.10.8.7" class="ltx_td"></td>
<td id="S4.T14.3.10.8.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.10.8.8.1" class="ltx_text ltx_font_typewriter">country</span></td>
<td id="S4.T14.3.10.8.9" class="ltx_td ltx_align_center">0.89</td>
<td id="S4.T14.3.10.8.10" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T14.3.10.8.11" class="ltx_td ltx_align_center">0.89</td>
<td id="S4.T14.3.10.8.12" class="ltx_td ltx_nopad_r ltx_align_center">1.0</td>
</tr>
<tr id="S4.T14.3.11.9" class="ltx_tr">
<td id="S4.T14.3.11.9.1" class="ltx_td"></td>
<td id="S4.T14.3.11.9.2" class="ltx_td"></td>
<td id="S4.T14.3.11.9.3" class="ltx_td"></td>
<td id="S4.T14.3.11.9.4" class="ltx_td"></td>
<td id="S4.T14.3.11.9.5" class="ltx_td"></td>
<td id="S4.T14.3.11.9.6" class="ltx_td"></td>
<td id="S4.T14.3.11.9.7" class="ltx_td"></td>
<td id="S4.T14.3.11.9.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.11.9.8.1" class="ltx_text ltx_font_typewriter">datetime</span></td>
<td id="S4.T14.3.11.9.9" class="ltx_td ltx_align_center">0.78</td>
<td id="S4.T14.3.11.9.10" class="ltx_td ltx_align_center">0.77</td>
<td id="S4.T14.3.11.9.11" class="ltx_td ltx_align_center">0.78</td>
<td id="S4.T14.3.11.9.12" class="ltx_td ltx_nopad_r ltx_align_center">0.96</td>
</tr>
<tr id="S4.T14.3.12.10" class="ltx_tr">
<td id="S4.T14.3.12.10.1" class="ltx_td"></td>
<td id="S4.T14.3.12.10.2" class="ltx_td"></td>
<td id="S4.T14.3.12.10.3" class="ltx_td"></td>
<td id="S4.T14.3.12.10.4" class="ltx_td"></td>
<td id="S4.T14.3.12.10.5" class="ltx_td"></td>
<td id="S4.T14.3.12.10.6" class="ltx_td"></td>
<td id="S4.T14.3.12.10.7" class="ltx_td"></td>
<td id="S4.T14.3.12.10.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.12.10.8.1" class="ltx_text ltx_font_typewriter">locality</span></td>
<td id="S4.T14.3.12.10.9" class="ltx_td ltx_align_center">0.89</td>
<td id="S4.T14.3.12.10.10" class="ltx_td ltx_align_center">0.80</td>
<td id="S4.T14.3.12.10.11" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T14.3.12.10.12" class="ltx_td ltx_nopad_r ltx_align_center">0.99</td>
</tr>
<tr id="S4.T14.3.13.11" class="ltx_tr">
<td id="S4.T14.3.13.11.1" class="ltx_td"></td>
<td id="S4.T14.3.13.11.2" class="ltx_td"></td>
<td id="S4.T14.3.13.11.3" class="ltx_td"></td>
<td id="S4.T14.3.13.11.4" class="ltx_td"></td>
<td id="S4.T14.3.13.11.5" class="ltx_td"></td>
<td id="S4.T14.3.13.11.6" class="ltx_td"></td>
<td id="S4.T14.3.13.11.7" class="ltx_td"></td>
<td id="S4.T14.3.13.11.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.13.11.8.1" class="ltx_text ltx_font_typewriter">poi</span></td>
<td id="S4.T14.3.13.11.9" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.13.11.10" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T14.3.13.11.11" class="ltx_td ltx_align_center">0.90</td>
<td id="S4.T14.3.13.11.12" class="ltx_td ltx_nopad_r ltx_align_center">0.99</td>
</tr>
<tr id="S4.T14.3.14.12" class="ltx_tr">
<td id="S4.T14.3.14.12.1" class="ltx_td"></td>
<td id="S4.T14.3.14.12.2" class="ltx_td"></td>
<td id="S4.T14.3.14.12.3" class="ltx_td"></td>
<td id="S4.T14.3.14.12.4" class="ltx_td"></td>
<td id="S4.T14.3.14.12.5" class="ltx_td"></td>
<td id="S4.T14.3.14.12.6" class="ltx_td"></td>
<td id="S4.T14.3.14.12.7" class="ltx_td"></td>
<td id="S4.T14.3.14.12.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.14.12.8.1" class="ltx_text ltx_font_typewriter">temperature</span></td>
<td id="S4.T14.3.14.12.9" class="ltx_td ltx_align_center">0.98</td>
<td id="S4.T14.3.14.12.10" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.14.12.11" class="ltx_td ltx_align_center">0.97</td>
<td id="S4.T14.3.14.12.12" class="ltx_td ltx_nopad_r ltx_align_center">1.0</td>
</tr>
<tr id="S4.T14.3.15.13" class="ltx_tr">
<td id="S4.T14.3.15.13.1" class="ltx_td ltx_align_left"><span id="S4.T14.3.15.13.1.1" class="ltx_text ltx_font_typewriter">Forecast</span></td>
<td id="S4.T14.3.15.13.2" class="ltx_td"></td>
<td id="S4.T14.3.15.13.3" class="ltx_td ltx_align_center">0.98</td>
<td id="S4.T14.3.15.13.4" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T14.3.15.13.5" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.15.13.6" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T14.3.15.13.7" class="ltx_td"></td>
<td id="S4.T14.3.15.13.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.15.13.8.1" class="ltx_text ltx_font_typewriter">locality</span></td>
<td id="S4.T14.3.15.13.9" class="ltx_td ltx_align_center">0.90</td>
<td id="S4.T14.3.15.13.10" class="ltx_td ltx_align_center">0.82</td>
<td id="S4.T14.3.15.13.11" class="ltx_td ltx_align_center">0.86</td>
<td id="S4.T14.3.15.13.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.16.14" class="ltx_tr">
<td id="S4.T14.3.16.14.1" class="ltx_td"></td>
<td id="S4.T14.3.16.14.2" class="ltx_td"></td>
<td id="S4.T14.3.16.14.3" class="ltx_td"></td>
<td id="S4.T14.3.16.14.4" class="ltx_td"></td>
<td id="S4.T14.3.16.14.5" class="ltx_td"></td>
<td id="S4.T14.3.16.14.6" class="ltx_td"></td>
<td id="S4.T14.3.16.14.7" class="ltx_td"></td>
<td id="S4.T14.3.16.14.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.16.14.8.1" class="ltx_text ltx_font_typewriter">poi</span></td>
<td id="S4.T14.3.16.14.9" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T14.3.16.14.10" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T14.3.16.14.11" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.16.14.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.17.15" class="ltx_tr">
<td id="S4.T14.3.17.15.1" class="ltx_td"></td>
<td id="S4.T14.3.17.15.2" class="ltx_td"></td>
<td id="S4.T14.3.17.15.3" class="ltx_td"></td>
<td id="S4.T14.3.17.15.4" class="ltx_td"></td>
<td id="S4.T14.3.17.15.5" class="ltx_td"></td>
<td id="S4.T14.3.17.15.6" class="ltx_td"></td>
<td id="S4.T14.3.17.15.7" class="ltx_td"></td>
<td id="S4.T14.3.17.15.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.17.15.8.1" class="ltx_text ltx_font_typewriter">country</span></td>
<td id="S4.T14.3.17.15.9" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T14.3.17.15.10" class="ltx_td ltx_align_center">0.90</td>
<td id="S4.T14.3.17.15.11" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T14.3.17.15.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.18.16" class="ltx_tr">
<td id="S4.T14.3.18.16.1" class="ltx_td"></td>
<td id="S4.T14.3.18.16.2" class="ltx_td"></td>
<td id="S4.T14.3.18.16.3" class="ltx_td"></td>
<td id="S4.T14.3.18.16.4" class="ltx_td"></td>
<td id="S4.T14.3.18.16.5" class="ltx_td"></td>
<td id="S4.T14.3.18.16.6" class="ltx_td"></td>
<td id="S4.T14.3.18.16.7" class="ltx_td"></td>
<td id="S4.T14.3.18.16.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.18.16.8.1" class="ltx_text ltx_font_typewriter">datetime</span></td>
<td id="S4.T14.3.18.16.9" class="ltx_td ltx_align_center">0.80</td>
<td id="S4.T14.3.18.16.10" class="ltx_td ltx_align_center">0.78</td>
<td id="S4.T14.3.18.16.11" class="ltx_td ltx_align_center">0.79</td>
<td id="S4.T14.3.18.16.12" class="ltx_td ltx_nopad_r ltx_align_center">0.96</td>
</tr>
<tr id="S4.T14.3.19.17" class="ltx_tr">
<td id="S4.T14.3.19.17.1" class="ltx_td ltx_align_left"><span id="S4.T14.3.19.17.1.1" class="ltx_text ltx_font_typewriter">ForecastItem</span></td>
<td id="S4.T14.3.19.17.2" class="ltx_td"></td>
<td id="S4.T14.3.19.17.3" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T14.3.19.17.4" class="ltx_td ltx_align_center">0.90</td>
<td id="S4.T14.3.19.17.5" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T14.3.19.17.6" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T14.3.19.17.7" class="ltx_td"></td>
<td id="S4.T14.3.19.17.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.19.17.8.1" class="ltx_text ltx_font_typewriter">region</span></td>
<td id="S4.T14.3.19.17.9" class="ltx_td ltx_align_center">0.95</td>
<td id="S4.T14.3.19.17.10" class="ltx_td ltx_align_center">0.92</td>
<td id="S4.T14.3.19.17.11" class="ltx_td ltx_align_center">0.93</td>
<td id="S4.T14.3.19.17.12" class="ltx_td ltx_nopad_r ltx_align_center">0.99</td>
</tr>
<tr id="S4.T14.3.20.18" class="ltx_tr">
<td id="S4.T14.3.20.18.1" class="ltx_td"></td>
<td id="S4.T14.3.20.18.2" class="ltx_td"></td>
<td id="S4.T14.3.20.18.3" class="ltx_td"></td>
<td id="S4.T14.3.20.18.4" class="ltx_td"></td>
<td id="S4.T14.3.20.18.5" class="ltx_td"></td>
<td id="S4.T14.3.20.18.6" class="ltx_td"></td>
<td id="S4.T14.3.20.18.7" class="ltx_td"></td>
<td id="S4.T14.3.20.18.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.20.18.8.1" class="ltx_text ltx_font_typewriter">item</span></td>
<td id="S4.T14.3.20.18.9" class="ltx_td ltx_align_center">0.99</td>
<td id="S4.T14.3.20.18.10" class="ltx_td ltx_align_center">0.94</td>
<td id="S4.T14.3.20.18.11" class="ltx_td ltx_align_center">0.96</td>
<td id="S4.T14.3.20.18.12" class="ltx_td ltx_nopad_r ltx_align_center">1.0</td>
</tr>
<tr id="S4.T14.3.21.19" class="ltx_tr">
<td id="S4.T14.3.21.19.1" class="ltx_td"></td>
<td id="S4.T14.3.21.19.2" class="ltx_td"></td>
<td id="S4.T14.3.21.19.3" class="ltx_td"></td>
<td id="S4.T14.3.21.19.4" class="ltx_td"></td>
<td id="S4.T14.3.21.19.5" class="ltx_td"></td>
<td id="S4.T14.3.21.19.6" class="ltx_td"></td>
<td id="S4.T14.3.21.19.7" class="ltx_td"></td>
<td id="S4.T14.3.21.19.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.21.19.8.1" class="ltx_text ltx_font_typewriter">country</span></td>
<td id="S4.T14.3.21.19.9" class="ltx_td ltx_align_center">0.88</td>
<td id="S4.T14.3.21.19.10" class="ltx_td ltx_align_center">0.84</td>
<td id="S4.T14.3.21.19.11" class="ltx_td ltx_align_center">0.86</td>
<td id="S4.T14.3.21.19.12" class="ltx_td ltx_nopad_r ltx_align_center">0.95</td>
</tr>
<tr id="S4.T14.3.22.20" class="ltx_tr">
<td id="S4.T14.3.22.20.1" class="ltx_td"></td>
<td id="S4.T14.3.22.20.2" class="ltx_td"></td>
<td id="S4.T14.3.22.20.3" class="ltx_td"></td>
<td id="S4.T14.3.22.20.4" class="ltx_td"></td>
<td id="S4.T14.3.22.20.5" class="ltx_td"></td>
<td id="S4.T14.3.22.20.6" class="ltx_td"></td>
<td id="S4.T14.3.22.20.7" class="ltx_td"></td>
<td id="S4.T14.3.22.20.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.22.20.8.1" class="ltx_text ltx_font_typewriter">datetime</span></td>
<td id="S4.T14.3.22.20.9" class="ltx_td ltx_align_center">0.82</td>
<td id="S4.T14.3.22.20.10" class="ltx_td ltx_align_center">0.79</td>
<td id="S4.T14.3.22.20.11" class="ltx_td ltx_align_center">0.80</td>
<td id="S4.T14.3.22.20.12" class="ltx_td ltx_nopad_r ltx_align_center">0.93</td>
</tr>
<tr id="S4.T14.3.23.21" class="ltx_tr">
<td id="S4.T14.3.23.21.1" class="ltx_td"></td>
<td id="S4.T14.3.23.21.2" class="ltx_td"></td>
<td id="S4.T14.3.23.21.3" class="ltx_td"></td>
<td id="S4.T14.3.23.21.4" class="ltx_td"></td>
<td id="S4.T14.3.23.21.5" class="ltx_td"></td>
<td id="S4.T14.3.23.21.6" class="ltx_td"></td>
<td id="S4.T14.3.23.21.7" class="ltx_td"></td>
<td id="S4.T14.3.23.21.8" class="ltx_td ltx_align_left"><span id="S4.T14.3.23.21.8.1" class="ltx_text ltx_font_typewriter">locality</span></td>
<td id="S4.T14.3.23.21.9" class="ltx_td ltx_align_center">0.87</td>
<td id="S4.T14.3.23.21.10" class="ltx_td ltx_align_center">0.80</td>
<td id="S4.T14.3.23.21.11" class="ltx_td ltx_align_center">0.83</td>
<td id="S4.T14.3.23.21.12" class="ltx_td ltx_nopad_r ltx_align_center">0.98</td>
</tr>
<tr id="S4.T14.3.24.22" class="ltx_tr">
<td id="S4.T14.3.24.22.1" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.2" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.3" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.4" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.5" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.6" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.7" class="ltx_td ltx_border_bb"></td>
<td id="S4.T14.3.24.22.8" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T14.3.24.22.8.1" class="ltx_text ltx_font_typewriter">poi</span></td>
<td id="S4.T14.3.24.22.9" class="ltx_td ltx_align_center ltx_border_bb">0.98</td>
<td id="S4.T14.3.24.22.10" class="ltx_td ltx_align_center ltx_border_bb">0.93</td>
<td id="S4.T14.3.24.22.11" class="ltx_td ltx_align_center ltx_border_bb">0.96</td>
<td id="S4.T14.3.24.22.12" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">0.99</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F8" class="ltx_figure"><img src="/html/1805.10190/assets/x7.png" id="S4.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="226" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Scatter plot of sentence-level confidence scores against word error rate. Each point represents a sentence from the test set of one of the two assistants, while the lines are obtained through a linear regression. The confidence score is correlated with the word error rate.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Embedded Performance</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.3" class="ltx_p">The embedded SLU components corresponding to the assistants described in the previous section are trained in under thirty seconds through the Snips web console (see section <a href="#S1.SS1" title="1.1 The Snips Ecosystem ‣ 1 Introduction ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a>). The resulting language models have a size of the order of the megabyte for the <span id="S4.SS2.p1.3.1" class="ltx_text ltx_font_typewriter">SmartLights</span> assistant (<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1.5" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="float" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1.5</annotation></semantics></math>MB in total, with the acoustic model), and <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="1.5" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="float" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">1.5</annotation></semantics></math>MB for the <span id="S4.SS2.p1.3.2" class="ltx_text ltx_font_typewriter">Weather</span> assistant (<math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="1.5" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn type="float" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">1.5</annotation></semantics></math>MB in total). The SLU components run faster than real time on a single core on a Raspberry Pi 3, as well as on the smaller NXP imx7D.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Training models without user data</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">The private-by-design approach described in the previous sections requires to train high-performance machine learning models without access to users queries. This problem is especially critical for the specialized language modeling components – Language Model and Natural Language Understanding engine – as both need to be trained on an assistant-specific dataset. A solution is to develop a data generation pipeline. Once the scope of an assistant has been defined, a mix of crowdsourcing and semi-supervised machine learning is used to generate thousands of high-quality training examples, mimicking user data collection without compromising on privacy. The aim of this section is to describe the data generation pipeline, and to demonstrate its impact on the performance of the NLU.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Data generation pipeline</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">A first simple approach to data generation is grammar-based generation, which consists in breaking down a written query into consecutive semantic blocks and requires enumerating every possible pattern in the chosen language. While this method guarantees an exact slot and intent supervision, queries generated in this way are highly correlated: their diversity is limited to the expressive power of the used grammar and the imagination of the person having created it. Moreover, the pattern definition and enumeration can be very time consuming and requires an extensive knowledge of the given language. This approach is therefore unfit for generating queries in natural language.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p">On the other hand, crowdsourcing – widely used in Natural Language Processing research <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">crowdsourcing </a></cite> – ensures diversity in formulation by sampling queries from a large number of demographically diverse contributors. However, the accuracy of intent and slot supervision decreases as soon as humans are in the loop. Any mislabeling of a query’s intent or slots has a strong impact on the end-to-end performance of the SLU. To guarantee a fast and accurate generation of training data for the language modeling components, we complement crowdsourcing with machine-learning-based disambiguation techniques. We new detail the implementation of the data generation pipeline.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Crowdsourcing</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Crowdsourcing tasks were originally submitted to Amazon Mechanical Turk<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://www.mturk.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mturk.com/</a></span></span></span>, a widely used platform in non-expert annotations for natural language tasks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref">amt </a></cite>. While a sufficient number of English-speaking contributors can be reached easily, other languages such as French, German or Japanese suffer from a comparatively smaller available crowd. Local crowdsourcing platforms therefore had to be integrated.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p">A text query generation task consists in generating an example of user query matching a provided set of intent and slots – e.g. the following set: <span id="S5.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_typewriter">Intent: The user wants to switch the lights on; slot: (bedroom)[room]</span> could result in the generated query “<span id="S5.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_typewriter">I want lights in the bedroom right now!</span>”. Fixing entity values reduces the task to a sentence generation and removes the need for a slot labeling step, limiting the sources of error. Diversity is enforced by both submitting this task to the widest possible crowd while limiting the number of available tasks per contributor and by selecting large sets of slot values.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p">Each generated query goes through a validation process taking the form of a second crowdsourcing task, where at least two out of three new contributors must confirm its formulation, spelling, and intent. Majority voting is indeed a simple and straightforward approach for quality assessment in crowdsourcing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib19" title="" class="ltx_ref">majorityvoting </a></cite>. A custom dashboard hosted on our servers has been developed to optimize the contributor’s workflow, with clear descriptions of the task. The dashboard also prevents a contributor from submitting a query that does not contain the imposed entity values, with a fuzzy matching rule allowing for inflections in all supported languages (conjugation, plural, gender, compounds, etc.).</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Disambiguation</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">While the previous validation step allows to filter out most spelling and formulation mistakes, it does not always guarantee the correctness of the intent or the absence of spurious entities. Indeed, in a first type of errors, the intent of the query may not match the provided one – e.g. <span id="S5.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">Switch off the lights</span> when the intent <span id="S5.SS1.SSS2.p1.1.2" class="ltx_text ltx_font_typewriter">SwitchLightOn</span> was required. In a second type of errors, spurious entities may be added by the contributor, so that they are not labeled as such – e.g. “<span id="S5.SS1.SSS2.p1.1.3" class="ltx_text ltx_font_typewriter">I want lights in the <span id="S5.SS1.SSS2.p1.1.3.1" class="ltx_text ltx_font_italic">guest</span> [bedroom](room) at <span id="S5.SS1.SSS2.p1.1.3.2" class="ltx_text ltx_font_italic">60</span> right now!</span>” when only <span id="S5.SS1.SSS2.p1.1.4" class="ltx_text ltx_font_typewriter">[bedroom](room)</span> was mentioned in the task specifications. An unlabeled entity has a particularly strong impact on the CRF features in the NLU component, and limits the ability of the LM to generalize. These errors in the training queries must be fixed to achieve a high accuracy of the SLU.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">To do so, we perform a 3-fold cross validation of the NLU engine on this dataset. This yields predicted intents and slots for each sentence in the dataset. By repeating this procedure several times, we obtain several predictions for each sentence. We then apply majority voting on these predictions to detect missing slots and wrong intents. Slots may therefore be extended – e.g. <span id="S5.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">(bedroom)[room]</span> <math id="S5.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mo stretchy="false" id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.1b"><ci id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.1c">\rightarrow</annotation></semantics></math> <span id="S5.SS1.SSS2.p2.1.2" class="ltx_text ltx_font_typewriter">(guest bedroom)[room]</span> in the previous example – or added – <span id="S5.SS1.SSS2.p2.1.3" class="ltx_text ltx_font_typewriter">(60)[intensity]</span> – and ill-formed queries (with regard to spelling or intent) are filtered-out.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation</h3>

<figure id="S5.F9" class="ltx_figure">
<br class="ltx_break">
<p id="S5.F9.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S5.F9.1.1.1" class="ltx_text"><img src="/html/1805.10190/assets/figures/datagen2.png" id="S5.F9.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="411" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Average F1-score for the slot-filling task for various intents depending on the number of training queries, for 10 (green), 50 (orange), and 500 (blue) queries.</figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">We illustrate the impact of data generation on the SLU performance on the specific case of the slot-filling task in the NLU component. The same in-house open dataset of over 16K crowdsourced query presented in Section <a href="#S3.SS3.SSS2" title="3.3.2 Evaluation ‣ 3.3 Natural Language Understanding ‣ 3 Language Modeling ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a> is used. Unsurprisingly, slot-filling performance drastically increases with the number of training samples. The F1-scores averaged over all slots are computed, depending on the number of training queries per intent. An NLU engine has been trained on each individual intent. Training queries are freely available on GitHub<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://github.com/snipsco/nlu-benchmark" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/nlu-benchmark</a></span></span></span>. The data has been generated with our data generation pipeline.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p">Figure <a href="#S5.F9" title="Figure 9 ‣ 5.2 Evaluation ‣ 5 Training models without user data ‣ Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows the influence of the number of training samples on the performance of the slot-filling task of the NLU component. Compared to 10 training queries, the gain in performance with 500 queries is of 32% absolute on average, ranging from 22% for the <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">RateBook</span> intent (from 0.76 to 0.98) to 44% for the <span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">GetWeather</span> intent (from 0.44 to 0.88). This gain indeed strongly depends on the intent’s complexity, which is mainly defined by its entities (number of entities, built-in or custom, number of entity values, etc.). While a few tens of training queries might suffice for some simple use cases (such as <span id="S5.SS2.p2.1.3" class="ltx_text ltx_font_typewriter">RateBook</span>), more complicated intents with larger sets of entity values (<span id="S5.SS2.p2.1.4" class="ltx_text ltx_font_typewriter">PlayMusic</span> for instance) require larger training datasets.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p">While it is easy to manually generate up to 50 queries, being able to come up with hundreds or thousands of diverse formulations of the same intent is nearly impossible. For private-by-design assistants that do not gather user queries, the ability to generate enough queries is key to training efficient machine learning models. Moreover, being able to generate training data allows us to validate the performance of our models before deploying them.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">In this paper, we have described the design of the Snips Voice Platform, a Spoken Language Understanding solution that can be embedded in small devices and runs entirely offline. In compliance with the privacy-by-design principle, assistants created through the Snips Voice Platform never send user queries to the cloud and offer state-of-the-art performance. Focusing on the Automatic Speech Recognition and Natural Language Understanding engines, we have described the challenges of embedding high-performance machine learning models on small IoT devices.
On the acoustic modeling side, we have shown how small-sized neural networks can be trained that enjoy near state-of-the-art accuracy while running in real-time on small devices.
On the language modeling side, we have described how to train the language model of the ASR and the NLU in a consistent way, efficiently specializing them to a particular use case. We have also demonstrated the accuracy of the resulting SLU engine on real-world assistants.
Finally, we have shown how sufficient, high-quality training data can be obtained without compromising user privacy through a combination of crowdsourcing and machine learning.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">We hope that the present paper can contribute to a larger effort towards ever more private and ubiquitous artificial intelligence. Future research directions will include private analytics, allowing to receive privacy-preserving feedback from assistant usage, and federated learning, as a complement to data generation.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">All of the work presented here has been done closely together with the engineering teams at Snips. We are grateful to the crowd of contributors who regularly work with us on the data generation pipeline. We are indebted to the community of users of the Snips Voice Platform for valuable feedback and contributions.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Appendix: NLU benchmark on an in-house dataset</h2>

<figure id="Sx2.T15" class="ltx_table">
<table id="Sx2.T15.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T15.1.1.1" class="ltx_tr">
<th id="Sx2.T15.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column">Intent Name</th>
<th id="Sx2.T15.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Slots</th>
<th id="Sx2.T15.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column">Samples</th>
<th id="Sx2.T15.1.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column">#Utterances</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T15.1.2.1" class="ltx_tr">
<td id="Sx2.T15.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="Sx2.T15.1.2.1.1.1" class="ltx_text ltx_font_typewriter">PlayMusic</span></td>
<td id="Sx2.T15.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="Sx2.T15.1.2.1.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">album, artist,</span></td>
<td id="Sx2.T15.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">I want to hear <span id="Sx2.T15.1.2.1.3.1" class="ltx_text" style="color:#0891D1;">I want to break free</span> by <span id="Sx2.T15.1.2.1.3.2" class="ltx_text" style="color:#9670D6;">Queen</span>
</td>
<td id="Sx2.T15.1.2.1.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">2300</td>
</tr>
<tr id="Sx2.T15.1.3.2" class="ltx_tr">
<td id="Sx2.T15.1.3.2.1" class="ltx_td"></td>
<td id="Sx2.T15.1.3.2.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.3.2.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">track</span></td>
<td id="Sx2.T15.1.3.2.3" class="ltx_td ltx_align_left">on <span id="Sx2.T15.1.3.2.3.1" class="ltx_text" style="color:#ED872E;">Spotify</span>
</td>
<td id="Sx2.T15.1.3.2.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.4.3" class="ltx_tr">
<td id="Sx2.T15.1.4.3.1" class="ltx_td"></td>
<td id="Sx2.T15.1.4.3.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.4.3.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">playlist</span></td>
<td id="Sx2.T15.1.4.3.3" class="ltx_td"></td>
<td id="Sx2.T15.1.4.3.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.5.4" class="ltx_tr">
<td id="Sx2.T15.1.5.4.1" class="ltx_td"></td>
<td id="Sx2.T15.1.5.4.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.5.4.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">music item</span></td>
<td id="Sx2.T15.1.5.4.3" class="ltx_td ltx_align_left">Play the <span id="Sx2.T15.1.5.4.3.1" class="ltx_text" style="color:#FF4063;">top-5</span> <span id="Sx2.T15.1.5.4.3.2" class="ltx_text" style="color:#178212;">soul</span> <span id="Sx2.T15.1.5.4.3.3" class="ltx_text" style="color:#FFC40D;">songs</span>
</td>
<td id="Sx2.T15.1.5.4.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.6.5" class="ltx_tr">
<td id="Sx2.T15.1.6.5.1" class="ltx_td"></td>
<td id="Sx2.T15.1.6.5.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.6.5.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">service</span></td>
<td id="Sx2.T15.1.6.5.3" class="ltx_td"></td>
<td id="Sx2.T15.1.6.5.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.7.6" class="ltx_tr">
<td id="Sx2.T15.1.7.6.1" class="ltx_td"></td>
<td id="Sx2.T15.1.7.6.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.7.6.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF4063;">sort</span></td>
<td id="Sx2.T15.1.7.6.3" class="ltx_td ltx_align_left">Put on <span id="Sx2.T15.1.7.6.3.1" class="ltx_text" style="color:#9670D6;">John Lennon</span>’s <span id="Sx2.T15.1.7.6.3.2" class="ltx_text" style="color:#0000FF;">1980</span> <span id="Sx2.T15.1.7.6.3.3" class="ltx_text" style="color:#FFC40D;">album</span>
</td>
<td id="Sx2.T15.1.7.6.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.8.7" class="ltx_tr">
<td id="Sx2.T15.1.8.7.1" class="ltx_td"></td>
<td id="Sx2.T15.1.8.7.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.8.7.2.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">year</span></td>
<td id="Sx2.T15.1.8.7.3" class="ltx_td"></td>
<td id="Sx2.T15.1.8.7.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.9.8" class="ltx_tr">
<td id="Sx2.T15.1.9.8.1" class="ltx_td"></td>
<td id="Sx2.T15.1.9.8.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.9.8.2.1" class="ltx_text ltx_font_typewriter" style="color:#178212;">genre</span></td>
<td id="Sx2.T15.1.9.8.3" class="ltx_td"></td>
<td id="Sx2.T15.1.9.8.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.10.9" class="ltx_tr">
<td id="Sx2.T15.1.10.9.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.10.9.1.1" class="ltx_text ltx_font_typewriter">GetWeather</span></td>
<td id="Sx2.T15.1.10.9.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.10.9.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">city, country,</span></td>
<td id="Sx2.T15.1.10.9.3" class="ltx_td ltx_align_left">Will it be <span id="Sx2.T15.1.10.9.3.1" class="ltx_text" style="color:#FFC40D;">sunny</span> <span id="Sx2.T15.1.10.9.3.2" class="ltx_text" style="color:#ED872E;">tomorrow</span> <span id="Sx2.T15.1.10.9.3.3" class="ltx_text" style="color:#178212;">near</span>
</td>
<td id="Sx2.T15.1.10.9.4" class="ltx_td ltx_nopad_r ltx_align_center">2300</td>
</tr>
<tr id="Sx2.T15.1.11.10" class="ltx_tr">
<td id="Sx2.T15.1.11.10.1" class="ltx_td"></td>
<td id="Sx2.T15.1.11.10.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.11.10.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">state</span></td>
<td id="Sx2.T15.1.11.10.3" class="ltx_td ltx_align_left">
<span id="Sx2.T15.1.11.10.3.1" class="ltx_text" style="color:#0891D1;">North Creek Forest</span>?</td>
<td id="Sx2.T15.1.11.10.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.12.11" class="ltx_tr">
<td id="Sx2.T15.1.12.11.1" class="ltx_td"></td>
<td id="Sx2.T15.1.12.11.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.12.11.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">poi</span></td>
<td id="Sx2.T15.1.12.11.3" class="ltx_td"></td>
<td id="Sx2.T15.1.12.11.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.13.12" class="ltx_tr">
<td id="Sx2.T15.1.13.12.1" class="ltx_td"></td>
<td id="Sx2.T15.1.13.12.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.13.12.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">time range</span></td>
<td id="Sx2.T15.1.13.12.3" class="ltx_td ltx_align_left">How <span id="Sx2.T15.1.13.12.3.1" class="ltx_text" style="color:#FF4063;">chilly</span> is it <span id="Sx2.T15.1.13.12.3.2" class="ltx_text" style="color:#0000FF;">here</span>?</td>
<td id="Sx2.T15.1.13.12.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.14.13" class="ltx_tr">
<td id="Sx2.T15.1.14.13.1" class="ltx_td"></td>
<td id="Sx2.T15.1.14.13.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.14.13.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">condition</span></td>
<td id="Sx2.T15.1.14.13.3" class="ltx_td"></td>
<td id="Sx2.T15.1.14.13.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.15.14" class="ltx_tr">
<td id="Sx2.T15.1.15.14.1" class="ltx_td"></td>
<td id="Sx2.T15.1.15.14.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.15.14.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF4063;">temperature</span></td>
<td id="Sx2.T15.1.15.14.3" class="ltx_td ltx_align_left">Should we expect <span id="Sx2.T15.1.15.14.3.1" class="ltx_text" style="color:#FFC40D;">fog</span> in <span id="Sx2.T15.1.15.14.3.2" class="ltx_text" style="color:#9670D6;">London</span>, <span id="Sx2.T15.1.15.14.3.3" class="ltx_text" style="color:#9670D6;">UK</span>?</td>
<td id="Sx2.T15.1.15.14.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.16.15" class="ltx_tr">
<td id="Sx2.T15.1.16.15.1" class="ltx_td"></td>
<td id="Sx2.T15.1.16.15.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.16.15.2.1" class="ltx_text ltx_font_typewriter" style="color:#178212;">spatial relation</span></td>
<td id="Sx2.T15.1.16.15.3" class="ltx_td"></td>
<td id="Sx2.T15.1.16.15.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.17.16" class="ltx_tr">
<td id="Sx2.T15.1.17.16.1" class="ltx_td"></td>
<td id="Sx2.T15.1.17.16.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.17.16.2.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">current location</span></td>
<td id="Sx2.T15.1.17.16.3" class="ltx_td"></td>
<td id="Sx2.T15.1.17.16.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.18.17" class="ltx_tr">
<td id="Sx2.T15.1.18.17.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.18.17.1.1" class="ltx_text ltx_font_typewriter">BookRestaurant</span></td>
<td id="Sx2.T15.1.18.17.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.18.17.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">sort</span></td>
<td id="Sx2.T15.1.18.17.3" class="ltx_td ltx_align_left">I’d like to eat at a <span id="Sx2.T15.1.18.17.3.1" class="ltx_text" style="color:#0000FF;">taverna</span> that serves</td>
<td id="Sx2.T15.1.18.17.4" class="ltx_td ltx_nopad_r ltx_align_center">2273</td>
</tr>
<tr id="Sx2.T15.1.19.18" class="ltx_tr">
<td id="Sx2.T15.1.19.18.1" class="ltx_td"></td>
<td id="Sx2.T15.1.19.18.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.19.18.2.1" class="ltx_text ltx_font_typewriter" style="color:#21B3AB;">party size nb</span></td>
<td id="Sx2.T15.1.19.18.3" class="ltx_td ltx_align_left">
<span id="Sx2.T15.1.19.18.3.1" class="ltx_text" style="color:#FFC40D;">chili con carne</span> with a party of <span id="Sx2.T15.1.19.18.3.2" class="ltx_text" style="color:#21B3AB;">10</span>
</td>
<td id="Sx2.T15.1.19.18.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.20.19" class="ltx_tr">
<td id="Sx2.T15.1.20.19.1" class="ltx_td"></td>
<td id="Sx2.T15.1.20.19.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.20.19.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">party size descr</span></td>
<td id="Sx2.T15.1.20.19.3" class="ltx_td"></td>
<td id="Sx2.T15.1.20.19.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.21.20" class="ltx_tr">
<td id="Sx2.T15.1.21.20.1" class="ltx_td"></td>
<td id="Sx2.T15.1.21.20.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.21.20.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">spatial relation</span></td>
<td id="Sx2.T15.1.21.20.3" class="ltx_td ltx_align_left">Make a reservation at a <span id="Sx2.T15.1.21.20.3.1" class="ltx_text" style="color:#0891D1;">highly rated</span> <span id="Sx2.T15.1.21.20.3.2" class="ltx_text" style="color:#0000FF;">pub</span>
</td>
<td id="Sx2.T15.1.21.20.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.22.21" class="ltx_tr">
<td id="Sx2.T15.1.22.21.1" class="ltx_td"></td>
<td id="Sx2.T15.1.22.21.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.22.21.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">city, country</span></td>
<td id="Sx2.T15.1.22.21.3" class="ltx_td ltx_align_left">for <span id="Sx2.T15.1.22.21.3.1" class="ltx_text" style="color:#178212;">tonight</span> in <span id="Sx2.T15.1.22.21.3.2" class="ltx_text" style="color:#78DE78;">Paris</span> <span id="Sx2.T15.1.22.21.3.3" class="ltx_text" style="color:#DE5C82;">within walking distance</span>
</td>
<td id="Sx2.T15.1.22.21.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.23.22" class="ltx_tr">
<td id="Sx2.T15.1.23.22.1" class="ltx_td"></td>
<td id="Sx2.T15.1.23.22.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.23.22.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">state</span></td>
<td id="Sx2.T15.1.23.22.3" class="ltx_td ltx_align_left">from <span id="Sx2.T15.1.23.22.3.1" class="ltx_text" style="color:#FF4063;">my hotel</span>
</td>
<td id="Sx2.T15.1.23.22.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.24.23" class="ltx_tr">
<td id="Sx2.T15.1.24.23.1" class="ltx_td"></td>
<td id="Sx2.T15.1.24.23.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.24.23.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF4063;">poi</span></td>
<td id="Sx2.T15.1.24.23.3" class="ltx_td"></td>
<td id="Sx2.T15.1.24.23.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.25.24" class="ltx_tr">
<td id="Sx2.T15.1.25.24.1" class="ltx_td"></td>
<td id="Sx2.T15.1.25.24.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.25.24.2.1" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">restaurant type</span></td>
<td id="Sx2.T15.1.25.24.3" class="ltx_td ltx_align_left">Book an <span id="Sx2.T15.1.25.24.3.1" class="ltx_text" style="color:#5C8AA8;">italian</span> place with a <span id="Sx2.T15.1.25.24.3.2" class="ltx_text" style="color:#ED872E;">parking</span>
</td>
<td id="Sx2.T15.1.25.24.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.26.25" class="ltx_tr">
<td id="Sx2.T15.1.26.25.1" class="ltx_td"></td>
<td id="Sx2.T15.1.26.25.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.26.25.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">restaurant name</span></td>
<td id="Sx2.T15.1.26.25.3" class="ltx_td ltx_align_left">for <span id="Sx2.T15.1.26.25.3.1" class="ltx_text" style="color:#9670D6;">my grand father and I</span>
</td>
<td id="Sx2.T15.1.26.25.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.27.26" class="ltx_tr">
<td id="Sx2.T15.1.27.26.1" class="ltx_td"></td>
<td id="Sx2.T15.1.27.26.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.27.26.2.1" class="ltx_text ltx_font_typewriter" style="color:#5C8AA8;">cuisine</span></td>
<td id="Sx2.T15.1.27.26.3" class="ltx_td"></td>
<td id="Sx2.T15.1.27.26.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.28.27" class="ltx_tr">
<td id="Sx2.T15.1.28.27.1" class="ltx_td"></td>
<td id="Sx2.T15.1.28.27.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.28.27.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">served dish</span></td>
<td id="Sx2.T15.1.28.27.3" class="ltx_td"></td>
<td id="Sx2.T15.1.28.27.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.29.28" class="ltx_tr">
<td id="Sx2.T15.1.29.28.1" class="ltx_td"></td>
<td id="Sx2.T15.1.29.28.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.29.28.2.1" class="ltx_text ltx_font_typewriter" style="color:#178212;">time range</span></td>
<td id="Sx2.T15.1.29.28.3" class="ltx_td"></td>
<td id="Sx2.T15.1.29.28.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.30.29" class="ltx_tr">
<td id="Sx2.T15.1.30.29.1" class="ltx_td"></td>
<td id="Sx2.T15.1.30.29.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.30.29.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">facility</span></td>
<td id="Sx2.T15.1.30.29.3" class="ltx_td"></td>
<td id="Sx2.T15.1.30.29.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.31.30" class="ltx_tr">
<td id="Sx2.T15.1.31.30.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.31.30.1.1" class="ltx_text ltx_font_typewriter">AddToPlaylist</span></td>
<td id="Sx2.T15.1.31.30.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.31.30.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">name, artist</span></td>
<td id="Sx2.T15.1.31.30.3" class="ltx_td ltx_align_left">Add <span id="Sx2.T15.1.31.30.3.1" class="ltx_text" style="color:#9670D6;">Diamonds</span> to <span id="Sx2.T15.1.31.30.3.2" class="ltx_text" style="color:#FFC40D;">my</span> <span id="Sx2.T15.1.31.30.3.3" class="ltx_text" style="color:#DE5C82;">roadtrip</span> playlist</td>
<td id="Sx2.T15.1.31.30.4" class="ltx_td ltx_nopad_r ltx_align_center">2242</td>
</tr>
<tr id="Sx2.T15.1.32.31" class="ltx_tr">
<td id="Sx2.T15.1.32.31.1" class="ltx_td"></td>
<td id="Sx2.T15.1.32.31.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.32.31.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">playlist owner</span></td>
<td id="Sx2.T15.1.32.31.3" class="ltx_td"></td>
<td id="Sx2.T15.1.32.31.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.33.32" class="ltx_tr">
<td id="Sx2.T15.1.33.32.1" class="ltx_td"></td>
<td id="Sx2.T15.1.33.32.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.33.32.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">playlist</span></td>
<td id="Sx2.T15.1.33.32.3" class="ltx_td ltx_align_left">Please add <span id="Sx2.T15.1.33.32.3.1" class="ltx_text" style="color:#9670D6;">Eddy De Pretto</span>’s <span id="Sx2.T15.1.33.32.3.2" class="ltx_text" style="color:#78DE78;">album</span>
</td>
<td id="Sx2.T15.1.33.32.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.34.33" class="ltx_tr">
<td id="Sx2.T15.1.34.33.1" class="ltx_td"></td>
<td id="Sx2.T15.1.34.33.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.34.33.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">music item</span></td>
<td id="Sx2.T15.1.34.33.3" class="ltx_td"></td>
<td id="Sx2.T15.1.34.33.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.35.34" class="ltx_tr">
<td id="Sx2.T15.1.35.34.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.35.34.1.1" class="ltx_text ltx_font_typewriter">RateBook</span></td>
<td id="Sx2.T15.1.35.34.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.35.34.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">type</span></td>
<td id="Sx2.T15.1.35.34.3" class="ltx_td ltx_align_left">Rate the <span id="Sx2.T15.1.35.34.3.1" class="ltx_text" style="color:#FFC40D;">current</span> <span id="Sx2.T15.1.35.34.3.2" class="ltx_text" style="color:#FF4063;">saga</span> <span id="Sx2.T15.1.35.34.3.3" class="ltx_text" style="color:#ED872E;">three</span> <span id="Sx2.T15.1.35.34.3.4" class="ltx_text" style="color:#78DE78;">stars</span>
</td>
<td id="Sx2.T15.1.35.34.4" class="ltx_td ltx_nopad_r ltx_align_center">2256</td>
</tr>
<tr id="Sx2.T15.1.36.35" class="ltx_tr">
<td id="Sx2.T15.1.36.35.1" class="ltx_td"></td>
<td id="Sx2.T15.1.36.35.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.36.35.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">name</span></td>
<td id="Sx2.T15.1.36.35.3" class="ltx_td"></td>
<td id="Sx2.T15.1.36.35.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.37.36" class="ltx_tr">
<td id="Sx2.T15.1.37.36.1" class="ltx_td"></td>
<td id="Sx2.T15.1.37.36.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.37.36.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">rating unit</span></td>
<td id="Sx2.T15.1.37.36.3" class="ltx_td ltx_align_left">Rate <span id="Sx2.T15.1.37.36.3.1" class="ltx_text" style="color:#DE5C82;">Of Mice and Men</span> <span id="Sx2.T15.1.37.36.3.2" class="ltx_text" style="color:#ED872E;">5</span> <span id="Sx2.T15.1.37.36.3.3" class="ltx_text" style="color:#78DE78;">points</span> out of <span id="Sx2.T15.1.37.36.3.4" class="ltx_text" style="color:#0891D1;">6</span>
</td>
<td id="Sx2.T15.1.37.36.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.38.37" class="ltx_tr">
<td id="Sx2.T15.1.38.37.1" class="ltx_td"></td>
<td id="Sx2.T15.1.38.37.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.38.37.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">best rating</span></td>
<td id="Sx2.T15.1.38.37.3" class="ltx_td"></td>
<td id="Sx2.T15.1.38.37.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.39.38" class="ltx_tr">
<td id="Sx2.T15.1.39.38.1" class="ltx_td"></td>
<td id="Sx2.T15.1.39.38.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.39.38.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">rating value</span></td>
<td id="Sx2.T15.1.39.38.3" class="ltx_td ltx_align_left">I give the <span id="Sx2.T15.1.39.38.3.1" class="ltx_text" style="color:#FFC40D;">previous</span> <span id="Sx2.T15.1.39.38.3.2" class="ltx_text" style="color:#9670D6;">essay</span> a <span id="Sx2.T15.1.39.38.3.3" class="ltx_text" style="color:#ED872E;">four</span>
</td>
<td id="Sx2.T15.1.39.38.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.40.39" class="ltx_tr">
<td id="Sx2.T15.1.40.39.1" class="ltx_td"></td>
<td id="Sx2.T15.1.40.39.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.40.39.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">select</span></td>
<td id="Sx2.T15.1.40.39.3" class="ltx_td"></td>
<td id="Sx2.T15.1.40.39.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.41.40" class="ltx_tr">
<td id="Sx2.T15.1.41.40.1" class="ltx_td"></td>
<td id="Sx2.T15.1.41.40.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.41.40.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF4063;">series</span></td>
<td id="Sx2.T15.1.41.40.3" class="ltx_td"></td>
<td id="Sx2.T15.1.41.40.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.42.41" class="ltx_tr">
<td id="Sx2.T15.1.42.41.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.42.41.1.1" class="ltx_text ltx_font_typewriter">SearchCreativeWork</span></td>
<td id="Sx2.T15.1.42.41.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.42.41.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">type</span></td>
<td id="Sx2.T15.1.42.41.3" class="ltx_td ltx_align_left">Find the <span id="Sx2.T15.1.42.41.3.1" class="ltx_text" style="color:#9670D6;">movie</span> named <span id="Sx2.T15.1.42.41.3.2" class="ltx_text" style="color:#DE5C82;">Garden State</span>
</td>
<td id="Sx2.T15.1.42.41.4" class="ltx_td ltx_nopad_r ltx_align_center">2254</td>
</tr>
<tr id="Sx2.T15.1.43.42" class="ltx_tr">
<td id="Sx2.T15.1.43.42.1" class="ltx_td"></td>
<td id="Sx2.T15.1.43.42.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.43.42.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">name</span></td>
<td id="Sx2.T15.1.43.42.3" class="ltx_td"></td>
<td id="Sx2.T15.1.43.42.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.44.43" class="ltx_tr">
<td id="Sx2.T15.1.44.43.1" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.44.43.1.1" class="ltx_text ltx_font_typewriter">SearchScreeningEvent</span></td>
<td id="Sx2.T15.1.44.43.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.44.43.2.1" class="ltx_text ltx_font_typewriter" style="color:#9670D6;">object</span></td>
<td id="Sx2.T15.1.44.43.3" class="ltx_td ltx_align_left">Which <span id="Sx2.T15.1.44.43.3.1" class="ltx_text" style="color:#0891D1;">movie theater</span> is playing</td>
<td id="Sx2.T15.1.44.43.4" class="ltx_td ltx_nopad_r ltx_align_center">2259</td>
</tr>
<tr id="Sx2.T15.1.45.44" class="ltx_tr">
<td id="Sx2.T15.1.45.44.1" class="ltx_td"></td>
<td id="Sx2.T15.1.45.44.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.45.44.2.1" class="ltx_text ltx_font_typewriter" style="color:#DE5C82;">type</span></td>
<td id="Sx2.T15.1.45.44.3" class="ltx_td ltx_align_left">
<span id="Sx2.T15.1.45.44.3.1" class="ltx_text" style="color:#78DE78;">The Good Will Hunting</span> <span id="Sx2.T15.1.45.44.3.2" class="ltx_text" style="color:#FFC40D;">nearby</span>?</td>
<td id="Sx2.T15.1.45.44.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.46.45" class="ltx_tr">
<td id="Sx2.T15.1.46.45.1" class="ltx_td"></td>
<td id="Sx2.T15.1.46.45.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.46.45.2.1" class="ltx_text ltx_font_typewriter" style="color:#78DE78;">name</span></td>
<td id="Sx2.T15.1.46.45.3" class="ltx_td"></td>
<td id="Sx2.T15.1.46.45.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.47.46" class="ltx_tr">
<td id="Sx2.T15.1.47.46.1" class="ltx_td"></td>
<td id="Sx2.T15.1.47.46.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.47.46.2.1" class="ltx_text ltx_font_typewriter" style="color:#0891D1;">location type</span></td>
<td id="Sx2.T15.1.47.46.3" class="ltx_td ltx_align_left">Show me the <span id="Sx2.T15.1.47.46.3.1" class="ltx_text" style="color:#9670D6;">movie schedule</span> at the</td>
<td id="Sx2.T15.1.47.46.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.48.47" class="ltx_tr">
<td id="Sx2.T15.1.48.47.1" class="ltx_td"></td>
<td id="Sx2.T15.1.48.47.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.48.47.2.1" class="ltx_text ltx_font_typewriter" style="color:#ED872E;">location name</span></td>
<td id="Sx2.T15.1.48.47.3" class="ltx_td ltx_align_left">
<span id="Sx2.T15.1.48.47.3.1" class="ltx_text" style="color:#ED872E;">Grand Rex</span> <span id="Sx2.T15.1.48.47.3.2" class="ltx_text" style="color:#FF4063;">tonight</span>
</td>
<td id="Sx2.T15.1.48.47.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.49.48" class="ltx_tr">
<td id="Sx2.T15.1.49.48.1" class="ltx_td"></td>
<td id="Sx2.T15.1.49.48.2" class="ltx_td ltx_align_left"><span id="Sx2.T15.1.49.48.2.1" class="ltx_text ltx_font_typewriter" style="color:#FFC40D;">spatial relation</span></td>
<td id="Sx2.T15.1.49.48.3" class="ltx_td"></td>
<td id="Sx2.T15.1.49.48.4" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="Sx2.T15.1.50.49" class="ltx_tr">
<td id="Sx2.T15.1.50.49.1" class="ltx_td ltx_border_bb"></td>
<td id="Sx2.T15.1.50.49.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="Sx2.T15.1.50.49.2.1" class="ltx_text ltx_font_typewriter" style="color:#FF4063;">time range</span></td>
<td id="Sx2.T15.1.50.49.3" class="ltx_td ltx_border_bb"></td>
<td id="Sx2.T15.1.50.49.4" class="ltx_td ltx_nopad_r ltx_border_bb"></td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>In-house slot-filling dataset summary</figcaption>
</figure>
<figure id="Sx2.T16" class="ltx_table ltx_align_center">
<table id="Sx2.T16.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T16.1.1.1" class="ltx_tr">
<th id="Sx2.T16.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">intent</th>
<th id="Sx2.T16.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">NLU provider</th>
<th id="Sx2.T16.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">train size</th>
<th id="Sx2.T16.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">precision</th>
<th id="Sx2.T16.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">recall</th>
<th id="Sx2.T16.1.1.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T16.1.2.1" class="ltx_tr">
<th id="Sx2.T16.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="10"><span id="Sx2.T16.1.2.1.1.1" class="ltx_text ltx_font_typewriter">SearchCreativeWork</span></th>
<th id="Sx2.T16.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="2"><span id="Sx2.T16.1.2.1.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T16.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">70</th>
<td id="Sx2.T16.1.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.993</td>
<td id="Sx2.T16.1.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.746</td>
<td id="Sx2.T16.1.2.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">0.849</td>
</tr>
<tr id="Sx2.T16.1.3.2" class="ltx_tr">
<th id="Sx2.T16.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.3.2.2" class="ltx_td ltx_align_center">1.000</td>
<td id="Sx2.T16.1.3.2.3" class="ltx_td ltx_align_center">0.995</td>
<td id="Sx2.T16.1.3.2.4" class="ltx_td ltx_nopad_r ltx_align_center">0.997</td>
</tr>
<tr id="Sx2.T16.1.4.3" class="ltx_tr">
<th id="Sx2.T16.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.4.3.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T16.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.959</td>
<td id="Sx2.T16.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.569</td>
<td id="Sx2.T16.1.4.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.956</td>
</tr>
<tr id="Sx2.T16.1.5.4" class="ltx_tr">
<th id="Sx2.T16.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.5.4.2" class="ltx_td ltx_align_center">0.974</td>
<td id="Sx2.T16.1.5.4.3" class="ltx_td ltx_align_center">0.955</td>
<td id="Sx2.T16.1.5.4.4" class="ltx_td ltx_nopad_r ltx_align_center">0.964</td>
</tr>
<tr id="Sx2.T16.1.6.5" class="ltx_tr">
<th id="Sx2.T16.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.6.5.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T16.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.915</td>
<td id="Sx2.T16.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.711</td>
<td id="Sx2.T16.1.6.5.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.797</td>
</tr>
<tr id="Sx2.T16.1.7.6" class="ltx_tr">
<th id="Sx2.T16.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.7.6.2" class="ltx_td ltx_align_center">1.000</td>
<td id="Sx2.T16.1.7.6.3" class="ltx_td ltx_align_center">0.968</td>
<td id="Sx2.T16.1.7.6.4" class="ltx_td ltx_nopad_r ltx_align_center">0.983</td>
</tr>
<tr id="Sx2.T16.1.8.7" class="ltx_tr">
<th id="Sx2.T16.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.8.7.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T16.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.8.7.3" class="ltx_td ltx_align_center ltx_border_t">0.492</td>
<td id="Sx2.T16.1.8.7.4" class="ltx_td ltx_align_center ltx_border_t">0.323</td>
<td id="Sx2.T16.1.8.7.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.383</td>
</tr>
<tr id="Sx2.T16.1.9.8" class="ltx_tr">
<th id="Sx2.T16.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.9.8.2" class="ltx_td ltx_align_center">0.464</td>
<td id="Sx2.T16.1.9.8.3" class="ltx_td ltx_align_center">0.375</td>
<td id="Sx2.T16.1.9.8.4" class="ltx_td ltx_nopad_r ltx_align_center">0.413</td>
</tr>
<tr id="Sx2.T16.1.10.9" class="ltx_tr">
<th id="Sx2.T16.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.10.9.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T16.1.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.10.9.3" class="ltx_td ltx_align_center ltx_border_t">0.864</td>
<td id="Sx2.T16.1.10.9.4" class="ltx_td ltx_align_center ltx_border_t">0.908</td>
<td id="Sx2.T16.1.10.9.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.885</td>
</tr>
<tr id="Sx2.T16.1.11.10" class="ltx_tr">
<th id="Sx2.T16.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.11.10.2" class="ltx_td ltx_align_center">0.983</td>
<td id="Sx2.T16.1.11.10.3" class="ltx_td ltx_align_center">0.976</td>
<td id="Sx2.T16.1.11.10.4" class="ltx_td ltx_nopad_r ltx_align_center">0.980</td>
</tr>
<tr id="Sx2.T16.1.12.11" class="ltx_tr">
<th id="Sx2.T16.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="10"><span id="Sx2.T16.1.12.11.1.1" class="ltx_text ltx_font_typewriter">GetWeather</span></th>
<th id="Sx2.T16.1.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.12.11.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T16.1.12.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.12.11.4" class="ltx_td ltx_align_center ltx_border_t">0.781</td>
<td id="Sx2.T16.1.12.11.5" class="ltx_td ltx_align_center ltx_border_t">0.271</td>
<td id="Sx2.T16.1.12.11.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.405</td>
</tr>
<tr id="Sx2.T16.1.13.12" class="ltx_tr">
<th id="Sx2.T16.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.13.12.2" class="ltx_td ltx_align_center">0.985</td>
<td id="Sx2.T16.1.13.12.3" class="ltx_td ltx_align_center">0.902</td>
<td id="Sx2.T16.1.13.12.4" class="ltx_td ltx_nopad_r ltx_align_center">0.940</td>
</tr>
<tr id="Sx2.T16.1.14.13" class="ltx_tr">
<th id="Sx2.T16.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.14.13.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T16.1.14.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.14.13.3" class="ltx_td ltx_align_center ltx_border_t">0.790</td>
<td id="Sx2.T16.1.14.13.4" class="ltx_td ltx_align_center ltx_border_t">0.411</td>
<td id="Sx2.T16.1.14.13.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.540</td>
</tr>
<tr id="Sx2.T16.1.15.14" class="ltx_tr">
<th id="Sx2.T16.1.15.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.15.14.2" class="ltx_td ltx_align_center">0.847</td>
<td id="Sx2.T16.1.15.14.3" class="ltx_td ltx_align_center">0.874</td>
<td id="Sx2.T16.1.15.14.4" class="ltx_td ltx_nopad_r ltx_align_center">0.825</td>
</tr>
<tr id="Sx2.T16.1.16.15" class="ltx_tr">
<th id="Sx2.T16.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.16.15.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T16.1.16.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.16.15.3" class="ltx_td ltx_align_center ltx_border_t">0.666</td>
<td id="Sx2.T16.1.16.15.4" class="ltx_td ltx_align_center ltx_border_t">0.513</td>
<td id="Sx2.T16.1.16.15.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.530</td>
</tr>
<tr id="Sx2.T16.1.17.16" class="ltx_tr">
<th id="Sx2.T16.1.17.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.17.16.2" class="ltx_td ltx_align_center">0.826</td>
<td id="Sx2.T16.1.17.16.3" class="ltx_td ltx_align_center">0.751</td>
<td id="Sx2.T16.1.17.16.4" class="ltx_td ltx_nopad_r ltx_align_center">0.761</td>
</tr>
<tr id="Sx2.T16.1.18.17" class="ltx_tr">
<th id="Sx2.T16.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.18.17.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T16.1.18.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.18.17.3" class="ltx_td ltx_align_center ltx_border_t">0.764</td>
<td id="Sx2.T16.1.18.17.4" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="Sx2.T16.1.18.17.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.572</td>
</tr>
<tr id="Sx2.T16.1.19.18" class="ltx_tr">
<th id="Sx2.T16.1.19.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.19.18.2" class="ltx_td ltx_align_center">0.818</td>
<td id="Sx2.T16.1.19.18.3" class="ltx_td ltx_align_center">0.701</td>
<td id="Sx2.T16.1.19.18.4" class="ltx_td ltx_nopad_r ltx_align_center">0.746</td>
</tr>
<tr id="Sx2.T16.1.20.19" class="ltx_tr">
<th id="Sx2.T16.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.20.19.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T16.1.20.19.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.20.19.3" class="ltx_td ltx_align_center ltx_border_t">0.791</td>
<td id="Sx2.T16.1.20.19.4" class="ltx_td ltx_align_center ltx_border_t">0.703</td>
<td id="Sx2.T16.1.20.19.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.742</td>
</tr>
<tr id="Sx2.T16.1.21.20" class="ltx_tr">
<th id="Sx2.T16.1.21.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.21.20.2" class="ltx_td ltx_align_center">0.964</td>
<td id="Sx2.T16.1.21.20.3" class="ltx_td ltx_align_center">0.926</td>
<td id="Sx2.T16.1.21.20.4" class="ltx_td ltx_nopad_r ltx_align_center">0.943</td>
</tr>
<tr id="Sx2.T16.1.22.21" class="ltx_tr">
<th id="Sx2.T16.1.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="10"><span id="Sx2.T16.1.22.21.1.1" class="ltx_text ltx_font_typewriter">PlayMusic</span></th>
<th id="Sx2.T16.1.22.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.22.21.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T16.1.22.21.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.22.21.4" class="ltx_td ltx_align_center ltx_border_t">0.983</td>
<td id="Sx2.T16.1.22.21.5" class="ltx_td ltx_align_center ltx_border_t">0.265</td>
<td id="Sx2.T16.1.22.21.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.624</td>
</tr>
<tr id="Sx2.T16.1.23.22" class="ltx_tr">
<th id="Sx2.T16.1.23.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.23.22.2" class="ltx_td ltx_align_center">0.816</td>
<td id="Sx2.T16.1.23.22.3" class="ltx_td ltx_align_center">0.737</td>
<td id="Sx2.T16.1.23.22.4" class="ltx_td ltx_nopad_r ltx_align_center">0.761</td>
</tr>
<tr id="Sx2.T16.1.24.23" class="ltx_tr">
<th id="Sx2.T16.1.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.24.23.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T16.1.24.23.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.24.23.3" class="ltx_td ltx_align_center ltx_border_t">0.677</td>
<td id="Sx2.T16.1.24.23.4" class="ltx_td ltx_align_center ltx_border_t">0.336</td>
<td id="Sx2.T16.1.24.23.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.580</td>
</tr>
<tr id="Sx2.T16.1.25.24" class="ltx_tr">
<th id="Sx2.T16.1.25.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.25.24.2" class="ltx_td ltx_align_center">0.773</td>
<td id="Sx2.T16.1.25.24.3" class="ltx_td ltx_align_center">0.518</td>
<td id="Sx2.T16.1.25.24.4" class="ltx_td ltx_nopad_r ltx_align_center">0.655</td>
</tr>
<tr id="Sx2.T16.1.26.25" class="ltx_tr">
<th id="Sx2.T16.1.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.26.25.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T16.1.26.25.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.26.25.3" class="ltx_td ltx_align_center ltx_border_t">0.549</td>
<td id="Sx2.T16.1.26.25.4" class="ltx_td ltx_align_center ltx_border_t">0.486</td>
<td id="Sx2.T16.1.26.25.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.593</td>
</tr>
<tr id="Sx2.T16.1.27.26" class="ltx_tr">
<th id="Sx2.T16.1.27.26.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.27.26.2" class="ltx_td ltx_align_center">0.744</td>
<td id="Sx2.T16.1.27.26.3" class="ltx_td ltx_align_center">0.701</td>
<td id="Sx2.T16.1.27.26.4" class="ltx_td ltx_nopad_r ltx_align_center">0.716</td>
</tr>
<tr id="Sx2.T16.1.28.27" class="ltx_tr">
<th id="Sx2.T16.1.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T16.1.28.27.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T16.1.28.27.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.28.27.3" class="ltx_td ltx_align_center ltx_border_t">0.603</td>
<td id="Sx2.T16.1.28.27.4" class="ltx_td ltx_align_center ltx_border_t">0.384</td>
<td id="Sx2.T16.1.28.27.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.464</td>
</tr>
<tr id="Sx2.T16.1.29.28" class="ltx_tr">
<th id="Sx2.T16.1.29.28.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T16.1.29.28.2" class="ltx_td ltx_align_center">0.690</td>
<td id="Sx2.T16.1.29.28.3" class="ltx_td ltx_align_center">0.518</td>
<td id="Sx2.T16.1.29.28.4" class="ltx_td ltx_nopad_r ltx_align_center">0.546</td>
</tr>
<tr id="Sx2.T16.1.30.29" class="ltx_tr">
<th id="Sx2.T16.1.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="Sx2.T16.1.30.29.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T16.1.30.29.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T16.1.30.29.3" class="ltx_td ltx_align_center ltx_border_t">0.546</td>
<td id="Sx2.T16.1.30.29.4" class="ltx_td ltx_align_center ltx_border_t">0.482</td>
<td id="Sx2.T16.1.30.29.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.577</td>
</tr>
<tr id="Sx2.T16.1.31.30" class="ltx_tr">
<th id="Sx2.T16.1.31.30.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2000</th>
<td id="Sx2.T16.1.31.30.2" class="ltx_td ltx_align_center ltx_border_bb">0.876</td>
<td id="Sx2.T16.1.31.30.3" class="ltx_td ltx_align_center ltx_border_bb">0.792</td>
<td id="Sx2.T16.1.31.30.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">0.823</td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 16: </span>Precision, recall and F1-score averaged on all slots in an in-house dataset, run in June 2017.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="Sx2.T17" class="ltx_table ltx_align_center">
<table id="Sx2.T17.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T17.1.1.1" class="ltx_tr">
<th id="Sx2.T17.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">intent</th>
<th id="Sx2.T17.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">NLU provider</th>
<th id="Sx2.T17.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">train size</th>
<th id="Sx2.T17.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">precision</th>
<th id="Sx2.T17.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">recall</th>
<th id="Sx2.T17.1.1.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt">F1-score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T17.1.2.1" class="ltx_tr">
<th id="Sx2.T17.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="10"><span id="Sx2.T17.1.2.1.1.1" class="ltx_text ltx_font_typewriter">AddToPlaylist</span></th>
<th id="Sx2.T17.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" rowspan="2"><span id="Sx2.T17.1.2.1.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T17.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">70</th>
<td id="Sx2.T17.1.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.759</td>
<td id="Sx2.T17.1.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.575</td>
<td id="Sx2.T17.1.2.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">0.771</td>
</tr>
<tr id="Sx2.T17.1.3.2" class="ltx_tr">
<th id="Sx2.T17.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.3.2.2" class="ltx_td ltx_align_center">0.971</td>
<td id="Sx2.T17.1.3.2.3" class="ltx_td ltx_align_center">0.938</td>
<td id="Sx2.T17.1.3.2.4" class="ltx_td ltx_nopad_r ltx_align_center">0.953</td>
</tr>
<tr id="Sx2.T17.1.4.3" class="ltx_tr">
<th id="Sx2.T17.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.4.3.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T17.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.647</td>
<td id="Sx2.T17.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.478</td>
<td id="Sx2.T17.1.4.3.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.662</td>
</tr>
<tr id="Sx2.T17.1.5.4" class="ltx_tr">
<th id="Sx2.T17.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.5.4.2" class="ltx_td ltx_align_center">0.862</td>
<td id="Sx2.T17.1.5.4.3" class="ltx_td ltx_align_center">0.761</td>
<td id="Sx2.T17.1.5.4.4" class="ltx_td ltx_nopad_r ltx_align_center">0.799</td>
</tr>
<tr id="Sx2.T17.1.6.5" class="ltx_tr">
<th id="Sx2.T17.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.6.5.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T17.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.830</td>
<td id="Sx2.T17.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.740</td>
<td id="Sx2.T17.1.6.5.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.766</td>
</tr>
<tr id="Sx2.T17.1.7.6" class="ltx_tr">
<th id="Sx2.T17.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.7.6.2" class="ltx_td ltx_align_center">0.943</td>
<td id="Sx2.T17.1.7.6.3" class="ltx_td ltx_align_center">0.951</td>
<td id="Sx2.T17.1.7.6.4" class="ltx_td ltx_nopad_r ltx_align_center">0.947</td>
</tr>
<tr id="Sx2.T17.1.8.7" class="ltx_tr">
<th id="Sx2.T17.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.8.7.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T17.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.8.7.3" class="ltx_td ltx_align_center ltx_border_t">0.718</td>
<td id="Sx2.T17.1.8.7.4" class="ltx_td ltx_align_center ltx_border_t">0.664</td>
<td id="Sx2.T17.1.8.7.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.667</td>
</tr>
<tr id="Sx2.T17.1.9.8" class="ltx_tr">
<th id="Sx2.T17.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.9.8.2" class="ltx_td ltx_align_center">0.746</td>
<td id="Sx2.T17.1.9.8.3" class="ltx_td ltx_align_center">0.704</td>
<td id="Sx2.T17.1.9.8.4" class="ltx_td ltx_nopad_r ltx_align_center">0.724</td>
</tr>
<tr id="Sx2.T17.1.10.9" class="ltx_tr">
<th id="Sx2.T17.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.10.9.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T17.1.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.10.9.3" class="ltx_td ltx_align_center ltx_border_t">0.787</td>
<td id="Sx2.T17.1.10.9.4" class="ltx_td ltx_align_center ltx_border_t">0.788</td>
<td id="Sx2.T17.1.10.9.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.785</td>
</tr>
<tr id="Sx2.T17.1.11.10" class="ltx_tr">
<th id="Sx2.T17.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.11.10.2" class="ltx_td ltx_align_center">0.914</td>
<td id="Sx2.T17.1.11.10.3" class="ltx_td ltx_align_center">0.891</td>
<td id="Sx2.T17.1.11.10.4" class="ltx_td ltx_nopad_r ltx_align_center">0.900</td>
</tr>
<tr id="Sx2.T17.1.12.11" class="ltx_tr">
<th id="Sx2.T17.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="10"><span id="Sx2.T17.1.12.11.1.1" class="ltx_text ltx_font_typewriter">RateBook</span></th>
<th id="Sx2.T17.1.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.12.11.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T17.1.12.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.12.11.4" class="ltx_td ltx_align_center ltx_border_t">0.993</td>
<td id="Sx2.T17.1.12.11.5" class="ltx_td ltx_align_center ltx_border_t">0.843</td>
<td id="Sx2.T17.1.12.11.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.887</td>
</tr>
<tr id="Sx2.T17.1.13.12" class="ltx_tr">
<th id="Sx2.T17.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.13.12.2" class="ltx_td ltx_align_center">1.000</td>
<td id="Sx2.T17.1.13.12.3" class="ltx_td ltx_align_center">0.997</td>
<td id="Sx2.T17.1.13.12.4" class="ltx_td ltx_nopad_r ltx_align_center">0.999</td>
</tr>
<tr id="Sx2.T17.1.14.13" class="ltx_tr">
<th id="Sx2.T17.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.14.13.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T17.1.14.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.14.13.3" class="ltx_td ltx_align_center ltx_border_t">0.987</td>
<td id="Sx2.T17.1.14.13.4" class="ltx_td ltx_align_center ltx_border_t">0.922</td>
<td id="Sx2.T17.1.14.13.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.933</td>
</tr>
<tr id="Sx2.T17.1.15.14" class="ltx_tr">
<th id="Sx2.T17.1.15.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.15.14.2" class="ltx_td ltx_align_center">0.990</td>
<td id="Sx2.T17.1.15.14.3" class="ltx_td ltx_align_center">0.950</td>
<td id="Sx2.T17.1.15.14.4" class="ltx_td ltx_nopad_r ltx_align_center">0.965</td>
</tr>
<tr id="Sx2.T17.1.16.15" class="ltx_tr">
<th id="Sx2.T17.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.16.15.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T17.1.16.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.16.15.3" class="ltx_td ltx_align_center ltx_border_t">0.868</td>
<td id="Sx2.T17.1.16.15.4" class="ltx_td ltx_align_center ltx_border_t">0.830</td>
<td id="Sx2.T17.1.16.15.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.840</td>
</tr>
<tr id="Sx2.T17.1.17.16" class="ltx_tr">
<th id="Sx2.T17.1.17.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.17.16.2" class="ltx_td ltx_align_center">0.976</td>
<td id="Sx2.T17.1.17.16.3" class="ltx_td ltx_align_center">0.983</td>
<td id="Sx2.T17.1.17.16.4" class="ltx_td ltx_nopad_r ltx_align_center">0.979</td>
</tr>
<tr id="Sx2.T17.1.18.17" class="ltx_tr">
<th id="Sx2.T17.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.18.17.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T17.1.18.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.18.17.3" class="ltx_td ltx_align_center ltx_border_t">0.873</td>
<td id="Sx2.T17.1.18.17.4" class="ltx_td ltx_align_center ltx_border_t">0.743</td>
<td id="Sx2.T17.1.18.17.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.798</td>
</tr>
<tr id="Sx2.T17.1.19.18" class="ltx_tr">
<th id="Sx2.T17.1.19.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.19.18.2" class="ltx_td ltx_align_center">0.867</td>
<td id="Sx2.T17.1.19.18.3" class="ltx_td ltx_align_center">0.733</td>
<td id="Sx2.T17.1.19.18.4" class="ltx_td ltx_nopad_r ltx_align_center">0.784</td>
</tr>
<tr id="Sx2.T17.1.20.19" class="ltx_tr">
<th id="Sx2.T17.1.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.20.19.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T17.1.20.19.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.20.19.3" class="ltx_td ltx_align_center ltx_border_t">0.966</td>
<td id="Sx2.T17.1.20.19.4" class="ltx_td ltx_align_center ltx_border_t">0.962</td>
<td id="Sx2.T17.1.20.19.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.964</td>
</tr>
<tr id="Sx2.T17.1.21.20" class="ltx_tr">
<th id="Sx2.T17.1.21.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.21.20.2" class="ltx_td ltx_align_center">0.997</td>
<td id="Sx2.T17.1.21.20.3" class="ltx_td ltx_align_center">0.997</td>
<td id="Sx2.T17.1.21.20.4" class="ltx_td ltx_nopad_r ltx_align_center">0.997</td>
</tr>
<tr id="Sx2.T17.1.22.21" class="ltx_tr">
<th id="Sx2.T17.1.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="10"><span id="Sx2.T17.1.22.21.1.1" class="ltx_text ltx_font_typewriter">SearchScreeningEvent</span></th>
<th id="Sx2.T17.1.22.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.22.21.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T17.1.22.21.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.22.21.4" class="ltx_td ltx_align_center ltx_border_t">0.995</td>
<td id="Sx2.T17.1.22.21.5" class="ltx_td ltx_align_center ltx_border_t">0.721</td>
<td id="Sx2.T17.1.22.21.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.826</td>
</tr>
<tr id="Sx2.T17.1.23.22" class="ltx_tr">
<th id="Sx2.T17.1.23.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.23.22.2" class="ltx_td ltx_align_center">1.000</td>
<td id="Sx2.T17.1.23.22.3" class="ltx_td ltx_align_center">0.961</td>
<td id="Sx2.T17.1.23.22.4" class="ltx_td ltx_nopad_r ltx_align_center">0.979</td>
</tr>
<tr id="Sx2.T17.1.24.23" class="ltx_tr">
<th id="Sx2.T17.1.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.24.23.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T17.1.24.23.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.24.23.3" class="ltx_td ltx_align_center ltx_border_t">0.903</td>
<td id="Sx2.T17.1.24.23.4" class="ltx_td ltx_align_center ltx_border_t">0.773</td>
<td id="Sx2.T17.1.24.23.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.809</td>
</tr>
<tr id="Sx2.T17.1.25.24" class="ltx_tr">
<th id="Sx2.T17.1.25.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.25.24.2" class="ltx_td ltx_align_center">0.849</td>
<td id="Sx2.T17.1.25.24.3" class="ltx_td ltx_align_center">0.849</td>
<td id="Sx2.T17.1.25.24.4" class="ltx_td ltx_nopad_r ltx_align_center">0.840</td>
</tr>
<tr id="Sx2.T17.1.26.25" class="ltx_tr">
<th id="Sx2.T17.1.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.26.25.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T17.1.26.25.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.26.25.3" class="ltx_td ltx_align_center ltx_border_t">0.859</td>
<td id="Sx2.T17.1.26.25.4" class="ltx_td ltx_align_center ltx_border_t">0.754</td>
<td id="Sx2.T17.1.26.25.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.800</td>
</tr>
<tr id="Sx2.T17.1.27.26" class="ltx_tr">
<th id="Sx2.T17.1.27.26.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.27.26.2" class="ltx_td ltx_align_center">0.974</td>
<td id="Sx2.T17.1.27.26.3" class="ltx_td ltx_align_center">0.959</td>
<td id="Sx2.T17.1.27.26.4" class="ltx_td ltx_nopad_r ltx_align_center">0.966</td>
</tr>
<tr id="Sx2.T17.1.28.27" class="ltx_tr">
<th id="Sx2.T17.1.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.28.27.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T17.1.28.27.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.28.27.3" class="ltx_td ltx_align_center ltx_border_t">0.710</td>
<td id="Sx2.T17.1.28.27.4" class="ltx_td ltx_align_center ltx_border_t">0.515</td>
<td id="Sx2.T17.1.28.27.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.560</td>
</tr>
<tr id="Sx2.T17.1.29.28" class="ltx_tr">
<th id="Sx2.T17.1.29.28.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.29.28.2" class="ltx_td ltx_align_center">0.695</td>
<td id="Sx2.T17.1.29.28.3" class="ltx_td ltx_align_center">0.541</td>
<td id="Sx2.T17.1.29.28.4" class="ltx_td ltx_nopad_r ltx_align_center">0.585</td>
</tr>
<tr id="Sx2.T17.1.30.29" class="ltx_tr">
<th id="Sx2.T17.1.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.30.29.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T17.1.30.29.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.30.29.3" class="ltx_td ltx_align_center ltx_border_t">0.881</td>
<td id="Sx2.T17.1.30.29.4" class="ltx_td ltx_align_center ltx_border_t">0.840</td>
<td id="Sx2.T17.1.30.29.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.858</td>
</tr>
<tr id="Sx2.T17.1.31.30" class="ltx_tr">
<th id="Sx2.T17.1.31.30.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.31.30.2" class="ltx_td ltx_align_center">0.965</td>
<td id="Sx2.T17.1.31.30.3" class="ltx_td ltx_align_center">0.971</td>
<td id="Sx2.T17.1.31.30.4" class="ltx_td ltx_nopad_r ltx_align_center">0.967</td>
</tr>
<tr id="Sx2.T17.1.32.31" class="ltx_tr">
<th id="Sx2.T17.1.32.31.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="10"><span id="Sx2.T17.1.32.31.1.1" class="ltx_text ltx_font_typewriter">BookRestaurant</span></th>
<th id="Sx2.T17.1.32.31.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.32.31.2.1" class="ltx_text">Luis</span></th>
<th id="Sx2.T17.1.32.31.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.32.31.4" class="ltx_td ltx_align_center ltx_border_t">0.859</td>
<td id="Sx2.T17.1.32.31.5" class="ltx_td ltx_align_center ltx_border_t">0.336</td>
<td id="Sx2.T17.1.32.31.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.473</td>
</tr>
<tr id="Sx2.T17.1.33.32" class="ltx_tr">
<th id="Sx2.T17.1.33.32.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.33.32.2" class="ltx_td ltx_align_center">0.906</td>
<td id="Sx2.T17.1.33.32.3" class="ltx_td ltx_align_center">0.891</td>
<td id="Sx2.T17.1.33.32.4" class="ltx_td ltx_nopad_r ltx_align_center">0.892</td>
</tr>
<tr id="Sx2.T17.1.34.33" class="ltx_tr">
<th id="Sx2.T17.1.34.33.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.34.33.1.1" class="ltx_text">Wit</span></th>
<th id="Sx2.T17.1.34.33.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.34.33.3" class="ltx_td ltx_align_center ltx_border_t">0.901</td>
<td id="Sx2.T17.1.34.33.4" class="ltx_td ltx_align_center ltx_border_t">0.436</td>
<td id="Sx2.T17.1.34.33.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.597</td>
</tr>
<tr id="Sx2.T17.1.35.34" class="ltx_tr">
<th id="Sx2.T17.1.35.34.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.35.34.2" class="ltx_td ltx_align_center">0.841</td>
<td id="Sx2.T17.1.35.34.3" class="ltx_td ltx_align_center">0.739</td>
<td id="Sx2.T17.1.35.34.4" class="ltx_td ltx_nopad_r ltx_align_center">0.736</td>
</tr>
<tr id="Sx2.T17.1.36.35" class="ltx_tr">
<th id="Sx2.T17.1.36.35.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.36.35.1.1" class="ltx_text">API.ai</span></th>
<th id="Sx2.T17.1.36.35.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.36.35.3" class="ltx_td ltx_align_center ltx_border_t">0.705</td>
<td id="Sx2.T17.1.36.35.4" class="ltx_td ltx_align_center ltx_border_t">0.548</td>
<td id="Sx2.T17.1.36.35.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.606</td>
</tr>
<tr id="Sx2.T17.1.37.36" class="ltx_tr">
<th id="Sx2.T17.1.37.36.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.37.36.2" class="ltx_td ltx_align_center">0.874</td>
<td id="Sx2.T17.1.37.36.3" class="ltx_td ltx_align_center">0.853</td>
<td id="Sx2.T17.1.37.36.4" class="ltx_td ltx_nopad_r ltx_align_center">0.834</td>
</tr>
<tr id="Sx2.T17.1.38.37" class="ltx_tr">
<th id="Sx2.T17.1.38.37.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="Sx2.T17.1.38.37.1.1" class="ltx_text">Alexa</span></th>
<th id="Sx2.T17.1.38.37.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.38.37.3" class="ltx_td ltx_align_center ltx_border_t">0.598</td>
<td id="Sx2.T17.1.38.37.4" class="ltx_td ltx_align_center ltx_border_t">0.364</td>
<td id="Sx2.T17.1.38.37.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.504</td>
</tr>
<tr id="Sx2.T17.1.39.38" class="ltx_tr">
<th id="Sx2.T17.1.39.38.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2000</th>
<td id="Sx2.T17.1.39.38.2" class="ltx_td ltx_align_center">0.760</td>
<td id="Sx2.T17.1.39.38.3" class="ltx_td ltx_align_center">0.575</td>
<td id="Sx2.T17.1.39.38.4" class="ltx_td ltx_nopad_r ltx_align_center">0.689</td>
</tr>
<tr id="Sx2.T17.1.40.39" class="ltx_tr">
<th id="Sx2.T17.1.40.39.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="Sx2.T17.1.40.39.1.1" class="ltx_text">Snips</span></th>
<th id="Sx2.T17.1.40.39.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">70</th>
<td id="Sx2.T17.1.40.39.3" class="ltx_td ltx_align_center ltx_border_t">0.727</td>
<td id="Sx2.T17.1.40.39.4" class="ltx_td ltx_align_center ltx_border_t">0.700</td>
<td id="Sx2.T17.1.40.39.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.719</td>
</tr>
<tr id="Sx2.T17.1.41.40" class="ltx_tr">
<th id="Sx2.T17.1.41.40.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2000</th>
<td id="Sx2.T17.1.41.40.2" class="ltx_td ltx_align_center ltx_border_bb">0.919</td>
<td id="Sx2.T17.1.41.40.3" class="ltx_td ltx_align_center ltx_border_bb">0.891</td>
<td id="Sx2.T17.1.41.40.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">0.903</td>
</tr>
</tbody>
</table>
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 17: </span>Precision, recall and F1-score averaged on all slots in an in-house dataset, run in June 2017.</figcaption>
</figure>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
Petar Aleksic, Mohammadreza Ghodsi, Assaf Michaely, Cyril Allauzen, Keith Hall,
Brian Roark, David Rybach, and Pedro Moreno.

</span>
<span class="ltx_bibblock">Bringing contextual information to google speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Sixteenth Annual Conference of the International Speech
Communication Association</span>, 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
Cyril Allauzen, Michael Riley, and Johan Schalkwyk.

</span>
<span class="ltx_bibblock">A generalized composition algorithm for weighted finite-state
transducers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Tenth Annual Conference of the International Speech
Communication Association</span>, 2009.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
Cyril Allauzen, Michael Riley, and Johan Schalkwyk.

</span>
<span class="ltx_bibblock">Filters for efficient composition of weighted finite-state
transducers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">International Conference on Implementation and Application of
Automata</span>, pages 28–38. Springer, 2010.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar
Mohri.

</span>
<span class="ltx_bibblock">Openfst: A general and efficient weighted finite-state transducer
library.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">International Conference on Implementation and Application of
Automata</span>, pages 11–23. Springer, 2007.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua
Bengio.

</span>
<span class="ltx_bibblock">End-to-end attention-based large vocabulary speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
International Conference on</span>, pages 4945–4949. IEEE, 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
Tobias Bocklet, Andreas Maier, Josef G Bauer, Felix Burkhardt, and Elmar Noth.

</span>
<span class="ltx_bibblock">Age and gender recognition for telephone applications based on gmm
supervectors and support vector machines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Acoustics, Speech and Signal Processing, 2008. ICASSP 2008.
IEEE International Conference on</span>, pages 1605–1608. IEEE, 2008.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
Tom Bocklisch, Joey Faulker, Nick Pawlowski, and Alan Nichol.

</span>
<span class="ltx_bibblock">Rasa: Open source language understanding and dialogue management.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1712.05181</span>, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
Daniel Braun, Adrian Hernandez-Mendez, Florian Matthes, and Manfred Langen.

</span>
<span class="ltx_bibblock">Evaluating natural language understanding services for conversational
question answering systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the 18th Annual SIGdial Meeting on Discourse
and Dialogue</span>, pages 174–185, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and
Jenifer C Lai.

</span>
<span class="ltx_bibblock">Class-based n-gram models of natural language.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Computational linguistics</span>, 18(4):467–479, 1992.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
Ann Cavoukian.

</span>
<span class="ltx_bibblock">Privacy by design.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Take the challenge. Information and privacy commissioner of
Ontario, Canada</span>, 2009.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
Ciprian Chelba, Dan Bikel, Maria Shugrina, Patrick Nguyen, and Shankar Kumar.

</span>
<span class="ltx_bibblock">Large scale language modeling in automatic speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1210.8440</span>, 2012.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
Ciprian Chelba, Johan Schalkwyk, Thorsten Brants, Vida Ha, Boulos Harb, Will
Neveitt, Carolina Parada, and Peng Xu.

</span>
<span class="ltx_bibblock">Query language modeling for voice search.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Spoken Language Technology Workshop (SLT), 2010 IEEE</span>, pages
127–132. IEEE, 2010.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
Facebook.

</span>
<span class="ltx_bibblock">Language, engine, and tooling for expressing, testing, and evaluating
composable language rules on input strings.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">GitHub repository</span>,
<a target="_blank" href="https://github.com/facebook/duckling" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebook/duckling</a>, 2017.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Speech recognition with deep recurrent neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Acoustics, speech and signal processing (icassp), 2013 ieee
international conference on</span>, pages 6645–6649. IEEE, 2013.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
Dilek Hakkani-Tür, Frédéric Béchet, Giuseppe Riccardi, and
Gokhan Tur.

</span>
<span class="ltx_bibblock">Beyond asr 1-best: Using word confusion networks in spoken language
understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Computer Speech &amp; Language</span>, 20(4):495–514, 2006.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
Melinda Hamill, Vicky Young, Jennifer Boger, and Alex Mihailidis.

</span>
<span class="ltx_bibblock">Development of an automated speech recognition interface for personal
emergency response systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Journal of NeuroEngineering and Rehabilitation</span>, 6(1):26, 2009.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep
Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath,
et al.

</span>
<span class="ltx_bibblock">Deep neural networks for acoustic modeling in speech recognition: The
shared views of four research groups.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Magazine</span>, 29(6):82–97, 2012.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
Axel Horndasch, Caroline Kaufhold, and Elmar Nöth.

</span>
<span class="ltx_bibblock">How to add word classes to the kaldi speech recognition toolkit.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">International Conference on Text, Speech, and Dialogue</span>,
pages 486–494. Springer, 2016.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
Panagiotis G Ipeirotis, Foster Provost, Victor S Sheng, and Jing Wang.

</span>
<span class="ltx_bibblock">Repeated labeling using multiple noisy labelers.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Data Mining and Knowledge Discovery</span>, 28(2):402–441, 2014.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
Hui Jiang.

</span>
<span class="ltx_bibblock">Confidence measures for speech recognition: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Speech communication</span>, 45(4):455–470, 2005.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
Slava Katz.

</span>
<span class="ltx_bibblock">Estimation of probabilities from sparse data for the language model
component of a speech recognizer.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">IEEE transactions on acoustics, speech, and signal processing</span>,
35(3):400–401, 1987.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
Chanwoo Kim, Ananya Misra, Kean Chin, Thad Hughes, Arun Narayanan, Tara
Sainath, and Michiel Bacchiani.

</span>
<span class="ltx_bibblock">Generation of large-scale simulated utterances in virtual rooms to
train deep-neural networks for far-field speech recognition in google home.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Proc. INTERSPEECH. ISCA</span>, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
Anjishnu Kumar, Arpit Gupta, Julian Chan, Sam Tucker, Bjorn Hoffmeister, and
Markus Dreyer.

</span>
<span class="ltx_bibblock">Just ask: Building an architecture for extensible self-service spoken
language understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1711.00549</span>, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
John Lafferty, Andrew McCallum, and Fernando CN Pereira.

</span>
<span class="ltx_bibblock">Conditional random fields: Probabilistic models for segmenting and
labeling sequence data.

</span>
<span class="ltx_bibblock">2001.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
Marc Langheinrich.

</span>
<span class="ltx_bibblock">Privacy by design—principles of privacy-aware ubiquitous systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">International conference on Ubiquitous Computing</span>, pages
273–291. Springer, 2001.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
Benjamin Lecouteux, Michel Vacher, and François Portet.

</span>
<span class="ltx_bibblock">Distant speech recognition in a smart home: Comparison of several
multisource asrs in realistic conditions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Interspeech 2011 Florence</span>, pages 2273–2276, 2011.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(27)</span>
<span class="ltx_bibblock">
Percy Liang.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Semi-supervised learning for natural language</span>.

</span>
<span class="ltx_bibblock">PhD thesis, Massachusetts Institute of Technology, 2005.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(28)</span>
<span class="ltx_bibblock">
Lidia Mangu, Eric Brill, and Andreas Stolcke.

</span>
<span class="ltx_bibblock">Finding consensus in speech recognition: word error minimization and
other applications of confusion networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Computer Speech &amp; Language</span>, 14(4):373–400, 2000.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(29)</span>
<span class="ltx_bibblock">
Nicholas D Matsakis and Felix S Klock II.

</span>
<span class="ltx_bibblock">The rust language.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">ACM SIGAda Ada Letters</span>, volume 34, pages 103–104. ACM,
2014.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(30)</span>
<span class="ltx_bibblock">
Grégoire Mesnil, Yann Dauphin, Kaisheng Yao, Yoshua Bengio, Li Deng, Dilek
Hakkani-Tur, Xiaodong He, Larry Heck, Gokhan Tur, Dong Yu, et al.

</span>
<span class="ltx_bibblock">Using recurrent neural networks for slot filling in spoken language
understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language
Processing</span>, 23(3):530–539, 2015.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(31)</span>
<span class="ltx_bibblock">
Grégoire Mesnil, Xiaodong He, Li Deng, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Investigation of recurrent-neural-network architectures and learning
methods for spoken language understanding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3771–3775, 2013.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(32)</span>
<span class="ltx_bibblock">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1301.3781</span>, 2013.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(33)</span>
<span class="ltx_bibblock">
Abdel-rahman Mohamed, George E Dahl, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Acoustic modeling using deep belief networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</span>,
20(1):14–22, 2012.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
Mehryar Mohri, Fernando Pereira, and Michael Riley.

</span>
<span class="ltx_bibblock">Weighted finite-state transducers in speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Departmental Papers (CIS)</span>, page 11, 2001.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(35)</span>
<span class="ltx_bibblock">
Mehryar Mohri, Fernando Pereira, and Michael Riley.

</span>
<span class="ltx_bibblock">Speech recognition with weighted finite-state transducers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Springer Handbook of Speech Processing</span>, pages 559–584.
Springer, 2008.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(36)</span>
<span class="ltx_bibblock">
Josef Robert Novak, Nobuaki Minematsu, and Keikichi Hirose.

</span>
<span class="ltx_bibblock">Phonetisaurus: Exploring grapheme-to-phoneme conversion with joint
n-gram models in the wfst framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Natural Language Engineering</span>, 22(6):907–938, 2016.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(37)</span>
<span class="ltx_bibblock">
Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider,
and Noah A Smith.

</span>
<span class="ltx_bibblock">Improved part-of-speech tagging for online conversational text with
word clusters.

</span>
<span class="ltx_bibblock">Association for Computational Linguistics, 2013.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE
International Conference on</span>, pages 5206–5210. IEEE, 2015.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(39)</span>
<span class="ltx_bibblock">
Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">A time delay neural network architecture for efficient modeling of
long temporal contexts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Sixteenth Annual Conference of the International Speech
Communication Association</span>, 2015.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(40)</span>
<span class="ltx_bibblock">
Vijayaditya Peddinti, Yiming Wang, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Low latency acoustic modeling using temporal convolution and lstms.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Letters</span>, 25(3):373–377, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(41)</span>
<span class="ltx_bibblock">
Bastian Pfleging, Stefan Schneegass, and Albrecht Schmidt.

</span>
<span class="ltx_bibblock">Multimodal interaction in the car: combining speech and gestures on
the steering wheel.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the 4th International Conference on Automotive
User Interfaces and Interactive Vehicular Applications</span>, pages 155–162. ACM,
2012.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(42)</span>
<span class="ltx_bibblock">
Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek,
Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz,
et al.

</span>
<span class="ltx_bibblock">The kaldi speech recognition toolkit.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">IEEE 2011 workshop on automatic speech recognition and
understanding</span>, number EPFL-CONF-192584. IEEE Signal Processing Society,
2011.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(43)</span>
<span class="ltx_bibblock">
Daniel Povey, Vijayaditya Peddinti, Daniel Galvez, Pegah Ghahremani, Vimal
Manohar, Xingyu Na, Yiming Wang, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Purely sequence-trained neural networks for asr based on lattice-free
mmi.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 2751–2755, 2016.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
Rohit Prabhavalkar, Ouais Alsharif, Antoine Bruguier, and Lan McGraw.

</span>
<span class="ltx_bibblock">On the compression of recurrent neural networks with an application
to lvcsr acoustic modeling for embedded speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
International Conference on</span>, pages 5970–5974. IEEE, 2016.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(45)</span>
<span class="ltx_bibblock">
Christian Raymond and Giuseppe Riccardi.

</span>
<span class="ltx_bibblock">Generative and discriminative algorithms for spoken language
understanding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Eighth Annual Conference of the International Speech
Communication Association</span>, 2007.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(46)</span>
<span class="ltx_bibblock">
Marta Sabou, Kalina Bontcheva, and Arno Scharl.

</span>
<span class="ltx_bibblock">Crowdsourcing research opportunities: lessons from natural language
processing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Proceedings of the 12th International Conference on Knowledge
Management and Knowledge Technologies</span>, page 17. ACM, 2012.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(47)</span>
<span class="ltx_bibblock">
Johan Schalkwyk, Doug Beeferman, Françoise Beaufays, Bill Byrne, Ciprian
Chelba, Mike Cohen, Maryam Kamvar, and Brian Strope.

</span>
<span class="ltx_bibblock">“your word is my command”: Google search by voice: a case study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Advances in speech recognition</span>, pages 61–90. Springer,
2010.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(48)</span>
<span class="ltx_bibblock">
Snips Team.

</span>
<span class="ltx_bibblock">Rustling, Rust implementation of Duckling.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">GitHub repository</span>,
<a target="_blank" href="https://github.com/snipsco/rustling" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/rustling</a>, 2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(49)</span>
<span class="ltx_bibblock">
Snips Team.

</span>
<span class="ltx_bibblock">Snips NLU rust, Snips NLU Rust implementation.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">GitHub repository</span>,
<a target="_blank" href="https://github.com/snipsco/snips-nlu-rs" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/snips-nlu-rs</a>, 2018.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(50)</span>
<span class="ltx_bibblock">
Snips Team.

</span>
<span class="ltx_bibblock">Snips NLU, Snips Python library to extract meaning from text.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">GitHub repository</span>,
<a target="_blank" href="https://github.com/snipsco/snips-nlu" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/snipsco/snips-nlu</a>, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(51)</span>
<span class="ltx_bibblock">
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Y Ng.

</span>
<span class="ltx_bibblock">Cheap and fast—but is it good?: evaluating non-expert annotations
for natural language tasks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Proceedings of the conference on empirical methods in natural
language processing</span>, pages 254–263. Association for Computational
Linguistics, 2008.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(52)</span>
<span class="ltx_bibblock">
Maksim Tkachenko and Andrey Simanovsky.

</span>
<span class="ltx_bibblock">Named entity recognition: Exploring features.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">KONVENS</span>, pages 118–127, 2012.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(53)</span>
<span class="ltx_bibblock">
Gökhan Tür, Anoop Deoras, and Dilek Hakkani-Tür.

</span>
<span class="ltx_bibblock">Semantic parsing using word confusion networks with conditional
random fields.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">INTERSPEECH</span>, pages 2579–2583, 2013.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(54)</span>
<span class="ltx_bibblock">
Ye-Yi Wang and Alex Acero.

</span>
<span class="ltx_bibblock">Discriminative models for spoken language understanding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Ninth International Conference on Spoken Language
Processing</span>, 2006.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(55)</span>
<span class="ltx_bibblock">
Yiming Wang, Vijayaditya Peddinti, Hainan Xu, Xiaohui Zhang, Daniel Povey, and
Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Backstitch: Counteracting finite-sample bias via negative steps.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">NIPS (submitted)</span>, 2017.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(56)</span>
<span class="ltx_bibblock">
Wayne Xiong, Jasha Droppo, Xuedong Huang, Frank Seide, Mike Seltzer, Andreas
Stolcke, Dong Yu, and Geoffrey Zweig.

</span>
<span class="ltx_bibblock">Achieving human parity in conversational speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1610.05256</span>, 2016.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(57)</span>
<span class="ltx_bibblock">
Haihua Xu, Daniel Povey, Lidia Mangu, and Jie Zhu.

</span>
<span class="ltx_bibblock">Minimum bayes risk decoding and system combination based on a
recursion for edit distance.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Computer Speech &amp; Language</span>, 25(4):802–828, 2011.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(58)</span>
<span class="ltx_bibblock">
Roman V Yampolskiy and Venu Govindaraju.

</span>
<span class="ltx_bibblock">Behavioural biometrics: a survey and classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">International Journal of Biometrics</span>, 1(1):81–113, 2008.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(59)</span>
<span class="ltx_bibblock">
Dong Yu, Jinyu Li, and Li Deng.

</span>
<span class="ltx_bibblock">Calibration of confidence measures in speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</span>,
19(8):2461–2473, 2011.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1805.10189" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1805.10190" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1805.10190">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1805.10190" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1805.10191" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar 15 23:30:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
