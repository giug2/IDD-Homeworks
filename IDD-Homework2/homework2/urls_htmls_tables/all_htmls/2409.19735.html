<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Scrambled text: training Language Models to correct OCR errors using synthetic data</title>
<!--Generated on Sun Sep 29 15:16:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on September 2024.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.19735v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S1" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S2" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS1" title="In 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS2" title="In 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>ScrambledText: Creating the Markov Corruption Process</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS2.SSS1" title="In 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>The Markov Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS2.SSS2" title="In 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Process Implementation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS2.SSS3" title="In 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Application of the model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS3" title="In 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS4" title="In 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>The Llama Model and training parameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS5" title="In 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Experimental setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS5.SSS1" title="In 3.5 Experimental setup ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.1 </span>Corruption level, and corruption distribution</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS5.SSS2" title="In 3.5 Experimental setup ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.2 </span>Text length vs number of observations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS5.SSS3" title="In 3.5 Experimental setup ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.3 </span>Between dataset comparison</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.SS1" title="In 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Tokens per observation and total tokens in dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.SS2" title="In 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Comparing models trained on different datasets</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S5" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S6" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Recommendations for training CLOCR-C models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S7" title="In Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\addbibresource</span>
<p class="ltx_p" id="p1.2">citations.bib</p>
</div>
<h1 class="ltx_title ltx_title_document">Scrambled text: training Language Models to correct OCR errors using synthetic data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jonathan Bourne
</span></span>
</div>
<div class="ltx_dates">(September 2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">OCR errors are common in digitised historical archives significantly affecting their usability and value.
Generative Language Models (LMs) have shown potential for correcting these errors using the context provided by the corrupted text and the broader socio-cultural context, a process called Context Leveraging OCR Correction (CLOCR-C). However, getting sufficient training data for fine-tuning such models can prove challenging. This paper shows that fine-tuning a language model on synthetic data using an LM and using a character level Markov corruption process can significantly improve the ability to correct OCR errors. Models trained on synthetic data reduce the character error rate by 55% and word error rate by 32% over the base LM and outperform models trained on real data. Key findings include; training on under-corrupted data is better than over-corrupted data; non-uniform character level corruption is better than uniform corruption; More tokens-per-observation outperforms more observations for a fixed token budget. The outputs for this paper are a set of 8 heuristics for training effective CLOCR-C models, a dataset of 11,000 synthetic 19th century newspaper articles and <code class="ltx_verbatim ltx_font_typewriter" id="id1.id1.1">scrambledtext</code> a python library for creating synthetic corrupted data.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Optical Character Recognition (OCR) is a valuable tool in the historical archive digitisation process. OCR allows the text of archived material to be digitised at character level, allowing archival documents to be searched and manipulated like more modern natively digital documents. However, performing OCR on archival documents is not without errors <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">smith_research_2018</span>]</cite>. These errors can be particularly acute in archival media such as newspapers and periodicals due to their complex layouts <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chiron_impact_2017</span>]</cite>. Such errors impact the value of the digitisation process as the ability to search for individuals or specific places and events can degrade dramatically <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">traub_impact_2015</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chiron_impact_2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hill_quantifying_2019</span>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">As a result of the issues with the OCR processes, post-OCR correction has become an area of active research <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chiron_icdar2017_2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen_survey_2021</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">neudecker_survey_2021</span>]</cite>. More recently, with advances in machine learning and the development of the transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vaswani_attention_2017</span>]</cite>, the use of transformer-based language models for post-OCR correction has grown in popularity <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">thomas_leveraging_nodate</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">boros_post-correction_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>. Transformers offer additional benefits over more traditional approaches to OCR correction <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen_survey_2021</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">neudecker_survey_2021</span>]</cite>, in that they can be prompted to have a base context for the text (‘This is a receipt’, ‘This is a poem’), as well as being able to use the Transformers facility to handle long-range textual dependencies to provide context on corrupted characters and words. Such an approach to OCR correction can be called Context Leveraging OCR Correction (CLOCR-C). Pre-trained language models have been shown to reduce errors by over 60% <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>. However, the cost of using them can be prohibitively high for large projects. An alternative approach is to fine-tune smaller open-source models <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">thomas_leveraging_nodate</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dereza_have_2024</span>]</cite> specifically on the task of CLOCR-C.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Fine-tuning is a process of performing additional training on a pre-trained LM to make it better at a specific task <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao_lora_2024</span>]</cite>. However, the process can be expensive and time-consuming. Recent research suggests that much of the functionality of transformer-based LMs exists on a relatively small sub-space of the LM parameters and that by fine-tuning a small subset of parameters on a specific task, the model can experience significant improvements in that task using much less compute. These processes are collectively known as Parameter Efficient Fine Tuning (PEFT)<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">fu_effectiveness_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">han_parameter-efficient_2024</span>]</cite>. One of the most popular approaches to PEFT is Low-Rank Adaptors (LoRA) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao_lora_2024</span>]</cite>, which, when combined with other recent advances, such as floating point quantization <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dettmers_llmint8_2022</span>]</cite>, substantially reduces the cost of fine-tuning, due to reduced GPU use, whilst also providing regularization to prevent overfitting <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">biderman_lora_2024</span>]</cite>. For example, Quantized LoRa Llama2 7B required RAM drops from 38.7 to 7.5, and token throughput increases 20% relative to the base Llama2 model <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng_llamafactory_2024</span>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The Fine-tuning process is dependent on having data in sufficient quantity and quality to be able to improve the performance of the model, whilst there are several appropriate datasets available <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">evershed_correcting_2014</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chiron_icdar2017_2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rigaud_icdar_2019</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jiang_prototype_2022</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">booth_bln600_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>, this does not mean they have the necessary qualities to act as training material. Recent research has highlighted that noisy or poor-quality data can impact the performance of trained LMs <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bagla_noisy_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li_can_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li_textbugger_2019</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang_noisyag-news_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">naplava_understanding_2021</span>]</cite>, such noise is a problem when it comes to creating ground truth datasets for OCR correction (as noted by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">evershed_correcting_2014</span>]</cite>). One way to avoid this problem is using expert transcribed datasets <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">evershed_correcting_2014</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">booth_bln600_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>. However, transcription is time-consuming and or costly, and using previously transcribed data may not have the correct error distribution or sufficient corruption <span class="ltx_ERROR undefined" id="S1.p4.1.1">\textcite</span>rychalska_models_2019 to be of value.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">An alternative to transcribed data is to use synthetic data created using a noising or corruption process <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">edunov_understanding_2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rychalska_models_2019</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">naplava_understanding_2021</span>]</cite>, as previous work has shown that OCR errors have identifiable patterns <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen_deep_2019</span>]</cite>.
Recent advances in training LMs suggests that synthetic data can play a crucial role in training and fine-tuning LM models due to the guaranteed high-quality nature of the data <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gunasekar_textbooks_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li_textbooks_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tan_15-pints_2024</span>]</cite>. However, synthetic data needs to be applied carefully, as there is evidence that when LMs are trained on recursively generated synthetic data, they can suffer model collapse and produce gibberish <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shumailov_ai_2024</span>]</cite>. Whilst synthetic data has been shown to be valuable in various LM applications, little is known about how such an approach would affect the final performance of LMs in CLOCR-C.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">This paper contributes to the literature by demonstrating that synthetically generated text, corrupted using a learned function can improve the performance of LMs to correct OCR errors. Specifically, it answers the following questions.</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Can synthetic corrupted OCR data be used to train a Langauge model such that it is better able to perform CLOCR-C?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">How does the level of corruption of the synthetic data impact the performance of the fine-tuned language model?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">What are a set of basic guidelines for practitioners using synthetic data for fine-tuning a CLOCR-C LM?</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The rest of the paper is as follows, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S2" title="2 Data ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">2</span></a> introduces the dataset used in this paper, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3" title="3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a> describes the methods for creating the synthetic text and the experiments used to measure its effectiveness as training data, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4" title="4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">4</span></a> reports the results of the experiments, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S5" title="5 Discussion ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">5</span></a> is the discussion interpreting the findings and their place relative to previous literature, Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S6" title="6 Recommendations for training CLOCR-C models ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">6</span></a> provides a list of heuristics for training CLOCR-C models, finally Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S7" title="7 Conclusions ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">7</span></a> provides the conclusions and considers future work</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Data</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">When fine-tuning LMs for OCR correction, data selection must be done carefully. This is because much open-source data has already been used to train the most high-performing LMs, which can lead to the memorisation of the text and apparently exceptional recovery rates due to data leakage. As a result, much potential training data is ruled out, such as <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jiang_prototype_2022</span>]</cite> as it is based on data from the Gutenberg project <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hart_project_1971</span>]</cite>, which is used in training many LMs. As such, this paper will use 4 OCR correction datasets transcribed from archive newspapers, which it is believed have not been used as training data on language models. Using archival newspaper data is also interesting due to the high levels of corruption that can tend to exhibit and the fact that the data will all be from a similar distribution regarding style and structure. The datasets used are described below.</p>
</div>
<div class="ltx_para" id="S2.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">NCSE: This is a 40,000-word corpus <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite> made up of 91 articles from the original Nineteenth-Century Serials Edition.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">SMH: These are articles from the Sydney Morning Herald containing 52,000 words and 159 articles created by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">evershed_overproof_2014</span>]</cite> using the TROVE dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">holley_many_2009</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">CA: Chronicling America, an 18,000-word dataset across 46 articles by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">evershed_overproof_2014</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1">BLN600: A collection of 600 articles from 19th century English newspapers from <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">booth_bln600_2024</span>]</cite>, this paper will also use the sequence level dataset created by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">thomas_leveraging_nodate</span>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Of these 4 datasets, the NCSE dataset will be used as the test dataset as it has the highest overall error rate and is an excerpt from a much larger dataset that would benefit from CLOCR-C. The other three datasets will be used to train the corruption function.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The method section is broken into 5 parts. The first section describes the synthetic data generation process, followed by the evaluation and metrics used in the paper. Once the evaluation metrics are described, the Markov process used to corrupt the data is defined. Then, the Llama LM architecture and training parameters are introduced and explained. Finally, the experiments are described.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">For clarity, Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.F1" title="Figure 1 ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a> shows the flow diagram of the project. The flow diagram has three types: Data, such as the line-aligned texts; Processes, such as corrupting the text; and Computational tools, such as <code class="ltx_verbatim ltx_font_typewriter" id="S3.p2.1.1">scrambledtext</code>. Each element of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.F1" title="Figure 1 ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a> will be described in detail in the rest of the method.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<p class="ltx_p ltx_align_center" id="S3.F1.1"><span class="ltx_text ltx_font_bold" id="S3.F1.1.1">Process Flow Diagram</span>
<svg class="ltx_picture" height="277.8" id="S3.F1.1.pic1" overflow="visible" version="1.1" width="482.09"><g fill="#000000" stroke="#000000" transform="translate(0,277.8) matrix(1 0 0 -1 0 0) translate(241.04,0) translate(0,257.84)"><g stroke-width="0.4pt"><g fill="#B3FFB3"><path d="M -53.82 -19.69 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -49.21 -4.84)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.1.1.1.1.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.1.1.1.1.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.1.1.1.1.1.1.2">Scrambled text</span>
</span></foreignobject></g><g fill="#D0FFF6"><path d="M -240.77 -19.69 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -236.16 2.87)"><foreignobject height="25.12" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.2.2.2.2.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.2.2.2.2.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.2.2.2.2.1.1.2">OCR aligned text</span>
</span></foreignobject></g><g fill="#D0FFF6"><path d="M 133.12 -19.69 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.73 2.87)"><foreignobject height="25.12" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.3.3.3.3.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.3.3.3.3.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.3.3.3.3.1.1.2">Synthetic text parameters</span>
</span></foreignobject></g><g fill="#FFDFDF"><path d="M 133.12 -98.98 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.73 -76.06)"><foreignobject height="25.85" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.4.4.4.4.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.4.4.4.4.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.4.4.4.4.1.1.2">Generate synthetic texts</span>
</span></foreignobject></g><g fill="#FFDFDF"><path d="M 133.12 -178.27 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.73 -163.43)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.5.5.5.5.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.5.5.5.5.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.5.5.5.5.1.1.2">Subset texts</span>
</span></foreignobject></g><g fill="#FFDFDF"><path d="M -240.77 -98.98 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -236.16 -77.7)"><foreignobject height="22.56" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.6.6.6.6.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.6.6.6.6.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.6.6.6.6.1.1.2">Get prob distribs</span>
</span></foreignobject></g><g fill="#FFDFDF"><path d="M -53.82 -98.98 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -49.21 -82.91)"><foreignobject height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.7.7.7.7.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.7.7.7.7.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.7.7.7.7.1.1.2">Corrupt text</span>
</span></foreignobject></g><g fill="#D0FFF6"><path d="M -240.77 -178.27 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -236.16 -162.2)"><foreignobject height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.8.8.8.8.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.8.8.8.8.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.8.8.8.8.1.1.2">Target CER</span>
</span></foreignobject></g><g fill="#B3FFB3"><path d="M -53.82 -178.27 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -49.21 -155.17)"><foreignobject height="26.21" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.9.9.9.9.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.9.9.9.9.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.9.9.9.9.1.1.2">Fine-tuned model</span>
</span></foreignobject></g><g fill="#B3FFB3"><path d="M 133.12 -257.57 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.73 -242.72)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.10.10.10.10.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.10.10.10.10.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.10.10.10.10.1.1.2">Base LLaMA</span>
</span></foreignobject></g><g fill="#FFDFDF"><path d="M -53.82 -257.57 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -49.21 -236.29)"><foreignobject height="22.56" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.11.11.11.11.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.11.11.11.11.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.11.11.11.11.1.1.2">Evaluate performance</span>
</span></foreignobject></g><g fill="#D0FFF6"><path d="M -240.77 -257.57 h 107.65 v 39.37 h -107.65 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -236.16 -242.72)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F1.1.pic1.12.12.12.12.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F1.1.pic1.12.12.12.12.1.1.1"></span>
<span class="ltx_p" id="S3.F1.1.pic1.12.12.12.12.1.1.2">Test data</span>
</span></foreignobject></g></g><g stroke-width="0.8pt"><path d="M -47.06 -19.96 L -139 -58.95" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(-0.92065 -0.39038 0.39038 -0.92065 -139 -58.95)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 0 -19.96 L 0 -58.35" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -58.35)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M -186.94 -19.96 L -186.94 -58.35" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 -186.94 -58.35)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 186.94 -19.96 L 186.94 -58.35" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 186.94 -58.35)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 186.94 -99.26 L 186.94 -137.64" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 186.94 -137.64)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M -132.84 -79.29 L -55.08 -79.29" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(1.0 0.0 0.0 1.0 -55.08 -79.29)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 139.88 -138.63 L 47.94 -99.64" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(-0.92065 0.39038 -0.39038 -0.92065 47.94 -99.64)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M -139.88 -138.63 L -47.94 -99.64" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.92065 0.39038 -0.39038 0.92065 -47.94 -99.64)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 132.84 -158.59 L 55.08 -158.59" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(-1.0 0.0 0.0 -1.0 55.08 -158.59)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 0 -99.26 L 0 -137.64" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -137.64)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 139.88 -217.92 L 47.94 -178.93" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(-0.92065 0.39038 -0.39038 -0.92065 47.94 -178.93)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M 0 -178.55 L 0 -216.94" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -216.94)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g><g stroke-width="0.8pt"><path d="M -132.84 -237.88 L -55.08 -237.88" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(1.0 0.0 0.0 1.0 -55.08 -237.88)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>How the elements of the project hang together can be visualised as above. In this diagram the data is shown in blue, the processes in pink and the computational tools such as scrambledtext and Llama as green</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Evaluation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">This paper evaluates the performance of the LMs using the Character Error Rate (CER) and the Word Error Rate, which are calculated using</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textrm{ER}=\frac{S+D+I}{S+D+C}" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mtext id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2a.cmml">ER</mtext><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mfrac id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml">S</mi><mo id="S3.E1.m1.1.1.3.2.1" xref="S3.E1.m1.1.1.3.2.1.cmml">+</mo><mi id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml">D</mi><mo id="S3.E1.m1.1.1.3.2.1a" xref="S3.E1.m1.1.1.3.2.1.cmml">+</mo><mi id="S3.E1.m1.1.1.3.2.4" xref="S3.E1.m1.1.1.3.2.4.cmml">I</mi></mrow><mrow id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">S</mi><mo id="S3.E1.m1.1.1.3.3.1" xref="S3.E1.m1.1.1.3.3.1.cmml">+</mo><mi id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml">D</mi><mo id="S3.E1.m1.1.1.3.3.1a" xref="S3.E1.m1.1.1.3.3.1.cmml">+</mo><mi id="S3.E1.m1.1.1.3.3.4" xref="S3.E1.m1.1.1.3.3.4.cmml">C</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><ci id="S3.E1.m1.1.1.2a.cmml" xref="S3.E1.m1.1.1.2"><mtext id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">ER</mtext></ci><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><divide id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3"></divide><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><plus id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2.1"></plus><ci id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2">𝑆</ci><ci id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3">𝐷</ci><ci id="S3.E1.m1.1.1.3.2.4.cmml" xref="S3.E1.m1.1.1.3.2.4">𝐼</ci></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><plus id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.1"></plus><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">𝑆</ci><ci id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3">𝐷</ci><ci id="S3.E1.m1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.3.3.4">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\textrm{ER}=\frac{S+D+I}{S+D+C}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">ER = divide start_ARG italic_S + italic_D + italic_I end_ARG start_ARG italic_S + italic_D + italic_C end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Where S is the number of substitutions, D is the number of deletions, I is the number of insertions, and C is the correct total number, the denominator is equivalent to the number of characters in the ground truth reference document. The modifications refer to characters or words depending on whether the metric is CER or WER.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Having defined the metrics used to measure corruption, we will next introduce the corruption function itself.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>ScrambledText: Creating the Markov Corruption Process</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The corruption generation function aims to simulate the character corruption type found in OCR documents. Previous research has produced high-quality corruption processes <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rychalska_models_2019</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">naplava_understanding_2021</span>]</cite>; however, these focus on typographical or human errors, not OCR-style errors. Other similar approaches, such as back-translation <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ott_fairseq_2019</span>]</cite>, cannot control the amount of error. Only Genelog <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gupte_lights_2021</span>]</cite> is explicitly designed to re-create OCR errors, which it does by creating a synthetically corrupted PDF then performing OCR on it. Whilst very thorough, this approach is computationally expensive and technically tricky due to automatically generating appropriate layouts, making it impractical for low-resource projects.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">This section is divided into three subsections, the first describes and defines the Markov Model, the second discusses the implementation of the model in <code class="ltx_verbatim ltx_font_typewriter" id="S3.SS2.p2.1.1">ScrambledText</code>, and The third discusses the application of the model in this project and provides example text.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>The Markov Model</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.3">Due to the issues with the existing methods, this paper develops ScrambledText, a simple, fast corruption process based on a Markov model specifically designed to simulate OCR corruption errors using a straightforward training process and can output text with an arbitrary amount of corruption. The Markov Model is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.F2" title="Figure 2 ‣ 3.2.1 The Markov Model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">2</span></a>; the model takes a single correct character <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.1"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mi id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><ci id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.1d">italic_x</annotation></semantics></math> and outputs a sequence of characters <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.2.m2.1"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mi id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><ci id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.2.m2.1d">italic_y</annotation></semantics></math> with a length greater than or equal to 0. Once in the model, each character has a learned conditional probability distribution of passing through the model unaltered, being deleted, substituted, and having a new character inserted after it. The insertion node of the model has a self-referential link, meaning that if a substitution or insertion takes place, the model can keep inserting characters with probability <math alttext="P(I|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.3.m3.1"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mrow id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p1.3.m3.1.1.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p1.3.m3.1.1.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p1.3.m3.1.1.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.2.cmml">I</mi><mo fence="false" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><apply id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1"><times id="S3.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.2"></times><ci id="S3.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.2">𝐼</ci><ci id="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">P(I|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.3.m3.1d">italic_P ( italic_I | italic_x )</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<p class="ltx_p ltx_align_center" id="S3.F2.1"><span class="ltx_text ltx_font_bold" id="S3.F2.1.1">The Corruption Network</span>
<svg class="ltx_picture" height="501.92" id="S3.F2.1.pic1" overflow="visible" version="1.1" width="745.89"><g fill="#000000" stroke="#000000" transform="translate(0,501.92) matrix(1 0 0 -1 0 0) translate(327.56,0) translate(0,456.64)"><g stroke-width="0.4pt"><path d="M 38.65 0 C 38.65 12.04 21.34 21.8 0 21.8 C -21.34 21.8 -38.65 12.04 -38.65 0 C -38.65 -12.04 -21.34 -21.8 0 -21.8 C 21.34 -21.8 38.65 -12.04 38.65 0 Z M 0 0" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -22.72 -10.8)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 16.87)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.46)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="23.45"><span class="ltx_ERROR undefined" id="S3.F2.1.pic1.1.1.1.1.1.1.1.1.1">\pgfmathresult</span>pt</foreignobject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 21.61)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Correct</text></g></g></g></g><path d="M 50.61 -170.08 C 50.61 -131.98 27.95 -101.09 0 -101.09 C -27.95 -101.09 -50.61 -131.98 -50.61 -170.08 C -50.61 -208.19 -27.95 -239.08 0 -239.08 C 27.95 -239.08 50.61 -208.19 50.61 -170.08 Z M 0 -170.08" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -31.17 -214.26)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 83.545)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 88.35)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Substitute</text></g></g></g></g><path d="M 35.43 -387.37 C 35.43 -349.26 19.57 -318.37 0 -318.37 C -19.57 -318.37 -35.43 -349.26 -35.43 -387.37 C -35.43 -425.47 -19.57 -456.36 0 -456.36 C 19.57 -456.36 35.43 -425.47 35.43 -387.37 Z M 0 -387.37" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.78 -431.54)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 83.545)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 88.35)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Finish</text></g></g></g></g><path d="M -110.21 -170.08 C -110.21 -132.04 -126.08 -101.2 -145.65 -101.2 C -165.22 -101.2 -181.08 -132.04 -181.08 -170.08 C -181.08 -208.13 -165.22 -238.97 -145.65 -238.97 C -126.08 -238.97 -110.21 -208.13 -110.21 -170.08 Z M -145.65 -170.08" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -163.19 -214.18)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 83.47)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 88.2)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Insert</text></g></g></g></g><path d="M 181.08 -170.08 C 181.08 -131.98 165.22 -101.09 145.65 -101.09 C 126.08 -101.09 110.21 -131.98 110.21 -170.08 C 110.21 -208.19 126.08 -239.08 145.65 -239.08 C 165.22 -239.08 181.08 -208.19 181.08 -170.08 Z M 145.65 -170.08" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 126.53 -214.26)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 83.545)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 88.35)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Delete</text></g></g></g></g><path d="M 38.92 0 C 418.05 0 414.84 -387.37 37.73 -387.37" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(-1.0 0.0 0.0 -1.0 37.73 -387.37)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M -12.11 -20.98 C -44.96 -77.87 -48.82 -134.84 -108.65 -156.62" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(-0.9397 -0.34203 0.34203 -0.9397 -108.65 -156.62)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M 0 -22.07 C 0 -52.78 0 -70.11 0 -98.79" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -98.79)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M 12.11 -20.98 C 41.07 -71.13 90.05 -73.79 118 -122.2" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(0.5 -0.86603 0.86603 0.5 118 -122.2)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M -119.03 -216.19 C -81.9 -280.51 -109.98 -387.37 -37.73 -387.37" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(1.0 0.0 0.0 1.0 -37.73 -387.37)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M -50.88 -170.08 C -73.91 -170.08 -86.91 -170.08 -107.92 -170.08" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(-1.0 0.0 0.0 -1.0 -107.92 -170.08)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M 0 -239.36 C 0 -270.06 0 -287.39 0 -316.08" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -316.08)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M 111.42 -189.85 C 45.77 -227.75 99.88 -329.7 35.98 -366.6" style="fill:none"></path><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(-0.86603 -0.5 0.5 -0.86603 35.98 -366.6)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><path d="M -145.65 -100.92 C -145.65 45.01 -327.29 -170.08 -183.38 -170.08" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt" transform="matrix(1.0 0.0 0.0 1.0 -183.38 -170.08)"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g></g></svg></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The corruption network is applied at character level to the text; the conditional transition probabilities between the nodes are learnt on a per character basis from parallel OCR and ground truth texts</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.2">The Markov model can be represented mathematically as the conditional probability distribution that <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.1.m1.1"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><mi id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><ci id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.1.m1.1d">italic_x</annotation></semantics></math> produces output sequence <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.2.m2.1"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mi id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><ci id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.2.m2.1d">italic_y</annotation></semantics></math>, as shown below.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y|x)=P(D|x)+\sum_{i=1}^{\infty}\left[P(S|x)+P(C|x)\right]P(I|x)^{i-1}" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">P</mi><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.5" xref="S3.E2.m1.4.4.5.cmml">=</mo><mrow id="S3.E2.m1.4.4.4" xref="S3.E2.m1.4.4.4.cmml"><mrow id="S3.E2.m1.2.2.2.1" xref="S3.E2.m1.2.2.2.1.cmml"><mi id="S3.E2.m1.2.2.2.1.3" xref="S3.E2.m1.2.2.2.1.3.cmml">P</mi><mo id="S3.E2.m1.2.2.2.1.2" xref="S3.E2.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml"><mo id="S3.E2.m1.2.2.2.1.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.1.2.cmml">D</mi><mo fence="false" id="S3.E2.m1.2.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.2.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.2.2.2.1.1.1.3" stretchy="false" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.4.4" rspace="0.055em" xref="S3.E2.m1.4.4.4.4.cmml">+</mo><mrow id="S3.E2.m1.4.4.4.3" xref="S3.E2.m1.4.4.4.3.cmml"><munderover id="S3.E2.m1.4.4.4.3.3" xref="S3.E2.m1.4.4.4.3.3.cmml"><mo id="S3.E2.m1.4.4.4.3.3.2.2" movablelimits="false" rspace="0em" xref="S3.E2.m1.4.4.4.3.3.2.2.cmml">∑</mo><mrow id="S3.E2.m1.4.4.4.3.3.2.3" xref="S3.E2.m1.4.4.4.3.3.2.3.cmml"><mi id="S3.E2.m1.4.4.4.3.3.2.3.2" xref="S3.E2.m1.4.4.4.3.3.2.3.2.cmml">i</mi><mo id="S3.E2.m1.4.4.4.3.3.2.3.1" xref="S3.E2.m1.4.4.4.3.3.2.3.1.cmml">=</mo><mn id="S3.E2.m1.4.4.4.3.3.2.3.3" xref="S3.E2.m1.4.4.4.3.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.4.4.4.3.3.3" mathvariant="normal" xref="S3.E2.m1.4.4.4.3.3.3.cmml">∞</mi></munderover><mrow id="S3.E2.m1.4.4.4.3.2" xref="S3.E2.m1.4.4.4.3.2.cmml"><mrow id="S3.E2.m1.3.3.3.2.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.2.cmml"><mo id="S3.E2.m1.3.3.3.2.1.1.1.2" xref="S3.E2.m1.3.3.3.2.1.1.2.1.cmml">[</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.1.3" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.3.cmml">P</mi><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.1.2" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.2.cmml">S</mi><mo fence="false" id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.3" xref="S3.E2.m1.3.3.3.2.1.1.1.1.3.cmml">+</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.2" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.2.3" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.3.cmml">P</mi><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.2.2" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.cmml"><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.2" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.2.cmml">C</mi><mo fence="false" id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.1" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.3" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.3.2.1.1.1.3" xref="S3.E2.m1.3.3.3.2.1.1.2.1.cmml">]</mo></mrow><mo id="S3.E2.m1.4.4.4.3.2.3" xref="S3.E2.m1.4.4.4.3.2.3.cmml">⁢</mo><mi id="S3.E2.m1.4.4.4.3.2.4" xref="S3.E2.m1.4.4.4.3.2.4.cmml">P</mi><mo id="S3.E2.m1.4.4.4.3.2.3a" xref="S3.E2.m1.4.4.4.3.2.3.cmml">⁢</mo><msup id="S3.E2.m1.4.4.4.3.2.2" xref="S3.E2.m1.4.4.4.3.2.2.cmml"><mrow id="S3.E2.m1.4.4.4.3.2.2.1.1" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.cmml"><mo id="S3.E2.m1.4.4.4.3.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.4.3.2.2.1.1.1" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.cmml"><mi id="S3.E2.m1.4.4.4.3.2.2.1.1.1.2" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.2.cmml">I</mi><mo fence="false" id="S3.E2.m1.4.4.4.3.2.2.1.1.1.1" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.4.4.4.3.2.2.1.1.1.3" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.4.4.4.3.2.2.1.1.3" stretchy="false" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.cmml">)</mo></mrow><mrow id="S3.E2.m1.4.4.4.3.2.2.3" xref="S3.E2.m1.4.4.4.3.2.2.3.cmml"><mi id="S3.E2.m1.4.4.4.3.2.2.3.2" xref="S3.E2.m1.4.4.4.3.2.2.3.2.cmml">i</mi><mo id="S3.E2.m1.4.4.4.3.2.2.3.1" xref="S3.E2.m1.4.4.4.3.2.2.3.1.cmml">−</mo><mn id="S3.E2.m1.4.4.4.3.2.2.3.3" xref="S3.E2.m1.4.4.4.3.2.2.3.3.cmml">1</mn></mrow></msup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><eq id="S3.E2.m1.4.4.5.cmml" xref="S3.E2.m1.4.4.5"></eq><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">𝑃</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.4.4.4.cmml" xref="S3.E2.m1.4.4.4"><plus id="S3.E2.m1.4.4.4.4.cmml" xref="S3.E2.m1.4.4.4.4"></plus><apply id="S3.E2.m1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1"><times id="S3.E2.m1.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.1.2"></times><ci id="S3.E2.m1.2.2.2.1.3.cmml" xref="S3.E2.m1.2.2.2.1.3">𝑃</ci><apply id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2">𝐷</ci><ci id="S3.E2.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.4.4.4.3.cmml" xref="S3.E2.m1.4.4.4.3"><apply id="S3.E2.m1.4.4.4.3.3.cmml" xref="S3.E2.m1.4.4.4.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.4.3.3.1.cmml" xref="S3.E2.m1.4.4.4.3.3">superscript</csymbol><apply id="S3.E2.m1.4.4.4.3.3.2.cmml" xref="S3.E2.m1.4.4.4.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.4.3.3.2.1.cmml" xref="S3.E2.m1.4.4.4.3.3">subscript</csymbol><sum id="S3.E2.m1.4.4.4.3.3.2.2.cmml" xref="S3.E2.m1.4.4.4.3.3.2.2"></sum><apply id="S3.E2.m1.4.4.4.3.3.2.3.cmml" xref="S3.E2.m1.4.4.4.3.3.2.3"><eq id="S3.E2.m1.4.4.4.3.3.2.3.1.cmml" xref="S3.E2.m1.4.4.4.3.3.2.3.1"></eq><ci id="S3.E2.m1.4.4.4.3.3.2.3.2.cmml" xref="S3.E2.m1.4.4.4.3.3.2.3.2">𝑖</ci><cn id="S3.E2.m1.4.4.4.3.3.2.3.3.cmml" type="integer" xref="S3.E2.m1.4.4.4.3.3.2.3.3">1</cn></apply></apply><infinity id="S3.E2.m1.4.4.4.3.3.3.cmml" xref="S3.E2.m1.4.4.4.3.3.3"></infinity></apply><apply id="S3.E2.m1.4.4.4.3.2.cmml" xref="S3.E2.m1.4.4.4.3.2"><times id="S3.E2.m1.4.4.4.3.2.3.cmml" xref="S3.E2.m1.4.4.4.3.2.3"></times><apply id="S3.E2.m1.3.3.3.2.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.3.2.1.1.2.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.3.3.3.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1"><plus id="S3.E2.m1.3.3.3.2.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.3"></plus><apply id="S3.E2.m1.3.3.3.2.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1"><times id="S3.E2.m1.3.3.3.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.2"></times><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.3">𝑃</ci><apply id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.2">𝑆</ci><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.3.3.3.2.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2"><times id="S3.E2.m1.3.3.3.2.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.2"></times><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.3">𝑃</ci><apply id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.2">𝐶</ci><ci id="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.2.1.1.1.1.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply><ci id="S3.E2.m1.4.4.4.3.2.4.cmml" xref="S3.E2.m1.4.4.4.3.2.4">𝑃</ci><apply id="S3.E2.m1.4.4.4.3.2.2.cmml" xref="S3.E2.m1.4.4.4.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.4.3.2.2.2.cmml" xref="S3.E2.m1.4.4.4.3.2.2">superscript</csymbol><apply id="S3.E2.m1.4.4.4.3.2.2.1.1.1.cmml" xref="S3.E2.m1.4.4.4.3.2.2.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.4.3.2.2.1.1.1.1.cmml" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.4.4.4.3.2.2.1.1.1.2.cmml" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.2">𝐼</ci><ci id="S3.E2.m1.4.4.4.3.2.2.1.1.1.3.cmml" xref="S3.E2.m1.4.4.4.3.2.2.1.1.1.3">𝑥</ci></apply><apply id="S3.E2.m1.4.4.4.3.2.2.3.cmml" xref="S3.E2.m1.4.4.4.3.2.2.3"><minus id="S3.E2.m1.4.4.4.3.2.2.3.1.cmml" xref="S3.E2.m1.4.4.4.3.2.2.3.1"></minus><ci id="S3.E2.m1.4.4.4.3.2.2.3.2.cmml" xref="S3.E2.m1.4.4.4.3.2.2.3.2">𝑖</ci><cn id="S3.E2.m1.4.4.4.3.2.2.3.3.cmml" type="integer" xref="S3.E2.m1.4.4.4.3.2.2.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">P(y|x)=P(D|x)+\sum_{i=1}^{\infty}\left[P(S|x)+P(C|x)\right]P(I|x)^{i-1}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">italic_P ( italic_y | italic_x ) = italic_P ( italic_D | italic_x ) + ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT [ italic_P ( italic_S | italic_x ) + italic_P ( italic_C | italic_x ) ] italic_P ( italic_I | italic_x ) start_POSTSUPERSCRIPT italic_i - 1 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS1.p3.12">Where <math alttext="P(C|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.1.m1.1"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p3.1.m1.1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.2.cmml">C</mi><mo fence="false" id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><times id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2"></times><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">P(C|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.1.m1.1d">italic_P ( italic_C | italic_x )</annotation></semantics></math> is the probability of output sequence <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.2.m2.1"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><mi id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><ci id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.2.m2.1d">italic_y</annotation></semantics></math> being the correct character, <math alttext="P(D|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.3.m3.1"><semantics id="S3.SS2.SSS1.p3.3.m3.1a"><mrow id="S3.SS2.SSS1.p3.3.m3.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.1.1.3" xref="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p3.3.m3.1.1.2" xref="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p3.3.m3.1.1.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.2.cmml">D</mi><mo fence="false" id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.1b"><apply id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1"><times id="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.2"></times><ci id="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.2">𝐷</ci><ci id="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.1c">P(D|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.3.m3.1d">italic_P ( italic_D | italic_x )</annotation></semantics></math> is the probability of <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.4.m4.1"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><mi id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><ci id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.4.m4.1d">italic_x</annotation></semantics></math> being deleted, <math alttext="P(S|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.5.m5.1"><semantics id="S3.SS2.SSS1.p3.5.m5.1a"><mrow id="S3.SS2.SSS1.p3.5.m5.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p3.5.m5.1.1.3" xref="S3.SS2.SSS1.p3.5.m5.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p3.5.m5.1.1.2" xref="S3.SS2.SSS1.p3.5.m5.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p3.5.m5.1.1.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.2.cmml">S</mi><mo fence="false" id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.5.m5.1b"><apply id="S3.SS2.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1"><times id="S3.SS2.SSS1.p3.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.2"></times><ci id="S3.SS2.SSS1.p3.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.2">𝑆</ci><ci id="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.5.m5.1c">P(S|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.5.m5.1d">italic_P ( italic_S | italic_x )</annotation></semantics></math> is the probability of <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.6.m6.1"><semantics id="S3.SS2.SSS1.p3.6.m6.1a"><mi id="S3.SS2.SSS1.p3.6.m6.1.1" xref="S3.SS2.SSS1.p3.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.6.m6.1b"><ci id="S3.SS2.SSS1.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.6.m6.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.6.m6.1d">italic_x</annotation></semantics></math> being substituted for another character, and <math alttext="P(I|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.7.m7.1"><semantics id="S3.SS2.SSS1.p3.7.m7.1a"><mrow id="S3.SS2.SSS1.p3.7.m7.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.cmml"><mi id="S3.SS2.SSS1.p3.7.m7.1.1.3" xref="S3.SS2.SSS1.p3.7.m7.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p3.7.m7.1.1.2" xref="S3.SS2.SSS1.p3.7.m7.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p3.7.m7.1.1.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.2" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.2.cmml">I</mi><mo fence="false" id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.3" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.7.m7.1b"><apply id="S3.SS2.SSS1.p3.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1"><times id="S3.SS2.SSS1.p3.7.m7.1.1.2.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.2"></times><ci id="S3.SS2.SSS1.p3.7.m7.1.1.3.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.2">𝐼</ci><ci id="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.7.m7.1c">P(I|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.7.m7.1d">italic_P ( italic_I | italic_x )</annotation></semantics></math> the probability of a new character being inserted. The self-reference in the network allowing multiple new characters to be inserted means that the input character <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.8.m8.1"><semantics id="S3.SS2.SSS1.p3.8.m8.1a"><mi id="S3.SS2.SSS1.p3.8.m8.1.1" xref="S3.SS2.SSS1.p3.8.m8.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.8.m8.1b"><ci id="S3.SS2.SSS1.p3.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.8.m8.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.8.m8.1d">italic_x</annotation></semantics></math> can return a sequence <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.9.m9.1"><semantics id="S3.SS2.SSS1.p3.9.m9.1a"><mi id="S3.SS2.SSS1.p3.9.m9.1.1" xref="S3.SS2.SSS1.p3.9.m9.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.9.m9.1b"><ci id="S3.SS2.SSS1.p3.9.m9.1.1.cmml" xref="S3.SS2.SSS1.p3.9.m9.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.9.m9.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.9.m9.1d">italic_i</annotation></semantics></math> long, where <math alttext="0\geq i\geq\infty" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.10.m10.1"><semantics id="S3.SS2.SSS1.p3.10.m10.1a"><mrow id="S3.SS2.SSS1.p3.10.m10.1.1" xref="S3.SS2.SSS1.p3.10.m10.1.1.cmml"><mn id="S3.SS2.SSS1.p3.10.m10.1.1.2" xref="S3.SS2.SSS1.p3.10.m10.1.1.2.cmml">0</mn><mo id="S3.SS2.SSS1.p3.10.m10.1.1.3" xref="S3.SS2.SSS1.p3.10.m10.1.1.3.cmml">≥</mo><mi id="S3.SS2.SSS1.p3.10.m10.1.1.4" xref="S3.SS2.SSS1.p3.10.m10.1.1.4.cmml">i</mi><mo id="S3.SS2.SSS1.p3.10.m10.1.1.5" xref="S3.SS2.SSS1.p3.10.m10.1.1.5.cmml">≥</mo><mi id="S3.SS2.SSS1.p3.10.m10.1.1.6" mathvariant="normal" xref="S3.SS2.SSS1.p3.10.m10.1.1.6.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.10.m10.1b"><apply id="S3.SS2.SSS1.p3.10.m10.1.1.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1"><and id="S3.SS2.SSS1.p3.10.m10.1.1a.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1"></and><apply id="S3.SS2.SSS1.p3.10.m10.1.1b.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1"><geq id="S3.SS2.SSS1.p3.10.m10.1.1.3.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1.3"></geq><cn id="S3.SS2.SSS1.p3.10.m10.1.1.2.cmml" type="integer" xref="S3.SS2.SSS1.p3.10.m10.1.1.2">0</cn><ci id="S3.SS2.SSS1.p3.10.m10.1.1.4.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1.4">𝑖</ci></apply><apply id="S3.SS2.SSS1.p3.10.m10.1.1c.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1"><geq id="S3.SS2.SSS1.p3.10.m10.1.1.5.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1.5"></geq><share href="https://arxiv.org/html/2409.19735v1#S3.SS2.SSS1.p3.10.m10.1.1.4.cmml" id="S3.SS2.SSS1.p3.10.m10.1.1d.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1"></share><infinity id="S3.SS2.SSS1.p3.10.m10.1.1.6.cmml" xref="S3.SS2.SSS1.p3.10.m10.1.1.6"></infinity></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.10.m10.1c">0\geq i\geq\infty</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.10.m10.1d">0 ≥ italic_i ≥ ∞</annotation></semantics></math>, the probability of <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.11.m11.1"><semantics id="S3.SS2.SSS1.p3.11.m11.1a"><mi id="S3.SS2.SSS1.p3.11.m11.1.1" xref="S3.SS2.SSS1.p3.11.m11.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.11.m11.1b"><ci id="S3.SS2.SSS1.p3.11.m11.1.1.cmml" xref="S3.SS2.SSS1.p3.11.m11.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.11.m11.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.11.m11.1d">italic_y</annotation></semantics></math> being 1 or greater is shown using the summation from all possible values of <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.12.m12.1"><semantics id="S3.SS2.SSS1.p3.12.m12.1a"><mi id="S3.SS2.SSS1.p3.12.m12.1.1" xref="S3.SS2.SSS1.p3.12.m12.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.12.m12.1b"><ci id="S3.SS2.SSS1.p3.12.m12.1.1.cmml" xref="S3.SS2.SSS1.p3.12.m12.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.12.m12.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.12.m12.1d">italic_i</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<p class="ltx_p" id="S3.SS2.SSS1.p4.2">Equation <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.E2" title="In 3.2.1 The Markov Model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">2</span></a> represents the probability distribution mapping only a single character to its output sequence, not the entire document. However, as this approach models all characters as independent, the joint probability of output sequence <math alttext="Y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.1.m1.1"><semantics id="S3.SS2.SSS1.p4.1.m1.1a"><mi id="S3.SS2.SSS1.p4.1.m1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.1.m1.1b"><ci id="S3.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.1.m1.1c">Y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p4.1.m1.1d">italic_Y</annotation></semantics></math> for input sequence <math alttext="X" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.2.m2.1"><semantics id="S3.SS2.SSS1.p4.2.m2.1a"><mi id="S3.SS2.SSS1.p4.2.m2.1.1" xref="S3.SS2.SSS1.p4.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.2.m2.1b"><ci id="S3.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.2.m2.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p4.2.m2.1d">italic_X</annotation></semantics></math> can be represented as</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(Y|X)=\prod_{j=1}^{j=n}P(y_{j}|x_{j})" class="ltx_Math" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml">P</mi><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">Y</mi><mo fence="false" id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">X</mi></mrow><mo id="S3.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.3" rspace="0.111em" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><munderover id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml"><mo id="S3.E3.m1.2.2.2.2.2.2" movablelimits="false" xref="S3.E3.m1.2.2.2.2.2.2.cmml">∏</mo><mrow id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.2.3.2.cmml">j</mi><mo id="S3.E3.m1.2.2.2.2.2.3.1" xref="S3.E3.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S3.E3.m1.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml"><mi id="S3.E3.m1.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.3.2.cmml">j</mi><mo id="S3.E3.m1.2.2.2.2.3.1" xref="S3.E3.m1.2.2.2.2.3.1.cmml">=</mo><mi id="S3.E3.m1.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.3.3.cmml">n</mi></mrow></munderover><mrow id="S3.E3.m1.2.2.2.1" xref="S3.E3.m1.2.2.2.1.cmml"><mi id="S3.E3.m1.2.2.2.1.3" xref="S3.E3.m1.2.2.2.1.3.cmml">P</mi><mo id="S3.E3.m1.2.2.2.1.2" xref="S3.E3.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.2.2.2.1.1.1" xref="S3.E3.m1.2.2.2.1.1.1.1.cmml"><mo id="S3.E3.m1.2.2.2.1.1.1.2" stretchy="false" xref="S3.E3.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.2.1.1.1.1" xref="S3.E3.m1.2.2.2.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.2.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2.2.1.1.1.1.2.2" xref="S3.E3.m1.2.2.2.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E3.m1.2.2.2.1.1.1.1.2.3" xref="S3.E3.m1.2.2.2.1.1.1.1.2.3.cmml">j</mi></msub><mo fence="false" id="S3.E3.m1.2.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.2.1.1.1.1.1.cmml">|</mo><msub id="S3.E3.m1.2.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.2.1.1.1.1.3.2" xref="S3.E3.m1.2.2.2.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E3.m1.2.2.2.1.1.1.1.3.3" xref="S3.E3.m1.2.2.2.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E3.m1.2.2.2.1.1.1.3" stretchy="false" xref="S3.E3.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">𝑃</ci><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">𝑌</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">𝑋</ci></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><apply id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2">product</csymbol><apply id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3"><eq id="S3.E3.m1.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E3.m1.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2">𝑗</ci><cn id="S3.E3.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="S3.E3.m1.2.2.2.2.2.3.3">1</cn></apply></apply><apply id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.3"><eq id="S3.E3.m1.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.3.1"></eq><ci id="S3.E3.m1.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.3.2">𝑗</ci><ci id="S3.E3.m1.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.3.3">𝑛</ci></apply></apply><apply id="S3.E3.m1.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.1"><times id="S3.E3.m1.2.2.2.1.2.cmml" xref="S3.E3.m1.2.2.2.1.2"></times><ci id="S3.E3.m1.2.2.2.1.3.cmml" xref="S3.E3.m1.2.2.2.1.3">𝑃</ci><apply id="S3.E3.m1.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E3.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.2.2">𝑦</ci><ci id="S3.E3.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.2.3">𝑗</ci></apply><apply id="S3.E3.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.3.2">𝑥</ci><ci id="S3.E3.m1.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.2.1.1.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">P(Y|X)=\prod_{j=1}^{j=n}P(y_{j}|x_{j})</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">italic_P ( italic_Y | italic_X ) = ∏ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j = italic_n end_POSTSUPERSCRIPT italic_P ( italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p6">
<p class="ltx_p" id="S3.SS2.SSS1.p6.1">Which is the product of all output sequences for the <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p6.1.m1.1"><semantics id="S3.SS2.SSS1.p6.1.m1.1a"><mi id="S3.SS2.SSS1.p6.1.m1.1.1" xref="S3.SS2.SSS1.p6.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p6.1.m1.1b"><ci id="S3.SS2.SSS1.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p6.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p6.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p6.1.m1.1d">italic_n</annotation></semantics></math> input characters in the document.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p7">
<p class="ltx_p" id="S3.SS2.SSS1.p7.5">A significant advantage of the Markov model is the ease with which the overall CER can be modified. As CER<math alttext="\approx 1-P(C)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p7.1.m1.1"><semantics id="S3.SS2.SSS1.p7.1.m1.1a"><mrow id="S3.SS2.SSS1.p7.1.m1.1.2" xref="S3.SS2.SSS1.p7.1.m1.1.2.cmml"><mi id="S3.SS2.SSS1.p7.1.m1.1.2.2" xref="S3.SS2.SSS1.p7.1.m1.1.2.2.cmml"></mi><mo id="S3.SS2.SSS1.p7.1.m1.1.2.1" xref="S3.SS2.SSS1.p7.1.m1.1.2.1.cmml">≈</mo><mrow id="S3.SS2.SSS1.p7.1.m1.1.2.3" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.cmml"><mn id="S3.SS2.SSS1.p7.1.m1.1.2.3.2" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.2.cmml">1</mn><mo id="S3.SS2.SSS1.p7.1.m1.1.2.3.1" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.1.cmml">−</mo><mrow id="S3.SS2.SSS1.p7.1.m1.1.2.3.3" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.cmml"><mi id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.2" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.2.cmml">P</mi><mo id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.1" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.1.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.3.2" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.cmml"><mo id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.3.2.1" stretchy="false" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.cmml">(</mo><mi id="S3.SS2.SSS1.p7.1.m1.1.1" xref="S3.SS2.SSS1.p7.1.m1.1.1.cmml">C</mi><mo id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.3.2.2" stretchy="false" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p7.1.m1.1b"><apply id="S3.SS2.SSS1.p7.1.m1.1.2.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2"><approx id="S3.SS2.SSS1.p7.1.m1.1.2.1.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.1"></approx><csymbol cd="latexml" id="S3.SS2.SSS1.p7.1.m1.1.2.2.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.2">absent</csymbol><apply id="S3.SS2.SSS1.p7.1.m1.1.2.3.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.3"><minus id="S3.SS2.SSS1.p7.1.m1.1.2.3.1.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.1"></minus><cn id="S3.SS2.SSS1.p7.1.m1.1.2.3.2.cmml" type="integer" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.2">1</cn><apply id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3"><times id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.1.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.1"></times><ci id="S3.SS2.SSS1.p7.1.m1.1.2.3.3.2.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.2.3.3.2">𝑃</ci><ci id="S3.SS2.SSS1.p7.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p7.1.m1.1.1">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p7.1.m1.1c">\approx 1-P(C)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p7.1.m1.1d">≈ 1 - italic_P ( italic_C )</annotation></semantics></math>, this paper uses a straightforward approach of directly setting the character level conditional probability of being correct based on the target CER, that is <math alttext="P(C|x)=1-\textrm{CER}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p7.2.m2.1"><semantics id="S3.SS2.SSS1.p7.2.m2.1a"><mrow id="S3.SS2.SSS1.p7.2.m2.1.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.cmml"><mrow id="S3.SS2.SSS1.p7.2.m2.1.1.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.cmml"><mi id="S3.SS2.SSS1.p7.2.m2.1.1.1.3" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p7.2.m2.1.1.1.2" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.2.cmml">C</mi><mo fence="false" id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS1.p7.2.m2.1.1.2" xref="S3.SS2.SSS1.p7.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS2.SSS1.p7.2.m2.1.1.3" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.cmml"><mn id="S3.SS2.SSS1.p7.2.m2.1.1.3.2" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.2.cmml">1</mn><mo id="S3.SS2.SSS1.p7.2.m2.1.1.3.1" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.1.cmml">−</mo><mtext id="S3.SS2.SSS1.p7.2.m2.1.1.3.3" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.3a.cmml">CER</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p7.2.m2.1b"><apply id="S3.SS2.SSS1.p7.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1"><eq id="S3.SS2.SSS1.p7.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.2"></eq><apply id="S3.SS2.SSS1.p7.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1"><times id="S3.SS2.SSS1.p7.2.m2.1.1.1.2.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.2"></times><ci id="S3.SS2.SSS1.p7.2.m2.1.1.1.3.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.SS2.SSS1.p7.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.3"><minus id="S3.SS2.SSS1.p7.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.1"></minus><cn id="S3.SS2.SSS1.p7.2.m2.1.1.3.2.cmml" type="integer" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.2">1</cn><ci id="S3.SS2.SSS1.p7.2.m2.1.1.3.3a.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.3"><mtext id="S3.SS2.SSS1.p7.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS1.p7.2.m2.1.1.3.3">CER</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p7.2.m2.1c">P(C|x)=1-\textrm{CER}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p7.2.m2.1d">italic_P ( italic_C | italic_x ) = 1 - CER</annotation></semantics></math>. The approach used to renormalise in this paper multiplies the other elements in the row by a factor and then renormalises to ensure the result is a probability distribution. Thus, the adjustment factor is for a conditional probability matrix <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p7.3.m3.1"><semantics id="S3.SS2.SSS1.p7.3.m3.1a"><mi id="S3.SS2.SSS1.p7.3.m3.1.1" xref="S3.SS2.SSS1.p7.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p7.3.m3.1b"><ci id="S3.SS2.SSS1.p7.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p7.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p7.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p7.3.m3.1d">italic_M</annotation></semantics></math> with <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p7.4.m4.1"><semantics id="S3.SS2.SSS1.p7.4.m4.1a"><mi id="S3.SS2.SSS1.p7.4.m4.1.1" xref="S3.SS2.SSS1.p7.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p7.4.m4.1b"><ci id="S3.SS2.SSS1.p7.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p7.4.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p7.4.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p7.4.m4.1d">italic_m</annotation></semantics></math> characters and <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p7.5.m5.1"><semantics id="S3.SS2.SSS1.p7.5.m5.1a"><mi id="S3.SS2.SSS1.p7.5.m5.1.1" xref="S3.SS2.SSS1.p7.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p7.5.m5.1b"><ci id="S3.SS2.SSS1.p7.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p7.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p7.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p7.5.m5.1d">italic_n</annotation></semantics></math> states.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="f_{ik}=\frac{1-\textrm{P}^{\prime}(k|i)}{1-\textrm{P}(k|i)}" class="ltx_Math" display="block" id="S3.E4.m1.2"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.3" xref="S3.E4.m1.2.3.cmml"><msub id="S3.E4.m1.2.3.2" xref="S3.E4.m1.2.3.2.cmml"><mi id="S3.E4.m1.2.3.2.2" xref="S3.E4.m1.2.3.2.2.cmml">f</mi><mrow id="S3.E4.m1.2.3.2.3" xref="S3.E4.m1.2.3.2.3.cmml"><mi id="S3.E4.m1.2.3.2.3.2" xref="S3.E4.m1.2.3.2.3.2.cmml">i</mi><mo id="S3.E4.m1.2.3.2.3.1" xref="S3.E4.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S3.E4.m1.2.3.2.3.3" xref="S3.E4.m1.2.3.2.3.3.cmml">k</mi></mrow></msub><mo id="S3.E4.m1.2.3.1" xref="S3.E4.m1.2.3.1.cmml">=</mo><mfrac id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mn id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">1</mn><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">−</mo><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mtext id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2a.cmml">P</mtext><mo id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml">′</mo></msup><mo id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">k</mi><mo fence="false" id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml">i</mi></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><mn id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml">1</mn><mo id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml">−</mo><mrow id="S3.E4.m1.2.2.2.1" xref="S3.E4.m1.2.2.2.1.cmml"><mtext id="S3.E4.m1.2.2.2.1.3" xref="S3.E4.m1.2.2.2.1.3a.cmml">P</mtext><mo id="S3.E4.m1.2.2.2.1.2" xref="S3.E4.m1.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml"><mo id="S3.E4.m1.2.2.2.1.1.1.2" stretchy="false" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.2.cmml">k</mi><mo fence="false" id="S3.E4.m1.2.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.cmml">|</mo><mi id="S3.E4.m1.2.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.3.cmml">i</mi></mrow><mo id="S3.E4.m1.2.2.2.1.1.1.3" stretchy="false" xref="S3.E4.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.3.cmml" xref="S3.E4.m1.2.3"><eq id="S3.E4.m1.2.3.1.cmml" xref="S3.E4.m1.2.3.1"></eq><apply id="S3.E4.m1.2.3.2.cmml" xref="S3.E4.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.3.2.1.cmml" xref="S3.E4.m1.2.3.2">subscript</csymbol><ci id="S3.E4.m1.2.3.2.2.cmml" xref="S3.E4.m1.2.3.2.2">𝑓</ci><apply id="S3.E4.m1.2.3.2.3.cmml" xref="S3.E4.m1.2.3.2.3"><times id="S3.E4.m1.2.3.2.3.1.cmml" xref="S3.E4.m1.2.3.2.3.1"></times><ci id="S3.E4.m1.2.3.2.3.2.cmml" xref="S3.E4.m1.2.3.2.3.2">𝑖</ci><ci id="S3.E4.m1.2.3.2.3.3.cmml" xref="S3.E4.m1.2.3.2.3.3">𝑘</ci></apply></apply><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><divide id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2"></divide><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><minus id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></minus><cn id="S3.E4.m1.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.1.1.1.3">1</cn><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2a.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><mtext id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2">P</mtext></ci><ci id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3">′</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2">𝑘</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><minus id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2"></minus><cn id="S3.E4.m1.2.2.2.3.cmml" type="integer" xref="S3.E4.m1.2.2.2.3">1</cn><apply id="S3.E4.m1.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.1"><times id="S3.E4.m1.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.1.2"></times><ci id="S3.E4.m1.2.2.2.1.3a.cmml" xref="S3.E4.m1.2.2.2.1.3"><mtext id="S3.E4.m1.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.1.3">P</mtext></ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1">conditional</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.2">𝑘</ci><ci id="S3.E4.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">f_{ik}=\frac{1-\textrm{P}^{\prime}(k|i)}{1-\textrm{P}(k|i)}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.2d">italic_f start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT = divide start_ARG 1 - P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ( italic_k | italic_i ) end_ARG start_ARG 1 - P ( italic_k | italic_i ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS1.p8.4">Where <math alttext="\textrm{P}^{\prime}(k|i)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p8.1.m1.1"><semantics id="S3.SS2.SSS1.p8.1.m1.1a"><mrow id="S3.SS2.SSS1.p8.1.m1.1.1" xref="S3.SS2.SSS1.p8.1.m1.1.1.cmml"><msup id="S3.SS2.SSS1.p8.1.m1.1.1.3" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.cmml"><mtext id="S3.SS2.SSS1.p8.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.2a.cmml">P</mtext><mo id="S3.SS2.SSS1.p8.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.3.cmml">′</mo></msup><mo id="S3.SS2.SSS1.p8.1.m1.1.1.2" xref="S3.SS2.SSS1.p8.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p8.1.m1.1.1.1.1" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.2" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.2.cmml">k</mi><mo fence="false" id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.1" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.3" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.3.cmml">i</mi></mrow><mo id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p8.1.m1.1b"><apply id="S3.SS2.SSS1.p8.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1"><times id="S3.SS2.SSS1.p8.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.2"></times><apply id="S3.SS2.SSS1.p8.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p8.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS1.p8.1.m1.1.1.3.2a.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.2"><mtext id="S3.SS2.SSS1.p8.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.2">P</mtext></ci><ci id="S3.SS2.SSS1.p8.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.3.3">′</ci></apply><apply id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.2">𝑘</ci><ci id="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p8.1.m1.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p8.1.m1.1c">\textrm{P}^{\prime}(k|i)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p8.1.m1.1d">P start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ( italic_k | italic_i )</annotation></semantics></math> is the adjusted conditional probability that the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p8.2.m2.1"><semantics id="S3.SS2.SSS1.p8.2.m2.1a"><mi id="S3.SS2.SSS1.p8.2.m2.1.1" xref="S3.SS2.SSS1.p8.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p8.2.m2.1b"><ci id="S3.SS2.SSS1.p8.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p8.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p8.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p8.2.m2.1d">italic_i</annotation></semantics></math>th character has state <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p8.3.m3.1"><semantics id="S3.SS2.SSS1.p8.3.m3.1a"><mi id="S3.SS2.SSS1.p8.3.m3.1.1" xref="S3.SS2.SSS1.p8.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p8.3.m3.1b"><ci id="S3.SS2.SSS1.p8.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p8.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p8.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p8.3.m3.1d">italic_k</annotation></semantics></math>. This means for each row of the matrix <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p8.4.m4.1"><semantics id="S3.SS2.SSS1.p8.4.m4.1a"><mi id="S3.SS2.SSS1.p8.4.m4.1.1" xref="S3.SS2.SSS1.p8.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p8.4.m4.1b"><ci id="S3.SS2.SSS1.p8.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p8.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p8.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p8.4.m4.1d">italic_M</annotation></semantics></math>, we can perform the operation</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p9">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="M^{\prime}_{ij}=\left\{\begin{array}[]{ll}M^{\prime}_{ij}\cdot f_{ik}&amp;\textrm{%
if}\;j\neq k\\
M_{ij}&amp;\textrm{if}\;j=k\end{array}\right." class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.2" xref="S3.E5.m1.1.2.cmml"><msubsup id="S3.E5.m1.1.2.2" xref="S3.E5.m1.1.2.2.cmml"><mi id="S3.E5.m1.1.2.2.2.2" xref="S3.E5.m1.1.2.2.2.2.cmml">M</mi><mrow id="S3.E5.m1.1.2.2.3" xref="S3.E5.m1.1.2.2.3.cmml"><mi id="S3.E5.m1.1.2.2.3.2" xref="S3.E5.m1.1.2.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.2.2.3.1" xref="S3.E5.m1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.2.2.3.3" xref="S3.E5.m1.1.2.2.3.3.cmml">j</mi></mrow><mo id="S3.E5.m1.1.2.2.2.3" xref="S3.E5.m1.1.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.E5.m1.1.2.1" xref="S3.E5.m1.1.2.1.cmml">=</mo><mrow id="S3.E5.m1.1.2.3.2" xref="S3.E5.m1.1.2.3.1.cmml"><mo id="S3.E5.m1.1.2.3.2.1" xref="S3.E5.m1.1.2.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.E5.m1.1.1" rowspacing="0pt" xref="S3.E5.m1.1.1.cmml"><mtr id="S3.E5.m1.1.1a" xref="S3.E5.m1.1.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.1.1b" xref="S3.E5.m1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><msubsup id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.1.1.1.1.1.2.2.2.cmml">M</mi><mrow id="S3.E5.m1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.2.3.2" xref="S3.E5.m1.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.1.2.3.1" xref="S3.E5.m1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.1.2.3.3" xref="S3.E5.m1.1.1.1.1.1.2.3.3.cmml">j</mi></mrow><mo id="S3.E5.m1.1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.1.2.2.3.cmml">′</mo></msubsup><mo id="S3.E5.m1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.3.2.cmml">f</mi><mrow id="S3.E5.m1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.1.3.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.1.3.3.3.cmml">k</mi></mrow></msub></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.1.1c" xref="S3.E5.m1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.2.1" xref="S3.E5.m1.1.1.1.2.1.cmml"><mrow id="S3.E5.m1.1.1.1.2.1.2" xref="S3.E5.m1.1.1.1.2.1.2.cmml"><mtext id="S3.E5.m1.1.1.1.2.1.2.2" xref="S3.E5.m1.1.1.1.2.1.2.2a.cmml">if</mtext><mo id="S3.E5.m1.1.1.1.2.1.2.1" lspace="0.280em" xref="S3.E5.m1.1.1.1.2.1.2.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.2.1.2.3" xref="S3.E5.m1.1.1.1.2.1.2.3.cmml">j</mi></mrow><mo id="S3.E5.m1.1.1.1.2.1.1" xref="S3.E5.m1.1.1.1.2.1.1.cmml">≠</mo><mi id="S3.E5.m1.1.1.1.2.1.3" xref="S3.E5.m1.1.1.1.2.1.3.cmml">k</mi></mrow></mtd></mtr><mtr id="S3.E5.m1.1.1d" xref="S3.E5.m1.1.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.1.1e" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.2.1.1" xref="S3.E5.m1.1.1.2.1.1.cmml"><mi id="S3.E5.m1.1.1.2.1.1.2" xref="S3.E5.m1.1.1.2.1.1.2.cmml">M</mi><mrow id="S3.E5.m1.1.1.2.1.1.3" xref="S3.E5.m1.1.1.2.1.1.3.cmml"><mi id="S3.E5.m1.1.1.2.1.1.3.2" xref="S3.E5.m1.1.1.2.1.1.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.2.1.1.3.1" xref="S3.E5.m1.1.1.2.1.1.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.2.1.1.3.3" xref="S3.E5.m1.1.1.2.1.1.3.3.cmml">j</mi></mrow></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.1.1f" xref="S3.E5.m1.1.1.cmml"><mrow id="S3.E5.m1.1.1.2.2.1" xref="S3.E5.m1.1.1.2.2.1.cmml"><mrow id="S3.E5.m1.1.1.2.2.1.2" xref="S3.E5.m1.1.1.2.2.1.2.cmml"><mtext id="S3.E5.m1.1.1.2.2.1.2.2" xref="S3.E5.m1.1.1.2.2.1.2.2a.cmml">if</mtext><mo id="S3.E5.m1.1.1.2.2.1.2.1" lspace="0.280em" xref="S3.E5.m1.1.1.2.2.1.2.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.2.2.1.2.3" xref="S3.E5.m1.1.1.2.2.1.2.3.cmml">j</mi></mrow><mo id="S3.E5.m1.1.1.2.2.1.1" xref="S3.E5.m1.1.1.2.2.1.1.cmml">=</mo><mi id="S3.E5.m1.1.1.2.2.1.3" xref="S3.E5.m1.1.1.2.2.1.3.cmml">k</mi></mrow></mtd></mtr></mtable><mi id="S3.E5.m1.1.2.3.2.2" xref="S3.E5.m1.1.2.3.1.1.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.2.cmml" xref="S3.E5.m1.1.2"><eq id="S3.E5.m1.1.2.1.cmml" xref="S3.E5.m1.1.2.1"></eq><apply id="S3.E5.m1.1.2.2.cmml" xref="S3.E5.m1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.2.2.1.cmml" xref="S3.E5.m1.1.2.2">subscript</csymbol><apply id="S3.E5.m1.1.2.2.2.cmml" xref="S3.E5.m1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.2.2.2.1.cmml" xref="S3.E5.m1.1.2.2">superscript</csymbol><ci id="S3.E5.m1.1.2.2.2.2.cmml" xref="S3.E5.m1.1.2.2.2.2">𝑀</ci><ci id="S3.E5.m1.1.2.2.2.3.cmml" xref="S3.E5.m1.1.2.2.2.3">′</ci></apply><apply id="S3.E5.m1.1.2.2.3.cmml" xref="S3.E5.m1.1.2.2.3"><times id="S3.E5.m1.1.2.2.3.1.cmml" xref="S3.E5.m1.1.2.2.3.1"></times><ci id="S3.E5.m1.1.2.2.3.2.cmml" xref="S3.E5.m1.1.2.2.3.2">𝑖</ci><ci id="S3.E5.m1.1.2.2.3.3.cmml" xref="S3.E5.m1.1.2.2.3.3">𝑗</ci></apply></apply><apply id="S3.E5.m1.1.2.3.1.cmml" xref="S3.E5.m1.1.2.3.2"><csymbol cd="latexml" id="S3.E5.m1.1.2.3.1.1.cmml" xref="S3.E5.m1.1.2.3.2.1">cases</csymbol><matrix id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><matrixrow id="S3.E5.m1.1.1a.cmml" xref="S3.E5.m1.1.1"><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><ci id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.2">𝑀</ci><ci id="S3.E5.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.3">′</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.2.3"><times id="S3.E5.m1.1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2.3.1"></times><ci id="S3.E5.m1.1.1.1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.E5.m1.1.1.1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.3.2">𝑓</ci><apply id="S3.E5.m1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3.3"><times id="S3.E5.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.3.3.1"></times><ci id="S3.E5.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.3.3.2">𝑖</ci><ci id="S3.E5.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3.3.3">𝑘</ci></apply></apply></apply><apply id="S3.E5.m1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.2.1"><neq id="S3.E5.m1.1.1.1.2.1.1.cmml" xref="S3.E5.m1.1.1.1.2.1.1"></neq><apply id="S3.E5.m1.1.1.1.2.1.2.cmml" xref="S3.E5.m1.1.1.1.2.1.2"><times id="S3.E5.m1.1.1.1.2.1.2.1.cmml" xref="S3.E5.m1.1.1.1.2.1.2.1"></times><ci id="S3.E5.m1.1.1.1.2.1.2.2a.cmml" xref="S3.E5.m1.1.1.1.2.1.2.2"><mtext id="S3.E5.m1.1.1.1.2.1.2.2.cmml" xref="S3.E5.m1.1.1.1.2.1.2.2">if</mtext></ci><ci id="S3.E5.m1.1.1.1.2.1.2.3.cmml" xref="S3.E5.m1.1.1.1.2.1.2.3">𝑗</ci></apply><ci id="S3.E5.m1.1.1.1.2.1.3.cmml" xref="S3.E5.m1.1.1.1.2.1.3">𝑘</ci></apply></matrixrow><matrixrow id="S3.E5.m1.1.1b.cmml" xref="S3.E5.m1.1.1"><apply id="S3.E5.m1.1.1.2.1.1.cmml" xref="S3.E5.m1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.1.1.cmml" xref="S3.E5.m1.1.1.2.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.2.1.1.2.cmml" xref="S3.E5.m1.1.1.2.1.1.2">𝑀</ci><apply id="S3.E5.m1.1.1.2.1.1.3.cmml" xref="S3.E5.m1.1.1.2.1.1.3"><times id="S3.E5.m1.1.1.2.1.1.3.1.cmml" xref="S3.E5.m1.1.1.2.1.1.3.1"></times><ci id="S3.E5.m1.1.1.2.1.1.3.2.cmml" xref="S3.E5.m1.1.1.2.1.1.3.2">𝑖</ci><ci id="S3.E5.m1.1.1.2.1.1.3.3.cmml" xref="S3.E5.m1.1.1.2.1.1.3.3">𝑗</ci></apply></apply><apply id="S3.E5.m1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.2.2.1"><eq id="S3.E5.m1.1.1.2.2.1.1.cmml" xref="S3.E5.m1.1.1.2.2.1.1"></eq><apply id="S3.E5.m1.1.1.2.2.1.2.cmml" xref="S3.E5.m1.1.1.2.2.1.2"><times id="S3.E5.m1.1.1.2.2.1.2.1.cmml" xref="S3.E5.m1.1.1.2.2.1.2.1"></times><ci id="S3.E5.m1.1.1.2.2.1.2.2a.cmml" xref="S3.E5.m1.1.1.2.2.1.2.2"><mtext id="S3.E5.m1.1.1.2.2.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2.1.2.2">if</mtext></ci><ci id="S3.E5.m1.1.1.2.2.1.2.3.cmml" xref="S3.E5.m1.1.1.2.2.1.2.3">𝑗</ci></apply><ci id="S3.E5.m1.1.1.2.2.1.3.cmml" xref="S3.E5.m1.1.1.2.2.1.3">𝑘</ci></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">M^{\prime}_{ij}=\left\{\begin{array}[]{ll}M^{\prime}_{ij}\cdot f_{ik}&amp;\textrm{%
if}\;j\neq k\\
M_{ij}&amp;\textrm{if}\;j=k\end{array}\right.</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = { start_ARRAY start_ROW start_CELL italic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ⋅ italic_f start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT end_CELL start_CELL if italic_j ≠ italic_k end_CELL end_ROW start_ROW start_CELL italic_M start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_CELL start_CELL if italic_j = italic_k end_CELL end_ROW end_ARRAY</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p10">
<p class="ltx_p" id="S3.SS2.SSS1.p10.2">This operation scales all elements in row <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p10.1.m1.1"><semantics id="S3.SS2.SSS1.p10.1.m1.1a"><mi id="S3.SS2.SSS1.p10.1.m1.1.1" xref="S3.SS2.SSS1.p10.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p10.1.m1.1b"><ci id="S3.SS2.SSS1.p10.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p10.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p10.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p10.1.m1.1d">italic_i</annotation></semantics></math> by the scaling factor created from element <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p10.2.m2.1"><semantics id="S3.SS2.SSS1.p10.2.m2.1a"><mi id="S3.SS2.SSS1.p10.2.m2.1.1" xref="S3.SS2.SSS1.p10.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p10.2.m2.1b"><ci id="S3.SS2.SSS1.p10.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p10.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p10.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p10.2.m2.1d">italic_k</annotation></semantics></math>. To ensure that the rows are a valid distribution, they are then renormalised using</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p11">
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S_{i}=\sum^{n}_{j=1}M_{ij}" class="ltx_Math" display="block" id="S3.E6.m1.1"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><msub id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.2.2" xref="S3.E6.m1.1.1.2.2.cmml">S</mi><mi id="S3.E6.m1.1.1.2.3" xref="S3.E6.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E6.m1.1.1.1" rspace="0.111em" xref="S3.E6.m1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><munderover id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.3.1.cmml"><mo id="S3.E6.m1.1.1.3.1.2.2" movablelimits="false" xref="S3.E6.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E6.m1.1.1.3.1.3" xref="S3.E6.m1.1.1.3.1.3.cmml"><mi id="S3.E6.m1.1.1.3.1.3.2" xref="S3.E6.m1.1.1.3.1.3.2.cmml">j</mi><mo id="S3.E6.m1.1.1.3.1.3.1" xref="S3.E6.m1.1.1.3.1.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.3.1.3.3" xref="S3.E6.m1.1.1.3.1.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.3.1.2.3" xref="S3.E6.m1.1.1.3.1.2.3.cmml">n</mi></munderover><msub id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><mi id="S3.E6.m1.1.1.3.2.2" xref="S3.E6.m1.1.1.3.2.2.cmml">M</mi><mrow id="S3.E6.m1.1.1.3.2.3" xref="S3.E6.m1.1.1.3.2.3.cmml"><mi id="S3.E6.m1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.3.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.3.2.3.1" xref="S3.E6.m1.1.1.3.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.3.2.3.3.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><apply id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.2.2">𝑆</ci><ci id="S3.E6.m1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.2.3">𝑖</ci></apply><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><apply id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.3.1">subscript</csymbol><apply id="S3.E6.m1.1.1.3.1.2.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.2.1.cmml" xref="S3.E6.m1.1.1.3.1">superscript</csymbol><sum id="S3.E6.m1.1.1.3.1.2.2.cmml" xref="S3.E6.m1.1.1.3.1.2.2"></sum><ci id="S3.E6.m1.1.1.3.1.2.3.cmml" xref="S3.E6.m1.1.1.3.1.2.3">𝑛</ci></apply><apply id="S3.E6.m1.1.1.3.1.3.cmml" xref="S3.E6.m1.1.1.3.1.3"><eq id="S3.E6.m1.1.1.3.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1.3.1"></eq><ci id="S3.E6.m1.1.1.3.1.3.2.cmml" xref="S3.E6.m1.1.1.3.1.3.2">𝑗</ci><cn id="S3.E6.m1.1.1.3.1.3.3.cmml" type="integer" xref="S3.E6.m1.1.1.3.1.3.3">1</cn></apply></apply><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2">𝑀</ci><apply id="S3.E6.m1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.3.2.3"><times id="S3.E6.m1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.3.1"></times><ci id="S3.E6.m1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.3.2.3.2">𝑖</ci><ci id="S3.E6.m1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.3.2.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">S_{i}=\sum^{n}_{j=1}M_{ij}</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ∑ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT italic_M start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p12">
<p class="ltx_p" id="S3.SS2.SSS1.p12.1">to get the sum of each row and then divide by each element in that row</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p13">
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="M^{\prime\prime}_{ij}=\frac{M^{\prime}_{ij}}{S_{i}}" class="ltx_Math" display="block" id="S3.E7.m1.1"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><msubsup id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.2.2.2" xref="S3.E7.m1.1.1.2.2.2.cmml">M</mi><mrow id="S3.E7.m1.1.1.2.3" xref="S3.E7.m1.1.1.2.3.cmml"><mi id="S3.E7.m1.1.1.2.3.2" xref="S3.E7.m1.1.1.2.3.2.cmml">i</mi><mo id="S3.E7.m1.1.1.2.3.1" xref="S3.E7.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.2.3.3" xref="S3.E7.m1.1.1.2.3.3.cmml">j</mi></mrow><mo id="S3.E7.m1.1.1.2.2.3" xref="S3.E7.m1.1.1.2.2.3.cmml">′′</mo></msubsup><mo id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml">=</mo><mfrac id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml"><msubsup id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.3.2.2.2" xref="S3.E7.m1.1.1.3.2.2.2.cmml">M</mi><mrow id="S3.E7.m1.1.1.3.2.3" xref="S3.E7.m1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.1.1.3.2.3.2" xref="S3.E7.m1.1.1.3.2.3.2.cmml">i</mi><mo id="S3.E7.m1.1.1.3.2.3.1" xref="S3.E7.m1.1.1.3.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.3.2.3.3" xref="S3.E7.m1.1.1.3.2.3.3.cmml">j</mi></mrow><mo id="S3.E7.m1.1.1.3.2.2.3" xref="S3.E7.m1.1.1.3.2.2.3.cmml">′</mo></msubsup><msub id="S3.E7.m1.1.1.3.3" xref="S3.E7.m1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.2" xref="S3.E7.m1.1.1.3.3.2.cmml">S</mi><mi id="S3.E7.m1.1.1.3.3.3" xref="S3.E7.m1.1.1.3.3.3.cmml">i</mi></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><eq id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"></eq><apply id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.2">subscript</csymbol><apply id="S3.E7.m1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.2.2.1.cmml" xref="S3.E7.m1.1.1.2">superscript</csymbol><ci id="S3.E7.m1.1.1.2.2.2.cmml" xref="S3.E7.m1.1.1.2.2.2">𝑀</ci><ci id="S3.E7.m1.1.1.2.2.3.cmml" xref="S3.E7.m1.1.1.2.2.3">′′</ci></apply><apply id="S3.E7.m1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.2.3"><times id="S3.E7.m1.1.1.2.3.1.cmml" xref="S3.E7.m1.1.1.2.3.1"></times><ci id="S3.E7.m1.1.1.2.3.2.cmml" xref="S3.E7.m1.1.1.2.3.2">𝑖</ci><ci id="S3.E7.m1.1.1.2.3.3.cmml" xref="S3.E7.m1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"><divide id="S3.E7.m1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.3"></divide><apply id="S3.E7.m1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.3.2">subscript</csymbol><apply id="S3.E7.m1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.2.1.cmml" xref="S3.E7.m1.1.1.3.2">superscript</csymbol><ci id="S3.E7.m1.1.1.3.2.2.2.cmml" xref="S3.E7.m1.1.1.3.2.2.2">𝑀</ci><ci id="S3.E7.m1.1.1.3.2.2.3.cmml" xref="S3.E7.m1.1.1.3.2.2.3">′</ci></apply><apply id="S3.E7.m1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.3.2.3"><times id="S3.E7.m1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.1.1.3.2.3.1"></times><ci id="S3.E7.m1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.1.1.3.2.3.2">𝑖</ci><ci id="S3.E7.m1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.1.1.3.2.3.3">𝑗</ci></apply></apply><apply id="S3.E7.m1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.2">𝑆</ci><ci id="S3.E7.m1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">M^{\prime\prime}_{ij}=\frac{M^{\prime}_{ij}}{S_{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.1d">italic_M start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = divide start_ARG italic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG start_ARG italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p14">
<p class="ltx_p" id="S3.SS2.SSS1.p14.2">for all rows in the conditional matrix. Although <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p14.1.m1.1"><semantics id="S3.SS2.SSS1.p14.1.m1.1a"><mi id="S3.SS2.SSS1.p14.1.m1.1.1" xref="S3.SS2.SSS1.p14.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p14.1.m1.1b"><ci id="S3.SS2.SSS1.p14.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p14.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p14.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p14.1.m1.1d">italic_k</annotation></semantics></math> can be any state, in this paper, only <math alttext="P(C|x)" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p14.2.m2.1"><semantics id="S3.SS2.SSS1.p14.2.m2.1a"><mrow id="S3.SS2.SSS1.p14.2.m2.1.1" xref="S3.SS2.SSS1.p14.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p14.2.m2.1.1.3" xref="S3.SS2.SSS1.p14.2.m2.1.1.3.cmml">P</mi><mo id="S3.SS2.SSS1.p14.2.m2.1.1.2" xref="S3.SS2.SSS1.p14.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS1.p14.2.m2.1.1.1.1" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.2" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.2.cmml">C</mi><mo fence="false" id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.1" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.3" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p14.2.m2.1b"><apply id="S3.SS2.SSS1.p14.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1"><times id="S3.SS2.SSS1.p14.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.2"></times><ci id="S3.SS2.SSS1.p14.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.3">𝑃</ci><apply id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p14.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p14.2.m2.1c">P(C|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p14.2.m2.1d">italic_P ( italic_C | italic_x )</annotation></semantics></math> will be adjusted. This approach can be critiqued as being a somewhat blunt instrument. Still, it is conceptually easy to understand and computationally cheap, making it ideal for this exploration of synthetic data for training LMs to perform CLOCR-C.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p15">
<p class="ltx_p" id="S3.SS2.SSS1.p15.1">An in-depth exploration of the implications of this corruption model is beyond the scope of this paper. However, it is worth noting that, as the output sequences are a probability distribution, the observed CER for a uniformly corrupted text will itself have a probability distribution centred approximately on</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p16">
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(\textrm{CER}|X)\approx 1-\sum P(C|x)P(\hat{x}|X)" class="ltx_Math" display="block" id="S3.E8.m1.3"><semantics id="S3.E8.m1.3a"><mrow id="S3.E8.m1.3.3" xref="S3.E8.m1.3.3.cmml"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.3" xref="S3.E8.m1.1.1.1.3.cmml">P</mi><mo id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mo id="S3.E8.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mtext id="S3.E8.m1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.2a.cmml">CER</mtext><mo fence="false" id="S3.E8.m1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.3.cmml">X</mi></mrow><mo id="S3.E8.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.3.3.4" xref="S3.E8.m1.3.3.4.cmml">≈</mo><mrow id="S3.E8.m1.3.3.3" xref="S3.E8.m1.3.3.3.cmml"><mn id="S3.E8.m1.3.3.3.4" xref="S3.E8.m1.3.3.3.4.cmml">1</mn><mo id="S3.E8.m1.3.3.3.3" rspace="0.055em" xref="S3.E8.m1.3.3.3.3.cmml">−</mo><mrow id="S3.E8.m1.3.3.3.2" xref="S3.E8.m1.3.3.3.2.cmml"><mo id="S3.E8.m1.3.3.3.2.3" movablelimits="false" xref="S3.E8.m1.3.3.3.2.3.cmml">∑</mo><mrow id="S3.E8.m1.3.3.3.2.2" xref="S3.E8.m1.3.3.3.2.2.cmml"><mi id="S3.E8.m1.3.3.3.2.2.4" xref="S3.E8.m1.3.3.3.2.2.4.cmml">P</mi><mo id="S3.E8.m1.3.3.3.2.2.3" xref="S3.E8.m1.3.3.3.2.2.3.cmml">⁢</mo><mrow id="S3.E8.m1.2.2.2.1.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.1.1.cmml"><mo id="S3.E8.m1.2.2.2.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.2.2.2.1.1.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.1.1.cmml"><mi id="S3.E8.m1.2.2.2.1.1.1.1.1.2" xref="S3.E8.m1.2.2.2.1.1.1.1.1.2.cmml">C</mi><mo fence="false" id="S3.E8.m1.2.2.2.1.1.1.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E8.m1.2.2.2.1.1.1.1.1.3" xref="S3.E8.m1.2.2.2.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E8.m1.2.2.2.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E8.m1.3.3.3.2.2.3a" xref="S3.E8.m1.3.3.3.2.2.3.cmml">⁢</mo><mi id="S3.E8.m1.3.3.3.2.2.5" xref="S3.E8.m1.3.3.3.2.2.5.cmml">P</mi><mo id="S3.E8.m1.3.3.3.2.2.3b" xref="S3.E8.m1.3.3.3.2.2.3.cmml">⁢</mo><mrow id="S3.E8.m1.3.3.3.2.2.2.1" xref="S3.E8.m1.3.3.3.2.2.2.1.1.cmml"><mo id="S3.E8.m1.3.3.3.2.2.2.1.2" stretchy="false" xref="S3.E8.m1.3.3.3.2.2.2.1.1.cmml">(</mo><mrow id="S3.E8.m1.3.3.3.2.2.2.1.1" xref="S3.E8.m1.3.3.3.2.2.2.1.1.cmml"><mover accent="true" id="S3.E8.m1.3.3.3.2.2.2.1.1.2" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2.cmml"><mi id="S3.E8.m1.3.3.3.2.2.2.1.1.2.2" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2.2.cmml">x</mi><mo id="S3.E8.m1.3.3.3.2.2.2.1.1.2.1" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2.1.cmml">^</mo></mover><mo fence="false" id="S3.E8.m1.3.3.3.2.2.2.1.1.1" xref="S3.E8.m1.3.3.3.2.2.2.1.1.1.cmml">|</mo><mi id="S3.E8.m1.3.3.3.2.2.2.1.1.3" xref="S3.E8.m1.3.3.3.2.2.2.1.1.3.cmml">X</mi></mrow><mo id="S3.E8.m1.3.3.3.2.2.2.1.3" stretchy="false" xref="S3.E8.m1.3.3.3.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.3b"><apply id="S3.E8.m1.3.3.cmml" xref="S3.E8.m1.3.3"><approx id="S3.E8.m1.3.3.4.cmml" xref="S3.E8.m1.3.3.4"></approx><apply id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><times id="S3.E8.m1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.2"></times><ci id="S3.E8.m1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.3">𝑃</ci><apply id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.2a.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2"><mtext id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2">CER</mtext></ci><ci id="S3.E8.m1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3">𝑋</ci></apply></apply><apply id="S3.E8.m1.3.3.3.cmml" xref="S3.E8.m1.3.3.3"><minus id="S3.E8.m1.3.3.3.3.cmml" xref="S3.E8.m1.3.3.3.3"></minus><cn id="S3.E8.m1.3.3.3.4.cmml" type="integer" xref="S3.E8.m1.3.3.3.4">1</cn><apply id="S3.E8.m1.3.3.3.2.cmml" xref="S3.E8.m1.3.3.3.2"><sum id="S3.E8.m1.3.3.3.2.3.cmml" xref="S3.E8.m1.3.3.3.2.3"></sum><apply id="S3.E8.m1.3.3.3.2.2.cmml" xref="S3.E8.m1.3.3.3.2.2"><times id="S3.E8.m1.3.3.3.2.2.3.cmml" xref="S3.E8.m1.3.3.3.2.2.3"></times><ci id="S3.E8.m1.3.3.3.2.2.4.cmml" xref="S3.E8.m1.3.3.3.2.2.4">𝑃</ci><apply id="S3.E8.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E8.m1.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.2">𝐶</ci><ci id="S3.E8.m1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.3">𝑥</ci></apply><ci id="S3.E8.m1.3.3.3.2.2.5.cmml" xref="S3.E8.m1.3.3.3.2.2.5">𝑃</ci><apply id="S3.E8.m1.3.3.3.2.2.2.1.1.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1"><csymbol cd="latexml" id="S3.E8.m1.3.3.3.2.2.2.1.1.1.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1.1.1">conditional</csymbol><apply id="S3.E8.m1.3.3.3.2.2.2.1.1.2.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2"><ci id="S3.E8.m1.3.3.3.2.2.2.1.1.2.1.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2.1">^</ci><ci id="S3.E8.m1.3.3.3.2.2.2.1.1.2.2.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1.1.2.2">𝑥</ci></apply><ci id="S3.E8.m1.3.3.3.2.2.2.1.1.3.cmml" xref="S3.E8.m1.3.3.3.2.2.2.1.1.3">𝑋</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.3c">P(\textrm{CER}|X)\approx 1-\sum P(C|x)P(\hat{x}|X)</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.3d">italic_P ( CER | italic_X ) ≈ 1 - ∑ italic_P ( italic_C | italic_x ) italic_P ( over^ start_ARG italic_x end_ARG | italic_X )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p17">
<p class="ltx_p" id="S3.SS2.SSS1.p17.3">which is one minus the joint probability of the characters being correct for input sequence <math alttext="X" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p17.1.m1.1"><semantics id="S3.SS2.SSS1.p17.1.m1.1a"><mi id="S3.SS2.SSS1.p17.1.m1.1.1" xref="S3.SS2.SSS1.p17.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p17.1.m1.1b"><ci id="S3.SS2.SSS1.p17.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p17.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p17.1.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p17.1.m1.1d">italic_X</annotation></semantics></math> and observed character distribution <math alttext="\hat{x}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p17.2.m2.1"><semantics id="S3.SS2.SSS1.p17.2.m2.1a"><mover accent="true" id="S3.SS2.SSS1.p17.2.m2.1.1" xref="S3.SS2.SSS1.p17.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p17.2.m2.1.1.2" xref="S3.SS2.SSS1.p17.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS2.SSS1.p17.2.m2.1.1.1" xref="S3.SS2.SSS1.p17.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p17.2.m2.1b"><apply id="S3.SS2.SSS1.p17.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p17.2.m2.1.1"><ci id="S3.SS2.SSS1.p17.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p17.2.m2.1.1.1">^</ci><ci id="S3.SS2.SSS1.p17.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p17.2.m2.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p17.2.m2.1c">\hat{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p17.2.m2.1d">over^ start_ARG italic_x end_ARG</annotation></semantics></math>, which may differ from the character distribution <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p17.3.m3.1"><semantics id="S3.SS2.SSS1.p17.3.m3.1a"><mi id="S3.SS2.SSS1.p17.3.m3.1.1" xref="S3.SS2.SSS1.p17.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p17.3.m3.1b"><ci id="S3.SS2.SSS1.p17.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p17.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p17.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p17.3.m3.1d">italic_x</annotation></semantics></math> learned during the training.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Process Implementation</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">The corruption function has been implemented in Python as a library called <code class="ltx_verbatim ltx_font_typewriter" id="S3.SS2.SSS2.p1.1.1">scrambledtext</code>. The process requires only parallel OCR texts that have been line-aligned; the learned conditional corruption probabilities can be easily exported as JSON files and passed between projects. In addition, as the process is based on adjacent symbols, the process is language and script agnostic.
The library has two main classes, <code class="ltx_verbatim ltx_font_typewriter" id="S3.SS2.SSS2.p1.1.2">ProbabilityDistributions</code>, which learns the corruption conditional probability distributions, and <code class="ltx_verbatim ltx_font_typewriter" id="S3.SS2.SSS2.p1.1.3">CorruptionEngine</code>, which uses the learned corruption distributions to corrupt text. The library is lightweight, relying only on Python libraries included in the standard distribution, and is easily extensible using class inheritance.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Application of the model</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">The model is trained using the BLN600, SMH and CA datasets, which are used to try to create diversity in the observed errors. Each dataset’s OCR and ground truth texts are character aligned using the <code class="ltx_verbatim ltx_font_typewriter" id="S3.SS2.SSS3.p1.1.1">genalog</code> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gupte_lights_2021</span>]</cite>. The texts are then sequentially loaded, and the conditional distributions are learned. Once the distributions have been learned, they are saved as a JSON file for use in the rest of the project. With the conditional probabilities learned, text can now be arbitrarily corrupted. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T1" title="Table 1 ‣ 3.2.3 Application of the model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example of text <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lovelace_sketch_1842</span>]</cite> being corrupted from CER = 0 to CER = 0.5. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T1" title="Table 1 ‣ 3.2.3 Application of the model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a> shows both the Target CER that the corruption function was aiming for and the Observed CER of the output sequence and drift from character insertions. The difference is due to the stochastic nature of the process.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>As can be seen as the corruption function increases the CER, the text becomes increasingly illegible</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.1.1" style="width:43.4pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1.1.1">Target CER</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.2.1">
<span class="ltx_p" id="S3.T1.1.1.1.2.1.1" style="width:60.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1.1.1">Observed CER</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.3.1">
<span class="ltx_p" id="S3.T1.1.1.1.3.1.1" style="width:303.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1.1.1">Corrupted Text</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.1.1">
<span class="ltx_p" id="S3.T1.1.2.1.1.1.1" style="width:43.4pt;">0.00</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.2.1">
<span class="ltx_p" id="S3.T1.1.2.1.2.1.1" style="width:60.7pt;">0.00</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.3.1">
<span class="ltx_p" id="S3.T1.1.2.1.3.1.1" style="width:303.5pt;">We may say most aptly that the Analytical Engine weaves algebraical patterns just as the Jacquard-loom weaves flowers and leaves.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.1.1">
<span class="ltx_p" id="S3.T1.1.3.2.1.1.1" style="width:43.4pt;">0.10</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.2.1">
<span class="ltx_p" id="S3.T1.1.3.2.2.1.1" style="width:60.7pt;">0.09</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.3.1">
<span class="ltx_p" id="S3.T1.1.3.2.3.1.1" style="width:303.5pt;">We may say mot aptly tAt tho Analytical Engine wedaves Talgebraical patterns just as theJacquard-lom weaves fowrs anld leavesi</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.1.1">
<span class="ltx_p" id="S3.T1.1.4.3.1.1.1" style="width:43.4pt;">0.20</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.2.1">
<span class="ltx_p" id="S3.T1.1.4.3.2.1.1" style="width:60.7pt;">0.20</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.3.1">
<span class="ltx_p" id="S3.T1.1.4.3.3.1.1" style="width:303.5pt;">We may san mest puly thab th e Analyticel Engrte weFaves ealgebr’airal Fpttens just a ihe J acquard-loofwcves flowers antd lleaves. 1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.1.1">
<span class="ltx_p" id="S3.T1.1.5.4.1.1.1" style="width:43.4pt;">0.30</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.2.1">
<span class="ltx_p" id="S3.T1.1.5.4.2.1.1" style="width:60.7pt;">0.28</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.3.1">
<span class="ltx_p" id="S3.T1.1.5.4.3.1.1" style="width:303.5pt;">Wcelay say mtost apteJy -thnt tha AndasyTlical E1ninewcaves algeibiacalf pattetnsa yus t -as t heo .Jaeqaard-loomweaovesflowers an-d leaves.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.5.1.1">
<span class="ltx_p" id="S3.T1.1.6.5.1.1.1" style="width:43.4pt;">0.40</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.5.2.1">
<span class="ltx_p" id="S3.T1.1.6.5.2.1.1" style="width:60.7pt;">0.47</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.5.3.1">
<span class="ltx_p" id="S3.T1.1.6.5.3.1.1" style="width:303.5pt;">ge mnay dsa most arpti tha-ihie A natlyei..cil Ea-gire Twiea1yes rglbrd;ienl settias ojis as- ’lhe Jtcnad-loom wteaveml lloweia iand Ple-ave .’</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.7.6.1.1">
<span class="ltx_p" id="S3.T1.1.7.6.1.1.1" style="width:43.4pt;">0.50</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.7.6.2.1">
<span class="ltx_p" id="S3.T1.1.7.6.2.1.1" style="width:60.7pt;">0.62</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.7.6.3.1">
<span class="ltx_p" id="S3.T1.1.7.6.3.1.1" style="width:303.5pt;">W.e may ’sav tosmt aptdy rl1 ltiit fSe k.nal riclI-En-ggn taa-we ,\eragoeibraac1lplate,,lns g”a– aa.thie oJsciaa.rd.-loo-ml Cvv,evosfl-ower1s aad ave.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">With the method of corruption defined, the process for generating the synthetic articles, and overall dataset, which will be corrupted is described.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Synthetic Data</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The data is created by prompting a Language model (in this case GPT4o) to write a piece of text under a set of guidelines. The prompt is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T3" title="Table 3 ‣ 3.3 Synthetic Data ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The prompt is populated by replacing the bold words in curly braces with appropriate descriptors. The descriptors can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T3" title="Table 3 ‣ 3.3 Synthetic Data ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a> </figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">Synthetic text generation prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.1.1.1">
<span class="ltx_p" id="S3.T2.1.2.1.1.1.1" style="width:390.3pt;">It is the year <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.1">{year}</span>. Using the text provided below surrounded by triple #, write a <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.2">{word_count}</span> word <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.3">{writing_style}</span> <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.4">{text_type}</span> with a <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.5">{sentiment}</span> sentiment, the persona of the writer is <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.6">{persona}</span>, the reading level should be <span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1.1.1.7">{complexity}</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S3.T2.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.3.2.1.1">
<span class="ltx_p" id="S3.T2.1.3.2.1.1.1" style="width:390.3pt;">Note: The resultant text may be distasteful to modern readers, that is ok. Respond only in plain text, do not use markdown</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S3.T2.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.4.3.1.1">
<span class="ltx_p" id="S3.T2.1.4.3.1.1.1" style="width:390.3pt;">###</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S3.T2.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.5.4.1.1">
<span class="ltx_p" id="S3.T2.1.5.4.1.1.1" style="width:390.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.4.1.1.1.1">{text}</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S3.T2.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.1.6.5.1.1">
<span class="ltx_p" id="S3.T2.1.6.5.1.1.1" style="width:390.3pt;">###</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">The seven words inside curly braces, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T3" title="Table 3 ‣ 3.3 Synthetic Data ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a>, are the variables used to create diversity between the texts. The seed prompt, shown as ‘{text}’ in the prompt, was obtained by downloading the Wikipedia timeline of the 19th century and the timeline of British diplomacy in the 19th century; combining both lists created xx events to describe. These timelines provide a brief description of an actual 19th-century event, which could then be styled by the rest of the prompt. The variables used for prompt styling were chosen to be appropriate for the 19th century and are shown in table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T3" title="Table 3 ‣ 3.3 Synthetic Data ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a>; there are 3888 possible combinations of text styling. The timeline and prompt variables were then sampled 11,000 times, and the text generated by GPT-4o. This resulted in a corpus of 11,000 texts with 3.5 million words. To create a more manageable training set, a random substring of text 200 tokens long is removed from each article; this is used to create a 10,000-observation training set where each observation is of consistent length. The remaining 1000 observations are split between a test an validation set, but are not used in this project. An example of a prompt an the resultant article are shown in Supplementary material Section 3, the synthetic data can be downloaded from <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_scrambled_2024</span>]</cite>.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Variables and options used in the prompt template</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.1">Variable</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.1.1.2.1">
<span class="ltx_p" id="S3.T3.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.2.1.1.1">Options</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.2.1.1.1">text type</span></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T3.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.2.1.2.1">
<span class="ltx_p" id="S3.T3.1.2.1.2.1.1">newspaper article, obituary of a named person, editorial, book excerpt, letter to the editor, personal diary entry</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.3.2.1.1">writing style</span></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T3.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.3.2.2.1">
<span class="ltx_p" id="S3.T3.1.3.2.2.1.1">formal, informal, satirical, religious, polemic, romantic, persuasive, descriptive</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.3.1.1">persona</span></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T3.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.4.3.2.1">
<span class="ltx_p" id="S3.T3.1.4.3.2.1.1">general public, women’s rights, politics, economics and trade, military, reactionary, chartist, clergy, arts and culture</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T3.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.5.4.1.1">sentiment</span></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T3.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.5.4.2.1">
<span class="ltx_p" id="S3.T3.1.5.4.2.1.1">positive, neutral, negative</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T3.1.6.5.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.6.5.1.1">complexity</span></th>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S3.T3.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.1.6.5.2.1">
<span class="ltx_p" id="S3.T3.1.6.5.2.1.1">simple, moderate, advanced</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Having provided an overview of the dataset and evaluation metrics, the models and training parameters used throughout the experiments is introduced.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>The Llama Model and training parameters</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">This paper constrains the number of experiments by not attempting to optimise the model’s performance but rather to explore the influence of the training synthetic data on performance. This Data Centric modelling <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">strickland_andrew_2022</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zha_data-centric_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">salehi_data-centric_2024</span>]</cite> approach means that we need only evaluate one model architecture and that the parameters of the model can be fixed so that the impact of changes in the data is clear.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">We use the Llama-3.1 8B instruct <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dubey_llama_2024</span>]</cite> an 8 Billion parameter model which, at the time of writing, was one of the top performing models of its size class. Like most current top-performing models, Llama is an autoregressive (or causal) decoder-only model based on the transformer architecture. In addition, the model has an open licence, making fine-tuning and distribution of the resultant models possible.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">In relation to the discussion of PEFT in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S1" title="1 Introduction ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a>, this paper will use LoRA <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hu_lora_2021</span>]</cite>, specifically Rank Stabilised LoRA <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kalajdzievski_rank_2023</span>]</cite> which has been shown to produce better results than the original LoRA approach.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">The model will be trained using the Huggingface framework and the Unsloth <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">han_unsloth_2024</span>]</cite> implementation of Llama. Training will use the lightning.ai platform, the GPU will be a 24Gb Nvidia L4. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T4" title="Table 4 ‣ 3.4 The Llama Model and training parameters ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">4</span></a> shows the most important hyper-parameters used in the training. The hyper-parameters were chosen to ensure that the model would not exceed the 24Gb RAM of the GPU; from this perspective, setting the context length was most important from experiments 1024 was chosen as it would be able to handle the tokens produced by all levels of corruption, detail on this choice can be seen in supplementary material Figure 1. After an appropriate context window was found, the batch size and LoRA parameters could be chosen. For a full list of hyper-parameters, see the code.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Hyper-parameters used in the model.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.1.1">Hyper-parameter</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.2.1">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T4.1.2.1.1">LoRA Rank</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.1.2.1.2">64</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.3.2.1">LoRa Alpha</th>
<td class="ltx_td ltx_align_center" id="S3.T4.1.3.2.2">32</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.4.3.1">Learning rate</th>
<td class="ltx_td ltx_align_center" id="S3.T4.1.4.3.2">5e-5</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.5.4.1">Epochs</th>
<td class="ltx_td ltx_align_center" id="S3.T4.1.5.4.2">1</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.6.5.1">Scheduler</th>
<td class="ltx_td ltx_align_center" id="S3.T4.1.6.5.2">AdamW 8-bit</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.7.6.1">Batch size</th>
<td class="ltx_td ltx_align_center" id="S3.T4.1.7.6.2">16</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T4.1.8.7.1">Context window</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.1.8.7.2">1024</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">with the experimental framework defined, the experiments themselves are introduced and defined.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Experimental setup</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">This section describes the 3 different experiments performed in this paper, producing a total of 68 models. First, the level of corruption and the distribution of corruption is explored. Then, the impact of the length of text vs the number of observations is investigated. Finally, a comparison between models trained on synthetic data and real data is performed.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.1 </span>Corruption level, and corruption distribution</h4>
<div class="ltx_para" id="S3.SS5.SSS1.p1">
<p class="ltx_p" id="S3.SS5.SSS1.p1.1">A fundamental question when using synthetic data to fine-tune an LM to learn how to do CLOCR-C is how much error is necessary and how should the error be distributed? This paper explores the topic using three experiments: first, by simply uniformly increasing the CER across the dataset; second, by varying the relationship between CER and WER; and finally, by combining CER and WER levels within the dataset. A more detailed description of the parameters are shown in the bullet points below. Given the extreme levels of corruption shown for CER = 0.5 shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T1" title="Table 1 ‣ 3.2.3 Application of the model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a>, having a CER level much beyond 0.4 produces almost complete nonsense; as such, this paper will focus on the lower end of the CER scale.
The question this series of experiments seeks to answer is “what corruption parameters provide the biggest improvement to model performance?”</p>
</div>
<div class="ltx_para" id="S3.SS5.SSS1.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Data is corrupted with a fixed conditional probability such that the mean CER of the text is one of nine possible values, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Using a grid of WER-CER pairs, data is corrupted across a WER range of 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7 for a target CER of 0.05, 0.1, 0.2, 0.3, 0.4.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Data is corrupted such that the dataset is constructed from a mixture of CER levels, where the samples are equally distributed between CER levels of 0-0.1, 0.1-0.2, 0.2-0.3, and 0.3-0.4. Each group makes up 25% of the dataset. The WER level will be controlled by sampling from the empirical WER distribution for that CER group from the combination of the BLN600, CA and SMH datasets. A second model will be created the same as described but with uncorrupted data as a fifth group, each group making up 20% of the dataset.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS5.SSS1.p3">
<p class="ltx_p" id="S3.SS5.SSS1.p3.1">This set of experiments will produce 46 models, 9 CER-only experiments, 35 CER-WER experiments, and 2 multi-CER-WER models.</p>
</div>
<div class="ltx_para" id="S3.SS5.SSS1.p4">
<p class="ltx_p" id="S3.SS5.SSS1.p4.1">It should be noted that as CER increases for a given WER, the relative corruption of the words being corrupted increases disproportionately. This means the document CER and the CER of the corrupted words may differ, which may play a role in the fine-tuned model’s overall performance. One can say that the CER of the corrupted words is the “effective CER” of the text. For the corruption function used in this paper, the effective CER saturates at 1.5. When CER is saturated, the solution to the problem is similar to masked language modelling, given the assumption that the text is all real words. However, a deeper exploration of these links is beyond the scope of this paper. More details on the relationship between CER-WER pairs and effective CER can be found in supplementary material in Figure 2.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.2 </span>Text length vs number of observations</h4>
<div class="ltx_para" id="S3.SS5.SSS2.p1">
<p class="ltx_p" id="S3.SS5.SSS2.p1.1">Given that a CER-WER combination can be found that provides sufficient improvement in the test set, it is valuable to investigate whether other factors beyond the corruption type play a role in the performance of the LM at CLOCR-C. Two critical elements in the training of the LM are the length of the text supplied and the number of observations. This will be explored by modifying the total number of tokens in the training set and also the total number of tokens per observation. These two parameters will be varied according to Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T5" title="Table 5 ‣ 3.5.2 Text length vs number of observations ‣ 3.5 Experimental setup ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">5</span></a>. This experiment will produce 36 token text length pairs, from which we will gain insight into the importance of text length and token volume. An example of the different token lengths is shown in supplementary material section 3.</p>
</div>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>The models will be trained using different combinations of text length and token budget. The table shows the number of data observations for a given observation token length and total token combination.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T5.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T5.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="S3.T5.1.1.1.2">Tokens per observation</th>
</tr>
<tr class="ltx_tr" id="S3.T5.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S3.T5.1.2.2.1">Total Tokens</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T5.1.2.2.2">200</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T5.1.2.2.3">100</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T5.1.2.2.4">50</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T5.1.2.2.5">25</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T5.1.2.2.6">10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T5.1.3.1.1">1,638,400</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T5.1.3.1.2">8,192</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T5.1.3.1.3">16,384</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T5.1.3.1.4">32,768</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T5.1.3.1.5">65,536</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T5.1.3.1.6">163,840</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.4.2.1">819,200</th>
<td class="ltx_td ltx_align_right" id="S3.T5.1.4.2.2">4,096</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.4.2.3">8,192</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.4.2.4">16,384</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.4.2.5">32,768</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.4.2.6">81,920</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.5.3.1">409,600</th>
<td class="ltx_td ltx_align_right" id="S3.T5.1.5.3.2">2,048</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.5.3.3">4,096</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.5.3.4">8,192</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.5.3.5">16,384</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.5.3.6">40,960</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.6.4.1">204,800</th>
<td class="ltx_td ltx_align_right" id="S3.T5.1.6.4.2">1,024</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.6.4.3">2,048</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.6.4.4">4,096</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.6.4.5">8,192</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.6.4.6">20,480</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.7.5.1">102,400</th>
<td class="ltx_td ltx_align_right" id="S3.T5.1.7.5.2">512</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.7.5.3">1,024</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.7.5.4">2,048</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.7.5.5">4,096</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.7.5.6">10,240</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.8.6.1">51,200</th>
<td class="ltx_td ltx_align_right" id="S3.T5.1.8.6.2">256</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.8.6.3">512</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.8.6.4">1,024</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.8.6.5">2,048</td>
<td class="ltx_td ltx_align_right" id="S3.T5.1.8.6.6">5,120</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T5.1.9.7.1">25,600</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T5.1.9.7.2">128</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T5.1.9.7.3">256</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T5.1.9.7.4">512</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T5.1.9.7.5">1,024</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T5.1.9.7.6">2,560</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS5.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.3 </span>Between dataset comparison</h4>
<div class="ltx_para" id="S3.SS5.SSS3.p1">
<p class="ltx_p" id="S3.SS5.SSS3.p1.1">Three models will be created, one for each of the datasets, BLN600, SMH, and CA. The performance of these models will be compared to synthetic data, the original dataset, the Base Llama3 model, and the current state-of-the-art Claude Opus. This comparison will provide insight into the relative performance of synthetic data vs available training data. The CA and SMH data have been transcribed with line breaks, making splitting the datasets easier; these two datasets will be split such that the median tokens per observation in the ground truth are 200, the same as the synthetic training set. As SMH and CA are small datasets, they will also be combined into a single Overproof dataset named after the project in which they were transcribed. The BLN600 data is not line aligned but has already been turned into a dataset using sequence matching <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">thomas_leveraging_nodate</span>]</cite>, however, the median tokens per sequence in the ground truth dataset is 26</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">All models with uniform synthetic CER reduced the WER on the NCSE dataset. The CER was minimised when the synthetic training data had a CER of 0.2, close to the median CER of 0.17 of the NCSE dataset, as well as the 0.05 model.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F3" title="Figure 3 ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performance of the models trained on synthetic data from different CER-WER combinations. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F3" title="Figure 3 ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3</span></a>, the performance of the baseline Llama3 model is shown with a solid red lines whilst the original NCSE dataset average is shown with a dashed red line. The figure shows that whilst all models reduced error compared to the baseline WER and most models beat the Baseline Llama3, reducing the CER relative to the NCSE dataset was much more difficult. Primarily, models trained with low levels of CER were more likely to reduce the overall CER; however, there was not such a clear pattern with the WER values. A key factor of OCR errors is that the range of errors can be large and have considerably different impact on the text (see Table<a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.T1" title="Table 1 ‣ 3.2.3 Application of the model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">1</span></a> for examples). The mean CER of the top ten models was 0.14 and the WER was 0.28; which is a an error reduction percentage of 21% and 55% respectively relative to the NCSE test dataset, and an improvement of CER 5̄5% and WER4̄1% relative to the Baseline Llama model.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The text was split at the median CER into high and low corruption subsets to explore the practical significance of the difference in overall CER on model performance. The High-low split was at CER = 0.17, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F4" title="Figure 4 ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">4</span></a>. What Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F4" title="Figure 4 ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">4</span></a> reveals is that there is a very large difference in the corruption, with the lower group having a median CER of 0.06 compared to the high corruption group’s CER of 0.61. Models that perform well in the low corruption group all have very low target CER values, typically 0.05 or 0.1</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="622" id="S4.F3.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Solid red lines show the performance of the baseline Llama3 model, and the dashed red line shows the median CER of the NCSE dataset. Across the whole NCSE dataset, most models outperformed the baseline Llama3. Still, few managed to reduce the CER compared to the NCSE average of 0.17.</figcaption>
</figure>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">In other words, the base Llama model increases the median error of the OCR data on average across the dataset except if the dataset is split into low and high corruption halves, in which case the base Llama model improves BOTH the high and low corruption sub-sets. This situation appears bizarre and reminiscent of Simpson’s paradox <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">simpson_interpretation_1951</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">blyth_simpsons_1972</span>]</cite>. However, it can be explained by considering the CER distribution of the NCSE dataset as a Gaussian-mixture model of two components. When partitioned at the midpoint, the lower distribution is heavily right-skewed, with the centre of mass close to the lower limit, whilst the upper distribution is more normally distributed, with the centre of mass shifted away from the 0.17 lower limit. When viewed as a whole dataset, the mean CER of the base Llama3 model and the original dataset are both approximately 0.32, but their median values diverge.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">In addition to the paradoxical appearance of model performance, the types of fine-tuned models that perform well are also very different. The low-corruption dataset was improved most by models trained on low-corruption data, whilst the high-corruption dataset was improved most by models trained on moderately corrupted data. This is interesting as it adds nuance to the findings of <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rychalska_models_2019</span>]</cite>, who suggested that corruption should be at least as bad; these findings indicate that there may be an upper limit to corruption for successfully training models to correct OCR.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="332" id="S4.F4.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The figure shows the contrast in performance when looking at only the High (CER<math alttext="&gt;" class="ltx_Math" display="inline" id="S4.F4.3.m1.1"><semantics id="S4.F4.3.m1.1b"><mo id="S4.F4.3.m1.1.1" xref="S4.F4.3.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.F4.3.m1.1c"><gt id="S4.F4.3.m1.1.1.cmml" xref="S4.F4.3.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.m1.1d">&gt;</annotation><annotation encoding="application/x-llamapun" id="S4.F4.3.m1.1e">&gt;</annotation></semantics></math>0.17) and low (CER<math alttext="\leq" class="ltx_Math" display="inline" id="S4.F4.4.m2.1"><semantics id="S4.F4.4.m2.1b"><mo id="S4.F4.4.m2.1.1" xref="S4.F4.4.m2.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S4.F4.4.m2.1c"><leq id="S4.F4.4.m2.1.1.cmml" xref="S4.F4.4.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m2.1d">\leq</annotation><annotation encoding="application/x-llamapun" id="S4.F4.4.m2.1e">≤</annotation></semantics></math>0.17) corruption. The red lines show the performance of the base Llama model.</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Tokens per observation and total tokens in dataset</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Given the results discussed in the previous section, the model trained with CER0̄.1 and WER = 0.2 was chosen as the base for the tokens-per-observations and tokens-in-training-set experiment.
The results of the experiment can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F5" title="Figure 5 ‣ 4.1 Tokens per observation and total tokens in dataset ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">5</span></a> which shows the interaction between The two variables. Looking at the left panel of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F5" title="Figure 5 ‣ 4.1 Tokens per observation and total tokens in dataset ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">5</span></a> the relationship between number of tokens and CER is difficult to see, it appears that there is substantial noise in the results, with only 200 tokens per observation models showing any discernible trend. Such an observation contrasts with the right panel, which shows how CER changes with increased tokens per observation. Here, the CER reduces up to the maximum of 200 tokens per observation.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="S4.F5.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The figures shown here illustrate the interaction between the number of tokens per observation and the total number of tokens in the whole training set. Increasing the number of tokens in the dataset improves model performance. However, the impact of the total number of tokens can be difficult given the overall level of noise</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparing models trained on different datasets</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F6" title="Figure 6 ‣ 4.2 Comparing models trained on different datasets ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">6</span></a>, the synthetic data outperforms all models trained on real data, both in terms of WER and CER. In addition, it is worth noting that the BLN600 data did not perform much better than the baseline, which could be related to the short token lengths of the sequenced text. In addition, whilst the larger SMH dataset outperformed the CA dataset, the combined CA and SMH dataset was the best performing of the three but, interestingly, only really improved on WER, not CER. It should be noted that from <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>, the State of the art is Claude Opus, which had a CER of 0.07 and a WER of 0.15, substantially outperforming the synthetic data. Similar to the earlier analysis, the data was split into high and low corruption; the synthetic data performed best with the low corruption but dropped to third in the high corruption subset. In contrast, the BLN600 went from last on the low corruption subset to first on the high corruption subset, outperforming the base Llama by 8 percentage points. A figure showing the high-low split is shown in supplementary material 4.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="622" id="S4.F6.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>When comparing models the model trained on synthetic data against the models trained on several existing datasets, the advantages of the synthetic data are clear with a lower CER and WER.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The use of synthetic data for fine-tuning LM’s to perform CLOCR-C has produced several findings. First, using synthetic data does improve the performance of an LM on real OCR data; the median performance of the top 10 models produced improved the CER of the base Llama model by 55% and the WER by 32%. Second, it is not only the amount of synthetic data that is important but also the distribution of the corruption in the data. Third, it is important to have enough tokens for each observation.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.3">Beyond the main finding that synthetic data can be used to fine-tune LMs to perform CLOCR-C, it was interesting to observe how the data distribution played an important role in the final performance. Models with relatively low levels of corruption (CER<math alttext="&lt;0.2" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mrow id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml"></mi><mo id="S5.p2.1.m1.1.1.1" xref="S5.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><lt id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">absent</csymbol><cn id="S5.p2.1.m1.1.1.3.cmml" type="float" xref="S5.p2.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">&lt;0.2</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">&lt; 0.2</annotation></semantics></math>) and WER in the low to mid-range (<math alttext="0.2&lt;" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><mrow id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mn id="S5.p2.2.m2.1.1.2" xref="S5.p2.2.m2.1.1.2.cmml">0.2</mn><mo id="S5.p2.2.m2.1.1.1" xref="S5.p2.2.m2.1.1.1.cmml">&lt;</mo><mi id="S5.p2.2.m2.1.1.3" xref="S5.p2.2.m2.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><lt id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1.1"></lt><cn id="S5.p2.2.m2.1.1.2.cmml" type="float" xref="S5.p2.2.m2.1.1.2">0.2</cn><csymbol cd="latexml" id="S5.p2.2.m2.1.1.3.cmml" xref="S5.p2.2.m2.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">0.2&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">0.2 &lt;</annotation></semantics></math>WER<math alttext="&lt;0.6" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><mrow id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml"><mi id="S5.p2.3.m3.1.1.2" xref="S5.p2.3.m3.1.1.2.cmml"></mi><mo id="S5.p2.3.m3.1.1.1" xref="S5.p2.3.m3.1.1.1.cmml">&lt;</mo><mn id="S5.p2.3.m3.1.1.3" xref="S5.p2.3.m3.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><apply id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1"><lt id="S5.p2.3.m3.1.1.1.cmml" xref="S5.p2.3.m3.1.1.1"></lt><csymbol cd="latexml" id="S5.p2.3.m3.1.1.2.cmml" xref="S5.p2.3.m3.1.1.2">absent</csymbol><cn id="S5.p2.3.m3.1.1.3.cmml" type="float" xref="S5.p2.3.m3.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">&lt;0.6</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">&lt; 0.6</annotation></semantics></math>) seemed to perform well, with the best models reducing CER by 30% and WER by 60%. Part of this reason may be the different drivers of text correction for texts with low or high levels of corruption. For highly corrupted text, simply getting words right improves the WER. Still, substantial reductions may not be possible due to the lack of information in the text. In contrast, at low levels of corruption, the CER is improved by LM acting as what is effectively a contextual spell check; however, as the error rate is so low, a single incorrect word can have a large relative impact on overall performance.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">When training LMs, a general rule is that more diverse data leads to better-performing models. Therefore, it was surprising that the blended models had lackluster performance, with neither managing to beat the baseline median CER of 0.17. This unexpected result suggests that a better approach than training a single model on a mixture of data might be to train a mixture of experts model. Such an approach could work better as it would be able to explicitly route tasks to sub-models trained on data in the appropriate corruption range, sparking further curiosity and engagement in the field.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">The exploration of the length of training context was revealing and supported the findings of <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dubey_llama_2024</span>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite>, as models trained on observations with fewer tokens performed worse than those trained with more tokens, even though the total token training budget was fixed.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">In this paper, the models were trained on text strings of 200 tokens; this is substantially less than most of the articles in the test set; it may be that, at inference time, some of the longer texts were corrected poorly due to the length itself and not the error distribution. However, such an investigation is beyond the scope of this paper. Another limitation of the paper is that the corruption function does not transpose entire words; this is a common feature of OCR errors. However, <code class="ltx_verbatim ltx_font_typewriter" id="S5.p5.1.1">scrambledtext</code> could be combined with approaches such as WildNLP <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rychalska_models_2019</span>]</cite> in a pipeline to include transposition.</p>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">Comparing the models showed how valuable synthetic data is, with the synthetic model outperforming all the real datasets. Whilst it can be said that synthetic data had an advantage in training on more tokens than the other models, this is one of the key advantages of synthetic data. The comparison also highlighted the challenge faced in creating real datasets, especially when using automatic sequencing, which is a common approach <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">thomas_leveraging_nodate</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chiron_icdar2017_2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jiang_gutenberg-hathitrust_2021</span>]</cite>. One interesting advantage that SMH and CA datasets was being line aligned; this allowed the data to be broken into almost arbitrary lengths of coherent text, something that is not possible with either <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_clocr-c_2024</span>]</cite> or <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">booth_bln600_2024</span>]</cite>. The fact that <code class="ltx_verbatim ltx_font_typewriter" id="S5.p6.1.1">scrambledtext</code> can flexibly corrupt data independent of the amount of corruption in the text it was trained on shows the value of using a Markov model, which can be easily re-normalised to tune the corruption to the desired amount.</p>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.1">Although the synthetic data performed very well, it is still a way off beating current SOTA Claude Opus, which scored a CER of 0.07 and WER of 0.15, compared to the synth dataset’s CER = 0.12 and WER 0.26 on the same dataset. A significant portion of the gap between Opus and the synthetically trained Llama model is the number of parameters, with Opus likely two orders of magnitude larger. Training and architecture could play a role, but as Opus is not an open-source model, exploring these differences is likely impossible.</p>
</div>
<div class="ltx_para" id="S5.p8">
<p class="ltx_p" id="S5.p8.1">One element of the process that could be improved to close the gap with the state of the art is the corruption function itself. The method described in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S3.SS2.SSS1" title="3.2.1 The Markov Model ‣ 3.2 ScrambledText: Creating the Markov Corruption Process ‣ 3 Method ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">3.2.1</span></a> is very simple and may explain the relatively poor performance compared to the other datasets in the high corruption subset. Perhaps a more sophisticated or nuanced approach may produce more realistic errors, improving model performance across the corruption range.</p>
</div>
<div class="ltx_para" id="S5.p9">
<p class="ltx_p" id="S5.p9.1">Although this paper shed light on how to train LMs to perform CLOCR-C it did not provide any insight into the mechanisms by which the LM’s perform the task. The question is therefore still open as to whether the LM is essentially acting as a stochastic parrot <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bender_dangers_2021</span>]</cite> or whether it is using a more fundamental understanding of language. This is an interesting question given the recent research by <span class="ltx_ERROR undefined" id="S5.p9.1.1">\textcite</span>kallini_mission_2024 into how LMs respond to impossible languages. It may be that one of the mechanisms used in CLOCR-C is that through fine-tuning, the LM gains some understanding of the structure of the “impossible language” that is the OCR errors and learns to relate this to its already existing language representation and, in doing reveal the latent “real language” masked by the errors. Further work could probe this aspect as advances could provide insight into LM language understanding and optimising for CLOCR-C.</p>
</div>
<div class="ltx_para" id="S5.p10">
<p class="ltx_p" id="S5.p10.1">Finally although this paper did not seek to optimise the performance the findings open the door for work exploring optimisation and model architecture comparison. This is made easier because, as is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.19735v1#S4.F5" title="Figure 5 ‣ 4.1 Tokens per observation and total tokens in dataset ‣ 4 Results ‣ Scrambled text: training Language Models to correct OCR errors using synthetic data"><span class="ltx_text ltx_ref_tag">5</span></a>, the model trained on observations of 200 tokens still beats the baseline when trained on only 512 examples, roughly 5% of the full dataset dramatically reducing training cost. Such work could then more concretely compare CLOCR-C with synthetic data against the state of the art.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Recommendations for training CLOCR-C models</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Given the results of the paper, below are some heuristics to consider when using synthetic data to train CLOCR-C models.</p>
</div>
<div class="ltx_para" id="S6.p2">
<ol class="ltx_enumerate" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1">Know your data: Model performance is dependent on the corruption level of the data were trained on and are being applied to. Having an idea of the overall level of corruption in the data can help tune the synthetic data to maximise model performance.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1">Corruption level: Train models on relatively low levels of corruption, a global CER of between 5-20% should produce good results on most texts.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S6.I1.i3.p1">
<p class="ltx_p" id="S6.I1.i3.p1.1">Not enough corruption is better than too much: When creating synthetic data, training on overly corrupted data produces worse results than somewhat under-corrupted data.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S6.I1.i4.p1">
<p class="ltx_p" id="S6.I1.i4.p1.1">Corruption distribution: Concentrating corruption into fewer words generally gives better results than spreading the corruption more evenly; this may be because the effect is more similar to masked language modelling and so is more challenging. A CER-WER pair that gives an effective CER between 0.2 and 0.6 seems to perform well.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S6.I1.i5.p1">
<p class="ltx_p" id="S6.I1.i5.p1.1">Synthetic text length: For a fixed token budget, having fewer observations containing more tokens provides better model performance than having more observations comprising fewer tokens.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="S6.I1.i6.p1">
<p class="ltx_p" id="S6.I1.i6.p1.1">Amount of observations: Modern LMs are very well trained and don’t need many examples; training on 1000 or fewer examples (low 100k tokens, not millions) is reasonable, possibly less than 500; however, with so few examples, the difference in training time will be a few minutes so better to err on the side of caution and, at least initially stick to a slightly higher number before working your way down if necessary.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="S6.I1.i7.p1">
<p class="ltx_p" id="S6.I1.i7.p1.1">Drop heavily corrupted texts: Depending on the distribution of your data, it may be worth splitting the dataset into lightly and heavily corrupted datasets or dropping the heavily corrupted texts entirely. This is because models appear to specialise in one of the two types, and lightly corrupted models have a significantly larger relative increase in quality compared to heavily corrupted texts, which may be corrected to something semantically different to the original, causing issues in downstream analysis.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span>
<div class="ltx_para" id="S6.I1.i8.p1">
<p class="ltx_p" id="S6.I1.i8.p1.1">BONUS! Line align your texts at transcription: Whilst not strictly part of synthetic data, it is still a valuable consideration. Line aligning means that text can be much more easily broken into sub-sequences without relying on automatic sequencing algorithms. Line-aligned text can also be used to split test-sets, creating more observations allowing better diagnostics on why models perform better or worse in various scenarios.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This paper has shown that Language Models can be fine-tuned to perform Context Leveraging OCR Correction on entirely synthetic data. That is, training data from texts generated using a language model and then corrupted using a learned Markov corruption function. This has the potential to substantially reduce the time and cost necessary to perform an OCR correction project on a digital archive and supports the findings of previous work on training LMs with synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gunasekar_textbooks_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li_textbooks_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tan_15-pints_2024</span>]</cite> but applied to the OCR correction domain.
The experiments developed here resulted in 68 fine-tuned models and provided a comprehensive exploration of the parameter space, which gave sufficient insight into the behaviour of the LM trained using synthetic data to allow for the creation of 8 heuristics to guide practitioners when training a CLOCR-C model. The symbol agnostic, <code class="ltx_verbatim ltx_font_typewriter" id="S7.p1.1.1">scrambledtext</code> package, makes it easy to generate synthetically corrupted training texts in any language. This paper indicates that the cost of fine-tuning a model of 8 Billion parameters is low, in the range of 10 cents to a few dollars, and the bulk of the cost of a recovery project will come from inference. As such, those seeking to recover corrupted archives should focus on efficient inference strategies. These strategies may involve taking advantage of advancements in model architecture <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shah_flashattention-3_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gu_mamba_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dao_transformers_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma_era_2024</span>]</cite> or hardware <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sambanova_accelerated_2021</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hall_training_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang_optimized_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">nvidia_nvidia_2024</span>]</cite>.
Overall, it is hoped that the findings of this paper have made it easier to create CLOCR-C models and, as such, easier to recover quality archival texts in resource-constrained projects.
perform</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Data Availability</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The <code class="ltx_verbatim ltx_font_typewriter" id="Sx1.p1.1.1">scrambledtext</code> library is available from <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/JonnoB/scrambledtext</span>, The synthetic articles and other data are available from the UCL data repository <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bourne_scrambled_2024</span>]</cite>, the github repo of the main code is available from <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/JonnoB/scrambledtext_analysis</span>, a repo of code used for training the models is available from <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/JonnoB/training_lms_with_synthetic_data</span> and can be launched directly as a lightning.ai studio.</p>
</div>
<div class="ltx_para" id="Sx1.p2">
<span class="ltx_ERROR undefined" id="Sx1.p2.1">\printbibliography</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Sep 29 15:16:21 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
