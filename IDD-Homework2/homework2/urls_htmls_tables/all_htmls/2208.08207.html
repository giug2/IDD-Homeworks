<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.08207] Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data</title><meta property="og:description" content="The vast progress in synthetic image synthesis enables the generation of facial images in high resolution and photorealism. In biometric applications, the main motivation for using synthetic data is to solve the shorta…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.08207">

<!--Generated on Wed Mar 13 19:38:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn" lang="en">
<h1 class="ltx_title ltx_title_document">Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcel Grimmer <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>NTNU, Norwegian Biometrics Laboratory, Gjøvik, marceg@ntnu.no</span></span></span>   Haoyu Zhang <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>NTNU, Norwegian Biometrics Laboratory, Gjøvik, haoyu.zhang@ntnu.no</span></span></span>  
Raghavendra Ramachandra<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>NTNU, Norwegian Biometrics Laboratory, Gjøvik, raghavendra.ramachandra@ntnu.no</span></span></span>  
Kiran Raja<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>NTNU, Norwegian Biometrics Laboratory, Gjøvik, kiran.raja@ntnu.no</span></span></span>  
Christoph Busch<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>h-da, Biometric and Internet-Security Research Group, Darmstadt, christoph.busch@h-da.de</span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">The vast progress in synthetic image synthesis enables the generation of facial images in high resolution and photorealism. In biometric applications, the main motivation for using synthetic data is to solve the shortage of publicly-available biometric data while reducing privacy risks when processing such sensitive information. These advantages are exploited in this work by simulating human face ageing with recent face age modification algorithms to generate mated samples, thereby studying the impact of ageing on the performance of an open-source biometric recognition system. Further, a real dataset is used to evaluate the effects of short-term ageing, comparing the biometric performance to the synthetic domain. The main findings indicate that short-term ageing in the range of 1-5 years has only minor effects on the general recognition performance. However, the correct verification of mated faces with long-term age differences beyond 20 years poses still a significant challenge and requires further investigation.</span></p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
<span id="id2.id1" class="ltx_text">
Synthetic Data, Face Age Modification, Face Recognition
</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The deployment of face recognition systems has gained popularity in various application scenarios, such as border control initiatives like the European Entry-Exit System (EES) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">Eu19</a>]</cite>. In particular, the EES will be used as a central system for collecting and querying traveller data to the Schengen area at all border crossing points to facilitate the cooperation of visa and law enforcement authorities. The biometric performance of a system deployed in such sensitive environments must comply with high standards, such as those defined in the best practices for automated border control of the European Border and Coast Guard Agency (Frontex) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Fr15</a>]</cite>. At the same time, the European General Data Protection Law complicates the processing of biometric data to avoid privacy leakages. 
<br class="ltx_break">Without an appropriate performance testing strategy, the risk of security lapses increases significantly and allows for the discriminatory treatment of travellers due to algorithmic or dataset bias. One solution to the lack of available test data includes the generation of synthetic data samples. However, in order to conduct reliable biometric performance tests, the synthetic samples must be as similar as possible to data collected in operational environments.
<br class="ltx_break">In the context of synthetic face images, the main focus of this work is to analyse the impact of human face ageing on biometric recognition performance. Due to the 10-year validity of EU passports and enrolment records in immigration systems, face recognition engines employed at the EU borders are frequently exposed to mated face comparisons captured over long time spans. This work deepens the understanding of recognition accuracy and face ageing by analysing synthetically generated face images rendered with ageing effects. This work relies on face age modification methods to avoid the time-consuming data collection of mated samples over time. 
<br class="ltx_break">This analysis is based on face age manipulation frameworks operating within the latent space of StyleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">KLA19</a>]</cite> and StyleGAN2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">Ka20</a>]</cite>: InterFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">Sh20</a>]</cite> and SAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">APCO21</a>]</cite>. The choice of these techniques is motivated by the high realism and resolution (1024x1024) of facial images the StyleGAN generator achieves. The age-modified face images are analysed with two different face quality assessment algorithms (FQAAs): FaceQnet v1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">He20</a>]</cite> and SER-FIQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">Te20</a>]</cite>. The biometric performance is further evaluated by computing mated and non-mated comparison scores with ArcFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">De19</a>]</cite>. The breakdown of mated comparison scores into age bins enables precise testing of the weaknesses of existing face recognition engines. Further, the <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">UNCW face ageing dataset</span> (also <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">MORPH-II</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">RT06</a>]</cite> is used as a reference for comparing short-term ageing effects to those ageing effects achieved in the synthetic domain. 
<br class="ltx_break">This work is structured as follows: A brief introduction of the face age modification frameworks used to generate the synthetic datasets is given in Section 2. The characteristics of the synthetic and reference datasets are described in Section 3. Finally, the experimental results are presented in Section 4, analysing the FAM ageing accuracy, the biometric quality and comparison scores of synthetic and bona fide data.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Face Age Modification</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section introduces the basic terms and methods used to create the synthetic cross-age datasets analysed in this work. Face age progression (FAP) refers to rendering from a given input image a synthetic face image with ageing effects, while face age regression (FAR) corresponds to the prediction of rejuvenation effects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">GRB21</a>]</cite>. Typically, recent face age modification (FAM) methods predict the appearance of an individual based on a given target age. Another type of FAM technique focuses on changing the age of subjects on a continuous scale with the motivation to better approximate the nature of human ageing. This work evaluates the impact of face ageing on a face recognition (FR) system, using two state-of-the-art FAM frameworks: SAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">APCO21</a>]</cite> and InterFaceGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">Sh20</a>]</cite>. 
<br class="ltx_break">Both FAM frameworks are based on manipulating latent vectors in the latent space of StyleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">KLA19</a>]</cite> and StyleGAN2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">Ka20</a>]</cite>. The main idea is to exploit the disentanglement of facial attributes given in the internal data representation of a generative adversarial network (GAN). Operating directly in the latent space of a pre-trained GAN alleviates the need to train complex adversarial networks and benefits from the high resolution and photorealism achieved by the StyleGAN generators.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2208.08207/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="165" height="78" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Latent face ageing with SAM and InterFaceGAN</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The basic FAM principles of SAM and InterFaceGAN are illustrated in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Face Age Modification ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The main question is where to move the randomly drawn latent vector to change the age while leaving other facial attributes unchanged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Gr21</a>]</cite>. InterFaceGAN addresses this issue by training a binary age boundary that divides the latent space into two subspaces (old vs young). Afterwards, the age is increased by moving an arbitrary latent vector into the perpendicular direction of the age boundary, with the magnitude defining the ageing extent. 
<br class="ltx_break">Unlike InterFaceGAN, SAM trains an additional age encoder conditioned on the target age <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="\alpha_{t}" display="inline"><semantics id="S2.p2.1.m1.1a"><msub id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mi id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">α</mi><mi id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">𝛼</ci><ci id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\alpha_{t}</annotation></semantics></math>, extracting the missing ageing patterns by learning the residuals to the original face image. In a next step, a pre-trained map2style network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">Ri21</a>]</cite> transforms the residual ageing patterns into latent codes, which are then fused with the initial latent vector randomly drawn from the latent space. After fusing the residual age patterns with the initial latent vector, the resulting latent code is passed to the StyleGAN2 generator to generate the age-modified face image.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Datasets</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section introduces the synthetic cross-age datasets generated with InterFaceGAN and SAM, as well as the bona fide reference datasets (FRGC v2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Ph05</a>]</cite>, UNCW ageing dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">RT06</a>]</cite>).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Synthetic Dataset Generation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.5" class="ltx_p">Our base synthetic data is randomly generated by the StyleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">KLA19</a>]</cite> generator pre-trained on the FFHQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">KLA19</a>]</cite> dataset. Choosing a truncation factor of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\psi=0.75" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">ψ</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><eq id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></eq><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝜓</ci><cn type="float" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\psi=0.75</annotation></semantics></math> has proven as an effective setup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Zh21</a>]</cite> for generating visually appealing face images with a high diversity of demographic factors. Further, the work of Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Zh21</a>]</cite> indicates minor differences in the face recognition performance between StyleGAN and StyleGAN2 generated face images. Therefore, we select a dataset of <math id="S3.SS1.p1.2.m2.2" class="ltx_Math" alttext="50,000" display="inline"><semantics id="S3.SS1.p1.2.m2.2a"><mrow id="S3.SS1.p1.2.m2.2.3.2" xref="S3.SS1.p1.2.m2.2.3.1.cmml"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">50</mn><mo id="S3.SS1.p1.2.m2.2.3.2.1" xref="S3.SS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><list id="S3.SS1.p1.2.m2.2.3.1.cmml" xref="S3.SS1.p1.2.m2.2.3.2"><cn type="integer" id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">50</cn><cn type="integer" id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">50,000</annotation></semantics></math> face images generated with StyleGAN as a basis for our face age modification algorithms. 
<br class="ltx_break">Given these synthetic base images, the corresponding age-modified samples are generated using the proposed semantic editing algorithms of Shen et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">Sh20</a>]</cite> (InterFaceGAN) and Alaluf et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">APCO21</a>]</cite>. As shown in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Face Age Modification ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, InterFaceGAN controls the shifting distance in the latent space with a scaling factor that we empirically set as <math id="S3.SS1.p1.3.m3.3" class="ltx_Math" alttext="s_{1}\pm 0.4,s_{2}\pm 0.8,s_{3}\pm 1.2" display="inline"><semantics id="S3.SS1.p1.3.m3.3a"><mrow id="S3.SS1.p1.3.m3.3.3.3" xref="S3.SS1.p1.3.m3.3.3.4.cmml"><mrow id="S3.SS1.p1.3.m3.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.cmml"><msub id="S3.SS1.p1.3.m3.1.1.1.1.2" xref="S3.SS1.p1.3.m3.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.3.m3.1.1.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.1.1.2.2.cmml">s</mi><mn id="S3.SS1.p1.3.m3.1.1.1.1.2.3" xref="S3.SS1.p1.3.m3.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.3.m3.1.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">±</mo><mn id="S3.SS1.p1.3.m3.1.1.1.1.3" xref="S3.SS1.p1.3.m3.1.1.1.1.3.cmml">0.4</mn></mrow><mo id="S3.SS1.p1.3.m3.3.3.3.4" xref="S3.SS1.p1.3.m3.3.3.4.cmml">,</mo><mrow id="S3.SS1.p1.3.m3.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.cmml"><msub id="S3.SS1.p1.3.m3.2.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.3.m3.2.2.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.2.2.cmml">s</mi><mn id="S3.SS1.p1.3.m3.2.2.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.3.m3.2.2.2.2.1" xref="S3.SS1.p1.3.m3.2.2.2.2.1.cmml">±</mo><mn id="S3.SS1.p1.3.m3.2.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.2.2.3.cmml">0.8</mn></mrow><mo id="S3.SS1.p1.3.m3.3.3.3.5" xref="S3.SS1.p1.3.m3.3.3.4.cmml">,</mo><mrow id="S3.SS1.p1.3.m3.3.3.3.3" xref="S3.SS1.p1.3.m3.3.3.3.3.cmml"><msub id="S3.SS1.p1.3.m3.3.3.3.3.2" xref="S3.SS1.p1.3.m3.3.3.3.3.2.cmml"><mi id="S3.SS1.p1.3.m3.3.3.3.3.2.2" xref="S3.SS1.p1.3.m3.3.3.3.3.2.2.cmml">s</mi><mn id="S3.SS1.p1.3.m3.3.3.3.3.2.3" xref="S3.SS1.p1.3.m3.3.3.3.3.2.3.cmml">3</mn></msub><mo id="S3.SS1.p1.3.m3.3.3.3.3.1" xref="S3.SS1.p1.3.m3.3.3.3.3.1.cmml">±</mo><mn id="S3.SS1.p1.3.m3.3.3.3.3.3" xref="S3.SS1.p1.3.m3.3.3.3.3.3.cmml">1.2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.3b"><list id="S3.SS1.p1.3.m3.3.3.4.cmml" xref="S3.SS1.p1.3.m3.3.3.3"><apply id="S3.SS1.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1">plus-or-minus</csymbol><apply id="S3.SS1.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2.2">𝑠</ci><cn type="integer" id="S3.SS1.p1.3.m3.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.3">0.4</cn></apply><apply id="S3.SS1.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2"><csymbol cd="latexml" id="S3.SS1.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.1">plus-or-minus</csymbol><apply id="S3.SS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2.2">𝑠</ci><cn type="integer" id="S3.SS1.p1.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2.3">2</cn></apply><cn type="float" id="S3.SS1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.3">0.8</cn></apply><apply id="S3.SS1.p1.3.m3.3.3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3"><csymbol cd="latexml" id="S3.SS1.p1.3.m3.3.3.3.3.1.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.1">plus-or-minus</csymbol><apply id="S3.SS1.p1.3.m3.3.3.3.3.2.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.3.3.3.3.2.1.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.3.3.3.3.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.2.2">𝑠</ci><cn type="integer" id="S3.SS1.p1.3.m3.3.3.3.3.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.2.3">3</cn></apply><cn type="float" id="S3.SS1.p1.3.m3.3.3.3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3.3.3.3">1.2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.3c">s_{1}\pm 0.4,s_{2}\pm 0.8,s_{3}\pm 1.2</annotation></semantics></math> to create 6 synthetic data subsets containing mated samples of the base images. 
<br class="ltx_break">As introduced in Section <a href="#S2" title="2 Face Age Modification ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the input of SAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">APCO21</a>]</cite> is a target age and a base image. We select 7 different target age groups (10, 20, 30, 40, 50, 60, 70) to which we transform the base synthetic images to. In the original SAM algorithm, the pixel2style2pixel (pSp) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">Ri21</a>]</cite> encoder is applied to first project the base images into the extended StyleGAN2 latent space (<math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="W+" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">W</mi><mo id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">+</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="latexml" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">limit-from</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝑊</ci><plus id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">W+</annotation></semantics></math>) in order to fuse it with the encoded age residual code. In this work, we discard the initial base image as soon as it is projected to the <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="W+" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">W</mi><mo id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">+</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="latexml" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">limit-from</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝑊</ci><plus id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">W+</annotation></semantics></math> latent space, re-defining the reconstructed face image as our new base in order to avoid the distortion of our results due to identity losses caused by GAN inversion. 
<br class="ltx_break">In this work, face images with unrealistic capturing conditions are filtered out to increase the representativeness of our datasets. Details of the filtering pipeline are given in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Synthetic Dataset Generation ‣ 3 Datasets ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For the inter-eye-distance (IED), a pre-trained landmark detection model is used to predict the centre of the eyes and filter out images with IED less than 90 pixels or failed landmark detections. To filter out images with unsatisfying illumination conditions, we prepare an internal dataset with binary labels (good or poor illumination condition) and train a random forest regressor on the extracted features that measure illumination uniformity and symmetry from these images. The Img2pose model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">Al21</a>]</cite> is applied to predict the Euler angles of the head pose and filter out images with extreme rotations. Additionally, we included C3AE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Zh19</a>]</cite> to predict the age of the given images and exclude those with ages not in the range of [13,59] years. Finally, Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Synthetic Dataset Generation ‣ 3 Datasets ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the exact number of face images in the analysed datasets - before and after applying the filtering pipeline.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.24" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:260.2pt;height:161pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.0pt,36.5pt) scale(0.687962963598068,0.687962963598068) ;">
<table id="S3.T1.24.24" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.24.24.25.1" class="ltx_tr">
<th id="S3.T1.24.24.25.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Dataset</th>
<th id="S3.T1.24.24.25.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">#Images before Filtering</th>
<th id="S3.T1.24.24.25.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">#Images after Filtering</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.2.2" class="ltx_tr">
<th id="S3.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">FRGC v2</th>
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.1.1.1.1.m1.2" class="ltx_Math" alttext="24,025" display="inline"><semantics id="S3.T1.1.1.1.1.m1.2a"><mrow id="S3.T1.1.1.1.1.m1.2.3.2" xref="S3.T1.1.1.1.1.m1.2.3.1.cmml"><mn id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">24</mn><mo id="S3.T1.1.1.1.1.m1.2.3.2.1" xref="S3.T1.1.1.1.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.1.1.1.1.m1.2.2" xref="S3.T1.1.1.1.1.m1.2.2.cmml">025</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.2b"><list id="S3.T1.1.1.1.1.m1.2.3.1.cmml" xref="S3.T1.1.1.1.1.m1.2.3.2"><cn type="integer" id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">24</cn><cn type="integer" id="S3.T1.1.1.1.1.m1.2.2.cmml" xref="S3.T1.1.1.1.1.m1.2.2">025</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.2c">24,025</annotation></semantics></math></td>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.2.2.2.2.m1.2" class="ltx_Math" alttext="17,919" display="inline"><semantics id="S3.T1.2.2.2.2.m1.2a"><mrow id="S3.T1.2.2.2.2.m1.2.3.2" xref="S3.T1.2.2.2.2.m1.2.3.1.cmml"><mn id="S3.T1.2.2.2.2.m1.1.1" xref="S3.T1.2.2.2.2.m1.1.1.cmml">17</mn><mo id="S3.T1.2.2.2.2.m1.2.3.2.1" xref="S3.T1.2.2.2.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.2.2.2.2.m1.2.2" xref="S3.T1.2.2.2.2.m1.2.2.cmml">919</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.2b"><list id="S3.T1.2.2.2.2.m1.2.3.1.cmml" xref="S3.T1.2.2.2.2.m1.2.3.2"><cn type="integer" id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">17</cn><cn type="integer" id="S3.T1.2.2.2.2.m1.2.2.cmml" xref="S3.T1.2.2.2.2.m1.2.2">919</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.2c">17,919</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.4.4.4" class="ltx_tr">
<th id="S3.T1.4.4.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Synthetic Base</th>
<td id="S3.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.3.3.3.1.m1.2" class="ltx_Math" alttext="50,000" display="inline"><semantics id="S3.T1.3.3.3.1.m1.2a"><mrow id="S3.T1.3.3.3.1.m1.2.3.2" xref="S3.T1.3.3.3.1.m1.2.3.1.cmml"><mn id="S3.T1.3.3.3.1.m1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.cmml">50</mn><mo id="S3.T1.3.3.3.1.m1.2.3.2.1" xref="S3.T1.3.3.3.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.3.3.3.1.m1.2.2" xref="S3.T1.3.3.3.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.2b"><list id="S3.T1.3.3.3.1.m1.2.3.1.cmml" xref="S3.T1.3.3.3.1.m1.2.3.2"><cn type="integer" id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">50</cn><cn type="integer" id="S3.T1.3.3.3.1.m1.2.2.cmml" xref="S3.T1.3.3.3.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.2c">50,000</annotation></semantics></math></td>
<td id="S3.T1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.4.4.4.2.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.4.4.4.2.m1.2a"><mrow id="S3.T1.4.4.4.2.m1.2.3.2" xref="S3.T1.4.4.4.2.m1.2.3.1.cmml"><mn id="S3.T1.4.4.4.2.m1.1.1" xref="S3.T1.4.4.4.2.m1.1.1.cmml">25</mn><mo id="S3.T1.4.4.4.2.m1.2.3.2.1" xref="S3.T1.4.4.4.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.4.4.4.2.m1.2.2" xref="S3.T1.4.4.4.2.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.2.m1.2b"><list id="S3.T1.4.4.4.2.m1.2.3.1.cmml" xref="S3.T1.4.4.4.2.m1.2.3.2"><cn type="integer" id="S3.T1.4.4.4.2.m1.1.1.cmml" xref="S3.T1.4.4.4.2.m1.1.1">25</cn><cn type="integer" id="S3.T1.4.4.4.2.m1.2.2.cmml" xref="S3.T1.4.4.4.2.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.2.m1.2c">25,918</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.6.6.6" class="ltx_tr">
<th id="S3.T1.6.6.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">InterFaceGAN (scale = 0.4)</th>
<td id="S3.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.5.5.5.1.m1.2" class="ltx_Math" alttext="51,836" display="inline"><semantics id="S3.T1.5.5.5.1.m1.2a"><mrow id="S3.T1.5.5.5.1.m1.2.3.2" xref="S3.T1.5.5.5.1.m1.2.3.1.cmml"><mn id="S3.T1.5.5.5.1.m1.1.1" xref="S3.T1.5.5.5.1.m1.1.1.cmml">51</mn><mo id="S3.T1.5.5.5.1.m1.2.3.2.1" xref="S3.T1.5.5.5.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.5.5.5.1.m1.2.2" xref="S3.T1.5.5.5.1.m1.2.2.cmml">836</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.2b"><list id="S3.T1.5.5.5.1.m1.2.3.1.cmml" xref="S3.T1.5.5.5.1.m1.2.3.2"><cn type="integer" id="S3.T1.5.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1">51</cn><cn type="integer" id="S3.T1.5.5.5.1.m1.2.2.cmml" xref="S3.T1.5.5.5.1.m1.2.2">836</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.2c">51,836</annotation></semantics></math></td>
<td id="S3.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.6.6.6.2.m1.2" class="ltx_Math" alttext="48,513" display="inline"><semantics id="S3.T1.6.6.6.2.m1.2a"><mrow id="S3.T1.6.6.6.2.m1.2.3.2" xref="S3.T1.6.6.6.2.m1.2.3.1.cmml"><mn id="S3.T1.6.6.6.2.m1.1.1" xref="S3.T1.6.6.6.2.m1.1.1.cmml">48</mn><mo id="S3.T1.6.6.6.2.m1.2.3.2.1" xref="S3.T1.6.6.6.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.6.6.6.2.m1.2.2" xref="S3.T1.6.6.6.2.m1.2.2.cmml">513</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.2.m1.2b"><list id="S3.T1.6.6.6.2.m1.2.3.1.cmml" xref="S3.T1.6.6.6.2.m1.2.3.2"><cn type="integer" id="S3.T1.6.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.6.2.m1.1.1">48</cn><cn type="integer" id="S3.T1.6.6.6.2.m1.2.2.cmml" xref="S3.T1.6.6.6.2.m1.2.2">513</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.2.m1.2c">48,513</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.8.8.8" class="ltx_tr">
<th id="S3.T1.8.8.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">InterFaceGAN (scale = 0.8)</th>
<td id="S3.T1.7.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.7.7.7.1.m1.2" class="ltx_Math" alttext="51,836" display="inline"><semantics id="S3.T1.7.7.7.1.m1.2a"><mrow id="S3.T1.7.7.7.1.m1.2.3.2" xref="S3.T1.7.7.7.1.m1.2.3.1.cmml"><mn id="S3.T1.7.7.7.1.m1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.cmml">51</mn><mo id="S3.T1.7.7.7.1.m1.2.3.2.1" xref="S3.T1.7.7.7.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.7.7.7.1.m1.2.2" xref="S3.T1.7.7.7.1.m1.2.2.cmml">836</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.2b"><list id="S3.T1.7.7.7.1.m1.2.3.1.cmml" xref="S3.T1.7.7.7.1.m1.2.3.2"><cn type="integer" id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1">51</cn><cn type="integer" id="S3.T1.7.7.7.1.m1.2.2.cmml" xref="S3.T1.7.7.7.1.m1.2.2">836</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.2c">51,836</annotation></semantics></math></td>
<td id="S3.T1.8.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.8.8.8.2.m1.2" class="ltx_Math" alttext="47,085" display="inline"><semantics id="S3.T1.8.8.8.2.m1.2a"><mrow id="S3.T1.8.8.8.2.m1.2.3.2" xref="S3.T1.8.8.8.2.m1.2.3.1.cmml"><mn id="S3.T1.8.8.8.2.m1.1.1" xref="S3.T1.8.8.8.2.m1.1.1.cmml">47</mn><mo id="S3.T1.8.8.8.2.m1.2.3.2.1" xref="S3.T1.8.8.8.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.8.8.8.2.m1.2.2" xref="S3.T1.8.8.8.2.m1.2.2.cmml">085</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.2.m1.2b"><list id="S3.T1.8.8.8.2.m1.2.3.1.cmml" xref="S3.T1.8.8.8.2.m1.2.3.2"><cn type="integer" id="S3.T1.8.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.8.2.m1.1.1">47</cn><cn type="integer" id="S3.T1.8.8.8.2.m1.2.2.cmml" xref="S3.T1.8.8.8.2.m1.2.2">085</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.2.m1.2c">47,085</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.10.10.10" class="ltx_tr">
<th id="S3.T1.10.10.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">InterFaceGAN (scale = 1.2)</th>
<td id="S3.T1.9.9.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.9.9.9.1.m1.2" class="ltx_Math" alttext="51,836" display="inline"><semantics id="S3.T1.9.9.9.1.m1.2a"><mrow id="S3.T1.9.9.9.1.m1.2.3.2" xref="S3.T1.9.9.9.1.m1.2.3.1.cmml"><mn id="S3.T1.9.9.9.1.m1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.cmml">51</mn><mo id="S3.T1.9.9.9.1.m1.2.3.2.1" xref="S3.T1.9.9.9.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.9.9.9.1.m1.2.2" xref="S3.T1.9.9.9.1.m1.2.2.cmml">836</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.2b"><list id="S3.T1.9.9.9.1.m1.2.3.1.cmml" xref="S3.T1.9.9.9.1.m1.2.3.2"><cn type="integer" id="S3.T1.9.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1">51</cn><cn type="integer" id="S3.T1.9.9.9.1.m1.2.2.cmml" xref="S3.T1.9.9.9.1.m1.2.2">836</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.2c">51,836</annotation></semantics></math></td>
<td id="S3.T1.10.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.10.10.10.2.m1.2" class="ltx_Math" alttext="44,858" display="inline"><semantics id="S3.T1.10.10.10.2.m1.2a"><mrow id="S3.T1.10.10.10.2.m1.2.3.2" xref="S3.T1.10.10.10.2.m1.2.3.1.cmml"><mn id="S3.T1.10.10.10.2.m1.1.1" xref="S3.T1.10.10.10.2.m1.1.1.cmml">44</mn><mo id="S3.T1.10.10.10.2.m1.2.3.2.1" xref="S3.T1.10.10.10.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.10.10.10.2.m1.2.2" xref="S3.T1.10.10.10.2.m1.2.2.cmml">858</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.2.m1.2b"><list id="S3.T1.10.10.10.2.m1.2.3.1.cmml" xref="S3.T1.10.10.10.2.m1.2.3.2"><cn type="integer" id="S3.T1.10.10.10.2.m1.1.1.cmml" xref="S3.T1.10.10.10.2.m1.1.1">44</cn><cn type="integer" id="S3.T1.10.10.10.2.m1.2.2.cmml" xref="S3.T1.10.10.10.2.m1.2.2">858</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.2.m1.2c">44,858</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.12.12.12" class="ltx_tr">
<th id="S3.T1.12.12.12.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 10)</th>
<td id="S3.T1.11.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.11.11.11.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.11.11.11.1.m1.2a"><mrow id="S3.T1.11.11.11.1.m1.2.3.2" xref="S3.T1.11.11.11.1.m1.2.3.1.cmml"><mn id="S3.T1.11.11.11.1.m1.1.1" xref="S3.T1.11.11.11.1.m1.1.1.cmml">25</mn><mo id="S3.T1.11.11.11.1.m1.2.3.2.1" xref="S3.T1.11.11.11.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.11.11.11.1.m1.2.2" xref="S3.T1.11.11.11.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.1.m1.2b"><list id="S3.T1.11.11.11.1.m1.2.3.1.cmml" xref="S3.T1.11.11.11.1.m1.2.3.2"><cn type="integer" id="S3.T1.11.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.11.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.11.11.11.1.m1.2.2.cmml" xref="S3.T1.11.11.11.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.12.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.12.12.12.2.m1.2" class="ltx_Math" alttext="18,290" display="inline"><semantics id="S3.T1.12.12.12.2.m1.2a"><mrow id="S3.T1.12.12.12.2.m1.2.3.2" xref="S3.T1.12.12.12.2.m1.2.3.1.cmml"><mn id="S3.T1.12.12.12.2.m1.1.1" xref="S3.T1.12.12.12.2.m1.1.1.cmml">18</mn><mo id="S3.T1.12.12.12.2.m1.2.3.2.1" xref="S3.T1.12.12.12.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.12.12.12.2.m1.2.2" xref="S3.T1.12.12.12.2.m1.2.2.cmml">290</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.2.m1.2b"><list id="S3.T1.12.12.12.2.m1.2.3.1.cmml" xref="S3.T1.12.12.12.2.m1.2.3.2"><cn type="integer" id="S3.T1.12.12.12.2.m1.1.1.cmml" xref="S3.T1.12.12.12.2.m1.1.1">18</cn><cn type="integer" id="S3.T1.12.12.12.2.m1.2.2.cmml" xref="S3.T1.12.12.12.2.m1.2.2">290</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.2.m1.2c">18,290</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.14.14.14" class="ltx_tr">
<th id="S3.T1.14.14.14.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 20)</th>
<td id="S3.T1.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.13.13.13.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.13.13.13.1.m1.2a"><mrow id="S3.T1.13.13.13.1.m1.2.3.2" xref="S3.T1.13.13.13.1.m1.2.3.1.cmml"><mn id="S3.T1.13.13.13.1.m1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.cmml">25</mn><mo id="S3.T1.13.13.13.1.m1.2.3.2.1" xref="S3.T1.13.13.13.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.13.13.13.1.m1.2.2" xref="S3.T1.13.13.13.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.2b"><list id="S3.T1.13.13.13.1.m1.2.3.1.cmml" xref="S3.T1.13.13.13.1.m1.2.3.2"><cn type="integer" id="S3.T1.13.13.13.1.m1.1.1.cmml" xref="S3.T1.13.13.13.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.13.13.13.1.m1.2.2.cmml" xref="S3.T1.13.13.13.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.14.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.14.14.14.2.m1.2" class="ltx_Math" alttext="22,671" display="inline"><semantics id="S3.T1.14.14.14.2.m1.2a"><mrow id="S3.T1.14.14.14.2.m1.2.3.2" xref="S3.T1.14.14.14.2.m1.2.3.1.cmml"><mn id="S3.T1.14.14.14.2.m1.1.1" xref="S3.T1.14.14.14.2.m1.1.1.cmml">22</mn><mo id="S3.T1.14.14.14.2.m1.2.3.2.1" xref="S3.T1.14.14.14.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.14.14.14.2.m1.2.2" xref="S3.T1.14.14.14.2.m1.2.2.cmml">671</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m1.2b"><list id="S3.T1.14.14.14.2.m1.2.3.1.cmml" xref="S3.T1.14.14.14.2.m1.2.3.2"><cn type="integer" id="S3.T1.14.14.14.2.m1.1.1.cmml" xref="S3.T1.14.14.14.2.m1.1.1">22</cn><cn type="integer" id="S3.T1.14.14.14.2.m1.2.2.cmml" xref="S3.T1.14.14.14.2.m1.2.2">671</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m1.2c">22,671</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.16.16.16" class="ltx_tr">
<th id="S3.T1.16.16.16.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 30)</th>
<td id="S3.T1.15.15.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.15.15.15.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.15.15.15.1.m1.2a"><mrow id="S3.T1.15.15.15.1.m1.2.3.2" xref="S3.T1.15.15.15.1.m1.2.3.1.cmml"><mn id="S3.T1.15.15.15.1.m1.1.1" xref="S3.T1.15.15.15.1.m1.1.1.cmml">25</mn><mo id="S3.T1.15.15.15.1.m1.2.3.2.1" xref="S3.T1.15.15.15.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.15.15.15.1.m1.2.2" xref="S3.T1.15.15.15.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.1.m1.2b"><list id="S3.T1.15.15.15.1.m1.2.3.1.cmml" xref="S3.T1.15.15.15.1.m1.2.3.2"><cn type="integer" id="S3.T1.15.15.15.1.m1.1.1.cmml" xref="S3.T1.15.15.15.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.15.15.15.1.m1.2.2.cmml" xref="S3.T1.15.15.15.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.16.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.16.16.16.2.m1.2" class="ltx_Math" alttext="23,253" display="inline"><semantics id="S3.T1.16.16.16.2.m1.2a"><mrow id="S3.T1.16.16.16.2.m1.2.3.2" xref="S3.T1.16.16.16.2.m1.2.3.1.cmml"><mn id="S3.T1.16.16.16.2.m1.1.1" xref="S3.T1.16.16.16.2.m1.1.1.cmml">23</mn><mo id="S3.T1.16.16.16.2.m1.2.3.2.1" xref="S3.T1.16.16.16.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.16.16.16.2.m1.2.2" xref="S3.T1.16.16.16.2.m1.2.2.cmml">253</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.2.m1.2b"><list id="S3.T1.16.16.16.2.m1.2.3.1.cmml" xref="S3.T1.16.16.16.2.m1.2.3.2"><cn type="integer" id="S3.T1.16.16.16.2.m1.1.1.cmml" xref="S3.T1.16.16.16.2.m1.1.1">23</cn><cn type="integer" id="S3.T1.16.16.16.2.m1.2.2.cmml" xref="S3.T1.16.16.16.2.m1.2.2">253</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.2.m1.2c">23,253</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.18.18.18" class="ltx_tr">
<th id="S3.T1.18.18.18.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 40)</th>
<td id="S3.T1.17.17.17.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.17.17.17.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.17.17.17.1.m1.2a"><mrow id="S3.T1.17.17.17.1.m1.2.3.2" xref="S3.T1.17.17.17.1.m1.2.3.1.cmml"><mn id="S3.T1.17.17.17.1.m1.1.1" xref="S3.T1.17.17.17.1.m1.1.1.cmml">25</mn><mo id="S3.T1.17.17.17.1.m1.2.3.2.1" xref="S3.T1.17.17.17.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.17.17.17.1.m1.2.2" xref="S3.T1.17.17.17.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.17.1.m1.2b"><list id="S3.T1.17.17.17.1.m1.2.3.1.cmml" xref="S3.T1.17.17.17.1.m1.2.3.2"><cn type="integer" id="S3.T1.17.17.17.1.m1.1.1.cmml" xref="S3.T1.17.17.17.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.17.17.17.1.m1.2.2.cmml" xref="S3.T1.17.17.17.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.17.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.18.18.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.18.18.18.2.m1.2" class="ltx_Math" alttext="23,513" display="inline"><semantics id="S3.T1.18.18.18.2.m1.2a"><mrow id="S3.T1.18.18.18.2.m1.2.3.2" xref="S3.T1.18.18.18.2.m1.2.3.1.cmml"><mn id="S3.T1.18.18.18.2.m1.1.1" xref="S3.T1.18.18.18.2.m1.1.1.cmml">23</mn><mo id="S3.T1.18.18.18.2.m1.2.3.2.1" xref="S3.T1.18.18.18.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.18.18.18.2.m1.2.2" xref="S3.T1.18.18.18.2.m1.2.2.cmml">513</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.18.2.m1.2b"><list id="S3.T1.18.18.18.2.m1.2.3.1.cmml" xref="S3.T1.18.18.18.2.m1.2.3.2"><cn type="integer" id="S3.T1.18.18.18.2.m1.1.1.cmml" xref="S3.T1.18.18.18.2.m1.1.1">23</cn><cn type="integer" id="S3.T1.18.18.18.2.m1.2.2.cmml" xref="S3.T1.18.18.18.2.m1.2.2">513</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.18.2.m1.2c">23,513</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.20.20.20" class="ltx_tr">
<th id="S3.T1.20.20.20.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 50)</th>
<td id="S3.T1.19.19.19.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.19.19.19.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.19.19.19.1.m1.2a"><mrow id="S3.T1.19.19.19.1.m1.2.3.2" xref="S3.T1.19.19.19.1.m1.2.3.1.cmml"><mn id="S3.T1.19.19.19.1.m1.1.1" xref="S3.T1.19.19.19.1.m1.1.1.cmml">25</mn><mo id="S3.T1.19.19.19.1.m1.2.3.2.1" xref="S3.T1.19.19.19.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.19.19.19.1.m1.2.2" xref="S3.T1.19.19.19.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.19.19.19.1.m1.2b"><list id="S3.T1.19.19.19.1.m1.2.3.1.cmml" xref="S3.T1.19.19.19.1.m1.2.3.2"><cn type="integer" id="S3.T1.19.19.19.1.m1.1.1.cmml" xref="S3.T1.19.19.19.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.19.19.19.1.m1.2.2.cmml" xref="S3.T1.19.19.19.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.19.19.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.20.20.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.20.20.20.2.m1.2" class="ltx_Math" alttext="22,671" display="inline"><semantics id="S3.T1.20.20.20.2.m1.2a"><mrow id="S3.T1.20.20.20.2.m1.2.3.2" xref="S3.T1.20.20.20.2.m1.2.3.1.cmml"><mn id="S3.T1.20.20.20.2.m1.1.1" xref="S3.T1.20.20.20.2.m1.1.1.cmml">22</mn><mo id="S3.T1.20.20.20.2.m1.2.3.2.1" xref="S3.T1.20.20.20.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.20.20.20.2.m1.2.2" xref="S3.T1.20.20.20.2.m1.2.2.cmml">671</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.20.20.20.2.m1.2b"><list id="S3.T1.20.20.20.2.m1.2.3.1.cmml" xref="S3.T1.20.20.20.2.m1.2.3.2"><cn type="integer" id="S3.T1.20.20.20.2.m1.1.1.cmml" xref="S3.T1.20.20.20.2.m1.1.1">22</cn><cn type="integer" id="S3.T1.20.20.20.2.m1.2.2.cmml" xref="S3.T1.20.20.20.2.m1.2.2">671</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.20.20.2.m1.2c">22,671</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.22.22.22" class="ltx_tr">
<th id="S3.T1.22.22.22.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 60)</th>
<td id="S3.T1.21.21.21.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.21.21.21.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.21.21.21.1.m1.2a"><mrow id="S3.T1.21.21.21.1.m1.2.3.2" xref="S3.T1.21.21.21.1.m1.2.3.1.cmml"><mn id="S3.T1.21.21.21.1.m1.1.1" xref="S3.T1.21.21.21.1.m1.1.1.cmml">25</mn><mo id="S3.T1.21.21.21.1.m1.2.3.2.1" xref="S3.T1.21.21.21.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.21.21.21.1.m1.2.2" xref="S3.T1.21.21.21.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.21.21.21.1.m1.2b"><list id="S3.T1.21.21.21.1.m1.2.3.1.cmml" xref="S3.T1.21.21.21.1.m1.2.3.2"><cn type="integer" id="S3.T1.21.21.21.1.m1.1.1.cmml" xref="S3.T1.21.21.21.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.21.21.21.1.m1.2.2.cmml" xref="S3.T1.21.21.21.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.21.21.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.22.22.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T1.22.22.22.2.m1.2" class="ltx_Math" alttext="17,174" display="inline"><semantics id="S3.T1.22.22.22.2.m1.2a"><mrow id="S3.T1.22.22.22.2.m1.2.3.2" xref="S3.T1.22.22.22.2.m1.2.3.1.cmml"><mn id="S3.T1.22.22.22.2.m1.1.1" xref="S3.T1.22.22.22.2.m1.1.1.cmml">17</mn><mo id="S3.T1.22.22.22.2.m1.2.3.2.1" xref="S3.T1.22.22.22.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.22.22.22.2.m1.2.2" xref="S3.T1.22.22.22.2.m1.2.2.cmml">174</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.22.22.22.2.m1.2b"><list id="S3.T1.22.22.22.2.m1.2.3.1.cmml" xref="S3.T1.22.22.22.2.m1.2.3.2"><cn type="integer" id="S3.T1.22.22.22.2.m1.1.1.cmml" xref="S3.T1.22.22.22.2.m1.1.1">17</cn><cn type="integer" id="S3.T1.22.22.22.2.m1.2.2.cmml" xref="S3.T1.22.22.22.2.m1.2.2">174</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.22.22.22.2.m1.2c">17,174</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.24.24.24" class="ltx_tr">
<th id="S3.T1.24.24.24.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">SAM (target age = 70)</th>
<td id="S3.T1.23.23.23.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S3.T1.23.23.23.1.m1.2" class="ltx_Math" alttext="25,918" display="inline"><semantics id="S3.T1.23.23.23.1.m1.2a"><mrow id="S3.T1.23.23.23.1.m1.2.3.2" xref="S3.T1.23.23.23.1.m1.2.3.1.cmml"><mn id="S3.T1.23.23.23.1.m1.1.1" xref="S3.T1.23.23.23.1.m1.1.1.cmml">25</mn><mo id="S3.T1.23.23.23.1.m1.2.3.2.1" xref="S3.T1.23.23.23.1.m1.2.3.1.cmml">,</mo><mn id="S3.T1.23.23.23.1.m1.2.2" xref="S3.T1.23.23.23.1.m1.2.2.cmml">918</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.23.23.23.1.m1.2b"><list id="S3.T1.23.23.23.1.m1.2.3.1.cmml" xref="S3.T1.23.23.23.1.m1.2.3.2"><cn type="integer" id="S3.T1.23.23.23.1.m1.1.1.cmml" xref="S3.T1.23.23.23.1.m1.1.1">25</cn><cn type="integer" id="S3.T1.23.23.23.1.m1.2.2.cmml" xref="S3.T1.23.23.23.1.m1.2.2">918</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.23.23.23.1.m1.2c">25,918</annotation></semantics></math></td>
<td id="S3.T1.24.24.24.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S3.T1.24.24.24.2.m1.2" class="ltx_Math" alttext="10,028" display="inline"><semantics id="S3.T1.24.24.24.2.m1.2a"><mrow id="S3.T1.24.24.24.2.m1.2.3.2" xref="S3.T1.24.24.24.2.m1.2.3.1.cmml"><mn id="S3.T1.24.24.24.2.m1.1.1" xref="S3.T1.24.24.24.2.m1.1.1.cmml">10</mn><mo id="S3.T1.24.24.24.2.m1.2.3.2.1" xref="S3.T1.24.24.24.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.24.24.24.2.m1.2.2" xref="S3.T1.24.24.24.2.m1.2.2.cmml">028</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.24.24.24.2.m1.2b"><list id="S3.T1.24.24.24.2.m1.2.3.1.cmml" xref="S3.T1.24.24.24.2.m1.2.3.2"><cn type="integer" id="S3.T1.24.24.24.2.m1.1.1.cmml" xref="S3.T1.24.24.24.2.m1.1.1">10</cn><cn type="integer" id="S3.T1.24.24.24.2.m1.2.2.cmml" xref="S3.T1.24.24.24.2.m1.2.2">028</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.24.24.24.2.m1.2c">10,028</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.26.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.27.2" class="ltx_text" style="font-size:90%;">General Database Information </span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Bona Fide Reference Datasets</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.7" class="ltx_p">To compare the synthetic data with real data, we choose a representative dataset containing <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="17,919" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">17</mn><mo id="S3.SS2.p1.1.m1.2.3.2.1" xref="S3.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">919</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><list id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.2"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">17</cn><cn type="integer" id="S3.SS2.p1.1.m1.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2">919</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">17,919</annotation></semantics></math> images from FRGC-V2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Ph05</a>]</cite>, which is known for its high-quality images and constrained conditions resembling those of border crossing capturing environments. However, despite the good representativeness, FRGC-V2 samples are not annotated with ground-truth ages, thus limiting the age-based performance comparison to the synthetic datasets. 
<br class="ltx_break">To overcome this limitation, the UNCW face ageing dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">RT06</a>]</cite> is further used in our analysis, including more than <math id="S3.SS2.p1.2.m2.2" class="ltx_Math" alttext="55,000" display="inline"><semantics id="S3.SS2.p1.2.m2.2a"><mrow id="S3.SS2.p1.2.m2.2.3.2" xref="S3.SS2.p1.2.m2.2.3.1.cmml"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">55</mn><mo id="S3.SS2.p1.2.m2.2.3.2.1" xref="S3.SS2.p1.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.2.m2.2.2" xref="S3.SS2.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><list id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.2"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">55</cn><cn type="integer" id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">55,000</annotation></semantics></math> face images of more than <math id="S3.SS2.p1.3.m3.2" class="ltx_Math" alttext="13,000" display="inline"><semantics id="S3.SS2.p1.3.m3.2a"><mrow id="S3.SS2.p1.3.m3.2.3.2" xref="S3.SS2.p1.3.m3.2.3.1.cmml"><mn id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">13</mn><mo id="S3.SS2.p1.3.m3.2.3.2.1" xref="S3.SS2.p1.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.3.m3.2.2" xref="S3.SS2.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.2b"><list id="S3.SS2.p1.3.m3.2.3.1.cmml" xref="S3.SS2.p1.3.m3.2.3.2"><cn type="integer" id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">13</cn><cn type="integer" id="S3.SS2.p1.3.m3.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.2c">13,000</annotation></semantics></math> individuals with exact age annotations, where for mated comparison trials the difference in age is ranging from 164 days to <math id="S3.SS2.p1.4.m4.2" class="ltx_Math" alttext="1,681" display="inline"><semantics id="S3.SS2.p1.4.m4.2a"><mrow id="S3.SS2.p1.4.m4.2.3.2" xref="S3.SS2.p1.4.m4.2.3.1.cmml"><mn id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">1</mn><mo id="S3.SS2.p1.4.m4.2.3.2.1" xref="S3.SS2.p1.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.4.m4.2.2" xref="S3.SS2.p1.4.m4.2.2.cmml">681</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.2b"><list id="S3.SS2.p1.4.m4.2.3.1.cmml" xref="S3.SS2.p1.4.m4.2.3.2"><cn type="integer" id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">1</cn><cn type="integer" id="S3.SS2.p1.4.m4.2.2.cmml" xref="S3.SS2.p1.4.m4.2.2">681</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.2c">1,681</annotation></semantics></math> days. In order to analyse short-term ageing effects and their impact on the face recognition performance, we sorted out mated samples with less than 1 year passed between the probe and reference image capturing, leaving an amount of <math id="S3.SS2.p1.5.m5.2" class="ltx_Math" alttext="37,423" display="inline"><semantics id="S3.SS2.p1.5.m5.2a"><mrow id="S3.SS2.p1.5.m5.2.3.2" xref="S3.SS2.p1.5.m5.2.3.1.cmml"><mn id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">37</mn><mo id="S3.SS2.p1.5.m5.2.3.2.1" xref="S3.SS2.p1.5.m5.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.5.m5.2.2" xref="S3.SS2.p1.5.m5.2.2.cmml">423</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.2b"><list id="S3.SS2.p1.5.m5.2.3.1.cmml" xref="S3.SS2.p1.5.m5.2.3.2"><cn type="integer" id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">37</cn><cn type="integer" id="S3.SS2.p1.5.m5.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2">423</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.2c">37,423</annotation></semantics></math> face images. Similarly, the synthetic datasets have been further reduced to only include mated pairs with age differences within 1 to 5 years. As no age labels are given for the synthetic data, we apply the C3AE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Zh19</a>]</cite> age estimator to predict the age labels for each face image individually. The resulting short-term InterFaceGAN (ST-InterFaceGAN) and SAM (ST-SAM) datasets comprise <math id="S3.SS2.p1.6.m6.2" class="ltx_Math" alttext="10,772" display="inline"><semantics id="S3.SS2.p1.6.m6.2a"><mrow id="S3.SS2.p1.6.m6.2.3.2" xref="S3.SS2.p1.6.m6.2.3.1.cmml"><mn id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">10</mn><mo id="S3.SS2.p1.6.m6.2.3.2.1" xref="S3.SS2.p1.6.m6.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.6.m6.2.2" xref="S3.SS2.p1.6.m6.2.2.cmml">772</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.2b"><list id="S3.SS2.p1.6.m6.2.3.1.cmml" xref="S3.SS2.p1.6.m6.2.3.2"><cn type="integer" id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">10</cn><cn type="integer" id="S3.SS2.p1.6.m6.2.2.cmml" xref="S3.SS2.p1.6.m6.2.2">772</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.2c">10,772</annotation></semantics></math> and <math id="S3.SS2.p1.7.m7.2" class="ltx_Math" alttext="12,298" display="inline"><semantics id="S3.SS2.p1.7.m7.2a"><mrow id="S3.SS2.p1.7.m7.2.3.2" xref="S3.SS2.p1.7.m7.2.3.1.cmml"><mn id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">12</mn><mo id="S3.SS2.p1.7.m7.2.3.2.1" xref="S3.SS2.p1.7.m7.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.7.m7.2.2" xref="S3.SS2.p1.7.m7.2.2.cmml">298</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.2b"><list id="S3.SS2.p1.7.m7.2.3.1.cmml" xref="S3.SS2.p1.7.m7.2.3.2"><cn type="integer" id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">12</cn><cn type="integer" id="S3.SS2.p1.7.m7.2.2.cmml" xref="S3.SS2.p1.7.m7.2.2">298</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.2c">12,298</annotation></semantics></math> samples.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Ageing Accuracy</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">This section evaluates the effectiveness of the FAM frameworks in terms of their ageing accuracy. Since the analysed face images are fully synthetic, no ground-truth age labels are given to assess the exact age difference between the target and the actual age of the individuals. Instead, a pre-trained age estimation network (C3AE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Zh19</a>]</cite> is utilised to predict the ground-truth age labels to determine the ageing accuracy performance. The predicted ages of face images generated with InterFaceGAN and SAM are visualised as boxplots in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1 Ageing Accuracy ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">By the nature of InterFaceGAN, it is not possible in the interaction with the latent vectors to specify target ages since ageing is achieved by continuously shifting the latent vectors in the non-linear latent space of StyleGAN. Therefore, Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1 Ageing Accuracy ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> aims to strengthen the understanding between latent space distances and their corresponding age differences. While the red boxplot shows the predicted ages of the base images, the decreasing medians of the left-sided boxplots verify the effectiveness of InterFaceGAN for FAR. Meanwhile, the increasing trend of medians of the right-sided boxplots confirms the same effectiveness for FAP. However, it is also noticeable that the same distances can lead to a diversity of age differences thus demonstrating the non-linearity of the latent space.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Additionally, Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1 Ageing Accuracy ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the ageing accuracy results of SAM, comparing the target ages (x-axis) with the predicted ages (y-axis). Other than InterFaceGAN, SAM enables us to specify target ages, thus allowing to evaluate the ageing accuracy performance more precisely. That to say, a linear increase of the boxplot’s medians (horizontal lines within boxes) corresponds to a perfect ageing accuracy since the average predicted age equals the target ages. By analysing and comparing the medians, SAM proves to reliably manipulate ages with target ages chosen between 20 and 40 years. However, the ageing accuracy of SAM drops for more extreme target ages – i.e., children and seniors. This observation is a typical sign of biased image generation models, which were trained on unbalanced datasets with unequal distribution of soft biometrics. Since SAM utilises the pre-trained generator of StyleGAN2 trained on the web-crawled FFHQ dataset, most of the individuals seen during training are within 30 to 40 years. As a consequence, the generator fails to learn the craniofacial growth occurring during adolescence, as well as the intensifying of wrinkles and furrows occurring with older ages. The issue of demographic biases is due to a general data scarcity of samples having underrepresented characteristics. Despite the so caused inaccuracies, the average ageing span of SAM includes 41 years, ranging from 19 to 60 years – thus suitable to simulate longer-term ageing patterns.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F2.4" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:275.9pt;vertical-align:-275.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.0pt,0.0pt) scale(0.915508939374452,0.915508939374452) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/age_accuracy_Interfacegan.png" id="S4.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="399" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/age_accuracy_SAM.png" id="S4.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="399" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.5.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.6.2" class="ltx_text" style="font-size:90%;">Ageing accuracy analysis of InterFaceGAN (left) and SAM (right)  </span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Face Image Quality Assessment</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The main goal of this subsection is to compare the age-modified datasets with the reference bona fide datasets by utilising face quality assessment algorithms (FQAAs). FQAAs are developed to predict the biometric quality of a given face image by translating its suitability for face recognition to a scalar value between [0, 1] (1= “Perfect biometric face image quality”, 0=”worst biometric quality”). In particular, two well-established deep learning-based FQAAs are selected for this task: FaceQnet v1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">He20</a>]</cite> and SER-FIQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">Te20</a>]</cite>. 
<br class="ltx_break">In Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 Face Image Quality Assessment ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the notched boxplots visualise the median face image qualities with their 95%-confidence intervals. In addition, the horizontal red line represents the median of the FRGC-V2 reference dataset. This view enables the analysis of statistical deviations of the synthetic datasets’ medians to the median biometric quality of real data. In this context, Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 Face Image Quality Assessment ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reveals that all boxplots enclose the red line, thus indicating no statistical differences in the biometric quality across all age-modified datasets. 
<br class="ltx_break">However, it is noticeable that the medians of the synthetic datasets estimated with SER-FIQ consistently falls below the red line, thus supporting the conclusion of minor biometric quality differences between synthetic and real data. In contrast, the medians estimated with FaceQnet v1 fluctuate below and and above the red reference line, hence strengthening the ”no difference” hypothesis.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F3.6" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:207.6pt;vertical-align:-207.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-90.1pt,0.0pt) scale(0.658229264974789,0.658229264974789) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/InterfaceGAN_faceqnetv1.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="399" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/InterfaceGAN_serfiq.png" id="S4.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="417" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F3.7" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:202.4pt;vertical-align:-202.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.7pt,0.0pt) scale(0.66925303755363,0.66925303755363) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/SAM_faceqnetv1.png" id="S4.F3.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="399" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/SAM_serfiq.png" id="S4.F3.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="399" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.8.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.9.2" class="ltx_text" style="font-size:90%;">Biometric quality analysis of synthetic images generated with InterFaceGAN (top) and SAM (bottom). The biometric quality is estimated with two FQAAs: SER-FIQ (right) and FaceQnet v1 (left). The red line visualises the median biometric quality of the bona fide reference dataset (FRGC-V2). </span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Comparison Score Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">This section analyses the mated and non-mated comparison scores obtained by comparing each base image to the age-modified versions (mated) and other age-modified identities (non-mated). Figure <a href="#S4.F4" title="Figure 4 ‣ 4.3 Comparison Score Analysis ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that increasing age modifications lead to decreasing similarities between the synthetic mated samples generated with InterFaceGAN. This observation corresponds to our initial hypothesis that existing face recognition systems are not trained to compensate ageing effects. The more years pass between the enrolment process and the re-capturing of a probe image, the more intense ageing effects will occur and thus affect the recognition performance. On the contrary, the non-mated comparison scores illustrate only minor performance differences, as seen by the nearly identical distributions. 
<br class="ltx_break">Similarly, Figure <a href="#S4.F4" title="Figure 4 ‣ 4.3 Comparison Score Analysis ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the kernel density plots of comparison scores obtained by comparing synthetic samples generated with SAM. The general behaviour of the mated and non-mated comparison scores is similar to the results reported with InterFaceGAN. The more the target age differs from the average StyleGAN age (34y), the less similar the mated samples become. This loss in identity over time can either be caused by the FAM algorithms or the incapability of ArcFace to handle long-term age differences between the probe and reference sample. That to say, the disentanglement of these two sources of potential identity loss remains a challenging task.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F4.6" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:280.3pt;vertical-align:-280.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.4pt,0.0pt) scale(0.830685157547559,0.830685157547559) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_mated_interfacegan.png" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_nonmated_interfacegan.png" id="S4.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F4.7" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:280.3pt;vertical-align:-280.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.4pt,0.0pt) scale(0.830685157547559,0.830685157547559) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_mated_sam_inv.png" id="S4.F4.3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_nonmated_sam_inv.png" id="S4.F4.4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.8.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.9.2" class="ltx_text" style="font-size:90%;">Mated (left column) and non-mated (right column) comparison scores based on age-modified datasets generated with InterFaceGAN (top) and SAM (bottom) </span></figcaption>
</figure>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Synthetic vs Natural Face Ageing</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">The final part of this section analyses the impact of short-term ageing effects based on the ST-ageing datasets introduced in Section <a href="#S3.SS2" title="3.2 Bona Fide Reference Datasets ‣ 3 Datasets ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. Figure <a href="#S4.F5" title="Figure 5 ‣ 4.3.1 Synthetic vs Natural Face Ageing ‣ 4.3 Comparison Score Analysis ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the mated comparison score distributions, indicating no significant differences between mated samples collected without ageing (FRGC v2.0) and those with age gaps within 1 to 5 years (UNCW). The main reason for this observation is most likely due to minor ageing patterns given the short time intervals available in this analysis. A similar behaviour is observed with SAM generated face images (red line), hence indicating that the synthetic mated samples are similar to those seen in real data. 
<br class="ltx_break">Finally, the cyan curve achieved the highest similarity scores, emphasising the capability of InterFaceGAN to preserve identity information during the age synthesis. Despite the effective identity preservation rate, the comparison to the real curves reveals a large domain gap, thus potentially overestimating mated comparison scores observed in real-world settings. Another domain-gap crystallizes in the non-mated comparison scores in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.3.1 Synthetic vs Natural Face Ageing ‣ 4.3 Comparison Score Analysis ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>: While the synthetic lines are nearly identical, their average scores are higher than those measured for bona fide data.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F5.4" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:280.3pt;vertical-align:-280.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.4pt,0.0pt) scale(0.830685157547559,0.830685157547559) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_mated_agediff.png" id="S4.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.08207/assets/figures/cscore_nonmated_agediff.png" id="S4.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.5.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.6.2" class="ltx_text" style="font-size:90%;">Mated (left) and non-mated (right) comparison scores based on synthetic and real datasets with age difference within 1-5 years </span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The main focus of this work is to analyse the impact of face ageing on face recognition systems by using FAM to generate synthetic mated and non-mated samples with varying age gaps. For this purpose, the FAM performance is analysed in terms of the biometric quality (Section <a href="#S4.SS2" title="4.2 Face Image Quality Assessment ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and identity preservation (Section <a href="#S4.SS3" title="4.3 Comparison Score Analysis ‣ 4 Experimental Results ‣ Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>) of the generated mated and non-mated face images. The main findings of this work underline the capability of synthetic face images to interfere with face recognition systems similar than bona fide data. Further, the comparison score analysis indicates only a minor deterioration in the recognition performance for short and medium-term ageing intervals - as shown by comparisons conducted in the synthetic and real domain. Nevertheless, the mated comparison scores significantly decrease for long-term age intervals or extreme target age choices. 
<br class="ltx_break">Finally, this work demonstrates the future value of synthetic face images in analysing the age-robustness of FR systems. Accelerated by the remarkable progress of deep generative networks, we believe the domain gap between synthetic and bona fide data to vanish over time. Especially in the context of face ageing, FAM algorithms are crucial for avoiding long-lasting data collection initiatives, which are not feasible given the time constraints of real-world applications. In an endeavour of closing the domain gap between synthetic and bona fide data, future research may benefit from new concepts, such as 3D multi-view image synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">Ch22</a>]</cite> in order to better preserve spatial information of the faces and support the generation of geometry-consistent mated samples.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Al21]</span>
<span class="ltx_bibblock">
Albiero, Vitor; Chen, Xingyu; Yin, Xi; Pang, Guan; Hassner, Tal: img2pose: Face
alignment and detection via 6dof, face pose estimation.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 7617–7627, 2021.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[APCO21]</span>
<span class="ltx_bibblock">
Alaluf, Yuval; Patashnik, Or; Cohen-Or, Daniel: Only a Matter of Style: Age
Transformation Using a Style-Based Regression Model.

</span>
<span class="ltx_bibblock">ACM Trans. Graph., 40(4), 2021.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ch22]</span>
<span class="ltx_bibblock">
Chan, Eric R; Lin, Connor Z; Chan, Matthew A; Nagano, Koki; Pan, Boxiao;
De Mello, Shalini; Gallo, Orazio; Guibas, Leonidas J; Tremblay, Jonathan;
Khamis, Sameh et al.: Efficient geometry-aware 3D generative adversarial
networks.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 16123–16133, 2022.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[De19]</span>
<span class="ltx_bibblock">
Deng, Jiankang; Guo, Jia; Xue, Niannan; Zafeiriou, Stefanos: Arcface: Additive
angular margin loss for deep face recognition.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition.

</span>
<span class="ltx_bibblock">pp. 4690–4699, 2019.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Eu19]</span>
<span class="ltx_bibblock">
European Council: , Commission Implementing Decision 2019/329 of 25 February
2019 laying down the specifications for the quality, resolution and use of
fingerprints and facial image for biometric verification and identification
in the Entry/Exit System (EES), February 2019.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Fr15]</span>
<span class="ltx_bibblock">
Frontex: , Best practice technical guidelines for Automated Border Control
(ABC) systems, 2015.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Gr21]</span>
<span class="ltx_bibblock">
Grimmer, Marcel; Zhang, Haoyu; Ramachandra, R.; Raja, K.; Busch, C.: Generation
of Non-Deterministic Synthetic Face Datasets Guided by Identity Priors.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2112.03632, 2021.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GRB21]</span>
<span class="ltx_bibblock">
Grimmer, Marcel; Ramachandra, Raghavendra; Busch, Christoph: Deep face age
progression: A survey.

</span>
<span class="ltx_bibblock">IEEE Access, 9:83376–83393, 2021.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[He20]</span>
<span class="ltx_bibblock">
Hernandez-Ortega, Javier; Galbally, Javier; Fierrez, Julian; Beslay, Laurent:
Biometric quality: Review and application to face recognition with faceqnet.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2006.03298, 2020.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ka20]</span>
<span class="ltx_bibblock">
Karras, Tero; Laine, Samuli; Aittala, Miika; Hellsten, Janne; Lehtinen, Jaakko;
Aila, Timo: Analyzing and improving the image quality of stylegan.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 8110–8119, 2020.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KLA19]</span>
<span class="ltx_bibblock">
Karras, Tero; Laine, Samuli; Aila, Timo: A style-based generator architecture
for generative adversarial networks.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 4401–4410, 2019.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ph05]</span>
<span class="ltx_bibblock">
Phillips, P. J.; Flynn, P. J.; Scruggs, T.; Bowyer, K. W.; Jin Chang;
Hoffman, K.; Marques, J.; Jaesik Min; Worek, W.: Overview of the face
recognition grand challenge.

</span>
<span class="ltx_bibblock">In: 2005 IEEE Computer Society Conference on Computer Vision and
Pattern Recognition (CVPR’05).

</span>
<span class="ltx_bibblock">pp. 947–954 vol. 1, June 2005.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ri21]</span>
<span class="ltx_bibblock">
Richardson, Elad; Alaluf, Yuval; Patashnik, Or; Nitzan, Yotam; Azar, Yaniv;
Shapiro, Stav; Cohen-Or, Daniel: Encoding in style: a stylegan encoder for
image-to-image translation.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 2287–2296, 2021.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RT06]</span>
<span class="ltx_bibblock">
Ricanek, Karl; Tesafaye, Tamirat: Morph: A longitudinal image database of
normal adult age-progression.

</span>
<span class="ltx_bibblock">In: 7th international conference on automatic face and gesture
recognition (FGR06).

</span>
<span class="ltx_bibblock">IEEE, pp. 341–345, 2006.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Sh20]</span>
<span class="ltx_bibblock">
Shen, Yujun; Yang, Ceyuan; Tang, Xiaoou; Zhou, Bolei: Interfacegan:
Interpreting the disentangled face representation learned by gans.

</span>
<span class="ltx_bibblock">IEEE transactions on pattern analysis and machine intelligence, 2020.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Te20]</span>
<span class="ltx_bibblock">
Terhorst, Philipp; Kolf, Jan Niklas; Damer, Naser; Kirchbuchner, Florian;
Kuijper, Arjan: SER-FIQ: Unsupervised estimation of face image quality based
on stochastic embedding robustness.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 5651–5660, 2020.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zh19]</span>
<span class="ltx_bibblock">
Zhang, Chao; Liu, Shuaicheng; Xu, Xun; Zhu, Ce: C3AE: Exploring the limits of
compact model for age estimation.

</span>
<span class="ltx_bibblock">In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition.

</span>
<span class="ltx_bibblock">pp. 12587–12596, 2019.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zh21]</span>
<span class="ltx_bibblock">
Zhang, Haoyu; Grimmer, Marcel; Ramachandra, Raghavendra; Raja, Kiran; Busch,
Christoph: On the Applicability of Synthetic Data for Face Recognition.

</span>
<span class="ltx_bibblock">In: 2021 IEEE International Workshop on Biometrics and Forensics
(IWBF).

</span>
<span class="ltx_bibblock">IEEE, pp. 1–6, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.08206" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.08207" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.08207">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.08207" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.08208" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 19:38:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
